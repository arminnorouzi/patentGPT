<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007157A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007157</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17930928</doc-number><date>20220909</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>235</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>2352</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>2356</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>2351</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>2353</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>243</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">Systems and Methods for Sampling Images</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17448481</doc-number><date>20210922</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11470259</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17930928</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16804052</doc-number><date>20200228</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11153501</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17448481</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15851901</doc-number><date>20171222</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10609294</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16804052</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>X Development LLC</orgname><address><city>Mountain View</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Cooper</last-name><first-name>Emily</first-name><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Talbott</last-name><first-name>Chad</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An example method includes determining, by a controller of an image capture system, a plurality of sets of exposure parameter values for one or more exposure parameters. The plurality of sets of exposure parameter values are determined at an exposure determination rate. The method further includes capturing, by an image capture device of the image capture system, a plurality of images. Each image of the plurality of images is captured according to a set of exposure parameter values of the plurality of sets of exposure parameter values. The method also includes sending, by the controller of the image capture system to an image processing unit, a subset of the plurality of images. Each subset of images is sent at a sampling rate, and the sampling rate is less than the exposure determination rate.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="198.97mm" wi="158.75mm" file="US20230007157A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="212.68mm" wi="163.24mm" file="US20230007157A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="205.74mm" wi="141.22mm" file="US20230007157A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="205.74mm" wi="155.87mm" file="US20230007157A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="205.66mm" wi="137.16mm" file="US20230007157A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="218.61mm" wi="168.91mm" file="US20230007157A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="225.64mm" wi="166.29mm" file="US20230007157A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="218.19mm" wi="155.70mm" file="US20230007157A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="222.84mm" wi="143.34mm" file="US20230007157A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application is a continuation of, and claims priority to, U.S. patent application Ser. No. No. 17/448,481, filed on Sep. 22, 2021, which is a continuation of, and claims priority to U.S. patent application Ser. No. 16/804,052, filed on Feb. 28, 2020, which is now U.S. Pat. No. 11,153,501, issued on Oct. 19, 2021, which is a continuation of, and claims priority to, U.S. patent application Ser. No. 15/851,901, filed Dec. 22, 2017, which is now U.S. Pat. No. 10,609,294, issued on Mar. 31, 2020, and which are hereby incorporated by reference into the present application in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">As technology advances, various types of robotic devices are being created for performing a variety of functions that may assist users. Robotic devices may be used for applications involving material handling, transportation, welding, assembly, and dispensing, among others. Over time, the manner in which these robotic systems operate is becoming more intelligent, efficient, and intuitive. As robotic systems become increasingly prevalent in numerous aspects of modern life, it is desirable for robotic systems to be efficient. Therefore, a demand for efficient robotic systems has helped open up a field of innovation in actuators, movement, sensing techniques, as well as component design and assembly.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">The present application discloses implementations that relate to image processing systems. In one example, the present application describes a method. The method includes determining, by a controller of an image capture system, a plurality of sets of exposure parameter values for one or more exposure parameters. The plurality of sets of exposure parameter values are determined at an exposure determination rate, where the exposure determination rate includes a rate at which captured images are processed by the controller to determine each set of exposure parameter values. The method further includes capturing, by an image capture device of the image capture system, a plurality of images. Each image of the plurality of images is captured according to a set of exposure parameter values of the plurality of sets of exposure parameter values. The method also includes sending, by the controller of the image capture system to an image processing unit, a subset of the plurality of images. Each subset of images is sent at a sampling rate, and the sampling rate is less than the exposure determination rate.</p><p id="p-0005" num="0004">In another example, the present application describes a system. The system includes at least one image capture device, an image processing unit, and a controller having one or more processors. The system further includes a non-transitory computer readable medium and program instructions stored on the non-transitory computer readable medium and executable by the one or more processors to perform functions. The instructions are executable to cause the at least one image capture device to capture a plurality of images. The instructions are further executable to determine a plurality of sets of exposure parameter values for one or more exposure parameters that correspond to the plurality of images. The plurality of sets of exposure parameter values are determined at an exposure determination rate, where the exposure determination rate includes a rate at which the plurality of images are processed by the controller to determine each set of exposure parameter values. The instructions are also executable to send, to the image processing unit, a subset of the plurality of images, wherein the subset of images is sent at a sampling rate, and wherein the sampling rate is less than the exposure determination rate.</p><p id="p-0006" num="0005">In yet another example, the present application describes a non-transitory computer readable medium. The non-transitory computer readable medium has stored thereon instructions executable by one or more processors to cause a computing system to perform functions. The functions include determining, by a controller of an image capture system, a plurality of sets of exposure parameter values for one or more exposure parameters. The plurality of sets of exposure parameter values are determined at an exposure determination rate, where the exposure determination rate includes a rate at which captured images are processed by the controller to determine each set of exposure parameter values. The functions further include capturing, by an image capture device of the image capture system, a plurality of images. Each image of the plurality of images is captured according to a set of exposure parameter values of the plurality of sets of exposure parameter values. The functions also include sending, by the controller of the image capture system to an image processing unit, a subset of the plurality of images. Each subset of images is sent at a sampling rate, and the sampling rate is less than the exposure determination rate.</p><p id="p-0007" num="0006">In an additional example, the present application describes a system. The system includes means for determining a plurality of sets of exposure parameter values for one or more exposure parameters. The plurality of sets of exposure parameter values are determined at an exposure determination rate, where the exposure determination rate includes a rate at which captured images are processed by the controller to determine each set of exposure parameter values. The system further includes means for capturing a plurality of images. Each image of the plurality of images is captured according to a set of exposure parameter values of the plurality of sets of exposure parameter values. The system also includes means for sending, to an image processing unit, a subset of the plurality of images. Each subset of images is sent at a sampling rate, and the sampling rate is less than the exposure determination rate.</p><p id="p-0008" num="0007">The foregoing summary is illustrative only and is not intended to be in any way limiting. In addition to the illustrative aspects, embodiments, and features described above, further aspects, embodiments, and features will become apparent by reference to the figures and the following detailed description and the accompanying drawings.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE FIGURES</heading><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a configuration of a robotic system, according to example embodiments.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a robotic arm, according to example embodiments.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a configuration of an image processing system, according to example embodiments.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates another configuration of an image processing system, according to example embodiments.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a timing diagram for an image processing system, according to example embodiments.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates operation of an image processing system, according to example embodiments.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates operation of another image processing system, according to example embodiments.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram of a method, according to example embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0017" num="0016">The following detailed description describes various features and operations of the disclosed systems and methods with reference to the accompanying figures. The illustrative system and method embodiments described herein are not meant to be limiting. It may be readily understood that certain aspects of the disclosed systems and methods can be arranged and combined in a wide variety of different configurations, all of which are contemplated herein.</p><heading id="h-0006" level="1">I. Overview</heading><p id="p-0018" num="0017">The present application discloses implementations that relate to image processing systems. An example system includes an image capture system and an image processing unit. The image capture system includes an image capture device and a controller. The image capture device is configured to capture images at a capture rate, and the controller is configured to determine a set of one or more exposure parameter values for each of the captured images at an exposure determination rate. The images are sampled by the controller and sent to the image processing unit at a sampling rate that is less than the exposure determination rate. The term &#x201c;sampling rate&#x201d; refers to a number of images that are sent by the controller to the image processing unit per unit time. Accordingly, only a subset of the captured images are processed by the image processing unit. Various types of image processing operations may be performed by the image processing unit on the sampled images, and the sampling rate may be determined based on an amount of time associated with performing the operations.</p><p id="p-0019" num="0018">Many systems use image processing systems to operate effectively. For instance, a robot may use an image processing system to recognize objects in an environment of the robot. Recognizing such objects may allow the robot to navigate within the environment, or to interact with the detected objects. Thus, a robot may rely on the accuracy of such image processing operations. Further, a robot may need to perform such operations quickly.</p><p id="p-0020" num="0019">A number of factors can affect the accuracy and speed of image processing operations. For example, dim photos may reduce the accuracy of color detection operations and off-focus or blurry images may increase the time required to perform edge detection operations. To account for this, image processing systems may perform pre-processing on images, alter parameters used when capturing images, or may only allow the capture of images in certain conditions. One such example can include performing auto-exposure on images. This allows subsequent operations to be performed more quickly and accurately because the subsequent operations use images with desired histogram distributions. Auto-exposure operations are also computationally simple relative to other operations, such as object detection operations or deblur operations, so auto-exposure operations can be performed quickly.</p><p id="p-0021" num="0020">Thus, various embodiments described herein include an image capture system that performs auto-exposure on a plurality of captured images. Each of the plurality of captured images is captured according to a set of one or more exposure parameter values determined by a controller of the image capture system. The controller can use pixel statistics of one or more prior images when determining the set of exposure parameter values for a captured image. Because determining the set of exposure parameters can be performed quickly, an image capture device of the image capture system can capture images at a high rate, while the controller determines the set of exposure parameters for each captured image.</p><p id="p-0022" num="0021">An image processing unit may perform image processing operations that are more computationally taxing than an auto-exposure operation. Accordingly, such operations may take longer than it takes the controller to determine sets of exposure parameter values. It therefore may be impracticable for the image processing unit to perform image processing operations on each of the plurality of captured images. But capturing images at a high rate allows the controller to determine sets of exposure parameter values that more effectively represent the scene captured in the images. Accordingly, the controller can sample some, but not all, of the images from the plurality of images captured by the image capture device to send to the image processing unit. This allows the sampled images to more effectively represent a scene, while still giving the image processing unit time to perform operations on an image before receiving another image. Further, because the controller does not send each captured image, less communication bandwidth is used. This can allow for more efficient communications between the controller and the image processing unit, particularly where the controller wirelessly communicates with the image processing unit.</p><p id="p-0023" num="0022">In some examples, additional steps may be taken to ensure that an image received by the image processing unit is fit for image processing operations. For example, a pre-processing unit may be included within the system that performs intermediate processing of an image. For example, the pre-processing unit can sample images in parallel with the image processing unit and determine a white level or focus level for those images. The pre-processing unit, or the controller of the image capture system, can then determine which images to send to the image processing unit based on the determined white level or focus level. In some examples, the pre-processing unit and the controller of the image capture device can be one and the same.</p><p id="p-0024" num="0023">In some examples, an image processing system can be part of another system, such as a robotic system. The robotic system may include a robot controller that determines actions for the robot, which may affect the operations performed by the image capture system. For example, the robot controller might determine a motion command for a robot that makes it more likely that the scene captured by the image capture device will experience a large change.</p><p id="p-0025" num="0024">In some embodiments, the sampling rate is constant (e.g., the controller samples and sends every nth captured image to the image processing unit). In other embodiments, the controller of the image capture system can also alter the sampling rate based on its own determinations. For instance, the controller can determine a large change in the scene based on an error term calculated from pixel statistics in various images. Such an error term may be indicative of a large shift in histogram data between two or more captured images. The controller can wait for the error term to return to a normal level before sending an image to the image processing unit.</p><p id="p-0026" num="0025">In further examples, the image processing unit can also cause the controller to alter the sampling rate with a feedback signal. For instance, the image processing unit can send a signal to the controller each time it completes an image processing operation such that the sampling rate is a variable rate consistent with an image processing operation time for each image. The image processing unit can also change the sampling rate based on a type of image processing operation it is to perform. For instance, the image processing unit may receive a command signal that instructs it to perform object detection operations for a first period, and to perform deblur operations in addition to the object detection operations for a second period. The image processing unit can set a first sampling rate during the first period and set a second sampling rate during the second period, where each sampling rate is commensurate with an expected image processing time.</p><p id="p-0027" num="0026">In addition to variable sampling rates based on actions of a robot, feedback from an image processing unit, feedback from a pre-processing unit, or determinations by the controller of the image capture system, various exposure parameter values can be altered based on such inputs. For example, an exposure duration or gain associated with a set of exposure parameters can be altered based on a type of image processing operation performed by the image processing unit, or based on a type of action carried out by a robot.</p><p id="p-0028" num="0027">These and various other embodiments are described herein. It should be understood that, though an image processing system is described in the context of a larger robotic system, this system can be a standalone system included within a single unitary device, such as a video recording device, a camera, or an imager. Further, the image processing system may be included within other types of systems such as in a manufacturing system, automotive vehicle system, or cellular handheld device system.</p><p id="p-0029" num="0028">Reference will now be made in detail to various embodiments, examples of which are illustrated in the accompanying drawings. In the following detailed description, numerous specific details are set forth in order to provide a thorough understanding of the present disclosure and the described embodiments. However, the present disclosure may be practiced without these specific details. In other instances, well-known methods, procedures, and components, and circuits have not been described in detail so as not to unnecessarily obscure aspects of the embodiments.</p><heading id="h-0007" level="1">II. Example Robotic Systems</heading><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example configuration of a robotic system that may be used in connection with the implementations described herein. The robotic system <b>100</b> may be a robotic arm, a different type of robotic manipulator, or it may have a number of different forms. Additionally, the robotic system <b>100</b> may also be referred to as a robotic device, robotic manipulator, or robot, among others.</p><p id="p-0031" num="0030">The robotic system <b>100</b> is shown to include processor(s) <b>102</b>, data storage <b>104</b>, program instructions <b>106</b>, controller <b>108</b>, sensor(s) <b>110</b>, power source(s) <b>112</b>, actuator(s) <b>114</b>, and movable component(s) <b>116</b>. Note that the robotic system <b>100</b> is shown for illustration purposes only as robotic system <b>100</b> may include additional components and/or have one or more components removed without departing from the scope of the invention. Further, note that the various components of robotic system <b>100</b> may be connected in any manner.</p><p id="p-0032" num="0031">Processor(s) <b>102</b> may be a general-purpose processor or a special purpose processor (e.g., digital signal processors, application specific integrated circuits, etc.). The processor(s) <b>102</b> can be configured to execute computer-readable program instructions <b>106</b> that are stored in the data storage <b>104</b> and are executable to provide the functionality of the robotic system <b>100</b> described herein. For instance, the program instructions <b>106</b> may be executable to provide functionality of controller <b>108</b>, where the controller <b>108</b> may be configured to instruct an actuator <b>114</b> to cause movement of one or more movable component(s) <b>116</b>.</p><p id="p-0033" num="0032">The data storage <b>104</b> may include or take the form of one or more computer-readable storage media that can be read or accessed by processor(s) <b>102</b>. The one or more computer-readable storage media can include volatile and/or non-volatile storage components, such as optical, magnetic, organic or other memory or disc storage, which can be integrated in whole or in part with processor(s) <b>102</b>. In some embodiments, the data storage <b>104</b> can be implemented using a single physical device (e.g., one optical, magnetic, organic or other memory or disc storage unit), while in other embodiments, the data storage <b>104</b> can be implemented using two or more physical devices. Further, in addition to the computer-readable program instructions <b>106</b>, the data storage <b>104</b> may include additional data such as diagnostic data, among other possibilities.</p><p id="p-0034" num="0033">The robotic system <b>100</b> may include one or more sensor(s) <b>110</b> such as force sensors, proximity sensors, motion sensors, load sensors, position sensors, touch sensors, depth sensors, ultrasonic range sensors, and infrared sensors, among other possibilities. The sensor(s) <b>110</b> may provide sensor data to the processor(s) <b>102</b> to allow for appropriate interaction of the robotic system <b>100</b> with the environment. Additionally, the sensor data may be used in evaluation of various factors for providing feedback as further discussed below. Further, the robotic system <b>100</b> may also include one or more power source(s) <b>112</b> configured to supply power to various components of the robotic system <b>100</b>. Any type of power source may be used such as, for example, a gasoline engine or a battery.</p><p id="p-0035" num="0034">The robotic system <b>100</b> may also include one or more actuator(s) <b>114</b>. An actuator is a mechanism that may be used to introduce mechanical motion. In particular, an actuator may be configured to convert stored energy into movement of one or more components. Various mechanisms may be used to power an actuator. For instance, actuators may be powered by chemicals, compressed air, or electricity, among other possibilities. In some cases, an actuator may be a rotary actuator that may be used in systems involving rotational forms of motion (e.g., a joint in the robotic system <b>100</b>). In other cases, an actuator may be a linear actuator that may be used in systems involving straight line motion.</p><p id="p-0036" num="0035">In either case, actuator(s) <b>114</b> may cause movement of various movable component(s) <b>116</b> of the robotic system <b>100</b>. The moveable component(s) <b>116</b> may include appendages such as robotic arms, legs, and/or hands, among others. The moveable component(s) <b>116</b> may also include a movable base, wheels, and/or end effectors, among others.</p><p id="p-0037" num="0036">In some implementations, a computing system (not shown) may be coupled to the robotic system <b>100</b> and may be configured to receive input from a user, such as via a graphical user interface. This computing system may be incorporated within the robotic system <b>100</b> or may be an external computing system that is capable of (wired or wireless) communication with the robotic system <b>100</b>. As such, the robotic system <b>100</b> may receive information and instructions, such as based on user-input at the graphical user interface and/or based on user-input received via press of buttons (or tactile input) on the robotic system <b>100</b>, among other possibilities.</p><p id="p-0038" num="0037">A robotic system <b>100</b> may take on various forms. To illustrate, <figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an example robotic arm <b>200</b>. As shown, the robotic arm <b>200</b> includes a base <b>202</b>, which may be a stationary base or may be a movable base. In the case of a movable base, the base <b>202</b> may be considered as one of the movable component(s) <b>116</b> and may include wheels (not shown), powered by one or more of the actuator(s) <b>114</b>, which allow for mobility of the entire robotic arm <b>200</b>.</p><p id="p-0039" num="0038">Additionally, the robotic arm <b>200</b> includes joints <b>204</b>A-<b>204</b>F each coupled to one or more of the actuator(s) <b>114</b>. The actuators in joints <b>204</b>A-<b>204</b>F may operate to cause movement of various movable component(s) <b>116</b> such as appendages <b>206</b>A-<b>206</b>F and/or end effector <b>208</b>. For example, the actuator in joint <b>204</b>F may cause movement of appendage <b>206</b>F and end effector <b>208</b> (i.e., since end effector <b>208</b> is coupled to appendage <b>206</b>F). Further, end effector <b>208</b> may take on various forms and may include various parts. In one example, end effector <b>208</b> may take the form of a gripper such as a finger gripper as shown here or a different type of gripper such as a suction gripper. In another example, end effector <b>208</b> may take the form of a tool such as a drill or a brush. In yet another example, the end effector may include sensors such as force sensors, location sensors, and/or proximity sensors. Other examples may also be possible.</p><p id="p-0040" num="0039">In an example implementation, a robotic system <b>100</b>, such as robotic arm <b>200</b>, may be capable of operating in a teach mode. In particular, teach mode may be an operating mode of the robotic arm <b>200</b> that allows a user to physically interact with and guide the robotic arm <b>200</b> towards carrying out and recording various movements. In a teaching mode, an external force is applied (e.g., by the user) to the robotic system <b>100</b> based on a teaching input that is intended to teach the robotic system regarding how to carry out a specific task. The robotic arm <b>200</b> may thus obtain data regarding how to carry out the specific task based on instructions and guidance from the user. Such data may relate to a plurality of configurations of the movable component(s) <b>116</b>, joint position data, velocity data, acceleration data, torque data, force data, and power data, among other possibilities.</p><p id="p-0041" num="0040">For example, during teach mode the user may grasp onto any part of the robotic arm <b>200</b> and provide an external force by physically moving the robotic arm <b>200</b>. In particular, the user may guide the robotic arm <b>200</b> towards grasping onto an object and then moving the object from a first location to a second location. As the user guides the robotic arm <b>200</b> during teach mode, the system may obtain and record data related to the movement such that the robotic arm <b>200</b> may be configured to independently carry out the task at a future time during independent operation (e.g., when the robotic arm <b>200</b> operates independently outside of teach mode). Note, however, that external forces may also be applied by other entities in the physical workspace such as by other objects, machines, and/or robotic systems, among other possibilities.</p><heading id="h-0008" level="1">III. Example Image Processing Systems</heading><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a configuration of an image processing system <b>300</b>, according to example embodiments. Image processing system <b>300</b> includes an image capture system <b>302</b> having an image capture device <b>304</b> and a controller <b>306</b>. The term &#x201c;image capture device&#x201d; refers to an optical instrument for recording or capturing images. The term &#x201c;controller&#x201d; refers to one or more processors configured to control the operation of the image capture device. Image capture device <b>304</b> and controller <b>306</b> are depicted as communicating back and forth. For example, controller <b>306</b> can send control signals indicative of a capture rate at which image capture device <b>304</b> is to capture a plurality of images, while image capture device <b>304</b> can send the plurality of images to controller <b>306</b>. Controller <b>306</b> can determine sets of one or more exposure parameter values for image capture device <b>304</b> to use when capturing images. For instance, controller <b>306</b> can receive a first image, determine a set exposure parameter values based on pixel statistics of the first image, and send the set of exposure parameter values to image capture device <b>304</b>. The term &#x201c;exposure parameter&#x201d; refers to at least one of an aperture, gain, or exposure duration used by the image capture device when capturing an image. The set of exposure parameter values can include at least one of an exposure duration value, gain value, and/or an aperture value for capturing a subsequent image. Image capture device <b>304</b> can capture a second image according to the determined set of exposure parameter values.</p><p id="p-0043" num="0042">As controller <b>306</b> determines the sets of exposure parameter values, controller <b>306</b> can also determine error terms for each captured image. The term &#x201c;error term&#x201d; refers to a level of change between pixel statistics associated with two or more captured images. For example, controller <b>306</b> can determine a level of variance between a first histogram associated with a first image and a second histogram associated with a second image. A large variance may indicate a sudden change in lighting within the environment. Though successively determined sets of exposure parameter values after the second image is captured may adjust for this change, it may take several images for controller <b>306</b> to reach a stable desired histogram. Thus, controller <b>306</b> may wait until the error term associated with a given image falls within an error term threshold before sampling that image for processing by image processing unit <b>308</b>.</p><p id="p-0044" num="0043">Image processing system <b>300</b> also includes an image processing unit <b>308</b>. Image processing unit <b>308</b> can receive a subset of the plurality of images captured by the image capture system and perform image processing operations on the captured images. Image processing unit <b>308</b> and image capture system <b>302</b> are depicted as communicating back and forth. For instance, controller <b>306</b> of image capture system <b>302</b> can send an image to image capture system <b>308</b>, and image capture system <b>308</b> can send a feedback signal to controller <b>306</b>. The feedback signal may indicate to controller <b>306</b> that image capture system <b>308</b> is ready to receive another image.</p><p id="p-0045" num="0044">Controller <b>306</b> can send images to image processing unit <b>308</b> at a sampling rate. In some examples, controller <b>306</b> can send images to image processing unit <b>308</b> in a periodic and consistent manner. In such examples, image capture device <b>304</b> may capture images at a capture rate that corresponds to an exposure determination rate of controller <b>306</b>. The term &#x201c;exposure determination rate&#x201d; refers to a rate at which captured images are processed by the controller to determine sets of exposure parameter values. For example, controller <b>306</b> can process a captured image to determine a value for one or more of an exposure duration, gain, or aperture to use when capturing a subsequent image, and the exposure determination rate can refer to the rate at which such processing occurs. More specifically, the exposure determination rate may be the rate at which the controller determines pixel statistics for one or more captured images and determines sets of exposure parameters based at least on the pixel statistics. The exposure determination rate may be a multiple of the sampling rate, such that, for a plurality of images captured by image capture device <b>302</b>, every nth image is sent to image processing unit <b>308</b>. For instance, the exposure determination rate could be thirty or sixty frames per second, while the sampling rate could be five or ten frames per second.</p><p id="p-0046" num="0045">Controller <b>306</b> may determine the sets of one or more exposure parameter values in accordance with the capture rate. For example, controller <b>306</b> may receive a first image, determine pixel statistics for the first image, and determine a set of exposure parameter values for image capture device <b>304</b> to use when capturing a second image. Controller <b>306</b> can determine the set of exposure parameter values for the second image based at least on the determined pixel statistics for the first image. For example, controller <b>306</b> can compare histogram data represented in the pixel statistics to a desired histogram, and can alter one or more exposure parameter values used to capture the first image such that the pixel statistics from the second image more closely match the desired histogram.</p><p id="p-0047" num="0046">In other examples, the sampling rate can be a variable rate. For example, each time image processing unit <b>308</b> completes an image processing operation, image processing unit can send a prompt to controller <b>306</b>. Thus, controller <b>306</b> can receive a plurality of prompts that correspond to a subset of the plurality of images. Controller <b>306</b> can send the subset of images one at a time as the prompts are received. Accordingly, as time for performing an image processing operation changes over time, so too will the sampling rate. In other examples, controller <b>306</b> or image processing unit <b>308</b> can alter the sampling rate based on a number and/or type of image processing operations to be performed on an image or images. For instance, image processing unit <b>308</b> may receive a command to perform object detection operations for a first period, and to perform deblur operations in addition to the object detection operations for a second period. Image processing unit <b>308</b> can set a first sampling rate during the first period and set a second sampling rate during the second period, where each sampling rate corresponds to an expected image processing time for the image processing operations. Image processing unit <b>308</b> can send a feedback signal that indicates the different sampling rates, and controller <b>306</b> can change the sampling rate based on the feedback signal. Other examples of variable sampling rates are possible as well.</p><p id="p-0048" num="0047">One or more exposure parameter values can be altered similarly to the sampling rate. For instance, an exposure duration, gain, or aperture used to capture one or more images of the plurality of images can be altered based on a feedback signal received from image processing unit <b>308</b>. In some examples, image processing unit <b>306</b> can determine that one or more images sampled from the plurality are too bright or too dim, and can send a feedback signal to controller <b>306</b> that indicates that different exposure parameters should be used for forthcoming images. Such feedback signals can be sent prospectively as well. For example, image processing unit <b>308</b> may determine a type of image processing operation to be performed on forthcoming sampled images and can send a feedback signal that indicates desired characteristics for the forthcoming sampled images. For instance, where a color thresholding operation is forthcoming, image processing unit <b>308</b> can send a feedback signal indicating that a gain greater than one should be applied to a first color channel, while a gain less than one should be applied to a second color channel and a third color channel. Other examples of feedback from image processing unit <b>308</b> are possible as well.</p><p id="p-0049" num="0048">In the present example, controller <b>306</b> and image processing unit <b>308</b> are depicted as being separate, but in some examples they may be part of a single unitary device, such as a video capture device, a camera, or an imager. In some examples, image processing system <b>300</b> may be included as a component of a larger system, such as a robotic system. Separating image capture device <b>304</b> and controller <b>306</b> from image processing unit <b>308</b> as depicted in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may reduce bandwidth usage within image processing system <b>300</b> because not all of the images captured by image capture device <b>304</b> are sent for processing. In particular, where controller <b>306</b> communicates wirelessly with image processing system <b>308</b>, separating controller <b>306</b> from image processing system <b>308</b> in this fashion may allow for efficient use of available communication bandwidth by sending only a subset of available images.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a configuration of another image processing system <b>400</b>, according example embodiments. Image processing system <b>400</b> is incorporated into a robotic system. The robotic system may be similar or identical to system <b>100</b> depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, image capture system <b>302</b>, described above with regard to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, is included within sensors(s) <b>110</b> described above with regard to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Image processing unit <b>308</b> is similarly incorporated into processor(s) <b>102</b>. An additional component, pre-processing unit <b>402</b>, is similarly incorporated into processor(s) <b>102</b>. For purposes of clarity, controller <b>108</b> depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref> has been re-labelled robot controller <b>108</b>.</p><p id="p-0051" num="0050">As described above with regard to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, image capture system <b>302</b> includes image capture device <b>304</b> and controller <b>306</b>. Image capture system <b>302</b> and image processing unit <b>308</b> may interact within image processing system <b>400</b> in substantially the same way described above. However, additional factors may contribute to the operation of these components in image processing system <b>400</b>. For instance, robot controller <b>108</b> can send commands to either or both of controller <b>306</b> and image processing unit <b>308</b> that affect the sampling rate. In one such example, robot controller <b>108</b> can be configured to plan successive actions of a robot, such as the robot described above with regard to <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The planned actions may require image processing unit <b>308</b> to perform different image processing operations. Robot controller <b>108</b> can send to controller <b>106</b> a sequence of commands to change the sampling rate based on the planned actions and, in parallel, send image processing unit <b>308</b> a sequence of commands to perform various image processing operations at different times. In another example, robot controller <b>108</b> can send a sequence of commands to image processing unit <b>308</b> only, image processing unit <b>308</b> can send a feedback signal to controller <b>306</b>, and controller <b>306</b> can change the sampling rate based on the feedback signal. Other ways of carrying out the image processing operations are possible as well.</p><p id="p-0052" num="0051">Controller <b>306</b> can alter the sampling rate in other ways as well. For instance, in a mapped environment, image processing unit <b>308</b> may be expected to carry out different image processing operations in different locations within the environment. Accordingly, controller <b>306</b> can alter the sampling rate based on a location and/or orientation of the robot within the environment. Controller <b>306</b> may receive such location or orientation information from robot controller <b>108</b>, from another sensor of sensor(s) <b>110</b>, or from another component of system <b>100</b> described above with regard to <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0053" num="0052">Image processing system <b>400</b> also includes pre-processing unit <b>402</b>. Pre-processing unit <b>402</b> can also be configured to alter which images are sent to image processing unit <b>308</b>. For example, pre-processing unit <b>402</b> can sample images from a plurality of images captured by image capture device <b>304</b>. Pre-processing unit <b>402</b> can determine a white level or focus level for the sampled images. The term &#x201c;white level&#x201d; refers to the intensity of pixels in a captured image. The term &#x201c;focus level&#x201d; refers to an identified in-focus portion or out-of-focus portion of a captured image. Different white levels or focus levels may be more suitable than others for processing by the image processing unit <b>308</b>. Accordingly, where controller <b>306</b> receives a prompt from image processing unit <b>308</b> to send an image, controller <b>306</b> can select an image to send based on the white level or focus level determined by pre-processing unit <b>402</b>. Though pre-processing unit <b>402</b> is depicted as being separate from controller <b>306</b>, it should be understood that, in some examples, pre-processing unit <b>402</b> and controller <b>306</b> might be one and the same. That is, controller <b>306</b> can determine a white level and/or a focus level for some or all of the plurality of images in addition to determining sets of one or more exposure parameter values for the plurality of images.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a timing diagram <b>500</b> for an image processing system, according to example embodiments. In <figref idref="DRAWINGS">FIG. <b>5</b></figref>, image capture device <b>304</b>, controller <b>306</b>, and image processing unit <b>308</b> are configured to perform different operations at different times.</p><p id="p-0055" num="0054">At time <b>502</b>, controller <b>306</b> is configured to send a first image to image processing unit <b>308</b>. Though not depicted in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, it should be understood that image capture device <b>304</b> first captured the first image. In timing diagram <b>500</b>, image capture device <b>304</b> captures images at a constant, or substantially constant, rate. Image capture device <b>304</b> captures a second image at time <b>504</b>, a third image at time <b>510</b>, and an nth image at time <b>516</b>.</p><p id="p-0056" num="0055">After receiving the first image, image processing unit <b>308</b> begins performing an image processing operation on the first image at time <b>506</b>. As illustrated in timing diagram <b>500</b>, the image processing time may take significantly longer than it takes controller <b>306</b> to determine a set of one or more exposure parameter values. Controller <b>306</b> determines a set of exposure parameter values for the third image at time <b>508</b>, and determines a set of exposure parameter values for a fourth image at time <b>512</b> before image processing unit <b>308</b> completes the image processing operation on the first image at time <b>514</b>.</p><p id="p-0057" num="0056">Once image processing unit <b>308</b> has completed the image processing operation, it sends a feedback signal at time <b>518</b>. In some examples, the feedback signal simply includes a prompt to send another image. In other examples, the feedback signal can include an indication to change the sampling rate, an indication of a type of image forming operation to be performed on another image, or an indication of target parameters for forthcoming images. For instance, image processing unit <b>308</b> can determine that an image processing operation took too long because of an improper focus level, or that the operation was unsuccessful because an image was overexposed. In response, controller <b>306</b> can alter a threshold for the focus level, or constrain an error term threshold for determining the set of exposure parameter values to ensure that forthcoming images are better suited for performance of image processing operations.</p><p id="p-0058" num="0057">After receiving the feedback signal, controller <b>306</b> sends an nth image at time <b>520</b>, and continues to determine a set of exposure parameter values at time <b>522</b>. In some examples, operation of the image processing system may continue in much the same way. In other examples, timing operation of controller <b>306</b> and image processing unit <b>308</b> can change based on external inputs.</p><p id="p-0059" num="0058">Further, it should be understood that timing diagram <b>500</b> is a simplified illustration of communications between controller <b>306</b> and image processing unit <b>308</b>. Sending the images may further include exchanging acknowledgement signals between controller <b>306</b> and image processing unit <b>308</b>. Sending the images may also include modulating or otherwise transforming image data. For instance, sending the image may include wirelessly sending the image data to the image processing unit according to a modulation scheme. In another example, controller <b>306</b> and image processing unit <b>308</b> may send signals according to a controller area network (CAN) protocol. Other such protocols and communication schemes are possible.</p><heading id="h-0009" level="1">IV. Additional Embodiments</heading><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates operation of an image processing system <b>600</b>, according to example embodiments. <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an image capture device <b>304</b>, a controller <b>306</b>, and an image processing unit <b>308</b>. <figref idref="DRAWINGS">FIG. <b>6</b></figref> also illustrates a plurality of images captured by the image capture device <b>304</b>, which include images <b>602</b>, <b>604</b>, and <b>606</b>, which are sampled by the image processing unit. The depicted images are captured at different times, such that image <b>602</b> is captured at a first time, image <b>604</b> is captured at a second time that is later than the first time, and image <b>606</b> is captured at a third time that is later than the second time.</p><p id="p-0061" num="0060">In some examples, image processing system <b>600</b> can be used in a robotics context. Image capture device <b>304</b> can capture a plurality of images at a capture rate commensurate with an exposure determination rate of the controller <b>306</b>. Controller <b>306</b> can communicate with a robot controller, such as controller <b>108</b> described above with regard to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Controller <b>306</b> can receive information related to one or more actions of the robot, and determine a sampling rate at which to send a subset of the plurality of images to image processing unit <b>308</b> based on the one or more actions of the robot. Each of the one or more actions may be related to an image processing performance time. For instance, an action that causes the robot to move may cause a large change in the scene captured by the image capture device. Image processing unit <b>308</b> may perform more image processing operations due to the large change in scene, and may accordingly take a longer time to perform the image processing operations. Accordingly, controller <b>306</b> may adjust the sampling rate based on the action of the robot. In other examples, image processing unit <b>308</b> may send a feedback signal that indicates to controller <b>306</b> that the sampling rate should change. In <figref idref="DRAWINGS">FIG. <b>6</b></figref>, every seventh image is sampled, therefore, this example scenario may depict a system where the sampling rate is constant, or where image processing unit <b>308</b> is taking a similar amount of time to perform operations of each of sampled images <b>602</b>, <b>604</b>, and <b>606</b>.</p><p id="p-0062" num="0061">In a robotics context, the sampling rate may be adjustable by controller <b>306</b> based on a location of the robot. For instance certain image processing operations may be associated with different locations in an environment of the robot. When a robot controller, such as controller <b>108</b> described above determines a location of the robot has changed, it can send signals to controller <b>306</b>, and controller <b>306</b> can alter the sampling rate based on the command signals. Other examples are possible in a robotics context as well.</p><p id="p-0063" num="0062">Sets of exposure parameter values can be adjustable by controller <b>306</b> in a robotics context as well. For example, for a given set of exposure parameters, controller <b>306</b> can alter one or more of an exposure duration, gain, or aperture based on an action of the robot or based on a current location of the robot.</p><p id="p-0064" num="0063">In further examples, image processing system <b>600</b> may be used in an automotive context. That is, image capture device <b>304</b> and controller <b>306</b> may be included within a vehicle, such as an autonomous vehicle. Image processing unit <b>308</b> may be tasked with recognizing other vehicles in an environment of the vehicle, identifying symbols or text in road signs, perceiving pedestrians, animals, or other obstructions in the environment, detecting blur directionality associated with a sudden movement of the vehicle, or other related image processing operations. Image processing unit <b>308</b> may be included within the vehicle, or may be remote from the vehicle. In examples where image processing unit <b>308</b> is remote from the vehicle, controller <b>306</b> may communicate with image processing unit <b>308</b> wirelessly.</p><p id="p-0065" num="0064">In an automotive context, controller <b>306</b> may interact with a vehicle controller. Similarly, controller <b>306</b> may interact with additional sensors of the vehicle that provide controller <b>306</b> with information relevant to setting a sampling rate at which to send a subset of images to image processing unit <b>308</b>. For example, proximity sensors of the vehicle may signal to controller <b>306</b> that an obstruction is within a threshold distance. Controller <b>306</b> can determine that image processing unit <b>308</b> will require more time to process each image based on the signal, and can account for this by lowering the sampling rate. In other examples, a vehicle controller can send a control signal to controller <b>306</b> based on a user input. Other examples in an automotive context are possible as well.</p><p id="p-0066" num="0065">In additional examples, system <b>600</b> can be used in a handheld device context. In this example, image capture device <b>304</b> and controller <b>306</b> can be included within a handheld device. Image processing unit <b>308</b> can be included within the handheld device or be remote from the handheld device. Image processing operations on images captured by image capture device can include facial recognition operations, object detection operations, high dynamic range (HDR) operations, filtering operations, or others. Other examples in a handheld device context are possible as well.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates operation of another image processing system <b>700</b>, according to example embodiments. In <figref idref="DRAWINGS">FIG. <b>7</b></figref>, system <b>700</b> includes image capture device <b>304</b>, controller <b>306</b>, and image processing unit <b>308</b>. System <b>700</b> additionally includes pre-processing unit <b>402</b>. Pre-processing unit <b>402</b> may be configured to perform image processing operations in parallel with image processing unit <b>308</b>, and may help determine the sampling rate.</p><p id="p-0068" num="0067">In some examples, one or more additional image capture devices may be used in addition to image capture device <b>304</b>. For instance, image capture device <b>304</b> may be a first image capture device configured to capture first images of a plurality of images at a first capture rate, and a second image capture device may capture second images at a second capture rate. Controller <b>306</b> may determine separate sets of one or more exposure parameter values for each image capture device. Having two image capture devices simultaneously capture images can allow for a faster overall capture rate, which in turn allows controller <b>306</b> to determine effective set of exposure parameter values more quickly. In such examples, sending a subset of the plurality of images may include selecting the subset of images from the first images and the second images. The first images and second images can be captured according to different parameters, and so controller <b>306</b> may sample corresponding images from the first image capture device and the second image capture device and send the corresponding images to image processing unit <b>308</b>. For example, the first image capture device may focus on a first portion of a scene, the second image capture device may focus on a second portion of the scene, and image processing unit <b>308</b> may be configured to perform HDR operations on corresponding images to form a combined image that is in focus at both portions of the scene.</p><p id="p-0069" num="0068">In some examples, pre-processing unit <b>402</b> can be configured to determine a white level or focus level associated with a plurality of images. Image processing unit <b>308</b> may send a plurality of prompts to receive images from the plurality of images. In turn, controller <b>306</b> may select an image from the plurality based on the determined white level and/or focus level. In <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the plurality of images captured by image capture device <b>304</b> includes images <b>602</b>, <b>702</b>, <b>604</b>, and <b>606</b>. Of these, controller <b>306</b> samples and sends images <b>602</b>, <b>702</b>, and <b>606</b> to image processing unit <b>308</b>. These may be selected from other images of the plurality that are captured within a time threshold of each prompt received from image processing unit <b>308</b>. For example, images <b>702</b> and <b>604</b> may be within the time threshold. In the present example, image <b>702</b> has a more appropriate white level and/or focus level than image <b>604</b>, and so image <b>702</b> is sent to image processing unit <b>308</b>.</p><p id="p-0070" num="0069">Pre-processing unit <b>402</b> can additionally or alternatively determine a level of change in the environment. For instance, pre-processing unit <b>402</b> may determine a threshold percent change in a color (e.g. red, green, or blue) in a scene captured by two or more images of the plurality of images. Such a change may be indicative of additional image processing operations for image processing unit <b>308</b> to perform. Pre-processing unit <b>402</b> may send a feedback signal to controller <b>306</b> based on the level of change in the scene, and controller <b>306</b> can change the sampling rate based on the feedback signal.</p><p id="p-0071" num="0070">In other examples, pre-processing unit <b>402</b> or image processing unit <b>308</b> can determine a number and type of image processing operations to be performed on an image. Image processing unit <b>308</b> may identify four separate objects in image <b>602</b> and perform a deblur operation to the image. Based on these operations, and a performance time associated with the operations, image processing unit <b>308</b> can send a feedback signal to change the sampling rate. The sampling rate can be adjusted to allow enough time to perform identical or similar image processing operations on the next sampled image. Pre-processing unit <b>402</b> may likewise perform a preliminary check to determine which types of image processing operations image processing unit <b>308</b> will likely carry out once an image is sampled. Controller <b>306</b> can accordingly change the sampling rate before image processing unit <b>308</b> receives the image.</p><p id="p-0072" num="0071">Though some of these example embodiments are discussed in a robotics context, an automotive context, or a handheld device context, it should be understood that any embodiments described herein can be applied in other contexts as well. Further, though image capture device <b>304</b>, controller <b>306</b>, image processing unit <b>308</b>, and pre-processing unit <b>402</b> are depicted as being separate, it should be understood that any or all of these components might be included within a single unitary device. Still further, it should be understood that any of these embodiments may be carried out as a method, or may be effectuated using a non-transitory computer readable medium having instructions stored thereon, that when executed by one or more processors, perform a series of functions.</p><heading id="h-0010" level="1">V. Example Operations</heading><p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example block diagram of a method <b>800</b>, according to an example embodiment. In some examples, method <b>800</b> may be carried out as part of a system. For example, blocks <b>802</b>, <b>804</b>, and <b>806</b> may be carried out as part of the system described above with regard to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, <figref idref="DRAWINGS">FIG. <b>2</b></figref>, or <figref idref="DRAWINGS">FIG. <b>3</b></figref>, <figref idref="DRAWINGS">FIG. <b>4</b></figref>, <figref idref="DRAWINGS">FIG. <b>4</b></figref>, and <figref idref="DRAWINGS">FIG. <b>5</b></figref>. These steps may be carried out by the system components described above in conjunction with one or more processors executing program instructions stored on a non-transitory computer readable medium.</p><p id="p-0074" num="0073">In other examples, the method may be carried out as part of a computing system. In these examples, a non-transitory computer readable medium may store instructions executable by one or more processors to cause the computing system to perform the blocks of the method.</p><p id="p-0075" num="0074">In these examples, the one or more processors and non-transitory computer readable medium may perform the blocks remotely. In other examples, the one or more processors and non-transitory computer readable medium may carry out the method at a robot, vehicle, handheld device, or in another system context. In still other examples, portions of the method may be carried out remotely, while other portions may be carried out at the robot, vehicle, handheld device, or other system context.</p><p id="p-0076" num="0075">Block <b>802</b> of the method <b>800</b> may be performed to determine, by a controller of an image capture system, a plurality of sets of exposure parameter values for one or more exposure parameters. The plurality of sets of exposure parameter values may be determined at an exposure determination rate, where the exposure determination rate includes a rate at which captured images are processed by the controller to determine each set of exposure parameter values.</p><p id="p-0077" num="0076">Block <b>804</b> of method <b>800</b> may be performed to capture, by an image capture device of the image capture system, a plurality of images. Each image of the plurality of images may be captured according to a set of exposure parameter values of the plurality of sets of exposure parameter values.</p><p id="p-0078" num="0077">Block <b>806</b> of method <b>800</b> may be performed to send, by the controller of the image capture system to an image processing unit, a subset of the plurality of images. The subset of images may be sent at a sampling rate, and the sampling rate may be less than the exposure determination rate. In some examples, sending the subset of the plurality of images at the sampling rate can include wirelessly sending the subset of images to the image processing unit.</p><p id="p-0079" num="0078">In some examples, the exposure determination rate may be a multiple of the sampling rate. In these examples, a controller, such as controller <b>306</b> can send every nth image of the plurality of images to an image processing unit, such as image processing unit <b>308</b>. In other examples, sending the subset of images at the sampling rate can include receiving, by the controller of the image processing system from the image processing unit, a plurality of prompts to send an image of the subset of the plurality of images. In these examples, each image of the subset may be sent in response to a received prompt. In other examples, method <b>800</b> may include receiving at a first time, by the controller of the image capture system from the image processing unit, a first prompt to send a first image of the plurality of images, receiving at a second time, by the controller of the image capture system from the image processing unit, a second prompt to send a second image of the plurality of images, and changing, by the controller of the image capture system, the sampling rate based on a difference between the first time and the second time.</p><p id="p-0080" num="0079">In other examples, the image processing unit can provide feedback signals to the controller. For instance, method <b>800</b> can further include receiving, by the controller of the image capture system from the image processing unit, a feedback signal, and changing, by the controller of the image capture system, the sampling rate based on the received feedback signal.</p><p id="p-0081" num="0080">In additional examples, the image capture system can be included within a robot. In these examples, the image processing unit may be configured to process images for a control system of the robot. In such examples, the method may also include the controller of the image capture system changing the sampling rate based on an action (e.g., a planned future action) of the robot.</p><p id="p-0082" num="0081">Method <b>800</b> may include performing additional operations on the subset of images. For example method <b>800</b> may further the controller compressing the subset of images prior to sending the subset of the plurality of images. In other examples, method <b>800</b> may further include determining, by the controller of the image capture system, a plurality of exposure error terms that correspond to the plurality of images. In these examples, sending the subset of the plurality of images may be based on the determined plurality of exposure error terms. The controller may determine whether an error term falls within an error term threshold. If the error term falls within the error term threshold, the controller may send an image of the plurality of images that corresponds to the error term to the image processing unit. In still other examples, method <b>800</b> can also include determining a white level or a focus level of the plurality of images. In these examples, sending the subset of images may include selecting the subset of images from the plurality of images based on the determined white level or focus level.</p><p id="p-0083" num="0082">Method <b>800</b> can also include altering one or more sets of exposure parameter values. For instance, method <b>800</b> can further include receiving, by the controller of the image capture system from the image processing unit, a feedback signal, and changing, by the controller of the image capture system, one or more sets of exposure parameter values of the plurality of sets of exposure parameter values based on the received feedback signal.</p><heading id="h-0011" level="1">VI. Conclusion</heading><p id="p-0084" num="0083">The present disclosure is not to be limited in terms of the particular embodiments described in this application, which are intended as illustrations of various aspects. Many modifications and variations can be made without departing from its spirit and scope, as will be apparent to those skilled in the art. Functionally equivalent methods and apparatuses within the scope of the disclosure, in addition to those enumerated herein, will be apparent to those skilled in the art from the foregoing descriptions. Such modifications and variations are intended to fall within the scope of the appended claims.</p><p id="p-0085" num="0084">The above detailed description describes various features and functions of the disclosed systems, devices, and methods with reference to the accompanying figures. In the figures, similar symbols typically identify similar components, unless context dictates otherwise.</p><p id="p-0086" num="0085">The example embodiments described herein and in the figures are not meant to be limiting. Other embodiments can be utilized, and other changes can be made, without departing from the spirit or scope of the subject matter presented herein. It will be readily understood that the aspects of the present disclosure, as generally described herein, and illustrated in the figures, can be arranged, substituted, combined, separated, and designed in a wide variety of different configurations, all of which are explicitly contemplated herein.</p><p id="p-0087" num="0086">A block that represents a processing of information may correspond to circuitry that can be configured to perform the specific logical functions of a herein-described method or technique. Alternatively or additionally, a block that represents a processing of information may correspond to a module, a segment, or a portion of program code (including related data). The program code may include one or more instructions executable by a processor for implementing specific logical functions or actions in the method or technique. The program code and/or related data may be stored on any type of computer readable medium such as a storage device including a disk or hard drive or other storage medium.</p><p id="p-0088" num="0087">The computer readable medium may also include non-transitory computer readable media such as computer-readable media that stores data for short periods of time like register memory, processor cache, and random access memory (RAM). The computer readable media may also include non-transitory computer readable media that stores program code and/or data for longer periods of time, such as secondary or persistent long term storage, like read only memory (ROM), optical or magnetic disks, compact-disc read only memory (CD-ROM), for example. The computer readable media may also be any other volatile or non-volatile storage systems. A computer readable medium may be considered a computer readable storage medium, for example, or a tangible storage device.</p><p id="p-0089" num="0088">Moreover, a block that represents one or more information transmissions may correspond to information transmissions between software and/or hardware modules in the same physical device. However, other information transmissions may be between software modules and/or hardware modules in different physical devices.</p><p id="p-0090" num="0089">The particular arrangements shown in the figures should not be viewed as limiting. It should be understood that other embodiments can include more or less of each element shown in a given figure. Further, some of the illustrated elements can be combined or omitted. Yet further, an example embodiment can include elements that are not illustrated in the figures.</p><p id="p-0091" num="0090">While various aspects and embodiments have been disclosed herein, other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting, with the true scope being indicated by the following claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method comprising:<claim-text>determining, by a controller of an image capture system, a plurality of sets of exposure parameter values for one or more exposure parameters;</claim-text><claim-text>capturing, by an image capture device of the image capture system, a plurality of images, wherein each image of the plurality of images is captured according to a set of exposure parameter values of the plurality of sets of exposure parameter values; and</claim-text><claim-text>based on the plurality of captured images, altering, by the controller of the image capture system, a sampling rate at which images are sent by the controller of the image capture system to an image processing unit, wherein the image processing unit comprises one or more processors configured to process the images.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein altering the sampling rate at which images are sent by the controller of the image capture system to the image processing unit comprises delaying sending the at least one of the plurality of images to the image processing.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein each set of the plurality of sets of exposure parameter values comprises a duration value and a gain value.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>receiving, by the controller of the image capture system from the image processing unit, a plurality of prompts to send an image of the plurality of images, wherein each image of the plurality of images is sent in response to a received prompt.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>receiving, by the controller of the image capture system from the image processing unit, a feedback signal; and</claim-text><claim-text>changing, by the controller of the image capture system, the sampling rate based on the received feedback signal.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>receiving, by the controller of the image capture system from the image processing unit, a feedback signal; and</claim-text><claim-text>changing, by the controller of the image capture system, one or more sets of exposure parameter values of the plurality of sets of exposure parameters based on the received feedback signal.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the images are wirelessly sent by the controller of the image capture system to the image processing unit.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the images are compressed before being sent by the controller of the image capture system to the image processing unit.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising determining a white level of the plurality of images, wherein images are selected for sending by the controller of the image capture system to the image processing unit based on the determined white level.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising determining a focus level of the plurality of images, wherein images are selected for sending by the controller of the image capture system to the image processing unit based on the determined focus level.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein altering, by the controller of the image capture system, the sampling rate at which images are sent by the controller of the image capture system to the image processing unit comprises decreasing the sampling rate.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising subsequently increasing the sampling rate based on one or more subsequently captured images.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A system comprising:<claim-text>at least one image capture device;</claim-text><claim-text>an image processing unit comprising to at least one processor configured to process images;</claim-text><claim-text>a controller comprising one or more processors;</claim-text><claim-text>a non-transitory computer readable medium; and</claim-text><claim-text>program instructions stored on the non-transitory computer readable medium and executable by the one or more processors of the controller to:</claim-text><claim-text>determine a plurality of sets of exposure parameter values for one or more exposure parameters;</claim-text><claim-text>cause the at least one image capture device to capture a plurality of images, wherein each image of the plurality of images is captured according to a set of exposure parameter values of the plurality of sets of exposure parameter values; and</claim-text><claim-text>based on the plurality of captured images, alter a sampling rate at which images are sent by the controller to the image processing unit.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the images are wirelessly sent by the controller to the image processing unit.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the images are compressed before being sent by the controller to the image processing unit.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A non-transitory computer readable medium having stored therein instructions executable by one or more processors to cause a computing system to perform functions comprising:<claim-text>determining, by a controller of an image capture system, a plurality of sets of exposure parameter values for one or more exposure parameters;</claim-text><claim-text>capturing, by an image capture device of the image capture system, a plurality of images, wherein each image of the plurality of images is captured according to a set of exposure parameter values of the plurality of sets of exposure parameter values; and</claim-text><claim-text>based on the plurality of captured images, altering, by the controller of the image capture system, a sampling rate at which images are sent by the controller of the image capture system to an image processing unit, wherein the image processing unit comprises one or more processors configured to process the images.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein altering the sampling rate at which images are sent by the controller of the image capture system to the image processing unit comprises delaying sending the at least one of the plurality of images to the image processing.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein altering, by the controller of the image capture system, the sampling rate at which images are sent by the controller of the image capture system to the image processing unit comprises decreasing the sampling rate.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, the functions further comprising determining a white level of the plurality of images, wherein images are selected for sending by the controller of the image capture system to the image processing unit based on the determined white level.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, the functions further comprising determining a focus level of the plurality of images, wherein images are selected for sending by the controller of the image capture system to the image processing unit based on the determined focus level.</claim-text></claim></claims></us-patent-application>
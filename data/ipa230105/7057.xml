<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007058A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007058</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17942572</doc-number><date>20220912</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2020-0053605</doc-number><date>20200506</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>1096</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>1089</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>403</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>1059</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>75</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>1096</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>1089</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>403</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>1059</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>762</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>4788</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">METHOD, SYSTEM, AND NON-TRANSITORY COMPUTER-READABLE RECORD MEDIUM FOR DISPLAYING REACTION DURING VOIP-BASED CALL</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17307518</doc-number><date>20210504</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11470127</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17942572</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>LINE Plus Corporation</orgname><address><city>Seongnam-si</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>AHN</last-name><first-name>DeokYong</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Hwan</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Min Jeong</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Jaehyun</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Seongsu</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Kyoung Min</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="06" designation="us-only"><addressbook><last-name>SUH</last-name><first-name>Sanghyuk</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="07" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Jeongrok</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="08" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Tae Jeong</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="09" designation="us-only"><addressbook><last-name>KWON</last-name><first-name>Jeong Hyeon</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="10" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Keumryong</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="11" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Na Young</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="12" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Inah</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="13" designation="us-only"><addressbook><last-name>PARK</last-name><first-name>Jungjun</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>LINE Plus Corporation</orgname><role>03</role><address><city>Seongnam-si</city><country>KR</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Disclosed is a reaction display method performed by a computer apparatus including processing circuitry, the reaction display method including displaying, by the processing circuitry, a content sharing screen with a voice over Internet protocol (VoIP) call screen during a VoIP call, the content sharing screen including shared media content, and a user of the computer apparatus participating in the VoIP call, receiving, by the processing circuitry, a position at which a reaction is input from the user during the VoIP call, sending reaction information and the position to at least one other user participating in the VoIP call, the reaction information corresponding to the reaction, and displaying an indication of the reaction on the VoIP call screen or the content sharing screen based on the position.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="145.80mm" wi="117.52mm" file="US20230007058A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="142.41mm" wi="140.89mm" file="US20230007058A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="196.93mm" wi="141.39mm" orientation="landscape" file="US20230007058A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="124.63mm" wi="69.77mm" file="US20230007058A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="160.36mm" wi="119.55mm" file="US20230007058A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="177.29mm" wi="126.41mm" orientation="landscape" file="US20230007058A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="177.38mm" wi="124.46mm" orientation="landscape" file="US20230007058A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="96.60mm" wi="81.28mm" file="US20230007058A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="96.35mm" wi="81.28mm" file="US20230007058A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="107.02mm" wi="119.55mm" file="US20230007058A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="167.13mm" wi="126.83mm" orientation="landscape" file="US20230007058A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="167.13mm" wi="127.25mm" orientation="landscape" file="US20230007058A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="198.88mm" wi="118.79mm" file="US20230007058A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION(S)</heading><p id="p-0002" num="0001">This U.S. application is a continuation of U.S. patent application Ser. No. 17/307,518, filed on May 4, 2021, which claims the benefit of priority under 35 U.S.C. &#xa7; 119 to Korean Patent Application No. 10-2020-0053605, filed May 6, 2020, the entire contents of which are incorporated herein by reference in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">At least one example embodiment relate to technology for providing a call function based on an Internet phone, for example, a voice over Internet protocol (VoIP).</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Currently, a communication device provides various services, such as, for example, a wireless Internet service, and a terrestrial/satellite broadcasting service, in addition to a voice call service or a text service.</p><p id="p-0005" num="0004">In particular, with developments in video compression technology and reconstruction technology, and commercialization of a device with a camera, a video call service that enables a call while verifying a face of a counterpart is being provided.</p><p id="p-0006" num="0005">As an example of technology for providing a video call service, a video call service is provided between mobile phone terminals in a mobile phone network of a wireless environment.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0007" num="0006">At least one example embodiment may share a variety of media contents between call participants during a voice over Internet protocol (VoIP) call using a social graph.</p><p id="p-0008" num="0007">At least one example embodiment may display a reaction exchanged between call participants during a VoIP call in real time.</p><p id="p-0009" num="0008">According to an aspect of at least one example embodiment, there is provided a reaction display method performed by a computer apparatus including processing circuitry, the reaction display method including displaying, by the processing circuitry, a content sharing screen with a voice over Internet protocol (VoIP) call screen during a VoIP call, the content sharing screen including shared media content, and a user of the computer apparatus participating in the VoIP call, receiving, by the processing circuitry, a position at which a reaction is input from the user during the VoIP call, sending reaction information and the position to at least one other user participating in the VoIP call, the reaction information corresponding to the reaction, and displaying an indication of the reaction on the VoIP call screen or the content sharing screen based on the position.</p><p id="p-0010" num="0009">The receiving may include recognizing coordinates on the VoIP call screen or the content sharing screen at which the reaction is input as the position.</p><p id="p-0011" num="0010">The receiving may include recognizing a playback position of content being played back on the content sharing screen at a point in time at which the reaction is input as the position.</p><p id="p-0012" num="0011">The reaction display method may further include specifying, by the processing circuitry, a reaction target among a participant video in the VoIP call screen and the content sharing screen based on the position.</p><p id="p-0013" num="0012">The specifying may include specifying a screen corresponding to coordinates of the position among the VoIP call screen and the content sharing screen as the reaction target.</p><p id="p-0014" num="0013">The specifying may include specifying the content sharing screen as the reaction target in response to a playback position of content being played back on the content sharing screen being received as the position.</p><p id="p-0015" num="0014">The sending may include specifying a particular user corresponding to the reaction target among a plurality of other users participating in the VoIP call, and sending the reaction information and the position to the particular user.</p><p id="p-0016" num="0015">The sending may include generating metadata of a VoIP call packet including the reaction information and the position, and sending the metadata to the at least one other user. The sending may cause the indication of the reaction to be displayed on a screen of a computer apparatus of the at least one other user based on the metadata.</p><p id="p-0017" num="0016">The displaying may include displaying an object matched to the reaction at a location on one of the VoIP call screen or the content sharing screen based on the position.</p><p id="p-0018" num="0017">The reaction display method may further include sending, by the processing circuitry, information about the shared media content and the reaction information to a chatroom related to the VoIP call.</p><p id="p-0019" num="0018">The reaction display method may further include managing, by the processing circuitry, the information about the shared media content and the reaction information in a format corresponding to a message type used in the chatroom.</p><p id="p-0020" num="0019">According to an aspect of at least one example embodiment, there is provided a non-transitory computer-readable record medium storing instructions that, when executed by at least one processor, cause the at least one processor to implement the reaction display method.</p><p id="p-0021" num="0020">According to an aspect of at least one example embodiment, there is provided a computer apparatus including processing circuitry is configured to display a content sharing screen with a voice over Internet protocol (VoIP) call screen during a VoIP call, the content sharing screen including shared media content, and a user of the computer apparatus participating in the VoIP call, receive a position at which a reaction is input from the user during the VoIP call, send reaction information and the position to at least one other user participating in the VoIP call, the reaction information corresponding to the reaction, and display an indication of the reaction on the VoIP call screen or the content sharing screen based on the position.</p><p id="p-0022" num="0021">Further areas of applicability will become apparent from the description provided herein. The description and specific examples in this summary are intended for purposes of illustration only and are not intended to limit the scope of the present disclosure.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example of a network environment according to at least one example embodiment;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example of an electronic device and a server according to at least one example embodiment;</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example of components includable in a processor of an electronic device according to at least one example embodiment;</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating an example of a method performed by an electronic device according to at least one example embodiment;</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIGS. <b>5</b> to <b>8</b></figref> illustrate examples of a process of sharing content during a voice over Internet protocol (VoIP) call according to at least one example embodiment;</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example of a method of displaying a reaction during a VoIP call according to at least one example embodiment; and</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIGS. <b>10</b> to <b>12</b></figref> illustrate examples of a process of displaying a reaction during a VoIP call according to at least one example embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0030" num="0029">At least one example embodiment will be described in detail with reference to the accompanying drawings. At least one example embodiment, however, may be embodied in various different forms, and should not be construed as being limited to only the illustrated examples. Rather, the illustrated examples are provided so that this disclosure will be thorough and complete, and will fully convey the concepts of this disclosure to those skilled in the art. Accordingly, known processes, elements, and techniques, may not be described with respect to at least one example embodiment. Unless otherwise noted, like reference characters denote like elements throughout the attached drawings and written description, and thus descriptions will not be repeated.</p><p id="p-0031" num="0030">As used herein, the singular forms &#x201c;a,&#x201d; &#x201c;an,&#x201d; and &#x201c;the,&#x201d; are intended to include the plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms &#x201c;comprises&#x201d; and/or &#x201c;comprising,&#x201d; when used in this specification, specify the presence of stated features, integers, operations, elements, and/or components, but do not preclude the presence or addition of one or more other features, integers, operations, elements, components, and/or groups, thereof. As used herein, the term &#x201c;and/or&#x201d; includes any and all combinations of one or more of the associated listed products. Expressions such as &#x201c;at least one of,&#x201d; when preceding a list of elements, modify the entire list of elements and do not modify the individual elements of the list. Also, the term &#x201c;exemplary&#x201d; is intended to refer to an example or illustration.</p><p id="p-0032" num="0031">Unless otherwise defined, all terms (including technical and scientific terms) used herein have the same meaning as, or a similar meaning to, that commonly understood by one of ordinary skill in the art to which at least one example embodiment belongs. Terms, such as those defined in commonly used dictionaries, should be interpreted as having a meaning that is consistent with their meaning in the context of the relevant art and/or this disclosure, and should not be interpreted in an idealized or overly formal sense unless expressly so defined herein.</p><p id="p-0033" num="0032">Software may include a computer program, program code, instructions, or some combination thereof, for independently or collectively instructing or configuring a hardware device to operate as desired. The computer program and/or program code may include program or computer-readable instructions, software components, software modules, data files, data structures, and/or the like, capable of being implemented by one or more hardware devices, such as one or more of the hardware devices mentioned herein. Examples of program code include both machine code produced by a compiler and higher level program code that is executed using an interpreter.</p><p id="p-0034" num="0033">A hardware device, such as a computer processing device, may run an operating system (OS) and one or more software applications that run on the OS. The computer processing device also may access, store, manipulate, process, and create data in response to execution of the software. For simplicity, at least one example embodiment may be exemplified as one computer processing device; however, one skilled in the art will appreciate that a hardware device may include multiple processing elements and multiple types of processing elements. For example, a hardware device may include multiple processors or a processor and a controller. In addition, other processing configurations are possible, such as parallel processors.</p><p id="p-0035" num="0034">Although described with reference to specific examples and drawings, modifications, additions and substitutions of at least one example embodiment may be variously made according to the description by those of ordinary skill in the art. For example, the described techniques may be performed in an order different with that of the methods described, and/or components such as the described system, architecture, devices, circuit, and the like, may be connected or combined to be different from the above-described methods, or results may be appropriately achieved by other components or equivalents.</p><p id="p-0036" num="0035">Hereinafter, at least one example embodiment will be described with reference to the accompanying drawings.</p><p id="p-0037" num="0036">At least one example embodiment relates to technology for providing a call function based on a voice over Internet protocol (VoIP).</p><p id="p-0038" num="0037">At least one example embodiment including the disclosures described herein may share a variety of media contents between call participants during a VoIP call using a social graph, and may display a reaction exchanged between the call participants during the VoIP call in real time, accordingly.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example of a network environment according to at least one example embodiment. Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the network environment may include a plurality of electronic devices <b>110</b>, <b>120</b>, <b>130</b>, and/or <b>140</b>, a plurality of servers <b>150</b> and/or <b>160</b>, and/or a network <b>170</b>. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is provided as an example only. A number of electronic devices or a number of servers is not limited thereto.</p><p id="p-0040" num="0039">Each of the plurality of electronic devices <b>110</b>, <b>120</b>, <b>130</b>, and/or <b>140</b> may be a fixed terminal or a mobile terminal that is configured as a computer apparatus. For example, the plurality of electronic devices <b>110</b>, <b>120</b>, <b>130</b>, and/or <b>140</b> may be a smartphone, a mobile phone, a navigation device, a computer, a laptop computer, a digital broadcasting terminal, a personal digital assistant (PDA), a portable multimedia player (PMP), a tablet personal computer (PC), a game console, a wearable device, an Internet of things (IoT) device, a virtual reality (VR) device, an augmented reality (AR) device, and/or the like. For example, although <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a shape of a smartphone as an example of the electronic device <b>110</b>, the electronic device <b>110</b> used herein may refer to one of various types of physical computer apparatuses capable of communicating with other electronic devices <b>120</b>, <b>130</b>, and <b>140</b>, and/or the servers <b>150</b> and <b>160</b> over the network <b>170</b> in a wireless or wired communication manner.</p><p id="p-0041" num="0040">The communication scheme is not limited and may include a near field wireless communication scheme between devices as well as a communication scheme using a communication network (e.g., a mobile communication network, wired Internet, wireless Internet, a broadcasting network, a satellite network, etc.) includable in the network <b>170</b>. For example, the network <b>170</b> may include at least one of network topologies that include a personal area network (PAN), a local area network (LAN), a campus area network (CAN), a metropolitan area network (MAN), a wide area network (WAN), a broadband network (BBN), and/or Internet. Also, the network <b>170</b> may include at least one of network topologies that include a bus network, a star network, a ring network, a mesh network, a star-bus network, a tree or hierarchical network, and/or the like. However, they are provided as examples only.</p><p id="p-0042" num="0041">Each of the servers <b>150</b> and <b>160</b> may be configured as a computer apparatus or a plurality of computer apparatuses that provides an instruction, a code, a file, content, a service, etc., through communication with the plurality of electronic devices <b>110</b>, <b>120</b>, <b>130</b>, and/or <b>140</b> over the network <b>170</b>. For example, the server <b>150</b> may be a system that provides a first service to the plurality of electronic devices <b>110</b>, <b>120</b>, <b>130</b>, and/or <b>140</b> connected over the network <b>170</b>. The server <b>160</b> may be a system that provides a second service to the plurality of electronic devices <b>110</b>, <b>120</b>, <b>130</b>, and/or <b>140</b> connected over the network <b>170</b>. In detail, the server <b>150</b> may provide, as the first service, a service (e.g., a VoIP call service) intended (e.g., requested and/or received) by an application through the application as a computer program installed and executed on the plurality of electronic devices <b>110</b>, <b>120</b>, <b>130</b>, and/or <b>140</b>. As another example, the server <b>160</b> may provide, as the second service, a service that distributes a file for installing and executing the application to the plurality of electronic devices <b>110</b>, <b>120</b>, <b>130</b>, and/or <b>140</b>.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an example of an electronic device and a server according to at least one example embodiment. Description is made using the electronic device <b>110</b> as an example of an electronic device and the server <b>150</b> as an example of a server with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Also, each of the other electronic devices <b>120</b>, <b>130</b>, and/or <b>140</b>, and/or the server <b>160</b>, may have the same configuration as, or a similar configuration to, that of the electronic device <b>110</b> or the server <b>150</b>.</p><p id="p-0044" num="0043">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the electronic device <b>110</b> may include a memory <b>211</b>, a processor <b>212</b>, a communication module <b>213</b>, and/or an input/output (I/O) interface <b>214</b>, and the server <b>150</b> may include a memory <b>221</b>, a processor <b>222</b>, a communication module <b>223</b>, and/or an I/O interface <b>224</b>. The memory <b>211</b>, <b>221</b> may include a permanent mass storage device, such as random access memory (RAM), a read only memory (ROM), a disk drive, a solid state drive (SSD), a flash memory, etc., as a non-transitory computer-readable record medium. The permanent mass storage device, such as a ROM, an SSD, a flash memory, and/or a disk drive, may be included in the electronic device <b>110</b> and/or the server <b>150</b> as a permanent storage device separate from the memory <b>211</b>, <b>221</b>. Also, an OS and at least one program code, for example, a code for a browser installed and executed on the electronic device <b>110</b>, or an application installed and executed on the electronic device <b>110</b> to provide a specific service, may be stored in the memory <b>211</b>, <b>221</b>. Such software components may be loaded from another non-transitory computer-readable record medium separate from the memory <b>211</b>, <b>221</b>. The other non-transitory computer-readable record medium may include a non-transitory computer-readable record medium, for example, a floppy drive, a disk, a tape, a DVD/CD-ROM drive, a memory card, etc. According to at least one example embodiment, software components may be loaded to the memory <b>211</b>, <b>221</b> through the communication module <b>213</b>, <b>223</b>, instead of the non-transitory computer-readable record medium. For example, at least one program may be loaded to the memory <b>211</b>, <b>221</b> based on a computer program, for example, the application, installed by files provided over the network <b>170</b> from developers or a file distribution system, for example, the server <b>160</b>, providing an installation file of the application.</p><p id="p-0045" num="0044">The processor <b>212</b>, <b>222</b> may be configured to process instructions of a computer program by performing basic arithmetic operations, logic operations, and/or I/O operations. The computer-readable instructions may be provided from the memory <b>211</b>, <b>221</b> or the communication module <b>213</b>, <b>223</b> to the processor <b>212</b>, <b>222</b>. For example, the processor <b>212</b>, <b>222</b> may be configured to execute received instructions in response to the program code stored in the storage device, such as the memory <b>211</b>, <b>221</b>.</p><p id="p-0046" num="0045">The communication module <b>213</b>, <b>223</b> may provide a function for communication between the electronic device <b>110</b> and the server <b>150</b> over the network <b>170</b>, and may provide a function for communication between the electronic device <b>110</b>, and/or the server <b>150</b>, and another electronic device, for example, the electronic device <b>120</b> or another server, for example, the server <b>160</b>. For example, the processor <b>212</b> of the electronic device <b>110</b> may transfer a request created based on a program code stored in the storage device such as the memory <b>211</b>, to the server <b>150</b> over the network <b>170</b> under control of the communication module <b>213</b>. Inversely, a control signal, an instruction, content, a file, etc., provided under control of the processor <b>222</b> of the server <b>150</b> may be received at the electronic device <b>110</b> through the communication module <b>213</b> of the electronic device <b>110</b> by going through the communication module <b>223</b> and the network <b>170</b>. For example, a control signal, an instruction, content, a file, etc., of the server <b>150</b> received through the communication module <b>213</b> may be transferred to the processor <b>212</b> or the memory <b>211</b>, and content, a file, etc., may be stored in a storage medium, for example, the permanent storage device, further includable in the electronic device <b>110</b>.</p><p id="p-0047" num="0046">The I/O interface <b>214</b> may be a device used for interfacing with an I/O apparatus <b>215</b> (e.g., an input device and/or an output device). The I/O apparatus <b>215</b> may also be referred to as an I/O device <b>215</b> herein. For example, an input device may include a device, such as a keyboard, a mouse, a microphone, a camera, etc., and an output device may include a device, such as a display, a speaker, a haptic feedback device, etc. As another example, the I/O interface <b>214</b> may be a device for interfacing with an apparatus in which an input function and an output function are integrated into a single function, such as a touchscreen. The I/O apparatus <b>215</b> may be configured as (e.g., incorporated in) a single device with the electronic device <b>110</b>. Also, the I/O interface <b>224</b> of the server <b>150</b> may be a device for interfacing with an apparatus (not shown), for input or output, that may be connected to the server <b>150</b> or included in the server <b>150</b>. In detail, when the processor <b>212</b> of the electronic device <b>110</b> processes an instruction of a computer program loaded to the memory <b>211</b>, content or a service screen configured based on data provided from the server <b>150</b> or the electronic device <b>120</b> may be displayed on the display through the I/O interface <b>214</b>.</p><p id="p-0048" num="0047">According to at least one example embodiment, the electronic device <b>110</b> and/or the server <b>150</b> may include a number of components greater than or less than a number of components shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. However, some components according to the related art are not illustrated in detail. For example, the electronic device <b>110</b> may include at least a portion of the I/O apparatus <b>215</b>, or may further include other components, for example, a transceiver, a global positioning system (GPS) module, a camera, a variety of sensors, a database (DB), and/or the like. In detail, if the electronic device <b>110</b> is a smartphone, the electronic device <b>110</b> may be configured to further include a variety of components, for example, an acceleration sensor, a gyro sensor, a camera module, various physical buttons, a button using a touch panel, an I/O port, a vibrator for vibration, etc., which are generally included in the smartphone.</p><p id="p-0049" num="0048">Hereinafter, at least one example embodiment of a method and system for sharing contents during a VoIP-based call is described.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example of components includable in a processor of an electronic device according to at least one example embodiment, and <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating an example of a method performed by an electronic device according to at least one example embodiment.</p><p id="p-0051" num="0050">A VoIP call system implemented as a computer may be configured in the electronic device <b>110</b> according to at least one example embodiment. For example, the VoIP call system may be configured in a form of an independently operating program or may be configured in an in-app form of a specific application, for example, a messenger, to be operable on the specific application. Depending on at least one example embodiment, a VoIP call service may be provided through interaction with the server <b>150</b>.</p><p id="p-0052" num="0051">The VoIP call system configured in the electronic device <b>110</b> may perform the content sharing method of <figref idref="DRAWINGS">FIG. <b>4</b></figref> in response to an instruction provided from an application installed on the electronic device <b>110</b>.</p><p id="p-0053" num="0052">Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, to perform the content sharing method of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the processor <b>212</b> of the electronic device <b>110</b> may include a call provider <b>310</b>, an interface provider <b>320</b>, a share requester <b>330</b>, a content display <b>340</b>, and/or a reaction display <b>350</b>. Depending on at least one example embodiment, the components of the processor <b>212</b> may be selectively included in or excluded from the processor <b>212</b>. Also, depending on at least one example embodiment, the components of the processor <b>212</b> may be separated or merged for representations of functions of the processor <b>212</b>.</p><p id="p-0054" num="0053">The processor <b>212</b>, and/or the components of the processor <b>212</b>, may control the electronic device <b>110</b> to perform operations S<b>410</b> to S<b>450</b> included in the content sharing method of <figref idref="DRAWINGS">FIG. <b>4</b></figref>. For example, the processor <b>212</b>, and/or the components of the processor <b>212</b>, may be configured to execute an instruction according to a code of at least one program and a code of an OS included in the memory <b>211</b>.</p><p id="p-0055" num="0054">Here, the components of the processor <b>212</b> may be representations of different functions of the processor <b>212</b> performed by the processor <b>212</b> in response to an instruction provided from the program code stored in the electronic device <b>110</b>, for example, an instruction provided from the application executed on the electronic device <b>110</b>. For example, the call provider <b>310</b> may be used as a functional representation of the processor <b>212</b> that controls the electronic device <b>110</b> to provide a VoIP call in response to the instruction.</p><p id="p-0056" num="0055">The processor <b>212</b> may read an instruction from the memory <b>211</b> to which instructions associated with control of the electronic device <b>110</b> are loaded. In this case, the read instruction may include an instruction for controlling the processor <b>212</b> to perform the following operations S<b>410</b> to S<b>450</b>.</p><p id="p-0057" num="0056">Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, in operation S<b>410</b>, the call provider <b>310</b> may provide a VoIP call in which at least two users including a user of the electronic device <b>110</b> participate. The VoIP call may include a video call function and/or a voice call function based on VoIP. Here, the VoIP call may support a group call including a number of users less than a maximum, or upper limit, preset or alternatively, given number of users as well as a one-to-one call. For example, in response to a request for a VoIP call between users of the electronic device <b>110</b>, <b>120</b>, <b>130</b>, and <b>140</b>, it is possible to transfer a call request to an electronic device of a counterpart and thereby, to connect a VoIP-based call channel to users that accept to participate in a corresponding call. According to at least one example embodiment, each participant to the VoIP call (e.g., the electronic device <b>110</b>, the electronic device <b>120</b>, the electronic device <b>130</b>, and/or the electronic device <b>140</b>) may generate a picture and/or video by capturing an image (e.g., sensing light from the environment and generating a digital image based on the sensed light). The pictures and/or videos generated by each respective participant to the VoIP call (e.g., generated using a camera included in, for example, the electronic device <b>110</b>) may be sent to the other participants of the VoIP call. The pictures and/or videos generated by each respective participant (e.g., other participants) to the VoIP call may be displayed in a call screen corresponding to the VoIP call.</p><p id="p-0058" num="0057">In the case of a video call, the call provider <b>310</b> may transfer, to the server <b>150</b>, an indication of an intent of the user of the electronic device <b>110</b> to participate in the call, may receive, from the server <b>150</b>, videos of participants of the VoIP call as an individual video, may render the received participant videos into a single screen and may configure a video call screen. Instead of generating, on the side of the server <b>150</b>, a single video that includes a plurality of participant videos and providing the generated single video to the electronic device <b>110</b>, the server <b>150</b> may send each of the participant videos to the electronic device <b>110</b> as an individual video and the electronic device <b>110</b> may configure the plurality of participant videos into a video call screen on a single screen. According to at least one example embodiment, the plurality of participant videos may correspond to videos generated by each respective participant to the VoIP call.</p><p id="p-0059" num="0058">In the case of a voice call, the call provider <b>310</b> may generate a list of participants based on profile information with respect to users that accept to participate in the call, and may configure a video and/or voice call screen that includes the list of participants. According to at least one example embodiment, the voice call screen may include pictures generated by each respective participant to the VoIP call.</p><p id="p-0060" num="0059">In operation S<b>420</b>, in response to receiving a user input that calls a content share function, from the user of the electronic device <b>110</b> during the VoIP call, the interface provider <b>320</b> may provide (e.g., generate and/or output to a display of the electronic device <b>110</b>) a graphical user interface (GUI) for specifying content desired to be shared with a participant in a call. The user input may include a media type selected as a content sharing medium. For example, the media type may include a screen share, and/or a content provider that provides a content sharing service such as YouTube, and the like. The content share function may be a function of sharing media content, through screen sharing or the content sharing service, between call participants during the VoIP call. The interface provider <b>320</b> may provide a GUI, corresponding to a media type by (e.g., included in) the user input, as an interface for specifying content to be shared with a call participant on a VoIP call screen.</p><p id="p-0061" num="0060">For example, in the case of sharing content of the content provider as one of several media types, the interface provider <b>320</b> may provide a GUI for a content search. The interface provider <b>320</b> may provide a provider selection screen for selecting a content provider and, in response to a selection on (e.g., of) the content provider through the provider section screen, may provide a GUI capable of (e.g., configured to facilitate) searching for content in (e.g., on) a platform of the content provider. That is, the interface provider <b>320</b> may provide a list of content providers that provide the content sharing service and may provide an interface capable of searching (e.g., configured to facilitate a search) for content of a content provider selected from the list of content providers. The user may select a specific content provider as a media type and then may specify content that the user desires to share with a call participant through the content search within the platform of the corresponding content provider. According to at least one example embodiment, the interface provider <b>320</b> may provide a GUI for the content search that corresponds to the content provider selected via the provider selection screen. According to at least one example embodiment, the provider selection screen may include a list of available content providers and may be configured to receive a user input selecting one of the content providers from the list of available content providers.</p><p id="p-0062" num="0061">As another example, in the case of sharing content through screen sharing as one of several media types, the interface provider <b>320</b> may provide a GUI that includes a preview for a screen sharing target. In the case of sharing content of a content provider through a URL, the interface provider <b>320</b> may provide a GUI that includes a preview for content of the corresponding URL. In the case of entering the VoIP call screen in a state in which a content URL of the content provider is copied on a clipboard, the interface provider <b>320</b> may recognize the entry as an instruction to call the content share function. Here, in response to recognizing the instruction to call the content share function, the interface provider <b>320</b> may provide a GUI that includes a preview for the URL copied to the clipboard. The user may verify a screen sharing target or media content of the URL through the preview, and then may specify the verified media content as content to be shared with the call participant.</p><p id="p-0063" num="0062">In providing a GUI for a content search, the interface provider <b>320</b> may recommend a keyword for the content search based on profile information set to a chatroom (e.g., a chatroom corresponding to a VoIP call) or previously shared data in the corresponding chatroom during the VoIP call. Here, the profile information may include topic information of the chatroom. The interface provider <b>320</b> may recommend a keyword based on profile information of a user that participates in the chatroom, such as, for example, an age, a gender, and/or a residential area. In addition to the profile information, a matter (e.g., a topic) of interest may be derived by analyzing previous shared data, for example, messages or contents sent through the chatroom, and a keyword related to the derived matter of interest may be provided as a recommend keyword. For example, if at least a desired or alternatively, given ratio of messages for corona virus are present in the chatroom, the interface provider <b>320</b> may recommend a keyword related to corona virus. If statistical information, for example, recent news about the chatroom, is shared a large number of times, the interface provider <b>320</b> may recommend a keyword related to the corresponding news. Also, if a video of a LINE Friends channel is shared most based on a content sharing history of the chatroom, for example, using LINE LIVE during the VoIP call, the interface provider <b>320</b> may recommend a real-time popular keyword of LINE LIVE or a keyword related to the LINE Friends channel. In the case of an open chatroom in which a plurality of users gather and exchange content on a specific topic on a messenger platform, the interface provider <b>320</b> may recommend a keyword based on topic information set to the open chatroom.</p><p id="p-0064" num="0063">In operation S<b>430</b>, in response to receiving a share request for specified content through the GUI from the user of the electronic device <b>110</b>, the share requester <b>330</b> may generate the share request for the specified content as metadata in a protocol of the VoIP call channel, and may send the generated metadata to the server <b>150</b>. That is, the share requester <b>330</b> may generate metadata of a VoIP call packet that includes data corresponding to the content share request and may send the generated metadata to the server <b>150</b>.</p><p id="p-0065" num="0064">A content sharing protocol for data exchange in a VoIP call state may be defined in advance based on a media type. For example, the content sharing protocol may include an identifier that represents a content share function and metadata defined based on a media type. Start and unset for content sharing may be processed through an event of a core. When the media type is a content provider, an identifier of the media type, an identifier, a title, a thumbnail, a playback state (playing, pause, etc.,), and/or a playback position, of user specified content, and/or the like may be added to the metadata of the VoIP call packet. In the case of sharing content of the content provider through the URL, an identifier of the media type, a URL (e.g., a URL identifying the content and/or a location of the content), a playback state, and/or a playback position of the content may be added to the metadata of the VoIP call packet. When the media type is a screen share, an identifier of the media type, data used for screen sharing, and/or the like, may be added to the metadata of the VoIP call packet. The share requester <b>330</b> may describe all information used to synchronize content specified through the GUI (preview or search result) between the user of the electronic device <b>110</b> and the call participant as metadata of VoIP, and may send the same (e.g., the information) to the server <b>150</b>.</p><p id="p-0066" num="0065">In operation S<b>440</b>, the content display <b>340</b> may display content corresponding to the share request from the user of the electronic device <b>110</b> with the VoIP call screen. When the share request for the content specified through the GUI is transferred from the user of the electronic device <b>110</b> to the server <b>150</b>, the content display <b>340</b> may display a playback screen (hereinafter, referred to as a &#x201c;content sharing screen&#x201d;) of the corresponding content with the VoIP call screen. For example, the content display <b>340</b> may include the content sharing screen in the VoIP call screen through interaction with the call provider <b>310</b>, and may adjust and display the playback screen as a single screen combined with the VoIP call screen. As another example, the content display <b>340</b> may display the content sharing screen to be overlaid on the VoIP call screen as an individual screen, such as picture-in-picture (PIP).</p><p id="p-0067" num="0066">The server <b>150</b> may recognize a media type and content to be shared based on the metadata of the VoIP call packet, may determine the electronic device <b>110</b> that requests content share among call participants as a sender, and may determine at least one of the electronic devices <b>120</b>, <b>130</b>, and <b>140</b> of the remaining participants as a receiver.</p><p id="p-0068" num="0067">The server <b>150</b> may transfer the metadata of the VoIP call packet that includes data corresponding to the content share request of the sender to at least one of the electronic devices <b>120</b>, <b>130</b>, and <b>140</b> corresponding to the receiver. The server <b>150</b> may perform relay functionality of transferring the metadata of the VoIP call packet between the sender and the receiver for sharing the content as is.</p><p id="p-0069" num="0068">At least one of the electronic devices <b>120</b>, <b>130</b>, and <b>140</b> corresponding to the receiver may share the content in the same state as, or a similar state to, that of the sender based on the metadata of the VoIP call packet received from the sender through the server <b>150</b>. When a video is to be shared, the sender may include only information about the video (e.g., URL information, or content identifier, and information about a start point in time) in the metadata, or may include the information in a video packet, and transfer the same to the receiver. The receiver may load the video from the content provider based on information included in the metadata or may start to play back the video included in the VoIP call packet received from the sender in a playback state of the sender as is without performing an additional loading operation. In the case of a request for sharing a playback list, the receiver may receive a state of the sender through the metadata of the VoIP call packet and may start to play back the video by directly referring to video information included in the playback list and filling the corresponding information.</p><p id="p-0070" num="0069">For a VoIP call, a relay server, for example, the server <b>150</b> may be used to transfer the VoIP call packet. However, it is provided as an example only. Peer to peer (P2P) communication may be used without using the server <b>150</b>. The electronic device <b>110</b> may directly transfer, to the electronic device <b>120</b> corresponding to the receiver, the metadata of the VoIP call packet that includes data corresponding to the content share request of the user through P2P of one-to-one communication. Therefore, the VoIP call packet may be sent and received between the sender and the receiver through P2P without using the server <b>150</b>. Content may be shared during the VoIP call using the metadata of the VoIP call packet.</p><p id="p-0071" num="0070">Basically, the sender may have a right (e.g., ability) to manipulate content shared with the receiver. When a user of a sender side modifies a playback position or a playback state, metadata of a VoIP call packet that includes modified data may be transferred to the receiver to synchronize a state of the content being shared between the sender and the receiver according to a manipulation of the sender. As another example, the receiver may receive a state of content being shared, or propose sharing of another content, based on consent from the sender or another call participant.</p><p id="p-0072" num="0071">In operation S<b>450</b>, the reaction display <b>350</b> may display a reaction corresponding to the user input for the VoIP call screen, or the content sharing screen, on a corresponding screen in an environment of sharing content during the VoIP call. A method of displaying the reaction on the VoIP call screen or the content sharing screen is further described below.</p><p id="p-0073" num="0072"><figref idref="DRAWINGS">FIGS. <b>5</b> to <b>8</b></figref> illustrate examples of describing a process of sharing content during a VoIP call according to at least one example embodiment.</p><p id="p-0074" num="0073"><figref idref="DRAWINGS">FIGS. <b>5</b> to <b>8</b></figref> illustrate examples of an interface screen displayed on a display of the electronic device <b>110</b>.</p><p id="p-0075" num="0074">Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the processor <b>212</b> may receive each of several participant videos of a VoIP call as an individual video, and may render the received participant videos into a single screen and then display a video call screen <b>510</b>. In response to receiving a user input for calling a content share function from the user of the electronic device <b>110</b> during the VoIP call, the processor <b>212</b> may provide a GUI for specifying content desired to be shared with a participant in a call.</p><p id="p-0076" num="0075">The video call screen <b>510</b> may be adjusted based on an environmental setting by the user and/or a number of participants. For example, the video call screen <b>510</b> may be configured such that all participant videos are displayed on a single screen, or participant videos are aligned in one direction and then swiped in an alignment direction. According to at least one example embodiment, participant videos up to a threshold number of videos may be displayed on the video call screen <b>710</b>, and participant videos in excess of the threshold number may be displayed in response to a swipe gesture input.</p><p id="p-0077" num="0076">Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, when the user desires to share content of a content provider, such as YouTube, as one of several media types, the processor <b>212</b> may provide a content search GUI <b>520</b> (e.g., as a pop-up screen, overlay, etc.). When a plurality of content providers is linkable, the processor <b>212</b> may provide a provider selection screen for selecting a content provider. In response to a selection on (e.g., of) a content provider through the provider selection screen, the processor <b>212</b> may provide the content search GUI <b>520</b> capable of searching (e.g., facilitating a search) for content in a platform of the selected content provider.</p><p id="p-0078" num="0077">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, when the user desires to share content through screen sharing as another media type, the processor <b>212</b> may provide a preview GUI <b>630</b> that includes a preview for a screen specified as a screen sharing target among screens executed on the electronic device <b>110</b>.</p><p id="p-0079" num="0078">The processor <b>212</b> may display the content search GUI <b>520</b> and/or the preview GUI <b>630</b> to be overlaid (e.g., as an overlay, pop-up, etc.) on the video call screen <b>510</b> as GUIs for specifying content (see <figref idref="DRAWINGS">FIG. <b>5</b></figref>), or may adjust the video call screen <b>510</b> and display the content search GUI <b>520</b> and the preview GUI <b>630</b> as a single screen combined with the video call screen <b>510</b> (see <figref idref="DRAWINGS">FIG. <b>6</b></figref>), as a GUI for specifying content.</p><p id="p-0080" num="0079">When the user specifies content through the content search GUI <b>520</b> or the preview GUI <b>630</b> and requests sharing of the specified content, the processor <b>212</b> may transfer, to a receiver, metadata of a VoIP call packet that includes data for the corresponding content sharing. Referring to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the processor <b>212</b> may display the video call screen <b>510</b> and a content sharing screen <b>740</b> that is a playback screen of content requested to be shared.</p><p id="p-0081" num="0080">In the case of displaying the content sharing screen <b>740</b> on a single screen combined with the video call screen <b>510</b>, the video call screen <b>510</b> may display participant videos on a remaining area excluding (e.g., outside of) the content sharing screen <b>740</b>. Here, the video call screen <b>510</b> may be configured to display all of the participant videos or a portion of the participant videos. Alternatively, the video call screen <b>510</b> may be configured to align participant videos in one direction and to be swiped in an alignment direction. According to at least one example embodiment, participant videos up to a threshold number of videos may be displayed on the video call screen <b>710</b>, and participant videos in excess of the threshold number may be displayed in response to a swipe gesture input.</p><p id="p-0082" num="0081">Referring to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, in the case of a voice call in addition to a video call, the processor <b>212</b> may provide a voice call screen <b>810</b> that includes a list of participants participating in a call as a VoIP call screen. In the case of sharing content during the voice call, the processor <b>212</b> may display the content sharing screen <b>740</b> with the voice call screen <b>810</b> that includes the list of participants.</p><p id="p-0083" num="0082">According to at least one example embodiment, a variety of media contents may be shared between call participants during a VoIP call, for example, a voice call or a video call, using a social graph.</p><p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example of a method of displaying a reaction during a VoIP call according to at least one example embodiment. The reaction display method of <figref idref="DRAWINGS">FIG. <b>9</b></figref> may be performed by the reaction display <b>350</b> and may be included in operation S<b>450</b> included in the content sharing method of <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0085" num="0084">Referring to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, in operation S<b>901</b>, the reaction display <b>350</b> may receive position information about a position at which a reaction is input from the user of the electronic device <b>110</b> during the VoIP call, for example, the voice call or the video call. For example, the reaction display <b>350</b> may recognize coordinates of an actual position at which the reaction is input from the user using a touch, as position information on a screen, for example, the VoIP call screen or the content sharing screen, on which the reaction of the user is input. The coordinates of the position at which the reaction is input may include a single pair of XY coordinates based on a reaction type, and/or may include an XY coordinate set as trajectory information that tracks one or more touches. As another example, in the case of a reaction input on the content sharing screen, the reaction display <b>350</b> may recognize a playback position of content being played back on the content sharing screen at a point in time at which the reaction is input from the user as position information about the position at which the reaction of the user is input. According to at least one example embodiment, the reaction display <b>350</b> may receive and/or determine the position at which the reaction is input (e.g., a reaction position) and/or information about the reaction (e.g., reaction information). Information about the reaction may include a reaction type (e.g., like, dislike, etc.), and information about the reaction target may include information representing whether the corresponding reaction relates to a participant video in the VoIP call screen or the content sharing screen.</p><p id="p-0086" num="0085">In operation S<b>902</b>, the reaction display <b>350</b> may specify a target (hereinafter, a reaction target) to which the reaction is input from the user of the electronic device <b>110</b> between (e.g., among) a participant video included in the VoIP call screen and the content sharing screen, based on the position information received in operation S<b>901</b>. The user may input the reaction to a single participant video, among participant videos included in the VoIP call screen, or the content sharing screen. Here, the reaction display <b>350</b> may specify the reaction target based on the position information about the position at which the reaction of the user is input. For example, the reaction display <b>350</b> may specify, as the reaction target, a screen corresponding to coordinates of an actual position at which the reaction is input between (e.g., among) the VoIP call screen and the content sharing screen. When the user inputs the reaction to a video of a specific participant on the VoIP call screen, the reaction display <b>350</b> may specify the reaction target through (e.g., using and/or as) an identifier of the corresponding specific participant. As another example, when a playback position of content is recognized as reaction position information, the reaction display <b>350</b> may specify the content sharing screen as the reaction target. As another example, the reaction display <b>350</b> may specify the reaction target by analyzing at least a portion of a screen corresponding to the playback position of the content. Here, the reaction display <b>350</b> may specify the reaction target by sending image data about at least a portion of the screen to the server <b>150</b>, and by receiving, from the server <b>150</b>, information about a thing, a person, and/or a location recognized from the image data using an image learning model constructed on the server <b>150</b> or a platform interactable with the server <b>150</b>.</p><p id="p-0087" num="0086">In operation S<b>903</b>, the reaction display <b>350</b> may send information about the reaction input from the user of the electronic device <b>110</b>, and the reaction target and position information related to the corresponding reaction, to another user participating in the VoIP call, that is, a call participant. Information about the reaction may include a reaction type, and information about the reaction target may include information representing whether the corresponding reaction relates to a participant video in the VoIP call screen or the content sharing screen. The reaction display <b>350</b> may generate information about the reaction and the reaction target, and the reaction position information, as metadata in a protocol of the VoIP call channel, and may send the generated metadata to the call participant through the server <b>150</b> or peer-to-peer (P2P) communication. For example, the reaction display <b>350</b> may send metadata of a VoIP call packet including information about the reaction, the reaction target and the reaction position information to all of users participating in the VoIP call. According to at least one example embodiment, the sending of the metadata to another user participating in the VoIP call causes an indication of the reaction to be displayed on a screen of a computer apparatus of the other user (e.g., based on the metadata). As another example, the reaction display <b>350</b> may specify a participant corresponding to the reaction target among users that participate in the VoIP call and may send, to the specified participant, metadata of the VoIP call packet that includes information about the reaction and the reaction position information.</p><p id="p-0088" num="0087">In operation S<b>904</b>, the reaction display <b>350</b> may display the reaction (e.g., an indication of the reaction) at a corresponding position (also referred to herein as a corresponding location) based on the reaction position information on a screen corresponding to the reaction target between the VoIP call screen and the content sharing screen. An object matched to a corresponding reaction may be predefined or alternatively, given for each reaction. The reaction display <b>350</b> may display an object matched to the reaction input from the user at the position at which the reaction is input, in association with the reaction target. Here, the object may include a visual element, such as an image, an effect animation, and/or the like, predefined or alternatively, given to correspond to the reaction. In addition to the visual element, the object may further include a tactile element, such as a haptic element, and/or an audio-based auditory element.</p><p id="p-0089" num="0088">All of the electronic devices <b>120</b>, <b>130</b>, and <b>140</b> of other users participating in the VoIP call may display the content sharing screen with the VoIP call screen. Here, the reaction input from the user of the electronic device <b>110</b>, the reaction target, and the reaction position information may be analyzed based on the metadata of the VoIP call packet received from the electronic device <b>110</b>. The electronic device <b>120</b>, <b>130</b>, <b>140</b> of the other users may display the reaction input from the user of the electronic device <b>110</b> at the corresponding position based on the reaction position information on a screen corresponding to the reaction target between the VoIP call screen and the content sharing screen. Depending on at least one example embodiment, only an electronic device, for example, the electronic device <b>120</b>, of a participant corresponding to the reaction target among the electronic devices <b>120</b>, <b>130</b>, and <b>140</b> of the other users that participate in the VoIP call, may receive reaction-related metadata from the electronic device <b>110</b> and may display the reaction input from the user of the electronic device <b>110</b> on a participant video screen of the user of the electronic device <b>110</b> within the VoIP call screen.</p><p id="p-0090" num="0089"><figref idref="DRAWINGS">FIGS. <b>10</b> to <b>12</b></figref> illustrate examples of a process of displaying a reaction during a VoIP call according to at least one example embodiment.</p><p id="p-0091" num="0090"><figref idref="DRAWINGS">FIGS. <b>10</b> and <b>11</b></figref> illustrate examples of a scenario in which a reaction is transferred between users during a video call.</p><p id="p-0092" num="0091">Referring to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the user of the electronic device <b>110</b> may share the same video, or similar videos, with other users participating in the video call through the content sharing screen <b>740</b>. Here, the user may input a reaction at a specific playback position while viewing the video.</p><p id="p-0093" num="0092">When the reaction is input through a reaction input interface <b>1001</b>, for example, a like button, associated with the content sharing screen <b>740</b>, the processor <b>212</b> may recognize a playback position of content, at a point in time at which the reaction is input from the user, as position information about the position at which the reaction of the user is input.</p><p id="p-0094" num="0093">The processor <b>212</b> may display an image <b>1002</b> of the reaction input from the user on the content sharing screen <b>740</b>, for example, a progress bar <b>1041</b> that represents the playback position of content. Here, the image <b>1002</b> of the reaction may be displayed at a point corresponding to the playback position at the point in time at which the reaction is input from the user.</p><p id="p-0095" num="0094">All of the electronic devices <b>120</b>, <b>130</b>, and <b>140</b> of the other users participating in the VoIP call may display the reaction input (e.g., the image <b>1002</b> of the reaction input) from the user of the electronic device <b>110</b> at an input position of the reaction on the content sharing screen <b>740</b> being shared with the user of the electronic device <b>110</b>, and may share the position at which the reaction is input among the users that participate in the VoIP call.</p><p id="p-0096" num="0095">Referring to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the user of the electronic device <b>110</b> may share a shopping site screen <b>1150</b>, specified as a screen sharing target among screens executed on the electronic device <b>110</b>, as a content sharing screen with other users that participate in the video call, and may input a reaction to a specific item on the shopping site screen <b>1150</b> through screen share.</p><p id="p-0097" num="0096">The processor <b>212</b> may display a reaction input interface <b>1101</b> in response to a user input on the shopping site screen <b>1150</b> corresponding to the content sharing screen. Here, the user may input the reaction at a position of the specific item on the shopping site screen <b>1150</b> through the reaction input interface <b>1101</b>.</p><p id="p-0098" num="0097">The processor <b>212</b> may display an image <b>1102</b> of the reaction input from the user at the position at which the reaction is input from the user on the shopping site screen <b>1150</b>.</p><p id="p-0099" num="0098">All of the electronic devices <b>120</b>, <b>130</b>, and <b>140</b> of the other users participating in the VoIP call may display the reaction input from the user of the electronic device <b>110</b> on the shopping site screen <b>1150</b> that is shared with the user of the electronic device <b>110</b> and, through this, may share the position at which the reaction is input among the users participating in the VoIP call.</p><p id="p-0100" num="0099">The processor <b>212</b> may identify a user that inputs a reaction among VoIP call participants and may display the reaction image <b>1102</b> on a video screen of the corresponding user in the video call screen <b>510</b>. Through this, the processor <b>212</b> may easily verify the user corresponding to the reaction among users that participate in the VoIP call.</p><p id="p-0101" num="0100">In addition to the above scenario, while sharing a screen on which a collaboration document is displayed between users participating in the VoIP call in a similar manner to the scenario described above with reference to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, a collaboration using screen share may forward, as a reaction, a question or an opinion on a specific portion in a document on the screen.</p><p id="p-0102" num="0101">In addition to the reaction to content being shared during the VoIP call, it is possible to designate and transfer a specific participant on the video call screen <b>510</b>. When the user of the electronic device <b>110</b> selects a specific participant and inputs a reaction on the video call screen <b>510</b>, the processor <b>212</b> may display a reaction image on a corresponding participant video screen in the video call screen <b>510</b>.</p><p id="p-0103" num="0102">During the VoIP call, the reaction may be unilaterally received and displayed, and may also be bidirectionally exchanged and displayed. For example, a reaction in which, if a user <b>1</b> participating in the VoIP call draws and delivers a part of a heart, a user <b>2</b> draws and completes the rest may be applied.</p><p id="p-0104" num="0103">Also, the processor <b>212</b> may send information about media content being shared during the VoIP call, and information about a reaction received during the VoIP call, to a chatroom in which the corresponding VoIP call is ongoing and, in this manner, may manage the information.</p><p id="p-0105" num="0104">Referring to <figref idref="DRAWINGS">FIG. <b>12</b></figref>, when users participating in the VoIP call similar to the scenario of <figref idref="DRAWINGS">FIG. <b>10</b></figref> input reactions for a video being shared during the VoIP call, the processor <b>212</b> may receive a thumbnail of the corresponding video, a reaction object, a time at which the reaction is input, and/or a user nickname, and may record and display the same as a message type <b>1201</b> included in a chatroom <b>1200</b>. According to at least one example embodiment, the processor <b>212</b> may manage the information about the media content being shared during the VoIP call, and the information about the reaction received during the VoIP call, by transforming the information to, and/or recording the information as, a message (e.g., in a message format) consistent with the message type <b>1201</b> used in the chatroom <b>1200</b>.</p><p id="p-0106" num="0105">Also, similar to the scenario of <figref idref="DRAWINGS">FIG. <b>11</b></figref>, when users participating in the VoIP call input reactions for a screen being shared during the VoIP call, the processor <b>212</b> may receive a capture image of the sharing screen, a reaction object, a time at which the reaction is input, and/or a user nickname, and may record and display the same as a message type <b>1202</b> included in the chatroom <b>1200</b>. Here, if a user participating in the VoIP call inputs a reaction for another user during the VoIP call, the processor <b>212</b> may display an image of the user that is a target of the reaction and a reaction object of the user having input the reaction.</p><p id="p-0107" num="0106">Therefore, the processor <b>212</b> may build a history related to the VoIP call by managing information about media content and reactions exchanged during the VoIP call through the chatroom <b>1200</b>. That is, although the VoIP call is terminated, data about the media content and the reactions exchanged during the VoIP call may be preserved in the chatroom <b>1200</b>.</p><p id="p-0108" num="0107">As described above, according to at least one example embodiment, a reaction exchanged between call participants during a VoIP call may be displayed in real time.</p><p id="p-0109" num="0108">According to at least one example embodiment, operations described herein as being performed by the electronic device <b>110</b>, the electronic device <b>120</b>, the electronic device <b>130</b>, the electronic device <b>140</b>, the server <b>150</b>, the server <b>160</b>, the processor <b>212</b>, the processor <b>222</b>, the call provider <b>310</b>, the interface provider <b>320</b>, the share requester <b>330</b>, the content display <b>340</b> and/or the reaction display <b>350</b> may be performed by processing circuitry. The term &#x2018;processing circuitry,&#x2019; as used in the present disclosure, may refer to, for example, hardware including logic circuits; a hardware/software combination such as a processor executing software; or a combination thereof. For example, the processing circuitry more specifically may include, but is not limited to, a central processing unit (CPU), an arithmetic logic unit (ALU), a digital signal processor, a microcomputer, a field programmable gate array (FPGA), a System-on-Chip (SoC), a programmable logic unit, a microprocessor, application-specific integrated circuit (ASIC), etc.</p><p id="p-0110" num="0109">The apparatuses described above may be implemented using hardware components, software components, and/or a combination thereof. For example, the apparatuses and the components described herein may be implemented using one or more general-purpose or special purpose computers, such as, for example, a processor, a controller, an arithmetic logic unit (ALU), a digital signal processor, a microcomputer, a field programmable gate array (FPGA), a programmable logic unit (PLU), a microprocessor, or any other device capable of responding to and executing instructions in a defined manner. The processing device may run an operating system (OS) and one or more software applications that run on the OS. The processing device also may access, store, manipulate, process, and create data in response to execution of the software. For simplicity, the description of a processing device is used as singular; however, one skilled in the art will appreciate that a processing device may include multiple processing elements and/or multiple types of processing elements. For example, a processing device may include multiple processors or a processor and a controller. In addition, different processing configurations are possible, such as parallel processors.</p><p id="p-0111" num="0110">The software may include a computer program, a piece of code, an instruction, or some combination thereof, for independently or collectively instructing or configuring the processing device to operate as desired. Software and/or data may be embodied permanently or temporarily in any type of machine, component, physical equipment, virtual equipment, computer storage medium or device, or in a propagated signal wave capable of providing instructions or data to or being interpreted by the processing device. The software also may be distributed over network coupled computer systems so that the software is stored and executed in a distributed fashion. The software and data may be stored by one or more computer readable storage mediums.</p><p id="p-0112" num="0111">The above-described methods according to at least one example embodiment may be configured in a form of program instructions performed through various computer devices and recorded in non-transitory computer-readable media. The media may also include, alone or in combination with the program instructions, data files, data structures, and the like. The media may continuously store computer-executable programs or may temporarily store the same for execution or download. Also, the media may be various types of recording devices or storage devices in a form in which one or a plurality of hardware components are combined. Without being limited to media directly connected to a computer system, the media may be distributed over the network. Examples of the media include magnetic media such as hard disks, floppy disks, and magnetic tapes; optical media such as CD-ROM and DVDs; magneto-optical media such as floptical disks; and hardware devices that are specially configured to store and perform program instructions, such as ROM, RAM, flash memory, and the like. Examples of other media may include recording media and storage media managed by an app store that distributes applications or a site, a server, and the like that supplies and distributes other various types of software.</p><p id="p-0113" num="0112">While this disclosure includes at least one example embodiment, it will be apparent to one of ordinary skill in the art that various alterations and modifications in form and details may be made without departing from the spirit and scope of the claims and their equivalents. For example, suitable results may be achieved if the described techniques are performed in a different order, and/or if components in a described system, architecture, device, or circuit are combined in a different manner, and/or replaced or supplemented by other components or their equivalents.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A reaction display method performed by a computer apparatus including processing circuitry, the reaction display method comprising:<claim-text>displaying, by the processing circuitry, a content sharing screen with a voice over Internet protocol (VoIP) call screen during a VoIP call, the content sharing screen including shared media content, and a first user of the computer apparatus participating in the VoIP call;</claim-text><claim-text>receiving, by the processing circuitry, a reaction from the first user during the VoIP call;</claim-text><claim-text>sending reaction information to at least one other user participating in the VoIP call, the reaction information corresponding to the reaction;</claim-text><claim-text>displaying an indication of the reaction on the VoIP call screen or the content sharing screen; and</claim-text><claim-text>sending, by the processing circuitry, a first message to a chatroom related to the VoIP call, the chatroom being provided on a messenger service, the first message including an image of a second user and the reaction information, and the at least one other user including the second user.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The reaction display method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the receiving comprises recognizing coordinates on the VoIP call screen or the content sharing screen at which the reaction is input as a position; and</claim-text><claim-text>the sending the reaction information includes sending the position with the reaction information.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The reaction display method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the receiving comprises recognizing a playback position of content being played back on the content sharing screen at a point in time at which the reaction is input as a position; and</claim-text><claim-text>the sending the reaction information includes sending the position with the reaction information.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The reaction display method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>specifying, by the processing circuitry, a reaction target among a participant video in the VoIP call screen and the content sharing screen based on a position at which the reaction is input.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The reaction display method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the specifying comprises specifying a screen corresponding to coordinates of the position among the VoIP call screen and the content sharing screen as the reaction target.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The reaction display method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the specifying comprises specifying the content sharing screen as the reaction target in response to a playback position of content being played back on the content sharing screen being received as the position.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The reaction display method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the sending the reaction information comprises:<claim-text>specifying a particular user corresponding to the reaction target among a plurality of other users participating in the VoIP call; and</claim-text><claim-text>sending the reaction information and the position to the particular user.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The reaction display method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sending the reaction information comprises:<claim-text>generating metadata of a VoIP call packet including the reaction information; and</claim-text><claim-text>sending the metadata to the at least one other user,</claim-text><claim-text>wherein the sending the metadata causes the indication of the reaction to be displayed on a screen of a computer apparatus of the at least one other user based on the metadata.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The reaction display method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the displaying comprises displaying an object matched to the reaction at a location on one of the VoIP call screen or the content sharing screen based on a position at which the reaction is input.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The reaction display method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>managing, by the processing circuitry, the reaction information as the first message received in the chatroom,</claim-text><claim-text>wherein the first message includes a captured image of the shared media content.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The reaction display method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the displaying comprises displaying an object matched to the reaction at a first location on the content sharing screen and a second location on the VoIP call screen, the first location being based on a position at which the reaction is input, and the second location corresponding to the first user.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A non-transitory computer-readable record medium storing instructions that, when executed by at least one processor, cause the at least one processor to implement the reaction display method of <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A computer apparatus comprising:<claim-text>processing circuitry is configured to,</claim-text><claim-text>display a content sharing screen with a voice over Internet protocol (VoIP) call screen during a VoIP call, the content sharing screen including shared media content, and a first user of the computer apparatus participating in the VoIP call,</claim-text><claim-text>receive a reaction from the first user during the VoIP call,</claim-text><claim-text>send reaction information to at least one other user participating in the VoIP call, the reaction information corresponding to the reaction, display an indication of the reaction on the VoIP call screen or the content sharing screen, and</claim-text><claim-text>send a first message to a chatroom related to the VoIP call, the chatroom being provided on a messenger service, the first message including an image of a second user and the reaction information, and the at least one other user including the second user.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The computer apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the processing circuitry is configured to:<claim-text>recognize coordinates on the VoIP call screen or the content sharing screen at which the reaction is input as a position; and</claim-text><claim-text>send the position with the reaction information to the at least one other user.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The computer apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the processing circuitry is configured to:<claim-text>recognize a playback position of content being played back on the content sharing screen at a point in time at which the reaction is input as a position; and</claim-text><claim-text>send the position with the reaction information to the at least one other user.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The computer apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the processing circuitry is configured to specify a reaction target among a participant video in the VoIP call screen and the content sharing screen based on a position at which the reaction is input.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The computer apparatus of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the processing circuitry is configured to:<claim-text>specify a particular user corresponding to the reaction target among a plurality of other users participating in the VoIP call; and</claim-text><claim-text>send the reaction information and the position to the particular user.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The computer apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the processing circuitry is configured to:<claim-text>generate metadata of a VoIP call packet including the reaction information; and</claim-text><claim-text>send the metadata to the at least one other user,</claim-text><claim-text>wherein the processing circuitry is configured to cause the indication of the reaction to be displayed on a screen of a computer apparatus of the at least one other user based on the metadata by sending the metadata to the at least one other user.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The computer apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the processing circuitry is configured to display an object matched to the reaction at a location on one of the VoIP call screen or the content sharing screen based on a position at which the reaction is input.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The computer apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the processing circuitry is configured to:<claim-text>manage the reaction information as the first message received in the chatroom,</claim-text><claim-text>wherein the first message includes a captured image of the shared media content.</claim-text></claim-text></claim></claims></us-patent-application>
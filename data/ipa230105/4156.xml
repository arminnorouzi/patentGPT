<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004157A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004157</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17902717</doc-number><date>20220902</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>W</subclass><main-group>50</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>0061</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>0088</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>50</main-group><subgroup>082</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2540</main-group><subgroup>22</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>2201</main-group><subgroup>0213</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>T</subclass><main-group>2220</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">MIXED-MODE DRIVING OF A VEHICLE HAVING AUTONOMOUS DRIVING CAPABILITIES</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15688540</doc-number><date>20170828</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11460842</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17902717</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Motional AD LLC</orgname><address><city>Boston</city><state>MA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Frazzoli</last-name><first-name>Emilio</first-name><address><city>Newton</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Ravichandran</last-name><first-name>Harshavardhan</first-name><address><city>Singapore</city><country>SG</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Wolff</last-name><first-name>Eric</first-name><address><city>Cambridge</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Chang</last-name><first-name>Hsun-Hsien</first-name><address><city>Brookline</city><state>MA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Among other things, a vehicle having autonomous driving capabilities is operated in a mixed driving mode.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="182.29mm" wi="158.75mm" file="US20230004157A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="215.73mm" wi="158.75mm" file="US20230004157A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="216.32mm" wi="163.49mm" file="US20230004157A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="206.08mm" wi="152.40mm" file="US20230004157A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="206.84mm" wi="171.37mm" file="US20230004157A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="211.16mm" wi="159.09mm" file="US20230004157A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="206.50mm" wi="162.05mm" file="US20230004157A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="241.64mm" wi="174.92mm" file="US20230004157A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="241.64mm" wi="179.24mm" file="US20230004157A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="148.51mm" wi="109.90mm" file="US20230004157A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This application is a continuation of and claims priority to U.S. patent application Ser. No. 15/688,540, filed Aug. 28, 2017, the entire contents of which are incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">This description relates to mixed-mode driving of a vehicle having autonomous driving capabilities.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">In at least some examples, the technologies described in this document include a mixed-driving system that utilizes a mixture of autonomous driving capabilities and manual driving capabilities of vehicles to provide efficient uses of the vehicles.</p><p id="p-0005" num="0004">In general, in one aspect, a method comprises: (1) automatically requiring a current driving mode of a vehicle to be one of (a) an autonomous driving mode, (b) a manual driving mode, or (c) another predefined driving mode; and (2) in response to updated information associated with the vehicle, the environment, or one or more occupants or parcels of the vehicle, automatically causing a transition from the current driving mode of the vehicle to a next driving mode that comprises one of the modes (a), (b), or (c).</p><p id="p-0006" num="0005">In some implementations, the updated information may comprise indicative of a condition of the vehicle or of one or more of the occupants or parcels on board the vehicle. The updated information may comprise a preference of one or more of the occupants for operation of the vehicle in one of the modes (a), (b), or (c). The preference may comprise a preference for mode (b). The updated information may comprise a physical condition of one or more of the occupants. The physical condition may comprise a condition requiring emergency medical care.</p><p id="p-0007" num="0006">In some implementations, the updated information may be associated with an identity of one or more of the occupants, with a license to manually drive the vehicle, with an impaired ability to manually drive, with a degree of danger associated with one or more parcels on board the vehicle, with a degree of danger associated with a driving environment of the vehicle, with the presence on board the vehicle of an occupant who has a preference for one of the driving modes, with a presence of an occupant in a driver's seat of the vehicle, or with combinations of them.</p><p id="p-0008" num="0007">In some implementations, the updated information may be received from sensors configured to sense a condition on board the vehicle, or from a data source not on board the vehicle, or both. The updated information may comprise a booking by an occupant for the vehicle, or profile information for an occupant for the vehicle, or a command from a remote operator, or combinations of them.</p><p id="p-0009" num="0008">In some implementations, the updated information may comprise a driving environment of the vehicle. In some implementations, the updated information may comprise one or more autonomous driving capabilities being disabled or enabled.</p><p id="p-0010" num="0009">In some implementations, the current driving mode comprises a manual driving mode and the next driving mode comprises an autonomous driving mode; or, the current driving mode comprises an autonomous driving mode and the next driving mode comprises a manual driving mode; or, the current driving mode comprises a manual driving mode and the next driving mode comprises a paused driving mode; or, the current driving mode comprises an autonomous driving mode and the next driving mode comprises a paused driving mode; or, the current driving mode comprises an autonomous driving mode and the next driving mode comprises a disabled driving mode.</p><p id="p-0011" num="0010">In some implementations, causing the transition may comprise smoothing a speed of the vehicle across the current driving mode and the next driving mode, evaluating a trajectory towards a goal position under the next driving mode, evaluating authentication of the one or more occupants under the next driving mode, recommending the next driving mode, inferring one or more intermediate driving modes between the current driving mode and the next driving mode, using a probabilistic model to optimally determine the next driving mode, or combinations of them.</p><p id="p-0012" num="0011">In some implementations, causing the transition may be rejected when the next driving mode is infeasible or unsafe.</p><p id="p-0013" num="0012">In general, in one aspect, a method comprises: (1) at a central server determining a next driving mode from a current driving mode for each vehicle in a fleet of vehicles, at least one vehicle in the fleet having both autonomous driving capabilities and manual driving capabilities, and the next driving mode comprising at least one of an autonomous driving mode, a manual driving mode, and a driving mode that uses a combination of autonomous driving capabilities and manual driving capabilities; and (2) sending signals wirelessly to each of the vehicles of the fleet identifying the next driving mode for that vehicle.</p><p id="p-0014" num="0013">In some implementations, the method may comprise determining a sequence of the next driving modes for each of the vehicles and sending signals wirelessly to each of the vehicles identifying each of the next driving modes in the sequence of driving modes.</p><p id="p-0015" num="0014">In some implementations, the next driving mode of each vehicle may be determined based on data representing one or a combination of two or more of the following factors: (a) a characteristic of one or more occupants for the vehicle, (b) a characteristic of one or more parcels on board the vehicle, (c) a condition of a driving environment of the vehicle, and (d) a condition of the vehicle.</p><p id="p-0016" num="0015">In some implementations, the characteristic of one or more occupants of the vehicle may comprise at least one of: a preference of the occupant for a particular driving mode, a health-related condition of the occupant, or impairment of the occupant's ability to manually drive the vehicle.</p><p id="p-0017" num="0016">In some implementations, the characteristic of one or more parcels on board the vehicle may comprise a destructive quality of the parcel.</p><p id="p-0018" num="0017">In some implementations, the current driving mode comprises an autonomous driving mode and the next driving mode comprises a manual driving mode; the current driving mode comprises a manual driving mode and the next driving mode comprises an autonomous driving mode. In some implementations, at least one of the next driving modes comprises an emergency driving mode, a paused mode, or a disabled mode.</p><p id="p-0019" num="0018">In some implementations, the method may comprise sending signals wirelessly to one or more of the vehicles of the fleet to require that the vehicles operate only according to the next driving mode.</p><p id="p-0020" num="0019">In some implementations, determining the next driving mode may comprise validating a license to manually drive a vehicle of the fleet, evaluating a driving environment of a vehicle of the fleet, evaluating if one or more autonomous driving capabilities is disabled or enabled in a vehicle of the fleet, evaluating a trajectory towards a goal position under the next driving mode, evaluating authentication of the one or more occupants under the next driving mode, making a recommendation for the next driving mode, inferring one or more intermediate driving modes between the current driving mode and the next driving mode, or using a probabilistic model to optimally determine the next driving mode, or combinations of them.</p><p id="p-0021" num="0020">In some implementations, the determined next driving mode may be rejected when the next driving mode is infeasible or unsafe.</p><p id="p-0022" num="0021">In some implementations, the method may include receiving a booking from a user, receiving instructions of determining the next driving mode from a fleet operator, or both.</p><p id="p-0023" num="0022">In general, in one aspect, a method comprises: (1) causing a vehicle that has both autonomous driving capabilities and manual driving capabilities to drive autonomously except while an identified occupant who prefers manual driving is in the vehicle, and (2) preventing the vehicle from driving autonomously and enabling the vehicle to be only in a manual driving mode while the identified occupant is in the vehicle.</p><p id="p-0024" num="0023">In some implementations, the method may comprise identifying the occupant based on at least one of the following: stored profile information for the occupant, authentication of the occupant, or booking information.</p><p id="p-0025" num="0024">In some implementations, the method may comprise causing the vehicle to switch to another driving mode if the occupant who is manually driving the vehicle is unable to manually drive the vehicle safely. The other driving mode may comprise at least one of an emergency driving mode, a disabled driving mode, or a paused driving mode.</p><p id="p-0026" num="0025">In some implementations, the method may comprise causing the vehicle to switch to another driving mode comprises evaluating a physical condition of the identified occupant. Causing the vehicle to switch to another driving mode may comprise detecting a degraded driving performance of the identified occupant, evaluating a driving environment of the vehicle, evaluating if one or more autonomous driving capabilities is disabled or enabled, smoothing a speed of the vehicle switching to the other driving mode, evaluating a trajectory towards a goal position under the other driving mode, recommending the other driving mode, inferring one or more intermediate driving modes before reaching the other driving mode, or using a probabilistic model to optimally determine the other driving mode, or combinations of them.</p><p id="p-0027" num="0026">In some implementations, causing the vehicle to switch to another driving mode is rejected when the other driving mode is infeasible or unsafe.</p><p id="p-0028" num="0027">In general, in one aspect, a method comprises: (1) commanding a vehicle to drive autonomously to a location without any occupant in the vehicle; (2) after the vehicle has reached the location, authorizing an occupant to enter the vehicle, determining that the occupant has entered the vehicle and has begun to drive the vehicle; and (3) while the occupant is driving the vehicle, automatically preventing the vehicle from driving autonomously.</p><p id="p-0029" num="0028">In some implementations, authorizing an occupant to enter the vehicle may comprise validating an identify of the occupant and a license of the occupant to manually operate the vehicle.</p><p id="p-0030" num="0029">In some implementations, determining that the occupant has entered the vehicle may comprise detecting a presence of the occupant in a driver's seat of the vehicle.</p><p id="p-0031" num="0030">In some implementations, the method may comprise disabling one or more autonomous driving capabilities while the occupant is driving the vehicle, maintaining one or more autonomous driving capabilities to be enabled while the occupant is driving the vehicle, or monitoring a condition of the vehicle or the occupant or a driving environment, or combinations of them.</p><p id="p-0032" num="0031">In some implementations, the method may comprise switching the vehicle to an autonomous driving mode when the occupant requiring emergency medical care is detected, switching the vehicle to an autonomous driving mode when a degree of danger associated with a driving environment of the vehicle is detected, switching the vehicle to an autonomous driving mode when a request from the occupant is issued, switching the vehicle to an autonomous driving mode when the autonomous driving mode is algorithmically determined to be safer than the occupant manually driving the vehicle, commanding the vehicle in a disabled mode when the occupant reaches a goal position, or commanding the vehicle in a parked mode when the occupant reaches a goal position, or combinations of them.</p><p id="p-0033" num="0032">In some implementations, the method may comprise the autonomous vehicle subsequently detecting that the vehicle is stopped and no occupant is present in the vehicle, and the autonomous vehicle driving autonomously to another location.</p><p id="p-0034" num="0033">In some implementations, the method may comprise allowing the occupant to request another driving mode. Requesting the other driving mode may be rejected when the other driving mode is infeasible or unsafe.</p><p id="p-0035" num="0034">In general, in one aspect, a vehicle comprising: (1) driving components including an acceleration component, a steering component, and a deceleration component; (2) autonomous driving capabilities to issue signals to the driving components to drive the vehicle in an autonomous driving mode; (3) manual driving capabilities to enable the driving components to be used to drive the vehicle in a manual driving mode; and (4) a supervisory component to issue signals to cause the vehicle to be driven only in the autonomous driving mode, only in the manual driving mode, or only in a predefined other driving mode.</p><p id="p-0036" num="0035">In some implementations, the supervisory component may comprise elements on board the vehicle. The elements of the supervisory component that are on board the vehicle may comprise only a portion of the elements of the supervisory component.</p><p id="p-0037" num="0036">In some implementations, the vehicle may comprise wireless communication components configured to carry data and commands to and from a central server.</p><p id="p-0038" num="0037">In some implementations, the supervisory component may be configured to issue the signals based on information from sensors that detect conditions of the vehicle, based on information about one or more occupants of the vehicle, based on information about an environment of the vehicle, based on a preference of one or more of occupants, based on an identity of one or more of occupants, based on a license to manually drive the vehicle, or based on a physical condition of one or more of occupants, based on a degree of danger associated with a driving environment of the vehicle, based on presence on board the vehicle of an occupant who has a preference for one of the driving modes, based on sensors configured to sense a condition on board the vehicle, based on a presence of an occupant in a driver's seat of the vehicle, based on a degree of danger associated with one or more parcels on board the vehicle, based on a data source not on board the vehicle, based on a booking, based on a command from a remote operator, based on profile information of an occupant of the vehicle, based on one or more autonomous driving capabilities being disabled or enabled, based on a driving environment of the vehicle, or based on combinations of them. In some cases, the physical condition may comprise a condition requiring emergency medical care.</p><p id="p-0039" num="0038">In some implementations, the supervisory component may be configured to smooth a speed of the vehicle transitioning from a current driving mode and a next driving mode, to evaluate a trajectory towards a goal position under a next driving mode, to evaluate authentication of one or more occupants under a next driving mode, to recommend a next driving mode, to infer one or more intermediate driving modes between a current driving mode and a next driving mode, to use a probabilistic model to optimally determine a next driving mode, or to reject switching to a next driving mode when the next driving mode is infeasible or unsafe, or to perform combinations of them.</p><p id="p-0040" num="0039">In general, in one aspect, an apparatus (e.g., an interface) comprises: (1) a storage for instructions, and (2) a processor to operate in accordance with the instructions to analyze information about a vehicle or an occupant or a driving environment and cause the vehicle to transition from a current driving mode comprising one of (a) an autonomous driving mode, (b) a manual driving mode, or (c) another predefined driving mode, to a next driving mode comprising one of (a), (b), or (c). In some implementations, the apparatus may comprise a display.</p><p id="p-0041" num="0040">In some implementations, the display may be configured to present a current driving mode of the vehicle, to present a list of possible next driving modes, to present a current condition of the vehicle or an occupant or a driving environment, to allow the user to indicate a condition of the vehicle or an occupant or a driving environment, to allow the user to indicate a medical emergency of an occupant of the vehicle, to allow the user to indicate an identity of an occupant of the vehicle, to allow the user to indicate a special need of an occupant of the vehicle, to allow the user to indicate a degree of danger associated with a driving environment of the vehicle, to present information of one or more autonomous driving capabilities, or to allow the user to enable or disable one or more autonomous driving capabilities, or to perform combinations of them.</p><p id="p-0042" num="0041">In some implementations, a current driving mode comprises a manual driving mode and the next driving mode comprises an autonomous driving mode; a current driving mode comprises an autonomous driving mode and the next driving mode comprises a manual driving mode; a current driving mode comprises a manual driving mode and the next driving mode comprises a paused driving mode; a current driving mode comprises an autonomous driving mode and the next driving mode comprises a paused driving mode; or a current driving mode comprises an autonomous driving mode and the next driving mode comprises a disabled driving mode; or combinations of them.</p><p id="p-0043" num="0042">In some implementations, the display may allow to choose a sequence of driving modes.</p><p id="p-0044" num="0043">In general, in one aspect, an apparatus (e.g., a mixed-mode controller of a vehicle) comprises a processor analyzing information about a vehicle or an occupant or a driving environment and causing the vehicle to transition from a current driving mode in one of (a) an autonomous driving mode, (b) a manual driving mode, or (c) another predefined driving mode, to a next driving mode in (a), (b), or (c).</p><p id="p-0045" num="0044">Implementations of the apparatus may include analyzing the information that may comprise analyzing a preference of one or more of the occupants for operation of the vehicle in one of the modes (a), (b), or (c).</p><p id="p-0046" num="0045">In some implementations of the apparatus, analyzing the information may comprise analyzing a physical condition of one or more of the occupants; The physical condition may comprise a condition requiring emergency medical care.</p><p id="p-0047" num="0046">In some implementations of the apparatus, analyzing the information may comprise analyzing the information comprises analyzing an identity of one or more of the occupants, analyzing a license to manually drive the vehicle, analyzing an impaired ability to manually drive, analyzing a degree of danger associated with one or more parcels on board the vehicle, analyzing a degree of danger associated with a driving environment of the vehicle, analyzing the presence on board the vehicle of an occupant who has a preference for one of the driving modes, analyzing if one or more autonomous driving capabilities is disabled or enabled, or analyzing a presence of an occupant in a driver's seat of the vehicle, or combinations of them.</p><p id="p-0048" num="0047">In some implementations of the apparatus, the processor may operate according to the instructions stored in the storage to receive information from sensors configured to sense a condition on board the vehicle, or from a data source not on board the vehicle, or both. The processor may receive information about a booking to use the vehicle, or about profile information for an occupant for the vehicle, or both. In some implementations, the processor may receive a command from a remote operator to cause the vehicle to transition.</p><p id="p-0049" num="0048">In some implementations of the apparatus, the current driving mode comprises a manual driving mode and the next driving mode comprises an autonomous driving mode; or, the current driving mode comprises an autonomous driving mode and the next driving mode comprises a manual driving mode; or, the current driving mode comprises a manual driving mode and the next driving mode comprises a paused driving mode; or, the current driving mode comprises an autonomous driving mode and the next driving mode comprises a paused driving mode; or, the current driving mode comprises an autonomous driving mode and the next driving mode comprises a disabled driving mode; or, combinations of them.</p><p id="p-0050" num="0049">In some implementations of the apparatus, causing the vehicle to transition may comprise smoothing a speed of the vehicle across the current driving mode and the next driving mode, evaluating a trajectory towards a goal position under the next driving mode, evaluating authentication of the one or more occupants under the next driving mode, recommending the next driving mode, inferring one or more intermediate driving modes between the current driving mode and the next driving mode, using a probabilistic model to optimally determine the next driving mode, or rejecting a next driving mode that is infeasible or unsafe, or combinations of them.</p><p id="p-0051" num="0050">In general, in one aspect, a computing device (e.g., a computer, a generic server, a specific server for mixed-mode driving) comprises: (1) a storage for instructions; (2) a network interface (e.g., wireless, or wired, or both) in communication with a vehicle; and (3) a processor to operates according to the instructions stored in the storage to analyze information about the vehicle or a user of the vehicle or a driving environment of the vehicle and transmit a command to the vehicle to transition from a current driving mode comprising one of (a) an autonomous driving mode, (b) a manual driving mode, or (c) another predefined driving mode, to a next driving mode comprising one of (a), (b), or (c).</p><p id="p-0052" num="0051">Implementations of the computing device may include analyzing a preference of one or more of the occupants for operation of the vehicle in one of the modes (a), (b), or (c).</p><p id="p-0053" num="0052">Implementations of the computing device may include analyzing a physical condition of one or more of the occupants. The physical condition may comprise a condition requiring emergency medical care.</p><p id="p-0054" num="0053">In some implementations of the computing device, analyzing the information may comprise analyzing an identity of one or more of the occupants, analyzing a license to manually drive the vehicle, analyzing an impaired ability to manually drive, analyzing a degree of danger associated with one or more parcels on board the vehicle, analyzing a degree of danger associated with a driving environment of the vehicle, analyzing the presence on board the vehicle of an occupant who has a preference for one of the driving modes, or analyzing a presence of an occupant in a driver's seat of the vehicle, or combinations of them.</p><p id="p-0055" num="0054">In some implementations of the computing device, the processor may operate in accordance with the instructions to receive information from sensors configured to sense a condition on board the vehicle, or from a data source not on board the vehicle, or both. The processor may receive information about a booking to use the vehicle, about profile information for an occupant for the vehicle, or both. The processor may receive a command from a remote operator to cause the vehicle to transition.</p><p id="p-0056" num="0055">In some implementations of the computing device, analyzing the information may comprise analyzing one or more autonomous driving capabilities being disabled or enabled, smoothing a speed of the vehicle across the current driving mode and the next driving mode, evaluating a trajectory towards a goal position under the next driving mode, evaluating authentication of the one or more occupants under the next driving mode, recommending the next driving mode, inferring one or more intermediate driving modes between the current driving mode and the next driving mode, or using a probabilistic model to optimally determine the next driving mode, or combinations of them.</p><p id="p-0057" num="0056">In some implementations of the computing device, the current driving mode comprises a manual driving mode and the next driving mode comprises an autonomous driving mode; or, the current driving mode comprises an autonomous driving mode and the next driving mode comprises a manual driving mode; or, the current driving mode comprises a manual driving mode and the next driving mode comprises a paused driving mode; or, the current driving mode comprises an autonomous driving mode and the next driving mode comprises a paused driving mode; or, the current driving mode comprises an autonomous driving mode and the next driving mode comprises a disabled driving mode, or combinations of them.</p><p id="p-0058" num="0057">Implementations of the computing device may be realized on board the vehicle, or remote to the vehicle, or both.</p><p id="p-0059" num="0058">These and other aspects, features, and implementations can be expressed as methods, apparatus, systems, computing devices, components, program products, methods of doing business, means or steps for performing a function, and in other ways.</p><p id="p-0060" num="0059">These and other aspects, features, and implementations will become apparent from the following descriptions, including the claims.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of an AV system.</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref> are block diagrams of mixed-mode driving systems.</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram of mixed-mode driving.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a processing flow for mixed-mode driving.</p><p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram of a mixed-mode driving system.</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIGS. <b>7</b> and <b>8</b></figref> are interfaces for interacting with a mixed-mode driving system.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows a risky or dangerous object in a cargo area of a vehicle with a sensor for determining if the object is risky or dangerous.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DESCRIPTION</heading><p id="p-0068" num="0067">The term &#x201c;autonomous driving capability&#x201d; is used broadly to include, for example, any function, feature, or facility that can participate in the driving of an AV other than by a person manipulating a steering wheel, accelerator, brake, or other physical controller of the AV. This document sometimes uses the abbreviation &#x201c;AV&#x201d; to refer to a vehicle having one or more autonomous driving capabilities.</p><p id="p-0069" num="0068">The term &#x201c;manual driving capabilities&#x201d; is used broadly to include, for example, any function, feature, or facility of a vehicle that is operated by a person, such as by manipulating a steering wheel, accelerator, brake, or other physical controller of the vehicle.</p><p id="p-0070" num="0069">The term &#x201c;driving mode&#x201d; is used broadly to include, for example, autonomous or manual driving modes or non-driving modes such as parked or disabled, and any other mode in which the AV system may be driven or prevented from being driven, and also any combination of manual driving capabilities or autonomous driving capabilities that may be used during any of the driving modes or non-driving modes.</p><p id="p-0071" num="0070">The terms &#x201c;fully autonomous mode driving&#x201d; and &#x201c;fully autonomous driving mode&#x201d; are used broadly to include, for example, any driving of a vehicle using only autonomous driving capabilities.</p><p id="p-0072" num="0071">The term &#x201c;partially autonomous mode driving&#x201d; and &#x201c;partially autonomous driving mode&#x201d; are used broadly to include, for example, any driving of a vehicle using both autonomous driving capabilities and manual driving capabilities.</p><p id="p-0073" num="0072">The term &#x201c;fully manual mode driving&#x201d; and &#x201c;fully manual driving mode&#x201d; are used broadly to include, for example, any driving of a vehicle using only manual driving capabilities.</p><p id="p-0074" num="0073">The term &#x201c;partially manual mode driving&#x201d; and &#x201c;partially manual driving mode&#x201d; are used broadly to include, for example, any driving of a vehicle using both autonomous driving capabilities and manual driving capabilities.</p><p id="p-0075" num="0074">The term &#x201c;mixed-mode driving&#x201d; is used broadly to include, for example, any driving of a vehicle that, at least at times, includes the use of one or more autonomous vehicle capabilities, and, at least at times, includes the use of manual driving capabilities. Mixed mode driving can include, at least at times, each of fully autonomous mode driving, partially autonomous mode driving, and fully manual mode driving.</p><p id="p-0076" num="0075">The term &#x201c;trajectory&#x201d; is used broadly to include, for example, any path or route from one place to another; for instance, a path from a pickup location to a drop off location.</p><p id="p-0077" num="0076">The term &#x201c;goal&#x201d; or &#x201c;goal position&#x201d; is used broadly to include, for example, any place to be reached by an AV, including, for example, an interim drop-off location, a final drop-off location, or a destination, among others.</p><p id="p-0078" num="0077">The term &#x201c;configure&#x201d; is used broadly to include, for example, control, select, recommend, or require, among other things.</p><heading id="h-0006" level="2">AV System</heading><p id="p-0079" num="0078">This document describes technologies applicable to any vehicles that have one or more autonomous driving capabilities including fully autonomous vehicles, highly autonomous vehicles, and conditionally autonomous vehicles, such as so-called Level 5, Level 4 and Level 3 vehicles, respectively (see SAE International's standard J3016: Taxonomy and Definitions for Terms Related to On-Road Motor Vehicle Automated Driving Systems, which is incorporated by reference in its entirety, for more details on the classification of levels of autonomy in vehicles). Autonomous driving capabilities may attempt to control the steering or speed of the vehicles. The technologies described in this document also can be applied to partially autonomous vehicles and driver assisted vehicles, such as so-called Level 2 and Level 1 vehicles (see SAE International's standard J3016: Taxonomy and Definitions for Terms Related to On-Road Motor Vehicle Automated Driving Systems). One or more of the Level 1, 2, 3, 4 and 5 vehicle systems may automate certain vehicle operations (e.g., steering, braking, and using maps) under certain driving conditions based on processing of sensor inputs. The technologies described in this document can benefit vehicles in any levels, ranging from fully autonomous vehicles to human-operated vehicles.</p><p id="p-0080" num="0079">As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a typical activity of an AV <b>100</b> is to safely and reliably drive autonomously or partially manually or both along a trajectory <b>198</b> through an environment <b>190</b> toward a goal location <b>199</b> while avoiding objects (e.g., barriers <b>191</b>, vehicles <b>193</b>, pedestrians <b>192</b>, cyclists, and other obstacles) and obeying rules of the road (e.g., rules of operation or driving preferences). The features, functions, and facilities of an AV <b>100</b> or an AV system <b>120</b> that enable the AV <b>100</b> to perform the autonomous driving often are referred to as autonomous driving capabilities.</p><p id="p-0081" num="0080">The driving of an AV <b>100</b> typically is supported by an array of technologies (e.g., hardware, software, and stored and real-time data) that this document together (and with the AV <b>100</b>) refers to as an AV system <b>120</b>. In some implementations, one or some or all of the technologies are on board the AV <b>100</b>. In some cases, one or some or all of the technologies are at another location such as at a server (e.g., in a cloud computing infrastructure). Components of an AV system <b>120</b> can include one or more or all of the following (among others).<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0081">1. Functional devices <b>101</b> of the AV <b>100</b> that are instrumented to receive and act on commands for driving (e.g., steering <b>102</b>, acceleration, deceleration, gear selection, and braking <b>103</b>) and for auxiliary functions (e.g., turning signal activation) from one or more computing processors <b>146</b> and <b>148</b>.</li>        <li id="ul0002-0002" num="0082">2. Data storage units <b>142</b> or memory <b>144</b> or both for storing machine instructions or various types of data or both.</li>        <li id="ul0002-0003" num="0083">3. One or more sensors <b>121</b> for measuring or inferring, or both, properties of the AV's state or condition, such as the AV's position, linear and angular velocity and acceleration, and heading (e.g., an orientation of the leading end of the AV). For example, such sensors can include, but are not limited to: GPS; inertial measurement units that measure both vehicle linear accelerations and angular rates; individual wheel speed sensors for measuring or estimating individual wheel slip ratios; individual wheel brake pressure or braking torque sensors; engine torque or individual wheel torque sensors; and steering wheel angle and angular rate sensors.</li>        <li id="ul0002-0004" num="0084">4. One or more sensors for sensing or measuring properties of the AV's environment. For example, such sensors can include, but are not limited to: monocular or stereo video cameras <b>122</b> in the visible light, infrared or thermal (or both) spectra; lidar <b>123</b>; radar; ultrasonic sensors; time-of-flight (TOF) depth sensors; speed sensors; and temperature and rain sensors.</li>        <li id="ul0002-0005" num="0085">5. One or more communications devices <b>140</b> for communicating measured or inferred or both properties of other vehicles' states and conditions, such as positions, linear and angular velocities, linear and angular accelerations, and linear and angular headings. These devices include Vehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure (V2I) communication devices and devices for wireless communications over point-to-point or ad hoc networks or both. The communications devices <b>140</b> can communicate across the electromagnetic spectrum (including radio and optical communications) or other media (e.g., air and acoustic media).</li>        <li id="ul0002-0006" num="0086">6. One or more communication interfaces <b>140</b> (e.g., wired, wireless, WiMAX, Wi-Fi, Bluetooth, satellite, cellular, optical, near field, or radio, or combinations of them) for transmitting data from a remotely located database <b>134</b> to the AV system <b>120</b>, transmitting sensor data or data related to driving performance to a remotely located database <b>134</b>, or transmitting information that relates to teleoperations, or a combination of them.</li>        <li id="ul0002-0007" num="0087">7. One or more data sources <b>142</b> for providing historical, or real-time, or predictive information, or a combination of any two or more of them about the environment <b>190</b>, including, for example, maps, driving performance, traffic congestion updates or weather conditions. Such data may be stored on a data storage unit <b>142</b> or memory <b>144</b> on the AV <b>100</b>, or may be transmitted to the AV <b>100</b> via a communications channel from a remote database <b>134</b> or a combination of them.</li>        <li id="ul0002-0008" num="0088">8. One or more data sources <b>136</b> for providing digital road map data from GIS databases, potentially including one or more of the following: high-precision maps of the roadway geometric properties; maps describing road network connectivity properties; maps describing roadway physical properties (such as traffic speed, traffic volume, the number of vehicular and cyclist traffic lanes, lane width, lane traffic directions, or lane marker types and locations, or combinations of them); and maps describing the spatial locations of road features such as crosswalks, traffic signs or other travel signals of various. Such data may be stored on a memory <b>144</b> on the AV <b>100</b>, or transmitted to the AV <b>100</b> via a communications channel from a remotely located database server <b>134</b>, or a combination of the two.</li>        <li id="ul0002-0009" num="0089">9. One or more data sources <b>134</b> or sensors <b>132</b> for providing historical information about driving properties (e.g., speed and acceleration profiles) of vehicles that have previously traveled along local road sections, for example, at similar times of day. Such data may be stored on a memory <b>144</b> on the AV <b>100</b>, or transmitted to the AV <b>100</b> via a communications channel from a remotely located database <b>134</b>, or a combination of the two.</li>        <li id="ul0002-0010" num="0090">10. One or more computing devices <b>146</b> and <b>148</b> located on the AV <b>100</b> (or remotely or both) for executing algorithms for on-line generation of control actions based on both real-time sensor data and prior information, allowing the AV system <b>120</b> to execute its autonomous driving capabilities.</li>        <li id="ul0002-0011" num="0091">11. One or more processes for processing sensor data, perceiving the environment, understanding conditions that are currently presented by and may at future times be presented by the perceived environment, performing trajectory planning, performing motion control, and making decisions based on those perceptions and understandings. A process may be implemented by integrated circuits, field-programmable gate arrays, hardware, software, or firmware, or a combination of two or more of them.</li>        <li id="ul0002-0012" num="0092">12. One or more interface devices <b>150</b> (e.g., displays, mice, track balls, keyboards, touchscreens, mobile devices, speakers, biometric readers, and gesture readers) coupled to the computing devices <b>146</b> and <b>148</b> for providing information and alerts to, and receiving input from, a user (e.g., an occupant or a remote user) of the AV <b>100</b>. The coupling may be wireless or wired. Any two or more of the interface devices may be integrated into a single device.</li>    </ul>    </li></ul></p><heading id="h-0007" level="2">Mixed-Mode Driving</heading><p id="p-0082" num="0093">AV systems that operate in a fully autonomous driving mode typically either do not require or do not permit the AV systems to be operated, for example, in a fully manual driving mode. This document describes mixed-mode driving and mixed-mode driving systems, at least some implementations of which offer an occupant of an AV an option of being driven in a fully or partially autonomous driving mode or in a fully or partially manual driving mode. In some implementations, the mixed-mode driving may at times allow the occupant to drive manually. In some instances of mixed-mode driving, the AV system may permit the occupant to engage in one or more or a combination of driving modes. In some cases, the AV system may require the occupant or the AV or both to engage only in one or more particular driving modes, while precluding one or more selected other driving modes.</p><p id="p-0083" num="0094">In some implementations, the AV system with mixed-mode driving capabilities may permit or require a transition of its driving mode from one to another. The transition may be based on automatic detection, an occupant request, or a server command, or combinations of them. The flexibility of driving mode transition of an AV system offers more options for an AV system user and provides a more efficient usage of the AV system.</p><p id="p-0084" num="0095">A mixed-mode driving system (we sometimes refer to one or more AV systems that permit or require mixed-mode driving as &#x201c;mixed-mode driving systems&#x201d;) may include one or more AVs and the AV systems of which they are part (we sometimes use the terms &#x201c;AV&#x201d; and &#x201c;AV system&#x201d; interchangeably although in some implementations, the AV is only a part of an AV system). <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example of an architecture of a mixed-mode driving system <b>230</b>. In some implementations, a mixed-mode driving system <b>230</b> may include one or more of the following elements (among others):<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0096">A mixed-mode controller <b>201</b>, which may be realized by integrated circuits, field-programmable gate arrays, hardware, software, or firmware, or a combination of two or more of them.</li>        <li id="ul0004-0002" num="0097">In some implementations, the mixed-mode controller <b>201</b> may be installed on the AV system <b>200</b>. The mixed-mode controller <b>201</b> may interact with one or more components of the AV system <b>200</b> (e.g., sensors <b>216</b> and <b>218</b>, communication devices <b>210</b>, user interface devices, memory <b>212</b>, a processor <b>214</b>, a database <b>220</b>, or a functional device, or combinations of them). The mixed-mode controller <b>201</b> may, for example, send and receive information and commands. The mixed-mode controller <b>201</b> can communicate over a communication interface <b>210</b> (that may be at least partly wireless) with a mixed-mode driving server <b>231</b>.</li>        <li id="ul0004-0003" num="0098">In some implementations, the mixed-mode controller <b>252</b> may be installed on a mobile device (e.g., a smartphone) <b>250</b> or a mixed-mode driving server <b>231</b>. The mixed-mode controller <b>252</b> may interact with one or more components of the AV system <b>200</b> (e.g., sensors <b>216</b> and <b>218</b>, communication devices <b>210</b>, user interface devices, memory <b>212</b>, a processor <b>214</b>, a database <b>220</b>, or functional devices, or combinations of them). The mixed-mode controller <b>252</b> may utilize signals collected by the sensors of the mobile device <b>250</b>, such as GPS sensors, cameras, accelerometers, gyroscopes, and barometers. The mixed-mode controller <b>252</b> can communicate with a mixed-mode driving server <b>231</b> over a communication interface of the mobile device <b>250</b>.</li>        <li id="ul0004-0004" num="0099">In some implementations, the mixed-mode controller <b>201</b> may be installed on a combination of the AV system (in particular on the AV itself), a mobile device <b>250</b>, a mixed-mode driving server <b>231</b>, or other elements of the AV system.</li>        <li id="ul0004-0005" num="0100">A mixed-mode driving server <b>231</b>, may be located in the AV of the AV system <b>200</b> or in a remote location, for example, at least 0.1, 1, 2, 3, 4, 5, 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, or 1000 meters away from the AV of the AV system <b>200</b>, or in a combination of the AV and the remote location. The mixed-mode driving server <b>231</b> communicates with the mixed-mode controllers <b>201</b> and <b>252</b>.</li>        <li id="ul0004-0006" num="0101">In some implementations, the mixed-mode driving server <b>231</b> may communicate with a mobile device <b>250</b> to receive a request to use the AV system <b>200</b>.</li>        <li id="ul0004-0007" num="0102">A user interface <b>232</b> may be presented by the mixed-mode controller <b>201</b> or by the mixed-mode driving server <b>231</b> or by both. Implementations may present on the interface <b>232</b> information of one or more of the following: configuring a driving mode, switching driving modes, a hazard request, a stop request, a teleoperation request, a road network, a condition of the AV of the AV system <b>200</b>, an environment of the AV of the AV system <b>200</b>, or sensor signals, or combinations of them, among other things. The user interface can be presented in the inside of the AV, on the outside of the AV, on the mobile device <b>250</b>, or in other locations or combinations of these.</li>    </ul>    </li></ul></p><p id="p-0085" num="0103">Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, in some implementations, a mixed-mode controller <b>311</b> may communicate with two or more mixed-mode driving servers <b>321</b>, <b>322</b> and <b>323</b>. In some cases, two or more servers (e.g., <b>321</b> and <b>322</b>) receive, aggregate, process, and deliver information for mixed-mode driving or for presentation on an interface <b>332</b>. In some implementations, a server (e.g., <b>323</b>) may receive information from two or more mixed-mode controllers <b>311</b> and <b>312</b>, which are installed, for example, on different AV systems <b>301</b> and <b>302</b>, respectively. Some implementations allow a server (e.g., <b>322</b>) to receive, aggregate, process and deliver information from and to two or more mixed-mode controllers <b>311</b> and <b>313</b>, which are installed on an AV system <b>301</b> and a standalone device (e.g., a mobile device <b>303</b>), respectively.</p><p id="p-0086" num="0104">In some implementations, a mixed-mode controller (e.g., <b>312</b>) may play a role as a server by receiving, aggregating, processing, and delivering information from or to one or more other mixed-mode controllers (e.g., <b>311</b> or <b>313</b>, or both). In some implementations, a mixed-mode controller (e.g., <b>312</b>) may play a role as a relaying device for establishing and maintaining a communication between a server <b>323</b> and another mixed-mode controller <b>311</b>.</p><p id="p-0087" num="0105">The mixed-mode driving system has advantages over other transportation systems (e.g., taxis, buses, shared vehicles or rented vehicles) such as those that require occupants or operators or drivers to drive vehicles (i.e., to use a fully manual or partially manual driving mode or fully autonomous) at all times and can be expensive or inconvenient. Implementations of the mixed-mode driving system described in this document may exploit autonomous driving capabilities to provide more efficient transportation services. In examples of the mixed-mode driving system, an AV system may be operated in different driving modes (e.g., fully autonomous driving mode, partially autonomous driving mode, fully manual driving mode, partially manual driving mode, and mixed-mode driving) and can readily switch among driving modes. Because the AV system may be operated in fully autonomous mode driving, partially autonomous mode driving, fully manual mode driving, partially manual mode driving, or mixed-mode driving, the mixed-mode driving system can maximize the efficiency of vehicle usage. For example, when the AV system needs maintenance or repair, it may drive autonomously to a service center without a driver being on board. In some implementations, the AV system may drive autonomously to pick up an occupant. In some instances, after the AV system drops off its occupant, it may drive autonomously to a parking space.</p><p id="p-0088" num="0106">In some implementations, the mixed-mode driving system can offer flexible or safer vehicle operations. For example, a driver operating a vehicle for a long time in fully manual driving mode or partially manual driving mode may become distracted or fatigued, and the mixed-mode controller may switch the vehicle to fully autonomous mode driving or partially autonomous mode driving so that the driver can take a rest or safely pay attention to the distraction.</p><p id="p-0089" num="0107">In some implementations, the mixed-mode driving system may avoid dangers. For example, when hazardous substances (e.g., flammables, weapons and bombs) are detected inside the AV system, the mixed-mode controller may switch the AV system into fully autonomous mode driving, and then into a disabled mode that prohibits further driving. In some instances, when a driver is detected in a medically emergent condition, the mixed-mode controller may switch (e.g., force) the AV system into emergency mode driving, in which the AV operates in fully autonomous mode driving to drive to an emergency room.</p><heading id="h-0008" level="2">Mixed-Mode Controller</heading><p id="p-0090" num="0108">The AV system may comprise one or more mixed-mode controllers. The mixed-mode controller may control, configure, select, recommend or require the AV system's driving mode, which can, for example, be (1) fully autonomous mode driving, or (2) fully manual mode driving by an occupant using the manual driving capabilities, or (3) a combination of partially autonomous mode driving and partially manual mode driving, among others.</p><p id="p-0091" num="0109">As part of the general control of the driving mode of the AV, the mixed-mode controller can control, configure, select, recommend or require the availability and use of one or more specific autonomous driving capabilities and one or more specific manual driving capabilities, or a combination of them.</p><p id="p-0092" num="0110"><figref idref="DRAWINGS">FIG. <b>4</b></figref> (a state transition diagram) shows implementations in which the mixed-mode controller may configure, control, select, recommend, or require one or more (or a succession of) driving modes to be used by the AV system, each of which may be either permissive or imposed. The figure illustrates the following driving modes and uses arrows to indicate permitted transitions between driving modes: permissive autonomous <b>401</b>, permissive manual <b>402</b>, imposed autonomous <b>403</b>, imposed manual <b>404</b>, imposed disabled <b>405</b>, imposed parked <b>406</b>, and parked <b>407</b>.</p><p id="p-0093" num="0111">In some implementations, a transition not represented by an arrow in <figref idref="DRAWINGS">FIG. <b>4</b></figref> is feasible. For example, any driving mode can be transitioned to any of other modes.</p><p id="p-0094" num="0112">Implementations of the permissive autonomous mode <b>401</b> may allow the AV system to operate in a fully autonomous driving mode or a partially autonomous driving mode. The permissive manual mode <b>402</b> may allow the AV system to operate in a fully manual driving mode or a partially manual driving mode. The mixed-mode controller may cause transitions <b>408</b> between the permissive autonomous mode <b>401</b> (fully autonomous or partially autonomous) and the permissive manual mode <b>402</b> (fully manual or partially manual). In some implementations, the transition <b>408</b> may be based on a request of a user (e.g., an occupant, a driver, or a remote user) of the AV system, or a request from a mixed-mode driving server, or a request from the mixed-mode controller, or a combination of them. For example, an occupant may initially ride the AV system in a fully autonomous driving mode, but due to one or more reasons (e.g., due to discomfort of the driving behavior of the fully autonomous driving mode) he may want to request the AV system to switch to a fully manual or partially manual driving mode. In some instances, an occupant may drive the AV system in a fully manual driving mode; he may request or cause a switch to a partially or fully autonomous driving mode and, within the partially or fully autonomous driving mode, the driver may request or specify one or more of the autonomous driving capabilities that he wishes to be used.</p><p id="p-0095" num="0113">In some implementations, the mixed-mode controller may configure the AV system to operate in an imposed autonomous mode <b>403</b>, in which only the autonomous driving capabilities can be used, or only one or more specified autonomous driving capabilities can be used. In some implementations, the mixed-mode controller may configure the AV system to operate in an imposed manual mode <b>404</b>, in which only the manual driving capabilities can be used, or only one or more specified manual driving capabilities. In some implementations, the mixed-mode controller may configure the AV system to operate in an imposed disabled mode <b>405</b>, in which the AV system is disabled for driving; in other words, it cannot be driven in the disabled mode. In some implementations, the mixed-mode controller may configure the AV system to operate in an imposed parked mode <b>406</b>, in which the AV system must be in a parked condition and any movement from the parked condition is prohibited.</p><p id="p-0096" num="0114">Generally, when the AV system is in an imposed driving mode or disabled mode or parked mode, the AV system will not change the AV system's driving mode in response to actions of an occupant. However, the mixed-mode controller may be influenced by the occupant, although the AV system is not commanded by the occupant. In some implementations, the mixed-mode controller may monitor the behavior of the occupant. For example, when the AV system is in the imposed driving mode, and an occupant may express discomfort or may be detected to be uncomfortable (e.g., motion sickness) about the AV driving behavior, the mixed-mode controller may evaluate the feasibility of switching to another driving mode (e.g., permissive autonomous, permissive manual, imposed manual, or imposed parked), and if feasible the mixed-mode controller may execute the transition to another driving mode.</p><p id="p-0097" num="0115">In some implementations, the mixed-mode controller may configure the AV system in a parked mode <b>407</b>, which pauses the driving of the AV system. For example, when being powered on, the AV system is initially in a parked mode <b>407</b>. In some instances, the AV system may have been driving to a goal position, and is then placed in a parked mode <b>407</b>.</p><p id="p-0098" num="0116">As mentioned above, in some implementations, the mixed-mode controller may transition the AV system from one driving mode to another. For instance, <figref idref="DRAWINGS">FIG. <b>4</b></figref> shows that the permissive autonomous mode <b>401</b> can transition to permissive manual mode <b>402</b>. In some implementations, the AV system may transition from the permissive autonomous mode <b>401</b> to, for example, the imposed autonomous mode <b>403</b>, the imposed manual mode <b>404</b>, the imposed disabled mode <b>405</b>, the imposed parked mode <b>406</b>, or parked mode <b>407</b>.</p><p id="p-0099" num="0117">In some implementations, the permissive manual mode <b>402</b> may transition to, for example, the permissive autonomous mode <b>401</b>, the imposed autonomous mode <b>403</b>, the imposed manual mode <b>404</b>, the imposed disabled mode <b>405</b>, the imposed parked mode <b>406</b>, or the parked mode <b>407</b>.</p><p id="p-0100" num="0118">In some implementations, the imposed autonomous mode <b>403</b> may transition to, for example, the permissive autonomous mode <b>401</b>, the imposed disabled mode <b>405</b>, the imposed parked mode <b>406</b>, or the parked mode <b>407</b>.</p><p id="p-0101" num="0119">In some implementations, the imposed manual mode <b>404</b> may transition to, for example, the permissive manual mode <b>402</b>, the imposed autonomous mode <b>403</b>, the imposed disabled mode <b>405</b>, the imposed parked mode <b>406</b>, or the parked mode <b>407</b>.</p><p id="p-0102" num="0120">In some implementations, the imposed disabled mode <b>405</b> may transition to, for example, the imposed parked mode <b>406</b>, or the parked mode <b>407</b>.</p><p id="p-0103" num="0121">In some implementations, the imposed parked mode <b>406</b> may transition to, for example, the permissive autonomous mode <b>401</b>, the permissive manual mode <b>402</b>, the imposed autonomous mode <b>403</b>, the imposed manual mode <b>404</b>, the imposed disabled mode <b>405</b>, or the parked mode <b>407</b>.</p><p id="p-0104" num="0122">In some implementations, the parked mode <b>407</b> may transition to, for example, the permissive autonomous mode <b>401</b>, the imposed autonomous mode <b>403</b>, the imposed manual mode <b>404</b>, the imposed disabled mode <b>405</b>, or the imposed parked mode <b>406</b>.</p><p id="p-0105" num="0123">These transitions are indicated by arrows in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. More complicated systems are possible in which other driving modes can be selected and transitions made among them, and in which transitions among the uses of specific selected sets of autonomous driving capabilities or manual driving capabilities or both are permitted or required.</p><heading id="h-0009" level="2">Mode Transition</heading><p id="p-0106" num="0124">The mixed-mode controller may analyze acquired information to determine which transitions may or must be made from one driving mode or non-driving mode (e.g., disabled or parked) to another, when such transitions should or must be made, and when and how sequences of such transitions should or must be made, among other features of the transitions.</p><p id="p-0107" num="0125">Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the mixed-mode controller <b>500</b> may comprise a mode transition analyzer <b>530</b> and a transition command converter <b>540</b>. Information sources for mode transition may include, for example, a sensor <b>502</b> (e.g., video cameras; LIDAR sensors; ultrasonic sensors; weight/pressure sensors on the seats and floor and in the trunk; X-ray sensors; chemical sensors; alcohol sensors; millimeter-wave imaging sensors; haptic sensors on the steering wheel or pedals; and eye trackers for occupant of the driver seat), a database <b>504</b> (e.g., map data, traffic data, infrastructure data, users, AV fleets, and insurance data), a user interface <b>506</b>, a component of the AV system <b>510</b>, a software process (e.g., perception, trajectory planning, motion control, and decision making), an AV system monitoring process <b>520</b>, a mix-mode driving server <b>550</b>, or a human, or combinations of them.</p><p id="p-0108" num="0126">When the mixed-mode controller receives information (e.g., system information and data <b>512</b>, an abnormal condition <b>522</b>, a request <b>552</b>), the mode transition analyzer <b>530</b> may evaluate the feasibility or desirability or necessity of mode transition and may determine the mode to which the AV system <b>510</b> should transition. When the analysis is done, a mode transition command <b>532</b> may be issued. In some cases, an analysis report <b>534</b> may be transferred to the mixed-mode driving server <b>550</b>.</p><p id="p-0109" num="0127">In some implementations, the mixed-mode driving server <b>550</b> may issue a mode transition command directly to the mixed-mode controller <b>500</b> without involvement by the occupant of the AV. For example, a fleet manager (which can be a human <b>551</b>, or fleet management algorithms running on the mixed-mode driving server <b>550</b>) may monitor a current environment of the AV system <b>510</b>, and cause the mixed-mode driving server <b>550</b> to instruct the AV system to transition into another driving mode. For instance, the AV system <b>510</b> may drop off an occupant, and its driving mode can then be transitioned into the imposed autonomous mode.</p><p id="p-0110" num="0128">When the transition command converter <b>540</b> receives a mode transition command <b>532</b>, it will convert the mode transition command <b>532</b> into one or more AV control commands <b>542</b> or into a sequence of AV control commands <b>542</b>. The AV system <b>510</b> may execute the AV control commands <b>542</b> and operate in the commanded driving mode.</p><p id="p-0111" num="0129">In some implementations, the mode transition may comprise a single-step transition; for example, the AV system may transition from the permissive autonomous mode <b>401</b> to the imposed autonomous mode <b>403</b>. In some implementations, the mode transition may comprise a multiple-step transition; for instance, the AV system may transition from the permissive manual mode <b>402</b>, to the permissive autonomous mode <b>401</b>, and to the imposed parked mode <b>406</b>.</p><p id="p-0112" num="0130">The mode transition analyzer <b>530</b> may determine transitions or sequences of transitions between and among driving modes based on one or more factors. Examples of the factors are described below.</p><p id="p-0113" num="0131">Health condition of the AV system. The AV system <b>510</b> may comprise an AV system monitoring process <b>520</b>, which may be a standalone process, or a part of the mixed-mode controller, or a part of mixed-mode driving server <b>550</b>. Among other things, the AV system monitoring process <b>520</b> may monitor the health condition or other operational condition of the AV system <b>510</b>, or the health condition or other operational condition of components of the AV system (e.g., a sensor, a computing device, a battery, an actuator, a tire, a steering wheel, a brake, a throttle, a headlight, a tail light, a controller, a data storage device, and an interface). Examples of the operational condition may include speed, orientation, acceleration, steering, data communications, perception, and trajectory planning.</p><p id="p-0114" num="0132">The AV system monitoring process <b>520</b> may receive system information and data <b>512</b> to monitor the operational condition (e.g., speed, orientation, acceleration, steering, data communications, perception, and trajectory planning) of the AV system <b>510</b> or of one or more components of the AV system. The operational condition may be based on directly reading outputs of hardware components or software processes, or both, of the AV system <b>510</b>, or indirectly inferring, e.g., computationally or statistically, the outputs by measuring associated quantities, or from inputs by an occupant of the AV system, or combinations of them. In some implementations, the AV system monitoring process <b>520</b> may derive information (e.g., computing a statistic, or comparing monitored conditions with knowledge in a database) from the operational condition. Based on the monitored operational condition or derived information or both, the monitoring process <b>520</b> may determine an abnormal condition <b>522</b>, which has led, or will lead, to degraded or undesirable performance or a failure of the AV system <b>510</b>. Examples of an abnormal condition include one or more or all of the following: a brake malfunction; a flat tire; the field of view of a vision sensor is blocked; a frame rate of a vision sensor drops below a threshold; an AV system's movement does not match a current steering angle, a throttle level, a brake level, or a combination of them; a fault software code; a reduced signal strength; an increased noise level; an unknown object perceived in the environment of the AV system <b>510</b>; a motion planning process is unable to find a trajectory towards the goal due to a planning error; or inaccessibility to a data source (e.g., a database, a sensor, and a map data source), among others.</p><p id="p-0115" num="0133">The existence of an abnormal condition <b>522</b> can be inferred. For example, in some implementations, the AV system monitoring process <b>520</b> may determine or infer an abnormal condition in the AV system <b>510</b> by pattern recognition. For example, one or more signal values received from the AV system <b>510</b> that are out of a normal pattern or a specified pattern may be determined as an abnormality. Patterns can be hand-crafted or deduced from data using machine learning approaches such as re-enforcement learning or deep learning.</p><p id="p-0116" num="0134">In some implementations, the AV system monitoring process <b>520</b> may detect an abnormal condition <b>522</b> in the AV system <b>510</b> by a model-based approach. For example, a model of a monitored hardware component or software process is constructed and a current state of the model is estimated using past inputs or past measurements. When a measurement associated with the current state deviates from its estimate, an abnormal condition <b>522</b> may occur. For example, dynamic quantities (e.g., speed and orientation) of the AV system <b>510</b> with respect to throttle and steering commands is described in a dynamics model, and the monitoring process <b>520</b> uses the dynamics model to estimate the dynamic quantities at time t based on the throttle and steering commands at time t&#x2212;1. When the measured dynamic quantities at time t differ from the estimated dynamic quantities by at least 1%, 2%, 3%, 4%, 5%, 10%, 15%, 20%, 25%, 30%, 35%, 40%, 45% or 50%, the monitoring process <b>520</b> determines an abnormal condition <b>522</b>. A model may be hand-designed or identified using system identification approaches or learned using machine learning approaches (e.g., neural networks).</p><p id="p-0117" num="0135">Occupant. In some implementations, the mixed-mode controller may evaluate preferences or characteristics or other status of an occupant who is on board or is planning to be on board the AV system. The preferences or characteristics or other status of the occupant may be provided by the occupant, or may be detected automatically, or both. The mixed-mode controller may analyze information from one or more sensors. For example, the AV system may comprise a sensor (e.g., a vision sensor, an acoustic sensor, an electric sensor, and pressure sensor) monitoring the interior of the AV system <b>510</b>, and the mixed-mode controller may analyze signals (e.g., images, videos, sounds, pressures, voltages, and currents) to infer behaviors of the occupant, such as seat occupancy, gestures, facial expressions, noises, utterances, body movement, and actions.</p><p id="p-0118" num="0136">In some implementations, the mixed-mode controller may access a database <b>504</b> of occupant records (e.g., driving history, social media, personal profiles, occupation, training, and crime database), and the mixed-mode controller may analyze the records to infer behaviors of occupant.</p><p id="p-0119" num="0137">In some implementations, the mixed-mode controller may evaluate if an occupant is an authenticated occupant, or if an occupant has special permission to override a driving mode or to request a driving mode, or if an occupant needs special care, or if an occupant should be restricted to certain modes (e.g., an occupant without a valid driver license may not be allowed to manually drive the AV).</p><p id="p-0120" num="0138">When a status of the occupant indicates that there is or may be a risky activity associated with an occupant, the mixed-mode controller may refuse to permit the occupant to control the AV system or may configure the AV system in a particular driving mode, such as the imposed autonomous mode <b>403</b>, the imposed disabled mode <b>405</b>, or the imposed parked mode <b>406</b>, among others.</p><p id="p-0121" num="0139">In some cases, the AV system may comprise a sensor measuring the intoxication level of an occupant. If the intoxication level is above a threshold, the mixed-mode controller may configure the AV system in a particular driving mode, such as the imposed autonomous mode <b>403</b>, the imposed disabled mode <b>405</b>, or the imposed parked mode <b>406</b>, among others.</p><p id="p-0122" num="0140">In some implementations, the mixed-mode controller may identify a medical emergency of an occupant driving the AV system, and the AV system may be configured in a particular driving mode, such as the imposed autonomous mode <b>403</b>, the imposed disabled mode <b>405</b>, or the imposed parked mode <b>406</b>, among others.</p><p id="p-0123" num="0141">In some implementations, the mixed-mode controller may determine a driving mode based on the lack of an occupant in the AV system. When there is no occupant and the AV system is instructed to drive towards a goal, the mixed-mode controller may configure the AV system in particular driving mode, such as the imposed autonomous mode <b>403</b> or the imposed parked mode <b>406</b>, among others.</p><p id="p-0124" num="0142">In some implementations, the mode transition may be executed upon a request of an occupant. For instance, an occupant may want to take over the control of the AV system, and he can instruct the mixed-mode controller to transition from one particular mode to another (e.g., from the permissive autonomous mode <b>401</b> to the permissive manual mode <b>402</b>).</p><p id="p-0125" num="0143">In some implementations, the mode transition may be executed upon activation or deactivation of one or more autonomous driving capabilities or of one or more manual driving capabilities. For example, when the AV system operates in an autonomous driving mode, an occupant may turn off a component of the perception process (e.g., traffic light detection, or sensing capability) and the deactivation may cause the mixed-mode controller to transition to a manual driving mode for safety reasons. For instance, a person may manually drive the AV system based on perception and trajectory planning processes, but he may activate the autonomous controller of the AV system, allowing or causing the mixed-mode controller to transition the manual driving to autonomous driving.</p><p id="p-0126" num="0144">Onboard objects. <figref idref="DRAWINGS">FIG. <b>9</b></figref> shows a risky or dangerous object <b>905</b> in a cargo area <b>904</b> (e.g., in a trunk) of a vehicle with a sensor <b>906</b> (e.g., a camera) for determining if the object <b>905</b> (e.g., a weapon) is risky or dangerous. In some implementations, the mixed-mode controller may evaluate characteristics or other status of an object (e.g., object <b>905</b>) placed, or to be placed (e.g., for shipping), on board the AV system, such as in the cargo area <b>904</b>. The AV system may comprise a sensor (e.g., sensor <b>906</b>) to identify shapes or chemical or other compositions, or both, of the object, and the mixed-mode controller may analyze sensor data to infer characteristics or other status of the object. The AV system may access records of a person (e.g., sender, owner, carrier, or receiver) associated with the object (e.g., driving history, social media, personal profiles, occupation, training, and crime database), and the mixed-mode controller may analyze the records to infer a purpose of having the object on the AV system. When there is a risky object (e.g., bomb or weapon) on board or a risky purpose (e.g., going to a drug party, or shipping an object to a hazard zone), the mixed-mode controller may configure the AV system in a particular driving or non-driving mode, such as the imposed disabled mode <b>405</b> or the imposed parked mode <b>406</b>, among others. When an object is a personal belonging or has no risk, the mixed-mode controller may configure the AV system in any preferred driving mode instructed by the person (e.g., sender, owner, carrier, or receiver) associated with the object.</p><p id="p-0127" num="0145">In some implementations, the mixed-mode controller may determine a driving mode based on the lack of an object placed on board the AV system. When there is no object and no occupant, the mixed-mode controller may configure the AV system in a particular driving mode, such as the permissive autonomous mode <b>401</b> or the imposed autonomous mode <b>403</b> or the imposed parked mode <b>406</b>, among others.</p><p id="p-0128" num="0146">Server requests. A mixed-mode driving server <b>550</b> may send a mode transition request <b>552</b> to the mixed-mode controller. The request <b>552</b> may include various information. For example, the request may show a scenario (e.g., a crowd, a medical emergency, a protest, a detour, a risky event, a police action, an inclement weather condition, a construction, an electricity blackout, and an accident) of a location during a trajectory towards the goal; the AV system may analyze the scenario to determine if the current driving mode has to be transitioned into another mode or sequence of modes.</p><p id="p-0129" num="0147">In some implementations, the AV system may be requested to pick up an occupant. In some implementations, the AV system may be requested to drive to a goal (e.g., returning to a service center) without an occupant.</p><p id="p-0130" num="0148">Safety. In some implementations, when the AV system is moving, the mixed-mode controller may evaluate feasibility, desirability, or safety of the transition based on the current driving condition of the AV system. In some implementations, the priority is to guarantee that the transition will not cause a risk on or to the AV system, any occupants and surrounding objects (e.g., vehicles, pedestrians, and infrastructure objects), or does not break rules of the road, or both. In some cases, the mixed-mode controller may measure the current driving speed or turning angle, or both, and evaluate the driving speed after the transition; the mixed-mode controller may smooth a change in the driving speed across the transitioned modes. For example, the speed of the current driving mode (e.g., manual driving) may be 50 km/hr, and the mixed-mode controller may transition the AV system to another driving mode (e.g., imposed autonomous driving) whose preferred speed is 30 km/hr; however, a sharp speed reduction from 50 km/hr to 30 km/hr may cause a collision by a following vehicle, so the mixed-mode controller may reduce the speed gradually from 50 km/hr to 30 km/hr. For instance, the mode transition may slow down or stop the AV system to enable a subsequent driving mode to take over. Sometimes, the mode transition may be realized along with audio prompts, video detection, or occupant confirmation, or a combination of them.</p><p id="p-0131" num="0149">When a driving mode includes one or more autonomous driving capabilities, the mode transition analyzer <b>530</b> may evaluate one or more or all of the following conditions by an algorithmically analyzing data provided by the sensors and other sources: (1) No human occupant is detected in the AV system <b>510</b>. (2) The AV system <b>510</b> is not in motion. (3) A mode transition command (e.g., <b>532</b> or <b>554</b>) may have been generated, regardless of an occupant being on board the AV system, to move from the current location to a new goal position. The AV might be moved to a new goal for a variety of reasons; for example, serving another booking or picking up an occupant; moving to a higher demand location or one where more booking requests are expected than at the current location; charging the vehicle (particularly relevant to electric vehicles); or vehicle maintenance. (4) The AV system <b>510</b> is capable of driving autonomously from its current location to the designated goal.</p><p id="p-0132" num="0150">Driving environment. The mixed-mode controller may evaluate functional status of one or more processes for processing sensor data, perceiving the environment, understanding conditions that are currently presented by and may at future times be presented by the perceived environment, performing trajectory planning, performing motion control, and making decisions based on those perceptions and understandings. The mixed-mode controller may use outputs from a process (e.g., perception) of the AV system or a source of information about the driving environment to determine a driving mode of the AV system. The perception process may detect objects in the driving environment of the AV system and thus may require the mixed-mode controller to respond to a detected object. For example, the perception process may detect an ambulance approaching the AV system, and the mixed-mode controller may configure the AV system into a particular driving mode, such as the imposed autonomous mode <b>403</b> or in the imposed parked mode <b>406</b>, among others; in some cases, the AV system may not find a safe-stopping place, and the mixed-mode controller may configure the AV system into the imposed manual mode <b>404</b>.</p><p id="p-0133" num="0151">In some instances, the perception process may detect an unknown object or unexpected event, and the mixed-mode controller may configure the AV system into a particular driving mode, such as the imposed parked mode <b>406</b>; in some cases, the AV system may not find a safe-stopping place, and the mixed-mode controller may configure the AV system into a particular driving mode, such as the imposed manual mode <b>404</b>.</p><p id="p-0134" num="0152">The mode transition analyzer <b>530</b> may keep using the AV system monitoring process <b>520</b> or reading the system information and data <b>512</b> to monitor if one or more autonomous driving capabilities remains in a functional state. When the AV system is powered on, the mode transition analyzer <b>530</b> may analyze if the AV system is able to switch from the parked mode to a particular driving mode. During the driving mode, the goal position may be updated over time, and the mode transition analyzer <b>530</b> may evaluate if the current driving mode remains appropriate, safe, feasible, or desirable or if a mode transition should be considered or implemented. Once the AV system reaches its goal, the mode transition analyzer <b>530</b> may issue a command to configure the AV system <b>510</b> to transition into the imposed parked mode <b>406</b> or parked mode <b>407</b>.</p><p id="p-0135" num="0153">The mode transition analyzer <b>530</b> may consider, control, select, recommend, or require particular characteristics to be followed during a given driving mode. For example:<ul id="ul0005" list-style="none">    <li id="ul0005-0001" num="0000">    <ul id="ul0006" list-style="none">        <li id="ul0006-0001" num="0154">1. The AV system may be configured to drive at a particular speed or within a speed range, say, not faster than 20 km/hr, 40 km/hr, 60 km/hr, 80 km/hr or 100 km/hr, due to constraints in regulation or software processing speed. In some scenarios, the AV system should not drive so slowly that it blocks traffic. Thus, the AV system may be configured to drive at a speed or within a speed range, say, not slower than 20 km/hr, 40 km/hr, 60 km/hr, 80 km/hr or 100 km/hr.</li>        <li id="ul0006-0002" num="0155">2. The mode transition analyzer <b>530</b> may analyze data to avoid certain locations or areas, for example, to avoid driving the AV in areas known to be difficult or dangerous to drive based on an autonomous driving capability. For instance, the AV system may prefer not to drive on complex road configurations (e.g., roundabouts and 4-way stops) or highways. In some examples, some roads or intersections might be blacklisted because they are known to be complex or dangerous. On the other hand, following a longer path might not be acceptable with an occupant on board but might be acceptable when there is no occupant.</li>        <li id="ul0006-0003" num="0156">3. The AV system can use conservative decision-making strategies with respect to the selection of a driving mode or sequences of driving modes. For instance, the AV system may choose never to cross over to an opposing lane of traffic in order to pass a parked car. In some implementations, the AV system may choose to have the AV system stop when it sees an unidentified object. Some of these strategies might not be desirable with an occupant on board, as the occupant may feel less efficient or frustrated. However, such inefficiencies or frustrations may be acceptable when the AV system is configured in the autonomous driving mode or when there is no occupant on board the AV.</li>        <li id="ul0006-0004" num="0157">4. When an occupant is on board the AV system, a choice of driving mode or a choice of specific autonomous driving capabilities for a given driving mode may consider or prioritize driving smoothness to avoid the occupant feeling uncomfortable. When there is no occupant on board the AV system, a lower threshold of &#x201c;driving smoothness&#x201d; might be acceptable during operation in the autonomous driving mode, which can increase efficiency.</li>        <li id="ul0006-0005" num="0158">5. In some unexpected situations, the AV system might have to make a sudden decision about driving mode, for example, between a choice that harms the AV system and another choice that harms another car. For example, if the AV system suddenly sees a car that it cannot avoid hitting, the AV system might have the choice of causing the AV system to swerve out of the way to avoid the car at the cost of going off the road or hitting a road barrier. Such a choice may be easier to make when the AV system is not carrying any occupant.</li>    </ul>    </li></ul></p><p id="p-0136" num="0159">In some implementations, the mixed-mode controller may allow an occupant to be driven in a fully or partially autonomous driving mode to a goal position. In such situations, the mixed-mode controller may enter the autonomous driving mode when an authorized occupant is successfully authenticated, enters the AV, confirms the goal position, and explicitly requests or requires or prefers the fully or partially autonomous driving mode. In other words, in some implementations, the occupant can determine the driving mode.</p><p id="p-0137" num="0160">In some implementations, the mixed-mode controller may transition the AV system into a partially or fully manual driving mode, if one or more occupants are determined to have successfully authenticated themselves and entered the AV system. In some cases, the AV system may be caused to enter the partially or fully manual driving mode because none of the occupants is a preferred driver or has sufficient privileges to use a partially or fully autonomous driving mode or to use certain of the autonomous driving capabilities in a given driving mode. In some cases, the AV system may prevent transitions to a partially or fully manual driving mode based on information indicating that the occupant is not capable of or not an appropriate condition to engage in such a driving mode. In some examples, one or more occupants may indicate to the AV system that he does not wish to use an autonomous driving mode. In some scenarios, the goal position may not be reached using an autonomous driving mode.</p><p id="p-0138" num="0161">When the AV system is in a partially or fully manual driving mode, one of the occupants is expected to partially or fully manually drive the AV system. In some examples, the AV system is then configured in an imposed manual driving mode, in which none of the occupants, for example, can cause the AV system to switch to a partially or fully autonomous driving mode, except that standard safety features such as ABS, ESC, etc. may be allowed to continue to operate in their autonomous driving mode. In some implementations, when the AV system is operated in a partially manual driving mode, one or more autonomous driving capabilities may be turned on so that the AV system may, for example, perceive the driving environment and detect risky events on the roads. When a risky event is detected, the mixed-mode controller may override one or more manual driving capabilities (e.g., applying brakes, slowing down the AV, or taking over the steering, or combinations of them).</p><p id="p-0139" num="0162">In some implementations, when the AV system recognizes that one or more occupants have reached the goal position or exited the AV system, the mixed-mode controller may transition the AV system to the parked mode.</p><p id="p-0140" num="0163">In some examples, transitioning the AV system into a fully or partially manual driving mode can provide advantages to the mixed-mode driving system.<ul id="ul0007" list-style="none">    <li id="ul0007-0001" num="0000">    <ul id="ul0008" list-style="none">        <li id="ul0008-0001" num="0164">1. For example, some existing transportation systems may require occupants to pick up AV systems from a predefined list of stations or locations. In such cases, an occupant is normally required to specify the station or location in the booking request, and the occupant is required to walk to an AV system's location. This arrangement may be less convenient than when an AV system having mixed-mode driving capabilities can drive to the occupant autonomously and then switch the AV system to a manual driving mode for the occupant.</li>        <li id="ul0008-0002" num="0165">2. The mixed-mode driving system may attempt to send an AV system to the occupant's preferred pickup location (e.g., the occupant's current location). The mixed-mode driving system may cause the AV system to drive in a fully autonomous driving mode from its current location to the occupant's preferred pickup location and come to a safe stop at or near the occupant's preferred pickup location. The user might then have to walk to the AV system.</li>    </ul>    </li></ul></p><p id="p-0141" num="0166">When the AV system is in the parked mode, the mixed-mode controller may transition the AV system to the imposed parked mode. Once an occupant is authenticated and has entered the AV system, the mixed-mode controller may transition the AV system to the partially or fully manual driving mode and the AV system is then available for the occupant to drive manually. Similarly, the mixed-mode controller may transition the AV system from the parked mode to the partially or fully autonomous driving mode and the AV system is then available for the occupant to ride autonomously.</p><p id="p-0142" num="0167">During a trip or at the end of the trip, the occupant may be expected to leave the AV system at a location at which the mixed-mode controller can cause the AV system to enter the fully autonomous driving mode and cause the AV system to drive itself autonomously to another location (e.g., for recharging, refueling, or picking up another occupant or object). This drop-off procedure can be implemented in various ways, including but not limited to the following:<ul id="ul0009" list-style="none">    <li id="ul0009-0001" num="0000">    <ul id="ul0010" list-style="none">        <li id="ul0010-0001" num="0168">1. In some implementations of the mixed-mode driving system, the occupant may not be required to specify a destination at the time of booking. In such cases, the occupant is provided with clear information about an autonomous service area where the occupant may be allowed to leave the AV system. This information is provided at the time of booking and also during the trip. The occupant may be assisted by providing to the occupant directions from the current location to the nearest valid drop-off location.</li>        <li id="ul0010-0002" num="0169">2. In some implementations of the mixed-mode driving system, the occupant can be required to specify her destination at the time of booking, and she can be limited to specifying destinations from which the AV system can be operated in the fully autonomous driving mode to proceed to another location. If the occupant attempts to leave the AV system at a location that is not a valid drop-off point or not the user's pre-selected destination, the AV system informs the occupant (e.g., through an in-car user interface or a smartphone app or something similar) and provides directions to the nearest valid drop-off point or the user's pre-selected destination.</li>    </ul>    </li></ul></p><p id="p-0143" num="0170">Algorithmic decision. The mode transition analyzer <b>530</b> may use algorithmic analysis to determine the transition. For example, the mode transition diagram <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be described as a probabilistic graphical model. The probabilities of all the arrows emitting from a node are summed to one, and each probability is derived from past and currently observed data (e.g., map data, perception data, trajectory data, and any data of the factors described in this document). The mode transition analyzer <b>530</b> may use probabilistic modeling on the various factors, and infer an optimal mode (which may be the current driving mode or another driving mode) to which the AV system is transitioned. The optimal mode may be determined as the mode with the greatest probability of transitioning from the current mode.</p><p id="p-0144" num="0171">In some implementations, the factors may be treated as hidden variables, and a hidden Markov model may be used in the algorithmic analysis regarding the current driving mode.</p><p id="p-0145" num="0172">In some implementations, the mode transition analyzer <b>530</b> may reject the mode transition requested by a user. For example, a user may request the AV system to transition from an autonomous mode into a parked mode, but the algorithmic analysis may be unable to identify a parking space in the neighborhood and the transition may be rejected.</p><p id="p-0146" num="0173">In some implementations, the mode transition analyzer <b>530</b> may recommend a mode transition. The recommendation may be made along with other actions (e.g., after rejecting a mode transition). For example, an autonomous mode may not be suitable in a driving environment (e.g., inclement weather, degraded driving performance, complex road configurations, and noisy sensor signals). The mixed-mode controller may recommend a manual driving mode if there is an occupant, or recommend a parked mode if a parking space is identified in the neighborhood.</p><heading id="h-0010" level="2">Mixed-Mode Driving Server</heading><p id="p-0147" num="0174">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a mixed-mode driving system may include two or more (e.g., a fleet of)</p><p id="p-0148" num="0175">AV systems (e.g., <b>601</b> and <b>602</b>), each of which comprises a mixed-mode controller (e.g., <b>611</b> and <b>612</b>). A fleet may comprise both AV systems and vehicles without autonomous driving capabilities. The number of the AV systems in a fleet may be at least 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, or 10,000. Such a fleet of AV systems can be managed by one or more mixed-mode driving servers (e.g., <b>621</b> and <b>622</b>). The mixed-mode driving servers are in communication through wireless networks with, among other things, all of the AV systems (<b>601</b> and <b>602</b>) of the fleet, with data sources (e.g., database <b>652</b>, and sensor <b>654</b>), and with one or more computing devices (e.g., mobile device <b>641</b>) where a transportation service user (e.g., <b>642</b>) may request a transportation service (e.g., taxi and package shipping) via the computing device (e.g., <b>641</b>).</p><p id="p-0149" num="0176">The mixed-mode driving server (e.g., <b>621</b> and <b>622</b>) may have access to various types of data; for example, profiles of users of transportation services. The profiles may include a preferred driving mode of an AV system in which the users will ride. The preferences may be expressed in advance in their profiles or expressed to the mixed-mode driving system at the time of booking a transportation service. The preferences can be expressed explicitly, or be inferred from conduct of the occupants or stored information about them, or may be obtained or inferred from other data sources (for example, social network accounts that have been linked by the users to their profiles).</p><p id="p-0150" num="0177">A user <b>642</b> of the mixed-mode driving system may send a request to the mixed-mode driving server (<b>621</b> or <b>622</b>) by using a mobile device <b>641</b> or a website or by calling an operator, or by any other hailing method, or combinations of them. The mixed-mode driving server then assigns an AV system to the request from a fleet of AV systems expected to be available at that time. Different AV systems in the fleet may have different manual driving capabilities and autonomous driving capabilities and therefore may be suited to serving the requests of various respective occupants.</p><p id="p-0151" num="0178">In some implementations, the user <b>642</b> may be comfortable riding in an AV system only when she is an occupant and is in a condition to be able to drive; thus, the mixed-mode controller may configure the driving mode of the AV system to operate in the imposed manual driving mode. She may have no objection to the AV system being driven autonomously to the goal position where she is to be picked up or autonomously from the goal position once she is no longer on board. These preferences (and a variety of other preferences about the driving mode and other characteristics of AV system) can be stored in her profile.</p><p id="p-0152" num="0179">In some cases, the occupant may wish to have the AV system operate in an imposed manual driving mode while the AV system is in one area (e.g., urban areas, crowded areas, and neighborhoods of events) but wishes to have the AV system in an autonomous driving mode in another area (e.g., non-urban areas, non-crowded areas, and low-traffic areas). A variety of other preferences could also be expressed. The data in the profile of the user <b>642</b> can serve as one factor used by the mixed-mode controller (e.g., <b>611</b> and <b>612</b>) to determine a driving mode of the AV system and to change the driving mode of the AV system from time to time.</p><p id="p-0153" num="0180">In some uses, the mixed-mode driving server (e.g., <b>622</b>) may receive a report that toxic or otherwise dangerous packages are detected or known to be on board the AV system. The server <b>622</b> can issue a mode transition command <b>625</b> to the mixed mode controller <b>611</b> to transition the AV system to the imposed manual mode <b>404</b> or disable the AV system from being driven (that is, switched to the imposed disabled mode <b>405</b>). Among other things, this feature could prevent a terror attack in which a terrorist would put a bomb in the AV system and send it to a goal position in an autonomous driving mode without himself being on board.</p><p id="p-0154" num="0181">In some instances, the mixed-mode driving server <b>622</b> may receive a report regarding an event (e.g., emergency, police action, and inclement weather). The server may analyze a suitable driving mode for the AV system <b>601</b>, and issue a mode transition command <b>625</b> to the mixed-mode controller <b>611</b>. For example, when the AV system <b>601</b> is in a manual driving mode and the driver is in medical emergency or intoxicated or asleep, the server <b>622</b> may determine a command <b>625</b> comprising a sequence of the following actions: (1) switch the AV system <b>601</b> from the manual driving to the imposed autonomous mode, (2) identify a nearest medical server facility as a new goal position, (3) drive autonomously to the new goal position, and (4) switch the AV system <b>601</b> from the imposed autonomous mode to the imposed parked mode when arriving the new goal position. After the mixed-mode controller <b>611</b> receives the command <b>625</b>, the mixed-mode controller <b>611</b> may execute as instructed, or may coordinate with other processes (e.g., perception, trajectory planning, and motion control) to identify a best timing to execute the individual actions and transitions of the sequence.</p><p id="p-0155" num="0182">In some cases (e.g., during emergencies), an occupant may leave the AV system at a location from which the AV system is unable to drive itself in an autonomous driving mode. Thus, the AV system must be moved by operating in a manual driving mode from the location. The removal can be achieved by the mixed-mode driving server notifying service personnel (e.g., through wireless communication) to move the AV system away, or by accepting a new booking for an occupant who can start manually driving the AV system.</p><p id="p-0156" num="0183">In some implementations, the AV system may be requested by itself or the mixed-mode driving server to move to a new location for a variety of reasons; for example, (1) serving another booking or picking up a new occupant; (2) moving to a higher demand location where more booking requests are expected than the current location; (3) fueling or charging the AV system (particularly when the AV system is powered by electricity); (4) vehicle maintenance. In some cases, the mixed-mode controller switches the AV system to the permissive or imposed autonomous driving mode, causes the AV system to drive to its goal position, and then may cause the AV system to switch to a parked mode.</p><p id="p-0157" num="0184">In some instances, the mixed-mode driving server <b>621</b> can, through the AV system <b>601</b> or device <b>641</b>, provide positive and negative incentives (e.g., penalties) to dissuade bad behavior and encourage compliance by occupants with rules, policies, and practices specified by the mixed-mode driving server <b>621</b>. In some examples, incentives may be used to discourage passengers from dropping off the AV system at locations where the AV system cannot drive itself autonomously.</p><p id="p-0158" num="0185">The mixed-mode driving server (e.g., <b>621</b> and <b>622</b>) may arrange a fleet of AV systems (e.g., <b>601</b> and <b>602</b>) to enhance transportation efficiency. The following examples illustrate the enhanced efficiency.</p><p id="p-0159" num="0186">Example 1. Traditional transportation systems, such as the ones generally used by car sharing companies, may request a user having reserved a vehicle to go to a location where the vehicle is parked, use the vehicle, bring the vehicle back to the same location, and then go back to her place. Such systems require users to: (1) make only round trips, i.e., to bring the vehicles back to the starting locations and (2) walk to and from the vehicles' parked locations. The mixed-mode driving system can avoid these limitations. The AV system may be requested by itself or by the mixed-mode driving server to drive in an autonomous driving mode to a user's start location. Thereafter the user may drive the AV system in a manual driving mode wherever she desires without having to make a round trip. And once the user exits the AV system, the AV system may be self-configured or instructed by the mixed-mode driving server to drive itself in an autonomous driving mode to a parking location or to serve another user.</p><p id="p-0160" num="0187">Example 2. In some existing transportation systems, a user who has reserved a vehicle for a transportation service needs to walk to a location where it is parked, followed by using the vehicle and finally dropping the vehicle off at any location (within a designated area) where parking is legal. Such systems have drawbacks that the user must walk to the vehicle's parked location and that the system operator has no control over where vehicles are located at the ends of the trips. The system operator often needs to deploy its own drivers to relocate the vehicles to areas of a high demand to keep system utilization high. The mixed-mode driving system described in this document can avoid these limitations. The mixed-mode controller can configure the AV system to drive in an autonomous driving mode to the user's start location. Once the user finishes her trip, the AV system can drive in an autonomous driving mode to a parking location or to serve another user.</p><p id="p-0161" num="0188">Example 3. In some existing transportation systems (such as taxis), a human driver has to be present in a vehicle to manually operate the vehicle. Upon a request, the driver drives the vehicle to a passenger's pickup location, takes the passenger to his destination, and then moves to the next trip or does something else. Such systems are costly because they require a human driver to provide mobility for passengers. The mixed-mode driving system described in this document may remove the limitation by (1) causing the AV system to drive in an autonomous driving mode when there is no occupant on board, and (2) allowing an occupant to drive in a manual driving mode during his trip.</p><heading id="h-0011" level="2">User Interface</heading><p id="p-0162" num="0189">A mixed-mode driving system may comprise a user interface for a user (e.g., occupant, fleet manager, tele-operator, and package sender). The interface may be installed in the AV system (e.g., for an occupant). In some implementations, the interface may be installed along with a mixed-mode driving server. In some implementations, the interface may be implemented as a software application installed on a user's mobile device.</p><p id="p-0163" num="0190">A user of the interface may be an occupant in the vehicle, or a user of the vehicle (e.g., for delivering a package), or a remote operator of the vehicle (e.g., a remote human operator or a computer program on a remote server).</p><p id="p-0164" num="0191">For example, <figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an apparatus <b>700</b> with which a user can choose what information (e.g., perception <b>712</b>, motion planning <b>714</b>, or mode transition <b>716</b>, or combinations of them) to be displayed. In this example, the user may choose perception information <b>712</b>, and the interface <b>710</b> may show a field of view of a vision sensor (e.g., camera, lidar, and radar) from the AV system. In some cases, the interface <b>750</b> may show a bird's-eye view of the vision sensor. Some implementations may comprise both a field of view and a bird's-eye view. The field of view or the bird's-eye view may be a view experienced by the AV system at the current moment, or a snap-shot at a past time or both. The perception information may comprise map information. The perception information may be an image or a video showing a 2D or a 3D view. In some implementations, the perception information may comprise processed data; for example, segmentation on images, perceived objects in vision data, detected but unrecognizable objects in vision data.</p><p id="p-0165" num="0192">For example, <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an apparatus <b>800</b> with which the user has chosen motion planning information <b>812</b> to be displayed on the interface <b>810</b>. In some implementations, the interface <b>810</b> may show a map, a trajectory of the AV, a geolocation of the AV, or an orientation of the AV, or combinations of them. The trajectory may be a current trajectory <b>814</b> of the AV at the current moment, or a snap-shot at a past time, or a combination of them.</p><p id="p-0166" num="0193">In some implementations, the interface may display a current driving mode, and allow the user to request another particular driving mode. For instance, the interface <b>820</b> may allow a user to click on the mode transition button <b>822</b> to select a mode for the AV system. The display may show the current driving mode (e.g., manual mode <b>832</b>) and allow the user to choose another mode (e.g., autonomous <b>834</b>, parked <b>836</b>, or disabled <b>838</b>).</p><p id="p-0167" num="0194">In some implementations, the interface may allow a user to indicate (e.g., draw, type, gesture, say, or select) driving information of the vehicle. For example, the interface may allow the user to indicate a goal position or a trajectory. For instance, the interface may allow the user to indicate an object detected by a perception system. In some cases, the interface may allow the user to indicate a current geolocation (e.g., landmark, street number, road, latitude, and longitude) of the AV system.</p><p id="p-0168" num="0195">In some implementations, the interface may allow a user to indicate (e.g., draw, type, gesture, say, or select) driver or occupant condition. For example, the interface may allow the user to indicate a health condition (e.g., healthy, injury, uncomfortable, motion sickness, or medical emergency). For example, the interface may allow the user to indicate a preference. Some examples of the interface may allow the user to indicate driver license information. In some cases, the interface may allow the user to indicate companion or package information.</p><p id="p-0169" num="0196">Other aspects and implementations are also within the scope of the claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method comprising:<claim-text>analyzing, using at least one processor, information about a vehicle or a user of the vehicle or a driving environment of the vehicle; and</claim-text><claim-text>transmitting, using the at least one processor, a command to the vehicle to transition from a first driving mode comprising one of (a) an autonomous driving mode, (b) a manual driving mode, or (c) another predefined driving mode, to a second driving mode comprising one of (a), (b), or (c),</claim-text><claim-text>wherein the first driving mode is different from the second driving mode.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the information comprises analyzing a preference of one or more occupants for operation of the vehicle in one of the modes (a), (b), or (c).</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the information comprises analyzing a physical condition of one or more occupants.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the physical condition comprises a condition requiring emergency medical care.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the information comprises analyzing an identity of one or more occupants.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the information comprises analyzing a license to manually drive the vehicle.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the information comprises analyzing an impaired ability to manually drive.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the information comprises analyzing a degree of danger associated with a driving environment of the vehicle.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>receiving the information from a data source not on board the vehicle; and</claim-text><claim-text>transitioning from the first driving mode to the second driving mode based on the received information.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>receiving profile information of an occupant for the vehicle; and</claim-text><claim-text>transitioning from the first driving mode to the second driving mode based on the profile information.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>receiving the command from a remote operator to cause the vehicle to transition.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the information comprises smoothing a speed of the vehicle across the first driving mode and the second driving mode.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the information comprises evaluating a trajectory towards a goal position under the next driving mode.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the information comprises evaluating authentication of the one or more occupants under the next driving mode.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the information comprises inferring one or more intermediate driving modes between the first driving mode and the second driving mode.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein analyzing the information comprises using a probabilistic model to optimally determine the next driving mode.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first driving mode comprises the manual driving mode and the second driving mode comprises a paused driving mode or a disabled driving mode.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first driving mode comprises the autonomous driving mode and the second driving mode comprises a paused driving mode or a disabled driving mode.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. An apparatus comprising:<claim-text>one or more processors; and</claim-text><claim-text>a memory storage in data communication with the one or more processors, the memory storage storing instructions executable by the one or more processors and that upon such execution cause the one or more processors to perform operations of <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A non-transitory computer storage medium encoded with a computer program, the computer program comprising instructions that when executed by data processing apparatus cause the data processing apparatus to perform operations of <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim></claims></us-patent-application>
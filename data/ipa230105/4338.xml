<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004339A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004339</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17363767</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>14</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>11</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>1462</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>11</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>51</main-group><subgroup>046</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SHARED VIEWING EXPERIENCE ENHANCEMENT</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>Rovi Guides, Inc.</orgname><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Chandrashekar</last-name><first-name>Padmassri</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Emmanuel</last-name><first-name>Daina</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Shah</last-name><first-name>Akshay Chetan</first-name><address><city>Mumbai</city><country>IN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Methods and systems are provided for receiving media content for display in a shared activity session; receiving additional content corresponding to respective users of one or more other user equipment devices participating in the shared activity session; generating for display, using control circuitry, a display screen including the media content and at least some of the additional content; and, during the shared activity session, automatically adapting the display of the additional content using the control circuitry based on the media content and/or the additional content. For example, images, avatars or video of the users displayed alongside the media content may be adapted using backgrounds or filters reflecting the media content; additional content, such as audio or chat messages, provided by those users; and/or information in their user profiles. The shared activity may be, for example, a group watch session, a videoconference, videocall, audio call, chat session or multi-player game session.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="105.16mm" wi="158.75mm" file="US20230004339A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="239.44mm" wi="175.09mm" file="US20230004339A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="241.55mm" wi="175.18mm" file="US20230004339A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="229.53mm" wi="131.32mm" file="US20230004339A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="241.55mm" wi="175.18mm" file="US20230004339A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="240.37mm" wi="175.01mm" file="US20230004339A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="240.37mm" wi="160.87mm" file="US20230004339A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">Embodiments of the disclosure relate generally to methods and systems for shared viewing activities, such as group video calls, videoconferences, chats, messaging, group watch sessions and multi-player games.</p><p id="p-0003" num="0002">Communication technology has developed to such an extent that videocalling and videoconferences are now commonplace. This permits virtual meetings between hundreds of participants at different locations, allowing them to communicate with one another using audio and video. Such meetings may also provide messaging and chat functions, allow the users to view presentations and media content together, and to screen-share.</p><p id="p-0004" num="0003">Group watch applications allow users at different locations to watch live or on-demand media content online together. For example, a group of friends might like to watch a sports event or movie together but cannot gather in the same physical location due to travelling distances between their locations and/or restrictions on indoor gatherings. While it may be possible to use screen-sharing or videoconferencing to allow a group of viewers at different locations to watch the same content together, dedicated group watch applications and functionality have become available. Some degree of synchronization between the playback of the content on the devices used by the viewers to view the content is provided, for example, using a group watch application implemented on the viewers' respective media devices. In particular, playback operations instigated by one or more of the viewers, such as pausing, rewinding, fast-forwarding or skipping content, is replicated in the playback of the content to the other viewers in the group.</p><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0005" num="0004">Embodiments of this disclosure include methods and systems for enhancing an online shared viewing session. Such methods and systems may use a shared viewing application implemented on user devices. The shared viewing application may be a stand-alone application, such as a group watching application, or may be a software module that is part of another application, such as an interactive television application, media guidance application, videocall application, videoconferencing application, or a multi-player game, in which images, avatars or video of one or more participants are displayed alongside the content being viewed.</p><p id="p-0006" num="0005">The shared viewing application or software module adapts the images, avatars or videos during the shared viewing session. The adaptation may include changing a background shown in an image, avatar or video of a participant, putting an image filter or video filter over an image, avatar or video of a participant, adding a visual effect to an image corresponding to a participant in an audio call or message-based chat, or changing a display profile of a participant in an audio call or message based chat, for example, by changing display attributes, such as color, font, emojis or icons, in the display of messages from a participant in a message-based chat activity.</p><p id="p-0007" num="0006">The adaptations may be based on media content being viewed by the group. For example, the shared viewing application or software module may select a frame from the media content and use that frame as a background to still or video images of some, or all, of the participants. In another example, a background may be selected to complement the media content, such as an image or an advertisement of a product or location featured in, or similar to an object, plot line, subject or location shown in the media content. Further adaptations may be made during the session, to update the background based on other frames, objects or locations in the media content.</p><p id="p-0008" num="0007">Another example of an adaptation is placing, or changing, a video filter to modify the appearance of the video images of some, or all, of the participants. Such filters may be selected to correspond to persons, characters, teams, events or locations in the media content or game.</p><p id="p-0009" num="0008">The shared viewing session may be a group watch session, in which media content is played to the participants on respective user equipment devices. The playback of media content is synchronized between the multiple user equipment devices, and playback operations requested by one or more of the participants, such as pausing, rewinding, skipping, fast-forwarding and/or other trickplay functions, are performed by all of the user equipment devices. The media content may be live media content or on-demand media content. Video or still images corresponding to some or all of the participants are displayed alongside the media content, for example in a gallery of images, and adapted in the manner described above.</p><p id="p-0010" num="0009">The shared viewing session may be a videocall or videoconference, in which case video of one or more of the participants is displayed to the other participants and adapted in the manner described above. Optionally, other content, such as a presentation or a screen-share, may be displayed alongside the video of the other participants.</p><p id="p-0011" num="0010">The shared viewing session may be a multi-player game in which images, avatars or videos of at least some of the players are displayed alongside game content and adapted in the manner described above.</p><p id="p-0012" num="0011">In a message-based chat application provided separately to, or alongside, viewing of media content or any of the applications described above, adaptations to the display profile of a participant may be made based on content of the messages exchanged between the participants, for example by adding a background or filter to an image of the participant, or changing display attributes for their messages.</p><p id="p-0013" num="0012">The adaptation may be based on the media content, as in the examples mentioned above. The adaptation may also, or instead, be based on a context such as a subject or keyword in a discussion or chat between participants, information in the user profiles of one or more participants, or other information. For example, the adaptations may be based on additional content provided by the participants, such as chat messages exchanged between participants during the session or audio input from the participants during the session. If the participants in a group watch session are watching a basketball game between two teams, the Nets and the Heat, and audio input from one participant indicates that they are cheering one particular team, their image, video or avatar may be adapted with a background or filter corresponding to that team. In another example, if user profile information of one participant may indicate that they support a particular sports team, then a video filter and/or background reflecting their support for that team may be applied to a video of that participant, such as a team emblem or shirt during a group watch session of a match involving that team. Alternatively, or additionally, a filter and/or background depicting a celebration may be applied to the video of that participant in response to points being scored by that team. Another option would be to provide an adaptation that presents team merchandise or an advertisement for products associated with the team or their sponsors.</p><p id="p-0014" num="0013">The adaptations may be triggered by detection of an event in the session, such as a goal in a sports event or a particular scene in a television program or film; detection of an event, tag or marker in the media content; detection of an event or keyword in chat messages; or audio input from the participants. Alternatively, or additionally, adaptations may be applied periodically, for example, at preset or variable time intervals, during commercial breaks in the media content.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE FIGURES</heading><p id="p-0015" num="0014">The above and other objects and advantages of the disclosure will be apparent upon consideration of the following detailed description, taken in conjunction with the accompanying drawings, in which like reference characters refer to like parts throughout, and in which:</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a system for providing a shared viewing activity in accordance with some embodiments;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram of a user equipment device in the system of <figref idref="DRAWINGS">FIG. <b>1</b></figref>;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> depicts an example of a display of media content in a shared viewing activity;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>3</b>B</figref> depicts an example of an adapted display of media content in a shared viewing activity;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of a method for adapting display of media content in a shared viewing activity according to an embodiment;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts an example of selecting a background for use in adapting the media content according to an embodiment;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts an example of selecting a background for use in adapting the media content according to another embodiment;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIGS. <b>7</b>A, <b>7</b>B and <b>7</b>C</figref> depict examples of an adapting a display associated with an audio call; and</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>8</b></figref> depicts an example of adapting the media content display of chat messages according to an embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0025" num="0024">Example methods and systems for transmitting user feedback and actions in a shared viewing activity will now be described.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts an example of a system <b>100</b> for providing shared viewing of media content in accordance with an embodiment in which a group of users <b>102</b><i>a</i>-<i>d </i>are watching media content on respective user equipment devices <b>104</b><i>a</i>-<i>d</i>. Examples of suitable user equipment devices <b>104</b><i>a</i>-<i>d </i>include, but are not limited to, a smart television, a tablet device, a smartphone, a device such as a set-top box or streaming device connected to a display device, a <b>3</b>D headset or virtual reality display equipment.</p><p id="p-0027" num="0026">The user equipment devices <b>104</b><i>a</i>-<i>d </i>receive the same media content from a content source <b>106</b> via a communication network <b>108</b>. In this example, the communications network is the Internet. Examples of content sources <b>106</b> include video-on-demand servers, streaming services, network digital video recorders or other devices that can communicate with the user equipment devices <b>104</b><i>a</i>-<i>d </i>via the network <b>108</b>. Examples of media content include a television program, a recording of media content, streamed media content or an online video game.</p><p id="p-0028" num="0027">The example shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> includes only one communication network <b>108</b>, through which the user equipment devices <b>104</b><i>a</i>-<i>d </i>can receive the media content and communicate with one another. In another embodiment, the user equipment devices <b>104</b><i>a</i>-<i>d </i>may receive the media content via a first communications network, such as a cable or broadcast network, and communicate with each other via a second communication network, such as the Internet.</p><p id="p-0029" num="0028">An example of a user equipment device <b>200</b> for use in the system <b>100</b> is depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The user equipment device <b>200</b> includes control circuitry <b>202</b> that comprises processing circuitry <b>204</b> and a memory <b>206</b> that stores, at least, a computer program that, when executed by the processing circuitry <b>204</b>, provides a shared viewing application. The processing circuitry <b>204</b> may be based on one or more microprocessors, microcontrollers, digital signal processors, programmable logic devices, etc. The memory <b>206</b> may be random-access memory, read-only memory, or any other suitable memory.</p><p id="p-0030" num="0029">The control circuitry <b>202</b> is arranged to receive media content via the communication network <b>108</b> through input/output path <b>208</b>, and generates for display a video component of the media content. In addition, the control circuitry <b>202</b> is arranged to generate and send data conveying reactions of the user of the user equipment device <b>200</b> to other users in the group and to receive, and generate for display, data conveying user reactions from other user equipment devices <b>104</b><i>b</i>-<i>d </i>in the group via the input/output path <b>208</b>.</p><p id="p-0031" num="0030">The control circuitry <b>202</b> is arranged to provide the video component and received data conveying the reactions of other users for display via display output <b>210</b>. The display output <b>210</b> may be configured to be connected, via a wired or wireless connection, to an external display device, such as a television or monitor (not shown), or may be an integrated display, such as a touch-screen display.</p><p id="p-0032" num="0031">The control circuitry <b>202</b> is also arranged to generate for output, via audio output <b>212</b>, an audio component of the media content. The display output <b>210</b> may be configured to be connected, via a wired or wireless connection, to an external audio output device, such as a television, monitor, speaker or headphones (not shown), and/or one or more speakers integrated into the user equipment device <b>200</b>.</p><p id="p-0033" num="0032">The control circuitry <b>202</b> is also arranged to receive input from a plurality of sensors. In the example shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the user equipment device <b>200</b> includes a microphone input <b>214</b> that is arranged to receive audio input signals via an integrated or external microphone <b>216</b>. The control circuitry <b>202</b> is also arranged to receive still and/or video images via at least one input <b>218</b> from a respective camera <b>220</b>. The camera <b>220</b>, or cameras, may be integrated into the user equipment device <b>200</b>, external cameras connected to the user equipment device <b>200</b>, or a combination thereof.</p><p id="p-0034" num="0033">The user equipment device <b>200</b> also includes a user input interface <b>222</b> for receiving commands and requests from a user, for example, to control playing and selection of media content using a remote control device (not shown). Such a remote control device may be connected to the user equipment device <b>200</b> via a wireless connection, such as an infra-red, Wi-Fi, Bluetooth or other suitable connection. Alternatively, or additionally, the microphone <b>216</b> and microphone input <b>214</b> may be used to receive voice input for controlling the user equipment device <b>200</b>, in which case the processing circuitry <b>204</b> may perform natural language processing to determine the user's command from the voice input and perform a corresponding action.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> depicts an example of a display screen for use in a shared viewing experience, according to some embodiments. In this example, a group of users are participating in a group watch session of media content in the form of a volleyball match. The display screen, shown on a user equipment device <b>300</b>, presents the media content in a main display portion <b>302</b> and a gallery <b>304</b> of images <b>306</b>, <b>308</b>, <b>310</b>, <b>312</b> showing video, still images or avatars of the users in the group.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>3</b>B</figref> depicts an example in which the display screen shown in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> is adapted based on the media content and/or additional content. The images <b>306</b>&#x2032;, <b>308</b>&#x2032;, <b>310</b>&#x2032;, <b>312</b>&#x2032; of users <b>1</b>-<b>4</b> have been adapted by adding backgrounds <b>312</b><i>a</i>, <b>312</b><i>b</i>, <b>312</b><i>c</i>, <b>312</b><i>d </i>associated with the media content. In this example, the backgrounds <b>312</b><i>a</i>, <b>312</b><i>b</i>, <b>312</b><i>c</i>, <b>312</b><i>d </i>show a crowd at a match, so that it appears as if the users are part of the crowd watching the match. This may give the users a greater degree of immersion in the media content.</p><p id="p-0037" num="0036">Also in the example of <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, the image <b>308</b>&#x2032; of one user, user <b>2</b>, is adapted with a video filter that adds to the image <b>308</b> a team badge <b>314</b> and beanie hat <b>316</b> associated with one of the teams, Team A, taking part in the match. These further adaptations may be based on user profile information of user <b>2</b> indicating that they support Team A, or a chat message or audio input from user <b>2</b> indicating their support for Team A. The filter may be applied in response to a determination that the match involves Team A, for example, based on metadata for the media content or closed caption data of the media content, where user's <b>2</b>'s support of Team A is known from user <b>2</b>'s profile in an interactive television application, social network, or social media posts by user <b>2</b>. The filter may be applied, or updated, in response to detecting keywords relating to Team A or Team A players extracted from chat or audio messages from user <b>2</b>, or triggered by a determination that a cheering pattern of user <b>2</b> gleaned from analyzing audio input from user <b>2</b> indicates that user <b>2</b> cheers in response to events favoring Team A.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of a process that may be performed by the control circuitry of the user equipment device <b>300</b> to adapt the images of one or more of users <b>1</b>-<b>4</b>. Beginning at step <b>400</b>, based on an instruction received from a user, for example, through the user input interface or a voice command, the control circuitry of the user equipment <b>300</b> causes the user equipment <b>300</b> to join a session (step <b>402</b>) of shared activity, such as a group watch session, multiplayer game session, videoconference, video call, audio call or message-based chat, and begins presenting the media content in that session. The session may be initiated by the control circuitry of the user equipment device <b>300</b> based on the instruction or, alternatively, the user equipment device <b>300</b> may join an existing group watch session initiated by another user.</p><p id="p-0039" num="0038">In the example shown in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, the user equipment device <b>300</b> is presenting a volleyball match to users <b>1</b>-<b>4</b> in a group watch session, and more than one user may be viewing the content at any one of the user equipment devices. A video of the user is captured through the camera and transmitted to the other user equipment devices connected to the group viewing session for display in the gallery <b>304</b> portion of their respective display screens. Alternatively, a still image or avatar of the user may be presented in the gallery <b>304</b>. Optionally, audio of the user may be captured through a microphone and transmitted to the other user equipment devices instead of, or as well as, the video of the first user <b>302</b>, to allow the users to converse with one another, and/or a message-based chat function may be provided.</p><p id="p-0040" num="0039">The control circuitry of the user equipment device <b>300</b> monitors the media content and/or additional content provided by the user during the session (step <b>404</b>). For example, the user equipment device <b>300</b> may monitor one or more of closed caption data, audio from the users or chat messages, parsing it to determine keywords associated with the media content and/or users. Alternatively, or additionally, the control circuitry of the user equipment device <b>300</b> may monitor metadata within or accompanying the media content to identify keywords relating to the content and/or events, tags or other markers indicating that the display of the media content is to be adapted, such as the beginning of a new scene in the media content or the beginning of a commercial.</p><p id="p-0041" num="0040">At step <b>406</b>, the control circuitry of the user equipment device <b>300</b> determines whether a trigger for adapting the display has been detected. The trigger may be an event within the media content, such as a point being won in the displayed volleyball match or the start of a new program or scene, a tag or marker or a keyword transmitted in metadata or closed caption data. Alternatively, the trigger may be an event in the additional content provided by the user, such as a keyword in audio or message-based chat. In yet another alternative embodiment, the trigger may simply be a time-based trigger, such as a preset time interval.</p><p id="p-0042" num="0041">If no trigger has been detected, then the control circuitry of the user equipment device <b>300</b> continues monitoring the content and/or additional content (step <b>404</b>) until a trigger is detected (step <b>406</b>) or the session ends (step <b>414</b>).</p><p id="p-0043" num="0042">If a trigger is detected (step <b>406</b>), then the control circuitry determines an adaptation to make to the display in the session (step <b>408</b>). For example, a tag in the media content detected at step <b>406</b> may also indicate a type of adaptation, such as a video background or filter, to apply to the images in the gallery <b>304</b>. Such a tag may include a location, such as a Universal Resource Locator, from which a background image or filter to be used in the adaptation may be retrieved, for example, from the content source <b>106</b>, or another remote server, via the communication network <b>108</b>. Alternatively, such a tag or marker may simply indicate a keyword such as a team name or location, and the control circuitry of the user equipment device <b>300</b> may conduct a search for suitable images or filters in its memory or stored at local or remote servers to find a corresponding image. In yet another embodiment, an image or filter may be transmitted to the user equipment device <b>300</b> alongside the media content. In a further embodiment, a tag, marker or metadata may indicate that some or all of a frame of the content is to be used as a video background and may include an indication of the frame and, optionally, the portion, to be used for this purpose.</p><p id="p-0044" num="0043">The selected adaptation is then applied to the user video, image, avatar or display profile (step <b>410</b>). The selected adaptation may be applied automatically by the control circuitry of the user equipment device <b>300</b>. Alternatively, the user equipment device <b>300</b> may generate for output a prompt for the user to confirm whether or not the selected adaptation should be applied. The user's response may be received via the user input interface, voice input via the microphone or a positive gesture, such as a &#x201c;thumbs up&#x201d; detected through gesture recognition performed on images captured by the camera.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts an example of determining an adaptation in which a portion of a frame of media content is selected for use as a background in step <b>408</b>. In this example, a tag or other metadata transmitted with, or alongside, the media content <b>502</b> identifies a frame, e.g., using a frame number or time stamp within the media content <b>502</b>, suitable for use as a video background in the gallery <b>504</b>. Optionally, the tag or metadata may identify a portion <b>514</b> of the frame of media content <b>502</b>, e.g., by specifying coordinates within the frame. The control circuitry of the user equipment device <b>300</b> may then determine that the adaptation is to be the use of that portion <b>514</b> of the frame as video backgrounds <b>512</b><i>a</i>-<b>512</b><i>d </i>in the images <b>506</b>&#x2032;, <b>508</b>&#x2032;, <b>510</b>&#x2032;, <b>512</b>&#x2032; of the users shown in the gallery <b>504</b>. In the example shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the frame of the media content <b>502</b> is a countryside scene, and a portion <b>514</b> showing the countryside is used as the video backgrounds <b>512</b><i>a</i>-<b>512</b><i>d</i>. In other embodiments, a similar background may be selected based on keywords such as &#x201c;country&#x201d;, &#x201c;countryside&#x201d; or &#x201c;rural&#x201d; extracted from closed caption data or metadata of the media content <b>502</b> or indicated in a tag within the media content <b>502</b>. In a similar manner, the crowd image used as in the backgrounds <b>312</b><i>a</i>-<i>d </i>shown in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref> could be portions of a frame of the media content <b>302</b>. The use of such backgrounds can provide a level of immersion in the media content for the participants in the session.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts another example in which a different image is used as the background. In this example, the media content <b>602</b> features an image of a car <b>614</b>, while the backgrounds <b>612</b><i>a</i>-<i>d </i>of the user images <b>606</b>&#x2032;, <b>608</b>&#x2032;, <b>610</b>&#x2032;, <b>612</b>&#x2032; show the users in the interior of the car. The image of the interior used as the backgrounds <b>612</b><i>a</i>-<i>d </i>may be transmitted to the user equipment device <b>300</b> alongside the media content <b>602</b> or retrieved from a location identified in a tag or metadata embedded in, or accompanying, the media content <b>602</b>. Such a background may provide a level of immersion, in a similar manner to the adaptations shown in <figref idref="DRAWINGS">FIGS. <b>3</b>B and <b>5</b></figref>. Alternatively, or additionally, such a background <b>612</b><i>a</i>-<i>d </i>may supplement the media content <b>602</b>. For instance, if the media content <b>602</b> is an advertisement for a car, the view of the car's interior provided by the backgrounds <b>612</b><i>a</i>-<i>d </i>may supplement the information provided by the advertisement.</p><p id="p-0047" num="0046">The adaptation may include a filter or other visual effect applied to a video, image or avatar of the user instead of, or as well as, a background. In the example shown in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, the adapted image <b>308</b>&#x2032; of user <b>2</b> includes both a filter, resulting in the display of the team badge <b>314</b> and beanie hat <b>316</b>, and a background <b>312</b><i>b</i>. Such filters and, optionally, backgrounds, may provide a level of immersion and/or opportunities for advertising items such as team merchandise or sponsors' products.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> depicts an example in which the session is an audio call received by user equipment device <b>700</b>. In this example, the control circuitry of the user equipment device <b>700</b> determines, at step <b>406</b>, an adaptation of an image <b>702</b> or avatar associated with one or more other participants in the audio call and may be based on their user profile information and/or subject matter in the audio call. For example, if user <b>1</b> were to speak about a skiing holiday, the user equipment device <b>700</b> may detect a keyword &#x201c;skiing&#x201d; in received audio data, obtain an image of mountains from a search of images stored at local and/or remote servers in step <b>406</b>. Then, in step <b>408</b>, the user equipment device <b>700</b> may display an adapted image <b>702</b>&#x2032; of user <b>1</b> that uses the obtained image as a background <b>704</b>, such as the image of mountains shown in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>. Alternatively, or additionally, the user equipment device <b>700</b> may search for image filters relevant to skiing in step <b>406</b>, such as a filter adding ski goggles <b>706</b> and a ski hat <b>708</b>, and display an adapted image <b>702</b>&#x2033; at step <b>408</b> in which that filter is applied, as shown in <figref idref="DRAWINGS">FIG. <b>7</b>C</figref>.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>8</b></figref> depicts a further example in which the shared activity is, or includes, message-based chat displayed by user equipment device <b>800</b>. In this case, an adjustment to an attribute of the display of the chat messages may be determined based on keywords in the chat at step <b>406</b> and that attribute adjusted at step <b>408</b>, for example, by adjusting the color, size or type of font used to display subsequent messages. In the example shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the keyword &#x201c;castle&#x201d; in a message <b>802</b> from user <b>1</b> has triggered an adaptation to display a subsequent message <b>804</b> from user <b>1</b> in a medieval style font.</p><p id="p-0050" num="0049">Returning to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the user equipment <b>300</b> may, optionally, transmit a message to some or all of the other user equipment devices (step <b>410</b>) that have joined the session so that a corresponding adaptation may be made to the user's video, image or avatar displayed by those other user equipment devices. For example, where Team A has scored a point in the volleyball match shown in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, a message requesting an adaptation that celebrates that point, such as a fireworks background, or a filter showing a message supporting Team A, may be sent to a sub-group of the users. In an alternative embodiment, such a message may be sent to all of the user equipment devices, and the user equipment devices may then determine whether or not to apply the adaptation based, for example, on user profile information of their respective user indicating whether or not they support Team A and/or confirmation provided by the respective user in response to a prompt. In some embodiments, the message may identify a file or location of a file containing audio or video data for display or may include the file itself. The message may be, or include, a JavaScript Object Notation (JSON) format file.</p><p id="p-0051" num="0050">The control circuitry then returns to the monitoring at step <b>404</b> until either another trigger is detected (step <b>406</b>) or the session finishes (step <b>414</b>), ending the process (step <b>416</b>).</p><p id="p-0052" num="0051">The foregoing description, for purposes of explanation, used specific nomenclature to provide a thorough understanding of the disclosure. However, it will be apparent to one skilled in the art that the specific details are not required to practice the methods and systems of the disclosure. For example, while many of the examples set out above refer to a group watch session, the methods and systems described may be used in other types of shared activity, such as a videocall, videoconference, multi-player game, screen-sharing session, audio call or message-based chat. The foregoing descriptions of specific embodiments of the present invention are, therefore, presented for purposes of illustration and description. They are not intended to be exhaustive or to limit the invention to the precise forms disclosed. Many modifications and variations are possible in view of the above teachings. The embodiments were chosen and described in order to best explain the principles of the invention and its practical applications, to thereby enable others skilled in the art to best utilize the methods and systems of the disclosure and various embodiments with various modifications as are suited to the particular use contemplated. Additionally, different features of the various embodiments, disclosed or otherwise, can be mixed and matched or otherwise combined so as to create further embodiments contemplated by the disclosure.</p><p id="p-0053" num="0000">This specification discloses embodiments which include, but are not limited to, the following:<br/>1. A method comprising:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0052">receiving, using control circuitry of a user equipment device, media content for display in a shared activity session;</li>        <li id="ul0002-0002" num="0053">receiving, using the control circuitry, additional content corresponding to respective users of one or more other user equipment devices participating in the shared activity session;</li>        <li id="ul0002-0003" num="0054">generating for display, using the control circuitry, a display screen including the media content and at least a portion of the additional content;</li>        <li id="ul0002-0004" num="0055">during the shared activity session, automatically adapting the display of the additional content, using the control circuitry, based on the media content and/or the additional content.<br/>2. The method of embodiment 1, wherein:</li>        <li id="ul0002-0005" num="0056">the additional content includes images corresponding to the users; and</li>        <li id="ul0002-0006" num="0057">adapting the display of the additional content comprises changing a background in the image of at least one of the users.<br/>3. The method of embodiment 2, wherein changing the background comprises:</li>        <li id="ul0002-0007" num="0058">selecting a frame of the media content; and</li>        <li id="ul0002-0008" num="0059">replacing a background in the image of said at least one of the users with at least a portion of the selected frame.<br/>4. The method of embodiment 1, wherein:</li>        <li id="ul0002-0009" num="0060">the additional content includes video images corresponding to the users; and</li>        <li id="ul0002-0010" num="0061">adapting the display of the additional content comprises applying a video filter to the video images of at least one of the users.<br/>5. The method of embodiment 1, wherein:</li>        <li id="ul0002-0011" num="0062">the additional content includes an avatar corresponding to at least of the users; and adapting the display of the additional content comprises applying a visual effect to the avatar corresponding to said at least one of the users and/or changing a display profile of said at least one of the users.<br/>6. The method of embodiment 1, wherein:</li>        <li id="ul0002-0012" num="0063">the shared activity session includes a message-based chat;</li>        <li id="ul0002-0013" num="0064">the additional content comprises a chat message from one of the users; and</li>        <li id="ul0002-0014" num="0065">adapting the display of the additional content comprises changing display attributes of the chat message from said one of the users.<br/>7. The method of embodiment 1, wherein automatically adapting the display of the additional content comprises:</li>        <li id="ul0002-0015" num="0066">selecting a visual effect based on the media content and/or metadata associated with the media content; and</li>        <li id="ul0002-0016" num="0067">generating for display the additional content with the visual effect applied thereto.<br/>8. The method of embodiment 1, wherein automatically adapting the display of the additional content comprises:</li>        <li id="ul0002-0017" num="0068">selecting a visual effect based on audio data or text data provided by one of the users during the shared activity session; and</li>        <li id="ul0002-0018" num="0069">generating for display the additional content with the visual effect applied thereto.<br/>9. The method of embodiment 1, wherein automatically adapting the display of the additional content comprises:</li>        <li id="ul0002-0019" num="0070">selecting a visual effect based on user profile information of at least one of the users; and</li>        <li id="ul0002-0020" num="0071">generating for display the additional content with the visual effect applied thereto.<br/>10. The method of embodiment 1, wherein the shared activity session is one of:</li>        <li id="ul0002-0021" num="0072">a group watch session, wherein the media content is live media content;</li>        <li id="ul0002-0022" num="0073">a group watch session, wherein the media content is on-demand media content;</li>        <li id="ul0002-0023" num="0074">a videoconference session;</li>        <li id="ul0002-0024" num="0075">a screen-sharing session;</li>        <li id="ul0002-0025" num="0076">a video call;</li>        <li id="ul0002-0026" num="0077">an audio call; or</li>        <li id="ul0002-0027" num="0078">a message-based chat session.<br/>11. A non-transitory computer readable medium on which are stored computer readable instructions to:</li>        <li id="ul0002-0028" num="0079">receive, using control circuitry of a user equipment device, media content for display in a shared activity session;</li>        <li id="ul0002-0029" num="0080">receive, using the control circuitry, additional content corresponding to respective users of one or more other user equipment devices participating in the shared activity session;</li>        <li id="ul0002-0030" num="0081">generate for display, using the control circuitry, a display screen including the media content and at least a portion of the additional content; and</li>        <li id="ul0002-0031" num="0082">during the shared activity session, automatically adapt the display of the additional content, using the control circuitry, based on the media content and/or additional content.<br/>12. The non-transitory computer-readable medium of embodiment 11, on which are stored further computer-readable instructions to adapt the display of the additional content by changing a background in an image corresponding to at least one of the users.<br/>13. The non-transitory computer-readable medium of embodiment 12, on which are stored further computer-readable instructions to change the background by:</li>        <li id="ul0002-0032" num="0083">selecting a frame of the media content; and</li>        <li id="ul0002-0033" num="0084">replacing a background in the image of said at least one of the users with at least a portion of the selected frame.<br/>14. The non-transitory computer-readable medium of embodiment 11, on which are stored further computer-readable instructions to adapt the display of the additional content by generating for display video images of at least one of the users with a video filter applied thereto.<br/>15. The non-transitory computer-readable medium of embodiment 11, on which are stored further computer-readable instructions to adapt the display of the additional content by generating for display an avatar corresponding to at least one of the users with a visual effect applied thereto and/or changing a display profile of said at least one of the users.<br/>16. The non-transitory computer-readable medium of embodiment 11, on which are stored further computer-readable instructions to adapt the display of the additional content by changing display attributes of a chat message from one of the users.<br/>17. The non-transitory computer-readable medium of embodiment 11, on which are stored further computer-readable instructions to adapt the display of the additional content by:</li>        <li id="ul0002-0034" num="0085">selecting a visual effect based on the media content and/or metadata associated with the media content; and</li>        <li id="ul0002-0035" num="0086">generating for display the additional content with the visual effect applied thereto.<br/>18. The non-transitory computer-readable medium of embodiment 11, on which are stored further computer-readable instructions to adapt the display of the additional content by:</li>        <li id="ul0002-0036" num="0087">selecting a visual effect based on audio data or text data provided by one of the users during the shared activity session; and</li>        <li id="ul0002-0037" num="0088">generating for display the additional content with the visual effect applied thereto.<br/>19. The non-transitory computer-readable medium of embodiment 11, on which are stored further computer-readable instructions to adapt the display of the additional content by:</li>        <li id="ul0002-0038" num="0089">selecting a visual effect based on user profile information of at least one of the users; and</li>        <li id="ul0002-0039" num="0090">generating for display the additional content with the visual effect applied thereto.<br/>20. An apparatus comprising:</li>        <li id="ul0002-0040" num="0091">a user equipment device comprising control circuitry configured to:        <ul id="ul0003" list-style="none">            <li id="ul0003-0001" num="0092">receive media content for display in a shared activity session;</li>            <li id="ul0003-0002" num="0093">receive additional content corresponding to respective users of one or more other user equipment devices participating in the shared activity session;</li>            <li id="ul0003-0003" num="0094">generate for display the media content and at least a portion of the additional content;</li>            <li id="ul0003-0004" num="0095">during the shared activity session, automatically adapt the display of the additional content based on the media content and/or the additional content.<br/>21. The apparatus of embodiment 20, wherein the control circuitry is configured to adapt the display of the additional content by changing a background in an image corresponding to at least one of the users.<br/>22. The apparatus of embodiment 21, wherein the control circuitry is configured to change the background by:</li>        </ul>        </li>        <li id="ul0002-0041" num="0096">selecting a frame of the media content; and</li>        <li id="ul0002-0042" num="0097">replacing a background in the image of said at least one of the users with at least a portion of the selected frame.<br/>23. The apparatus of embodiment 20, wherein the control circuitry is configured to adapt the display of the additional content by generating for display video images of at least one of the users with a video filter applied thereto.<br/>24. The apparatus of embodiment 20, wherein the control circuitry is configured to adapt the display of the additional content by generating for display an avatar corresponding to at least one of the users with a visual effect applied thereto and/or changing a display profile of said at least one of the users.<br/>25. The apparatus of embodiment 20, wherein the control circuitry is configured to adapt the display of the additional content by changing display attributes of a chat message from one of the users.<br/>26. The apparatus of embodiment 20, wherein the control circuitry is configured to adapt the display of the additional content by:</li>        <li id="ul0002-0043" num="0098">selecting a visual effect based on the media content and/or metadata associated with the media content; and</li>        <li id="ul0002-0044" num="0099">generating for display the additional content with the visual effect applied thereto.<br/>27. The apparatus of embodiment 20, wherein the control circuitry is configured to adapt the display of the additional content by:</li>        <li id="ul0002-0045" num="0100">selecting a visual effect based on audio data or text data provided by one of the users during the shared activity session; and</li>        <li id="ul0002-0046" num="0101">generating for display the additional content with the visual effect applied thereto.<br/>28. The apparatus of embodiment 20, wherein the control circuitry is configured to adapt the display of the additional content by:</li>        <li id="ul0002-0047" num="0102">selecting a visual effect based on user profile information of at least one of the users; and</li>        <li id="ul0002-0048" num="0103">generating for display the additional content with the visual effect applied thereto.<br/>29. A method comprising:</li>        <li id="ul0002-0049" num="0104">receiving, using the control circuitry of a user equipment device, media content for display in a shared activity session;</li>        <li id="ul0002-0050" num="0105">receiving, using the control circuitry, additional content corresponding to respective users of one or more other user equipment devices participating in the shared activity session;</li>        <li id="ul0002-0051" num="0106">generating for display, using control circuitry, a display screen including the media content and at least a portion of the additional content;</li>        <li id="ul0002-0052" num="0107">during the shared activity session, automatically adapting the display of the additional content using the control circuitry based on the media content and/or the additional content.<br/>30. The method of embodiment 29, wherein:</li>        <li id="ul0002-0053" num="0108">the additional content includes images corresponding to the users; and</li>        <li id="ul0002-0054" num="0109">adapting the display of the additional content comprises changing a background in the image of at least one of the users.<br/>31. The method of embodiment 30, wherein changing the background comprises:</li>        <li id="ul0002-0055" num="0110">selecting a frame of the media content; and</li>        <li id="ul0002-0056" num="0111">replacing a background in the image of said at least one of the users with at least a portion of the selected frame.<br/>32. The method of embodiment 29, 30, or 31, wherein:</li>        <li id="ul0002-0057" num="0112">the additional content includes video images corresponding to the users; and</li>        <li id="ul0002-0058" num="0113">adapting the display of the additional content comprises applying a video filter to the video images of at least one of the users.<br/>33. The method of embodiment 29, 30, or 31, wherein:</li>        <li id="ul0002-0059" num="0114">the additional content includes an avatar corresponding to at least one of the users; and</li>        <li id="ul0002-0060" num="0115">adapting the display of the additional content comprises applying a visual effect to the avatar corresponding to said at least one of the users and/or changing a display profile of said at least one of the users.<br/>34. The method of any of embodiments 29-33, wherein:</li>        <li id="ul0002-0061" num="0116">the shared activity session includes a message-based chat;</li>        <li id="ul0002-0062" num="0117">the additional content comprises a chat message from one of the users; and</li>        <li id="ul0002-0063" num="0118">adapting the display of the additional content comprises changing display attributes of the chat message from said one of the users.<br/>35. The method of any of embodiments 29-34, wherein automatically adapting the display of the additional content comprises:</li>        <li id="ul0002-0064" num="0119">selecting a visual effect based on the media content and/or metadata associated with the media content; and</li>        <li id="ul0002-0065" num="0120">generating for display the additional content with the visual effect applied thereto.<br/>36. The method of any of embodiments 29-34, wherein automatically adapting the display of the additional content comprises:</li>        <li id="ul0002-0066" num="0121">selecting a visual effect based on audio data or text data provided by one of the users during the shared activity session; and</li>        <li id="ul0002-0067" num="0122">generating for display the additional content with the visual effect applied thereto.<br/>37. The method of any of embodiments 29-34, wherein automatically adapting the display of the additional content comprises:</li>        <li id="ul0002-0068" num="0123">selecting a visual effect based on user profile information of at least one of the users; and</li>        <li id="ul0002-0069" num="0124">generating for display the additional content with the visual effect applied thereto.<br/>38. The method of any of embodiments 29-37, wherein the shared activity session is one of:</li>        <li id="ul0002-0070" num="0125">a group watch session, wherein the media content is live media content;</li>        <li id="ul0002-0071" num="0126">a group watch session, wherein the media content is on-demand media content;</li>        <li id="ul0002-0072" num="0127">a videoconference session;</li>        <li id="ul0002-0073" num="0128">a screen-sharing session;</li>        <li id="ul0002-0074" num="0129">a video call;</li>        <li id="ul0002-0075" num="0130">an audio call; or</li>        <li id="ul0002-0076" num="0131">a message-based chat session.<br/>39. A computer program comprising computer readable instructions that, when executed by one or more processors, causes the one or more processors to perform the method of any of embodiments 29-38.<br/>40. An apparatus comprising:</li>        <li id="ul0002-0077" num="0132">a user equipment device comprising:        <ul id="ul0004" list-style="none">            <li id="ul0004-0001" num="0133">means for receiving media content for display in a shared activity session;</li>            <li id="ul0004-0002" num="0134">means for receiving additional content corresponding to respective users of one or more other user equipment devices participating in the shared activity session;</li>            <li id="ul0004-0003" num="0135">means for generating for display the media content and at least a portion of the additional content;</li>            <li id="ul0004-0004" num="0136">means for, during the shared activity session, automatically adapting the display of the additional content based on the media content and/or the additional content.<br/>41. The apparatus of embodiment 40, wherein the means for automatically adapting the display of the additional content is configured to change a background in an image corresponding to at least one of the users.<br/>42. The apparatus of embodiment 41, wherein the means for automatically adapting the display is configured to change the background by:</li>        </ul>        </li>        <li id="ul0002-0078" num="0137">selecting a frame of the media content; and</li>        <li id="ul0002-0079" num="0138">replacing a background in the image of said at least one of the users with at least a portion of the selected frame.<br/>43. The apparatus of embodiment 40, 41, or 42, wherein the means for automatically adapting the display of the additional content is configured to generate for display video images of at least one of the users with a video filter applied thereto.<br/>44. The apparatus of any of embodiments 40-43, wherein the means for automatically adapting the display of the additional content is configured to generate for display an avatar corresponding to at least one of the users with a visual effect applied thereto and/or changing a display profile of said at least one of the users.<br/>45. The apparatus of any of embodiments 40-44, wherein the means for automatically adapting the display of the additional content is configured to change display attributes of a chat message from one of the users.<br/>46. The apparatus of any of embodiments 40-45, wherein the means for automatically adapting the display of the additional content is configured to adapt the display of the additional content by:</li>        <li id="ul0002-0080" num="0139">selecting a visual effect based on the media content and/or metadata associated with the media content; and</li>        <li id="ul0002-0081" num="0140">generating for display the additional content with the visual effect applied thereto.<br/>47. The apparatus of any of embodiments 40-45, wherein the means for automatically adapting the display of the additional content is configured to adapt the display of the additional content by:</li>        <li id="ul0002-0082" num="0141">selecting a visual effect based on audio data or text data provided by one of the users during the shared activity session; and</li>        <li id="ul0002-0083" num="0142">generating for display the additional content with the visual effect applied thereto.<br/>48. The apparatus of any of embodiments 40-45, wherein the means for automatically adapting the display of the additional content is configured to adapt the display of the additional content by:</li>        <li id="ul0002-0084" num="0143">selecting a visual effect based on user profile information of at least one of the users; and</li>        <li id="ul0002-0085" num="0144">generating for display the additional content with the visual effect applied thereto.</li>    </ul>    </li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method comprising:<claim-text>receiving, using control circuitry of a user equipment device, media content for display in a shared activity session;</claim-text><claim-text>receiving, using the control circuitry, additional content corresponding to respective users of one or more other user equipment devices participating in the shared activity session;</claim-text><claim-text>generating for display, using the control circuitry, a display screen including the media content and at least a portion of the additional content;</claim-text><claim-text>during the shared activity session, automatically adapting the display of the additional content, using the control circuitry, based on the media content and/or the additional content.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the additional content includes images corresponding to the users; and</claim-text><claim-text>adapting the display of the additional content comprises changing a background in the image corresponding to at least one of the users.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein changing the background comprises:<claim-text>selecting a frame of the media content; and</claim-text><claim-text>replacing a background in the image corresponding to said at least one of the users with at least a portion of the selected frame.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the additional content includes video images corresponding to the users; and</claim-text><claim-text>adapting the display of the additional content comprises applying a video filter to the video images of at least one of the users.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the additional content includes an avatar corresponding to at least one of the users; and</claim-text><claim-text>adapting the display of the additional content comprises applying a visual effect to the image corresponding to said at least one of the users and/or changing a display profile of said at least one of the users.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the shared activity session includes a message-based chat;</claim-text><claim-text>the additional content comprises a chat message from one of the users; and</claim-text><claim-text>adapting the display of the additional content comprises changing display attributes of the chat message from said one of the users.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein automatically adapting the display of the additional content comprises:<claim-text>selecting a visual effect based on the media content and/or metadata associated with the media content; and</claim-text><claim-text>generating for display the additional content with the visual effect applied thereto.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein automatically adapting the display of the additional content comprises:<claim-text>selecting a visual effect based on audio data or text data provided by one of the users during the shared activity session; and</claim-text><claim-text>generating for display the additional content with the visual effect applied thereto.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein automatically adapting the additional content comprises:<claim-text>selecting a visual effect based on user profile information of at least one of the users; and</claim-text><claim-text>generating for display the additional content with the visual effect applied thereto.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the shared activity session is one of:<claim-text>a group watch session, wherein the media content is live media content;</claim-text><claim-text>a group watch session, wherein the media content is on-demand media content;</claim-text><claim-text>a videoconference session;</claim-text><claim-text>a screen-sharing session;</claim-text><claim-text>a video call;</claim-text><claim-text>an audio call; or</claim-text><claim-text>a message-based chat session.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A non-transitory computer-readable medium on which is stored computer-readable instructions to:<claim-text>receive, using control circuitry of a user equipment device, media content for display in a shared activity session;</claim-text><claim-text>receive, using the control circuitry, additional content corresponding to respective users of one or more other user equipment devices participating in the shared activity session;</claim-text><claim-text>generate for display, using the control circuitry, a display screen including the media content and at least a portion of the additional content; and</claim-text><claim-text>during the shared activity session, automatically adapt the display of the additional content, using the control circuitry, based on the media content and/or additional content.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. An apparatus comprising:<claim-text>a user equipment device comprising control circuitry configured to:<claim-text>receive media content for display in a shared activity session;</claim-text><claim-text>receive additional content corresponding to respective users of one or more other user equipment devices participating in the shared activity session;</claim-text><claim-text>generate for display the media content and at least a portion of the additional content;</claim-text><claim-text>during the shared activity session, automatically adapt the display of the additional content based on the media content and/or the additional content.</claim-text></claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the control circuitry is configured to adapt the display of the additional content by changing a background in an image corresponding to at least one of the users.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the control circuitry is configured to change the background by:<claim-text>selecting a frame of the media content; and</claim-text><claim-text>replacing a background in the image of said at least one of the users with at least a portion of the selected frame.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the control circuitry is configured to adapt the display of the additional content by generating for display video images of at least one of the users with a video filter applied thereto.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the control circuitry is configured to adapt the display of the additional content by generating for display an avatar corresponding to at least one of the users with a visual effect applied thereto and/or changing a display profile of said at least one of the users.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the control circuitry is configured to adapt the display of the additional content by changing display attributes of a chat message from one of the users.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the control circuitry is configured to adapt the display of the additional content by:<claim-text>selecting a visual effect based on the media content and/or metadata associated with the media content; and</claim-text><claim-text>generating for display the additional content with the visual effect applied thereto.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the control circuitry is configured to adapt the display of the additional content by:<claim-text>selecting a visual effect based on audio data or text data provided by one of the users during the shared activity session; and</claim-text><claim-text>generating for display the additional content with the visual effect applied thereto.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the control circuitry is configured to adapt the display of the additional content by:<claim-text>selecting a visual effect based on user profile information of at least one of the users; and</claim-text><claim-text>generating for display the additional content with the visual effect applied thereto.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230001314A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230001314</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17854017</doc-number><date>20220630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2021-109860</doc-number><date>20210701</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>63</class><subclass>G</subclass><main-group>31</main-group><subgroup>16</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>63</class><subclass>G</subclass><main-group>31</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>62</class><subclass>J</subclass><main-group>45</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>62</class><subclass>K</subclass><main-group>11</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>63</class><subclass>G</subclass><main-group>31</main-group><subgroup>16</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>011</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>016</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>63</class><subclass>G</subclass><main-group>31</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200201</date></cpc-version-indicator><section>B</section><class>62</class><subclass>J</subclass><main-group>45</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20161101</date></cpc-version-indicator><section>B</section><class>62</class><subclass>K</subclass><main-group>11</main-group><subgroup>007</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">VIRTUAL EXPERIENCE PROVIDING SYSTEM, VIRTUAL EXPERIENCE PROVIDING METHOD, AND STORAGE MEDIUM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>HONDA MOTOR CO., LTD.</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Kobashi</last-name><first-name>Shinichiro</first-name><address><city>Wako-shi</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Sakamoto</last-name><first-name>Tomokazu</first-name><address><city>Wako-shi</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Iwakami</last-name><first-name>Hiroshi</first-name><address><city>Wako-shi</city><country>JP</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Yamaguchi</last-name><first-name>Shota</first-name><address><city>Wako-shi</city><country>JP</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Shikano</last-name><first-name>Naoto</first-name><address><city>Wako-shi</city><country>JP</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>Haneda</last-name><first-name>Satoshi</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A virtual experience providing system that provides a virtual experience in a virtual reality image based on a virtual world representing a real world or an artificial world to a user who rides a rideable mobile body includes a storage medium configured to store computer-readable instructions and a processor connected to the storage medium, the processor executing the computer-readable instructions to generate a basic movement command which is a movement command to the rideable mobile body based on a steering operation of the user and generate an event action command different from the basic movement command when a predetermined event has occurred in the virtual world, wherein the event action command is a command for causing the rideable mobile body to perform an event action that is predetermined according to the predetermined event.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="135.81mm" wi="117.43mm" file="US20230001314A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="147.57mm" wi="121.33mm" file="US20230001314A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="231.90mm" wi="155.96mm" orientation="landscape" file="US20230001314A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="217.93mm" wi="156.13mm" orientation="landscape" file="US20230001314A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="196.93mm" wi="82.72mm" orientation="landscape" file="US20230001314A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="197.44mm" wi="141.90mm" orientation="landscape" file="US20230001314A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="218.02mm" wi="159.09mm" orientation="landscape" file="US20230001314A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="218.27mm" wi="132.76mm" orientation="landscape" file="US20230001314A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">Priority is claimed on Japanese Patent Application No. 2021-109860, filed Jul. 1, 2021, the content of which is incorporated herein by reference.</p><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Field of the Invention</heading><p id="p-0003" num="0002">The present invention relates to a virtual experience providing system, a virtual experience providing method, and a storage medium.</p><heading id="h-0004" level="1">Description of Related Art</heading><p id="p-0004" num="0003">A technique for displaying content corresponding to a predetermined route of a mobile body in VR goggles when providing an amusement experience using the VR goggles is known in the related art (Published Japanese Translation No. 2017-522911 of the PCT International Publication).</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0005" num="0004">When a user has an experience including movement in the content of VR goggles, it may not be possible to realize the movement of a mobile body or perform an action associated with the content according to the user's intention, resulting in a lack of a sense of presence.</p><p id="p-0006" num="0005">Aspects of the present invention have been made in consideration of such circumstances and it is an object of the present invention to provide a virtual experience providing system, a virtual experience providing method, and a storage medium that can produce a sense of presence when providing a virtual experience to a user.</p><p id="p-0007" num="0006">The virtual experience providing system, the virtual experience providing method, and the storage medium according to the present invention have the following configurations.</p><p id="p-0008" num="0007">(1) A virtual experience providing system according to an aspect of the present invention is a virtual experience providing system that provides a virtual experience in a virtual reality image based on a virtual world representing a real world or an artificial world to a user who rides a rideable mobile body, the system including a storage medium configured to store computer-readable instructions and a processor connected to the storage medium, the processor executing the computer-readable instructions to generate a basic movement command which is a movement command to the rideable mobile body based on a steering operation of the user and generate an event action command different from the basic movement command when a predetermined event has occurred in the virtual world, wherein the event action command is a command for causing the rideable mobile body to perform an event action that is predetermined according to the predetermined event.</p><p id="p-0009" num="0008">(2) In the above aspect (1), the steering operation is performed according to movement of a center of gravity of the user and the processor generates the basic movement command based on the movement of the center of gravity detected using a sensor mounted on the rideable mobile body and generates a correction command for changing a relationship between the steering operation and the basic movement command as the event action command based on an environment in which the rideable mobile body is placed in the virtual world.</p><p id="p-0010" num="0009">(3) In the above aspect (1), the rideable mobile body has a function of moving the user up and down and the processor generates a command for an operation of moving the user up and down as the event action command.</p><p id="p-0011" num="0010">(4) In the above aspect (1), the rideable mobile body has a function of moving the user up and down and the processor generates a command for an operation of moving the user up and down as the basic movement command based on the steering operation of the user.</p><p id="p-0012" num="0011">(5) In the above aspect (1), the rideable mobile body includes a blower and the processor generates a command for an operation of activating the blower in response to a change in an environment in the virtual world as the event action command when a specific predetermined event has occurred.</p><p id="p-0013" num="0012">(6) In the above aspect (1), the processor generates a command for an operation of moving the rideable mobile body backward as the event action command when the predetermined event in which the user who rides the rideable mobile body collides with an object has occurred.</p><p id="p-0014" num="0013">(7) In the above aspect (1), the processor further operates the rideable mobile body based on both the basic movement command and the event action command.</p><p id="p-0015" num="0014">(8) In the above aspect (7), when causing the rideable mobile body to perform an operation based on both the basic movement command and the event action command, the processor generates an event action command for not performing an operation hindering an operation based on the basic movement command.</p><p id="p-0016" num="0015">(9) A virtual experience providing method according to another aspect of the present invention is a virtual experience providing method performed using at least one computer of a virtual experience providing system that provides a virtual experience in a virtual reality image based on a virtual world representing a real world or an artificial world to a user who rides a rideable mobile body, the method including generating a basic movement command which is a movement command to the rideable mobile body based on a steering operation of the user and generating an event action command different from the basic movement command when a predetermined event has occurred in the virtual world, wherein the event action command is a command for causing the rideable mobile body to perform an event action that is predetermined according to the predetermined event.</p><p id="p-0017" num="0016">(10) A storage medium according to another aspect of the present invention is a computer-readable non-transitory storage medium storing a program causing at least one computer of a virtual experience providing system, the system providing a virtual experience in a virtual reality image based on a virtual world representing a real world or an artificial world to a user who rides a rideable mobile body, to generate a basic movement command which is a movement command to the rideable mobile body based on a steering operation of the user and generate, when a predetermined event has occurred in the virtual world, an event action command for causing the rideable mobile body to perform an event action that is predetermined according to the predetermined event, the event action command being a command different from the basic movement command.</p><p id="p-0018" num="0017">According to the above aspects (1) to (10), it is possible to produce a sense of presence when providing a virtual experience to a user.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a configuration diagram of a virtual experience providing system of a first embodiment.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram for explaining the configuration and operation of an omnidirectional moving wheel of a rideable mobile body.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram of the rideable mobile body.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a configuration diagram of a content control device.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram schematically showing examples of predetermined events in a virtual world.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a configuration diagram of a rideable mobile body according to a modification of the first embodiment.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a configuration diagram of a rideable mobile body according to a second embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0026" num="0025">Hereinafter, embodiments of a virtual experience providing system, a virtual experience providing method, and a storage medium of the present invention will be described with reference to the drawings. The virtual experience providing system is, for example, a system that provides a virtual experience using a rideable mobile body which a user rides. The virtual experience providing system provides the user with a service for providing a virtual experience of a virtual world representing the real world or an artificial world. The virtual experience providing system can provide a virtual experience such as an unrealistic game world. This service is provided, for example, in a virtual experience facility. The virtual experience is, for example, an experience in which a user becomes a player in a game and participates in the game. The virtual experience facility is, for example, a facility having a traveling space in which the rideable mobile body travels. Hereinafter, a virtual experience may sometimes be referred to as content.</p><heading id="h-0008" level="1">First Embodiment</heading><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a configuration diagram of a virtual experience providing system <b>1</b> of a first embodiment. The virtual experience providing system <b>1</b> includes, for example, a rideable mobile body <b>100</b>, a head-mounted display <b>200</b>, and a content control device <b>300</b>. Of the rideable mobile body <b>100</b>, the head-mounted display <b>200</b>, and the content control device <b>300</b>, at least both the rideable mobile body <b>100</b> and the content control device <b>300</b> and both the head-mounted display <b>200</b> and the content control device <b>300</b> can communicate each other in a wireless manner or the like. The rideable mobile body <b>100</b> includes a base <b>110</b> and an omnidirectional moving wheel <b>120</b>.</p><p id="p-0028" num="0027">In the first embodiment, the rideable mobile body <b>100</b> is controlled such that it automatically travels, for example, as content provided by the head-mounted display <b>200</b> progresses. The rideable mobile body <b>100</b> also moves by balance control for a steering operation corresponding to movement of the center of gravity of the user P. That is, the rideable mobile body <b>100</b> moves according to both the progress of the content and the movement of the center of gravity of the user P. The content is preferably content having degrees of freedom to the extent that movements according to the intention of the user P are allowed. For example, in a scene in which the user P is to move forward in the flow of content, it is preferable that the content have degrees of freedom such that the rideable mobile body <b>100</b> decelerates or stops when the user P has performed a steering operation indicating the intention to &#x201c;move backward&#x201d; and the rideable mobile body <b>100</b> turns into a side road when the user P has performed a steering operation indicating the intention to &#x201c;turn left or right.&#x201d;</p><p id="p-0029" num="0028">The head-mounted display <b>200</b> is, for example, virtual reality (VR) goggles. The head-mounted display <b>200</b> receives data for displaying a virtual reality image (hereinafter referred to as content playback data) from the content control device <b>300</b> and displays the virtual reality image on its own display <b>210</b>. The head-mounted display <b>200</b> may be mixed reality (MR) goggles or augmented reality (AR) goggles. The method of realizing the head-mounted display <b>200</b> is not limited to a specific method as long as it allows the user P to perceive the same sense. For example, the projection method of the head-mounted display <b>200</b> may be a retinal projection method, a virtual image projection method, or another method. Further, for example, a display unit of the head-mounted display <b>200</b> may be of an open type or a shield type.</p><p id="p-0030" num="0029">The content control device <b>300</b> generates content data and transmits it to the head-mounted display <b>200</b>. The content control device <b>300</b> instructs the rideable mobile body <b>100</b> to operate in synchronization with the virtual reality image displayed on the head-mounted display <b>200</b>. By doing so, the rideable mobile body <b>100</b> can operate in conjunction with the virtual reality image displayed on the head-mounted display <b>200</b> and the user P can have a virtual experience as a player in the virtual reality image. The content control device <b>300</b> may be installed in a virtual experience facility or may be a cloud server that communicates via a network such as the Internet.</p><heading id="h-0009" level="2">Rideable Mobile Body</heading><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram for explaining the configuration and operation of the omnidirectional moving wheel <b>120</b> of the rideable mobile body <b>100</b>. The omnidirectional moving wheel <b>120</b> is a wheel that enables the vehicle to immediately advance in an arbitrary direction (in all directions of 360 degrees) from the current position without performing a preliminary operation such as turning. The omnidirectional moving wheel <b>120</b> includes, for example, a large-diameter wheel <b>120</b>A as a front wheel and a turning wheel <b>120</b>C as a rear wheel and has a plurality of small diameter wheels <b>120</b>B on a ground contact portion (a radially outer edge portion) of the large-diameter wheel <b>120</b>A which is the front wheel. The large-diameter wheel <b>120</b>A is a wheel that mainly realizes straight-ahead movement in the forward/backward direction. The small-diameter wheels <b>120</b>B are wheels that mainly realize lateral movement on the spot by rotating around the rotation direction (circumferential direction) of the large-diameter wheel <b>120</b>A as a rotation axis. On the other hand, the turning wheel <b>120</b>C which is the rear wheel has a smaller diameter than the large-diameter wheel <b>120</b>A and mainly realizes turning movement by rotating around a rotation axis orthogonal to the rotation axis of the large-diameter wheel <b>120</b>A. The omnidirectional moving wheel <b>120</b> includes motors (not shown) that can independently control the rotations of the large diameter wheel <b>120</b>A, the small diameter wheels <b>120</b>B, and the turning wheel <b>120</b>C. With such a configuration, the omnidirectional moving wheel <b>120</b> can realize not only movements in various directions such as just sideways and oblique but also agile movements such as turning in place and curving by using the difference in lateral movement speed between the front and rear wheels in addition to the forward/backward movement.</p><p id="p-0032" num="0031">Here, the forward direction of the rideable mobile body <b>100</b> is the positive direction of the y-axis in <figref idref="DRAWINGS">FIG. <b>1</b></figref> (the direction from the back to the front of the paper, which is hereinafter referred to as a +y-axis direction) and the backward direction is the negative direction of the y-axis (the direction from the front to the back of the paper, which is hereinafter referred to as a&#x2014;y-axis direction). For example, as shown in an operation example M<b>1</b> (forward or backward movement) of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the omnidirectional moving wheel <b>120</b> moves forward by rotating the large-diameter wheel <b>120</b>A in the direction of an arrow A<b>1</b> and moves backward by rotating the large-diameter wheel <b>120</b>A in the direction of an arrow A<b>2</b>.</p><p id="p-0033" num="0032">Further, as shown in an operation example M<b>2</b> (leftward or rightward movement) of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the omnidirectional moving wheel <b>120</b> can move to the left on the spot without changing the direction by rotating the small diameter wheels <b>120</b>B in the direction of an arrow A<b>3</b>. In this case, the turning wheel <b>120</b>C may be configured to rotate naturally in the direction of an arrow A<b>4</b> according to the movement in the leftward/rightward direction or may be controlled to rotate in the direction of the arrow A<b>4</b> according to the amount of rotation of the small diameter wheels <b>120</b>B. The omnidirectional moving wheel <b>120</b> can also move to the right on the spot without changing the direction by rotating the small diameter wheels <b>120</b>B in a direction opposite to the direction of the arrow A<b>3</b>. The leftward direction referred to here is the leftward direction in <figref idref="DRAWINGS">FIG. <b>1</b></figref> and corresponds to the negative direction of the x-axis (a &#x2212;x-axis direction) and the rightward direction is the rightward direction in <figref idref="DRAWINGS">FIG. <b>1</b></figref> and corresponds to the positive direction of the x-axis (a +x-axis direction). The plurality of small diameter wheels <b>120</b>B may be configured such that all the wheels rotate at the same time or may be configured such that only wheels at the ground contact portion rotate.</p><p id="p-0034" num="0033">As shown in an operation example M<b>3</b> (turning in place) of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the omnidirectional moving wheel <b>120</b> can turn in place in the direction of an arrow A<b>6</b> around a ground contact point P<b>1</b> of the large-diameter wheel <b>120</b>A as a center by rotating the turning wheel <b>120</b>C in the direction of an arrow A<b>5</b> and can turn in place in a direction opposite to the arrow A<b>6</b> by rotating in a direction opposite to the arrow A<b>5</b>.</p><p id="p-0035" num="0034">As shown in an operation example M<b>4</b> (cornering) of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the omnidirectional moving wheel <b>120</b> can move forward while turning in the direction of an arrow A<b>9</b> (can corner) by rotating the large-diameter wheel <b>120</b>A in the direction of an arrow A<b>7</b> and the turning wheel <b>120</b>C in the direction of an arrow A<b>8</b>. The omnidirectional moving wheel <b>120</b> can also move backward while turning in a direction opposite to the direction of the arrow A<b>9</b> by rotating the large-diameter wheel <b>120</b>A in a direction opposite to the direction of the arrow A<b>7</b> and the turning wheel <b>120</b>C in the direction of the arrow A<b>8</b>. In this example, the omnidirectional moving wheel <b>120</b> can also move forward or backward while keeping the turning center on the right side by rotating the turning wheel <b>120</b>C in a direction opposite to the arrow A<b>8</b>.</p><p id="p-0036" num="0035">The method of realizing the omnidirectional moving wheel <b>120</b> is not limited to the method of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The omnidirectional moving wheel <b>120</b> may be realized by any existing technique. Also, the rideable mobile body <b>100</b> may include one omnidirectional moving wheel <b>120</b> or may include a plurality of omnidirectional moving wheels <b>120</b>. Further, the rideable mobile body <b>100</b> may include an ordinary wheel(s) as an auxiliary wheel(s) in addition to the omnidirectional moving wheel <b>120</b>. The operation of the omnidirectional moving wheel <b>120</b> is controlled by a control unit (not shown) mounted in the rideable mobile body <b>100</b> (for example, installed in a seat <b>180</b>) and the control unit changes the operation (the moving direction and speed) of the omnidirectional moving wheel <b>120</b> based on a control signal input from the content control device <b>300</b>.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a configuration diagram of the rideable mobile body <b>100</b>. The rideable mobile body <b>100</b> includes, for example, a communication device <b>130</b>, a sensor <b>140</b>, and a control device <b>150</b> in the base <b>110</b>. The base <b>110</b> is provided with the seat <b>180</b>. The communication device <b>130</b> communicates with the content control device <b>300</b>. The communication device <b>130</b> performs wireless communication, for example, based on Wi-Fi, DSRC, Bluetooth (registered trademark), and other communication standards. The communication device <b>130</b> periodically transmits the amount of movement and position of the rideable mobile body <b>100</b> to the content control device <b>300</b> under the control of the control device <b>150</b>.</p><p id="p-0038" num="0037">The sensor <b>140</b> includes, for example, an acceleration sensor <b>142</b> and an angular velocity sensor <b>144</b>. The acceleration sensor <b>142</b> is attached to one or more arbitrary positions of the base <b>110</b> or the seat <b>180</b>, detects an acceleration acting at each attachment position, and outputs the acceleration to the control device <b>150</b>. Similarly, the angular velocity sensor <b>144</b> is attached to one or more arbitrary positions of the base <b>110</b> or the seat <b>180</b>, detects an angular velocity acting at each attachment position, and outputs the angular velocity to the control device <b>150</b>.</p><p id="p-0039" num="0038">The control device <b>150</b> includes, for example, a basic movement command generation unit <b>160</b>, an event action command generation unit <b>170</b>, and a motor control unit <b>175</b>. The basic movement command generation unit <b>160</b> includes, for example, a content action command generation unit <b>162</b>, a center of gravity estimation unit <b>164</b>, and a balance control unit <b>166</b>. These components are implemented, for example, by a hardware processor such as a central processing unit (CPU) executing a program (software). Some or all of these components may be implemented by hardware (including circuitry) such as large scale integration (LSI), an application specific integrated circuit (ASIC), a field-programmable gate array (FPGA), or a graphics processing unit (GPU) or may be implemented by software and hardware in cooperation. The program may be stored in a storage device (a storage device including a non-transitory storage medium) such as a hard disk drive (HDD) or a flash memory in advance or may be stored in a detachable storage medium (a non-transitory storage medium) such as a DVD or a CD-ROM and then installed in the storage device by mounting the storage medium in a drive device.</p><p id="p-0040" num="0039">The functions of each unit of the control device <b>150</b> will be described after the functions of the content control device <b>300</b> are described.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a configuration diagram of the content control device <b>300</b>. The content control device <b>300</b> includes, for example, a communication device <b>310</b>, a processing device <b>320</b>, and a storage unit <b>330</b>.</p><p id="p-0042" num="0041">The communication device <b>310</b> communicates with the rideable mobile body <b>100</b> and the head-mounted display <b>200</b>. A communication device may be integrated in either the rideable mobile body <b>100</b> or the head-mounted display <b>200</b>, and for example, the rideable mobile body <b>100</b> may appropriately transfer information received from the content control device <b>300</b> to the head-mounted display <b>200</b> by wire or wirelessly.</p><p id="p-0043" num="0042">The processing device <b>320</b> includes, for example, a content providing unit <b>322</b>, a content action notification unit <b>324</b>, and an event occurrence notification unit <b>326</b>. These components are implemented, for example, by a hardware processor such as a CPU executing a program (software). Some or all of these components may be implemented by hardware (including circuitry) such as LSI, an ASIC, an FPGA, or a GPU or may be implemented by software and hardware in cooperation. The program may be stored in a storage device (a storage device including a non-transitory storage medium) such as an HDD or a flash memory in advance or may be stored in a detachable storage medium (a non-transitory storage medium) such as a DVD or a CD-ROM and then installed in the storage device by mounting the storage medium in a drive device.</p><p id="p-0044" num="0043">The storage unit <b>330</b> is, for example, an HDD or a flash memory. Content data <b>332</b> is stored in the storage unit <b>330</b>. The content data <b>332</b> includes map information of a virtual world (including the positions of objects that are virtually present), basic movement information that determines the direction and speed at which the user P and the rideable mobile body <b>100</b> are to move in the virtual world with the passage of time, information on events that occur with the passage of time, information on events that occur according to the position where the user P and the rideable mobile body <b>100</b> are present in the virtual world (calculated by acquiring information from the rideable mobile body <b>100</b> as described above), progress schedule information of the content according to points earned according to the user P's actions in the virtual world, and the like.</p><p id="p-0045" num="0044">Using the communication device <b>310</b>, the content providing unit <b>322</b> transmits content playback data to the head-mounted display <b>200</b> based on the content data <b>332</b>. The content playback data may include audio data.</p><p id="p-0046" num="0045">The content action notification unit <b>324</b> transmits a content action synchronized with the content playback data to the rideable mobile body <b>100</b> using the communication device <b>310</b>. Content actions are, for example, instruction information such as that of instructions to move forward, move backward, stop, turn right, turn left, move to the right, and move to the left with a speed attached to each of them.</p><p id="p-0047" num="0046">The event occurrence notification unit <b>326</b> transmits an event occurrence notification to the rideable mobile body <b>100</b> using the communication device <b>310</b> at the timing when a predetermined event is to occur according to event information in the content data. Predetermined events are events with conditions of occurrence determined in advance such that they are to occur based on an environment in which the rideable mobile body is placed in the virtual world (which typically means the position, the elapsed time, or a combination thereof). The event occurrence notification is instruction information instructing the rideable mobile body <b>100</b> to generate a predetermined event and includes information instructing an operation of the rideable mobile body <b>100</b> such as swinging back and forth, swinging from side to side, movement (acceleration or deceleration) in a specific direction, or temporary stop.</p><p id="p-0048" num="0047">Hereinafter, the functions of each unit of the control device <b>150</b> of the rideable mobile body <b>100</b> will be described again. The content action command generation unit <b>162</b> of the basic movement command generation unit <b>160</b> generates a content action command based on a content action that the communication device <b>130</b> has received from the content control device <b>300</b>. The content action command appropriately controls the motors attached to the omnidirectional moving wheel <b>120</b> according to instruction information such as that of an instruction to move forward, move backward, stop, turn right, turn left, move to the right, or move to the left included in the content action. Specifically, the content action command contains information such as &#x201c;move in direction XX at speed AA&#x201d; or &#x201c;turn clockwise at speed XX.&#x201d; The content action command may also be represented in another measure such as acceleration. The content action command generation unit <b>162</b> outputs the content action command to the balance control unit <b>166</b>.</p><p id="p-0049" num="0048">The center of gravity estimation unit <b>164</b> estimates the center of gravity of an object including the user P, the base <b>110</b>, and the seat <b>180</b> based on the outputs of the acceleration sensor <b>142</b> and the angular velocity sensor <b>144</b>.</p><p id="p-0050" num="0049">The balance control unit <b>166</b> generates a control command with a direction for returning the position of the center of gravity estimated by the center of gravity estimation unit <b>164</b> to a reference position (a position of the center of gravity in a stationary state). For example, when the position of the center of gravity is biased to the right rear of the reference position, the balance control unit <b>166</b> generates information indicating acceleration toward the right rear as a control command. Further, the balance control unit <b>166</b> adjusts the control command such that the rideable mobile body <b>100</b> does not fall while realizing the behavior of the rideable mobile body <b>100</b> based on each of the content action command and the event action command. For example, when the content action command is for an accelerated forward movement and the position of the center of gravity is behind the reference position, the balance control unit <b>166</b> may suppress the acceleration to prevent the position of the center of gravity from being further biased backward by the accelerated forward movement or may start the accelerated forward movement after temporally moving the rideable mobile body <b>100</b> backward to adjust the position of the center of gravity forward. In the first embodiment, a part (component), which is based on both the center of gravity estimated by the center of gravity estimation unit <b>164</b> and the content action command, of the control command generated by the balance control unit <b>166</b> corresponds to a basic movement command.</p><p id="p-0051" num="0050">Then, the basic movement command generation unit <b>160</b> outputs the control command generated by the balance control unit <b>166</b> to the motor control unit <b>175</b>. The motor control unit <b>175</b> individually controls each motor attached to the omnidirectional moving wheel <b>120</b> based on the control command input from the basic movement command generation unit <b>160</b>.</p><p id="p-0052" num="0051">With such control, the user P can move the rideable mobile body <b>100</b> in a desired direction by changing his/her posture to move the center of gravity in a desired direction. That is, the rideable mobile body <b>100</b> recognizes the movement of the center of gravity of the user P as a steering operation for the rideable mobile body <b>100</b> and performs a moving operation according to the steering operation.</p><p id="p-0053" num="0052">The event action command generation unit <b>170</b> generates an event action command based on the event occurrence notification that the communication device <b>130</b> has received from the content control device <b>300</b>. The event action command of the first embodiment is information on a disturbance given to processing performed by the balance control unit <b>166</b>. For example, when the event occurrence notification indicates &#x201c;to swing back and forth,&#x201d; the event action command generation unit <b>170</b> corrects the position of the center of gravity estimated by the center of gravity estimation unit <b>164</b> such that the position of the center of gravity repeatedly changes back and forth at a predetermined cycle. Thereby, the basic movement command is corrected such that it includes an operation of swinging back and forth. Further, when the event occurrence notification is &#x201c;to suppress a forward movement due to a steering operation,&#x201d; the event action command generation unit <b>170</b> outputs an upper limit value of the forward speed to the balance control unit <b>166</b>. In this way, the event action command generation unit <b>170</b> generates a correction command for changing the relationship between the steering operation (movement of the center of gravity) and the basic movement command based on the environment (described above) in which the rideable mobile body <b>100</b> is placed in the virtual world as an event action command.</p><p id="p-0054" num="0053">An example of the relationship between examples of predetermined events in a virtual world and event action commands will be described below. <figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram schematically showing examples of predetermined events in a virtual world. For example, a rough road, an uphill, a suspension bridge, and a collision with another user P in the same virtual world are prepared as predetermined events.</p><p id="p-0055" num="0054">When the user P and the rideable mobile body <b>100</b> pass through a rough road in the virtual world, for example, an event occurrence notification indicating &#x201c;to swing back and forth&#x201d; is given. In response to this, the event action command generation unit <b>170</b> performs the processing described above. This can provide the user P with an experience as if he/she is actually driving on a rough road. When an event occurrence notification indicating &#x201c;to swing from side to side&#x201d; is given, the event action command generation unit <b>170</b> corrects the position of the center of gravity estimated by the center of gravity estimation unit <b>164</b> such that it repeatedly changes from side to side at a predetermined cycle.</p><p id="p-0056" num="0055">When the user P and the rideable mobile body <b>100</b> pass through an uphill in the virtual world, an event occurrence notification indicating, for example, &#x201c;to suppress a forward movement due to a steering operation&#x201d; is given. In response to this, for example, the event action command generation unit <b>170</b> suppresses the forward speed below usual when the position of the center of gravity estimated by the center of gravity estimation unit <b>164</b> is ahead of the reference position. For example, the event action command generation unit <b>170</b> sets the upper limit value of the forward speed lower as the slope of the uphill included in the event occurrence notification is larger and transmits the upper limit value to the balance control unit <b>166</b>. This can provide the user P with an experience in which the rideable mobile body <b>100</b> does not easily move forward on an uphill.</p><p id="p-0057" num="0056">When the user P and the rideable mobile body <b>100</b> pass through a suspension bridge in the virtual world, for example, an event occurrence notification indicating &#x201c;to restrict turning and leftward or rightward movement&#x201d; is given. In response to this, the event action command generation unit <b>170</b> corrects the position of the center of gravity estimated by the center of gravity estimation unit <b>164</b> to the reference position in the leftward/rightward direction even if the position of the center of gravity is biased to either the left or right from the reference position. This can provide the user P with an experience in which the rideable mobile body <b>100</b> cannot move to the left or right on a suspension bridge.</p><p id="p-0058" num="0057">When the user P and the rideable mobile body <b>100</b> collide with another user P in the virtual world, for example, an event occurrence notification indicating &#x201c;to move backward&#x201d; is given. In response to this, the event action command generation unit <b>170</b> forcibly corrects the position of the center of gravity estimated by the center of gravity estimation unit <b>164</b> sufficiently behind the reference position. This can provide the user P with an experience in which the rideable mobile body <b>100</b> temporarily moves backward due to a collision.</p><p id="p-0059" num="0058">With such control, the virtual experience providing system <b>1</b> can enhance the sense of presence when providing a virtual world experience.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a configuration diagram of a rideable mobile body <b>100</b>A according to a modification of the first embodiment. In the first embodiment, the rideable mobile body <b>100</b>A may include a seat actuator <b>182</b> that moves the seat <b>180</b> up and down with respect to the base <b>110</b> or tilts the seat <b>180</b> forward, backward, to the left, or to the right with respect to the base <b>110</b>. The rideable mobile body <b>100</b>A may also include a blower <b>146</b> that blows air to the head of the user P or the like. In this case, the control device <b>150</b> may perform control for swinging the seat <b>180</b> up and down or swinging (fluctuating) the forward, backward, leftward, and rightward tilt of the seat <b>180</b>, for example, when the user P and the rideable mobile body <b>100</b>A pass through a rough road in the virtual world. The control device <b>150</b> may also perform control for moving the seat <b>180</b> up with respect to the base <b>110</b>, for example, when the user P and the rideable mobile body <b>100</b>A have reached a place with a good view in the virtual world. The control device <b>150</b> may also activate the blower <b>146</b>, for example, when a scene where a strong wind blows (such as a coast, a mountainous area, or an encounter with a monster that blows breath) is set in the virtual world. Control signals for performing these operations are generated by the event action command generation unit <b>170</b> and transmitted to the seat actuator <b>182</b> and the blower <b>146</b>.</p><p id="p-0061" num="0060">The rideable mobile body <b>100</b>A of the first embodiment may also include an operation receiving unit that receives an operation of raising or lowering the seat <b>180</b>. In this case, the operation receiving unit may include a button or the like for receiving a raising or lowering instruction.</p><p id="p-0062" num="0061">According to the first embodiment described above, it is possible to produce a sense of presence when providing a virtual experience to the user P.</p><heading id="h-0010" level="1">Second Embodiment</heading><p id="p-0063" num="0062">Hereinafter, a second embodiment will be described. In the second embodiment, the rideable mobile body <b>100</b> may be provided with a moving mechanism (which is capable of at least moving forward, moving backward, and turning) other than the omnidirectional moving wheel <b>120</b> and thus it will be referred to as a moving mechanism <b>120</b>B in the following description and drawing.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a configuration diagram of a rideable mobile body <b>100</b>B of the second embodiment. The rideable mobile body <b>100</b>B of the second embodiment includes an operation receiving unit <b>190</b> in place of (or in addition to) the sensor <b>140</b>. The operation receiving unit <b>190</b> is, for example, a lever that can be operated back and forth and left and right and receives an instruction to accelerate when operated forth, an instruction to decelerate or move backward when operated back, and an instruction to turn when operated left or right. For example, the moving mechanism <b>120</b>B of the second embodiment includes a drive wheel and a steering wheel and is configured such that a drive motor and a brake device are attached to the drive wheel and a steering mechanism is attached to the steering wheel. Specific modes of the operation receiving unit <b>190</b> and the moving mechanism <b>120</b>B are not limited to these and any forms can be adopted. The operation receiving unit <b>190</b> may include that which receives an operation of raising and lowering a seat <b>180</b>. In this case, the operation receiving unit <b>190</b> may include a button or the like for receiving a raising and lowering instruction. The blower <b>146</b> has any configuration and may be omitted.</p><p id="p-0065" num="0064">The rideable mobile body <b>100</b>B of the second embodiment is not limited to those that move somewhat freely on a plane and may be one that runs on rails laid in a virtual experience facility. In this case, the operation receiving unit <b>190</b> may be that which exclusively receives an instruction to accelerate and an instruction to decelerate or move backward.</p><p id="p-0066" num="0065">A basic movement command generation unit <b>160</b>B of the second embodiment physically integrates a content action command based on the content action received from the content control device <b>300</b> and a control command for acceleration, deceleration, or turning based on an operation received by the operation receiving unit <b>190</b> to generate a basic movement command.</p><p id="p-0067" num="0066">An event action command generated by an event action command generation unit <b>170</b>B of the second embodiment includes some or all of an instruction for a seat actuator <b>182</b>, an instruction for a blower <b>146</b>, and a correction command for the basic movement command. For example, when an event occurrence notification indicating &#x201c;to swing back and forth&#x201d; is given, the event action command generation unit <b>170</b>B instructs the seat actuator <b>182</b> to swing (fluctuate) the forward and backward tilt of the seat <b>180</b>. When an event occurrence notification indicating &#x201c;to suppress a forward movement due to a steering operation&#x201d; is given, the event action command generation unit <b>170</b>B may instruct the seat actuator <b>182</b> to tilt the seat <b>180</b> backward to give the user P a feeling that it is difficult to move forward in a pseudo manner or may output an instruction to decelerate to a motor control unit <b>175</b> as a correction command for the basic movement command. When an event occurrence notification indicating &#x201c;to restrict turning&#x201d; is given, the event action command generation unit <b>170</b>B may output an instruction to suppress turning as a correction command for the basic movement command to the motor control unit <b>175</b>. When an event occurrence notification indicating &#x201c;to move backward&#x201d; is given, the event action command generation unit <b>170</b>B may output a correction command for cancelling a moving forward command and instructing to move backward as a correction command for the basic movement command to the motor control unit <b>175</b>. Regarding the &#x201c;strong wind,&#x201d; the second embodiment is similar to the modification of the first embodiment (of <figref idref="DRAWINGS">FIG. <b>6</b></figref>). In the second embodiment, regarding &#x201c;to swing back and forth&#x201d; or &#x201c;to swing from side to side,&#x201d; the event action command generation unit <b>170</b>B may swing (fluctuate) the driving force and braking force of the moving mechanism <b>120</b>B or swing (fluctuate) the steering angle from side to side to achieve swinging back and forth or from side to side.</p><p id="p-0068" num="0067">In the second embodiment, when performing an operation based on a basic movement command and an operation based on an event action command in parallel, the control device <b>150</b>B may generate an event action command for not performing an operation hindering the operation based on the basic movement command That is, when an instruction from the user P received by the operation receiving unit <b>190</b> is to accelerate, decelerate, or turn, the event action command may be limited to swinging, tilting, or the like of the seat <b>180</b> that does not interfere with the acceleration, deceleration, or turning.</p><p id="p-0069" num="0068">According to the second embodiment described above, it is possible to produce a sense of presence when providing the virtual experience to the user P, similar to the first embodiment.</p><p id="p-0070" num="0069">Although the mode for carrying out the present invention has been described above by way of embodiments, the present invention is not limited to these embodiments at all and various modifications and substitutions may be made without departing from the spirit of the present invention.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A virtual experience providing system that provides a virtual experience in a virtual reality image based on a virtual world representing a real world or an artificial world to a user who rides a rideable mobile body, the system comprising:<claim-text>a storage medium configured to store computer-readable instructions; and</claim-text><claim-text>a processor connected to the storage medium, the processor executing the computer-readable instructions to:</claim-text><claim-text>generate a basic movement command which is a movement command to the rideable mobile body based on a steering operation of the user; and</claim-text><claim-text>generate an event action command different from the basic movement command when a predetermined event has occurred in the virtual world,</claim-text><claim-text>wherein the event action command is a command for causing the rideable mobile body to perform an event action that is predetermined according to the predetermined event.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The virtual experience providing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the steering operation is performed according to movement of a center of gravity of the user, and</claim-text><claim-text>the processor generates the basic movement command based on the movement of the center of gravity detected using a sensor mounted on the rideable mobile body and generates a correction command for changing a relationship between the steering operation and the basic movement command as the event action command based on an environment in which the rideable mobile body is placed in the virtual world.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The virtual experience providing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the rideable mobile body has a function of moving the user up and down, and</claim-text><claim-text>the processor generates a command for an operation of moving the user up and down as the event action command.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The virtual experience providing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the rideable mobile body has a function of moving the user up and down, and</claim-text><claim-text>the processor generates a command for an operation of moving the user up and down as the basic movement command based on the steering operation of the user.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The virtual experience providing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the rideable mobile body includes a blower, and</claim-text><claim-text>the processor generates a command for an operation of activating the blower in response to a change in an environment in the virtual world as the event action command when a specific predetermined event has occurred.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The virtual experience providing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the processor generates a command for an operation of moving the rideable mobile body backward as the event action command when the predetermined event in which the user who rides the rideable mobile body collides with an object has occurred.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The virtual experience providing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the processor further operates the rideable mobile body based on both the basic movement command and the event action command.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The virtual experience providing system according to <claim-ref idref="CLM-00007">claim 7</claim-ref>,<claim-text>wherein, when causing the rideable mobile body to perform an operation based on both the basic movement command and the event action command, the processor generates an event action command for not performing an operation hindering an operation based on the basic movement command.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A virtual experience providing method performed using at least one computer of a virtual experience providing system that provides a virtual experience in a virtual reality image based on a virtual world representing a real world or an artificial world to a user who rides a rideable mobile body, the method comprising:<claim-text>generating a basic movement command which is a movement command to the rideable mobile body based on a steering operation of the user; and</claim-text><claim-text>generating an event action command different from the basic movement command when a predetermined event has occurred in the virtual world,</claim-text><claim-text>wherein the event action command is a command for causing the rideable mobile body to perform an event action that is predetermined according to the predetermined event.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A computer-readable non-transitory storage medium storing a program causing at least one computer of a virtual experience providing system, the system providing a virtual experience in a virtual reality image based on a virtual world representing a real world or an artificial world to a user who rides a rideable mobile body, to:<claim-text>generate a basic movement command which is a movement command to the rideable mobile body based on a steering operation of the user; and</claim-text><claim-text>generate, when a predetermined event has occurred in the virtual world, an event action command for causing the rideable mobile body to perform an event action that is predetermined according to the predetermined event, the event action command being a command different from the basic movement command.</claim-text></claim-text></claim></claims></us-patent-application>
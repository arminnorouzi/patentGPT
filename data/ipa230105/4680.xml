<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004681A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004681</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17930326</doc-number><date>20220907</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>75</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>31</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>79</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>75</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>31</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>79</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>2221</main-group><subgroup>2103</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SECURE PUF-BASED DEVICE AUTHENTICATION USING ADVERSARIAL CHALLENGE SELECTION</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17132387</doc-number><date>20201223</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11455431</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17930326</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Intel Corporation</orgname><address><city>Santa Clara</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Suresh</last-name><first-name>Vikram</first-name><address><city>Portland</city><state>OR</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Kumar</last-name><first-name>Raghavan</first-name><address><city>Hillsboro</city><state>OR</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Mathew</last-name><first-name>Sanu</first-name><address><city>Portland</city><state>OR</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Intel Corporation</orgname><role>02</role><address><city>Santa Clara</city><state>CA</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method comprises generating, during an enrollment process conducted in a controlled environment, a dark bit mask comprising a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device, and using at least a portion of the plurality of state information values to generate a set of challenge-response pairs for use in an authentication process for the electronic device.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="190.25mm" wi="122.43mm" file="US20230004681A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="209.97mm" wi="124.46mm" file="US20230004681A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="218.10mm" wi="168.91mm" orientation="landscape" file="US20230004681A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="235.71mm" wi="127.93mm" file="US20230004681A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="214.04mm" wi="156.72mm" orientation="landscape" file="US20230004681A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="240.62mm" wi="128.19mm" file="US20230004681A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="221.66mm" wi="153.50mm" orientation="landscape" file="US20230004681A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="190.84mm" wi="138.60mm" file="US20230004681A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="184.07mm" wi="152.91mm" orientation="landscape" file="US20230004681A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="218.19mm" wi="152.91mm" orientation="landscape" file="US20230004681A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="232.49mm" wi="159.77mm" file="US20230004681A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CLAIM TO PRIORITY</heading><p id="p-0002" num="0001">This Application is a continuation of and claims the benefit of and priority to U.S. application Ser. No. 17/132,387, entitled SECURE PUF-BASED DEVICE AUTHENTICATION USING ADVERSARIAL CHALLENGE SELECTION, by Vikram Suresh, et al., filed Dec. 23, 2020, the entire contents of which are incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Physically Unclonable Functions (PUFs) are emerging as attractive solutions for low-cost device authentication which does not require computationally expensive public key cryptography. PUFs harness manufacturing process variations to provide a unique device-specific response for a given input (known as challenge) to enable authentication over an insecure communication channel. A class of PUFs commonly referred to as a &#x201c;strong PUF&#x201d; provides an exponentially large number of Challenge-Response pairs (CRPs). This ensures a given CRP is used only once to eliminate the risk of replay attacks, while still supporting a large number of authentications per device. Although PUF CRPs are used only once to avoid replay attacks, a sophisticated malicious attacker can monitor the challenge response pairs and use machine learning or neural network models to learn the behavior of the PUF. A predictive model can then be used to clone a device, even if previously unused challenges are used for authentication.</p><p id="p-0004" num="0003">Early PUF designs based on delay chains and ring oscillators were easily modelled using support vector machine and logistic regression. More sophisticated PUFs with non-linear behavior are still vulnerable to modelling attacks using genetic algorithm and deep neural network. Thus, additional PUF-based authentication techniques may find utility, e.g., in secure computing applications.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0005" num="0004">The concepts described herein are illustrated by way of example and not by way of limitation in the accompanying figures. For simplicity and clarity of illustration, elements illustrated in the figures are not necessarily drawn to scale. Where considered appropriate, reference labels have been repeated among the figures to indicate corresponding or analogous elements.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a simplified schematic diagram of an example system including an authentication system in accordance with an embodiment.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a simplified block diagram illustrating generation of a multi-voltage/multi-temperature dark-bit mask in accordance with an embodiment.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> is a simplified data flow diagram of at least one embodiment of a method for secure PUF-based authentication using adversarial challenge selection according to an embodiment.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>3</b>B</figref> is a simplified block diagram of at least one embodiment of a method for secure PUF-based authentication using adversarial challenge selection according to an embodiment.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is a simplified data flow diagram of at least one embodiment of a method for secure PUF-based authentication using adversarial challenge selection according to an embodiment.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> is a simplified block diagram of at least one embodiment of a method for secure PUF-based authentication using adversarial challenge selection according to an embodiment.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a simplified block diagram of a non-linear cascaded PUF architecture according to an embodiment.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a simplified diagram of at least one embodiment of a configurable cross-coupled inverter according to an embodiment.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is an illustration of a model attack using a 128-bit PUF, according to an embodiment.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram illustrating a computing architecture which may be adapted to provide a method for secure PUF-based authentication using adversarial challenge selection according to an embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE DRAWINGS</heading><p id="p-0016" num="0015">While the concepts of the present disclosure are susceptible to various modifications and alternative forms, specific embodiments thereof have been shown by way of example in the drawings and will be described herein in detail. It should be understood, however, that there is no intent to limit the concepts of the present disclosure to the particular forms disclosed, but on the contrary, the intention is to cover all modifications, equivalents, and alternatives consistent with the present disclosure and the appended claims.</p><p id="p-0017" num="0016">References in the specification to &#x201c;one embodiment,&#x201d; &#x201c;an embodiment,&#x201d; &#x201c;an illustrative embodiment,&#x201d; etc., indicate that the embodiment described may include a particular feature, structure, or characteristic, but every embodiment may or may not necessarily include that particular feature, structure, or characteristic. Moreover, such phrases are not necessarily referring to the same embodiment. Further, when a particular feature, structure, or characteristic is described in connection with an embodiment, it is submitted that it is within the knowledge of one skilled in the art to effect such feature, structure, or characteristic in connection with other embodiments whether or not explicitly described. Additionally, it should be appreciated that items included in a list in the form of &#x201c;at least one A, B, and C&#x201d; can mean (A); (B); (C); (A and B); (A and C); (B and C); or (A, B, and C) Similarly, items listed in the form of &#x201c;at least one of A, B, or C&#x201d; can mean (A); (B); (C); (A and B); (A and C); (B and C); or (A, B, and C).</p><p id="p-0018" num="0017">The disclosed embodiments may be implemented, in some cases, in hardware, firmware, software, or any combination thereof. The disclosed embodiments may also be implemented as instructions carried by or stored on a transitory or non-transitory machine-readable (e.g., computer-readable) storage medium, which may be read and executed by one or more processors. A machine-readable storage medium may be embodied as any storage device, mechanism, or other physical structure for storing or transmitting information in a form readable by a machine (e.g., a volatile or non-volatile memory, a media disc, or other media device). In the drawings, some structural or method features may be shown in specific arrangements and/or orderings. However, it should be appreciated that such specific arrangements and/or orderings may not be required. Rather, in some embodiments, such features may be arranged in a different manner and/or order than shown in the illustrative figures. Additionally, the inclusion of a structural or method feature in a particular figure is not meant to imply that such feature is required in all embodiments and, in some embodiments, may not be included or may be combined with other features.</p><p id="p-0019" num="0018">As described above, physically unclonable functions (PUFs) are emerging as attractive solutions for low-cost device authentication which does not require computationally expensive public key cryptography. PUFs harness manufacturing process variations to provide a unique device-specific response for a given input (known as challenge) to enable authentication over an insecure communication channel. A class of PUFs commonly referred to as a &#x201c;strong PUF&#x201d; provides an exponentially large number of Challenge-Response pairs (CRPs). This ensures a given CRP is used only once to eliminate the risk of replay attacks, while still supporting a large number of authentications per device. Although PUF CRPs are used only once to avoid replay attacks, a sophisticated malicious attacker can monitor the challenge response pairs and use machine learning or neural network models to learn the behavior of the PUF. A predictive model can then be used to clone a device, even if previously unused challenges are used for authentication.</p><p id="p-0020" num="0019">Early PUF designs based on delay chains and ring oscillators were easily modelled using support vector machine and logistic regression. More sophisticated PUFs with non-linear behavior are still vulnerable to modelling attacks using genetic algorithm and deep neural network.</p><p id="p-0021" num="0020">To address these and other issues, described herein are two stability-based adversarial challenge selection techniques which are rendered resistant to model-based attacks by (i) using unstable CRPs during device authentication to force an attacker to train the model on inaccurate responses and/or (ii) using unstable CRPs as part of the authentication requirement by requiring a specific portion of device responses to be incorrect. Techniques described herein utilize a stability-aware adversarial challenge selection process. During an enrollment process, the PUF device is characterized across a range of voltage and temperature values to identify unstable CRPs. These unstable CRPs are used during authentication to (i) to disrupt the machine learning model of an attacker; or (ii) increase the complexity of modelling by requiring incorrect responses as part of authentication.</p><p id="p-0022" num="0021">Techniques described herein utilize the native instability of PUF circuits to improve resistance to machine-language (ML) based attack. No additional changes to the PUF circuit(s) are required, and response reliability is not degraded. Since the PUF characterization happens during the enrollment phase, there is no additional cost involved at the edge device to improve ML-based attack resistance. The overhead of stability-aware challenge selection may be managed by the resourceful authentication server. Furthermore, the proposed techniques are agnostic to PUF architecture and entropy source, making them extremely versatile for PUF-based authentication.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a simplified schematic diagram of an example system <b>100</b> including an authentication system in accordance with an embodiment. Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in some examples, system <b>100</b> comprises an edge device <b>110</b> which is communicatively coupled to an authentication server <b>130</b>. A detailed description of components of an authentication server <b>130</b> is provided with reference to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, below.</p><p id="p-0024" num="0023">In some examples, edge device <b>110</b> an electronic device such as a one or more components of a computing system. In other examples, edge device <b>110</b> may comprise an electronically activatable device such as an integrated circuit that is to be mounted on a credit card, identification card, or the like. Edge device <b>110</b> comprises one or more physically unclonable functions (PUFs) such as a non-linear cascaded PUF <b>115</b>. A more detailed description of PUF <b>115</b> is provided with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref>, below.</p><p id="p-0025" num="0024">During the course of an enrollment process, authentication server <b>130</b> generates a large number of records including CRPs for each device that is enrolled with the authentication server. In the example depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the authentication server <b>130</b> generates a first device record <b>132</b>A that comprises a first challenge <b>134</b>A stored in logical association with a first response <b>136</b>A, a second challenge <b>134</b>B stored in logical association with a second response <b>136</b>B, and so on up to an Nth challenge <b>134</b>N stored in logical association with an Nth response <b>136</b>N. A second device record <b>132</b>B contains a similar set of CRPs for the second device, and so on up to an Nth device record contains a similar set of CRPs for the Nth device. In subsequent authentication processes, the authentication server <b>130</b> uses the CRPs for a device to securely authenticate the device without the need for computationally expensive public key cryptography, i.e., over an insecure communication channel.</p><p id="p-0026" num="0025">In some examples, PUF devices may be constructed using delay chains, SRAM bitcells, or cross-coupled inverters as an entropy source. While the enrollment process is conducted in a controlled environment, the authentication process may take place in an uncontrolled environment which exhibits a wide range of voltage and/or temperature conditions. This variation in the operating environment introduces error in the responses generated on the PUF device, resulting in mismatch with a locally computed golden value generated under standardized conditions. In the adversarial challenge technique, this native instability in the PUF response may be harnessed to inhibit ML-based attacks.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a simplified block diagram illustrating generation of a multi-voltage/multi-temperature dark-bit mask in accordance with an embodiment. In some examples, during PUF enrollment, a dark-bit (DB) mask is generated at a variety of different voltages and/or temperatures. The DB masks at different temperatures and/or voltages are combined to generate a single multi-voltage/temperature dark-bit mask for each PUF device. Each cell in the bitmask represents an entropy source which may be implemented using, e.g., delay chains, SRAM bitcells, or cross-coupled inverters as an entropy source.</p><p id="p-0028" num="0027">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in one example a first dark bitmask <b>210</b>A may be generated at a first temperature of zero degrees Celsius (0&#xb0; C.), a second dark bitmask <b>210</b>B may be generated at a second temperature of 25 degrees Celsius (25&#xb0; C.), and a third dark bitmask <b>210</b>C may be generated at a third temperature of 100 degrees Celsius (100&#xb0; C.). In some examples the three dark bitmasks <b>210</b>A, <b>210</b>B, <b>210</b>C may comprise state information that indicates whether a challenge-response pair (CRP) generated from the value of any given cell in the PUF device is stable at the given temperature and/or voltage or whether the CRP is unstable at the given temperature and/or voltage. In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, cells which produce stable CRP values are indicated as blank cells while cells which produce unstable CRP values are indicated with diagonal shading. The three dark bitmasks <b>210</b>A, <b>210</b>B, <b>210</b>C may be combined to generate a multi-temperature dark bitmask <b>220</b>. During PUF authentication, this multi-voltage/temperature dark-bit mask <b>220</b> may be for adversarial challenge selection using techniques described in <figref idref="DRAWINGS">FIGS. <b>3</b>A-<b>3</b>B</figref> and <figref idref="DRAWINGS">FIGS. <b>4</b>A-<b>4</b>B</figref>.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIGS. <b>3</b>A-<b>3</b>B</figref> illustrate a technique <b>300</b> which implements adversarial challenge selection in which CRPs which produce unstable responses are rejected, i.e., not used in the authentication process. <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> is a simplified data flow diagram of at least one embodiment of a method <b>30</b> for secure PUF-based authentication using adversarial challenge selection according to an embodiment. <figref idref="DRAWINGS">FIG. <b>3</b>B</figref> is a simplified block diagram of at least one embodiment of a method for secure PUF-based authentication using adversarial challenge selection according to an embodiment.</p><p id="p-0030" num="0029">Referring to <figref idref="DRAWINGS">FIGS. <b>3</b>A-<b>3</b>B</figref>, at operation <b>310</b> a dark bit mask is generated during an enrollment process. In some examples the dark bit mask comprises a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device. In some examples this dark bitmask <b>220</b> may be generated as described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0031" num="0030">At operation <b>315</b> at least a portion of the plurality of state information values in the dark bitmask <b>220</b> are used to generate a set of challenge-response pairs for use in an authentication process for the electronic device. In some examples at least a portion of the state information values of the dark bitmask <b>220</b> are input to a stability aware adversarial challenge selection process <b>350</b>, which generates a set of challenges [C<sub>n</sub>, C<sub>n&#x2212;1 </sub>. . . C<sub>3</sub>, C<sub>2</sub>, C<sub>1</sub>, C<sub>0</sub>] that includes state information from entropy sources that generate stable responses and from entropy sources that generate unstable responses. Thus, at operation <b>320</b> a set of state information values from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device are selected for use in an authentication procedure (operation <b>325</b>). In some examples, the set of challenges [C<sub>n</sub>, C<sub>n&#x2212;1 </sub>. . . C<sub>3</sub>, C<sub>2</sub>, C<sub>1</sub>, C<sub>0</sub>] is used by the authentication server to generate (operation <b>330</b>) a corresponding set of responses [R<sub>n</sub>, R<sub>n&#x2212;1 </sub>. . . R<sub>3</sub>, R<sub>2</sub>, R<sub>1</sub>, R<sub>0</sub>] to generate challenge-response pairs (CRPs) that include both stable CRPs and unstable CRPs.</p><p id="p-0032" num="0031">In some examples only the challenge-response pairs (CRPs) that originated from entropy sources that generate a stable response are used in the authentication process. Thus, at operation <b>335</b> the authentication server uses, in the authentication process, only a subset of the challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device. Referring to <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, at decision box <b>352</b> the authentication server determines whether a particular challenge is a stable challenge, i.e., if it generates a stable response. If a particular challenge is stable, then the authentication server <b>130</b> uses the response for authentication. By contrast, if the challenge is not stable then the authentication server <b>130</b> discards the response and does not use it for authentication.</p><p id="p-0033" num="0032">As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, a malicious actor attempting to snoop into the CRP exchange between the PUF device <b>360</b> and the authentication server <b>130</b> cannot distinguish between a challenge that generates a stable response and a challenge that generates an unstable response. Thus, the malicious actor will train the predictive model generated by the machine language deep neural network <b>120</b> using both stable challenges and unstable challenges, which significantly impedes the predictive model from generating useful results.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIGS. <b>4</b>A-<b>4</b>B</figref> illustrate a technique <b>400</b> which implements adversarial challenge selection in which CRPs which produce unstable responses are utilized in the authentication process. <figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is a simplified data flow diagram of at least one embodiment of a method for secure PUF-based authentication using adversarial challenge selection according to an embodiment. <figref idref="DRAWINGS">FIG. <b>4</b>B</figref> is a simplified block diagram of at least one embodiment of a method for secure PUF-based authentication using adversarial challenge selection according to an embodiment.</p><p id="p-0035" num="0034">Referring to <figref idref="DRAWINGS">FIGS. <b>4</b>A-<b>4</b>B</figref>, at operation <b>410</b> a dark bit mask is generated during an enrollment process. In some examples the dark bit mask comprises a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device. In some examples this dark bitmask <b>220</b> may be generated as described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0036" num="0035">At operation <b>415</b> at least a portion of the plurality of state information values in the dark bitmask <b>220</b> are used to generate a set of challenge-response pairs for use in an authentication process for the electronic device. In some examples at least a portion of the state information values of the dark bitmask <b>220</b> are input to a stability aware adversarial challenge selection process <b>450</b>, which generates a set of challenges [C<sub>n</sub>, C<sub>n&#x2212;1 </sub>. . . C<sub>3</sub>, C<sub>2</sub>, C<sub>1</sub>, C<sub>0</sub>] that includes state information from entropy sources that generate stable responses and from entropy sources that generate unstable responses. Thus, at operation <b>420</b> a set of state information values from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device are selected for use in an authentication procedure (operation <b>425</b>). In some examples, the set of challenges [C<sub>n</sub>, C<sub>n&#x2212;1 </sub>. . . C<sub>3</sub>, C<sub>2</sub>, C<sub>1</sub>, C<sub>0</sub>] is used by the authentication server to generate (operation <b>330</b>) a corresponding set of responses [R<sub>n</sub>, R<sub>n&#x2212;1 </sub>. . . R<sub>3</sub>, R<sub>2</sub>, R<sub>1</sub>, R<sub>0</sub>] to generate challenge-response pairs (CRPs) that include both stable CRPs and unstable CRPs.</p><p id="p-0037" num="0036">In some examples the authentication process uses the challenge-response pairs (CRPs) that originated from entropy sources that generate a stable response and CRPs that originated from entropy sources that generate an unstable response. Thus, at operation <b>435</b> the authentication server uses, in the authentication process, challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device. Referring to <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>, at decision box <b>452</b> the authentication server determines whether a particular challenge is a stable challenge, i.e., if it generates a stable response.</p><p id="p-0038" num="0037">In some examples the authentication protocol may be adapted to require a pre-determined percentage (if not all) of the responses that result from an unstable CRPs to not match with the golden response in order to pass authentication. As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>, a malicious actor attempting to snoop into the CRP exchange between the PUF device <b>460</b> and the authentication server <b>130</b> cannot distinguish between a challenge that generates a stable response and a challenge that generates an unstable response. Since the unstable responses are also used for authentication, the malicious actor will need to model not just the stable behavior of the PUF, but also the unstable behavior across a large operating range, which significantly impedes the predictive model from generating useful results.</p><p id="p-0039" num="0000">Instead of ignoring all challenges that are stable/unstable only in few operating conditions, in some examples the authentication server may also select challenges from a non-overlapping group of unstable challenges. For instance, the server may choose a challenge C<b>1</b> (and a corresponding response R<b>1</b>) that is stable at 25&#xb0; C., but unstable at 100&#xb0; C. It can also choose a second challenge C<b>2</b> (and a corresponding response R<b>2</b>) that is unstable at 25&#xb0; C., but stable at 100&#xb0; C. So, depending on the operating temperature on the in-field PUF device, either R<b>1</b> is stable or R<b>2</b> is stable. It is not expected that both R<b>1</b>, R<b>2</b> are stable or both R<b>1</b>, R<b>2</b> are unstable. This adds an additional characteristic for an attacker to learn, making modelling attacks more challenging.</p><p id="p-0040" num="0038"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a simplified block diagram of a non-linear cascaded PUF <b>500</b> architecture according to an embodiment. Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, in one example the non-linear cascaded PUF <b>500</b> consists of a first stage <b>510</b> of <b>64</b> entropy sources (ES1<sub>63</sub>, ES1<sub>62 </sub>. . . , ES1<sub>32</sub>, ES1<sub>31 </sub>. . . ES1<sub>0</sub>) and a second stage <b>530</b> of <b>64</b> entropy sources (ES2<sub>63</sub>, ES2<sub>62 </sub>. . . , ES2<sub>32</sub>, ES2<sub>31 </sub>. . . ES2<sub>0</sub>) cascaded via a non-linear transformation <b>520</b>. In the example depicted in <figref idref="DRAWINGS">FIG. <b>5</b></figref> the non-linear transformation may be implemented using an advanced encryption standard (AES) substitute-box (Sbox) operation. The input challenge bits (CH) configure the entropy source in the first stage <b>510</b>. The output of the first stage <b>510</b> is non-linearly transformed by the non-linear transformation <b>520</b> before being applied as the challenge to the second stage <b>530</b>.</p><p id="p-0041" num="0039">In one example the entropy source may comprise cross-coupled inverter-pair with two configurable NMOS legs and two configurable clock delays. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a simplified diagram of at least one embodiment of a configurable cross-coupled inverter <b>600</b> according to an embodiment. In some examples, two challenge bits are used to generate one-hot select signals to enable one of the NMOS legs in each inverter, while two additional challenge bits select the delay cell on the clock path, providing 16 unique response bits per entropy source.</p><p id="p-0042" num="0040"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is an illustration <b>700</b> of a model attack using a 128-bit PUF, according to an embodiment. Modelling attack was performed using a 6-layer DNN with 4096 neurons per layer on a scaled down version of the PUF with 16, 24 and 32-bit challenges, where adversarial challenge selection with response rejection showed 4&#xd7; increase in modelling complexity. Attack on the full 128-bit PUF using DNN, Support Vector Machine, Logistic Regression and Evolution Strategy shows that adversarial challenge selection with response rejection limits prediction accuracy to 50%, which is approximately equivalent to a random guess.</p><heading id="h-0005" level="1">Exemplary Computing Architecture</heading><p id="p-0043" num="0041"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram illustrating a computing architecture which may be adapted to implement a secure address translation service using a permission table (e.g., HPT <b>135</b> or HPT <b>260</b>) and based on a context of a requesting device in accordance with some examples. The embodiments may include a computing architecture supporting one or more of (i) verification of access permissions for a translated request prior to allowing a memory operation to proceed; (ii) prefetching of page permission entries of an HPT responsive to a translation request; and (iii) facilitating dynamic building of the HPT page permissions by system software as described above.</p><p id="p-0044" num="0042">In various embodiments, the computing architecture <b>800</b> may comprise or be implemented as part of an electronic device. In some embodiments, the computing architecture <b>800</b> may be representative, for example, of a computer system that implements one or more components of the operating environments described above. In some embodiments, computing architecture <b>800</b> may be representative of one or more portions or components in support of a secure address translation service that implements one or more techniques described herein.</p><p id="p-0045" num="0043">As used in this application, the terms &#x201c;system&#x201d; and &#x201c;component&#x201d; and &#x201c;module&#x201d; are intended to refer to a computer-related entity, either hardware, a combination of hardware and software, software, or software in execution, examples of which are provided by the exemplary computing architecture <b>800</b>. For example, a component can be, but is not limited to being, a process running on a processor, a processor, a hard disk drive or solid state drive (SSD), multiple storage drives (of optical and/or magnetic storage medium), an object, an executable, a thread of execution, a program, and/or a computer. By way of illustration, both an application running on a server and the server can be a component. One or more components can reside within a process and/or thread of execution, and a component can be localized on one computer and/or distributed between two or more computers. Further, components may be communicatively coupled to each other by various types of communications media to coordinate operations. The coordination may involve the unidirectional or bi-directional exchange of information. For instance, the components may communicate information in the form of signals communicated over the communications media. The information can be implemented as signals allocated to various signal lines. In such allocations, each message is a signal. Further embodiments, however, may alternatively employ data messages. Such data messages may be sent across various connections. Exemplary connections include parallel interfaces, serial interfaces, and bus interfaces.</p><p id="p-0046" num="0044">The computing architecture <b>800</b> includes various common computing elements, such as one or more processors, multi-core processors, co-processors, memory units, chipsets, controllers, peripherals, interfaces, oscillators, timing devices, video cards, audio cards, multimedia input/output (I/O) components, power supplies, and so forth. The embodiments, however, are not limited to implementation by the computing architecture <b>800</b>.</p><p id="p-0047" num="0045">As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the computing architecture <b>800</b> includes one or more processors <b>802</b> and one or more graphics processors <b>808</b>, and may be a single processor desktop system, a multiprocessor workstation system, or a server system having a large number of processors <b>802</b> or processor cores <b>807</b>. In on embodiment, the system <b>800</b> is a processing platform incorporated within a system-on-a-chip (SoC or SOC) integrated circuit for use in mobile, handheld, or embedded devices.</p><p id="p-0048" num="0046">An embodiment of system <b>800</b> can include, or be incorporated within, a server-based gaming platform, a game console, including a game and media console, a mobile gaming console, a handheld game console, or an online game console. In some embodiments system <b>800</b> is a mobile phone, smart phone, tablet computing device or mobile Internet device. Data processing system <b>800</b> can also include, couple with, or be integrated within a wearable device, such as a smart watch wearable device, smart eyewear device, augmented reality device, or virtual reality device. In some embodiments, data processing system <b>800</b> is a television or set top box device having one or more processors <b>802</b> and a graphical interface generated by one or more graphics processors <b>808</b>.</p><p id="p-0049" num="0047">In some embodiments, the one or more processors <b>802</b> each include one or more processor cores <b>807</b> to process instructions which, when executed, perform operations for system and user software. In some embodiments, each of the one or more processor cores <b>807</b> is configured to process a specific instruction set <b>814</b>. In some embodiments, instruction set <b>809</b> may facilitate Complex Instruction Set Computing (CISC), Reduced Instruction Set Computing (RISC), or computing via a Very Long Instruction Word (VLIW). Multiple processor cores <b>807</b> may each process a different instruction set <b>809</b>, which may include instructions to facilitate the emulation of other instruction sets. Processor core <b>807</b> may also include other processing devices, such a Digital Signal Processor (DSP).</p><p id="p-0050" num="0048">In some embodiments, the processor <b>802</b> includes cache memory <b>804</b>. Depending on the architecture, the processor <b>802</b> can have a single internal cache or multiple levels of internal cache. In some embodiments, the cache memory is shared among various components of the processor <b>802</b>. In some embodiments, the processor <b>802</b> also uses an external cache (e.g., a Level-3 (L3) cache or Last Level Cache (LLC)) (not shown), which may be shared among processor cores <b>807</b> using known cache coherency techniques. A register file <b>806</b> is additionally included in processor <b>802</b> which may include different types of registers for storing different types of data (e.g., integer registers, floating point registers, status registers, and an instruction pointer register). Some registers may be general-purpose registers, while other registers may be specific to the design of the processor <b>802</b>.</p><p id="p-0051" num="0049">In some embodiments, one or more processor(s) <b>802</b> are coupled with one or more interface bus(es) <b>810</b> to transmit communication signals such as address, data, or control signals between processor <b>802</b> and other components in the system. The interface bus <b>810</b>, in one embodiment, can be a processor bus, such as a version of the Direct Media Interface (DMI) bus. However, processor buses are not limited to the DMI bus, and may include one or more Peripheral Component Interconnect buses (e.g., PCI, PCI Express), memory buses, or other types of interface buses. In one embodiment the processor(s) <b>802</b> include an integrated memory controller <b>816</b> and a platform controller hub <b>830</b>. The memory controller <b>816</b> facilitates communication between a memory device and other components of the system <b>800</b>, while the platform controller hub (PCH) <b>830</b> provides connections to I/O devices via a local I/O bus.</p><p id="p-0052" num="0050">Memory device <b>820</b> can be a dynamic random-access memory (DRAM) device, a static random-access memory (SRAM) device, flash memory device, phase-change memory device, or some other memory device having suitable performance to serve as process memory. In one embodiment the memory device <b>820</b> can operate as system memory for the system <b>800</b>, to store data <b>822</b> and instructions <b>821</b> for use when the one or more processors <b>802</b> execute an application or process. Memory controller hub <b>816</b> also couples with an optional external graphics processor <b>812</b>, which may communicate with the one or more graphics processors <b>808</b> in processors <b>802</b> to perform graphics and media operations. In some embodiments a display device <b>811</b> can connect to the processor(s) <b>802</b>. The display device <b>811</b> can be one or more of an internal display device, as in a mobile electronic device or a laptop device or an external display device attached via a display interface (e.g., DisplayPort, etc.). In one embodiment the display device <b>811</b> can be a head mounted display (HMD) such as a stereoscopic display device for use in virtual reality (VR) applications or augmented reality (AR) applications.</p><p id="p-0053" num="0051">In some embodiments the platform controller hub <b>830</b> enables peripherals to connect to memory device <b>820</b> and processor <b>802</b> via a high-speed I/O bus. The I/O peripherals include, but are not limited to, an audio controller <b>846</b>, a network controller <b>834</b>, a firmware interface <b>828</b>, a wireless transceiver <b>826</b>, touch sensors <b>825</b>, a data storage device <b>824</b> (e.g., hard disk drive, flash memory, etc.). The data storage device <b>824</b> can connect via a storage interface (e.g., SATA) or via a peripheral bus, such as a Peripheral Component Interconnect bus (e.g., PCI, PCI Express). The touch sensors <b>825</b> can include touch screen sensors, pressure sensors, or fingerprint sensors. The wireless transceiver <b>826</b> can be a Wi-Fi transceiver, a Bluetooth transceiver, or a mobile network transceiver such as a 3G, 4G, Long Term Evolution (LTE), or 5G transceiver. The firmware interface <b>828</b> enables communication with system firmware, and can be, for example, a unified extensible firmware interface (UEFI). The network controller <b>834</b> can enable a network connection to a wired network. In some embodiments, a high-performance network controller (not shown) couples with the interface bus <b>810</b>. The audio controller <b>846</b>, in one embodiment, is a multi-channel high definition audio controller. In one embodiment the system <b>800</b> includes an optional legacy I/O controller <b>840</b> for coupling legacy (e.g., Personal System 2 (PS/2)) devices to the system. The platform controller hub <b>830</b> can also connect to one or more Universal Serial Bus (USB) controllers <b>842</b> connect input devices, such as keyboard and mouse <b>843</b> combinations, a camera <b>844</b>, or other USB input devices.</p><p id="p-0054" num="0052">The following clauses and/or examples pertain to further embodiments or examples. Specifics in the examples may be used anywhere in one or more embodiments. The various features of the different embodiments or examples may be variously combined with some features included and others excluded to suit a variety of different applications. Examples may include subject matter such as a method, means for performing acts of the method, at least one machine-readable medium including instructions that, when performed by a machine cause the machine to perform acts of the method, or of an apparatus or system for facilitating hybrid communication according to embodiments and examples described herein.</p><p id="p-0055" num="0053">Example 1 is method comprising generating, during an enrollment process conducted in a controlled environment, a dark bit mask comprising a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device and using at least a portion of the plurality of state information values to generate a set of challenge-response pairs for use in an authentication process for the electronic device.</p><p id="p-0056" num="0054">Example 2 includes the subject matter of Example 1, wherein the plurality of entropy sources comprises at least one of one or more delay chains, one or more static random access memory (SRAM) memory bitcells, or one or more cross-coupled inverters.</p><p id="p-0057" num="0055">Example 3 includes the subject matter of Examples 1-2, wherein the plurality of operating conditions comprises at least one of one or more operating voltages, one or more operating temperatures, or one or more age-related parameters.</p><p id="p-0058" num="0056">Example 4 includes the subject matter of Examples 1-3, further comprising selecting, from the plurality of state information values, a set of state information values from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device, and using the set of challenge-response pairs in an authentication procedure for the electronic device.</p><p id="p-0059" num="0057">Example 5 includes the subject matter of Examples 1-4, wherein the authentication procedure generates a set of challenge-response pairs from the set of state information values, and uses, in the authentication process, only a subset of the challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device.</p><p id="p-0060" num="0058">Example 6 includes the subject matter of Examples 1-5, wherein the authentication procedure generates a set of challenge-response pairs from the set of state information values; and uses, in the authentication process, challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device.</p><p id="p-0061" num="0059">Example 7 includes the subject matter of Examples 1-6 wherein authentication procedure requires that at least a portion of the challenge-response pairs generated include a generated response that does not match an expected response.</p><p id="p-0062" num="0060">Example 8 is an apparatus, comprising a processor; and a computer readable memory comprising instructions which, when executed by the processor, cause the processor to generate, during an enrollment process conducted in a controlled environment, a dark bit mask comprising a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device and use at least a portion of the plurality of state information values to generate a set of challenge-response pairs for use in an authentication process for the electronic device.</p><p id="p-0063" num="0061">Example 9 includes the subject matter of Example 8, wherein the plurality of entropy sources comprises at least one of one or more delay chains, one or more static random access memory (SRAM) memory bitcells, or one or more cross-coupled inverters.</p><p id="p-0064" num="0062">Example 10 includes the subject matter of Examples 8-9, wherein the plurality of operating conditions comprises at least one of one or more operating voltages, one or more operating temperatures, or one or more age-related parameters.</p><p id="p-0065" num="0063">Example 11 includes the subject matter of Examples 8-10, select, from the plurality of state information values, a set of state information values from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device, and use the set of challenge-response pairs in an authentication procedure for the electronic device.</p><p id="p-0066" num="0064">Example 12 includes the subject matter of Examples 8-11, further comprising instructions which, when executed by the processor, cause the processor to generate a set of challenge-response pairs from the set of state information values; and use, in the authentication process, only a subset of the challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device.</p><p id="p-0067" num="0065">Example 13 includes the subject matter of Examples 8-12, the computer readable memory comprising instructions which, when executed by the processor, cause the processor to generate a set of challenge-response pairs from the set of state information values; and use, in the authentication process, challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device</p><p id="p-0068" num="0066">Example 14 includes the subject matter of Examples 8-13, wherein authentication procedure requires that at least a portion of the challenge-response pairs generated include a generated response that does not match an expected response.</p><p id="p-0069" num="0067">Example 15 is one or more computer-readable storage media comprising instructions stored thereon that, in response to being executed, cause a computing device to generate, during an enrollment process conducted in a controlled environment, a dark bit mask comprising a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device and use at least a portion of the plurality of state information values to generate a set of challenge-response pairs for use in an authentication process for the electronic device.</p><p id="p-0070" num="0068">Example 16 includes the subject matter of Examples 13-15, wherein the plurality of entropy sources comprises at least one of one or more delay chains, one or more static random access memory (SRAM) memory bitcells, or one or more cross-coupled inverters.</p><p id="p-0071" num="0069">Example 17 includes the subject matter of Examples 15-16, wherein the plurality of operating conditions comprises at least one of one or more operating voltages, one or more operating temperatures, or one or more age-related parameters.</p><p id="p-0072" num="0070">Example 18 includes the subject matter of Examples 15-17, further comprising instructions stored thereon that, in response to being executed, cause the computing device to select, from the plurality of state information values, a set of state information values from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device; and use the set of challenge-response pairs in an authentication procedure for the electronic device.</p><p id="p-0073" num="0071">Example 19 includes the subject matter of Examples 15-18, further comprising instructions stored thereon that, in response to being executed, cause the computing device to generate a set of challenge-response pairs from the set of state information values; and use, in the authentication process, only a subset of the challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device.</p><p id="p-0074" num="0072">Example 20 includes the subject matter of Examples 15-19, further comprising instructions stored thereon that, in response to being executed, cause the computing device to generate a set of challenge-response pairs from the set of state information values; and use, in the authentication process, challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device.</p><p id="p-0075" num="0073">Example 21 includes the subject matter of Examples 15-20, wherein authentication procedure requires that at least a portion of the challenge-response pairs generated include a generated response that does not match an expected response.</p><p id="p-0076" num="0074">In the description above, for the purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the described embodiments. It will be apparent, however, to one skilled in the art that embodiments may be practiced without some of these specific details. In other instances, well-known structures and devices are shown in block diagram form. There may be intermediate structure between illustrated components. The components described or illustrated herein may have additional inputs or outputs that are not illustrated or described.</p><p id="p-0077" num="0075">Various embodiments may include various processes. These processes may be performed by hardware components or may be embodied in computer program or machine-executable instructions, which may be used to cause a general-purpose or special-purpose processor or logic circuits programmed with the instructions to perform the processes. Alternatively, the processes may be performed by a combination of hardware and software.</p><p id="p-0078" num="0076">Portions of various embodiments may be provided as a computer program product, which may include a computer-readable medium having stored thereon computer program instructions, which may be used to program a computer (or other electronic devices) for execution by one or more processors to perform a process according to certain embodiments. The computer-readable medium may include, but is not limited to, magnetic disks, optical disks, read-only memory (ROM), random access memory (RAM), erasable programmable read-only memory (EPROM), electrically-erasable programmable read-only memory (EEPROM), magnetic or optical cards, flash memory, or other type of computer-readable medium suitable for storing electronic instructions. Moreover, embodiments may also be downloaded as a computer program product, wherein the program may be transferred from a remote computer to a requesting computer.</p><p id="p-0079" num="0077">Many of the methods are described in their most basic form, but processes can be added to or deleted from any of the methods and information can be added or subtracted from any of the described messages without departing from the basic scope of the present embodiments. It will be apparent to those skilled in the art that many further modifications and adaptations can be made. The particular embodiments are not provided to limit the concept but to illustrate it. The scope of the embodiments is not to be determined by the specific examples provided above but only by the claims below.</p><p id="p-0080" num="0078">If it is said that an element &#x201c;A&#x201d; is coupled to or with element &#x201c;B,&#x201d; element A may be directly coupled to element B or be indirectly coupled through, for example, element C. When the specification or claims state that a component, feature, structure, process, or characteristic A &#x201c;causes&#x201d; a component, feature, structure, process, or characteristic B, it means that &#x201c;A&#x201d; is at least a partial cause of &#x201c;B&#x201d; but that there may also be at least one other component, feature, structure, process, or characteristic that assists in causing &#x201c;B.&#x201d; If the specification indicates that a component, feature, structure, process, or characteristic &#x201c;may&#x201d;, &#x201c;might&#x201d;, or &#x201c;could&#x201d; be included, that particular component, feature, structure, process, or characteristic is not required to be included. If the specification or claim refers to &#x201c;a&#x201d; or &#x201c;an&#x201d; element, this does not mean there is only one of the described elements.</p><p id="p-0081" num="0079">An embodiment is an implementation or example. Reference in the specification to &#x201c;an embodiment,&#x201d; &#x201c;one embodiment,&#x201d; &#x201c;some embodiments,&#x201d; or &#x201c;other embodiments&#x201d; means that a particular feature, structure, or characteristic described in connection with the embodiments is included in at least some embodiments, but not necessarily all embodiments. The various appearances of &#x201c;an embodiment,&#x201d; &#x201c;one embodiment,&#x201d; or &#x201c;some embodiments&#x201d; are not necessarily all referring to the same embodiments. It should be appreciated that in the foregoing description of exemplary embodiments, various features are sometimes grouped together in a single embodiment, figure, or description thereof for the purpose of streamlining the disclosure and aiding in the understanding of one or more of the various novel aspects. This method of disclosure, however, is not to be interpreted as reflecting an intention that the claimed embodiments requires more features than are expressly recited in each claim. Rather, as the following claims reflect, novel aspects lie in less than all features of a single foregoing disclosed embodiment. Thus, the claims are hereby expressly incorporated into this description, with each claim standing on its own as a separate embodiment.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method comprising:<claim-text>using at least a portion of a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device to generate a set of challenge-response pairs for use in an authentication process for the electronic device;</claim-text><claim-text>selecting, from the plurality of state information values, a set of state information values from one or more entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from one or more entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device; and</claim-text><claim-text>using the set of challenge-response pairs in an authentication procedure for the electronic device.<claim-text>generating, during an enrollment process conducted in a controlled environment, a dark bit mask comprising a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device; and</claim-text><claim-text>using at least a portion of the plurality of state information values to generate a set of challenge-response pairs for use in an authentication process for the electronic device.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of entropy sources comprises at least one of:<claim-text>one or more delay chains;</claim-text><claim-text>one or more static random access memory (SRAM) memory bitcells; or</claim-text><claim-text>one or more cross-coupled inverters.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of operating conditions comprises at least one of:<claim-text>one or more operating voltages;</claim-text><claim-text>one or more operating temperatures; or</claim-text><claim-text>one or more age-related parameters.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>generating, during an enrollment process conducted in a controlled environment, a dark bit mask comprising a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the authentication procedure:<claim-text>generates a set of challenge-response pairs from the set of state information values; and</claim-text><claim-text>uses, in the authentication process, only a subset of the challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the authentication procedure:<claim-text>generates a set of challenge-response pairs from the set of state information values; and</claim-text><claim-text>uses, in the authentication process, challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein authentication procedure requires that at least a portion of the challenge-response pairs generated include a generated response that does not match an expected response.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. An apparatus comprising:<claim-text>a processor; and</claim-text><claim-text>a computer readable memory comprising instructions which, when executed by the processor, cause the processor to:<claim-text>use at least a portion of a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device to generate a set of challenge-response pairs for use in an authentication process for the electronic device;</claim-text></claim-text><claim-text>select, from the plurality of state information values, a set of state information values from one or more entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from one or more entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device; and</claim-text><claim-text>use the set of challenge-response pairs in an authentication procedure for the electronic device.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the plurality of entropy sources comprises at least one of:<claim-text>one or more delay chains;</claim-text><claim-text>one or more static random access memory (SRAM) memory bitcells; or</claim-text><claim-text>one or more cross-coupled inverters.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the plurality of operating conditions comprises at least one of:<claim-text>one or more operating voltages;</claim-text><claim-text>one or more operating temperatures; or</claim-text><claim-text>one or more age-related parameters.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, the computer readable memory comprising instructions which, when executed by the processor, cause the processor to:<claim-text>generate, during an enrollment process conducted in a controlled environment, a dark bit mask comprising a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, the computer readable memory comprising instructions which, when executed by the processor, cause the processor to:<claim-text>generate a set of challenge-response pairs from the set of state information values; and</claim-text><claim-text>use, in the authentication process, only a subset of the challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, the computer readable memory comprising instructions which, when executed by the processor, cause the processor to:<claim-text>generate a set of challenge-response pairs from the set of state information values; and</claim-text><claim-text>use, in the authentication process, challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein authentication procedure requires that at least a portion of the challenge-response pairs generated include a generated response that does not match an expected response.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. One or more computer-readable storage media comprising instructions stored thereon that, in response to being executed, cause a computing device to:<claim-text>use at least a portion of a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device to generate a set of challenge-response pairs for use in an authentication process for the electronic device;</claim-text><claim-text>select, from the plurality of state information values, a set of state information values from one or more entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from one or more entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device; and</claim-text><claim-text>use the set of challenge-response pairs in an authentication procedure for the electronic device.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The one or more computer-readable storage media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the plurality of entropy sources comprises at least one of:<claim-text>one or more delay chains;</claim-text><claim-text>one or more static random access memory (SRAM) memory bitcells; or</claim-text><claim-text>one or more cross-coupled inverters.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The one or more computer-readable storage media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the plurality of operating conditions comprises at least one of:<claim-text>one or more operating voltages;</claim-text><claim-text>one or more operating temperatures; or</claim-text><claim-text>one or more age-related parameters.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The one or more computer-readable storage media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising instructions stored thereon that, in response to being executed, cause the computing device to:<claim-text>generate, during an enrollment process conducted in a controlled environment, a dark bit mask comprising a plurality of state information values derived from a plurality of entropy sources at a plurality of operating conditions for an electronic device.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The one or more computer-readable storage media of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further comprising instructions stored thereon that, in response to being executed, cause the computing device to:<claim-text>generate a set of challenge-response pairs from the set of state information values; and</claim-text><claim-text>use, in the authentication process, only a subset of the challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The one or more computer-readable storage media of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further comprising instructions stored thereon that, in response to being executed, cause the computing device to:<claim-text>generate a set of challenge-response pairs from the set of state information values; and</claim-text><claim-text>use, in the authentication process, challenge-response pairs generated from entropy sources that exhibit a stable response at the plurality of different operating conditions for the electronic device and from entropy sources that exhibit an unstable response at one or more operating conditions for the electronic device.</claim-text></claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The one or more computer-readable storage media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein authentication procedure requires that at least a portion of the challenge-response pairs generated include a generated response that does not match an expected response.</claim-text></claim></claims></us-patent-application>
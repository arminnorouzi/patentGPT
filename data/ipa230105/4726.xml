<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004727A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004727</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17711864</doc-number><date>20220401</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>IN</country><doc-number>202141029376</doc-number><date>20210630</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>40</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>51</main-group><subgroup>046</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>40</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>06311</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>51</main-group><subgroup>046</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">TASK-ACTION PREDICTION ENGINE FOR A TASK MANAGEMENT SYSTEM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>MICROSOFT TECHNOLOGY LICENSING, LLC</orgname><address><city>Redmond</city><state>WA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>OBEROI</last-name><first-name>Raunak</first-name><address><city>Seattle</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Madiraju</last-name><first-name>Shashank</first-name><address><city>Hyderabad</city><country>IN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Kumar</last-name><first-name>Ajay</first-name><address><city>Hyderabad</city><country>IN</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Singh</last-name><first-name>Neha</first-name><address><city>Hyderabad</city><country>IN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Methods, systems, and computer storage media for providing predicted task-actions for tasks from a plurality of task applications associated with a task management system. In operation, a task associated with a task application is accessed at a task-action prediction engine. An intent of the task is determined. The intent of the task is determined based on task features and an intent prediction machine learning model that is trained to predict intents associated with natural language text. Based on the intent of the task, a predicted task-action is selected based on a task-action computation model that is associated with predefined task-actions and predefined intent-task-categories. The predicted task-action can be communicated to a task management client that causes display of the predicted task-action in combination with a predicted task-action interface element associated with executing the predicted task-action. The predicted task-action can be displayed with supplemental task-action information for executing the predicted task-action.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="113.11mm" wi="158.75mm" file="US20230004727A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="218.52mm" wi="181.95mm" orientation="landscape" file="US20230004727A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="260.94mm" wi="192.62mm" orientation="landscape" file="US20230004727A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="213.53mm" wi="180.93mm" file="US20230004727A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="250.95mm" wi="195.33mm" orientation="landscape" file="US20230004727A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="272.97mm" wi="192.36mm" orientation="landscape" file="US20230004727A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="262.97mm" wi="179.49mm" orientation="landscape" file="US20230004727A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="250.36mm" wi="112.01mm" orientation="landscape" file="US20230004727A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="256.46mm" wi="190.08mm" orientation="landscape" file="US20230004727A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="266.19mm" wi="184.40mm" orientation="landscape" file="US20230004727A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="241.64mm" wi="168.57mm" orientation="landscape" file="US20230004727A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="209.63mm" wi="183.98mm" orientation="landscape" file="US20230004727A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="168.83mm" wi="120.99mm" file="US20230004727A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="244.18mm" wi="121.24mm" file="US20230004727A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="259.42mm" wi="121.24mm" file="US20230004727A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="230.38mm" wi="144.78mm" file="US20230004727A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="195.83mm" wi="146.30mm" file="US20230004727A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims priority to Indian Patent Application No.: 202141029376, filed Jun. 30, 2021, the entire contents of which is hereby incorporated by reference in its entirety.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Users rely on computing resources such as applications and services to perform various computing tasks. Productivity tools systems (e.g., a cloud-based suite of productivity application and services) include different types of software&#x2014;from word processing software to email and personal information software&#x2014;that provide functionality to support performing computing tasks. For example, a cloud-based email application may include a to-do list for managing tasks associated with emails. Task management systems (e.g., task management applications and task management services) in productivity tools systems support creating, tracking, and reporting on user tasks. For example, computing resources of a standalone task management client can logically track and manage tasks based on information received from a user.</p><p id="p-0004" num="0003">Conventionally, task management systems are limited in their capacity to provide integrated and intelligent management of tasks to efficiently execute intended task goals. Some conventional task management systems&#x2014;such as those in task applications&#x2014;were developed to meet specific user needs, where the user needs are associated only with particular computing contexts (e.g., email tasks, to-do-list task, or digital assistant tasks). As a result, these task management systems are not integrated with other applications, services, or computing resources, which leads to inefficient computing operations in that tasks are managed independently. In addition, some task management systems are designed to merely communicate listings of tasks without additional functionality to facilitate performing the tasks. As such, a more robust task management system&#x2014;with an alternative basis for performing task management operations&#x2014;can improve computing operations and interfaces in task management systems.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0005" num="0004">Various aspects of the technology described herein are generally directed to systems, methods, and computer storage media, for among other things, providing predicted task-actions for tasks from a plurality of task applications associated with a task management system. A predicted task-action is a projected action associated with accomplishing the task. The predicted task-action (also known as a suggested action, a quick action, or a smart action) of a task may be computed based on task features of the task and communicated to a user to proactively enable executing the projected action. For example, in response to identifying a task, &#x201c;Talk to John Smith,&#x201d; from a task application (e.g., a to-do list of an email application), a projected task-action may be determined to be, &#x201c;Send email to John Smith,&#x201d; based on determining an intent (e.g., communication) of the task from a set of predefined intent-task-categories (e.g., communication, document, learning, find time, and travel and expenses). The projected task-action (i.e., &#x201c;Send email&#x201d; in this example) is one of a set of predefined task-actions that correspond to an intent-task-category from the set of predefined intent-task-categories.</p><p id="p-0006" num="0005">Conventionally, task management systems do not provide computing logic to provide integrated and intelligent management of tasks to efficiently execute intended task goals. A technical solution&#x2014;to the limitations of conventional task management system operations&#x2014;provides predicted task-actions via a task-action prediction engine of a task management system. In operation, the predicted task-action engine accesses a task that is associated with a task application. For example, a task may include a flagged email in an email application, explicit tasks that are added to a to-do list of an application, or implicit tasks that are derived from task application data. The predicted task-action engine determines an intent of the task using task features of the task and an intent prediction machine learning model. The intent prediction machine learning model is trained to predict intents based on natural language text corresponding to task features and a set of predefined intent-task-categories. Based on the intent of the task, a predicted task-action is selected for the task.</p><p id="p-0007" num="0006">In addition, in some embodiments, the task management client (e.g., a task management application) initially requests task data that triggers the task-action prediction engine to access the task from the task application. The predicted task-action engine further operates to communicate with a data analytics service to retrieve data analytics service data that can be used to generate or communicate supplemental task-action data. The supplemental task-action data can&#x2014;in some instances&#x2014;be identified based on task features of the task and the intent determined for the task. The predicted task-action is selected based on a task-action computation model that defines a set of predefined task-actions that correspond to the set of predefined intent-task-categories. The predicted task-action is communicated to a task management client.</p><p id="p-0008" num="0007">Moreover, in some embodiments, the task management client operates with the task-action prediction engine to provide the predicted task-action through a predicted task-action interface of the task management client. The predicted-task action interface includes predicted task-action interface elements (e.g., interface controls to initialize a chat, email, or other activity using a video-telephony system, email application, or other application) that support performing the predicted task-action. For example, if the predicted task-action is to &#x201c;Send an email,&#x201d; the predicated task-action interface provides interface elements (e.g., an envelope icon, &#x201c;Send email&#x201d; hyperlink) to support sending the email. In some examples, the interface elements may include additional elements for reviewing details corresponding to supplemental task-action data. The task management client receives the predicted task-action, in some cases along with supplemental task-action data (e.g., documents, images, contact information, or resource locators) that are relevant for performing the predicted task-action.</p><p id="p-0009" num="0008">This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0009">The technology described herein is described in detail below with reference to the attached drawing figures, wherein:</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> is a block diagram of an exemplary task management system for providing predicted task-actions using a task-action prediction engine of the integrated management system, in accordance with aspects of the technology described herein;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>1</b>B</figref> is a block diagram of an exemplary schematic for providing predicted task-actions using a task-action prediction engine in a task management system, in accordance with aspects of the technology described herein;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b>C</figref> is a block diagram of an exemplary schematic for providing predicted task-actions using a task-action prediction engine in a task management system, in accordance with aspects of the technology described herein;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b>D</figref> is a block diagram of an exemplary schematic for providing predicted task-actions using a task-action prediction engine in a task management system, in accordance with aspects of the technology described herein;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>1</b>E</figref> is a block diagram of an exemplary schematic for providing predicted task-actions using a task-action prediction engine in a task management system, in accordance with aspects of the technology described herein;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> is an exemplary task management system for providing predicted task-actions using a task-action prediction engine in the task management system, in accordance with aspects of the technology described herein;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> is an exemplary schematic for providing predicted task-actions using a task-action prediction engine in a task management system, in accordance with aspects of the technology described herein;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>3</b>B</figref> are view models for providing predicted task-actions using a task-action prediction engine in a task management system, in accordance with aspects of the technology described herein;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIGS. <b>4</b>A, <b>4</b>B and <b>4</b>C</figref> are exemplary predicted task-action interfaces for providing predicted task-actions using a task-action prediction engine in a task management system, in accordance with aspects of the technology described herein;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>5</b></figref> provides a first exemplary method of providing predicted task-action using a task-action prediction engine in a task management system, in accordance with aspects of the technology described herein;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>6</b></figref> provides a second exemplary method of providing predicted task-action using a task-action prediction engine in a task management system, in accordance with aspects of the technology described herein;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>7</b></figref> provides a third exemplary method of providing predicted task-action using a task-action prediction engine in a task management system, in accordance with aspects of the technology described herein;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>8</b></figref> provides a block diagram of an exemplary distributed computing environment suitable for use in implementing aspects of the technology described herein; and</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram of an exemplary computing environment suitable for use in implementing aspects of the technology described herein.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0025" num="0024">Task management systems (e.g., task management applications and task management services) in productivity tools systems support creating, tracking, and reporting on user tasks. For example, computing resources of a standalone task management client can logically track and manage tasks associated with day-to-day interactions of users. Conventionally, task management systems are limited in their capacity to provide integrated and intelligent management of tasks to efficiently execute intended task goals. Some conventional task management systems operate based on a limited data set of task details (e.g., user-provided data) when performing task management. For example, a conventional task management system provides an interface to receive manually-entered tasks and task details into a task application&#x2014;in many ways, the interface is exclusively an electronic to-do list without much more. Such task management systems rely on the limited data set of task details in providing task management functionality.</p><p id="p-0026" num="0025">Moreover, conventional task management systems do not facilitate identifying or performing an underlying action associated with a task. Currently, a task management system (e.g., a to-do list) of an application (e.g., email application) simply provides a listing of tasks. The burden is on the user to identify an appropriate action to complete the task, and the application must perform additional processing of user input to perform the identified action. For example, if a task indicates that a first user should send an email to a second user&#x2014;without indicating the second user's email address&#x2014;the first user has to trigger operations that cause additional inefficient computations by the application to determine the email address of the second user and then initialize an email drafting interface. As such, a more robust task management system&#x2014;with an alternative basis for performing task management operations&#x2014;can improve computing operations and interfaces in task management systems.</p><p id="p-0027" num="0026">Embodiments of the present disclosure are directed to simple and efficient methods, systems, and computer storage media for, providing predicted task-actions using a task-action prediction engine of a task management system. A predicted task-action is a projected action associated with accomplishing the task. The predicted task-action (also known as a suggested action, a quick action, or a smart action) may be computed based on task features of a task and communicated to a user to proactively enable executing the projected action. The task may be associated with one or more of a plurality of task applications associated with a task management system. The task management system may be integrated with the plurality of task applications via a data analytics service. The task applications provide task application data&#x2014;and the data analytics service provides data analytics service data to provide additional task management functionality as described herein. In this way, embodiments of the present disclosure include a technical solution to the limitations of conventional task management system operations and interfaces.</p><p id="p-0028" num="0027">Aspects of the disclosure can be described by way of examples and with reference to <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>E</figref>. With reference to <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> is an example task management system <b>100</b> for providing predicted task-actions in accordance with embodiments of the present disclosure. The task management system <b>100</b> provides components, instructions, operations, and interfaces for generating, processing, communicating, and presenting predicted task-actions using the following: a task-action prediction engine <b>110</b>, a task management client <b>120</b>, intent prediction machine learning model <b>140</b>, task application <b>150</b>, data analytics service <b>160</b>, task-action computation model <b>170</b>, and network <b>180</b>A.</p><p id="p-0029" num="0028">At a high level, the task management system <b>100</b> provides one or more predicted task-actions for a task based on first predicting an intent of the task, and then selecting likely task-actions (i.e., predicted task-actions) that are associated with the tasks. The likely task-actions are caused to be displayed via a task management client <b>120</b> that is configured to trigger execution of the task via a predicted task-action interface, e.g., in response to a user selection of the task-action. Initially, a task is retrieved via the task-action prediction engine; the task may refer to an implicit or explicit work item or assignment. The task may be assigned to a user. The task may be associated with a task application or any other type of application that includes information that can be used to identify the task. A task may include one or more subdivisions of the task that is referred to as a step(s). A task can be associated with an action&#x2014;and specifically a predicted task-action&#x2014;that is, a projected action, suggested action, or smart action identified for accomplishing the task.</p><p id="p-0030" num="0029">The task management system <b>100</b> can be developed as a platform module that is communicatively coupled to different application or service endpoints (e.g., endpoints associated with productivity applications and services of a cloud-based implementation) for accessing tasks. For example, a to-do application having a first task can include an endpoint associated with task-action prediction engine such that the task is accessed for predicting a first predicted task-action for the first task. The task management system <b>100</b> can specifically include communicatively coupled task applications to support managing tasks from the task applications. The task applications may be part of the same computing ecosystem as the task management system or may be part of a different ecosystem.</p><p id="p-0031" num="0030">By way of example, with reference to <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>, the task management client <b>120</b> may be a to-do client application that supports tracking tasks from several different sources of task data of the tasks. The task management client <b>120</b> can specifically provide session credentials of a user, where the session credentials are used to access user-specific task data from data Application Programming Interfaces (APIs) that support retrieving data analytics service data. The to-do client application calls a service (e.g., a service of the task-action prediction engine <b>110</b>). The service provides a framework for communications between the to-do client application and the task-action prediction engine <b>110</b>. The service fetches a task from a task application (e.g., task application <b>150</b>). Task applications, such as email applications or to-do lists can identify user-entered tasks, flagged emails, or inferred tasks. The task-action prediction engine <b>110</b> includes an intent prediction machine learning model <b>140</b> that operates to analyze the task and determine an intent of the task. The task-action prediction engine <b>110</b> may further (e.g., based on a particular intent) retrieve additional information (e.g., data analytics service data) from a data analytics service <b>160</b>&#x2014;for processing the task. The data analytics service <b>160</b> can refer to APIs of a data and intelligence platform with a unified programmability model for accessing data associated with a cloud-based productivity tools implementation.</p><p id="p-0032" num="0031">By way of illustration, with reference to <figref idref="DRAWINGS">FIGS. <b>1</b>C and <b>1</b>D</figref>, <figref idref="DRAWINGS">FIG. <b>1</b>C</figref> illustrates a framework for surfacing predicted task-actions on a predicted task-action interface. For example, text from an email may read &#x201c;Talk to John&#x201d; <b>120</b>C. The text may be analyzed (e.g., via task-action prediction engine) to identify a first task. A language understanding model (e.g., LUIS <b>142</b> of <figref idref="DRAWINGS">FIG. <b>1</b>E</figref>) of the task-action prediction engine is employed to understand an intent of the task. The intent can be identified based on task features associated with the task. As illustrated, a &#x201c;communication&#x201d; intent <b>130</b>C is identified for the task. The intent (i.e., communication in this example) and task features are analyzed to determine a predicted task-action <b>140</b>B and supplemental task-action information <b>150</b>C. The predicted task-action and supplemental task-action information are generated for display. For example, in the illustrated case, a first predicted task-action is &#x201c;Chat on Video&#x201d; and a second predicted task-action is &#x201c;Send email.&#x201d; Supplemental task-action data <b>118</b>B can include profile information for &#x201c;John Smith.&#x201d;</p><p id="p-0033" num="0032">With reference to <figref idref="DRAWINGS">FIG. <b>1</b>D</figref>, an exemplary schematic for identifying intent and supplemental task-action information is shown in <figref idref="DRAWINGS">FIG. <b>1</b>D</figref>. Communication <b>110</b>D and document <b>120</b>C can correspond to intent-task-categories of a set of predefined intent-task-categories. At a high level, an intent-task-category can refer to a classification of a task that supports identifying a predicted task-action for the task, based on a set of predefined task-actions for the intent classification. Operationally, task features (i.e., programmatically defined characteristics) of a task are compared to intent-task-categories features to identify an intent-task-category associated with task. For example, task features of the text &#x201c;Talk to Gyan about Q4 roadmap&#x201d; may correspond to &#x201c;person&#x201d; and &#x201c;topic&#x201d; intent-task-category features&#x2014;such that a prediction is made that the intent-task-category is &#x201c;communication.&#x201d; As another example, task features of the text &#x201c;Share out report draft by today&#x201d; may correspond to &#x201c;file&#x201d; and &#x201c;time&#x201d; intent-task-category features&#x2014;such that a prediction is made that the intent-task-category is &#x201c;document.&#x201d; Additional details for associating task features to intent-task-category features to predict an intent-task-category as discussed below.</p><p id="p-0034" num="0033">With continued reference to <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, the task-action computation model <b>170</b> of the task-action prediction engine&#x2014;based on the intent and optionally the additional information (i.e., data analytics service data) from the data analytics service&#x2014;generates a predicted task-action. The task-action computation model <b>170</b> stores the mapping between the set of predefined intent-task-categories and corresponding sets of predefined task-actions for each predefined intent-task-category. As discussed, the task features may be used to determine intent; moreover, task features may further be based on additional information (e.g., user features, documents, user-computer interaction behavior) that is associated with data analytics service data. The task-action computation model <b>170</b> may be used&#x2014;based on an intent determined from the task features&#x2014;to identify one or more predicted task-actions for the task. The additional information may further be used to generate supplemental task-action data that is communicated to the task management client along with the predicted task-action to cause execution of the predicted task-action.</p><p id="p-0035" num="0034">As shown in <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>, the task management client <b>120</b>, at step <b>10</b>, communicates a request for task data. At step <b>20</b>, the task-action prediction engine <b>110</b> accesses the request for task data from the task management client <b>120</b>. At step <b>30</b>, based on the request for task data, the task-action prediction engine accesses a task (e.g., task application data) from the task application <b>150</b>. At step <b>40</b>, using the intent prediction machine learning model <b>140</b>, the task-action prediction engine <b>110</b> determines an intent of the task. At step <b>50</b>, the task-action prediction engine <b>110</b> accesses data analytics service data. At step <b>60</b>, the task-action prediction engine <b>110</b> uses a task-action computation model <b>160</b> to select a predicted task-action. At step <b>70</b>, the task-action prediction engine <b>110</b> communicates the predicted task-action, optionally in combination with supplemental task-action data.</p><p id="p-0036" num="0035">With reference to <figref idref="DRAWINGS">FIG. <b>1</b>E</figref>, <figref idref="DRAWINGS">FIG. <b>1</b>E</figref> illustrates additional features of the task management system <b>100</b> for providing predicted task-actions in accordance with embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>1</b>E</figref> includes task-action prediction engine <b>110</b>, intent prediction machine learning model <b>140</b> with LUIS (Language Understanding Services) <b>142</b>, data analytics service <b>160</b> with data API <b>162</b> and data API <b>164</b>, task application <b>150</b> with flagged emails <b>152</b>, email API <b>154</b>, mail body <b>156</b>, and rule-based set of keywords <b>158</b>. The task management system <b>100</b> can support the task-action prediction engine <b>110</b> that in combination with a microservice <b>170</b> contains the logic for getting tasks, understanding an intent of the task, and suggesting actions and insights for the tasks, as discussed in more detail below.</p><p id="p-0037" num="0036">The task-action prediction engine <b>110</b> may include the intent prediction machine learning model <b>140</b>, which is configured to identify an intent for a task. The intent prediction machine learning model <b>140</b> may be based on a language understanding service framework (i.e., LUIS)&#x2014;LUIS <b>142</b> may refer to a cloud-based artificial intelligence service that applies custom machine-learning intelligence to natural language text to predict overall meaning, and outputs relevant, detailed information. LUIS <b>142</b> provides access through its custom portal, APIs and SDK client libraries. At a high level, LUIS <b>142</b> processes the text (or sound converted to text) including segmentation of text into components (e.g., segmentation and tokenization). LUIS <b>142</b> further performs text cleaning (e.g., filtering out &#x201c;garbage,&#x201d; removal of unnecessary elements). Text vectorization and feature engineering operations may be performed&#x2014;and in some instances lemmatization and stemming&#x2014;reducing inflections for words. Using machine learning algorithms and methods, the intent prediction machine learning model <b>140</b> is trained. Other variations and combinations of operations for providing a machine learning model are contemplated with embodiments described herein.</p><p id="p-0038" num="0037">The intent prediction machine learning model <b>140</b> uses relevant data to classify the intent of the tasks. The task-action prediction engine supports a set of predefined intent-task-categories&#x2014;each intent in the predefined set of intent-task-categories having intent features&#x2014;that can be matched to task features.</p><p id="p-0039" num="0038">In operation, using the intent prediction machine learning model <b>140</b>, task features (e.g., email attributes and additional information) of a task may be classified into any of the following predefined intent-task-categories: communication (e.g., if the user task indicates the intent to contact a person); document (e.g., if the user task indicates that he wants to share/edit/create a pre-existing/new document (WORD, POWERPOINT, EXCEL)); find time (e.g., if a task specifies a deadline or idle time for the user); learning (e.g., if a task indicates learning a new work-related or home-related concept); and travel and expenses (e.g., if the task indicates travel plans or booking a trip). The intent-task categories provided here are exemplary and should not be construed as limiting. The task features may be compared to intent features extracted from historical tasks and their corresponding intents. A determination may be made that a task should have a particular intent based on a threshold similarity (e.g., an intent score) between the task features of the task and the intent features of historical intents. For example, the intent prediction machine learning model <b>140</b> may identify an intent for a task and generate an intent score that indicates a quantified likelihood that the task corresponds to a particular intent in the set of predefined intent-task-categories. The different intents can further be ranked based on a corresponding intent score of the intents. As such, the predicted task-action or an ordered listing of predicted task-actions can be provided based on the intent score(s), where the top scoring intents are selected or ranked over lower scored intents.</p><p id="p-0040" num="0039">The microservice <b>170</b> communicates with different APIs to support retrieving additional information from external sources (e.g., data analytics service data associated with supplemental task-action data and task-action prediction data). For example, the email tasks API may return attributes such as Owner, Subject, CreatedDateTime, Importance, ReminderDateTime, CompletedDateTime, etc. associated with a task. The attributes that are received via the tasks API may be used to acquire the required data about the tasks to use LUIS <b>142</b>. The microservice <b>180</b>E may further communicate with a task fabric <b>180</b>E that provide the computing logic or instructions for managing a task based on the task ID <b>172</b> and email ID <b>174</b>.</p><p id="p-0041" num="0040">The data analytics service <b>160</b>&#x2014;associated with productivity applications and services of a cloud-based provider (e.g., MICROSOFT GRAPH, SHAREPOINT, BING)&#x2014;may refer to a data and intelligence platform with a unified programmability model for accessing data associated with cloud-based productivity tools. By way of example, the data analytics service <b>160</b> may include a first data API, data API <b>162</b>, which may be used to retrieve the contact details of a person (e.g., display name, user principal name (alias), email, contact number). The microservice <b>170</b> can construct a URI (universal resource identifier) to a person's default mail and SIP (session initiation protocol). The APIs may also be used to retrieve a profile picture of the user.</p><p id="p-0042" num="0041">In another example, the data analytics service <b>160</b> can include a second data API, data API <b>164</b>, that may be used to retrieve the relevant files for a task related to document sharing or creating. The microservice <b>170</b> is configured to search for the required files with the help of a FileName attribute returned by the data API <b>164</b>. File name is extracted from the tasks using LUIS <b>142</b> and then used to generate links of the pre-existing files the user might want to use to complete the task. The data API <b>164</b> response may include various attributes like FileName, AccessUrl, Author, DateCreated, DateModified, DateAccessed, etc. Other variations and combinations of data APIs are contemplated with embodiments of the present disclosure.</p><p id="p-0043" num="0042">With continued reference to <figref idref="DRAWINGS">FIG. <b>1</b>E</figref>, <figref idref="DRAWINGS">FIG. <b>1</b>E</figref> illustrates additional features of the task management system <b>100</b> with reference to the flagged emails <b>152</b> of task application <b>150</b>. In particular, flagged emails may be intelligently processed to identify explicit and implicit tasks. Flagged emails may be tracked via a task ID <b>172</b> and email ID <b>174</b>. An API of the task application <b>150</b> (e.g., email tasks API <b>164</b>) may be used to fetch the body of the email (e.g., mail body <b>156</b>). The mail body <b>156</b> can be processed into a format that can be analyzed&#x2014;via the intent prediction machine learning model <b>140</b> to identify an intent from the mail body <b>156</b>. For example, the mail body <b>156</b> may be deserialized and converted into plain text, and a rule-based set of keywords for scenarios (e.g., rule-based set of keywords for scenarios <b>158</b>) may be used to filter mail body <b>156</b> sentences and align them with intents (i.e., preliminary intents) from the set of predefined intent-task-categories. The intent prediction machine learning model <b>140</b> may process the filtered mail body <b>156</b> sentences and corresponding preliminary intents to identify an intent (i.e., a predicted intent) of the flagged email. It is contemplated that different types of email&#x2014;and not exclusively flagged emails&#x2014;may be processed using the above-described steps to identify implicit tasks and intents of corresponding tasks for providing predicted task-actions.</p><p id="p-0044" num="0043">Aspects of the disclosure can be described by way of examples and with reference to <figref idref="DRAWINGS">FIGS. <b>2</b>A, <b>2</b>B, <b>3</b>A, <b>3</b>B, <b>4</b>A, <b>4</b>B, and <b>4</b>C</figref>. <figref idref="DRAWINGS">FIG. <b>2</b>A</figref> is a block diagram of an exemplary computing environment, based on example environments described with reference to <figref idref="DRAWINGS">FIGS. <b>8</b> and <b>9</b></figref> for use in implementing embodiments of the disclosure are shown. Generally, the exemplary computing environment includes a system suitable for providing the example task management system <b>100</b> in which methods of the present disclosure may be employed. In particular, <figref idref="DRAWINGS">FIG. <b>2</b>A</figref> shows a high level architecture of the task management system <b>100</b> in accordance with implementations of the present disclosure. Among other engines, managers, generators, selectors, or components not shown (collectively referred to herein as &#x201c;components&#x201d;), the computing environment of task management system <b>100</b> includes task-action prediction engine <b>110</b>&#x2014;including predicted task-action data <b>180</b>, supplemental task-action data <b>182</b>, predicted task-action interface data <b>184</b>; a task management client <b>120</b>&#x2014;including predicted task-action interface data <b>122</b>; intent prediction machine learning model <b>140</b>&#x2014;including task features <b>142</b> and intent-task-category features <b>144</b>; task application <b>150</b>; data analytics service <b>160</b>; and task-action computation model <b>170</b>&#x2014;including intent-task-categories <b>172</b> and task-actions <b>174</b>.</p><p id="p-0045" num="0044">In operation, the task-action prediction engine <b>110</b> is responsible for providing predicted task-actions. The task-action prediction engine receives a request for task data. The request may be received from a task management client <b>120</b> (e.g., a task management client running on a client computing device). The task management client <b>120</b> may include session credentials (e.g., user data for a user associated with the task management client) that allow the task-action prediction engine <b>110</b> to access services in the task management system <b>100</b> on behalf of the user. The task management client <b>120</b> may be a task management aggregator application that supports and integrates management of tasks from a plurality of task applications or task sources. For example, the task management client <b>120</b> may be integrated into an existing task management application (e.g., a to-do application) such that the task management application supports task management functionality based on predicted task-actions as described herein.</p><p id="p-0046" num="0045">Based on the request for task data, the task-action prediction engine retrieves task-action prediction engine data <b>112</b> that includes task application data <b>112</b>A and data analytics service data. The task-prediction engine data <b>112</b> may generally refer to data that supports determining the predicted task-action. The task application data <b>112</b>A may include data retrieved from task application <b>150</b>. The task application <b>150</b> may refer to any type of application (e.g., an email application) that tracks tasks, such that the task application data <b>112</b>A may include information identifying tasks along with task details. The task application data <b>112</b>A may include explicit task and further include implied tasks, such as tasks that are derived from text of communications or documents associated with the task application <b>150</b>. For example, an email body may be analyzed to determine a task associated with the email body text. The explicit tasks and implicit tasks comprising the task application data <b>112</b>B may be processed to predict an intent associated with the tasks.</p><p id="p-0047" num="0046">The task-action prediction engine data <b>112</b> may also include data analytics service data <b>112</b>B. The task-action prediction engine <b>110</b> may be associated with productivity tools software that includes data that is tracked for different users. For example, a user drafting a document using a word processor application, accessing a search engine, or accessing shared documents may have data analytics service data <b>112</b>B associated with their interactions and behavior relative to the document&#x2014;such as&#x2014;where the document is stored and how recently the document was opened. The data analytics service data <b>112</b>B may be retrieved via the data analytics service <b>160</b> to supplement operations for providing predicted task-actions&#x2014;including predicting an intent of the task. For example, user features (e.g., programmatically define characteristics of the user with regard to the task management system) can be a subset of task features that are used for determining an intent associated with a particular task. In this way, the task-action prediction engine is responsible for retrieving both task application data <b>112</b>A and data analytics service data <b>112</b>B that can be used for providing predicted task-actions.</p><p id="p-0048" num="0047">The task-action prediction engine <b>110</b> includes intent prediction machine learning model <b>140</b> that uses task features and intent-task-category features to determine an intent of the task. The task features may refer to specific characteristics of a task that are determined through natural language processing of task application data <b>112</b>A and data analytics service data <b>112</b>B. For example, in a first scenario (e.g., communication), a communication may be identified in task application predicted task-actions (e.g., Talk to Alice, Mail Bob, Follow up with Clive). The predicted task-actions may provide the user with an option to directly start a new email to the recipient (e.g., via their default email client) or contact the person via video-telephony (or their preferred SIP client), along with the recipient's details (e.g., name, role in organization). For example, for a task of the task application for which the text reads &#x201c;Talk to John Smith about demo,&#x201d; the intent prediction machine learning model may include intelligence for identifying the task as a communication task (or classifying the task to the intent-task-category of &#x201c;communication&#x201d;). The intent-task-category may specifically include intent-task-features associated with the intelligence&#x2014;such as&#x2014;a topic and a person that are identified in the task features. The intelligence may further include supplemental task-action data that should be retrieved based on determining that the task features correspond to a particular intent-task-category. For example, for the communication intent-task-category, a determination of a best timeslot between all parties to communicate can be made. As discussed herein, different types of intent-task-categories may include corresponding intent-task-category features and intent-task-category intelligence for comparing task features to intent-task category features to make a determination that the task belongs a particular intent-task-category.</p><p id="p-0049" num="0048">In a second scenario (e.g., document), data analytics service data may identify a task associated with user interactions with functionality of applications and services of a cloud-based productivity tools system. For example, predicted task-actions for a document intent-task-category may be related to sharing or reviewing documents or creating new documents. Predicted task-actions may support contacting a relevant person or sharing the most relevant documents corresponding to a file or subject referenced by the task. Predicted task-actions related to sharing or reviewing documents may support fetching relevant documents and causing display of a resource locator (e.g., a link) to access the document. Predicted task-actions related to creating new documents may identify different templates, sample documents, and information on subject matter experts. For example, for a task of the task application for which the text reads &#x201c;Work on demo presentation,&#x201d; &#x201c;Send Quarterly Report to Alice&#x201d; or &#x201c;Have to send the foundry doc to Trilok,&#x201d; the intent prediction machine learning model may include intelligence to create or open a document, or also send a doc as an attachment. Intelligence to create a document may include identifying that the intent is to create document, identifying a document type to suggest templates to get started, identifying subject matter expects, and/or identifying related documents on a similar topic. Intelligence to open a document may include identifying the intent is to open a document, and identifying a relevant document based on the context of the task and working set data (e.g., most recently used documents) associated with the user.</p><p id="p-0050" num="0049">In a third scenario (e.g., learning), a task may be identified as related to learning a subject matter related to work or any identified topic, such that supplemental task-action data may include subject matter experts (SMEs), useful content from a professional social network learning and other sources, etc. In this way, predicted task-actions may include quick links to contact SMEs or professional social network profiles. Supplemental task-action data may include identifying relevant resources on the particular topic that may be accessed via the internet or intranet. For example, for a task of the task application for which the text reads &#x201c;Ramp up on data analytics ervice apis,&#x201d; &#x201c;Read about microservices and REST APIS,&#x201d; &#x201c;Learn about communication services,&#x201d; or &#x201c;What is a microservice?,&#x201d; the intent prediction machine learning model may include intelligence to identify the intent to learn about a topic, identify a topic to learn, determine documents and associated links for a given topic identified with the learning intent, and identifying SMEs.</p><p id="p-0051" num="0050">In a fourth scenario (e.g., find time), a task can be identified as related to finding time, e.g., with regard to an identified deadline approaching for a task that requires a period of focus time to accomplish the task. The supplemental task-action data may include showing free calendar slots for such activities. The predicted task-action may include showing one or more free calendar slots for approval by the user. For example, for a task of the task application for which the text reads &#x201c;Complete design doc by today,&#x201d; &#x201c;Complete some application by 31<sup>st</sup>,&#x201d; or &#x201c;Mail Ajay details by tomorrow,&#x201d; the intent prediction machine learning model includes intelligence to identify free time.</p><p id="p-0052" num="0051">In a fifth scenario (e.g., travel and expenses), a task may be identified as related to travel and expenses with regard to an trip, destination, and/or dates in text data. The supplemental task-action data may include identifying travel booking resources. The predicted task-action may include showing one or more travel booking resources or proactively executing a search to identify travel options (e.g., flight options) to book travel. For example, for a task of the task application for which the text reads &#x201c;Fly to New York City on May 13<sup>th</sup>,&#x201d; &#x201c;Get hotel for family vacation in Hawaii,&#x201d; or &#x201c;Pay light bill for apartment,&#x201d; the intent prediction machine learning model includes intelligence to identify the travel and expense intent.</p><p id="p-0053" num="0052">The task-action prediction engine <b>110</b> operates with the task-action computation model <b>170</b> to select a predicted task-action. The task-action computation model <b>170</b> is a computing model that includes a mapping of intent-task-categories to corresponding predefined task-actions. In this way, the mapping operates as an indicator of a first set of predefined task-actions that correspond to an intent-task-category. For example, the communication intent-task-category can include predicted task-actions to email a user using an email application, chat with a user via a video-telephony system, or set up a meeting&#x2014;while surfacing free timeslots.</p><p id="p-0054" num="0053">With reference to <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, <figref idref="DRAWINGS">FIG. <b>2</b>B</figref> illustrates a schematic that identifies predefined intent-task-categories (e.g., communication <b>208</b>, document <b>210</b>, learning <b>212</b>, find time <b>214</b>, and travel and expenses <b>216</b>). At step <b>202</b>, a client makes a request with session credentials. At step <b>204</b>, the task-action prediction engine <b>110</b> uses the session credentials to fetch user tasks from task application (e.g., email API). At step <b>206</b>, the task-action prediction engine uses the intent prediction machine learning engine <b>140</b> to predict an intent of the task based on the predefined intent-task-categories.</p><p id="p-0055" num="0054">At steps: communication <b>208</b>, document <b>210</b>, learning <b>212</b>, find time <b>214</b>, and travel and expenses <b>216</b>, when a particular intent-task-category is determined, the following corresponding steps are performed: at step <b>218</b>, the task-action prediction engine <b>110</b> fetches a user's information from a data API; step <b>220</b> the task-action prediction engine <b>110</b> fetches related document using a data API; step <b>222</b> the task-action prediction engine <b>110</b> fetches subject matter expert content; step <b>224</b>, the task-action prediction engine <b>110</b> fetches a user information free time using a data API; and step <b>226</b> the task-action prediction engine <b>110</b> links to flight book and hotel booking. At step <b>228</b>, task-action prediction engine <b>110</b> provides the predicted task-action and supplement task-action data for the task.</p><p id="p-0056" num="0055">With reference to <figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>3</b>B</figref>, <figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>3</b>B</figref> illustrate a view model in accordance with embodiments of the present disclosure. The view model can be based on a model-view-viewmodel (MVVM) software architectural pattern that facilitates the separation of the development of the graphical user interface from development of business logic or back end logic so that the view is not dependent on any specific model. In embodiments where a task management client (e.g., a to-do application) is based on the MVVM architecture, and the views for providing the functionality described herein can be based on the same MVVM architecture.</p><p id="p-0057" num="0056">In operation, a view can be created in an XAML (Extensible Application Markup Language) file, where the file is attached to an existing view of the task management client. For example, the task management client may identify a view (e.g., DetailsView) as such, the view for predicted title-actions (e.g., SubtaskSuggestionView) can be attached to the same view for the client application. The view can be created in an XAML file. In one implementation, a ViewModel for SubtaskSuggestionView is constructed class and associated with DetailsViewModel, and passed to the SubtaskSuggestionView. The ViewModel may contain the properties relevant to be shown on the screen&#x2014;the presentation of which depends on the kind of predicted task-action that is to be taken.</p><p id="p-0058" num="0057">As shown in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, by way of example, the Subtask class <b>302</b> acts as a Model class in the MVVM to control the data that the ViewModel will access. Schema <b>304</b> is the schema of the JSON (Java Script Object Notation) data arriving from the service. The Subtask class <b>302</b> fetches the data from the REST api and takes the deserialized ActionData <b>306</b> and feeds to the ICardFactory <b>308</b>. Cards are created for each action&#x2014;different deriving classes for different intents&#x2014;as shown in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref> (e.g., DocumentCard <b>320</b> and LearningCard <b>330</b>). Each card has a list of IActionButton <b>312</b>&#x2014;each button contains a Lambda function to execute on click.</p><p id="p-0059" num="0058">With reference to <figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref>, <figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref> illustrate predicted task-action interfaces with interface elements that support providing the predicted task-actions. <figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref> include a first interface portion <b>410</b>, a second interface portion <b>420</b>, and a third interface portion <b>430</b>. At a high level, the predicted task-action interfaces provide a particular manner for summarizing, presenting, and/or accessing predicted task-action data as described herein. The predicted task-action interfaces can support managing of tasks via a task management client that generates the predicted task-action interfaces.</p><p id="p-0060" num="0059">As shown, first interface portion <b>410</b> may include selectable links to cause display of additional details associated with each corresponding link. For example, flagged emails <b>410</b>, tasks <b>412</b>, and suggested tasks <b>414</b> are selectable to cause display of additional details that are associated with the selectable links&#x2014;and have been identified using a task-action prediction engine. Second interface portion <b>420</b> includes a list of tasks&#x2014;&#x201c;Talk to John&#x201d; <b>422</b>, &#x201c;Work on report&#x201d; <b>424</b>, and &#x201c;Figure out Platform framework&#x201d; <b>426</b>. For example, the tasks may be retrieved based on a task management client request for task data for a particular user, such that tasks from applications or services associated with the user are queried to retrieve tasks. The tasks are selectable to cause display of additional details that are associated with the corresponding task.</p><p id="p-0061" num="0060">Third interface portion <b>430</b> provides additional details for a selected task from interface portion <b>420</b>. Interface portion <b>430</b> can identify the task&#x2014;task identification portion <b>432</b>&#x2014; and provide predicted task-actions for the task along with supplemental task-action&#x2014;via task-action prediction data portion <b>434</b>. A task may be provided on interface portion <b>430</b> as a section header in the task identification portion <b>432</b>, the task as a section header is associated with several predicted task-actions that are additional interface elements provided below the task identification portion <b>432</b> in the task-action prediction data portion <b>434</b>. For example, &#x201c;Talk to John&#x201d; <b>440</b> is a task&#x2014;in this example&#x2014;and it is provided along with predicted task-actions &#x201c;John Smith&#x201d; <b>442</b> as a contact, &#x201c;Send email&#x201d; <b>442</b> and &#x201c;Chat with John&#x201d; <b>446</b> as predicted task-actions (i.e., smart actions).</p><p id="p-0062" num="0061">Supplemental task-action data may be provided as part of the task-action prediction data portion <b>434</b> proximate the predicted task-actions. For example, time period <b>448</b> is provided as supplemental task-action data. As shown in <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>, the &#x201c;work on final deck&#x201d; <b>428</b> task has been selected&#x2014;as such provided with corresponding additional details&#x2014;&#x201c;File A&#x201d; <b>450</b>. As shown in <figref idref="DRAWINGS">FIG. <b>4</b>C</figref>, &#x201c;John Smith&#x201d; <b>452</b>, &#x201c;File A&#x201d; <b>454</b> and &#x201c;Site A&#x201d; resource location <b>456</b> are also different types of supplemental task-action data that can be provided&#x2014;on interface portion <b>430</b>&#x2014;for a selected task.</p><p id="p-0063" num="0062">With reference to <figref idref="DRAWINGS">FIGS. <b>5</b>, <b>6</b> and <b>7</b></figref>, flow diagrams are provided illustrating methods for providing predicted task-actions using a task-action prediction engine. The methods may be performed using the task management system described herein. In embodiments, one or more computer-storage media having computer-executable or computer-useable instructions embodied thereon that, when executed, by one or more processors can cause the one or more processors to perform the methods (e.g., computer-implemented method) in the multi-tenant system (e.g., a computerized system or computing system).</p><p id="p-0064" num="0063">Turning to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, a flow diagram is provided that illustrates a method <b>500</b> for providing predicted task-action using a task-action prediction engine. At block <b>502</b>, a task-action prediction engine accesses a task associated with a task application. Accessing the task, at the task-action prediction engine, is caused by a request for task data, where the request is received from a task management client. The task management client integrates task management for a plurality of task applications and supports executing predicted task-actions via a predicted task-action interface of the task management client. At block <b>504</b>, the task-action prediction engine determines an intent of the task. Determining the intent of the task is based on task features of the task and an intent prediction machine learning model that is trained to predict intents associated with natural language texts. At block <b>506</b>, based on the intent, a predicted task-action is selected based on a task-action computation model associated with predefined task-actions and predefined intent-task-categories. At block <b>508</b>, the predicted task-action is communicated to a task management client.</p><p id="p-0065" num="0064">Turning to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a flow diagram is provided that illustrates a method <b>600</b> for providing predicted task-action using a task-action prediction engine. At block <b>602</b>, a request for task data is communicated from a task management client. The request may be communicated with session credentials that allow access to task data associated with a user having the session credentials. The session credentials are used to authenticate access to user data comprising the task data that corresponds to productivity tools software of the task management system. For example, the task management client provides session credentials to the task-action prediction engine to support authenticating a user associated with the session credentials with a data analytics service to access data analytics service that is used is selecting the predicted task-action.</p><p id="p-0066" num="0065">At block <b>604</b>, based on the communicating the request, the task management client receives a predicted task-action from a task-action prediction engine. The predicted task-action is predicted based on an intent of the task and the task features of the task. The intent of the task is determined using an intent prediction machine learning model that is trained to predict intents associated with natural language text.</p><p id="p-0067" num="0066">At block <b>606</b>, the predicted task-action is caused to be displayed. The predicted task-action is caused to be displayed in combination with a predicted task-action interface element associated with executing the predicted task-action. At block <b>608</b>, an indication to execute the predicted task-action is received. At block <b>610</b>, based on receiving the indication to execute the predicted task-action, the predicted task action is executed.</p><p id="p-0068" num="0067">Turning to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, a flow diagram is provided that illustrates a method <b>700</b> for providing predicted task-action using a task-action prediction engine. At block <b>702</b>, based on receiving, from the task management client, a request for task data, a first task associated with a first task application and a second task associated with a second task application are accessed via a task-action prediction engine. The first task is an explicit task and the second task is an implicit task. At block <b>702</b>, a task-action prediction engine determines a first intent associated with the first task and a second intent associated with a second task. Determining the first intent and the second intent is based on task features corresponding to each task and an intent prediction machine learning model that is trained to predict intents associated with natural language texts.</p><p id="p-0069" num="0068">At block <b>706</b>, based on the first intent, select a first predicted task-action based on a task-action computation model associated with predefined task-actions and predefined intent-task-categories. The first predicted task-action is associated with a first intent-task-category. At block <b>708</b>, based on the second intent, select a second predicted task-action based on the task-action computation model. The second predicted task-action is associated with a second intent-task-category that is different the first intent-task-category. At block <b>710</b>, communicate the first predicted task-action and the second predicted task-action to the task management client.</p><p id="p-0070" num="0069">Embodiments of the present disclosure have been described with reference to several inventive features (e.g., operations, systems, engines, and components) associated with a task management system having a task-action prediction engine for predicting task-actions. Inventive features described include: operations, interfaces, data structures, and arrangements of computing resources associated with providing the functionality described herein relative with reference to task-action prediction engine and user interfaces providing user interaction models. Functionality of the embodiments of the present disclosure have further been described, by way of an implementation and anecdotal examples&#x2014;to demonstrate that the operations for providing predicted task actions based on an intent prediction machine learning model and a task-action computation model&#x2014;are an unconventional ordered combination of operations that operate with a task-action prediction engine as a solution to a specific problem in search technology environment to improve computing operations and interfaces for user interface navigation in search systems. Overall, these improvements result in less CPU computation, smaller memory requirements, and increased flexibility in task management systems when compared to previous conventional task management system operations performed for similar functionality.</p><heading id="h-0006" level="2">Example Distributed Computing System Environment</heading><p id="p-0071" num="0070">Referring now to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example distributed computing environment <b>800</b> in which implementations of the present disclosure may be employed. In particular, <figref idref="DRAWINGS">FIG. <b>8</b></figref> shows a high level architecture of an example cloud computing platform <b>810</b> that can host a technical solution environment, or a portion thereof (e.g., a data trustee environment). It should be understood that this and other arrangements described herein are set forth only as examples. For example, as described above, many of the elements described herein may be implemented as discrete or distributed components or in conjunction with other components, and in any suitable combination and location. Other arrangements and elements (e.g., machines, interfaces, functions, orders, and groupings of functions) can be used in addition to or instead of those shown.</p><p id="p-0072" num="0071">Data centers can support distributed computing environment <b>800</b> that includes cloud computing platform <b>810</b>, rack <b>820</b>, and node <b>830</b> (e.g., computing devices, processing units, or blades) in rack <b>820</b>. The technical solution environment can be implemented with cloud computing platform <b>810</b> that runs cloud services across different data centers and geographic regions. Cloud computing platform <b>810</b> can implement fabric controller <b>840</b> component for provisioning and managing resource allocation, deployment, upgrade, and management of cloud services. Typically, cloud computing platform <b>810</b> acts to store data or run service applications in a distributed manner. Cloud computing infrastructure <b>810</b> in a data center can be configured to host and support operation of endpoints of a particular service application. Cloud computing infrastructure <b>810</b> may be a public cloud, a private cloud, or a dedicated cloud.</p><p id="p-0073" num="0072">Node <b>830</b> can be provisioned with host <b>850</b> (e.g., operating system or runtime environment) running a defined software stack on node <b>830</b>. Node <b>830</b> can also be configured to perform specialized functionality (e.g., compute nodes or storage nodes) within cloud computing platform <b>810</b>. Node <b>830</b> is allocated to run one or more portions of a service application of a tenant. A tenant can refer to a customer utilizing resources of cloud computing platform <b>810</b>. Service application components of cloud computing platform <b>810</b> that support a particular tenant can be referred to as a multi-tenant infrastructure or tenancy. The terms service application, application, or service are used interchangeably herein and broadly refer to any software, or portions of software, that run on top of, or access storage and compute device locations within, a datacenter.</p><p id="p-0074" num="0073">When more than one separate service application is being supported by nodes <b>830</b>, nodes <b>830</b> may be partitioned into virtual machines (e.g., virtual machine <b>852</b> and virtual machine <b>854</b>). Physical machines can also concurrently run separate service applications. The virtual machines or physical machines can be configured as individualized computing environments that are supported by resources <b>860</b> (e.g., hardware resources and software resources) in cloud computing platform <b>810</b>. It is contemplated that resources can be configured for specific service applications. Further, each service application may be divided into functional portions such that each functional portion is able to run on a separate virtual machine. In cloud computing platform <b>810</b>, multiple servers may be used to run service applications and perform data storage operations in a cluster. In particular, the servers may perform data operations independently but exposed as a single device referred to as a cluster. Each server in the cluster can be implemented as a node.</p><p id="p-0075" num="0074">Client device <b>880</b> may be linked to a service application in cloud computing platform <b>810</b>. Client device <b>880</b> may be any type of computing device, which may correspond to computing device <b>800</b> described with reference to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, for example, client device <b>880</b> can be configured to issue commands to cloud computing platform <b>810</b>. In embodiments, client device <b>880</b> may communicate with service applications through a virtual Internet Protocol (IP) and load balancer or other means that direct communication requests to designated endpoints in cloud computing platform <b>810</b>. The components of cloud computing platform <b>610</b> may communicate with each other over a network (not shown), which may include, without limitation, one or more local area networks (LANs) and/or wide area networks (WANs).</p><heading id="h-0007" level="2">Example Distributed Computing Environment</heading><p id="p-0076" num="0075">Having briefly described an overview of embodiments of the present invention, an example operating environment in which embodiments of the present invention may be implemented is described below in order to provide a general context for various aspects of the present invention. Referring initially to <figref idref="DRAWINGS">FIG. <b>9</b></figref> in particular, an example operating environment for implementing embodiments of the present invention is shown and designated generally as computing device <b>900</b>. Computing device <b>900</b> is but one example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention. Neither should computing device <b>900</b> be interpreted as having any dependency or requirement relating to any one or combination of components illustrated.</p><p id="p-0077" num="0076">The invention may be described in the general context of computer code or machine-useable instructions, including computer-executable instructions such as program modules, being executed by a computer or other machine, such as a personal data assistant or other handheld device. Generally, program modules including routines, programs, objects, components, data structures, etc. refer to code that perform particular tasks or implement particular abstract data types. The invention may be practiced in a variety of system configurations, including hand-held devices, consumer electronics, general-purpose computers, more specialty computing devices, etc. The invention may also be practiced in distributed computing environments where tasks are performed by remote-processing devices that are linked through a communications network.</p><p id="p-0078" num="0077">With reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, computing device <b>900</b> includes bus <b>910</b> that directly or indirectly couples the following devices: memory <b>912</b>, one or more processors <b>914</b>, one or more presentation components <b>916</b>, input/output ports <b>918</b>, input/output components <b>920</b>, and illustrative power supply <b>922</b>. Bus <b>910</b> represents what may be one or more buses (such as an address bus, data bus, or combination thereof). The various blocks of <figref idref="DRAWINGS">FIG. <b>9</b></figref> are shown with lines for the sake of conceptual clarity, and other arrangements of the described components and/or component functionality are also contemplated. For example, one may consider a presentation component such as a display device to be an I/O component. Also, processors have memory. We recognize that such is the nature of the art, and reiterate that the diagram of <figref idref="DRAWINGS">FIG. <b>9</b></figref> is merely illustrative of an example computing device that can be used in connection with one or more embodiments of the present invention. Distinction is not made between such categories as &#x201c;workstation,&#x201d; &#x201c;server,&#x201d; &#x201c;laptop,&#x201d; &#x201c;hand-held device,&#x201d; etc., as all are contemplated within the scope of <figref idref="DRAWINGS">FIG. <b>9</b></figref> and reference to &#x201c;computing device.&#x201d;</p><p id="p-0079" num="0078">Computing device <b>900</b> typically includes a variety of computer-readable media. Computer-readable media can be any available media that can be accessed by computing device <b>900</b> and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer-readable media may comprise computer storage media and communication media.</p><p id="p-0080" num="0079">Computer storage media include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device <b>900</b>. Computer storage media excludes signals per se.</p><p id="p-0081" num="0080">Communication media typically embodies computer-readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term &#x201c;modulated data signal&#x201d; means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer-readable media.</p><p id="p-0082" num="0081">Memory <b>912</b> includes computer storage media in the form of volatile and/or nonvolatile memory. The memory may be removable, non-removable, or a combination thereof. Exemplary hardware devices include solid-state memory, hard drives, optical-disc drives, etc. Computing device <b>900</b> includes one or more processors that read data from various entities such as memory <b>912</b> or I/O components <b>920</b>. Presentation component(s) <b>916</b> present data indications to a user or other device. Exemplary presentation components include a display device, speaker, printing component, vibrating component, etc.</p><p id="p-0083" num="0082">I/O ports <b>918</b> allow computing device <b>900</b> to be logically coupled to other devices including I/O components <b>920</b>, some of which may be built in. Illustrative components include a microphone, joystick, game pad, satellite dish, scanner, printer, wireless device, etc.</p><heading id="h-0008" level="1">Additional Structural and Functional Features of Embodiments of the Technical Solution</heading><p id="p-0084" num="0083">Having identified various components utilized herein, it should be understood that any number of components and arrangements may be employed to achieve the desired functionality within the scope of the present disclosure. For example, the components in the embodiments depicted in the figures are shown with lines for the sake of conceptual clarity. Other arrangements of these and other components may also be implemented. For example, although some components are depicted as single components, many of the elements described herein may be implemented as discrete or distributed components or in conjunction with other components, and in any suitable combination and location. Some elements may be omitted altogether. Moreover, various functions described herein as being performed by one or more entities may be carried out by hardware, firmware, and/or software, as described below. For instance, various functions may be carried out by a processor executing instructions stored in memory. As such, other arrangements and elements (e.g., machines, interfaces, functions, orders, and groupings of functions) can be used in addition to or instead of those shown.</p><p id="p-0085" num="0084">Embodiments described in the paragraphs below may be combined with one or more of the specifically described alternatives. In particular, an embodiment that is claimed may contain a reference, in the alternative, to more than one other embodiment. The embodiment that is claimed may specify a further limitation of the subject matter claimed.</p><p id="p-0086" num="0085">The subject matter of embodiments of the invention is described with specificity herein to meet statutory requirements. However, the description itself is not intended to limit the scope of this patent. Rather, the inventors have contemplated that the claimed subject matter might also be embodied in other ways, to include different steps or combinations of steps similar to the ones described in this document, in conjunction with other present or future technologies. Moreover, although the terms &#x201c;step&#x201d; and/or &#x201c;block&#x201d; may be used herein to connote different elements of methods employed, the terms should not be interpreted as implying any particular order among or between various steps herein disclosed unless and except when the order of individual steps is explicitly described.</p><p id="p-0087" num="0086">For purposes of this disclosure, the word &#x201c;including&#x201d; has the same broad meaning as the word &#x201c;comprising,&#x201d; and the word &#x201c;accessing&#x201d; comprises &#x201c;receiving,&#x201d; &#x201c;referencing,&#x201d; or &#x201c;retrieving.&#x201d; Further the word &#x201c;communicating&#x201d; has the same broad meaning as the word &#x201c;receiving,&#x201d; or &#x201c;transmitting&#x201d; facilitated by software or hardware-based buses, receivers, or transmitters using communication media described herein. In addition, words such as &#x201c;a&#x201d; and &#x201c;an,&#x201d; unless otherwise indicated to the contrary, include the plural as well as the singular. Thus, for example, the constraint of &#x201c;a feature&#x201d; is satisfied where one or more features are present. Also, the term &#x201c;or&#x201d; includes the conjunctive, the disjunctive, and both (a or b thus includes either a or b, as well as a and b).</p><p id="p-0088" num="0087">For purposes of a detailed discussion above, embodiments of the present invention are described with reference to a distributed computing environment; however the distributed computing environment depicted herein is merely exemplary. Components can be configured for performing novel aspects of embodiments, where the term &#x201c;configured for&#x201d; can refer to &#x201c;programmed to&#x201d; perform particular tasks or implement particular abstract data types using code. Further, while embodiments of the present invention may generally refer to the technical solution environment and the schematics described herein, it is understood that the techniques described may be extended to other implementation contexts.</p><p id="p-0089" num="0088">Embodiments of the present invention have been described in relation to particular embodiments which are intended in all respects to be illustrative rather than restrictive. Alternative embodiments will become apparent to those of ordinary skill in the art to which the present invention pertains without departing from its scope.</p><p id="p-0090" num="0089">From the foregoing, it will be seen that this invention is one well adapted to attain all the ends and objects hereinabove set forth together with other advantages which are obvious and which are inherent to the structure.</p><p id="p-0091" num="0090">It will be understood that certain features and sub-combinations are of utility and may be employed without reference to other features or sub-combinations. This is contemplated by and is within the scope of the claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer-implemented method, the method comprising:<claim-text>accessing, at a task-action prediction engine, a task associated with a task application;</claim-text><claim-text>determining an intent of the task, wherein determining the intent of the task is based on task features of the task and an intent prediction machine learning model that is trained to predict intents associated with natural language text;</claim-text><claim-text>based on the intent of the task, selecting a predicted task-action based on a task-action computation model that is associated with predefined task-actions and predefined intent-task-categories; and</claim-text><claim-text>communicating the predicted task-action to a task management client.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, the method further comprising accessing, at the task-action engine, a second task associated with a second task application, wherein the task management client is configured to integrate task management for a plurality of application and execute predicted task-actions for the task application and the second task application via a predicted task-action interface of the task management client.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, the method further comprising:<claim-text>receiving session credentials from the task management client;</claim-text><claim-text>based on receiving session credentials, authenticating a user with a data analytics service that provides access to data analytics service data that is used in selecting the predicted task-action.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein selecting a predicted task-action comprises:<claim-text>comparing task features of the task to intent-task-category features corresponding to each intent-task-category of the predefined intent-task-categories; and</claim-text><claim-text>based on comparing the task features of the task to the intent-task-category features, generating an intent score, wherein the intent score indicates a quantified likelihood that the task corresponds to a predefined intent-task-category.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, the method further comprising:<claim-text>generating supplemental task-action data; and</claim-text><claim-text>causing the supplemental task-action data to be displayed in association with the predicted task-action on a predicted task action interface.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predefined intent-task-categories comprise each of the following: communication, document, learning, find time, and travel and expenses.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the task-action computation model is configured to:<claim-text>identify a plurality of predicted task-actions for the task, wherein each of the plurality of predicted task-actions is associated with an intent score; and</claim-text><claim-text>based on an intent score of the predicted task-action and corresponding intent scores of the plurality of predicted task-actions, select the predicted task-action from the plurality task-action; and</claim-text><claim-text>cause communication of the predicted task-action to the task management client.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. One or more computer-storage media having computer-executable instructions embodied thereon that, when executed by a computing system having a processor and memory, cause the processor to:<claim-text>communicate, from a task management client, a request for task data;</claim-text><claim-text>based on communicating the request, receive a predicted task-action from a task-action prediction engine, wherein the predicted task-action is predicted based on an intent of the task and task features of the task, wherein the intent of task is determined using an intent prediction machine learning model that is trained to predict intents associated with natural language text;</claim-text><claim-text>causing display of the predicted task-action, wherein the predicted task-action is caused to be displayed in combination with a predicted task-action interface element associated with executing the predicted task-action;</claim-text><claim-text>receiving an indication to execute the predicted task-action; and</claim-text><claim-text>causing execution of the predicted task-action.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The media of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the task management client integrates task management for a plurality of task applications and supports executing predicted task-actions via a predicted task-action interface of the task management client.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The media of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the task management client provides session credentials to the task-action prediction engine, wherein the session credentials are associated with authenticating a user with a data analytics service that provides access to data analytics service data that is used in selecting the predicted task-action.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The media of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the task features of the task are compared to intent-task-category features corresponding to each of the intent-task-categories of the predefined intent-task-categories, wherein comparing the task features to the intent-task-category features is associated with corresponding intent scores that indicate a quantified likelihood that the task corresponds to a predefined intent-task-category.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The media of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising instruction to:<claim-text>generate supplemental task-action data; and</claim-text><claim-text>cause the supplemental task-action data to be displayed in association with the predicted task-action on a predicted task action interface.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The media of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the predefined intent-task-categories comprise each of the following: communication, document, learning, find time, and travel and expenses.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The media of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein communicating the predicted task-action over a plurality of predicted task-actions for the task is based on an intent score associated with the predefined task-action.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A computerized system, the system comprising:<claim-text>one or more computer processors; and</claim-text><claim-text>computer memory storing computer-useable instructions that, when used by the one or more computer processors, cause the one or more computer processors to perform operations comprising:</claim-text><claim-text>communicating a request for task data, wherein the request is communicated from a task management client to a task-action prediction engine;</claim-text><claim-text>based on receiving the request, accessing, at the task-action prediction engine, a task associated with a task application;</claim-text><claim-text>determining an intent of the task, wherein determining the intent of the tasks is based on task features of the task and an intent prediction machine learning model that is trained to predict intents using natural language text;</claim-text><claim-text>based on the intent of the task, selecting a predicted task-action based on a task-action computation model that is associated with predefined task-actions and predefined intent-task-categories; and</claim-text><claim-text>communicating the predicted task-action to the task management client.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, the operations further comprising accessing, at the task-action engine, a second task associated with a second task application, wherein the task management client is configured to integrate task management for a plurality of application and execute predicted task-actions for the task application and the second task application via a predicted task-action interface of the task management client.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, the operations further comprising:<claim-text>receiving session credentials from the task management client;</claim-text><claim-text>based on receiving session credentials, authenticating a user with a data analytics service that provides access to data analytics service data that is used in selecting the predicted task-action.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein selecting a predicted task-action comprises:<claim-text>comparing task features of the task to intent-task-category features corresponding to each intent-task-category of the predefined intent-task-categories; and</claim-text><claim-text>based on comparing the task features of the task to the intent-task-category features, generating an intent score, wherein the intent score indicates a quantified likelihood that the task corresponds to a predefined intent-task-category.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, the operations further comprising:<claim-text>generating supplemental task-action data; and</claim-text><claim-text>causing the supplemental task-action data to be displayed in association with the predicted task-action on a predicted task action interface.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the predefined intent-task-categories comprise each of the following: communication, document, learning, find time, and travel and expenses.</claim-text></claim></claims></us-patent-application>
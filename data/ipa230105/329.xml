<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000330A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221220" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000330</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17902031</doc-number><date>20220902</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>1</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>1</main-group><subgroup>0638</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>1</main-group><subgroup>00009</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220201</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>1</main-group><subgroup>0655</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">MEDICAL OBSERVATION SYSTEM, MEDICAL IMAGING DEVICE AND IMAGING METHOD</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2020/009883</doc-number><date>20200306</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17902031</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>OLYMPUS CORPORATION</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>IGARASHI</last-name><first-name>Takaaki</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>OLYMPUS CORPORATION</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A medical observation system includes: a light source configured to emit, to body tissue, at least one of first narrow band light and second narrow band light; an imaging element that includes: a pixel portion including plural pixels arranged in a two-dimensional matrix; and a color filter including red filters, green filters, and blue filters that are provided on light receiving surfaces of the plural pixels, each of the light receiving surfaces including any one filter of the red, green, and blue filters on each of the light receiving surfaces; and a cut filter that is provided on a light receiving surface side of at least the pixels provided with the green filters, the cut filter being configured to shield light of a shorter wavelength band including the wavelength band of the second narrow band light, and transmit therethrough the first narrow band light.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="102.79mm" wi="126.83mm" file="US20230000330A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="123.19mm" wi="128.86mm" file="US20230000330A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="224.96mm" wi="151.30mm" orientation="landscape" file="US20230000330A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="215.98mm" wi="134.45mm" file="US20230000330A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="217.17mm" wi="134.45mm" file="US20230000330A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="215.31mm" wi="48.01mm" file="US20230000330A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="189.31mm" wi="100.92mm" file="US20230000330A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="221.83mm" wi="147.74mm" orientation="landscape" file="US20230000330A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="221.74mm" wi="148.17mm" orientation="landscape" file="US20230000330A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="225.13mm" wi="153.67mm" orientation="landscape" file="US20230000330A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="219.20mm" wi="148.08mm" orientation="landscape" file="US20230000330A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="201.00mm" wi="154.26mm" orientation="landscape" file="US20230000330A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="168.91mm" wi="91.78mm" file="US20230000330A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="165.18mm" wi="91.78mm" file="US20230000330A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="152.57mm" wi="91.78mm" file="US20230000330A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="149.10mm" wi="91.78mm" file="US20230000330A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="103.04mm" wi="66.63mm" file="US20230000330A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="226.74mm" wi="126.32mm" file="US20230000330A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="214.55mm" wi="147.66mm" orientation="landscape" file="US20230000330A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="211.24mm" wi="126.07mm" file="US20230000330A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="111.00mm" wi="139.62mm" file="US20230000330A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="225.47mm" wi="81.96mm" file="US20230000330A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="217.68mm" wi="133.94mm" file="US20230000330A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00023" num="00023"><img id="EMI-D00023" he="99.82mm" wi="90.25mm" file="US20230000330A1-20230105-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00024" num="00024"><img id="EMI-D00024" he="191.52mm" wi="142.41mm" file="US20230000330A1-20230105-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00025" num="00025"><img id="EMI-D00025" he="224.96mm" wi="149.52mm" orientation="landscape" file="US20230000330A1-20230105-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00026" num="00026"><img id="EMI-D00026" he="188.89mm" wi="138.09mm" file="US20230000330A1-20230105-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00027" num="00027"><img id="EMI-D00027" he="190.92mm" wi="51.90mm" file="US20230000330A1-20230105-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00028" num="00028"><img id="EMI-D00028" he="204.55mm" wi="134.45mm" file="US20230000330A1-20230105-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This application is a continuation of International Application No. PCT/JP2020/009883, filed on Mar. 6, 2020, the entire contents of which are incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">1. Technical Field</heading><p id="p-0003" num="0002">The present disclosure relates to a medical observation system, a medical imaging device, and an imaging method that generate image data on an object, such as a subject, by imaging the object.</p><heading id="h-0004" level="1">2. Related Art</heading><p id="p-0004" num="0003">In the related art, two imaging elements are provided in an endoscope, light for emission is switched between first narrow band light and second narrow band light having wavelength bands different from each other according to observation modes, and one of the two imaging elements is caused to perform imaging correspondingly to an observation mode (see, for example, Japanese Patent No. 5371946). When narrow band light observation is performed using this technique, imaging is performed by a first imaging element through irradiation of a subject with the first narrow band light, the first imaging element including, on a light receiving surface thereof, a light shielding filter that blocks reflected light from the subject at a predetermined light shielding rate. According to Japanese Patent No. 5371946, when first autofluorescence light observation is performed, first autofluorescence emitted from the subject by irradiation of the subject with the first narrow band light serving as excitation light is imaged by the first imaging element via the light shielding filter, and in a second autofluorescence light observation mode, second autofluorescence emitted from the subject by irradiation of the subject with the second narrow band light serving as excitation light is imaged by a second imaging element.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0005" num="0004">In some embodiments, a medical observation system includes: a light source configured to emit, to body tissue, at least one of: first narrow band light having a wavelength band narrower than a wavelength band of white light; and second narrow band light that has a wavelength band shorter than the wavelength band of the first narrow band light and causes excitation of an advanced glycation end product produced by performing a heat treatment on the body tissue; an imaging element that includes: a pixel portion including plural pixels arranged in a two-dimensional matrix; and a color filter including red filters, green filters, and blue filters that are provided on light receiving surfaces of the plural pixels, each of the light receiving surfaces including any one filter of the red, green, and blue filters on each of the light receiving surfaces, the imaging element being configured to generate image data by imaging at least one of returned light from the body tissue and fluorescence from the advanced glycation end product; and a cut filter that is provided on a light receiving surface side of at least the pixels provided with the green filters, the cut filter being configured to shield light of a shorter wavelength band including the wavelength band of the second narrow band light, and transmit therethrough the first narrow band light.</p><p id="p-0006" num="0005">In some embodiments, provided is a medical observation system equipped with a narrow band light observation mode and a heat treatment observation mode. The medical observation system includes: a light source configured to illuminate body tissue with: blue light that is to illuminate the body tissue in the narrow band light observation mode, is highly absorbed by hemoglobin in blood, and is easily reflected by a mucosal surface layer; and blue light that is to illuminate the body tissue in the heat treatment observation mode and excites an advanced glycation end product generated by performing a heat treatment on the body tissue; an imaging element to be commonly used in the narrow band light observation mode and the heat treatment observation mode, the imaging element including: a pixel portion including plural pixels arranged in a two-dimensional matrix; and a color filter including red filters, green filters, and blue filters that are provided on light receiving surfaces of the plural pixels, each of the light receiving surfaces including any one filter of the red, green, and blue filters on each of the light receiving surfaces, the imaging element being configured to generate image data by imaging at least one of returned light from the body tissue and fluorescence from the advanced glycation end product; and a cut filter that is provided on a light receiving surface side of at least the pixels provided with the green filters, the cut filter being configured to shield light of a wavelength band including a wavelength band of the fluorescence, and transmit therethrough the blue light.</p><p id="p-0007" num="0006">In some embodiments, a medical imaging device includes: an imaging element including: a pixel portion including plural pixels arranged in a two-dimensional matrix; and a color filter including red filters, green filters, and blue filters that are provided on light receiving surfaces of the plural pixels, each of the light receiving surfaces including any one filter of the red, green, and blue filters on each of the light receiving surfaces; and a cut filter provided on a light receiving surface side of at least the pixels provided with the green filters, the imaging element being configured to generate image data by imaging at least one of: returned light from body tissue when first narrow band light having a wavelength band narrower than a wavelength band of white light has been emitted to the body tissue; and fluorescence from an advanced glycation end product generated by performing a heat treatment on the body tissue when second narrow band light that excites the advanced glycation end product has been emitted to the advanced glycation end product, the second narrow band light having a wavelength band shorter than the wavelength band of the first narrow band light, and the cut filter being configured to shield light having a shorter wavelength band including a wavelength band of the second narrow band light and transmit therethrough the first narrow band light.</p><p id="p-0008" num="0007">In some embodiments, a medical imaging device includes: an imaging element including: a pixel portion including plural pixels arranged in a two-dimensional matrix; and a color filter including red filters, green filters, and blue filters that are provided on light receiving surfaces of the plural pixels, each of the light receiving surfaces including any one filter of the red, green, and blue filters on each of the light receiving surfaces, the imaging element being configured to generate image data by imaging at least one of: returned light from body tissue when first narrow band light having a wavelength band narrower than a wavelength band of white light has been emitted to the body tissue; and fluorescence from an advanced glycation end product generated by performing a heat treatment on the body tissue when second narrow band light that excites the advanced glycation end product has been emitted to the advanced glycation end product, the second narrow band light having a wavelength band shorter than the wavelength band of the first narrow band light, and the green filters being configured to shield light having a shorter wavelength band including the wavelength band of the second narrow band light and transmit therethrough the first narrow band light.</p><p id="p-0009" num="0008">In some embodiments, an imaging method includes: emitting, by a light source, narrow band light to excite an advanced glycation end product, to body tissue, capturing, by blue pixels of an imaging element, an image of first light of: returned light from the body tissue; and fluorescence from the advanced glycation end product, the first light having passed through blue filters configured to mainly transmit therethrough light of a blue wavelength band, and capturing, by green pixels of the imaging element, an image of second light of: the returned light from the body tissue; and the fluorescence from the advanced glycation end product, the second light having passed through a cut filter to shield light shorter in wavelength than the fluorescence and having passed through green filters configured to mainly transmit therethrough light of a green wavelength band.</p><p id="p-0010" num="0009">The above and other features, advantages and technical and industrial significance of this disclosure will be better understood by reading the following detailed description of presently preferred embodiments of the disclosure, when considered in connection with the accompanying drawings.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating a schematic configuration of an endoscope system according to a first embodiment;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating a functional configuration of main parts of the endoscope system according to the first embodiment;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram schematically illustrating wavelength characteristics of light emitted by a second light source portion and a third light source portion, according to the first embodiment;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram schematically illustrating a configuration of a pixel portion according to the first embodiment;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram schematically illustrating a configuration of a color filter according to the first embodiment;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram schematically illustrating sensitivity and wavelength bands of filters, according to the first embodiment;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> is a diagram schematically illustrating signal values of G pixels of an imaging element according to the first embodiment;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> is a diagram schematically illustrating signal values of R pixels of the imaging element according to the first embodiment;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>7</b>C</figref> is a diagram schematically illustrating signal values of B pixels of the imaging element according to the first embodiment;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram schematically illustrating a configuration of a cut filter according to the first embodiment;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram schematically illustrating transmission characteristics of the cut filter according to the first embodiment;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram schematically illustrating principles of observation in a narrow band light observation mode according to the first embodiment;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram schematically illustrating principles of observation in a heat treatment observation mode according to the first embodiment;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram schematically illustrating principles of observation in an autofluorescence observation mode according to the first embodiment;</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram schematically illustrating principles of observation in a normal light observation mode according to the first embodiment;</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart illustrating an outline of processing executed by the endoscope system according to the first embodiment;</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart illustrating an outline of narrow band light observation mode processing in <figref idref="DRAWINGS">FIG. <b>14</b></figref>;</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a flowchart illustrating an outline of heat treatment observation mode processing in <figref idref="DRAWINGS">FIG. <b>14</b></figref>;</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flowchart illustrating an outline of autofluorescence observation mode processing in <figref idref="DRAWINGS">FIG. <b>14</b></figref>;</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a flowchart illustrating an outline of normal light observation mode processing in <figref idref="DRAWINGS">FIG. <b>14</b></figref>;</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a flowchart illustrating an outline of processing executed by an endoscope system according to a second embodiment;</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a flowchart illustrating an outline of imaging recording processing in <figref idref="DRAWINGS">FIG. <b>19</b></figref>;</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>21</b></figref> is a flowchart illustrating an outline of display processing in <figref idref="DRAWINGS">FIG. <b>19</b></figref>;</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>22</b></figref> is a diagram illustrating an example of an image displayed by a display device according to the second embodiment;</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>23</b></figref> is a diagram illustrating an example of an image displayed by the display device according to the second embodiment;</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>24</b></figref> is a diagram illustrating another example of the image displayed by the display device according to the second embodiment;</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>25</b>A</figref> is a diagram illustrating another example of the image displayed by the display device according to the second embodiment;</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>25</b>B</figref> is a diagram illustrating another example of the image displayed by the display device according to the second embodiment;</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>25</b>C</figref> is a diagram illustrating another example of the image displayed by the display device according to the second embodiment;</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>26</b></figref> is a diagram illustrating an example of an image displayed by the display device according to the second embodiment;</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>27</b></figref> is a diagram illustrating correspondence between intensity of fluorescence and depth of heat treatment;</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>28</b></figref> is a diagram illustrating another example of the image displayed by the display device according to the second embodiment;</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>29</b></figref> is a diagram illustrating a schematic configuration of an endoscope system according to a third embodiment;</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>30</b></figref> is a block diagram illustrating a functional configuration of main parts of the endoscope system according to the third embodiment;</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>31</b></figref> is a diagram illustrating a schematic configuration of a surgical microscope system according to a fourth embodiment;</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>32</b></figref> is a diagram schematically illustrating a configuration of a cut filter according to a first modified example of the first to fourth embodiments;</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>33</b>A</figref> is a diagram schematically illustrating a method of manufacturing the cut filter according to the first modified example of the first to fourth embodiments;</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>33</b>B</figref> is a diagram schematically illustrating the method of manufacturing the cut filter according to the first modified example of the first to fourth embodiments;</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>34</b></figref> is a diagram schematically illustrating transmission characteristics of a filter G of a color filter according to a second modified example of the first to fourth embodiments; and</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>35</b></figref> is a diagram schematically illustrating a configuration of a cut filter according to a third modified example of the first to fourth embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0051" num="0050">Modes for implementing the present disclosure will hereinafter be described in detail, together with the drawings. The present disclosure is not limited by the following embodiments. Furthermore, the drawings referred to in the following description schematically depict shapes, sizes, and positional relations merely to an extent that allows substance of the present disclosure to be understood. That is, the present disclosure is not limited only to the shapes, sizes, and positional relations exemplified by the drawings. In addition, any portions that are the same will be assigned with the same reference sign throughout the drawings. An endoscope system including a rigid endoscope and a medical imaging device will be described as an example of a medical observation system according to the present disclosure.</p><heading id="h-0008" level="1">First Embodiment</heading><p id="p-0052" num="0051">Configuration of Endoscope System <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating a schematic configuration of an endoscope system according to a first embodiment. An endoscope system <b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a system that is used in the medical field and is for observation of body tissue in a subject, such as an organism. For this first embodiment, a rigid endoscope system using a rigid endoscope (an insertion portion <b>2</b>) illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> will be described as the endoscope system <b>1</b>, but without being limited to the rigid endoscope system, the endoscope system <b>1</b> may be, for example, an endoscope system including a flexible endoscope. The endoscope system <b>1</b> may also be a system including a medical imaging device that captures an image of a subject and where surgery or treatment is conducted while a display image based on image data captured by this medical imaging device is being displayed by a display device. The endoscope system <b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is used when surgery or treatment of a subject is conducted by use of a treatment tool (not illustrated in the drawings), such as an electrosurgical knife or an energy device, which enables heat treatment.</p><p id="p-0053" num="0052">The endoscope system <b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> includes the insertion portion <b>2</b>, a light source device <b>3</b>, a light guide <b>4</b>, an endoscope camera head <b>5</b> (an imaging device for an endoscope), a first transmission cable <b>6</b>, a display device <b>7</b>, a second transmission cable <b>8</b>, a control device <b>9</b>, and a third transmission cable <b>10</b>.</p><p id="p-0054" num="0053">The insertion portion <b>2</b> is rigid or at least a part of the insertion portion <b>2</b> is flexible, and the insertion portion <b>2</b> has an elongated shape. The insertion portion <b>2</b> is inserted into a subject, such as a patient, via a trocar. The insertion portion <b>2</b> has, provided therein, an optical system, such as a lens, that forms an observation image.</p><p id="p-0055" num="0054">One end of the light guide <b>4</b> is connected to the light source device <b>3</b>, and the light source device <b>3</b> supplies, under control by the control device <b>9</b>, illumination light to be emitted to the interior of a subject, to that one end of the light guide <b>4</b>. The light source device <b>3</b> is implemented by use of: any one or more selected from a group of a light emitting diode (LED) light source, a xenon lamp, and a semiconductor laser element, such as a laser diode (LD); a processor that is a processing device having hardware, such as a field programmable gate array (FPGA) or a central processing unit (CPU); and a memory that is a transitory storage area used by the processor. The light source device <b>3</b> and the control device <b>9</b> may be configured to perform communication individually as illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> or may be configured to be integrated with each other.</p><p id="p-0056" num="0055">The one end of the light guide <b>4</b> is detachably connected to the light source device <b>3</b> and the other end of the light guide <b>4</b> is detachably connected to the insertion portion <b>2</b>. The light guide <b>4</b> guides the illumination light supplied from the light source device <b>3</b> to the other end from the one end, to supply the illumination light to the insertion portion <b>2</b>.</p><p id="p-0057" num="0056">An eyepiece unit <b>21</b> of the insertion portion <b>2</b> is detachably connected to the endoscope camera head <b>5</b>. Under control by the control device <b>9</b>, the endoscope camera head <b>5</b> generates image data (RAW data) by receiving an observation image formed by the insertion portion <b>2</b> and performing photoelectric conversion of the observation image, and outputs the image data to the control device <b>9</b> via the first transmission cable <b>6</b>.</p><p id="p-0058" num="0057">One end of the first transmission cable <b>6</b> is detachably connected to the control device <b>9</b> via a video connector <b>61</b>, and the other end of the first transmission cable <b>6</b> is detachably connected to the endoscope camera head <b>5</b> via a camera head connector <b>62</b>. The first transmission cable <b>6</b> transmits the image data output from the endoscope camera head <b>5</b> to the control device <b>9</b> and transmits, for example, setting data and electric power output from the control device <b>9</b>, to the endoscope camera head <b>5</b>. The setting data include a control signal, a synchronization signal, and a clock signal for controlling the endoscope camera head <b>5</b>.</p><p id="p-0059" num="0058">Under control by the control device <b>9</b>, the display device <b>7</b> displays a display image based on the image data that have been subjected to image processing at the control device <b>9</b>, and various kinds of information related to the endoscope system <b>1</b>. The display device <b>7</b> is implemented by use of a display monitor of, for example, liquid crystal or organic electroluminescence (EL).</p><p id="p-0060" num="0059">One end of the second transmission cable <b>8</b> is detachably connected to the display device <b>7</b>, and the other end of the second transmission cable <b>8</b> is detachably connected to the control device <b>9</b>. The second transmission cable <b>8</b> transmits the image data that have been subjected to the image processing at the control device <b>9</b>, to the display device <b>7</b>.</p><p id="p-0061" num="0060">The control device <b>9</b> is implemented by use of a processor that is a processing device having hardware, such as a graphics processing unit (GPU), an FPGA, or a CPU, and a memory that is a transitory storage area used by the processor. According to a program recorded in the memory, the control device <b>9</b> integrally controls operation of the light source device <b>3</b>, the endoscope camera head <b>5</b>, and the display device <b>7</b>, via each of the first transmission cable <b>6</b>, the second transmission cable <b>8</b>, and the third transmission cable <b>10</b>. Furthermore, the control device <b>9</b> performs various kinds of image processing of the image data input via the first transmission cable <b>6</b> and outputs the image processed image data to the second transmission cable <b>8</b>.</p><p id="p-0062" num="0061">One end of the third transmission cable <b>10</b> is detachably connected to the light source device <b>3</b>, and the other end of the third transmission cable <b>10</b> is detachably connected to the control device <b>9</b>. The third transmission cable <b>10</b> transmits control data from the control device <b>9</b> to the light source device <b>3</b>.</p><p id="p-0063" num="0062">Functional Configuration of Main Parts of Endoscope System</p><p id="p-0064" num="0063">A functional configuration of main parts of the endoscope system <b>1</b> described above will be described next. <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating the functional configuration of the main parts of the endoscope system <b>1</b>.</p><p id="p-0065" num="0064">Configuration of Insertion Portion A configuration of the insertion portion <b>2</b> will be described first. The insertion portion <b>2</b> includes an optical system <b>22</b> and an illumination optical system <b>23</b>.</p><p id="p-0066" num="0065">The optical system <b>22</b> forms a subject image by condensing light, such as reflected light reflected by a subject, returned light from a subject, excitation light from a subject, and/or light emitted by a subject. The optical system <b>22</b> is implemented by use of, for example, one or plural lenses.</p><p id="p-0067" num="0066">The illumination optical system <b>23</b> outputs illumination light supplied from the light guide <b>4</b>, to a subject. The illumination optical system <b>23</b> is implemented by use of, for example, one or plural lenses.</p><p id="p-0068" num="0067">Configuration of Light Source Device A configuration of the light source device <b>3</b> will be described next. The light source device <b>3</b> includes a condenser lens <b>30</b>, a first light source portion <b>31</b>, a second light source portion <b>32</b>, a third light source portion <b>33</b>, and a light source control unit <b>34</b>.</p><p id="p-0069" num="0068">The condenser lens <b>30</b> condenses light emitted by each of the first light source portion <b>31</b>, the second light source portion <b>32</b>, and the third light source portion <b>33</b> and outputs the condensed light to the light guide <b>4</b>.</p><p id="p-0070" num="0069">Under control by the light source control unit <b>34</b>, the first light source portion <b>31</b> supplies illumination light that is white light to the light guide <b>4</b> by emitting white light (normal light) that is visible light. The first light source portion <b>31</b> is configured by use of, for example, a collimator lens, a white LED lamp, and a driver. The first light source portion <b>31</b> may supply visible white light by simultaneous emission using a red LED lamp, a green LED lamp, and a blue LED lamp. Of course, the first light source portion <b>31</b> may be configured by use of, for example, a halogen lamp or a xenon lamp.</p><p id="p-0071" num="0070">Under control by the light source control unit <b>34</b>, the second light source portion <b>32</b> supplies illumination light that is first narrow band light having a predetermined wavelength band, to the light guide <b>4</b> by emitting the first narrow band light. The wavelength band of this first narrow band light is 530 nm to 550 nm (with a central wavelength of 540 nm). The second light source portion <b>32</b> is configured by use of, for example, a green LED lamp, a collimator lens, a transmission filter that transmits therethrough light of 530 nm to 550 nm, and a driver.</p><p id="p-0072" num="0071">Under control by the light source control unit <b>34</b>, the third light source portion <b>33</b> supplies illumination light that is second narrow band light having a wavelength band different from that of the first narrow band light, to the light guide <b>4</b> by emitting the second narrow band light. The wavelength band of this second narrow band light is 400 nm to 430 nm (with a central wavelength of 515 nm). The third light source portion <b>33</b> is implemented by use of, for example, a collimator lens, a semiconductor laser, such as a violet laser diode (LD), and a driver.</p><p id="p-0073" num="0072">The light source control unit <b>34</b> is implemented by use of a processor that is a processing device having hardware, such as an FPGA or a CPU, and a memory that is a transitory storage area used by the processor. On the basis of control data input from the control device <b>9</b>, the light source control unit <b>34</b> controls the emission timing and emission time period of each of the first light source portion <b>31</b>, the second light source portion <b>32</b>, and the third light source portion <b>33</b>.</p><p id="p-0074" num="0073">The following is a description of wavelength characteristics of light emitted by each of the second light source portion <b>32</b> and the third light source portion <b>33</b>. <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram schematically illustrating the wavelength characteristics of the light emitted by each of the second light source portion <b>32</b> and the third light source portion <b>33</b>. In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the horizontal axis represents wavelength in nanometers (nm), and the vertical axis represents the wavelength characteristics. In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a polygonal line L<sub>NG </sub>represents wavelength characteristics of the first narrow band light emitted by the second light source portion <b>32</b> and a polygonal line L<sub>V </sub>represents wavelength characteristics of the second narrow band light emitted by the third light source portion <b>33</b>. Furthermore, in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a curve L<sub>B </sub>represents a blue wavelength band, a curve L<sub>G </sub>represents a green wavelength band, and a curve L<sub>R </sub>represents a red wavelength band.</p><p id="p-0075" num="0074">As represented by the polygonal line L<sub>NG </sub>in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the second light source portion <b>32</b> emits the first narrow band light having the central wavelength (peak wavelength) of 540 nm and the wavelength band of 530 nm to 550 nm. The third light source portion <b>33</b> emits the second narrow band light having the central wavelength (peak wavelength) of 415 nm and the wavelength band of 400 nm to 430 nm.</p><p id="p-0076" num="0075">As described above, the second light source portion <b>32</b> and the third light source portion <b>33</b> respectively emit the first narrow band light and second narrow band light having wavelength bands different from each other.</p><p id="p-0077" num="0076">Configuration of Endoscope Camera Head</p><p id="p-0078" num="0077">By reference back to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the description of the configuration of the endoscope system <b>1</b> will be continued.</p><p id="p-0079" num="0078">A configuration of the endoscope camera head <b>5</b> will be described next. The endoscope camera head <b>5</b> includes an optical system <b>51</b>, a drive unit <b>52</b>, an imaging element <b>53</b>, a cut filter <b>54</b>, an A/D converter <b>55</b>, a P/S converter <b>56</b>, an imaging recording unit <b>57</b>, and an imaging control unit <b>58</b>.</p><p id="p-0080" num="0079">The optical system <b>51</b> forms, on a light receiving surface of the imaging element <b>53</b>, a subject image condensed by the optical system <b>22</b> of the insertion portion <b>2</b>. The focal length and the focal position of the optical system <b>51</b> are able to be changed. The optical system <b>51</b> is configured by use of plural lenses <b>511</b>. In the optical system <b>51</b>, the plural lenses <b>511</b> are moved along an optical axis L<b>1</b> by the drive unit <b>52</b>, and the focal distance and focal position are thereby changed.</p><p id="p-0081" num="0080">Under control by the imaging control unit <b>58</b>, the drive unit <b>52</b> moves the plural lenses <b>511</b> of the optical system <b>51</b> along the optical axis L<b>1</b>. The drive unit <b>52</b> is configured by use of: a motor, such as a stepping motor, a DC motor, or a voice coil motor; and a transmission mechanism, such as a gear, that transmits rotation of the motor to the optical system <b>51</b>.</p><p id="p-0082" num="0081">The imaging element <b>53</b> is implemented by use of a charge coupled device (CCD) image sensor or a complementary metal oxide semiconductor (CMOS) image sensor, which has plural pixels arranged in a two-dimensional matrix. Under control by the imaging control unit <b>58</b>, the imaging element <b>53</b> receives, via the cut filter <b>54</b>, a subject image (light rays) formed by the optical system <b>51</b>, photoelectrically converts the subject image to generate image data (RAW data), and outputs the image data to the A/D converter <b>55</b>. The imaging element <b>53</b> includes a pixel portion <b>531</b> and a color filter <b>532</b>.</p><p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram schematically illustrating a configuration of the pixel portion <b>531</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the pixel portion <b>531</b> has plural pixels P<sub>nm </sub>(n is an integer equal to or larger than 1 and m is an integer equal to or larger than 1), such as photodiodes that accumulate electric charge corresponding to quantity of light, the plural pixels P<sub>nm </sub>being arranged in a two-dimensional matrix. Under control by the imaging control unit <b>58</b>, the pixel portion <b>531</b> reads image data that are image signals from some pixels P<sub>nm </sub>of a read area optionally set as a target to be read from the plural pixels P<sub>nm </sub>and outputs the image data to the A/D converter <b>55</b>.</p><p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram schematically illustrating a configuration of the color filter <b>532</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the color filter <b>532</b> has a Bayer arrangement having 2&#xd7;2 filters as a single unit. The color filter <b>532</b> is configured by use of a filter R that transmits therethrough light of the red wavelength band, two filters G that transmit therethrough light of the green wavelength band, and a filter B that transmits therethrough light of the blue wavelength band.</p><p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram schematically illustrating sensitivity and the wavelength band of each filter. In <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the horizontal axis represents wavelength in nanometers (nm) and the vertical axis represents transmission characteristics (sensitivity characteristics). In <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a curve L<sub>B </sub>represents the transmission characteristics of the filter B, a curve L<sub>G </sub>represents transmission characteristics of the filter G, and a curve L<sub>R </sub>represents the transmission characteristics of the filter R.</p><p id="p-0086" num="0085">As represented by the curve L<sub>B </sub>in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the filter B transmits therethrough light of the blue wavelength band. As represented by the curve L<sub>G </sub>in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the filter G transmits therethrough light of the green wavelength band. As represented by the curve L<sub>R </sub>in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the filter R transmits therethrough light of the red wavelength band. In the following description, pixels P<sub>nm </sub>having filters R arranged on light receiving surfaces thereof will be referred to as R pixels, pixels P<sub>nm </sub>having filters G arranged on light receiving surfaces thereof will be referred to as G pixels, and pixels P<sub>nm </sub>having filters B arranged on light receiving surfaces thereof will be referred to as B pixels.</p><p id="p-0087" num="0086">In a case where a subject image formed by the optical system <b>51</b> is received by the imaging element <b>53</b> configured as described above, the imaging element <b>53</b> generates, as illustrated in FIG. <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>7</b>C</figref>, color signals (R signals, G signals, and B signals) of the R pixels, G pixels, and B pixels respectively.</p><p id="p-0088" num="0087">By reference back to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the description of the configuration of the endoscope system <b>1</b> will be continued.</p><p id="p-0089" num="0088">The cut filter <b>54</b> is arranged on the optical axis L<b>1</b> of the optical system <b>51</b> and the imaging element <b>53</b>. The cut filter <b>54</b> is provided on a light receiving surface side (incident surface side) of at least the G pixels provided with the filters G of the color filter <b>532</b>, the filters G transmitting therethrough light of the green wavelength band. The cut filter <b>54</b> shields light of a short wavelength band including the wavelength band of the second narrow band light, and transmits therethrough light that includes the first narrow band light and that is light of a wavelength band longer than the wavelength band of the second narrow band light.</p><p id="p-0090" num="0089"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram schematically illustrating a configuration of the cut filter <b>54</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, a filter F<sub>11 </sub>included in the cut filter <b>54</b> is arranged at a position where a filter G<sub>11 </sub>(see <figref idref="DRAWINGS">FIG. <b>5</b></figref>) is arranged and on a light receiving surface side directly above the filter G<sub>11</sub>.</p><p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram schematically illustrating transmission characteristics of the cut filter <b>54</b>. In <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the horizontal axis represents wavelength in nanometers (nm), and the vertical axis represents the transmission characteristics. Furthermore, in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, a polygonal line L<sub>F </sub>represents the transmission characteristics of the cut filter <b>54</b>, the polygonal line L<sub>NG </sub>represents the wavelength characteristics of the first narrow band light, and the polygonal line L<sub>V </sub>represents the wavelength characteristics of the second narrow band light.</p><p id="p-0092" num="0091">As illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the cut filter <b>54</b> shields the second narrow band light and transmits therethrough light of a wavelength band longer than the wavelength band of the second narrow band light. Specifically, the cut filter <b>54</b> shields light of a shorter wavelength band including the wavelength band of the second narrow band light and of 400 nm or longer and shorter than 430 nm, and transmits therethrough light of a wavelength band longer than 400 nm to 430 nm including the second narrow band light.</p><p id="p-0093" num="0092">By reference back to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the description of the configuration of the endoscope camera head <b>5</b> will be continued.</p><p id="p-0094" num="0093">Under control by the imaging control unit <b>58</b>, the A/D converter <b>55</b> performs A/D conversion processing of analog image data input from the imaging element <b>53</b> and outputs the converted image data to the P/S converter <b>56</b>. The A/D converter <b>55</b> is implemented by use of, for example, an A/D conversion circuit.</p><p id="p-0095" num="0094">Under control by the imaging control unit <b>58</b>, the P/S converter <b>56</b> performs parallel/serial conversion of digital image data input from the A/D converter <b>55</b>, and outputs the image data that has been subjected to the parallel/serial conversion, to the control device <b>9</b>, via the first transmission cable <b>6</b>. The P/S converter <b>56</b> is implemented by use of, for example, a P/S conversion circuit. In this first embodiment, an E/O converter that converts image data into an optical signal may be provided instead of the P/S converter <b>56</b>, and the image data may be output through the optical signal to the control device <b>9</b>, or image data may be transmitted to the control device <b>9</b> by wireless communication, such as Wi-Fi (wireless fidelity) (registered trademark), for example.</p><p id="p-0096" num="0095">The imaging recording unit <b>57</b> records therein various kinds of information related to the endoscope camera head <b>5</b> (for example, pixel information on the imaging element <b>53</b> and characteristics of the cut filter <b>54</b>). Furthermore, the imaging recording unit <b>57</b> records therein various kinds of setting data and control parameters transmitted from the control device <b>9</b> via the first transmission cable <b>6</b>. The imaging recording unit <b>57</b> is configured by use of a nonvolatile memory or a volatile memory.</p><p id="p-0097" num="0096">On the basis of setting data received from the control device <b>9</b> via the first transmission cable <b>6</b>, the imaging control unit <b>58</b> controls operation of each of the drive unit <b>52</b>, the imaging element <b>53</b>, the A/D converter <b>55</b>, and the P/S converter <b>56</b>. The imaging control unit <b>58</b> is implemented by use of a timing generator (TG), a processor that is a processing device having hardware, such as a CPU, and a memory that is a transitory storage area used by the processor.</p><p id="p-0098" num="0097">Configuration of Control Device</p><p id="p-0099" num="0098">A configuration of the control device <b>9</b> will be described next.</p><p id="p-0100" num="0099">The control device <b>9</b> includes an S/P converter <b>91</b>, an image processing unit <b>92</b>, an input unit <b>93</b>, a recording unit <b>94</b>, and a control unit <b>95</b>.</p><p id="p-0101" num="0100">Under control by the control unit <b>95</b>, the S/P converter <b>91</b> performs serial/parallel conversion of image data received from the endoscope camera head <b>5</b> via the first transmission cable <b>6</b>, and outputs the converted image data to the image processing unit <b>92</b>. In a case where the endoscope camera head <b>5</b> outputs the image data as an optical signal, an <b>0</b>/E converter that converts the optical signal into an electric signal may be provided instead of the S/P converter <b>91</b>. In a case where the endoscope camera head <b>5</b> transmits the image data by wireless communication, a communication module capable of receiving a wireless signal may be provided instead of the S/P converter <b>91</b>.</p><p id="p-0102" num="0101">Under control by the control unit <b>95</b>, the image processing unit <b>92</b> performs predetermined image processing of image data in the form of parallel data input from the S/P converter <b>91</b> and outputs the processed image data to the display device <b>7</b>. This predetermined image processing may include any of demosaicing processing, white balance processing, gain adjustment processing, y correction processing, and format conversion processing. The image processing unit <b>92</b> is implemented by use of a processor that is a processing device having hardware, such as a GPU or an FPGA, and a memory that is a transitory storage area used by the processor.</p><p id="p-0103" num="0102">The input unit <b>93</b> receives input of various operations related to the endoscope system <b>1</b> and outputs the received operations to the control unit <b>95</b>. The input unit <b>93</b> is configured by use of a mouse, a foot switch, a keyboard, a button, a switch, and/or a touch panel, for example.</p><p id="p-0104" num="0103">The recording unit <b>94</b> is implemented by use of a volatile memory, a nonvolatile memory, a solid state drive (SSD), a hard disk drive (HDD), and/or a recording medium, such as a memory card. The recording unit <b>94</b> records therein data including various parameters needed for operation of the endoscope system <b>1</b>. The recording unit <b>94</b> includes a program recording unit <b>941</b> that records therein various programs for operation of the endoscope system <b>1</b>.</p><p id="p-0105" num="0104">The control unit <b>95</b> is implemented by use of a processor that is a processing device having hardware, such as an FPGA or a CPU, and a memory that is a transitory storage area used by the processor. The control unit <b>95</b> integrally controls the units included in the endoscope system <b>1</b>.</p><p id="p-0106" num="0105">Outline of Each Observation Mode</p><p id="p-0107" num="0106">Outlines of observation modes implemented by the endoscope system <b>1</b> will be described next. The observation modes will be described hereinafter in the order, a narrow band light observation mode, a heat treatment observation mode, an autofluorescence observation mode, and a normal light observation mode.</p><p id="p-0108" num="0107">Outline of Narrowband Light Observation Mode</p><p id="p-0109" num="0108">The narrow band light observation mode will be described first. <figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram schematically illustrating principles of observation in the narrow band light observation mode.</p><p id="p-0110" num="0109">The narrow band light observation mode (narrow band imaging: NBI) corresponds to an observation method of enhancing capillaries of a mucosal surface layer and a mucosal surface structure, of body tissue, by utilization of a property of hemoglobin in blood, the property being of strongly absorbing light near the wavelength of 415 nm. That is, in the narrow band light observation mode, the two types of narrow band light, the first narrow band light (having the wavelength band of 530 nm to 550 nm) and the second narrow band light (having a wavelength band of 390 nm to 445 nm), that are easily absorbed by hemoglobin in blood are emitted to a subject, such as body tissue. Blood vessels in and bloodstream information on a mucosal deep region that are difficult to be visually confirmed with normal light (white light) are thereby able to be highlight-displayed in the narrow band light observation mode.</p><p id="p-0111" num="0110">Specifically, as represented by a graph G<b>1</b> in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, firstly, under control by the control device <b>9</b>, the light source device <b>3</b> causes first narrow band light W<b>1</b> and second narrow band light W<b>2</b> to be emitted to body tissue O<b>1</b> (mucosa) of a subject by causing the second light source portion <b>32</b> and the third light source portion <b>33</b> to emit light. In this case, part of reflected light and returned light (hereinafter, simply referred to as &#x201c;reflected light WR<b>1</b>, reflected light WR<b>2</b>, reflected light WG<b>1</b>, reflected light WG<b>2</b>, reflected light WB<b>1</b>, and reflected light WB<b>2</b>&#x201d;) including at least plural components reflected by the body tissue O<b>1</b> of the subject is shielded by the cut filter <b>54</b> and the rest enters the imaging element <b>53</b>. In the following description, reflected light from the first narrow band light W<b>1</b> will be referred to as the reflected light WR<b>1</b>, the reflected light WG<b>1</b>, and the reflected light WB<b>1</b>, and reflected light from the second narrow band light W<b>2</b> will be referred to as the reflected light WR<b>2</b>, the reflected light WG<b>2</b>, and the reflected light WB<b>2</b>. In <figref idref="DRAWINGS">FIG. <b>10</b></figref>, thickness of each line represents intensity of a component (quantity of light or signal value).</p><p id="p-0112" num="0111">More specifically, as represented by the polygonal line L<sub>F </sub>of a graph G<b>2</b> in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the cut filter <b>54</b> shields the reflected light WG<b>2</b> to be incident on the G pixels, the reflected light WG<b>2</b> having a short wavelength band including the wavelength band of the second narrow band light W<b>2</b>.</p><p id="p-0113" num="0112">Furthermore, the cut filter <b>54</b> transmits therethrough the reflected light WG<b>1</b> of a wavelength band including the first narrow band light W<b>1</b> and longer than the wavelength band of the second narrow band light W<b>2</b>. The reflected light (the reflected light WR<b>1</b>, the reflected light WR<b>2</b>, the reflected light WB<b>1</b>, and the reflected light WB<b>2</b>) resulting from reflection of the first narrow band light W<b>1</b> and the second narrow band light W<b>2</b> by the subject enters each of the R pixels and B pixels.</p><p id="p-0114" num="0113">Next, as represented by a graph G<b>3</b> of transmission characteristics in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the R pixels, G pixels, and B pixels have transmission characteristics (sensitivity characteristics) different from one another. Specifically, the B pixels do not have sensitivity to the reflected light WB<b>1</b> of the first narrow band light W<b>1</b> and the output value corresponding to the quantity of the reflected light WB<b>1</b> received thus becomes minute. On the contrary, the B pixels have sensitivity to the reflected light WB<b>2</b> of the second narrow band light WW<b>2</b> and the output value corresponding to the quantity of the reflected light WB<b>1</b> received thus becomes large.</p><p id="p-0115" num="0114">Thereafter, the image processing unit <b>92</b> obtains image data (RAW data) from the imaging element <b>53</b> of the endoscope camera head <b>5</b>, and generates a pseudocolor image (narrow band image) by performing image processing of signal values from the G pixels and B pixels, the signals values being included in the image data obtained. In this case, the signal values from the G pixels include mucosal deep layer information on the subject. Furthermore, the signal values from the B pixels include mucosal surface layer information on the subject. The image processing unit <b>92</b> thus generates the pseudocolor image by performing the image processing of the signal values from the G pixels and B pixels, the signal values being included in the image data, the image processing including, for example, gain control processing, pixel interpolation processing, and mucosa enhancement processing, and outputs the pseudocolor image to the display device <b>7</b>. This pseudocolor image is an image generated by use of only the signal values from the G pixels and the signal values from the B pixels. The image processing unit <b>92</b> obtains signal values from the R pixels but deletes these signal values without using them in generating the pseudocolor image.</p><p id="p-0116" num="0115">Accordingly, in the narrow band light observation mode, blood vessels in a mucosal deep region and bloodstream information on the mucosal deep region that are difficult to be visually confirmed with white light (normal light) are able to be highlight-displayed.</p><p id="p-0117" num="0116">Outline of Heat Treatment Observation Mode</p><p id="p-0118" num="0117">The heat treatment observation mode will be described next. <figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram schematically illustrating principles of observation in the heat treatment observation mode.</p><p id="p-0119" num="0118">In recent years, minimally invasive treatments using, for example, endoscopes and laparoscopes have been widely adopted in the medical field. For example, widely adopted ones of the minimally invasive treatments using endoscopes and laparoscopes include endoscopic submucosal dissection (ESD), laparoscopy and endoscopy cooperative surgery (LECS), and non-exposed endoscopic wall-inversion surgery (NEWS).</p><p id="p-0120" num="0119">In these minimally invasive treatments, for example, an operating surgeon, such as a medical doctor, performs pretreatment that is heat treatment or marking treatment by heat treatment, of body tissue, by use of a treatment tool, such as an energy device that may be a high frequency knife or an electrosurgical knife, for marking of a region to be operated. Furthermore, for the actual treatment, the operating surgeon also performs treatment, such as excision and coagulation of the body tissue of the subject by using the energy device, for example.</p><p id="p-0121" num="0120">In reality, the extent of the heat treatment applied to the body tissue by the energy device is checked by the operating surgeon on the basis of, for example, the operating surgeon's visual inspection, sense of touch, and/or guess. Therefore, in a conventional treatment using an energy device, for example, it is difficult for an operating surgeon to check in real time the degree of heat treatment to be applied during the operation in surgery and this check requires great skill and experience. Accordingly, there is a demand from operating surgeons for a technology that enables visualization of a cauterization state of a heat-treated region in heat treatment of body tissue conducted by use of an energy device.</p><p id="p-0122" num="0121">A glycation reaction (the Maillard reaction) occurs when an amino acid and a reducing sugar are heated. End products produced as a result of this Maillard reaction are generally called advanced glycation end products (AGEs). AGEs are known to include a substance having fluorescence.</p><p id="p-0123" num="0122">That is, when body tissue is heat-treated by an energy device, AGEs are produced by the Maillard reaction caused by heating of amino acids and reducing sugars in the body tissue. Fluorescence observation of the AGEs produced by this heating enables visualization of states of the heat treatment. In addition, AGEs are known to emit fluorescence that is more intense than that by autofluorescent substances present in body tissue by nature.</p><p id="p-0124" num="0123">That is, the heat treatment observation mode corresponds to an observation method of visualizing a heat-treated region subjected to heat treatment by utilizing fluorescence of AGEs produced in body tissue by heat treatment by means of, for example, an energy device. Accordingly, in the heat treatment observation mode, blue light near the wavelength of 415 nm for exciting the AGEs is emitted from the light source device <b>3</b> to the body tissue. In the heat treatment observation mode, a heat treatment image (a fluorescence image) having, captured therein, fluorescence (for example, green light having a wavelength of 490 nm to 625 nm) generated by the AGEs is thereby able to be observed.</p><p id="p-0125" num="0124">Specifically, as represented by a graph G<b>11</b> in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, firstly, under control by the control device <b>9</b>, the light source device <b>3</b> emits the second narrow band light W<b>2</b> that is excitation light (with a central wavelength of 415 nm) to body tissue O<b>2</b> (a heat-treated region) of a subject, the body tissue O<b>2</b> having been heat-treated by means of, for example, an energy device, by causing the third light source portion <b>33</b> to emit light. In this case, as represented by a graph G<b>12</b> in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, reflected light including at least components of the second narrow band light W<b>2</b> reflected by the body tissue O<b>2</b> (heat-treated region) and returned light (hereinafter, simply referred to as &#x201c;the reflected light WR<b>10</b>, the reflected light WG<b>10</b>, and the reflected light WB<b>10</b>&#x201d;) is shielded by the cut filter <b>54</b> and some of longer wavelength components enter the imaging element <b>53</b>. In <figref idref="DRAWINGS">FIG. <b>11</b></figref>, thickness of each line represents intensity of a component (quantity of light or signal value).</p><p id="p-0126" num="0125">More specifically, as represented by a graph G<b>12</b> in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the cut filter <b>54</b> shields the reflected light WG<b>10</b> to be incident on the G pixels, the reflected light WG<b>10</b> having a short wavelength band including the wavelength band of the second narrow band light W<b>2</b>. Furthermore, as represented by the graph G<b>12</b> in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the cut filter <b>54</b> transmits therethrough fluorescence (WF<b>1</b>) generated by autofluorescence of AGEs in the body tissue O<b>2</b> (heat-treated region). Therefore, reflected light (the reflected light WR<b>10</b> and the reflected light WB<b>10</b>) and fluorescence (WF<b>1</b>) enter the R pixels and B pixels. Furthermore, fluorescence (WF<b>1</b>) enters the G pixels. As described above, because the cut filter <b>54</b> is arranged on the light receiving surface side (incident surface side) of the G pixels, the fluorescence component is prevented from being buried in the reflected light WG<b>10</b> of the second narrow band light W<b>2</b> that is excitation light.</p><p id="p-0127" num="0126">Furthermore, as represented by a polygonal line L<sub>NG </sub>for fluorescence in the graph G<b>12</b> in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the G pixels have sensitivity to fluorescence, but because the fluorescence is a minute reaction, the output value becomes small.</p><p id="p-0128" num="0127">Thereafter, the image processing unit <b>92</b> obtains image data (RAW data) from the imaging element <b>53</b> of the endoscope camera head <b>5</b>, and generates a pseudocolor image (a heat treatment fluorescence image) by performing image processing of signal values from the G pixels and B pixels, the signal values being included in the image data obtained. In this case, the signal values from the G pixels include fluorescence information generated from the heat-treated region. The signals values from the B pixels include background information on body tissue around the heat-treated region. The image processing unit <b>92</b> thus generates the pseudocolor image by performing the image processing of the signal values from the G pixels and B pixels, the signal values being included in the image data, the image processing including, for example, gain control processing, pixel interpolation processing, and mucosa enhancement processing, and outputs the pseudocolor image (heat treatment image) to the display device <b>7</b>. In this case, the image processing unit <b>92</b> performs the gain control processing to make gains for the signal values from the G pixels larger than gains for signal values from the G pixels in normal light observation and make gains for the signal values from the B pixels smaller than gains for signal values from the B pixels in the normal light observation. Furthermore, the image processing unit <b>92</b> performs the gain control processing to make the signal values from the G pixels and the signal values from the B pixels the same (1:1).</p><p id="p-0129" num="0128">Accordingly, the heat treatment observation mode facilitates observation of the body tissue O<b>2</b> (heat-treated region) that is heat-treated by the energy device, for example.</p><p id="p-0130" num="0129">Outline of Autofluorescence Observation Mode</p><p id="p-0131" num="0130">The autofluorescence observation mode will be described next. <figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram schematically illustrating principles of observation in the autofluorescence observation mode.</p><p id="p-0132" num="0131">The autofluorescence observation mode (autofluorescence imaging: AFI) corresponds to an observation method of facilitating discrimination of normal tissue and lesional tissue, such as a tumor, by exciting a fluorescent substance, such as collagen, present in a submucosal layer of body tissue. In the autofluorescence observation mode, excitation light to excite an autofluorescent substance, the excitation light being blue light having a wavelength band near 415 nm, and reference light reflected by a mucosal surface layer of body tissue, the reference light being green light having a wavelength band near 540 nm, are sequentially emitted (alternately emitted). In the autofluorescence observation mode, a fluorescent component emitted by a fluorescent substance present in body tissue and a reflected light component of the reference light returned from normal body tissue are imaged by the imaging element <b>53</b>, and are displayed as a pseudocolor image that enables discrimination between normal tissue and lesional tissue.</p><p id="p-0133" num="0132">Specifically, as represented by a graph G<b>21</b> in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, firstly, under control by the control device <b>9</b>, the light source device <b>3</b> causes the first narrow band light W<b>1</b> (with the central wavelength of 540 nm) serving as reference light and the second narrow band light W<b>2</b> (with the central wavelength of 415 nm) serving as excitation light, to be sequentially emitted (alternately emitted) to body tissue O<b>3</b> of a subject by causing the second light source portion <b>32</b> and the third light source portion <b>33</b> to emit light alternately. In this case, part of light including at least reflected light and returned light that include plural components reflected by the subject (hereinafter, simply referred to as the &#x201c;reflected light WR<b>20</b>, reflected light WG<b>20</b>, and reflected light WB<b>20</b>&#x201d;) is shielded by the cut filter <b>54</b> and the rest enters the imaging element <b>53</b>.</p><p id="p-0134" num="0133">More specifically, as represented by a graph G<b>22</b> in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the cut filter <b>54</b> shields the reflected light WG<b>20</b> to be incident on the G pixels and having a short wavelength band including the wavelength band of the second narrow band light W<b>2</b>. Specifically, in the autofluorescence observation mode, in a case where the second narrow band light W<b>2</b> is emitted, fluorescence WF<b>10</b> (with a central wavelength of 540 nm) enters the G pixels. Furthermore, in the autofluorescence observation mode, in the case where the second narrow band light W<b>2</b> is emitted, fluorescence WF<b>10</b> generated from a fluorescent substance in the body tissue O<b>3</b> and the reflected light WB<b>20</b> of the second narrow band light W<b>2</b> enter the B pixels, the reflected light WB<b>20</b> having been reflected by the body tissue O<b>3</b>, and fluorescence WF<b>10</b> generated from the fluorescent substance in the body tissue O<b>3</b> and the reflected light WR<b>20</b> of the second narrow band light W<b>2</b> enter the R pixels, the reflected light WR<b>20</b> having been reflected by the body tissue O<b>3</b>.</p><p id="p-0135" num="0134">Furthermore, in the autofluorescence observation mode, in a case where the first narrow band light W<b>1</b> is emitted, reflected light WG<b>30</b> of the first narrow band light W<b>1</b> (reference light) enters the G pixels, the reflected light WG<b>30</b> having been reflected by the body tissue O<b>3</b>. In addition, in the autofluorescence observation mode, in the case where the first narrow band light W<b>1</b> is emitted, reflected light WB<b>30</b> of the first narrow band light W<b>1</b> (reference light) enters the B pixels, the reflected light WB<b>30</b> having been reflected by the body tissue O<b>3</b>, and reflected light WR<b>30</b> of the first narrow band light W<b>1</b> (reference light) enters the R pixels, the reflected light WR<b>30</b> having been reflected by the body tissue O<b>3</b>. In <figref idref="DRAWINGS">FIG. <b>12</b></figref>, thickness of each line represents intensity of a component (quantity of light or signal value).</p><p id="p-0136" num="0135">Thereafter, the image processing unit <b>92</b> obtains image data (RAW data) from the imaging element <b>53</b> of the endoscope camera head <b>5</b>, and generates a pseudocolor image (autofluorescence image) by performing image processing of signal values from the G pixels, the signal values being included in the image data obtained. In this case, the signal values from the G pixels include: fluorescence information (first necessary component) generated from the fluorescent substance in the body tissue O<b>3</b> where the second narrow band light W<b>2</b> enters in the case where the second narrow band light W<b>2</b> is emitted; and background information (second necessary component) on the reflected reference light including reflected light and returned light that result from reflection of the first narrow band light W<b>1</b> by the body tissue O<b>3</b> in the case where the first narrow band light W<b>1</b> (reference light) is emitted. The quantity of the reflected reference light from a region having a blood vessel or inflammation is smaller than that from a normal tissue region or a region having a hypertrophic superficial mucosa, these regions being of the body tissue O<b>3</b> irradiated with the first narrow band light W<b>1</b> (reference light). Therefore, the image processing unit <b>92</b> performs enhancement processing so that a region where the fluorescence information (first necessary component) generated from the fluorescent substance in the body tissue O<b>3</b> is weak and the background information (second necessary component) on the reflected reference light from the body tissue O<b>3</b> is intense is more enhanced. Specifically, the image processing unit <b>92</b> generates a pseudocolor image so that a region presumed to be a tumor is displayed in magenta. For example, the image processing unit <b>92</b> assigns the color tone of regional fluorescence information (first necessary component) generated from a fluorescent substance in body tissue to blue and red on a pseudocolor image and assigns the color tone of background information (second necessary component) on reflected reference light from the body tissue to green on the pseudocolor image. A region presumed to be a tumor is thereby represented in magenta and a normal mucosa region or a region having a blood vessel or inflammation is represented in a green color. The image processing unit <b>92</b> deletes signal values of the B pixels and R pixels included in the image data without using these signal values.</p><p id="p-0137" num="0136">As illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref> described above, in the autofluorescence observation mode, the image processing unit <b>92</b> performs gain control processing of making gains for the signal values from the G pixels larger than gains for signal values from the G pixels in the normal light observation.</p><p id="p-0138" num="0137">As described above, in the autofluorescence observation mode, observation of autofluorescence from body tissue enables observation by highlight display of a lesional region (abnormal region), such as a tumor, and a normal region in different color tones.</p><p id="p-0139" num="0138">Outline of Normal Light Observation Mode</p><p id="p-0140" num="0139">The normal light observation mode will be described next. <figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram schematically illustrating principles of observation in the normal light observation mode.</p><p id="p-0141" num="0140">As illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, firstly, under control by the control device <b>9</b>, the light source device <b>3</b> emits white light W<b>3</b> to body tissue O<b>4</b> of a subject by causing the first light source portion <b>31</b> to emit light. In this case, part of reflected light and returned light that are reflected by the body tissue O<b>4</b> (hereinafter, simply referred to as the &#x201c;reflected light WR<b>40</b>, reflected light WG<b>40</b>, and reflected light WB<b>40</b>&#x201d;) is shielded by the cut filter <b>54</b> and the rest enters the imaging element <b>53</b>. Specifically, as illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the cut filter <b>54</b> shields the reflected light WG<b>40</b> to be incident on the G pixels and having a short wavelength band including the wavelength band of the second narrow band light W<b>2</b>. Therefore, as illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, a blue wavelength band light component incident on the G-pixels is less than that in a state without the cut filter <b>54</b> arranged in the system.</p><p id="p-0142" num="0141">Next, the image processing unit <b>92</b> obtains image data (RAW data) from the imaging element <b>53</b> of the endoscope camera head <b>5</b>, and generates a white light image by performing image processing of signal values from the R pixels, G pixels, and B pixels, the signal values being included in the image data obtained. In this case, because the blue component included in the image data is smaller than that in conventional white light observation, the image processing unit <b>92</b> performs white balance adjustment processing of adjusting white balance to make the ratio of the red component, green component, and blue component constant.</p><p id="p-0143" num="0142">As described above, in the normal light observation mode, even in a case where the cut filter <b>54</b> is arranged on the light receiving surface side of the G pixels, a natural white image is able to be observed.</p><p id="p-0144" num="0143">Processing by Endoscope System</p><p id="p-0145" num="0144">Processing executed by the endoscope system <b>1</b> will be described next. <figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart illustrating an outline of the processing executed by the endoscope system <b>1</b>. The image processing unit <b>92</b> performs various kinds of image processing for developing image data, but for simplification, only characteristic image processing in each observation mode will be described hereinafter.</p><p id="p-0146" num="0145">As illustrated in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, firstly, the control unit <b>95</b> determines whether or not the endoscope system <b>1</b> has been set in the narrow band light observation mode (Step S<b>1</b>). In a case where the control unit <b>95</b> determines that the endoscope system <b>1</b> has been set in the narrow band light observation mode (Step S<b>1</b>: Yes), the endoscope system <b>1</b> proceeds to Step S<b>2</b> described later. On the contrary, in a case where the control unit <b>95</b> determines that the endoscope system <b>1</b> has not been set in the narrow band light observation mode (Step S<b>1</b>: No), the endoscope system <b>1</b> proceeds to Step S<b>4</b> described later.</p><p id="p-0147" num="0146">At Step S<b>2</b>, the endoscope system <b>1</b> executes narrow band light observation mode processing. After Step S<b>2</b>, the endoscope system <b>1</b> proceeds to Step S<b>3</b> described later.</p><p id="p-0148" num="0147">Narrowband Light Observation Mode Processing</p><p id="p-0149" num="0148"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart illustrating an outline of the narrow band light observation mode processing at Step S<b>2</b> in <figref idref="DRAWINGS">FIG. <b>14</b></figref> described above.</p><p id="p-0150" num="0149">As illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, the control unit <b>95</b> controls the light source control unit <b>34</b> to cause each of the second light source portion <b>32</b> and the third light source portion <b>33</b> to emit light, and thereby causes the first narrow band light and the second narrow band light to be emitted to a subject (Step S<b>11</b>).</p><p id="p-0151" num="0150">Subsequently, by controlling the imaging control unit <b>58</b>, the control unit <b>95</b> causes the imaging element <b>53</b> to capture a subject image condensed by the optical system <b>22</b> and optical system <b>51</b> and transmitted through the cut filter <b>54</b> (Step S<b>12</b>).</p><p id="p-0152" num="0151">Thereafter, the control unit <b>95</b> causes the image processing unit <b>92</b> to execute gain control processing of image data input via the A/D converter <b>55</b>, the P/S converter <b>56</b>, and the S/P converter <b>91</b> (Step S<b>13</b>).</p><p id="p-0153" num="0152">Subsequently, the control unit <b>95</b> causes the image processing unit <b>92</b> to execute demosaicing processing of the image data that have been subjected to the gain control processing (Step S<b>14</b>) and causes the image processing unit <b>92</b> to execute image quality improvement processing of the image data that have been subjected to the demosaicing processing and to generate a pseudocolor image (Step S<b>15</b>).</p><p id="p-0154" num="0153">Thereafter, the control unit <b>95</b> causes the image processing unit <b>92</b> to output the pseudocolor image to the display device <b>7</b> (Step S<b>16</b>). An operating surgeon, such as a medical doctor, is thereby able to conduct observation of the subject while looking at the narrow band light image.</p><p id="p-0155" num="0154">Subsequently, the control unit <b>95</b> determines whether or not a switching signal to change the observation mode of the endoscope system <b>1</b> has been input from the input unit <b>93</b> (Step S<b>17</b>). In a case where the control unit <b>95</b> determines that the switching signal to change the observation mode of the endoscope system <b>1</b> has been input from the input unit <b>93</b> (Step S<b>17</b>: Yes), the endoscope system <b>1</b> returns to the main routine in <figref idref="DRAWINGS">FIG. <b>14</b></figref>. On the contrary, in a case where the control unit <b>95</b> determines that the switching signal to change the observation mode of the endoscope system <b>1</b> has not been input from the input unit <b>93</b> (Step S<b>17</b>: No), the endoscope system <b>1</b> returns to Step S<b>11</b> described above.</p><p id="p-0156" num="0155">By reference back to <figref idref="DRAWINGS">FIG. <b>14</b></figref>, description of the processing from Step S<b>3</b> will be continued.</p><p id="p-0157" num="0156">At Step S<b>3</b>, the control unit <b>95</b> determines whether or not an instruction signal to instruct the system to end the observation of the subject has been input from the input unit <b>93</b>. In a case where the control unit <b>95</b> determines that the instruction signal to instruct the system to end the observation of the subject has been input from the input unit <b>93</b> (Step S<b>3</b>: Yes), the endoscope system <b>1</b> ends the processing. On the contrary, in a case where the control unit <b>95</b> determines that the instruction signal to instruct the system to end the observation of the subject has not been input from the input unit <b>93</b> (Step S<b>3</b>: No), the endoscope system <b>1</b> returns to Step S<b>1</b> described above.</p><p id="p-0158" num="0157">At Step S<b>4</b>, the control unit <b>95</b> determines whether or not the endoscope system <b>1</b> has been set in the heat treatment observation mode. In a case where the control unit <b>95</b> determines that the endoscope system <b>1</b> has been set in the heat treatment observation mode (Step S<b>4</b>: Yes), the endoscope system <b>1</b> proceeds to Step S<b>5</b> described later. On the contrary, in a case where the control unit <b>95</b> determines that the endoscope system <b>1</b> has not been set in the heat treatment observation mode (Step S<b>4</b>: No), the endoscope system <b>1</b> proceeds to Step S<b>6</b> described later.</p><p id="p-0159" num="0158">At Step S<b>5</b>, the endoscope system <b>1</b> executes heat treatment observation mode processing. After Step S<b>5</b>, the endoscope system <b>1</b> proceeds to Step S<b>3</b>.</p><p id="p-0160" num="0159">Heat Treatment Observation Mode Processing</p><p id="p-0161" num="0160"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a flowchart illustrating an outline of the heat treatment observation mode processing at Step S<b>5</b> in <figref idref="DRAWINGS">FIG. <b>14</b></figref> described above.</p><p id="p-0162" num="0161">As illustrated in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, by controlling the light source control unit <b>34</b>, the control unit <b>95</b> causes the third light source portion <b>33</b> to emit light to thereby cause the second narrow band light to be emitted to a subject (Step S<b>51</b>).</p><p id="p-0163" num="0162">Subsequently, by controlling the imaging control unit <b>58</b>, the control unit <b>95</b> causes the imaging element <b>53</b> to capture a subject image condensed by the optical system <b>22</b> and optical system <b>51</b> and transmitted through the cut filter <b>54</b> (Step S<b>52</b>).</p><p id="p-0164" num="0163">Thereafter, the control unit <b>95</b> causes the image processing unit <b>92</b> to execute gain control processing of image data input via the A/D converter <b>55</b>, the P/S converter <b>56</b>, and the S/P converter <b>91</b> (Step S<b>53</b>). In this case, the image processing unit <b>92</b> performs the gain control processing of making gains for signal values from the G pixels larger than gains for signal values from the G pixels in normal light observation and make gains corresponding to signal values from the B pixels smaller than gains for signal values from the B pixels in the normal light observation, the signal values being included in the image data. Furthermore, the image processing unit <b>92</b> performs the gain control processing to make the signal values from the G pixels and the signal values from the B pixels the same (1:1).</p><p id="p-0165" num="0164">Subsequently, the control unit <b>95</b> causes the image processing unit <b>92</b> to execute demosaicing processing of the image data that have been subjected to the gain control processing (Step S<b>54</b>) and causes the image processing unit <b>92</b> to execute image quality improvement processing of the image data that have been subjected to the demosaicing processing and to generate a pseudocolor image (heat treatment image) (Step S<b>55</b>).</p><p id="p-0166" num="0165">Thereafter, the control unit <b>95</b> causes the image processing unit <b>92</b> to output the pseudocolor image to the display device <b>7</b> (Step S<b>56</b>). An operating surgeon, such as a medical doctor, is thereby able to conduct observation of the subject while looking at the heat treatment image.</p><p id="p-0167" num="0166">Subsequently, the control unit <b>95</b> determines whether or not a switching signal to change the observation mode of the endoscope system <b>1</b> has been input from the input unit <b>93</b> (Step S<b>57</b>). In a case where the control unit <b>95</b> determines that the switching signal to change the observation mode of the endoscope system <b>1</b> has been input from the input unit <b>93</b> (Step S<b>57</b>: Yes), the endoscope system <b>1</b> returns to the main routine in <figref idref="DRAWINGS">FIG. <b>14</b></figref>. On the contrary, in a case where the control unit <b>95</b> determines that the switching signal to change the observation mode of the endoscope system <b>1</b> has not been input from the input unit <b>93</b> (Step S<b>57</b>: No), the endoscope system <b>1</b> returns to Step S<b>51</b> described above.</p><p id="p-0168" num="0167">By reference back to <figref idref="DRAWINGS">FIG. <b>14</b></figref>, description of the processing from Step S<b>6</b> will be continued.</p><p id="p-0169" num="0168">At Step S<b>6</b>, the control unit <b>95</b> determines whether or not the endoscope system <b>1</b> has been set in the autofluorescence observation mode. In a case where the control unit <b>95</b> determines that the endoscope system <b>1</b> has been sent in the autofluorescence observation mode (Step S<b>6</b>: Yes), the endoscope system <b>1</b> proceeds to Step S<b>7</b> described later. On the contrary, in a case where the control unit <b>95</b> determines that the endoscope system <b>1</b> has not been set in the autofluorescence observation mode (Step S<b>6</b>: No), the endoscope system <b>1</b> proceeds to Step S<b>8</b> described later.</p><p id="p-0170" num="0169">At Step S<b>7</b>, the endoscope system <b>1</b> executes autofluorescence observation mode processing. After Step S<b>7</b>, the endoscope system <b>1</b> proceeds to Step S<b>3</b>.</p><p id="p-0171" num="0170">Autofluorescence Observation Mode Processing</p><p id="p-0172" num="0171"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flowchart illustrating an outline of the autofluorescence observation mode processing at Step S<b>7</b> in <figref idref="DRAWINGS">FIG. <b>14</b></figref> described above.</p><p id="p-0173" num="0172">As illustrated in <figref idref="DRAWINGS">FIG. <b>17</b></figref>, the control unit <b>95</b> controls the light source control unit <b>34</b> to cause each of the second light source portion <b>32</b> and the third light source portion <b>33</b> to emit light, and thereby causes the first narrow band light and the second narrow band light to be sequentially emitted (alternately emitted) to a subject (Step S<b>71</b>).</p><p id="p-0174" num="0173">Subsequently, by controlling the imaging control unit <b>58</b>, the control unit <b>95</b> causes the imaging element <b>53</b> to capture a subject image condensed by the optical system <b>22</b> and optical system <b>51</b> and transmitted through the cut filter <b>54</b> (Step S<b>72</b>).</p><p id="p-0175" num="0174">Thereafter, the control unit <b>95</b> causes the image processing unit <b>92</b> to execute demosaicing processing of image data input via the A/D converter <b>55</b>, the P/S converter <b>56</b>, and the S/P converter <b>91</b> (Step S<b>73</b>).</p><p id="p-0176" num="0175">Subsequently, the control unit <b>95</b> causes the image processing unit <b>92</b> to execute color tone conversion processing of the image data that have been subjected to the demosaicing processing and to generate a pseudocolor image (Step S<b>74</b>). In this case, signal values from the G pixels include: fluorescence information (first necessary component) generated from a fluorescent substance in body tissue where the second narrow band light W<b>2</b> enters in the case where the second narrow band light W<b>2</b> is emitted; and background information (second necessary component) on reflected reference light including reflected light and returned light that result from reflection of the first narrow band light W<b>1</b> by the body tissue in the case where the first narrow band light W<b>1</b> (reference light) is emitted. The quantity of reflected reference light from a region having a blood vessel or inflammation is smaller than that from a normal tissue region or a region having a hypertrophic superficial mucosa, the regions being of the body tissue irradiated with the first narrow band light W<b>1</b> (reference light). Therefore, the image processing unit <b>92</b> performs enhancement processing so that a region where the fluorescence information (first necessary component) generated by the fluorescent substance in the body tissue is weak and the background information (second necessary component) on the reflected reference light from the body tissue is intense is more enhanced. Specifically, the image processing unit <b>92</b> generates a pseudocolor image so that a region presumed to be a tumor is displayed in magenta. For example, the image processing unit <b>92</b> assigns the color tone of regional fluorescence information (first necessary component) generated from a fluorescent substance in body tissue to blue and red on a pseudocolor image and assigns the color tone of background information (second necessary component) on reflected reference light from the body tissue to green on the pseudocolor image. A region presumed to be a tumor is represented in magenta, and a normal mucosa region or a region having a blood vessel or inflammation is represented in a green color. The image processing unit <b>92</b> deletes signal values from the B pixels and R pixels, the signal values being included in the image data, without using these signal values.</p><p id="p-0177" num="0176">Thereafter, the control unit <b>95</b> causes the image processing unit <b>92</b> to output the pseudocolor image to the display device <b>7</b> (Step S<b>75</b>). An operating surgeon, such as a medical doctor, is thereby able to conduct observation of an abnormal site including, for example, a tumor, in the subject while looking at the autofluorescence image.</p><p id="p-0178" num="0177">Subsequently, the control unit <b>95</b> determines whether or not a switching signal to change the observation mode of the endoscope system <b>1</b> has been input from the input unit <b>93</b> (Step S<b>76</b>). In a case where the control unit <b>95</b> determines that the switching signal to change the observation mode of the endoscope system <b>1</b> has been input from the input unit <b>93</b> (Step S<b>76</b>: Yes), the endoscope system <b>1</b> returns to the main routine in <figref idref="DRAWINGS">FIG. <b>14</b></figref>. On the contrary, in a case where the control unit <b>95</b> determines that the switching signal to change the observation mode of the endoscope system <b>1</b> has not been input by the input unit <b>93</b> (Step S<b>76</b>: No), the endoscope system <b>1</b> returns to Step S<b>71</b> described above.</p><p id="p-0179" num="0178">By reference back to <figref idref="DRAWINGS">FIG. <b>14</b></figref>, description of the processing from Step S<b>8</b> will be continued.</p><p id="p-0180" num="0179">At Step S<b>8</b>, the control unit <b>95</b> determines whether or not the endoscope system <b>1</b> has been set in the normal light observation mode. In a case where the control unit <b>95</b> determines that the endoscope system <b>1</b> has been set in the normal light observation mode (Step S<b>8</b>: Yes), the endoscope system <b>1</b> proceeds to Step S<b>9</b> described later. On the contrary, in a case where the control unit <b>95</b> determines that the endoscope system <b>1</b> has not been set in the normal light observation mode (Step S<b>8</b>: No), the endoscope system <b>1</b> proceeds to Step S<b>3</b>.</p><p id="p-0181" num="0180">Normal Light Observation Mode Processing</p><p id="p-0182" num="0181"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a flowchart illustrating an outline of normal light observation mode processing at Step S<b>9</b> in <figref idref="DRAWINGS">FIG. <b>14</b></figref> described above.</p><p id="p-0183" num="0182">As illustrated in <figref idref="DRAWINGS">FIG. <b>18</b></figref>, the control unit <b>95</b> causes the first light source portion <b>31</b> to emit light by controlling the light source control unit <b>34</b> and thereby causes white light to be emitted to a subject (Step S<b>91</b>).</p><p id="p-0184" num="0183">Subsequently, by controlling the imaging control unit <b>58</b>, the control unit <b>95</b> causes the imaging element <b>53</b> to capture a subject image condensed by the optical system <b>22</b> and optical system <b>51</b> and transmitted through the cut filter <b>54</b> (Step S<b>92</b>).</p><p id="p-0185" num="0184">Thereafter, the control unit <b>95</b> causes the image processing unit <b>92</b> to execute demosaicing processing of image data input via the A/D converter <b>55</b>, the P/S converter <b>56</b>, and the S/P converter <b>91</b> (Step S<b>93</b>).</p><p id="p-0186" num="0185">Subsequently, the control unit <b>95</b> causes the image processing unit <b>92</b> to execute white balance adjustment processing of the image data that have been subjected to the demosaicing processing and to generate a white image (Step S<b>94</b>). Specifically, because the blue component included in the image data is less than that in conventional white light observation, the image processing unit <b>92</b> performs white balance adjustment processing of adjusting white balance to make the ratio of the red component, green component, and blue component constant and generates the white image.</p><p id="p-0187" num="0186">Thereafter, the control unit <b>95</b> causes the image processing unit <b>92</b> to output the white image to the display device <b>7</b> (Step S<b>95</b>). An operating surgeon, such as a medical doctor, is thereby able to conduct observation of the subject while looking at the white image.</p><p id="p-0188" num="0187">Subsequently, the control unit <b>95</b> determines whether or not a switching signal to change the observation mode of the endoscope system <b>1</b> has been input from the input unit <b>93</b> (Step S<b>96</b>). In a case where the control unit <b>95</b> determines that the switching signal to change the observation mode of the endoscope system <b>1</b> has been input from the input unit <b>93</b> (Step S<b>96</b>: Yes), the endoscope system <b>1</b> returns to the main routine in <figref idref="DRAWINGS">FIG. <b>14</b></figref>. On the contrary, in a case where the control unit <b>95</b> determines that the switching signal to change the observation mode of the endoscope system <b>1</b> has not been input from the input unit <b>93</b> (Step S<b>96</b>: No), the endoscope system <b>1</b> returns to Step S<b>71</b> described above.</p><p id="p-0189" num="0188">The first embodiment described above enables, by the single imaging element <b>53</b>, both narrow band light observation and observation of fluorescence generated by heat treatment using an energy device, for example, because the cut filter <b>54</b> is provided on the light receiving surface side of the pixels provided with the filters G and the cut filter <b>54</b> shields shorter wavelength light including the wavelength band of the second narrow band light and transmits therethrough the first narrow band light.</p><p id="p-0190" num="0189">Furthermore, the first embodiment enables, by means of the single imaging element <b>53</b>, both narrow band light observation and observation of fluorescence generated by heat treatment using an energy device, for example, because the image processing unit <b>92</b> generates a narrow band light image (pseudocolor image) on the basis of blue component signals and green component signals in the narrow band light observation mode, and generates a heat treatment image (pseudocolor image) on the basis of blue component signals and green component signals in the heat treatment observation mode.</p><p id="p-0191" num="0190">Furthermore, according to the first embodiment, in a case where only the second narrow band light is emitted to an advanced glycation end product by the light source device <b>3</b>, the image processing unit <b>92</b> makes gains for blue component signals smaller than gains for green component signals, and fluorescence included in a heat treatment image is thus able to be enhanced relatively to the background</p><p id="p-0192" num="0191">Furthermore, the first embodiment enables, by means of the single imaging element <b>53</b>, all of narrow band light observation, observation of fluorescence generated by heat treatment using an energy device, for example, and normal light observation, because in the normal light observation mode, the image processing unit <b>92</b> generates a white image by adjusting the white balance so that the ratio of values of the red component signals, green component signals, and blue component signals included in image data becomes constant.</p><heading id="h-0009" level="1">Second Embodiment</heading><p id="p-0193" num="0192">A second embodiment will be described next. An endoscope system according to a second embodiment has the same configuration as the above described endoscope system <b>1</b> according to the first embodiment, but executes processing different from that of the endoscope system <b>1</b>. Specifically, in the first embodiment described above, the observation mode is switched between plural observation modes, but in this second embodiment, two sets of image data having different characteristics are generated by alternate execution of plural observation modes, and recording is conducted through manual switching by an operating surgeon, such as a medical doctor, or recording is conducted by switching between images displayed by a display device when a predetermined condition is met. The processing executed by the endoscope system according to the second embodiment will thus be described hereinafter. The same reference signs will be assigned to components of the second embodiment that are the same as those of the above described endoscope system <b>1</b> according to the first embodiment, and detailed description of these components will thus be omitted.</p><p id="p-0194" num="0193">Processing by Endoscope System</p><p id="p-0195" num="0194"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a flowchart illustrating an outline of the processing executed by the endoscope system <b>1</b> according to the second embodiment. For simplification, a case where the endoscope system <b>1</b> performs the normal light observation and heat treatment observation described above will be described with respect to <figref idref="DRAWINGS">FIG. <b>19</b></figref>.</p><p id="p-0196" num="0195">As illustrated in <figref idref="DRAWINGS">FIG. <b>19</b></figref>, firstly, the endoscope system <b>1</b> executes imaging recording processing of irradiating body tissue of a subject with white light or the second narrow band light and imaging and recording returned light, reflected light, and fluorescence from the body tissue (Step S<b>101</b>), and executes display processing of displaying an image based on image data captured (Step S<b>102</b>). Details of the imaging recording processing and display processing will be described later.</p><p id="p-0197" num="0196">Subsequently, the control unit <b>95</b> determines whether or not an instruction signal to instruct the system to end the observation of the subject has been input from the input unit <b>93</b> (Step S<b>103</b>). In a case where the control unit <b>95</b> determines that the instruction signal to instruct the system to end the observation of the subject has been input from the input unit <b>93</b> (Step S<b>103</b>: Yes), the endoscope system <b>1</b> ends the processing. On the contrary, in a case where the control unit <b>95</b> determines that the instruction signal to instruct the system to end the observation of the subject has not been input from the input unit <b>93</b> (Step S<b>103</b>: No), the endoscope system <b>1</b> returns to Step S<b>101</b> described above.</p><p id="p-0198" num="0197">Imaging Recording Processing</p><p id="p-0199" num="0198">Details of the imaging recording processing at Step S<b>101</b> in <figref idref="DRAWINGS">FIG. <b>19</b></figref> described above will be described next. <figref idref="DRAWINGS">FIG. <b>20</b></figref> is a flowchart illustrating an outline of the imaging recording processing.</p><p id="p-0200" num="0199">As illustrated in <figref idref="DRAWINGS">FIG. <b>20</b></figref>, the control unit <b>95</b> causes the first light source portion <b>31</b> to emit light by controlling the light source control unit <b>34</b> and thereby causes white light to be emitted to the subject (Step S<b>201</b>).</p><p id="p-0201" num="0200">Subsequently, by controlling the imaging control unit <b>58</b>, the control unit <b>95</b> causes the imaging element <b>53</b> to capture a subject image condensed by the optical system <b>22</b> and optical system <b>51</b> and transmitted through the cut filter <b>54</b> (Step S<b>202</b>).</p><p id="p-0202" num="0201">Thereafter, the control unit <b>95</b> causes the image processing unit <b>92</b> to execute predetermined image processing of image data input via the A/D converter <b>55</b>, the P/S converter <b>56</b>, and the S/P converter <b>91</b> and to generate a white image (Step S<b>203</b>).</p><p id="p-0203" num="0202">Subsequently, the control unit <b>95</b> records the white image generated by the image processing unit <b>92</b> into the recording unit <b>94</b> (Step S<b>204</b>).</p><p id="p-0204" num="0203">Thereafter, the control unit <b>95</b> controls the light source control unit <b>34</b> to cause the third light source portion <b>33</b> to emit light, and thereby causes the second narrow band light to be emitted to the subject (Step S<b>205</b>).</p><p id="p-0205" num="0204">Subsequently, by controlling the imaging control unit <b>58</b>, the control unit <b>95</b> causes the imaging element <b>53</b> to capture a subject image condensed by the optical system <b>22</b> and optical system <b>51</b> and transmitted through the cut filter <b>54</b> (Step S<b>206</b>).</p><p id="p-0206" num="0205">Thereafter, the control unit <b>95</b> causes the image processing unit <b>92</b> to execute predetermined image processing of image data input via the A/D converter <b>55</b>, the P/S converter <b>56</b>, and the S/P converter <b>91</b> and to generate a heat treatment image (Step S<b>207</b>).</p><p id="p-0207" num="0206">Subsequently, the control unit <b>95</b> determines whether or not a recording signal to record the heat treatment image has been input from the input unit <b>93</b> (Step S<b>208</b>). Specifically, in a case where an operating surgeon, such as a medical doctor, performs heat treatment of body tissue by means of an energy device, for example, by operating the input unit <b>93</b>, the control unit <b>95</b> determines whether or not a recording signal to record a heat treatment image captured, into the recording unit <b>94</b>, has been input from the input unit <b>93</b>. In a case where the control unit <b>95</b> determines that the recording signal to record the heat treatment image has been input from the input unit <b>93</b> (Step S<b>208</b>: Yes), the endoscope system <b>1</b> proceeds to Step S<b>209</b> described later. On the contrary, in a case where the control unit <b>95</b> determines that the recording signal to record the heat treatment image has not been input from the input unit <b>93</b> (Step S<b>209</b>: No), the endoscope system <b>1</b> proceeds to Step S<b>210</b> described later.</p><p id="p-0208" num="0207">At Step S<b>209</b>, the control unit <b>95</b> records the heat treatment image generated by the image processing unit <b>92</b>, into the recording unit <b>94</b>. After Step S<b>209</b>, the endoscope system <b>1</b> returns to the main routine in <figref idref="DRAWINGS">FIG. <b>19</b></figref> described above.</p><p id="p-0209" num="0208">At Step S<b>210</b>, the control unit <b>95</b> determines whether or not a predetermined condition has been met. Specifically, the control unit <b>95</b> determines, on the basis of a driving signal input from, for example, the energy device, whether or not, the energy device has started heat treatment. Furthermore, the control unit <b>95</b> determines whether or not the predetermined condition has been met, on the basis of: a state of the body tissue included in the heat treatment image generated by the image processing unit <b>92</b>, the body tissue having been subjected to the heat treatment; and/or the quantity of fluorescence emitted. For example, in a case where the quantity of fluorescence emitted is equal to or larger than a predetermined threshold, the control unit <b>95</b> determines that the predetermined condition has been met. In addition, the control unit <b>95</b> determines whether or not the predetermined condition has been met, on the basis of: an area of a fluorescent region of the body tissue subjected to the heat treatment, the fluorescent region being included in the heat treatment image generated by the image processing unit <b>92</b>. For example, the control unit <b>95</b> determines whether or not the area of the fluorescent region included in the heat treatment image is equal to or larger than a predetermined threshold. In a case where the control unit <b>95</b> determines that the predetermined condition has been met (Step S<b>210</b>: Yes), the endoscope system <b>1</b> proceeds to Step S<b>211</b> described later. On the contrary, in a case where the control unit <b>95</b> determines that the predetermined condition has not been met (Step S<b>210</b>: No), the endoscope system <b>1</b> returns to the main routine in <figref idref="DRAWINGS">FIG. <b>19</b></figref> described above.</p><p id="p-0210" num="0209">At Step S<b>211</b>, the control unit <b>95</b> records the heat treatment image generated by the image processing unit <b>92</b>, into the recording unit <b>94</b>. After Step S<b>211</b>, the endoscope system <b>1</b> returns to the main routine in <figref idref="DRAWINGS">FIG. <b>19</b></figref> described above.</p><p id="p-0211" num="0210">Display Processing</p><p id="p-0212" num="0211">An outline of the display processing at Step S<b>102</b> in <figref idref="DRAWINGS">FIG. <b>19</b></figref> described above will be described next. <figref idref="DRAWINGS">FIG. <b>21</b></figref> is a flowchart illustrating the outline of the display processing.</p><p id="p-0213" num="0212">As illustrated in <figref idref="DRAWINGS">FIG. <b>21</b></figref>, the control unit <b>95</b> determines whether or not an instruction signal to instruct display of a white image and a heat treatment image has been input from the input unit <b>93</b> (Step S<b>301</b>). In a case where the control unit <b>95</b> determines that the instruction signal to instruct the display of the white image and the heat treatment image has been input from the input unit <b>93</b> (Step S<b>301</b>: Yes), the endoscope system <b>1</b> proceeds to Step S<b>302</b> described later. On the contrary, in a case where the control unit <b>95</b> determines that the instruction signal to instruct the display of the white image and the heat treatment image has not been input from the input unit <b>93</b> (Step S<b>301</b>: No), the endoscope system <b>1</b> proceeds to Step S<b>305</b> described later.</p><p id="p-0214" num="0213">At Step S<b>302</b>, the control unit <b>95</b> causes the white image and the heat treatment image to be displayed by the display device <b>7</b> by causing the image processing unit <b>92</b> to output the white image and the heat treatment image. <figref idref="DRAWINGS">FIG. <b>22</b></figref> is a diagram illustrating an example of an image displayed by the display device <b>7</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>22</b></figref>, the control unit <b>95</b> causes the display device <b>7</b> to display a combined image P<b>1</b> that is a combination of a white image and a heat treatment image. In this case, the image processing unit <b>92</b> combines the white image and the heat treatment image such that a combination ratio between the white image and the heat treatment image becomes 1:1. Of course, the image processing unit <b>92</b> may change, as appropriate, the combination ratio according to an instruction signal input from the input unit <b>93</b>. Furthermore, the image processing unit <b>92</b> may combine only a fluorescent region in the heat treatment image, for example, pixels of the heat treatment image, with the white image, the pixels having signal values equal to or larger than a threshold. An operating surgeon, such as a medical doctor, is thereby able to intuitively know a heat-treated region Z<b>1</b> including the position of heat treatment by the energy device, for example, by observing a combined image P<b>1</b> that is a combination of the white image and the heat treatment image. Of course, in the second embodiment, a combined image may be a superimposed image having a heat treatment image superimposed on a white image.</p><p id="p-0215" num="0214">Subsequently, the control unit <b>95</b> determines whether or not a switching signal to change the display mode of an image displayed by the display device <b>7</b> has been input from the input unit <b>93</b> (Step S<b>303</b>). In a case where the control unit <b>95</b> determines that the switching signal to change the display mode of the image displayed by the display device <b>7</b> has been input from the input unit <b>93</b> (Step S<b>303</b>: Yes), the endoscope system <b>1</b> proceeds to Step S<b>304</b> described later. On the contrary, in a case where the control unit <b>95</b> determines that the switching signal to change the display mode of the image displayed by the display device <b>7</b> has not been input from the input unit <b>93</b> (Step S<b>303</b>: No), the endoscope system <b>1</b> returns to the main routine in <figref idref="DRAWINGS">FIG. <b>19</b></figref>.</p><p id="p-0216" num="0215">At Step S<b>304</b>, the control unit <b>95</b> causes a white image and a heat treatment image to be generated and output to the display device <b>7</b>, the white image and heat treatment image being in a display mode according to the switching signal input from the input unit <b>93</b>, and thereby controls the display mode of the image displayed by the display device <b>7</b>. After Step S<b>304</b>, the endoscope system <b>1</b> returns to the main routine in <figref idref="DRAWINGS">FIG. <b>19</b></figref>.</p><p id="p-0217" num="0216"><figref idref="DRAWINGS">FIG. <b>23</b></figref> is a diagram illustrating an example of an image displayed by the display device <b>7</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>23</b></figref>, the control unit <b>95</b> causes the image processing unit <b>92</b> to generate a display image P<b>2</b> having a white image P<b>10</b> and a heat treatment image P<b>11</b> juxtaposed to each other and to output the display image P<b>2</b> to the display device <b>7</b>. An operating surgeon, such as a medical doctor, is thereby able to intuitively know the heat-treated region Z<b>1</b> including the position of the heat treatment by a treatment tool, such as an energy device, for example, by observing the display image P<b>2</b> while comparing the white image P<b>10</b> and the heat treatment image P<b>11</b> to each other.</p><p id="p-0218" num="0217"><figref idref="DRAWINGS">FIG. <b>24</b></figref> is a diagram illustrating another example of the image displayed by the display device <b>7</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>24</b></figref>, the control unit <b>95</b> causes the image processing unit <b>92</b> to generate a display image P<b>3</b> and to output the display image P<b>3</b> to the display device <b>7</b>, the display image P<b>3</b> having the white image P<b>10</b> and the heat treatment image P<b>11</b> juxtaposed to each other. In this display image P<b>3</b>, a display area of the heat treatment image P<b>11</b> is smaller than a display area of the white image P<b>10</b>. An operating surgeon, such as a medical doctor, is thereby able to intuitively know the heat-treated region Z<b>1</b> including the position of the heat treatment by the energy device, for example, by observing the display image P<b>3</b> while comparing the white image P<b>10</b> and the heat treatment image P<b>11</b> to each other. The control unit <b>95</b> may cause the image processing unit <b>92</b> to generate the display image P<b>3</b> with the display ratio of the heat treatment image P<b>11</b> and the white image P<b>10</b> in the display image P<b>3</b> changed according to an instruction signal from the input unit <b>93</b>.</p><p id="p-0219" num="0218"><figref idref="DRAWINGS">FIG. <b>25</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>25</b>C</figref> are diagrams illustrating other examples of the image displayed by the display device <b>7</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>25</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>25</b>C</figref>, according to the number of times of input of a switching signal by the input unit <b>93</b>, the control unit <b>95</b> may cause the image processing unit <b>92</b> to change the image to be output in the order, the white image P<b>10</b> (<figref idref="DRAWINGS">FIG. <b>25</b>A</figref>), the display image P<b>3</b> (FIG. <b>25</b>B), and the heat treatment image P<b>11</b> (<figref idref="DRAWINGS">FIG. <b>25</b>C</figref>), and to thereby cause the image to be displayed by the display device <b>7</b>. An operating surgeon, such as a medical doctor, is able to observe a desired image by streamlined operations.</p><p id="p-0220" num="0219">By reference back to <figref idref="DRAWINGS">FIG. <b>21</b></figref>, description of the processing from Step S<b>305</b> will be continued.</p><p id="p-0221" num="0220">At Step S<b>305</b>, the control unit <b>95</b> determines whether or not a predetermined condition has been met. Specifically, the control unit <b>95</b> determines, on the basis of a driving signal input from, for example, an energy device, whether or not, the energy device has started or ended heat treatment. Furthermore, the control unit <b>95</b> determines whether or not the predetermined condition has been met, on the basis of: a state of the body tissue included in the heat treatment image generated by the image processing unit <b>92</b>, the body tissue having been subjected to the heat treatment; and/or quantity of fluorescence emitted. For example, in a case where the quantity of fluorescence emitted is equal to or larger than a predetermined threshold, the control unit <b>95</b> determines that the predetermined condition has been met. Furthermore, the control unit <b>95</b> determines whether or not the predetermined condition has been met, on the basis of: an area of a fluorescent region of the body tissue subjected to the heat treatment, the fluorescent region being included in the heat treatment image generated by the image processing unit <b>92</b>. For example, the control unit <b>95</b> determines whether or not the area of the fluorescent region included in the heat treatment image is equal to or larger than a predetermined threshold. In a case where the control unit <b>95</b> determines that the predetermined condition has been met (Step S<b>305</b>: Yes), the endoscope system <b>1</b> proceeds to Step S<b>306</b> described later. On the contrary, in a case where the control unit <b>95</b> determines that the predetermined condition has not been met (Step S<b>305</b>: No), the endoscope system <b>1</b> proceeds to Step S<b>309</b> described later.</p><p id="p-0222" num="0221">At Step S<b>306</b>, the control unit <b>95</b> causes a combined image to be generated and output to the display device <b>7</b>, the combined image being a combination of a white image and a heat treatment image, and thereby causes the display device <b>7</b> to display the combined image. After Step S<b>306</b>, the endoscope system <b>1</b> returns to the main routine in <figref idref="DRAWINGS">FIG. <b>19</b></figref>.</p><p id="p-0223" num="0222"><figref idref="DRAWINGS">FIG. <b>26</b></figref> is a diagram illustrating an example of an image displayed by the display device <b>7</b>. <figref idref="DRAWINGS">FIG. <b>27</b></figref> is a diagram illustrating correspondence between intensity of fluorescence and depth of heat treatment. In <figref idref="DRAWINGS">FIG. <b>27</b></figref>, the vertical axis represents the intensity of fluorescence and the horizontal axis represents the depth of heat treatment within body tissue. Furthermore, in <figref idref="DRAWINGS">FIG. <b>27</b></figref>, a straight line Ly represents a correlation between the intensity of fluorescence and the depth of heat treatment within the body tissue.</p><p id="p-0224" num="0223">As illustrated in <figref idref="DRAWINGS">FIG. <b>26</b></figref>, the control unit <b>95</b> causes the image processing unit <b>92</b> to cause the display device <b>7</b> to display a combined image P<b>20</b> that is a combination of a white image and a heat treatment image. In this case, the image processing unit <b>92</b> generates the combined image P<b>20</b> by combining the white image and the heat treatment image so that a combination ratio between the white image and the heat treatment image becomes 1:1. Furthermore, as illustrated in <figref idref="DRAWINGS">FIG. <b>26</b></figref> and <figref idref="DRAWINGS">FIG. <b>27</b></figref>, the image processing unit <b>92</b> generates the combined image P<b>20</b> having a color highlight-displayed, the color being that of a fluorescent region, according to quantity of fluorescence emitted from a heat-treated region included in the heat treatment image. For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>26</b></figref>, the image processing unit <b>92</b> generates a heat-treated region Z<b>2</b> where the quantity of fluorescence emitted is small in blue and the heat-treated region Z<b>1</b> where the quantity of fluorescence emitted is larger than that in the heat-treated region Z<b>2</b> in green. The heat-treated region Z<b>2</b> where the quantity of fluorescence emitted is small represents a region that has been marked by use of a treatment tool, such as an energy device, before excision of an abnormal region, such as a tumor, by an operating surgeon, such as a medical doctor, using an electrosurgical knife. Furthermore, as illustrated by a heat treatment image P<b>21</b> in <figref idref="DRAWINGS">FIG. <b>28</b></figref>, the image processing unit <b>92</b> may generate a heat-treated region Z<b>3</b> that has been heat-treated in yellow, correspondingly to quantity of fluorescence emitted. An operating surgeon, such as a medical doctor, is thereby able to intuitively know a state of heat treatment according to a color.</p><p id="p-0225" num="0224">At Step S<b>307</b>, the control unit <b>95</b> determines whether or not an instruction signal to specify a heat treatment image as an image instructed to be displayed by the display device <b>7</b> has been input from the input unit <b>93</b>. In a case where the control unit <b>95</b> determines that the instruction signal to specify a heat treatment image as an image instructed to be displayed by the display device <b>7</b> has been input from the input unit <b>93</b> (Step S<b>307</b>: Yes), the endoscope system <b>1</b> proceeds to Step S<b>308</b> described later. On the contrary, in a case where the control unit <b>95</b> determines that the instruction signal to specify a heat treatment image as an image instructed to be displayed by the display device <b>7</b> has not been input from the input unit <b>93</b> (Step S<b>307</b>: No), the endoscope system <b>1</b> proceeds to Step S<b>309</b> described later.</p><p id="p-0226" num="0225">At Step S<b>308</b>, the control unit <b>95</b> causes the image processing unit <b>92</b> to generate a heat treatment image and to output the heat treatment image to the display device <b>7</b> and thereby causes the display device <b>7</b> to display the heat treatment image. For example, the control unit <b>95</b> causes the image processing unit <b>92</b> to generate the heat treatment image P<b>11</b> in <figref idref="DRAWINGS">FIG. <b>25</b>C</figref> described above and to output the heat treatment image P<b>11</b> to the display device <b>7</b>. After Step S<b>308</b>, the endoscope system <b>1</b> returns to the main routine in <figref idref="DRAWINGS">FIG. <b>19</b></figref>.</p><p id="p-0227" num="0226">At Step S<b>309</b>, the control unit <b>95</b> causes the image processing unit <b>92</b> to generate a white image and to output the white image to the display device <b>7</b> and thereby causes the display device <b>7</b> to display the white image. For example, the control unit <b>95</b> causes the image processing unit <b>92</b> to generate the white image P<b>10</b> in <figref idref="DRAWINGS">FIG. <b>25</b>A</figref> described above and to output the white image P<b>10</b> to the display device <b>7</b>. After Step S<b>309</b>, the endoscope system <b>1</b> returns to the main routine in <figref idref="DRAWINGS">FIG. <b>19</b></figref>.</p><p id="p-0228" num="0227">The second embodiment described above enables, by means of the single imaging element <b>53</b>, both narrow band light observation and observation of fluorescence generated by heat treatment using an energy device because the cut filter <b>54</b> is provided on the light receiving surface side of the pixels provided with the filters G and the cut filter <b>54</b> shields shorter wavelength light including the wavelength band of the second narrow band light and transmits therethrough the first narrow band light.</p><heading id="h-0010" level="1">Third Embodiment</heading><p id="p-0229" num="0228">A third embodiment will be described next. The first and second embodiments described above are each related to an endoscope system including a rigid endoscope, but with respect to the third embodiment, an endoscope system including a flexible endoscope will be described. The endoscope system according to the third embodiment will be described hereinafter. The same reference signs will be assigned to components of the third embodiment that are the same as those of the above described endoscope system <b>1</b> according to the first embodiment, and detailed description of these components will thus be omitted.</p><p id="p-0230" num="0229">Configuration of Endoscope System</p><p id="p-0231" num="0230"><figref idref="DRAWINGS">FIG. <b>29</b></figref> is a diagram illustrating a schematic configuration of the endoscope system according to the third embodiment. <figref idref="DRAWINGS">FIG. <b>30</b></figref> is a block diagram illustrating a functional configuration of main parts of the endoscope system according to the third embodiment.</p><p id="p-0232" num="0231">In an endoscope system <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>29</b></figref> and <figref idref="DRAWINGS">FIG. <b>30</b></figref>, an image of the interior of the body of a subject, such as a patient, is captured by insertion into the subject, and a display image based on data on the image captured is displayed by the display device <b>7</b>. By observing the display image displayed by the display device <b>7</b>, an operating surgeon, such as a medical doctor, examines any presence and/or a state of an abnormal region having a site to be examined captured therein, the site being, for example, a bleeding site, a tumor site, and/or an abnormal site. Furthermore, the operating surgeon, such as a medical doctor, performs treatment of the subject by inserting a treatment tool, such as an energy device, into the body of the subject via a treatment tool channel of an endoscope. The endoscope system <b>100</b> includes, in addition to the light source device <b>3</b>, display device <b>7</b>, and control device <b>9</b> described above, an endoscope <b>102</b>.</p><p id="p-0233" num="0232">Configuration of Endoscope</p><p id="p-0234" num="0233">The following description is related to a configuration of the endoscope <b>102</b>. The endoscope <b>102</b> generates image data by capturing an image of the interior of the body of a subject and outputs the image data generated, to the control device <b>9</b>. The endoscope <b>102</b> includes an operating unit <b>122</b> and a universal cord <b>123</b>.</p><p id="p-0235" num="0234">An insertion portion <b>121</b> has flexibility and is elongated. The insertion portion <b>121</b> includes: a distal end portion <b>124</b> having, built therein, an imaging device described later; a bending portion <b>125</b> that includes plural bending pieces and is bendable; and a flexible tube portion <b>126</b> that is connected to a proximal end of the bending portion <b>125</b>, has flexibility, and is elongated.</p><p id="p-0236" num="0235">The distal end portion <b>124</b> is formed by use of, for example, glass fiber. The distal end portion <b>124</b> includes: a light guide <b>241</b> forming a light guiding path for light supplied from the light source device <b>3</b>; an illumination lens <b>242</b> provided at a distal end of the light guide <b>241</b>; and an imaging device <b>243</b>.</p><p id="p-0237" num="0236">The imaging device <b>243</b> includes an optical system <b>244</b> for condensing light, and the above described imaging element <b>53</b>, cut filter <b>54</b>, A/D converter <b>55</b>, P/S converter <b>56</b>, imaging recording unit <b>57</b>, and imaging control unit <b>58</b> according to the first embodiment. In this third embodiment, the imaging device <b>243</b> functions as a medical imaging device.</p><p id="p-0238" num="0237">The universal cord <b>123</b> has, built therein, at least the light guide <b>241</b> and an assembly cable having one or plural cables bundled together. The assembly cable includes signal lines for transmitting and receiving signals between: the endoscope <b>102</b> and light source device <b>3</b>; and the control device <b>9</b>. These signal lines include a signal line for transmitting and receiving setting data, a signal line for transmitting and receiving a captured image (image data), and a signal line for transmitting and receiving a driving timing signal for driving the imaging element <b>53</b>. The universal cord <b>123</b> has a connector <b>127</b> that is attachable to and detachable from the light source device <b>3</b>. A coil cable <b>127</b><i>a </i>that is coil-shaped extends from the connector <b>127</b>. A connector <b>128</b> attachable to and detachable from the control device <b>9</b> is provided at an extended end of the coil cable <b>127</b><i>a. </i></p><p id="p-0239" num="0238">The endoscope system <b>100</b> configured as described above performs processing similar to that by the above described endoscope system <b>1</b> according to the first embodiment.</p><p id="p-0240" num="0239">The third embodiment described above has effects similar to those of the first embodiment described above, and also enables reduction in diameter of the insertion portion <b>121</b> because both narrow band light observation and observation of fluorescence generated by heat treatment with an energy device are able to be conducted by means of just the single imaging element <b>53</b>.</p><heading id="h-0011" level="1">Fourth Embodiment</heading><p id="p-0241" num="0240">A fourth embodiment will be described next. Endoscope systems have been described above with respect to the first to third embodiments, but application to a surgical microscope system will be described with respect to the fourth embodiment. The same reference signs will be assigned to components of the fourth embodiment that are the same as those of the above described endoscope system <b>1</b> according to the first embodiment, and detailed description of these components will thus be omitted.</p><p id="p-0242" num="0241">Configuration of Surgical Microscope System</p><p id="p-0243" num="0242"><figref idref="DRAWINGS">FIG. <b>31</b></figref> is a diagram illustrating a schematic configuration of the surgical microscope system according to the fourth embodiment. A surgical microscope system <b>300</b> illustrated in <figref idref="DRAWINGS">FIG. <b>31</b></figref> includes: a microscope device <b>310</b> that is a medical imaging device that obtains an image for observation of a subject by imaging; and the display device <b>17</b>. The display device <b>17</b> and the microscope device <b>310</b> may be configured integrally with each other.</p><p id="p-0244" num="0243">The microscope device <b>310</b> includes: a microscope unit <b>312</b> that captures an enlarged image of a microscopic site in a subject; a supporting unit <b>313</b> that is connected to a proximal end portion of the microscope unit <b>312</b> and includes an arm that supports the microscope unit <b>312</b> rotatably; and a base unit <b>314</b> that holds a proximal end portion of the supporting unit <b>313</b> rotatably and is capable of moving on a floor surface. The base unit <b>314</b> includes: the light source device <b>3</b> that generates, for example, white light, the first narrow band light, and the second narrow band light to be emitted to a subject from the microscope device <b>310</b>; and the control device <b>9</b> that controls operation of the surgical microscope system <b>300</b>. The light source device <b>3</b> and the control device <b>9</b> both have at least the same configurations as those in the first embodiment described above. Specifically, the light source device <b>3</b> includes the condenser lens <b>30</b>, the first light source portion <b>31</b>, the second light source portion <b>32</b>, the third light source portion <b>33</b>, and the light source control unit <b>34</b>. The control device <b>9</b> includes the S/P converter <b>91</b>, the image processing unit <b>92</b>, the input unit <b>93</b>, the recording unit <b>94</b>, and the control unit <b>95</b>. Instead of being provided movably on the floor surface, the base unit <b>314</b> may be configured to support the supporting unit <b>313</b> by being be fixed to, for example, a ceiling or a wall surface.</p><p id="p-0245" num="0244">The microscope unit <b>312</b> is, for example, cylindrical, and includes therein the medical imaging device described above. Specifically, the medical imaging device includes the same configuration as that of the above described endoscope camera head <b>5</b> according to the first embodiment. For example, the microscope unit <b>312</b> includes the optical system <b>51</b>, the drive unit <b>52</b>, the imaging element <b>53</b>, the cut filter <b>54</b>, the A/D converter <b>55</b>, the P/S converter <b>56</b>, the imaging recording unit <b>57</b>, and the imaging control unit <b>58</b>. Furthermore, a switch that receives input of an operation instruction for the microscope device <b>310</b> is provided on a side surface of the microscope unit <b>312</b>. A cover glass that protects the interior of the microscope unit <b>312</b> is provided on the plane of an opening at a lower end of the microscope unit <b>312</b>.</p><p id="p-0246" num="0245">In the surgical microscope system <b>300</b> configured as described above, the microscope unit <b>312</b> is moved, a zooming operation is performed, and/or illumination light is changed, by a user, such as an operating surgeon, while the user operates any of various switches in a state where the microscope unit <b>312</b> is being held by the user. The microscope unit <b>312</b> preferably has an elongated shape extending in an observation direction so that it is easy for the user to hold the microscope unit <b>312</b> and change the field of view direction. Therefore, the microscope unit <b>312</b> may be not cylindrical, and may have, for example, a polygonal prism shape.</p><p id="p-0247" num="0246">The above described surgical microscope system <b>300</b> according to the fourth embodiment also achieves effects similar to those of the above described first embodiment and additionally enables downsizing of the microscope unit <b>312</b>.</p><heading id="h-0012" level="1">First Modified Example of First to Fourth Embodiments</heading><p id="p-0248" num="0247">A first modified example of the first to fourth embodiments will be described next. Only a configuration of a cut filter in the first modified example of the first to fourth embodiments is different from those of the first to fourth embodiments. The configuration of the cut filter according to the first modified example of the first to fourth embodiments will thus be described hereinafter.</p><p id="p-0249" num="0248"><figref idref="DRAWINGS">FIG. <b>32</b></figref> is a diagram schematically illustrating the configuration of the cut filter according to the first modified example of the first to fourth embodiments. A cut filter <b>54</b>A illustrated in <figref idref="DRAWINGS">FIG. <b>32</b></figref> is provided on the light receiving surface side (incident surface side) of at least the G pixels provided with the filters G of the color filter <b>532</b> and on the light receiving surface side (incident surface side) of the R pixels provided with the filters R of the color filter <b>532</b>, shields light of a short wavelength band including the wavelength band of the second narrow band light, and transmits therethrough light that includes the first narrow band light and that is light of a wavelength band longer than the wavelength band of the second narrow band light. Specifically, as illustrated in <figref idref="DRAWINGS">FIG. <b>32</b></figref>, a filter F<sub>11 </sub>forming the cut filter <b>54</b>A is arranged at a position where the filter G<sub>11 </sub>is arranged (see <figref idref="DRAWINGS">FIG. <b>5</b></figref>) and on the light receiving surface side directly above the filter G<sub>11</sub>. Furthermore, a filter F<sub>21 </sub>is arranged at a position where the filter R<sub>21 </sub>is arranged (see <figref idref="DRAWINGS">FIG. <b>5</b></figref>) and on the light receiving surface side directly above the filter R<sub>21</sub>.</p><p id="p-0250" num="0249">Method of Manufacturing Cut Filter</p><p id="p-0251" num="0250">A method of manufacturing the cut filter <b>54</b>A will be described next. <figref idref="DRAWINGS">FIG. <b>33</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>33</b>B</figref> are diagrams schematically illustrating the method of manufacturing the cut filter <b>54</b>A.</p><p id="p-0252" num="0251">As illustrated in <figref idref="DRAWINGS">FIG. <b>33</b>A</figref>, firstly, a coating device (not illustrated in the drawings) that coats an object with a light-shielding film coats rows in the cut filter <b>54</b>A with a light-shielding film, the rows corresponding to rows of G pixels and R pixels arranged along a vertical direction of the cut filter <b>54</b>A (<figref idref="DRAWINGS">FIG. <b>33</b>A</figref>). Subsequently, the coating device coats rows in the cut filter <b>54</b>A with a light-shielding film, the rows corresponding to rows of G pixels and R pixels arranged along a horizontal direction of the cut filter <b>54</b>A (<figref idref="DRAWINGS">FIG. <b>33</b>B</figref>).</p><p id="p-0253" num="0252">The above described first modified example of the first to fourth embodiments facilitates connection of the cut filter <b>54</b>A.</p><p id="p-0254" num="0253">Furthermore, in the above described first modified example of the first to fourth embodiments, the coating process is performed twice in the vertical direction and the horizontal direction, but, for example, the cut filter <b>54</b>A may be manufactured by masking portions corresponding to the B pixels, coating the entire surface with a light-shielding film, and thereafter removing the mask.</p><heading id="h-0013" level="1">Second Modified Example of First to Fourth Embodiments</heading><p id="p-0255" num="0254">A second modified example of the first to fourth embodiments will be described next. In the second modified example of the first to fourth embodiments, the above described cut filter <b>54</b> according to the first embodiment has been omitted and transmission characteristics of filters G of a color filter have been made different. A configuration of the color filter according to the second modified example of the first to fourth embodiments will thus be described hereinafter. The same reference signs will be assigned to components of the second modified example of the first to fourth embodiments, the components being the same as those of the above described endoscope system <b>1</b> according to the first embodiment, and detailed description of these components will thus be omitted.</p><p id="p-0256" num="0255"><figref idref="DRAWINGS">FIG. <b>34</b></figref> is a diagram schematically illustrating the transmission characteristics of the filters G of the color filter according to the second modified example of the first to fourth embodiments. In <figref idref="DRAWINGS">FIG. <b>34</b></figref>, the horizontal axis represents wavelength and the vertical axis represents the transmission characteristics. In <figref idref="DRAWINGS">FIG. <b>34</b></figref>, a curve L<sub>G10 </sub>represents the transmission characteristics of the filters G.</p><p id="p-0257" num="0256">As represented by the curve L<sub>G10 </sub>in <figref idref="DRAWINGS">FIG. <b>34</b></figref>, the filters G shield light of a wavelength band shorter than 415 nm. That is, the filters G shield light of a short wavelength band including the wavelength band of the second narrow band light and transmit therethrough light that includes the first narrow band light and that is light of a wavelength band longer than the wavelength band of the second narrow band light.</p><p id="p-0258" num="0257">The above described second modified example of the first to fourth embodiments enables the cut filter <b>54</b> to be omitted and thus enables the configuration to be uncomplicated.</p><heading id="h-0014" level="1">Third Modified Example of First to Fourth Embodiments</heading><p id="p-0259" num="0258">A third modified example of the first to fourth embodiments will be described next. A cut filter in the third modified example of the first to fourth embodiments has a configuration different from that of the above described cut filter <b>54</b> according to the first embodiment. The configuration of the cut filter according to the third modified example of the first to fourth embodiments will thus be described hereinafter. The same reference signs will be assigned to components of the third modified example of the first to fourth embodiments, the components being the same as those of the above described endoscope system <b>1</b> according to the first embodiment, and detailed description of these components will thus be omitted.</p><p id="p-0260" num="0259"><figref idref="DRAWINGS">FIG. <b>35</b></figref> is a diagram schematically illustrating the configuration of the cut filter according to the third modified example of the first to fourth embodiments. A cut filter <b>54</b>C illustrated in <figref idref="DRAWINGS">FIG. <b>35</b></figref> has a transmitting portion <b>541</b> that is disk-shaped and transmits therethrough light of all wavelength bands, and a transmitting portion <b>542</b> that shields light of a short wavelength band including the wavelength band of the second narrow band light and transmits therethrough light that includes the first narrow band light and that is light of a wavelength band longer than the wavelength band of the second narrow band light. The cut filter <b>54</b>C is rotated about the optical axis L<b>1</b> by a drive unit, such as a motor, not illustrated in the drawings.</p><p id="p-0261" num="0260">The above described third modified example of the first to fourth embodiments achieves effects similar to those of the above described first to fourth embodiments.</p><p id="p-0262" num="0261">Furthermore, in the third modified example of the first to fourth embodiments, the wavelength band of light incident on the imaging element <b>53</b> is limited by rotation of the cut filter <b>54</b>C, but, for example, an electronic filter that shields light of a predetermined wavelength band according to an electric current value may be provided instead of the cut filter <b>54</b>C.</p><heading id="h-0015" level="1">OTHER EMBODIMENTS</heading><p id="p-0263" num="0262">Various embodiments may be formed by combination, as appropriate, of plural components disclosed with respect to the above described medical observation systems according to the first to fourth embodiments of the present disclosure. For example, some of the components described with respect to the medical observation system/systems according to any of the above described embodiments of the present disclosure may be eliminated. Furthermore, any components described with respect to the medical observation system/systems according to any of the above described embodiments of the present disclosure may be combined as appropriate.</p><p id="p-0264" num="0263">Furthermore, the &#x201c;units&#x201d; described above with respect to the medical observation systems according to the first to fourth embodiments of the present disclosure may be read as &#x201c;means&#x201d; or &#x201c;circuits&#x201d;. For example, the control unit may be read as a control means or a control circuit.</p><p id="p-0265" num="0264">In the description of the flowcharts in this specification, the context of the processing among the steps is disclosed by use of expressions, such as &#x201c;firstly&#x201d;, &#x201c;thereafter&#x201d;, and &#x201c;subsequently&#x201d;, but sequences in the processing needed for implementation of the disclosure are not uniquely defined by these expressions. That is, the sequences in the processing in the flowcharts described in this specification may be modified as far as no contradiction arises from the modification.</p><p id="p-0266" num="0265">Some of embodiments of the present application have been described hereinbefore in detail on the basis of the drawings, but these are just examples. The disclosure may be implemented in various other modes modified or improved on the basis of the modes described through the present disclosure and knowledge of those skilled in the art.</p><p id="p-0267" num="0266">The present disclosure achieves an effect of enabling both narrow band light observation and fluorescence observation by means of a single imaging element.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A medical observation system, comprising:<claim-text>a light source configured to emit, to body tissue, at least one of:<claim-text>first narrow band light having a wavelength band narrower than a wavelength band of white light; and</claim-text><claim-text>second narrow band light that has a wavelength band shorter than the wavelength band of the first narrow band light and causes excitation of an advanced glycation end product produced by performing a heat treatment on the body tissue;</claim-text></claim-text><claim-text>an imaging element that includes:<claim-text>a pixel portion including plural pixels arranged in a two-dimensional matrix; and</claim-text><claim-text>a color filter including red filters, green filters, and blue filters that are provided on light receiving surfaces of the plural pixels, each of the light receiving surfaces including any one filter of the red, green, and blue filters on each of the light receiving surfaces, the imaging element being configured to generate image data by imaging at least one of returned light from the body tissue and fluorescence from the advanced glycation end product; and</claim-text></claim-text><claim-text>a cut filter that is provided on a light receiving surface side of at least the pixels provided with the green filters, the cut filter being configured to shield light of a shorter wavelength band including the wavelength band of the second narrow band light, and transmit therethrough the first narrow band light.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The medical observation system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>a processor comprising hardware, the processor being configured to<claim-text>generate a narrow band light image to output a display based on first blue component signals from the pixels where the blue filters are arranged and on first green component signals from the pixels where the green filters are arranged, the first blue component signals and the first green component signals being included in the image data when the first narrow band light and the second narrow band light have been emitted to the body tissue from the light source; and</claim-text><claim-text>generate a heat treatment image to output the display based on second blue component signals from the pixels where the blue filters are arranged and on second green component signals from the pixels where the green filters are arranged, the second blue component signals and the second green component signals being included in the image data when only the second narrow band light has been emitted to the advanced glycation end product from the light source.</claim-text></claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The medical observation system according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the processor is configured to make gains for the second blue component signals smaller than gains for the second green component signals when only the second narrow band light has been emitted to the advanced glycation end product from the light source.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The medical observation system according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the processor is configured to adjust gains for the second blue component signals and gains for the second green component signals such that a ratio between the second blue component signals and the second green component signals becomes constant when only the second narrow band light has been emitted to the advanced glycation end product from the light source.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The medical observation system according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the light source is further configured to emit white light, and</claim-text><claim-text>the processor is configured to adjust white balance to generate a white image such that a ratio of values of a red component signal, a green component signal, and a blue component signal included in the image data when the white light has been emitted to the body tissue from the light source becomes constant.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The medical observation system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the fluorescence has a wavelength band of 500 nm to 640 nm.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The medical observation system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the first narrow band light has a wavelength band of 530 nm to 550 nm,</claim-text><claim-text>the second narrow band light has a wavelength band of 390 nm to 430 nm, and</claim-text><claim-text>the cut filter is configured to shield light having a wavelength shorter than 430 nm.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The medical observation system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the advanced glycation end product is generated by the heat treatment by an energy device.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The medical observation system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>an insertion portion configured to be inserted into a subject, the insertion portion including an optical system configured to condense the returned light and the fluorescence; and</claim-text><claim-text>a medical imaging device where the insertion portion is attachable to and detachable from, the medical imaging device including the imaging element and the cut filter.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The medical observation system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>an endoscope including an insertion portion including a distal end portion configured to be inserted into a subject; and</claim-text><claim-text>a medical imaging device provided in the distal end portion, the medical imaging device including the imaging element and the cut filter.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The medical observation system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>a medical imaging device;</claim-text><claim-text>a support configured to support the medical imaging device rotatably; and</claim-text><claim-text>a base configured to hold a proximal end portion of the support rotatably, the base being configured to move on a floor surface,</claim-text><claim-text>the medical imaging device including the imaging element and the cut filter.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A medical observation system equipped with a narrow band light observation mode and a heat treatment observation mode, the medical observation system comprising:<claim-text>a light source configured to illuminate body tissue with:<claim-text>blue light that is to illuminate the body tissue in the narrow band light observation mode, is highly absorbed by hemoglobin in blood, and is easily reflected by a mucosal surface layer; and</claim-text><claim-text>blue light that is to illuminate the body tissue in the heat treatment observation mode and excites an advanced glycation end product generated by performing a heat treatment on the body tissue;</claim-text></claim-text><claim-text>an imaging element to be commonly used in the narrow band light observation mode and the heat treatment observation mode, the imaging element including:<claim-text>a pixel portion including plural pixels arranged in a two-dimensional matrix; and</claim-text><claim-text>a color filter including red filters, green filters, and blue filters that are provided on light receiving surfaces of the plural pixels, each of the light receiving surfaces including any one filter of the red, green, and blue filters on each of the light receiving surfaces, the imaging element being configured to generate image data by imaging at least one of returned light from the body tissue and fluorescence from the advanced glycation end product; and</claim-text></claim-text><claim-text>a cut filter that is provided on a light receiving surface side of at least the pixels provided with the green filters, the cut filter being configured to shield light of a wavelength band including a wavelength band of the fluorescence, and transmit therethrough the blue light.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The medical observation system according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the blue light is generated from a single light source portion.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The medical observation system according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising:<claim-text>a processor comprising hardware, the processor being configured to<claim-text>generate a narrow band light image to output a display based on first blue component signals from the pixels where the blue filters arranged, the first blue component signals being included in the image data when the blue light has been emitted to the body tissue from the light source in the narrow band light observation mode; and</claim-text><claim-text>generate a heat treatment image to output the display based on second blue component signals from the pixels where the blue filters are arranged and on green component signals from the pixels where the green filters are arranged, the second blue component signals and the green component signals being included in the image data when only the blue light has been emitted to the advanced glycation end product from the light source in the heat treatment observation mode.</claim-text></claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A medical imaging device, comprising:<claim-text>an imaging element including:<claim-text>a pixel portion including plural pixels arranged in a two-dimensional matrix; and</claim-text><claim-text>a color filter including red filters, green filters, and blue filters that are provided on light receiving surfaces of the plural pixels, each of the light receiving surfaces including any one filter of the red, green, and blue filters on each of the light receiving surfaces; and</claim-text></claim-text><claim-text>a cut filter provided on a light receiving surface side of at least the pixels provided with the green filters,</claim-text><claim-text>the imaging element being configured to generate image data by imaging at least one of:<claim-text>returned light from body tissue when first narrow band light having a wavelength band narrower than a wavelength band of white light has been emitted to the body tissue; and</claim-text><claim-text>fluorescence from an advanced glycation end product generated by performing a heat treatment on the body tissue when second narrow band light that excites the advanced glycation end product has been emitted to the advanced glycation end product, the second narrow band light having a wavelength band shorter than the wavelength band of the first narrow band light, and</claim-text></claim-text><claim-text>the cut filter being configured to shield light having a shorter wavelength band including a wavelength band of the second narrow band light and transmit therethrough the first narrow band light.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A medical imaging device, comprising:<claim-text>an imaging element including:<claim-text>a pixel portion including plural pixels arranged in a two-dimensional matrix; and</claim-text><claim-text>a color filter including red filters, green filters, and blue filters that are provided on light receiving surfaces of the plural pixels, each of the light receiving surfaces including any one filter of the red, green, and blue filters on each of the light receiving surfaces,</claim-text></claim-text><claim-text>the imaging element being configured to generate image data by imaging at least one of:<claim-text>returned light from body tissue when first narrow band light having a wavelength band narrower than a wavelength band of white light has been emitted to the body tissue; and</claim-text><claim-text>fluorescence from an advanced glycation end product generated by performing a heat treatment on the body tissue when second narrow band light that excites the advanced glycation end product has been emitted to the advanced glycation end product, the second narrow band light having a wavelength band shorter than the wavelength band of the first narrow band light, and</claim-text></claim-text><claim-text>the green filters being configured to shield light having a shorter wavelength band including the wavelength band of the second narrow band light and transmit therethrough the first narrow band light.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. An imaging method, comprising:<claim-text>emitting, by a light source, narrow band light to excite an advanced glycation end product, to body tissue,</claim-text><claim-text>capturing, by blue pixels of an imaging element, an image of first light of: returned light from the body tissue; and fluorescence from the advanced glycation end product, the first light having passed through blue filters configured to mainly transmit therethrough light of a blue wavelength band, and</claim-text><claim-text>capturing, by green pixels of the imaging element, an image of second light of: the returned light from the body tissue; and the fluorescence from the advanced glycation end product, the second light having passed through a cut filter to shield light shorter in wavelength than the fluorescence and having passed through green filters configured to mainly transmit therethrough light of a green wavelength band.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005567A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005567</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17784576</doc-number><date>20201211</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>B</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>B</subclass><main-group>30</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20190201</date></cpc-version-indicator><section>G</section><class>16</class><subclass>B</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190201</date></cpc-version-indicator><section>G</section><class>16</class><subclass>B</subclass><main-group>30</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">GENERATING PROTEIN SEQUENCES USING MACHINE LEARNING TECHNIQUES BASED ON TEMPLATE PROTEIN SEQUENCES</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>62947430</doc-number><date>20191212</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Just- Evotec Biologics, Inc.</orgname><address><city>Seattle</city><state>WA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Shaver et al.</last-name><first-name>Jeremy Martin</first-name><address><city>Lake Forest Park</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Amimeur</last-name><first-name>Tileli</first-name><address><city>Seattle</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Ketchem</last-name><first-name>Randal Robert</first-name><address><city>Snohomish</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Taylor</last-name><first-name>Alex</first-name><address><city>Bellevue</city><state>WA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/US2020/064579</doc-number><date>20201211</date></document-id><us-371c12-date><date>20220610</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Systems and techniques are described to generate amino acid sequences of target proteins based on amino acid sequences of template proteins using machine learning techniques. The amino acid sequences of the target proteins can be generated based on data that constrains the modifications that can be made to the amino acid sequences of the template proteins. In illustrative examples, the template proteins can include antibodies produced by a non-human mammal that bind to an antigen and the target proteins can correspond to human antibodies with a region having at least a threshold amount of identity with the binding region of the template antibody. Generative adversarial networks can be used to produce the amino acid sequences of the target proteins.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="108.20mm" wi="158.75mm" file="US20230005567A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="202.78mm" wi="148.34mm" orientation="landscape" file="US20230005567A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="211.92mm" wi="157.31mm" orientation="landscape" file="US20230005567A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="218.61mm" wi="153.67mm" file="US20230005567A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="215.90mm" wi="157.31mm" orientation="landscape" file="US20230005567A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="206.93mm" wi="157.31mm" orientation="landscape" file="US20230005567A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="214.38mm" wi="141.22mm" file="US20230005567A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="214.38mm" wi="141.14mm" file="US20230005567A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="216.41mm" wi="146.90mm" file="US20230005567A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">Proteins are biological molecules that are comprised of one or more chains of amino acids. Proteins can have various functions within an organism. For example, some proteins can be involved in causing a reaction to take place within an organism. In other examples, proteins can transport molecules throughout the organism. In still other examples, proteins can be involved in the replication of genes. Additionally, some proteins can have therapeutic properties and can be used to treat various biological conditions. The structure and function of proteins are based on the arrangement of amino acids that comprise the proteins. The arrangement of amino acids for proteins can be represented by a sequence of letters with each letter corresponding to an amino acid at a certain position of the protein. The arrangement of amino acids for proteins can also be represented by three dimensional structures that not only indicate the amino acids at certain positions of the protein, but also indicate three dimensional features of the proteins, such as an &#x3b1;-helix or a &#x3b2;-sheet.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0002" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0003" num="0002">The present disclosure is illustrated by way of example and not limitation in the figures of the accompanying drawings, in which like references indicate similar elements.</p><p id="p-0004" num="0003"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example framework to generate target protein sequences using machine learning techniques based on template protein sequences, in accordance with some implementations.</p><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example framework to utilize transfer learning techniques to generate protein sequences having specified characteristics, in accordance with some implementations.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example framework to generate target protein sequences using a generative adversarial network based on a template protein sequence and constraint data related to modifications of positions of the template sequence, in accordance with some implementations.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating an example framework to utilize data indicating an antibody sequence of a first organism having specified functionality to generate data corresponding to additional antibody sequences having the specified functionality for a second, different organism, in accordance with some implementations.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating an example framework to generate target protein sequences using machine learning techniques by combining protein fragment sequences with template protein sequences, in accordance with some implementations.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow diagram illustrating an example method for producing target protein sequences using template protein sequences and position modification data, in accordance with some implementations.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flow diagram illustrating an example method for producing target protein sequences using a generative adversarial network based on template protein sequences, in accordance with some implementations.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a diagrammatic representation of a machine in the form of a computer system within which a set of instructions may be executed for causing the machine to perform any one or more of the methodologies discussed herein, according to an example embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0003" level="1">DETAILED DESCRIPTION</heading><p id="p-0012" num="0011">Proteins can have many beneficial uses within organisms. For example, proteins can be used to treat diseases and other biological conditions that can detrimentally impact the health of humans and other mammals. In various scenarios, proteins can participate in reactions that are beneficial to subjects and that can counteract one or more biological conditions being experienced by the subjects. In some examples, proteins can also bind to molecules within an organism that may be detrimental to the health of a subject. In various situations, the binding of proteins to potentially harmful molecules can result in activation of the immune system of a subject to neutralize the potential effects of the molecules. For these reasons, many individuals and organizations have sought to develop proteins that may have therapeutic benefits.</p><p id="p-0013" num="0012">The development of proteins for use in treating biological conditions can be a time consuming and resource intensive process. Often, candidate proteins for development can be identified as potentially having desired biophysical properties, three-dimensional (3D) structures, and/or behavior within an organism. In order to determine whether the candidate proteins actually have the desired characteristics, the proteins can be physically synthesized and then tested to determine whether the actual characteristics of the synthesized proteins correspond to the desired characteristics. Due to the amount of resources needed to synthesize and test proteins for specified biophysical properties, 3D structures, and/or behaviors, the number of candidate proteins synthesized for therapeutic purposes is limited. In some situations, the number of proteins synthesized for therapeutic purposes can be limited by the loss of resources that takes place when candidate proteins are synthesized and do not have the desired characteristics.</p><p id="p-0014" num="0013">The use of computer-implemented techniques to identify candidate proteins that have particular characteristics has increased. These conventional techniques, however, can be limited in their scope and accuracy. In various situations, conventional computer-implemented techniques to generate protein sequences can be limited by the amount of data available and/or the types of data available that may be needed by those conventional techniques to accurately generate protein sequences with specified characteristics. Additionally, the techniques utilized to produce models that can generate protein sequences with particular characteristics can be complex and the know-how needed to produce models that are accurate and efficient can be complex and difficult to implement. The length of the protein sequences produced by conventional models can also be limited because the accuracy of conventional techniques can decrease as the lengths of the proteins increases and because the computing resources used to generate large numbers of protein sequences, such as hundreds, thousands, up to millions of protein sequences, having a relatively large number of amino acids (e.g., 50-1000) can become prohibitive. Thus, the number of proteins generated by conventional computational techniques is limited.</p><p id="p-0015" num="0014">Further, although proteins produced by one organism or type of organism can have functionality that may be beneficial to a number of organisms, in various scenarios, the same proteins can be rejected by the immune system of another organism or type of organism and obviate the beneficial functionality of the proteins. The techniques and systems described herein can be used to generate amino acid sequences of target molecules based on amino acid sequences of template molecules. The template molecules can exhibit a functionality that can be beneficial for a number of different organisms besides the original host that produced the template molecules. The target molecules can also exhibit the functionality of the template molecules, while minimizing the possibility of rejection by an organism that is different from the original host.</p><p id="p-0016" num="0015">For example, the portions of the amino acid sequence of a template protein that are attributed to a functionality of the template protein within a host organism can be preserved, while additional portions of the amino acid sequence of the template protein can be modified to minimize the possibility of rejection by another organism. To illustrate, a template antibody produced in a mouse can effectively bind to an antigen that is found in both mice and humans. The binding of the template antibody to the antigen can be attributed to one or more binding regions of the template antibody. The techniques and systems described herein can generate data corresponding to a number of amino acid sequences for target antibodies that include the binding regions of the template antibody and that also include additional regions that have been modified from the template antibody that correspond to amino acid sequences included in human antibodies. In this way, the techniques and systems described herein can produce an antibody with a human framework in conjunction with binding regions for a specific antigen, where the binding regions for the antigen may not be present in known human antibodies. Accordingly, biological conditions that may not have been responsive to known human antibodies can be treated using antibodies with amino acid sequences generated from the techniques and systems described herein.</p><p id="p-0017" num="0016">Machine learning techniques can be used to generate the target protein amino acid sequences from the template protein amino acid sequences. In illustrative examples, generative adversarial networks can be used to generate the target protein amino acid sequences. The generative adversarial networks can be trained using target protein amino acid sequences in relation to template protein amino acid sequences and position modification data. The position modification data can indicate, for individual positions of a template protein amino acid sequence, a likelihood that the amino acid can be modified to a different amino acid. In various implementations, the position modification data can correspond to a penalty applied by the generative adversarial network in response to modification of an individual amino acid. For example, a position of a template protein amino acid sequence having a relatively high penalty for being modified can be less likely to be modified by the generative adversarial network, while another position of the template protein amino acid sequence having a relatively low penalty for being modified can be more likely to be modified by the generative adversarial network. In various examples, transfer learning techniques can also be applied to produce target antibodies having one or more biophysical properties.</p><p id="p-0018" num="0017">The position modification data can be based on the location of the amino acids in the template protein sequence. Amino acids located in regions of the template protein associated with a desired functionality can have a relatively high penalty for being modified, while amino acids located in other regions of a template protein can have relatively moderate or relatively low penalties for being modified. In situations where a target protein corresponds to a different organism than a host organism that produces the template protein, the positions of the template protein associated with relatively low penalties for being modified can be the most likely to be changed to correspond to a framework for the organism related to the target protein. Additionally, in scenarios where the target protein is derived from a germline gene that is different from the germline gene of the host that produces the template protein, the positions of the template protein associated with relatively low penalties for being modified can be the most likely to be changed to correspond to a protein produced from the target protein germline gene. As used herein, germline, can correspond to amino acid sequences of proteins that are conserved when cells of the proteins replicate. An amino acid sequence can be conserved from a parent cell to a progeny cell when the amino acid sequence of the progeny cell has at least a threshold amount of identity with respect to the corresponding amino acid sequence in the parent cell. In an illustrative example, a portion of an amino acid sequence of a human antibody that is part of a kappa light chain that is conserved from a parent cell to a progeny cell can be a germline portion of the antibody.</p><p id="p-0019" num="0018">In illustrative examples, an antibody produced in mice can bind to an antigen that is found in both mice and humans. The binding of the antibody to the antigen can be based on amino acids located in the complementarity-determining regions (CDRs) of the antibody. In this scenario, the position modification data can indicate relatively high penalties for changing amino acids located in the CDRs of the template mouse antibody. The position modification data can also indicate lower penalties for the modification of amino acids located in the constant domains and other portions of the variable domains of the template mouse antibody. Thus, the generative adversarial networks described herein can generate target human antibody amino acid sequences that preserve most or all of the residues of the mouse antibody that participate in binding the antigen, while changing constant domains and/or other parts of the variable domains of the heavy chains and/or light chains of the mouse antibody to correspond to the heavy chains and light chains of human antibodies. The generative adversarial networks described herein can also be trained using human antibodies in order to determine the characteristics of human antibodies and identify changes to the template mouse antibody that can be made to produce a humanized target antibody for the antigen.</p><p id="p-0020" num="0019">By implementing the techniques and systems described herein, target protein amino acid sequences can be generated based on one or more template proteins amino acid sequences that can preserve at least some functionality of the template proteins, while utilizing a different supporting framework for the portions of the template proteins that are attributed to the functionality The computational and machine learning techniques described herein can efficiently generate target protein amino acid sequences, while minimizing the probability that the target proteins will lose functionality of the template proteins. The techniques and systems described herein can also minimize the probability that the target proteins will be rejected by an organism that is different from the host organism that produced the template proteins. For example, the use of position modification data can decrease the amount of computing resources utilized in generating target protein sequences by constraining the number of changes that can be made by a computational model to the template protein sequences, while allowing for flexibility in portions of the template sequences that are less constrained to coincide with features of target proteins related to the new host organism. In various examples, the techniques and systems described herein can analyze thousands up to millions of amino acid sequences of proteins to accurately generate amino acid sequences of new proteins that both preserve the functionality of template proteins while also minimizing the probability of the new proteins being rejected by a new host organism.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example framework <b>100</b> to generate target protein sequences using machine learning techniques based on template protein sequences, in accordance with some implementations. For example, a machine learning architecture <b>102</b> can obtain an amino acid sequence of a template protein <b>104</b> and generate an amino acid sequence of a target protein <b>106</b>. The template protein <b>104</b> can include a region <b>108</b> that has a functionality and the machine learning architecture <b>102</b> can generate the target protein <b>106</b> such that the target protein <b>106</b> also includes the region <b>108</b>. In various implementations, target proteins include a region having at least a threshold amount of identity with the region <b>108</b>. In this way, the target protein <b>106</b> can retain the functionality of the template protein <b>104</b>. To illustrate, the machine learning architecture <b>102</b> can generate the target protein <b>106</b> to maximize a probability that the target protein <b>106</b> retains the functionality attributed to the region <b>108</b> by preserving at least a threshold amount of the region <b>108</b> and/or preserving amino acids at various locations of the region <b>108</b>.</p><p id="p-0022" num="0021">In illustrative examples, an amount of sequence identity between the region <b>108</b> of the template protein <b>104</b> and a portion of a target protein <b>106</b> can indicate that at least a portion of the region <b>108</b> of the template protein <b>104</b> and the portion of the target protein <b>106</b> have the same nucleotide at a number of positions. An amount of identity between at least a portion of the region <b>108</b> of the template protein <b>104</b> and a portion of the target protein <b>106</b> can be determined using a Basic Local Alignment Search Tool (BLAST).</p><p id="p-0023" num="0022">Additional portions of the target protein <b>106</b> can have different amino acid sequences in relation to portions of the template protein <b>104</b>. The regions of the target protein <b>106</b> that have different amino acid sequences in relation to portions of the template protein <b>104</b> can also have one or more different secondary structures in relation to the secondary structures of the template protein <b>104</b>. The differences between the amino acid sequences of regions of the template protein <b>104</b> and the regions of the target protein <b>106</b> can also result in different tertiary structures for the template protein <b>104</b> and the target protein <b>106</b>. In the illustrative example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the template protein <b>104</b> can include a region <b>110</b> that has a different amino acid sequence from a region <b>112</b> of the target protein <b>106</b>. Further, the template protein <b>104</b> can include a region <b>114</b> that has a different amino acid sequence from a region <b>116</b> of the target protein <b>106</b>.</p><p id="p-0024" num="0023">The machine learning architecture <b>102</b> can modify regions of the template protein <b>104</b> to produce the amino acid sequence of the target protein <b>106</b> such that portions of the amino acid sequence of the target protein <b>106</b> correspond to proteins produced by a different organism than the organism that produced the template protein <b>104</b>. For example, the template protein <b>104</b> can be produced by one mammal and the target protein <b>106</b> can be produced by a different mammal. To illustrate, the template protein <b>104</b> can be produced by mice and the target protein <b>106</b> can correspond to proteins produced by humans. In additional examples, the template protein <b>104</b> can correspond to a protein produced in relation to a first germline gene and the target protein <b>106</b> can correspond to a protein produced in relation to a second germline gene. In situations where the template protein <b>104</b> and the target protein <b>106</b> are antibodies, the template protein <b>104</b> can have an amino acid sequence that corresponds to a first antibody isotype (e.g., immunoglobin E (IgE)) and the target protein <b>106</b> can have an amino acid sequence that corresponds to a second antibody isotype (e.g., IgG).</p><p id="p-0025" num="0024">The machine learning architecture <b>102</b> can include a generating component <b>118</b> and a challenging component <b>120</b>. The generating component <b>118</b> can implement one or more models to generate amino acid sequences based on input provided to the generating component <b>118</b>. In various implementations, the one or more models implemented by the generating component <b>118</b> can include one or more functions. The challenging component <b>120</b> can generate output indicating whether the amino acid sequences produced by the generating component <b>118</b> satisfy various characteristics. The output produced by the challenging component <b>120</b> can be provided to the generating component <b>118</b> and the one or more models implemented by the generating component <b>118</b> can be modified based on the feedback provided by the challenging component <b>120</b>. The challenging component <b>120</b> can compare the amino acid sequences produced by the generating component <b>118</b> with amino acid sequences of a library of target proteins and generate an output indicating an amount of correspondence between the amino acid sequences produced by the generating component <b>118</b> and the amino acid sequences of target proteins provided to the challenging component <b>120</b>.</p><p id="p-0026" num="0025">In various implementations, the machine learning architecture <b>102</b> can implement one or more neural network technologies. For example, the machine learning architecture <b>102</b> can implement one or more recurrent neural networks. Additionally, the machine learning architecture <b>102</b> can implement one or more convolution neural networks. In certain implementations, the machine learning architecture <b>102</b> can implement a combination of recurrent neural networks and convolutional neural networks. In examples, the machine learning architecture <b>102</b> can include a generative adversarial network (GAN). In these situations, the generating component <b>118</b> can include a generator and the challenging component <b>120</b> can include a discriminator. In additional implementations, the machine learning architecture <b>102</b> can include a conditional generative adversarial network (cGAN).</p><p id="p-0027" num="0026">In the illustrative example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, data can be provided to the generating component <b>118</b> and the generating component <b>118</b> can utilize the data and one or more models to produce generated sequences <b>122</b>. The generated sequences <b>122</b> can include amino acid sequences that are represented by a series of letters with each letter indicating an amino acid located at a respective position of a protein. The data provided to the generating component <b>118</b> to produce the generated sequences <b>122</b> can include input data <b>124</b>. The input data <b>124</b> can include noise that is produced by a random number generator or noise produced by a pseudo-random number generator. In addition, the data provided to the generating component <b>118</b> to produce the generated sequences <b>122</b> can include one or more template protein sequences <b>126</b>. A template protein sequence <b>126</b> can include an amino acid sequence of a protein that has one or more characteristics that are desirable to include in proteins that are different from a template protein, such as the template protein <b>104</b>. In illustrative examples, the template protein sequences <b>126</b> can correspond to antibodies that bind to a specified antigen. In additional examples, the template protein sequences <b>126</b> can correspond to proteins that transport one or more metals through a body of a mammal.</p><p id="p-0028" num="0027">Additionally, position modification data <b>128</b> can be provided to the generating component <b>118</b> to be used by the generating component <b>118</b> to produce the generated sequences <b>122</b>. The position modification data <b>128</b> can indicate one or more criteria related to the modification of amino acids of the one or more template protein sequences <b>126</b>. For example, the position modification data <b>128</b> can indicate one or more criteria corresponding to the modification of individual amino acids of the one or more template protein sequences <b>126</b>. To illustrate, the position modification data <b>128</b> can indicate respective probabilities that amino acids at individual positions of a template protein sequence <b>126</b> can be modified. In additional implementations, the position modification data <b>128</b> can indicate a penalty associated with the modification of amino acids at individual positions of a template protein sequence <b>126</b>. The position modification data <b>128</b> can include values or functions corresponding to the respective amino acids located at individual positions of a template protein sequence <b>126</b>.</p><p id="p-0029" num="0028">In illustrative examples, the position modification data <b>128</b> can include criteria that reduce the probability of amino acids being modified at positions of a template protein that correspond to functionality of the template protein that is to be preserved in a target protein. For example, a penalty associated with modifying an amino acid located in a region that is attributed to functionality of a template protein can be relatively high. Additionally, the position modification data <b>128</b> can include criteria for amino acids outside of one or more regions that are attributed to functionality of a template protein that indicate increased or neutral probabilities for modification of those amino acids. To illustrate, a penalty associated with modifying an amino acid located at a position outside of a region attributed to particular functionality of a protein can be relatively low or neutral. Further, the position modification data <b>128</b> can indicate probabilities of changing amino acids at positions of a template protein to different types of amino acids. In illustrative examples, an amino acid located at a position of a template protein can have a first penalty for being changed to a first type of amino acid and a second, different penalty for being changed to a second type of amino acid. That is, in various implementations, a hydrophobic amino acid of a template protein can have a first penalty for being changed to another hydrophobic amino acid and a second, different penalty for being changed to a positively charged amino acid.</p><p id="p-0030" num="0029">In one or more examples, the position modification data <b>128</b> can be determined, at least in part, based on input obtained via a computing device. For example, a user interface can be generated that includes one or more user interface elements to capture at least a portion of the position modification data <b>128</b>. In addition, a data file can be obtained over a communication interface that includes at least a portion of the position modification data <b>128</b>. Further, the position modification data <b>128</b> can be computed by analyzing a number of amino acid sequences to determine numbers of occurrences of different amino acids at one or more positions of the proteins. Occurrences of amino acids at positions of proteins, including template proteins and target proteins, can be used to determine probabilities of modifications of amino acids that are indicated in the position modification data <b>128</b>. In various examples, biophysical properties and/or structural properties of proteins can be analyzed in conjunction with the placement of amino acids at one or more positions of template proteins and target proteins to determine probabilities included in the position modification data <b>128</b> for modifying amino acids at one or more positions of template proteins to generate target proteins.</p><p id="p-0031" num="0030">The generated sequence(s) <b>122</b> can be compared by the challenging component <b>120</b> against sequences of proteins included in target protein sequence data <b>130</b>. The target protein sequence data <b>130</b> can be training data for the machine learning architecture <b>102</b>. The target protein sequence data <b>130</b> can be encoded according to a schema. A schema applied to amino acid sequences included in the target protein sequence data <b>130</b> can be based on a classification of the amino acid sequences. For example, an antibody can be stored according to a first classification, a signaling protein can be stored according to a second classification, and a transport protein can be stored according to a third classification.</p><p id="p-0032" num="0031">The target protein sequence data <b>130</b> can include sequences of proteins obtained from one or more data sources that store amino acid sequences of proteins. The one or more data sources can include one or more websites that are searched and information corresponding to amino acid sequences of target proteins can be extracted from the one or more websites. Additionally, the one or more data sources can include electronic versions of research documents from which amino acid sequences of target proteins can be extracted.</p><p id="p-0033" num="0032">In illustrative examples, the target protein sequence data <b>130</b> can include amino acid sequences of proteins that are produced by an organism that is different from an organism that produces the template protein sequences <b>126</b>. For example, the target protein sequence data <b>130</b> can include amino acid sequences of human proteins and the one or more template protein sequences <b>126</b> can correspond to one or more proteins produced by mice or chickens. In additional examples, the target protein sequence data <b>130</b> can include amino acid sequences of horse proteins and the one or more template protein sequences <b>126</b> can correspond to one or more proteins produced by humans. In various examples, the amino acid sequences included in the target protein sequence data <b>130</b> can have one or more characteristics and/or functions. To illustrate, the amino acid sequences included in the target protein sequence data <b>130</b> can correspond to human enzymes used in the metabolism of various foods consumed by humans. In further examples, the amino acid sequences included in the target protein sequence data <b>130</b> can correspond to human antibodies.</p><p id="p-0034" num="0033">The template protein sequences <b>126</b>, the position modification data <b>128</b>, the target protein sequence data <b>130</b>, or combinations thereof, can be stored in one or more data stores that are accessible to the machine learning architecture <b>102</b>. The one or more data stores can be connected to the machine learning architecture <b>102</b> via a wireless network, a wired network, or combinations thereof. The template protein sequences <b>126</b>, the position modification data <b>128</b>, the target protein sequence data <b>130</b>, or combinations thereof, can be obtained by the machine learning architecture <b>102</b> based on requests sent to the data stores to retrieve one or more portions of at least one of the template protein sequences <b>126</b>, the position modification data <b>128</b>, or the target protein sequence data <b>130</b>.</p><p id="p-0035" num="0034">The challenging component <b>120</b> can generate output indicating whether the amino acid sequences produced by the generating component <b>118</b> satisfy various characteristics. In one or more implementations, the challenging component <b>120</b> can be a discriminator. In additional situations, such as when the machine learning architecture <b>102</b> includes a Wasserstein GAN, the challenging component <b>120</b> can include a critic.</p><p id="p-0036" num="0035">In illustrative examples, based on similarities and differences between the generated sequence(s) <b>122</b> and additional sequences provided to the challenging component <b>120</b>, such as amino acid sequences included in the target protein sequence data <b>130</b>, the challenging component <b>120</b> can generate the classification output <b>132</b> to indicate an amount of similarity or an amount of difference between the generated sequence(s) <b>122</b> and sequences provided to the challenging component <b>120</b> that are included in the target protein sequence data <b>130</b>. Additionally, the classification output <b>132</b> can indicate an amount of similarity or an amount of difference between the generated sequence(s) <b>122</b> and the template protein sequences <b>126</b>.</p><p id="p-0037" num="0036">In one or more examples, the challenging component <b>120</b> can label the generated sequence(s) <b>122</b> as zero and the encoded sequences obtained from the target protein sequence data <b>130</b> as 1. In these situations, the classification output <b>132</b> can include a first number from 0 to 1 with respect to one or more amino acid sequences included in the target protein sequence data <b>130</b>. Additionally, the challenging component <b>120</b> can label the generated sequences <b>122</b> as zero and the template protein sequences <b>126</b> as 1. Accordingly, the challenging component <b>120</b> can generate another number from 0 to 1 with respect to the template protein sequences <b>126</b>.</p><p id="p-0038" num="0037">In additional examples, the challenging component <b>120</b> can implement a distance function that produces an output that indicates an amount of distance between the generated sequence(s) <b>120</b> and the proteins included in the target protein sequence data <b>130</b>. Further, the challenging component <b>120</b> can implement a distance function that produces an output that indicates an amount of distance between the generated sequence(s) <b>122</b> and the template protein sequence(s) <b>126</b>. In implementations where the challenging component <b>120</b> implements a distance function, the classification output <b>132</b> can include a number from &#x2212;&#x221e; to &#x221e; indicating a distance between the generated sequence(s) <b>122</b> and one or more sequences included in the target protein sequence data <b>130</b>. The challenging component <b>120</b> can also implement a distance function and generate a classification output <b>132</b> including an additional number from &#x2212;&#x221e; to &#x221e; indicating a distance between the generated sequence(s) <b>122</b> and the template protein sequences <b>126</b>.</p><p id="p-0039" num="0038">The amino acid sequences included in the target protein sequence data <b>130</b> can be subject to data preprocessing <b>134</b> before being provided to the challenging component <b>120</b>. For example, the target protein sequence data <b>130</b> can be arranged according to a classification system before being provided to the challenging component <b>120</b>. The data preprocessing <b>134</b> can include pairing amino acids included in the target proteins of the target protein sequence data <b>130</b> with numerical values that can represent structure-based positions within the proteins. The numerical values can include a sequence of numbers having a starting point and an ending point. In an illustrative example, a T can be paired with the number 43 indicating that a Threonine molecule is located at a structure-based position 43 of a specified protein domain type. In illustrative examples, structure-based numbering can be applied to any general protein type, such as fibronectin type III (FNIII) proteins, avimers, antibodies, VHH domains, kinases, zinc fingers, T-cell receptors, and the like.</p><p id="p-0040" num="0039">In various implementations, the classification system implemented by the data preprocessing <b>134</b> can include a numbering system that encodes structural position for amino acids located at respective positions of proteins. In this way, proteins having different numbers of amino acids can be aligned according to structural features. For example, the classification system can designate that portions of proteins having particular functions and/or characteristics can have a specified number of positions. In various situations, not all of the positions included in the classification system may be associated with an amino acid because the number of amino acids in a particular region of a protein may vary between proteins. In additional examples, the structure of a protein can be reflected in the classification system. To illustrate, positions of the classification system that are not associated with a respective amino acid can indicate various structural features of a protein, such as a turn or a loop. In an illustrative example, a classification system for antibodies can indicate that heavy chain regions, light chain regions, and hinge regions have a specified number of positions assigned to them and the amino acids of the antibodies can be assigned to the positions according to the classification system. In one or more implementations, the data preprocessing <b>134</b> can use Antibody Structural Numbering (ASN) to classify individual amino acids located at respective positions of an antibody.</p><p id="p-0041" num="0040">The data used to train the machine learning architecture <b>102</b> can impact the amino acid sequences produced by the generating component <b>118</b>. For example, in situations where human antibodies are included in the protein sequence data <b>130</b> provided to the challenging component <b>120</b>, the amino acid sequences generated by the generating component <b>118</b> can correspond to human antibody amino acid sequences. In another example, in scenarios where the amino acid sequences included in the target protein sequence data <b>130</b> provided to the challenging component <b>120</b> correspond to proteins produced from a germline gene, the amino acid sequences produced by the generating component <b>118</b> can correspond to proteins produced from the germline gene. Further, when the amino acid sequences included in the target protein sequence data <b>130</b> provided to the challenging component <b>120</b> correspond to antibodies of a specified isotype, the amino acid sequences produced by the generating component <b>118</b> can correspond to antibodies of the specified isotype.</p><p id="p-0042" num="0041">The output produced by the data preprocessing <b>134</b> can include encoded sequences <b>136</b>. The encoded sequences <b>136</b> can include a matrix indicating amino acids associated with various positions of a protein. In examples, the encoded sequences <b>136</b> can include a matrix having columns corresponding to different amino acids and rows that correspond to structure-based positions of proteins. For each element in the matrix, a 0 can be used to indicate the absence of an amino acid at the corresponding position and a 1 can be used to indicate the presence of an amino acid at the corresponding position. The matrix can also include an additional column that represents a gap in an amino acid sequence where there is no amino acid at a particular position of the amino acid sequence. Thus, in situations where a position represents a gap in an amino acid sequence, a 1 can be placed in the gap column with respect to the row associated with the position where an amino acid is absent. The generated sequence(s) <b>122</b> can also be represented using a vector according to a same or similar number scheme as used for the encoded sequences <b>136</b>. In some illustrative examples, the encoded sequences <b>136</b> and the generated sequence(s) <b>122</b> can be encoded using a method that may be referred to as a one-hot encoding method.</p><p id="p-0043" num="0042">After the machine learning architecture <b>102</b> has undergone a training process, a trained model <b>138</b> can be generated that can produce sequences of proteins. The trained model <b>138</b> can include the generating component <b>118</b> after a training process has been performed using the protein sequence data <b>130</b>. In illustrative examples, the trained model <b>138</b> include a number of weights and/or a number of parameters of a convolution neural network. The training process for the machine learning architecture <b>102</b> can be complete after the function(s) implemented by the generating component <b>118</b> and the function(s) implemented by the challenging component <b>120</b> converge. The convergence of a function can be based on the movement of values of model parameters toward particular values as protein sequences are generated by the generating component <b>118</b> and feedback is obtained from the challenging component <b>120</b>. In various implementations, the training of the machine learning architecture <b>102</b> can be complete when the protein sequences produced by the generating component <b>118</b> have particular characteristics. For example, the amino acid sequences generated by the generating component <b>118</b> can be analyzed by a software tool that determines at least one of biophysical properties of the amino acid sequences, structural features of the amino acid sequences, or adherence to amino acid sequences corresponding to one or more protein germlines The machine learning architecture <b>102</b> can produce the trained model <b>138</b> in situations where the amino acid sequences produced by the generating component <b>118</b> are determined by the software tool to have one or more specified characteristics. In various examples, a software tool used to evaluate the amino acid sequences produced by the generating component <b>118</b> can determine that the trained model <b>138</b> produces amino acid sequences that have preserved functionality of a template protein.</p><p id="p-0044" num="0043">Protein sequence input <b>140</b> can be provided to the trained model <b>138</b>, and the trained model <b>138</b> can produce generated protein sequences <b>142</b>. The protein sequence input <b>140</b> can include one or more template protein sequences, additional position constraint data, and an input vector that can include a random or pseudo-random series of numbers. In an illustrative example, the protein sequence input <b>140</b> can include one or more template protein sequences <b>126</b>. The generated protein sequences <b>142</b> produced by the trained model <b>138</b> can be represented as a matrix structure that is the same as or similar to the matrix structure used to represent the encoded sequences <b>136</b> and/or the generated sequence(s) <b>122</b>. In various implementations, the matrices produced by the trained model <b>138</b> that comprise the generated protein sequences <b>142</b> can be decoded to produce a string of amino acids that correspond to the sequence of a target protein. In illustrative examples, the protein sequence input <b>140</b> can include the amino acid sequence of the template protein <b>104</b> and position modification data indicating a relatively high probability that the amino acids located in the region <b>108</b> are to be preserved in order to preserve the functionality of the region <b>108</b>. The trained model <b>138</b> can then use the protein sequence input <b>140</b> to generate a number of amino acid sequences of target proteins, such as an amino acid sequence of the target protein <b>106</b>. In various examples, the trained model <b>138</b> can use the protein sequence input <b>140</b> to produce hundreds, up to thousands, and up to millions of protein sequences similar to the target protein <b>106</b> that correspond to the template protein <b>104</b>.</p><p id="p-0045" num="0044">Although not shown in the illustrative example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, additional processing can be performed with respect to the generated protein sequences <b>142</b>. For example, the generated protein sequences <b>142</b> can be evaluated to determine whether the generated protein sequences <b>142</b> have a specified set of characteristics. To illustrate, one or more metrics can be determined with respect to the target protein sequence(s) <b>142</b>. For example, metrics that can be determined with respect to the generated protein sequences <b>142</b> can be related to characteristics of the generated protein sequences <b>142</b>, such as a number of negatively charged amino acids, a number of positively charged amino acids, a number of amino acids interacting to form one or more polar regions, amino acids interacting to form one or more hydrophobic regions, one or more combinations thereof, and the like.</p><p id="p-0046" num="0045">The generated protein sequences <b>142</b> produced by the trained model <b>138</b> can correspond to various types of proteins. For example, the generated protein sequences <b>142</b> can correspond to proteins that function as T-cell receptors. In additional examples, the generated protein sequences <b>142</b> can correspond to proteins that function as catalysts to cause biochemical reactions within an organism to take place. The generated protein sequences <b>142</b> can also correspond to one or more types of antibodies. To illustrate, the generated protein sequences <b>142</b> can correspond to one or more antibody subtypes, such as immunoglobin A (IgA), immunoglobin D (IgD), immunoglobin E (IgE), immunoglobin G (IgG), or immunoglobin M (IgM). Further, the generated protein sequences <b>142</b> can correspond to additional proteins that bind antigens. In examples, the generated protein sequences <b>142</b> can correspond to affibodies, affilins, affimers, affitins, alphabodies, anticalins, avimers, monobodies, designed ankyrin repeat proteins (DARPins), nanoCLAMP (clostridal antibody mimetic proteins), antibody fragments, or combinations thereof. In still other examples, the generated protein sequences <b>142</b> can correspond to amino acid sequences that participate in protein-to-protein interactions, such as proteins that have regions that bind to antigens or regions that bind to other molecules.</p><p id="p-0047" num="0046">In some implementations, the generated protein sequences <b>142</b> can be subject to sequence filtering. The sequence filtering can parse the generated protein sequences <b>142</b> to identify one or more of the generated protein sequences <b>142</b> that correspond to one or more characteristics. For example, the generated protein sequences <b>142</b> can be analyzed to identify amino acid sequences that have specified amino acids at particular positions. One or more of the generated protein sequences <b>142</b> can also be filtered to identify amino acid sequences having one or more particular strings or regions of amino acids. In various implementations, the generated protein sequences <b>142</b> can be filtered to identify amino acid sequences that are associated with a set of biophysical properties based at least partly on similarities between at least one of the generated protein sequences <b>142</b> and amino acid sequences of additional proteins having the set of biophysical properties.</p><p id="p-0048" num="0047">The machine learning architecture <b>102</b> can be implemented by one or more computing devices <b>144</b>. The one or more computing devices <b>144</b> can include one or more server computing devices, one or more desktop computing devices, one or more laptop computing devices, one or more tablet computing devices, one or more mobile computing devices, or combinations thereof. In certain implementations, at least a portion of the one or more computing devices <b>144</b> can be implemented in a distributed computing environment. For example, at least a portion of the one or more computing devices <b>144</b> can be implemented in a cloud computing architecture. Additionally, although the illustrative example of <figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an implementation of the machine learning architecture <b>102</b> that includes a generative adversarial network with a single generating component and a single challenging component, in additional implementations, the machine learning architecture <b>102</b> can include multiple generative adversarial networks. Further, each generative adversarial network implemented by the machine learning architecture <b>102</b> can include one or more generating components and one or more challenging components.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example framework <b>200</b> to utilize transfer learning techniques to generate protein sequences having specified characteristics, in accordance with some implementations. The framework <b>200</b> can include a first generative adversarial network <b>202</b>. The first generative adversarial network <b>202</b> can include a first generating component <b>204</b> and a first challenging component <b>206</b>. In various implementations, the first generating component <b>204</b> can be a generator and the first challenging component <b>206</b> can be a discriminator. The first generating component <b>204</b> can implement one or more models to generate amino acid sequences based on input provided to the first generating component <b>204</b>. The first challenging component <b>206</b> can generate output indicating that the amino acid sequences produced by the generating component <b>204</b> satisfy one or more characteristics or output indicating that the amino acid sequences produced by the generating component <b>204</b> do not satisfy the one or more characteristics. The output produced by the first challenging component <b>206</b> can be provided to the generating component <b>204</b> and one or more models implemented by the first generating component <b>204</b> can be modified based on the feedback provided by the first challenging component <b>206</b>. In various implementations, the first challenging component <b>206</b> can compare the amino acid sequences produced by the first generating component <b>204</b> with amino acid sequences of target proteins and generate an output indicating an amount of correspondence between the amino acid sequences produced by the first generating component <b>204</b> and the amino acid sequences of target proteins provided to the first challenging component <b>206</b>.</p><p id="p-0050" num="0049">The first generative adversarial network <b>202</b> can be trained in a same or similar manner described with respect to the machine learning architecture <b>102</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. For example, first encoded sequences <b>210</b> and one or more template protein sequences <b>212</b> can be fed into the first challenging component <b>206</b> and compared against output produced by the first generating component <b>204</b>. The output produced by the first generating component <b>204</b> can be based on the one or more template protein sequences <b>212</b>, position modification data <b>214</b>, and first input data <b>216</b>. The one or more template protein sequences <b>212</b> can include amino acid sequences of proteins that include one or more characteristics that are to be preserved. The position modification data <b>214</b> can indicate constraints related to the modification of amino acids at various positions of the one or more template protein sequences <b>214</b>. The first input data <b>216</b> can include data generated by a random number generator or a pseudo-random number generator. The trained model <b>208</b> can be produced in response to one or more functions implemented by at least one of the first generating component <b>204</b> or the first challenging component <b>206</b> satisfying one or more criteria, such as one or more convergence criteria or one or more optimization criteria.</p><p id="p-0051" num="0050">The first encoded target protein sequences <b>210</b> can be encoded according to a classification scheme. In addition, the first encoded target protein sequences <b>210</b> can include amino acid sequences of target proteins, where the target proteins include a scaffolding or foundational structure that can support one or more functional regions. For example, in situations where the first encoded target protein sequences <b>210</b> are human antibodies, the first encoded target protein sequences <b>210</b> can have constant regions of light chains and/or heavy chains that are representative of a particular type or class of antibody. To illustrate, the first encoded target protein sequences <b>210</b> can include antibodies that have constant regions of heavy chains that correspond to IgA antibodies.</p><p id="p-0052" num="0051">The trained model <b>208</b> can generate amino acid sequences of proteins that have at least a portion of the functionality of the one or more template proteins in addition to the underlying structure or scaffold structure of the target proteins. In implementations, the trained model <b>208</b> can generate amino acid sequences of human antibodies that bind to an antigen with a CDR that corresponds to a CDR originally found in a mouse antibody. In additional examples, the trained model <b>208</b> can generate amino acid sequences of proteins produced from a first germline gene based on input of one or more amino acid sequences of proteins produced from a second, different germline gene.</p><p id="p-0053" num="0052">In additional implementations, the trained model <b>208</b> can be generated without using at least one of the template protein sequences <b>212</b> or the position modification data <b>214</b>. For example, the trained model <b>208</b> can be generated using the first encoded target protein sequences <b>210</b> and the first input data <b>216</b>. In various implementations, the trained model <b>208</b> can be generated using training data for the first generative adversarial network <b>202</b> such that the first encoded target protein sequences <b>210</b> include amino acid sequences corresponding to one or more germline genes.</p><p id="p-0054" num="0053">In various examples, the amino acid sequences generated by the trained model <b>208</b> can be refined further. To illustrate, the trained model <b>208</b> can be modified by being subjected to another training process using a different set of training data than the initial training process. For example, the data used for additional training of the trained model <b>208</b> can include a subset of the data used to initially produce the trained model <b>208</b>. In additional examples, the data used for additional training of the trained model <b>208</b> can include a different set of data than the data used to initially produce the trained model <b>208</b>. In illustrative examples, the trained model <b>208</b> can produce amino acid sequences of human antibodies with CDR regions of a mouse antibody that binds to an antigen and the trained model <b>208</b> can be further refined to generate amino acid sequences of human antibodies with CDR regions originally found in the chicken antibody that have a higher probability of having at least a threshold level of expression in an environment having a specified pH range. Continuing with this example, the trained model <b>208</b> can be refined through additional training using a dataset of human antibodies that have a relatively high level of expression in the specified pH range. In the illustrative example of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the refinement of the trained model <b>208</b> can be represented by training a second generative adversarial network <b>218</b> that includes the training model <b>208</b> as the second generating component <b>220</b>. In various implementations, the second generating component <b>220</b> can include the trained model <b>208</b> after one or more modifications have been made to the trained model <b>208</b>. For example, modifications can be made to the trained model <b>208</b> in relation to the architecture of the trained model <b>208</b>, such as the addition of one or more hidden layers or changes to one or more network filters. The second generative adversarial network <b>218</b> can also include a second challenging component <b>222</b>. The second challenging component <b>222</b> can include a discriminator.</p><p id="p-0055" num="0054">Second input data <b>228</b> can be provided to the second generating component <b>220</b> and the second generating component <b>220</b> can produce one or more generated sequences <b>224</b>. The second input data <b>228</b> can include a random or pseudo-random sequence of numbers that the second generating component <b>220</b> uses to produce the generated sequences <b>224</b>. The second challenging component <b>222</b> can generate second classification output <b>226</b> indicating that the amino acid sequences produced by the second generating component <b>220</b> satisfy various characteristics or that the amino acid sequences produced by the second generating component <b>220</b> do not satisfy various characteristics. In illustrative examples, the second challenging component <b>222</b> can generate the classification output <b>226</b> based on similarities and differences between one or more generated sequences <b>224</b> and amino acid sequences provided to the second challenging component <b>222</b>. The classification output <b>226</b> can indicate an amount of similarity or an amount of difference between the generated sequences <b>224</b> and comparison sequences provided to the second challenging component <b>222</b>.</p><p id="p-0056" num="0055">The amino acid sequences provided to the second challenging component <b>222</b> can be included in additional protein sequence data <b>230</b>. The additional protein sequence data <b>230</b> can include amino acid sequences of proteins that have one or more specified characteristics. For example, the additional protein sequence data <b>230</b> can include amino acid sequences of proteins having a threshold level of expression in humans. In additional examples, the additional protein sequence data <b>230</b> can include amino acid sequences of proteins having one or more biophysical properties and/or one or more structural properties. To illustrate, the proteins included in the additional protein sequence data can have negatively charged regions, hydrophobic regions, a relatively low probability of aggregation, a specified percentage of high molecular weight (HMW), melting temperature, one or more combinations thereof, and the like. In various examples, the additional protein sequence data <b>230</b> can include a subset of the protein sequence data used to produce the trained model <b>208</b>. By providing amino acid sequences to the second challenging component <b>222</b> that have one or more specified characteristics, the second generating component <b>220</b> can be trained to produce amino acid sequences have at least a threshold probability of having the one or more of the specified characteristics.</p><p id="p-0057" num="0056">Additionally, in many situations where it is desired to produce amino acid sequences of proteins having specific characteristics, the number of sequences available to train a generative adversarial network is limited. In these situations, the accuracy, efficiency, and/or effectiveness of the generative adversarial network to produce amino acid sequences of proteins having the specified characteristics may be unsatisfactory. Thus, without a sufficient number of amino acid sequences available to train a generative adversarial network, the amino acid sequences produced by the generative adversarial network may not have the desired characteristics. By implementing the techniques and systems described with respect to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a first generative adversarial network <b>202</b> can perform part of the process of determining amino acid sequences that correspond to proteins or that correspond to a broader class of proteins using a first dataset and the second generative adversarial network <b>218</b> can perform additional training to generate amino acid sequences of proteins having more specific characteristics are accurately and efficiently using a second, different dataset. The second dataset can include a subset of the initial training dataset or can include amino acid sequences of proteins having the desired characteristics.</p><p id="p-0058" num="0057">Before being provided to the second challenging component <b>222</b>, the amino acid sequences included in the additional protein sequence data <b>230</b> can be subject to data preprocessing <b>232</b>. For example, the additional protein sequence data <b>230</b> can be arranged according to a classification system before being provided to the second challenging component <b>222</b>. The data preprocessing <b>232</b> can include pairing amino acids included in the amino acid sequences of proteins included in the additional protein sequence data <b>230</b> with numerical values that can represent structure-based positions within the proteins. The numerical values can include a sequence of numbers having a starting point and an ending point. The second encoded sequences <b>234</b> can include a matrix indicating amino acids associated with various positions of a protein. In various examples, the second encoded sequences <b>234</b> can include a matrix having columns corresponding to different amino acids and rows that correspond to structure-based positions of proteins. For each element in the matrix, a 0 can be used to indicate the absence of an amino acid at the corresponding position and a 1 can be used to indicate the presence of an amino acid at the corresponding position. The matrix can also include an additional column that represents a gap in an amino acid sequence where there is no amino acid at a particular position of the amino acid sequence. Thus, in situations where a position represents a gap in an amino acid sequence, a 1 can be placed in the gap column with respect to the row associated with the position where an amino acid is absent. The generated sequence(s) <b>224</b> can also be represented using a vector according to a same or similar number scheme as used for the second encoded sequences <b>234</b>. In some illustrative examples, the second encoded sequences <b>234</b> and the second generated sequence(s) <b>224</b> can be encoded using a method that may be referred to as a one-hot encoding method. In illustrative examples, the classification system used in the data preprocessing <b>232</b> can be the same as or similar to the classification system used in the preprocessing <b>134</b> described with respect to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The data preprocessing <b>232</b> can produce second encoded sequences <b>234</b> that are provided to the second challenging component <b>222</b>.</p><p id="p-0059" num="0058">The second challenging component <b>222</b> can generate output indicating whether the amino acid sequences produced by the second generating component <b>220</b> satisfy various characteristics. In various implementations, the second challenging component <b>222</b> can be a discriminator. In additional situations, such as when the second generative adversarial network <b>218</b> includes a Wasserstein GAN, the second challenging component <b>222</b> can include a critic.</p><p id="p-0060" num="0059">In illustrative examples, based on similarities and differences between the generated sequence(s) <b>224</b> and additional sequences provided to the second challenging component <b>222</b>, such as amino acid sequences included in the additional protein sequence data <b>232</b>, the second challenging component <b>222</b> can generate the classification output <b>226</b> to indicate an amount of similarity or an amount of difference between the generated sequence(s) <b>224</b> and sequences provided to the second challenging component <b>222</b> that are included in the additional protein sequence data <b>232</b>. Additionally, the classification output <b>226</b> can indicate an amount of similarity or an amount of difference between the generated sequence(s) <b>224</b> and the amino acid sequences included in the additional protein sequence data <b>232</b>. In additional examples, the second challenging component <b>222</b> can implement a distance function that produces an output that indicates an amount of distance between the generated sequence(s) <b>222</b> and the proteins included in the additional protein sequence data <b>232</b>. In implementations where the second challenging component <b>222</b> implements a distance function, the classification output <b>226</b> can include a number from &#x2212;&#x221e; to &#x221e; indicating a distance between the generated sequence(s) <b>224</b> and one or more amino acid sequences included in the additional protein sequence data <b>232</b>.</p><p id="p-0061" num="0060">After the second generative adversarial network <b>218</b> has undergone a training process, a modified trained model <b>236</b> can be generated that can produce sequences of proteins. The modified trained model <b>236</b> can represent the trained model <b>208</b> after being trained using the additional protein sequence data <b>230</b>. In examples, the training process for the second generative adversarial network <b>218</b> can be complete after the function(s) implemented by the second generating component <b>220</b> and the second challenging component <b>222</b> converge. The convergence of a function can be based on the movement of values of model parameters toward particular values as protein sequences are generated by the second generating component <b>220</b> and feedback is obtained from the second challenging component <b>222</b>. The training of the second generative adversarial network <b>218</b> can be complete when the protein sequences generated by the second generating component <b>220</b> have particular characteristics.</p><p id="p-0062" num="0061">Additional sequence input <b>238</b> can be provided to the modified trained model <b>236</b>, and the modified trained model <b>236</b> can produce generated sequences <b>240</b>. The additional sequence input <b>238</b> can include a random or pseudo-random series of numbers and the generated sequences <b>240</b> can include amino acid sequences that can be sequences of proteins. In additional implementations, the generated sequences <b>240</b> can be evaluated to determine whether the generated sequences <b>240</b> have a specified set of characteristics. The evaluation of the generated sequences <b>240</b> can produce metrics that indicate characteristics of the generated sequences <b>240</b>, such as biophysical properties of a protein, biophysical properties of a region of a protein, and/or the presence or absence of amino acids located at specified positions. Additionally, the metrics can indicate an amount of correspondence between the characteristics of the generated sequences <b>240</b> and a specified set of characteristics. In some examples, the metrics can indicate a number of positions of a generated sequence <b>240</b> that vary from a sequence produced by a germline gene of a protein. Further, an evaluation of the generated sequences <b>240</b> can determine the presence or absence of structural features of proteins that correspond to the generated sequences <b>240</b>.</p><p id="p-0063" num="0062">While the illustrative example of <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates the training of a model using multiple training sets in a framework that includes two generative adversarial networks. in additional implementations, the training of a model using multiple training datasets can also be represented using a single generative adversarial network. Further, while the illustrative example of <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates the training of a model using generative adversarial networks with two training datasets, in various implementations, more than two datasets can be used to train models using one or more generative adversarial networks according to implementations described herein. For example, the first generating component <b>204</b> of the first generative adversarial network <b>202</b> can be produced using a previously trained generative adversarial network. To illustrate, the first generating component <b>204</b> can be produced using a training data set of amino acid sequences of antibodies and the trained model <b>208</b> can be produced using transfer learning techniques with a training data set of amino acid sequences of antibodies that have one or more groups of positions that correspond to a germline gene. The trained model <b>208</b> can then be further trained to produce the modified trained model <b>236</b> that can generate amino acid sequences of human antibodies.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example framework <b>300</b> to generate target protein sequences using a generative adversarial network based on a template protein sequence and constraint data related to modifications of positions of the template protein sequence, in accordance with some implementations. The framework <b>300</b> can include a computing system <b>302</b>. The computing system <b>302</b> can be implemented by one or more computing devices. The one or more computing devices can include one or more server computing devices, one or more desktop computing devices, one or more laptop computing devices, one or more tablet computing devices, one or more mobile computing devices, or combinations thereof. In various implementations, at least a portion of the one or more computing devices can be implemented in a distributed computing environment. For example, at least a portion of the one or more computing devices can be implemented in a cloud computing architecture.</p><p id="p-0065" num="0064">The computing system <b>302</b> can include one or more generative adversarial networks <b>304</b>. The one or more generative adversarial networks <b>304</b> can include a conditional generative adversarial network. In various implementations, the one or more generative adversarial networks <b>304</b> can include a generating component and a challenging component. The generating component can generate amino acid sequences of proteins and the challenging component can classify the amino acid sequences produced by the generating component as being an amino acid sequence that is included in a set of training or an amino acid sequence that is not included in the set of training data. The set of training data can include amino acid sequences of proteins that have been synthesized and characterized according to one or more analytical tests and/or one or more assays. The output of the challenging component can be based on comparisons between the amino acid sequences produced by the generating component and amino acid sequences included in the set of training data. In illustrative examples, the output of the challenging component can correspond to a probability that an amino acid sequence produced by the generating component is included in the set of training data. As the generating component produces amino acid sequences and as the challenging component produces feedback regarding the amino acid sequences produced by the generating component, the parameters and/or weightings of one or more models implemented by the challenging component and the parameters and/or weightings of one or more models implemented by the generating component can be refined until the one or more models related to the generating component and the one or more models related to the challenging component have been trained and satisfy one or more training criteria. In implementations, the generating component can generate one or more false amino acid sequences of proteins that are not included in the set of training data to try and &#x201c;trick&#x201d; the challenging component into classifying the one or more false amino acid sequences of proteins as being included in the set of training data.</p><p id="p-0066" num="0065">The one or more generative adversarial networks <b>302</b> can use amino acid sequences of one or more template proteins, such as a template protein <b>306</b>, and generate one or more amino acid sequences of target proteins, such as a target protein <b>308</b>. In the illustrative example of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, data corresponding to a first amino acid sequence <b>310</b> of the template protein <b>304</b> can be provided to the computing system <b>302</b> and the computing system <b>302</b> can generate a second amino acid sequence <b>312</b> of the target protein <b>308</b>. The first amino acid sequence <b>310</b> can include a number of amino acids at respective positions, such as amino acid <b>314</b> (Threonine) at position <b>111</b> of the template protein <b>306</b>, amino acid <b>316</b> (Histidine) at position <b>112</b> of the template protein <b>318</b>, amino acid <b>318</b> (Methionine) at position <b>113</b> of the template protein <b>306</b>, amino acid <b>320</b> (Arginine) at position <b>274</b> of the template protein <b>306</b>, amino acid <b>322</b> (Histidine) at position <b>275</b> of the template protein <b>306</b>, and amino acid <b>324</b> (Histidine) at position <b>276</b> of the template protein <b>306</b>. The one or more generative adversarial network <b>304</b> can be conditional according to position modification data that corresponds to individual positions of amino acid sequences that are provided to the computing system <b>302</b>. For example, the amino acids <b>314</b>, <b>316</b>, <b>318</b>, <b>320</b>, <b>322</b>, <b>324</b> are associated with respective position modification data. To illustrate, the amino acid <b>314</b> can be associated with position modification data <b>326</b>, the amino acid <b>316</b> can be associated with position modification data <b>328</b>, the amino acid <b>318</b> can be associated with position modification data <b>330</b>, the amino acid <b>320</b> can be associated with position modification data <b>332</b>, the amino acid <b>322</b> can be associated with position modification data <b>334</b>, and the amino acid <b>324</b> can be associated with position modification data <b>336</b>.</p><p id="p-0067" num="0066">The position modification data <b>326</b>, <b>328</b>, <b>330</b>, <b>332</b>, <b>334</b>, <b>336</b> can correspond to constraints on the modification of the individual amino acids <b>314</b>, <b>316</b>, <b>318</b>, <b>320</b>, <b>322</b> <b>324</b> included in the first sequence of amino acids <b>310</b> of the template protein <b>306</b>. In illustrative examples, the position modification data <b>326</b>, <b>328</b>, <b>330</b>, <b>332</b>, <b>334</b>, <b>336</b> can indicate penalties that are to be applied by one or more generating components and/or one or more challenging components of the one or more generative adversarial networks <b>304</b> in response to modification of the respective individual amino acids <b>314</b>, <b>316</b>, <b>318</b>, <b>320</b>, <b>322</b> <b>324</b> in the first sequence of amino acids <b>310</b>. For example, penalties included in the position modification data <b>326</b>, <b>328</b>, <b>330</b>, <b>332</b>, <b>334</b>, <b>336</b> can be applied to at least one loss function of the one or more generative adversarial networks <b>304</b>. In additional examples, the position modification data <b>326</b>, <b>328</b>, <b>330</b>, <b>332</b>, <b>334</b>, <b>336</b> can include probabilities that individual amino acids <b>314</b>, <b>316</b>, <b>318</b>, <b>320</b>, <b>322</b> <b>324</b> in the first sequence of amino acids <b>310</b> can be modified. The position modification data <b>326</b>, <b>328</b>, <b>330</b>, <b>332</b>, <b>334</b>, <b>336</b> can include numerical values related to probabilities and/or penalties corresponding to the modification of individual amino acids <b>314</b>, <b>316</b>, <b>318</b>, <b>320</b>, <b>322</b> <b>324</b> included in the first sequence of amino acids <b>310</b>. To illustrate, the position modification data <b>326</b>, <b>328</b>, <b>330</b>, <b>332</b>, <b>334</b>, <b>336</b> can include numerical values from 0 to 1, numerical values from &#x2212;1 to 1, and/or values from 0 to 100. In additional implementations, the position modification data <b>326</b>, <b>328</b>, <b>330</b>, <b>332</b>, <b>334</b>, <b>336</b> can include one or more functions, such as one or more linear functions or one or more non-linear functions, that include one or more variables are related to the probabilities and/or penalties corresponding to modification of the individual amino acids <b>314</b>, <b>316</b>, <b>318</b>, <b>320</b>, <b>322</b> <b>324</b> included in first sequence of amino acids <b>310</b>. In further examples, at least a portion of the position modification data <b>326</b>, <b>328</b>, <b>330</b>, <b>332</b>, <b>334</b>, <b>336</b> can indicate that the amino acids located at one or more positions <b>314</b>, <b>316</b>, <b>318</b>, <b>320</b>, <b>322</b>, <b>324</b> are not to be modified by the one or more generative adversarial networks <b>304</b>. Also, although the illustrative example of <figref idref="DRAWINGS">FIG. <b>3</b></figref> indicates that each position <b>314</b>, <b>316</b>, <b>318</b>, <b>320</b>, <b>322</b>, <b>324</b> is associated with respective position modification data <b>326</b>, <b>328</b>, <b>330</b>, <b>332</b>, <b>334</b>, <b>336</b>, in additional implementations, at least one of the positions <b>314</b>, <b>316</b>, <b>318</b>, <b>320</b>, <b>322</b>, <b>324</b> may not be associated with any position modification data. In one or more implementations, position modification data can be associated with one or more groups of positions of the first amino acid sequence.</p><p id="p-0068" num="0067">In various examples, the data corresponding to the first sequence of amino acids <b>310</b> of the template protein <b>306</b> can be provided to the computing system <b>302</b>. The first sequence of amino acids <b>310</b> and the corresponding position modification data can be used by the one or more generative adversarial networks <b>304</b> to generate the second sequence of amino acids <b>312</b> that corresponds to the target protein <b>308</b>. The target protein <b>308</b> can be related to, but different from the template protein <b>306</b>. For example, the one or more generative adversarial networks <b>304</b> can modify amino acids at one or more positions of the first sequence of amino acids <b>310</b> to produce the second sequence of amino acids <b>312</b>. To illustrate, the second amino acid sequence <b>312</b> includes amino acids <b>346</b> and <b>348</b> that correspond to amino acids <b>314</b>, <b>316</b> of the first sequence of amino acids <b>310</b>. That is, amino acid <b>314</b> and amino acid <b>338</b> are both Threonine and the amino acid <b>316</b> and the amino acid <b>340</b> are both Histidine. In the illustrative example of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the amino acid <b>318</b> and the amino acid <b>342</b> are different indicating that the Methionine of amino acid <b>318</b> has been changed by the one or more generative adversarial networks <b>304</b> to Leucine for amino acid <b>342</b>. Further, amino acid <b>320</b> can correspond to the amino acid <b>344</b> with both amino acids <b>320</b>, <b>344</b> being Arginine, while the amino acids <b>322</b>, <b>324</b> in the first amino acid sequence <b>310</b> of the template protein <b>306</b> have been changed from Histidine to Lysine at amino acids <b>346</b>, <b>348</b> of the second sequence of amino acids <b>312</b> of the target protein <b>308</b>. In addition to modifying amino acids at various positions of the first sequence of amino acids <b>310</b> of the template protein <b>306</b>, the one or more generative adversarial networks <b>304</b> can generate the second sequence of amino acids <b>312</b> of the target protein <b>308</b> by adding amino acids to the first sequence of amino acids <b>310</b>. The one or more generative adversarial networks <b>304</b> can also generate the second sequence of amino acids <b>312</b> of the target protein <b>308</b> by deleting amino acids from the first sequence of amino acids <b>310</b> of the template protein <b>306</b>.</p><p id="p-0069" num="0068">The target protein <b>310</b> can retain one or more characteristics of the template protein <b>308</b>. The one or more characteristics of the template protein <b>308</b> can be maintained in the target protein <b>310</b> by maintaining the individual amino acids at various positions of the first amino acid sequence <b>310</b> of the template protein <b>306</b> in the second amino acid sequence <b>312</b> of the target protein <b>308</b>. The one or more characteristics of the template protein <b>306</b> that are also present in the target protein <b>308</b> can be preserved by determining one or more positions of the first sequence of amino acids <b>310</b> that correspond to the one or more characteristics and minimizing the probability that the one or more generative adversarial networks <b>304</b> change the amino acids located at the one or more positions. Additionally, the characteristics of the amino acids in the target protein <b>308</b> that are used to replace the initial amino acids in the template protein <b>306</b> can be limited. For example, the position modification data for the first sequence of amino acids <b>310</b> can indicate that a hydrophobic amino acid is to be replaced by another hydrophobic amino acid. In this way, the target protein <b>308</b> can have one or more characteristics of the template protein <b>306</b> that are similar or the same. For example, the target protein <b>308</b> can have values of one or more biophysical properties that are within a threshold amount of the values of the one or more biophysical properties of the template protein <b>306</b>. Additionally, the target protein <b>308</b> can have functionality that is similar to or the same as functionality of the template protein <b>306</b>. To illustrate, the target protein <b>308</b> and the template protein <b>306</b> can both bind to a specified molecule or to a specified type of molecule. In illustrative examples, the template protein <b>306</b> can include an antibody that binds to an antigen and the first sequence of amino acids <b>310</b> can be modified to the second sequence of amino acids <b>312</b> such that the target protein <b>308</b> can also bind to the antigen.</p><p id="p-0070" num="0069">In various examples, the position modification data can indicate a penalty and/or a probability associated with changing an amino acid at one position of the template protein <b>306</b> to one or more different amino acids in the target protein <b>308</b>. To illustrate, the position modification data can indicate a first penalty and/or a first probability of changing a threonine of amino acid <b>314</b> at position <b>114</b> to a serine and a second penalty and/or a second probability of changing the threonine of amino acid <b>314</b> at position <b>114</b> to a cysteine. The position modification data can, in various implementations, indicate a respective probability and/or a respective penalty for modifying an amino acid at a position of the template protein with respect to each of at least 5 other amino acids, at least 10 other amino acids, at least 15 other amino acids, or at least 20 other amino acids.</p><p id="p-0071" num="0070">The one or more generative adversarial networks <b>304</b> can modify template proteins produced by one organism to generate target proteins that correspond to a different organism. For example, the template protein <b>306</b> can be produced by mice and the first sequence of amino acids <b>310</b> can be modified such that the second sequence of amino acids <b>312</b> corresponds to a human protein. In an additional example, the template protein <b>306</b> can be produced by humans and the first sequence of amino acids <b>310</b> can be modified such that the second sequence of amino acids <b>312</b> corresponds to an equine protein. Additionally, the one or more generative adversarial networks <b>304</b> can modify template proteins that are produced by one or more genes of a germline to generate proteins that correspond to different germline genes. In illustrative examples, modifications of one or more amino acids of a germline gene of an antibody within a species can have an effect on one or more characteristics of the antibody (e.g., expression level, yield, variable region stability) while maintaining an amount of binding capacity to a specified antigen. Further, in situations where the one or more generative adversarial networks <b>304</b> modify amino acid sequences of antibodies, the one or more generative adversarial networks <b>304</b> can modify template proteins that correspond to a first antibody isotype, such as an IgE isotype antibody, to generate target antibodies that correspond to a second antibody isotype, such as an IgG isotype antibody.</p><p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating an example framework <b>400</b> to utilize data indicating an antibody sequence of a first organism having specified functionality to generate data corresponding to additional antibody sequences having the specified functionality for a second, different organism, in accordance with some implementations. The framework <b>400</b> can include a computing system <b>402</b> that can implement one or more generative adversarial networks <b>404</b> to modify an amino acid sequence of a template antibody <b>406</b> of a first mammal <b>08</b> to produce a target antibody <b>410</b> of a second mammal <b>412</b>. In the illustrative example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the template antibody <b>406</b> can be a mouse antibody and the target antibody <b>410</b> can correspond to a human antibody. The template antibody <b>406</b> can bind to an antigen <b>414</b>. In addition, the one or more generative adversarial networks <b>404</b> can generate the target antibody <b>410</b> such that the target antibody <b>410</b> has at least a threshold probability of also binding to the antigen <b>414</b>.</p><p id="p-0073" num="0072">The template antibody <b>406</b> can include a first light chain <b>416</b>. The first light chain <b>416</b> can include a variable region having a number of framework regions and a number of hypervariable regions. In various instances, the hypervariable regions can be referred to herein as complementarity determining regions (CDRs). In the illustrative example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the first light chain <b>416</b> can include a first framework region <b>418</b>, a second framework region <b>420</b>, a third framework region <b>422</b>, and a fourth framework region <b>424</b>. Additionally, the first light chain <b>416</b> can include a first CDR <b>426</b>, a second CDR <b>428</b>, and a third CDR <b>430</b>. Although not shown in the illustrative example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the first light chain <b>416</b> can include a constant region that is coupled to the variable region of the first light chain <b>416</b> and follows the amino acid sequence of the variable region of the first light chain <b>416</b>. The constant region of the first light chain <b>416</b> and the variable region of the first light chain <b>416</b> can form an antigen binding region for the first light chain <b>416</b>.</p><p id="p-0074" num="0073">The template antibody <b>406</b> can also include a first heavy chain <b>432</b>. The first heavy chain <b>432</b> can include a variable region having a number of framework regions and a number of hypervariable regions. The first heavy chain <b>432</b> can include a first framework region <b>434</b>, a second framework region <b>436</b>, a third framework region <b>438</b>, and a fourth framework region <b>440</b>. Further, the first heavy chain <b>432</b> can include a first CDR <b>442</b>, a second CDR <b>444</b>, and a third CDR <b>446</b>. Although not shown in the illustrative example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the first heavy chain <b>432</b> can include a number of constant regions that coupled to the variable region of the first heavy chain <b>432</b>. To illustrate, a first constant region of the first heavy chain <b>432</b> can be coupled to the variable region and together the first constant region of the first heavy chain <b>432</b> and the variable region of the first heavy chain <b>432</b> can form an antigen binding region of the first heavy chain <b>432</b>. The first heavy chain <b>432</b> can also include a crystallizable region that includes two additional constant regions and is coupled to the antigen binding region by a bridge region.</p><p id="p-0075" num="0074">The antigen binding region of the first light chain <b>416</b> and the antigen binding region of the first heavy chain <b>432</b> can have a shape that corresponds to a shape and a chemical profile of the antigen <b>414</b>. In various examples, at least a portion of the CDRs <b>426</b>, <b>428</b>, <b>430</b> of the first light chain <b>416</b> and at least a portion of the CDRs <b>442</b>, <b>444</b>, <b>446</b> of the first heavy chain <b>432</b> can include amino acids that interact with amino acids of an epitope region of the antigen <b>414</b>. In this way, amino acids of at least a portion of the CDRs <b>426</b>, <b>428</b>, <b>430</b>, <b>442</b>, <b>444</b>, <b>446</b> can interact with amino acids of the antigen <b>414</b> through at least one of electrostatic interactions, hydrogen bonds, van der Waals forces, or hydrophobic interactions.</p><p id="p-0076" num="0075">Although not shown in the illustrative example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the template antibody <b>406</b> can also include an additional light chain that is paired with an additional heavy chain. The additional light chain can correspond to the first light chain <b>416</b> and the additional heavy chain can correspond to the first heavy chain <b>432</b>. In illustrative examples, the additional light chain can have a same amino acid sequence as the first light chain <b>414</b> and the additional heavy chain can have a same amino acid sequence as the first heavy chain <b>432</b>. The additional light chain and the additional heavy chain of the template antibody <b>406</b> can bind to another antigen molecule that corresponds to the antigen <b>414</b>.</p><p id="p-0077" num="0076">The one or more generative adversarial networks <b>404</b> can generate the target antibody <b>410</b> using the amino acid sequences of the regions of the template antibody <b>406</b>. The target antibody <b>410</b> can have one or more portions with amino acid sequences that are different from portions of the amino acid sequence of the template antibody <b>406</b>. The portions of the amino acid sequence of the template antibody <b>406</b> that are changed in relation to the amino acid sequence of the target antibody <b>410</b> can be modified such that the target antibody <b>410</b> corresponds more closely to an antibody produced by a different species than an antibody produced by a species related to the template antibody <b>406</b>. In one or more illustrative examples, the one or more generative adversarial networks <b>404</b> can modify amino acids included in the variable region of the first light chain <b>416</b> and/or amino acids included in the variable region of the first heavy chain <b>432</b> to produce the target antibody <b>410</b>. In various illustrative examples, the one or more generative adversarial networks <b>404</b> can modify amino acids included in at least one of one or more of the CDRs <b>426</b>, <b>438</b>, <b>430</b> of the first light chain <b>416</b> or one or more of the CDRs <b>442</b>, <b>444</b>, <b>446</b> of the first heavy chain <b>432</b> to produce the target antibody <b>410</b>.</p><p id="p-0078" num="0077">The target antibody <b>410</b> can include a second light chain <b>448</b>. The second light chain <b>448</b> can correspond to the first light chain <b>416</b>. In various examples, at least one amino acid of the second light chain <b>448</b> can be different from at least one amino acid of the first light chain <b>416</b>. The second light chain <b>448</b> can include a variable region having a number of framework regions and a number of hypervariable regions. The second light chain <b>448</b> can include a first framework region <b>450</b>, a second framework region <b>452</b>, a third framework region <b>454</b>, and a fourth framework region <b>456</b>. Additionally, the second light chain <b>448</b> can include a first CDR <b>458</b>, a second CDR <b>460</b>, and a third CDR <b>462</b>. Although not shown in the illustrative example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the second light chain <b>448</b> can include a constant region that is coupled to the variable region of the second light chain <b>448</b> and follows the amino acid sequence of the variable region of the second light chain <b>448</b>. The constant region of the second light chain <b>448</b> and the variable region of the second light chain <b>448</b> can form an antigen binding region for the second light chain <b>448</b>.</p><p id="p-0079" num="0078">The target antibody <b>410</b> can also include a second heavy chain <b>464</b>. The second heavy chain <b>464</b> can correspond to the first heavy chain <b>432</b>. In one or more implementations, at least one amino acid of the second heavy chain <b>464</b> can be different from at least one amino acid of the first heavy chain <b>432</b>. The second heavy chain <b>464</b> can include a variable region having a number of framework regions and a number of hypervariable regions. The second heavy chain <b>464</b> can include a first framework region <b>466</b>, a second framework region <b>468</b>, a third framework region <b>470</b>, and a fourth framework region <b>472</b>. Further, the second heavy chain <b>464</b> can include a first CDR <b>474</b>, a second CDR <b>476</b>, and a third CDR <b>478</b>. Although not shown in the illustrative example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the second heavy chain <b>464</b> can include a number of constant regions that coupled to the variable region of the second heavy chain <b>464</b>. To illustrate, a first constant region of the second heavy chain <b>464</b> can be coupled to the variable region and together the first constant region of the second heavy chain <b>464</b> and the variable region of the second heavy chain <b>464</b> can form an antigen binding region of the second heavy chain <b>464</b>. The second heavy chain <b>464</b> can also include a crystallizable region that includes two additional constant regions and is coupled to the antigen binding region by a bridge region.</p><p id="p-0080" num="0079">Although the second light chain <b>448</b> can have a different amino acid sequence than the first light chain <b>416</b> and/or the second heavy chain <b>464</b> can have a different amino acid sequence than the first heavy chain <b>432</b>, the antigen binding region of the second light chain <b>448</b> and the antigen binding region of the second heavy chain <b>464</b> can have a shape that corresponds to a shape and a chemical profile of the antigen <b>414</b>. In various examples, at least a portion of the CDRs <b>458</b>, <b>460</b>, <b>462</b> of the second light chain <b>448</b> and at least a portion of the CDRs <b>474</b>, <b>476</b>, <b>478</b> of the second heavy chain <b>464</b> can include amino acids that interact with amino acids of an epitope region of the antigen <b>414</b>. In this way, amino acids of at least a portion of the CDRs <b>458</b>, <b>460</b>, <b>462</b>, <b>474</b>, <b>476</b>, <b>478</b> can interact with amino acids of the antigen <b>414</b> through at least one of electrostatic interactions, hydrogen bonds, van der Waals forces, or hydrophobic interactions.</p><p id="p-0081" num="0080">Although not shown in the illustrative example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the target antibody <b>410</b> can also include an additional light chain that is paired with an additional heavy chain. The additional light chain can correspond to the second light chain <b>448</b> and the additional heavy chain can correspond to the second heavy chain <b>464</b>. In illustrative examples, the additional light chain can have a same amino acid sequence as the second light chain <b>448</b> and the additional heavy chain can have a same amino acid sequence as the second heavy chain <b>464</b>. The additional light chain and the additional heavy chain of the target antibody <b>410</b> can bind to another antigen molecule that corresponds to the antigen <b>414</b>.</p><p id="p-0082" num="0081">In the illustrative example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the template antibody <b>406</b> can include a first portion having a first amino acid sequence <b>480</b> that is different from a second portion of the target antibody <b>410</b> that has a second amino acid sequence <b>482</b>. For example, a threonine molecule included in the first amino acid sequence <b>480</b> of the template antibody <b>406</b> can be replaced by an asparagine molecule in the second amino acid sequence <b>482</b> of a corresponding portion of the target antibody <b>410</b>. Additionally, the template antibody <b>406</b> can include a third portion having a third amino acid sequence <b>484</b> that is different from a fourth portion of the target antibody <b>410</b> having a fourth amino acid sequence <b>482</b>. To illustrate, a proline molecule included in the third amino acid sequence <b>484</b> of the third portion of the template antibody <b>406</b> can be replaced by a serine molecule in the fourth amino acid sequence <b>486</b> corresponding to the fourth portion of the target antibody <b>410</b>.</p><p id="p-0083" num="0082">In various implementations, for each antibody isotype, such as IgA, IgD, IgE, IgG, IgM, the light chain constant regions can be comprised of a same or similar sequence of amino acids and the respective heavy chain constant regions can be comprised of a same or similar sequence of amino acids.</p><p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating an example framework <b>500</b> to generate target protein sequences using machine learning techniques by combining protein fragment sequences with template protein sequences, in accordance with some implementations. In various examples, the machine learning architecture <b>502</b> can generate sequences of fragments of proteins. The sequences of the fragments of proteins can be combined with sequences of protein templates to generate sequences of target proteins. In one or more examples, the machine learning architecture <b>502</b> can generate sequences of fragments of antibodies. In these scenarios, the sequences of the antibody fragments can be combined with a template sequence, such as an antibody framework to generate an antibody sequence. In one or more illustrative examples, the machine learning architecture <b>502</b> can generate sequences of at least a portion of variable regions of antibodies and the antibody fragment sequences generated by the machine learning architecture <b>502</b> can be combined with sequences of additional portions of an antibody to generate a complete antibody sequence. In one or more implementations, the antibody sequence can include one or more light chain variable regions, one or more light chain constant regions, one or more heavy chain variable regions, one or more heavy chain constant regions, or one or more combinations thereof.</p><p id="p-0085" num="0084">The machine learning architecture <b>502</b> can include a generating component <b>504</b> and a challenging component <b>506</b>. The generating component <b>506</b> can implement one or more models to generate amino acid sequences based on input provided to the generating component <b>506</b>. In various implementations, the one or more models implemented by the generating component <b>506</b> can include one or more functions. The challenging component <b>506</b> can generate output indicating whether the amino acid sequences produced by the generating component <b>504</b> satisfy various characteristics. The output produced by the challenging component <b>506</b> can be provided to the generating component <b>504</b> and the one or more models implemented by the generating component <b>504</b> can be modified based on the feedback provided by the challenging component <b>506</b>. The challenging component <b>506</b> can compare the amino acid sequences produced by the generating component <b>504</b> with amino acid sequences of a library of target proteins and generate an output indicating an amount of correspondence between the amino acid sequences produced by the generating component <b>504</b> and the amino acid sequences of target proteins provided to the challenging component <b>506</b>.</p><p id="p-0086" num="0085">In various implementations, the machine learning architecture <b>502</b> can implement one or more neural network technologies. For example, the machine learning architecture <b>502</b> can implement one or more recurrent neural networks. Additionally, the machine learning architecture <b>502</b> can implement one or more convolution neural networks. In certain implementations, the machine learning architecture <b>502</b> can implement a combination of recurrent neural networks and convolutional neural networks. In examples, the machine learning architecture <b>502</b> can include a generative adversarial network (GAN). In these situations, the generating component <b>504</b> can include a generator and the challenging component <b>506</b> can include a discriminator. The challenging component <b>506</b> can generate output indicating whether the amino acid sequences produced by the generating component <b>504</b> satisfy various characteristics. In various implementations, the challenging component <b>506</b> can be a discriminator. In additional situations, such as when the machine learning architecture <b>502</b> includes a Wasserstein GAN, the challenging component <b>506</b> can include a critic. In additional implementations, the machine learning architecture <b>502</b> can include a conditional generative adversarial network (cGAN).</p><p id="p-0087" num="0086">In the illustrative example of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the generating component <b>504</b> can obtain input data <b>508</b> and the generating component <b>504</b> can utilize the input data <b>508</b> and one or more models to produce generated sequences <b>510</b>. The input data <b>508</b> can include noise that is produced by a random number generator or noise produced by a pseudo-random number generator. The generated sequences <b>510</b> can include amino acid sequences that are represented by a series of letters with each letter indicating an amino acid located at a respective position of a protein. In various examples, the generated sequences <b>510</b> can represent fragments of proteins. In one or more illustrative examples, the generated sequences <b>510</b> can correspond to fragments of antibodies.</p><p id="p-0088" num="0087">The generated sequence(s) <b>510</b> can be analyzed by the challenging component <b>506</b> against sequences of proteins included in protein sequence data <b>512</b>. The protein sequence data <b>512</b> can be training data for the machine learning architecture <b>502</b>. The protein sequence data <b>512</b> can be encoded according to a schema. The protein sequence data <b>512</b> can include sequences of proteins obtained from one or more data sources that store amino acid sequences of proteins. The one or more data sources can include one or more websites that are searched and information corresponding to amino acid sequences of target proteins is extracted from the one or more websites. Additionally, the one or more data sources can include electronic versions of research documents from which amino acid sequences of target proteins can be extracted. The protein sequence data <b>512</b> can be stored in one or more data stores that are accessible to the machine learning architecture <b>502</b>. The one or more data stores can be connected to the machine learning architecture <b>502</b> via a wireless network, a wired network, or combinations thereof. The protein sequence data <b>512</b> can be obtained by the machine learning architecture <b>502</b> based on requests sent to the data stores to retrieve one or more portions of the protein sequence data <b>512</b>.</p><p id="p-0089" num="0088">In one or more examples, the protein sequence data <b>512</b> can include amino acid sequences of fragments of proteins. For example, the protein sequence data <b>512</b> can include sequences of at least one of light chains of antibodies or heavy chains of antibodies. In addition, the protein sequence data <b>512</b> can include sequences of at least one of variable regions of antibody light chains, variable regions of antibody heavy chains, constant regions of antibody light chains, constant regions of antibody heavy chains, hinge regions of antibodies, or antigen binding sites of antibodies. In one or more illustrative examples, the protein sequence data <b>512</b> can include sequences of complementarity determining regions (CDRs) of antibodies, such as at least one of CDR1, CDR2, or CDR3. In one or more additional illustrative examples, the protein sequence data <b>512</b> can include sequences of fragments of T-cell receptors. To illustrate, the protein sequence data <b>512</b> can include sequences of antigen binding sites of T-cell receptors, such as one or more CDRs of T-cell receptors.</p><p id="p-0090" num="0089">The amino acid sequences included in the protein sequence data <b>512</b> can be subject to data preprocessing <b>514</b> before being provided to the challenging component <b>506</b>. For example, the protein sequence data <b>512</b> can be arranged according to a classification system before being provided to the challenging component <b>506</b>. The data preprocessing <b>514</b> can include pairing amino acids included in the target proteins of the protein sequence data <b>512</b> with numerical values that can represent structure-based positions within the proteins. The numerical values can include a sequence of numbers having a starting point and an ending point. In an illustrative example, a T can be paired with the number 43 indicating that a Threonine molecule is located at a structure-based position 43 of a specified protein domain type. In illustrative examples, structure-based numbering can be applied to any general protein type, such as fibronectin type III (FNIII) proteins, avimers, antibodies, VHH domains, kinases, zinc fingers, T-cell receptors, and the like.</p><p id="p-0091" num="0090">In various implementations, the classification system implemented by the data preprocessing <b>516</b> can include a numbering system that encodes structural position for amino acids located at respective positions of proteins. In this way, proteins having different numbers of amino acids can be aligned according to structural features. For example, the classification system can designate that portions of proteins having particular functions and/or characteristics can have a specified number of positions. In various situations, not all of the positions included in the classification system may be associated with an amino acid because the number of amino acids in a particular region of a protein may vary between proteins. In additional examples, the structure of a protein can be reflected in the classification system. To illustrate, positions of the classification system that are not associated with a respective amino acid can indicate various structural features of a protein, such as a turn or a loop. In an illustrative example, a classification system for antibodies can indicate that heavy chain regions, light chain regions, and hinge regions have a specified number of positions assigned to them and the amino acids of the antibodies can be assigned to the positions according to the classification system. In one or more implementations, the data preprocessing <b>514</b> can use Antibody Structural Numbering (ASN) to classify individual amino acids located at respective positions of an antibody.</p><p id="p-0092" num="0091">The output produced by the data preprocessing <b>514</b> can include encoded sequences <b>516</b>. The encoded sequences <b>516</b> can include a matrix indicating amino acids associated with various positions of a protein. In examples, the encoded sequences <b>516</b> can include a matrix having columns corresponding to different amino acids and rows that correspond to structure-based positions of proteins. For each element in the matrix, a 0 can be used to indicate the absence of an amino acid at the corresponding position and a 1 can be used to indicate the presence of an amino acid at the corresponding position. The matrix can also include an additional column that represents a gap in an amino acid sequence where there is no amino acid at a particular position of the amino acid sequence. Thus, in situations where a position represents a gap in an amino acid sequence, a 1 can be placed in the gap column with respect to the row associated with the position where an amino acid is absent. The generated sequence(s) <b>510</b> can also be represented using a vector according to a same or similar number scheme as used for the encoded sequences <b>516</b>. In some illustrative examples, the encoded sequences <b>516</b> and the generated sequence(s) <b>510</b> can be encoded using a method that may be referred to as a one-hot encoding method.</p><p id="p-0093" num="0092">In one or more examples, based on similarities and differences between the generated sequence(s) <b>510</b> and additional sequences provided to the challenging component <b>506</b>, such as amino acid sequences included in the protein sequence data <b>512</b>, the challenging component <b>506</b> can generate the classification output <b>518</b> to indicate an amount of similarity or an amount of difference between the generated sequence(s) <b>510</b> and sequences provided to the challenging component <b>506</b> that are included in the protein sequence data <b>512</b>. In one or more examples, the challenging component <b>506</b> can label the generated sequence(s) <b>510</b> as zero and the encoded sequences obtained from the protein sequence data <b>512</b> as 1. In these situations, the classification output <b>518</b> can include a first number from 0 to 1 with respect to one or more amino acid sequences included in the protein sequence data <b>512</b>.</p><p id="p-0094" num="0093">In one or more additional examples, the challenging component <b>506</b> can implement a distance function that produces an output that indicates an amount of distance between the generated sequence(s) <b>510</b> and the protein sequences included in the protein sequence data <b>512</b>. In implementations where the challenging component <b>506</b> implements a distance function, the classification output <b>518</b> can include a number from &#x2212;&#x221e; to &#x221e; indicating a distance between the generated sequence(s) <b>510</b> and one or more sequences included in the protein sequence data <b>512</b>.</p><p id="p-0095" num="0094">The data used to train the machine learning architecture <b>502</b> can impact the amino acid sequences produced by the generating component <b>504</b>. For example, in situations where CDRs of antibodies are included in the protein sequence data <b>512</b> provided to the challenging component <b>506</b>, the amino acid sequences generated by the generating component <b>504</b> can correspond to amino acid sequences of antibody CDRs. In another example, in scenarios where the amino acid sequences included in the target protein sequence data <b>512</b> provided to the challenging component <b>506</b> correspond to CDRs of T-cell receptors, the amino acid sequences produced by the generating component <b>504</b> can correspond to sequences of CDRs of T-cell receptors.</p><p id="p-0096" num="0095">After the machine learning architecture <b>502</b> has undergone a training process, a trained model <b>518</b> can be generated that can produce sequences of proteins. The trained model <b>518</b> can include the generating component <b>504</b> after a training process has been performed using the protein sequence data <b>512</b>. In one or more illustrative examples, the trained model <b>518</b> include a number of weights and/or a number of parameters of a convolution neural network. The training process for the machine learning architecture <b>502</b> can be complete after the function(s) implemented by the generating component <b>504</b> and the function(s) implemented by the challenging component <b>506</b> converge. The convergence of a function can be based on the movement of values of model parameters toward particular values as protein sequences are generated by the generating component <b>504</b> and feedback is obtained from the challenging component <b>506</b>. In various implementations, the training of the machine learning architecture <b>502</b> can be complete when the protein sequences produced by the generating component <b>504</b> have particular characteristics. For example, the amino acid sequences generated by the generating component <b>504</b> can be analyzed by a software tool that determines at least one of biophysical properties of the amino acid sequences, structural features of the amino acid sequences, or adherence to amino acid sequences corresponding to one or more protein germlines The machine learning architecture <b>502</b> can produce the trained model <b>518</b> in situations where the amino acid sequences produced by the generating component <b>504</b> are determined by the software tool to have one or more specified characteristics. In one or more implementations, the trained model <b>518</b> can be included in a target protein system <b>520</b> that generates sequences of target proteins.</p><p id="p-0097" num="0096">Protein sequence input <b>522</b> can be provided to the trained model <b>518</b>, and the trained model <b>518</b> can produce protein fragment sequences <b>524</b>. The protein sequence input <b>522</b> can include an input vector that can include a random or pseudo-random series of numbers. In one or more illustrative examples, the protein fragment sequences <b>524</b> produced by the trained model <b>518</b> can be represented as a matrix structure that is the same as or similar to the matrix structure used to represent the encoded sequences <b>516</b> and/or the generated sequence(s) <b>510</b>. In various implementations, the matrices produced by the trained model <b>518</b> that comprise the protein fragment sequences <b>524</b> can be decoded to produce a string of amino acids that correspond to the sequence of a protein fragment. The protein fragment sequences <b>524</b> can include sequences of at least portions of fibronectin type III (FNIII) proteins, avimers, VHH domains, antibodies, kinases, zinc fingers, T-cell receptors, and the like. In one or more illustrative examples, the protein fragment sequences <b>524</b> can include sequences of fragments of antibodies. For example, the protein fragment sequences <b>524</b> can correspond to portions one or more antibody subtypes, such as immunoglobin A (IgA), immunoglobin D (IgD), immunoglobin E (IgE), immunoglobin G (IgG), or immunoglobin M (IgM). In one or more examples, the protein fragment sequences <b>524</b> can include sequences of at least one of one or more antibody light chain variable regions, one or more antibody heavy chain variable regions, one or more antibody light chain constant regions, one or more antibody heavy chain constant regions, or one or more antibody hinge regions. Further, the protein fragment sequences <b>524</b> can correspond to additional proteins that bind antigens. In still other examples, the protein fragment sequences <b>524</b> can correspond to amino acid sequences that participate in protein-to-protein interactions, such as proteins that have regions that bind to antigens or regions that bind to other molecules.</p><p id="p-0098" num="0097">The target protein system <b>520</b> can combine one or more protein fragment sequences <b>524</b> with one or more template protein sequences <b>526</b> to produce one or more target protein sequences <b>528</b>. The template protein sequences <b>526</b> can include amino acid sequences of portions of proteins that can be combined with the protein fragment sequences <b>524</b>. For example, a protein fragment sequence <b>524</b> can include an amino acid sequence of a variable region of an antibody light chain and a template protein sequence <b>526</b> can include an amino acid sequence of a remainder of an antibody. To illustrate, the template protein sequence <b>526</b> can include an amino acid sequence that includes a constant region of an antibody light chain. In these scenarios, the target protein sequences <b>528</b> can include an amino acid sequence of an antibody light chain. In one or more additional examples, one or more protein fragment sequences <b>524</b> can include an amino acid sequence of a variable region of an antibody light chain and an amino acid sequence of a variable region of an antibody heavy chain and one or more template sequences <b>526</b> can include amino acid sequences of a constant region of an antibody light chain, a first constant region of an antibody heavy chain, a hinge region of an antibody heavy chain, a second constant region of an antibody heavy chain, and a third constant region of an antibody heavy chain. In these instances, the target protein sequences <b>528</b> can include an amino acid sequence of an antibody light chain coupled with an antibody heavy chain.</p><p id="p-0099" num="0098">The target protein system <b>520</b> can determine one or more locations of one or more missing amino acids in a template protein sequence <b>526</b> and determine one or more amino acids included in one or more protein fragment sequences <b>524</b> that can be used to supply the one or more missing amino acid sequences. In various examples, the template protein sequences <b>526</b> can indicate locations of missing amino acids within individual template protein sequences <b>526</b>. In one or more illustrative examples, the trained model <b>518</b> can produce protein fragment sequences <b>524</b> can correspond to amino acid sequences of antigen binding regions of one or more antibodies. In these scenarios, the target protein system <b>520</b> can determine that the template protein sequences <b>526</b> are missing at least a portion of the antigen binding regions of one or more antibodies. The target protein system <b>520</b> can then extract an amino acid sequence included in the protein fragment sequences <b>524</b> that correspond to a missing amino acid sequence of an antigen binding region of a template protein sequence <b>526</b>. The target protein system <b>520</b> can combine the amino acid sequence obtained from the protein fragment sequence <b>524</b> with a template protein sequence <b>526</b> to generate a target protein sequence <b>528</b> that includes the template protein sequence <b>526</b> with the antigen binding region supplied by one or more of the protein fragment sequences <b>524</b>.</p><p id="p-0100" num="0099">Although not shown in the illustrative example of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, additional processing can be performed with respect to the target protein sequences <b>528</b>. For example, the target protein sequences <b>528</b> can be evaluated to determine whether the target protein sequences <b>528</b> have a specified set of characteristics. To illustrate, one or more metrics can be determined with respect to the target protein sequence(s) <b>528</b>. For example, metrics that can be determined with respect to the target protein sequences <b>528</b> can be related to characteristics of the target protein sequences <b>528</b>, such as a number of negatively charged amino acids, a number of positively charged amino acids, a number of amino acids interacting to form one or more polar regions, amino acids interacting to form one or more hydrophobic regions, one or more combinations thereof, and the like.</p><p id="p-0101" num="0100">In one or more implementations, the target protein sequences <b>528</b> can be subject to sequence filtering. The sequence filtering can parse the target protein sequences <b>528</b> to identify one or more of the target protein sequences <b>528</b> that correspond to one or more characteristics. For example, the target protein sequences <b>528</b> can be analyzed to identify amino acid sequences that have specified amino acids at particular positions. One or more of the target protein sequences <b>528</b> can also be filtered to identify amino acid sequences having one or more particular strings or regions of amino acids. In various implementations, the target protein sequences <b>528</b> can be filtered to identify amino acid sequences that are associated with a set of biophysical properties based at least partly on similarities between at least one of the target protein sequences <b>528</b> and amino acid sequences of additional proteins having the set of biophysical properties.</p><p id="p-0102" num="0101">The machine learning architecture <b>502</b> can be implemented by one or more computing devices <b>530</b>. The one or more computing devices <b>530</b> can include one or more server computing devices, one or more desktop computing devices, one or more laptop computing devices, one or more tablet computing devices, one or more mobile computing devices, or combinations thereof. In certain implementations, at least a portion of the one or more computing devices <b>530</b> can be implemented in a distributed computing environment. For example, at least a portion of the one or more computing devices <b>530</b> can be implemented in a cloud computing architecture. Additionally, although the illustrative example of <figref idref="DRAWINGS">FIG. <b>5</b></figref> shows an implementation of the machine learning architecture <b>530</b> that includes a generative adversarial network with a single generating component and a single challenging component, in additional implementations, the machine learning architecture <b>502</b> can include multiple generative adversarial networks. Further, each generative adversarial network implemented by the machine learning architecture <b>502</b> can include one or more generating components and one or more challenging components. Also, although the illustrative example of <figref idref="DRAWINGS">FIG. <b>5</b></figref> shows the machine learning architecture <b>502</b> and the target protein system <b>520</b> as separate entities, the machine learning architecture <b>502</b> and the target protein system <b>520</b> can be implemented as a single system by the one or more computing devices <b>530</b>.</p><p id="p-0103" num="0102"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow diagram illustrating an example method <b>600</b> for producing target protein sequences using template protein sequences and position modification data, in accordance with some implementations. The method <b>600</b> can include, at operation <b>602</b>, obtaining first data indicating an amino acid sequence of a template protein that has a functional region. The functional region of the template protein can include amino acids that cause the template protein to bind with another molecule. In various examples, the functional region can have a shape that corresponds to a shape and chemical properties of another molecule. In illustrative examples, the template protein can include an antibody and the functional region can include amino acids that bind to an antigen.</p><p id="p-0104" num="0103">At operation <b>604</b>, the method <b>600</b> can include obtaining second data indicating additional amino acid sequences corresponding to additional proteins having one or more specified characteristics. The one or more specified characteristics can correspond to one or more biophysical properties. The one or more specified characteristics can also correspond to amino acid sequences that can be included in certain types of proteins. For example, the one or more specified characteristics can correspond to amino acid sequences included in human antibodies. To illustrate, the one or more specified characteristics can correspond to amino acid sequences included in framework regions of variable regions of human antibodies. Additionally, the one or more specified characteristics can correspond to amino acid sequences produced by one or more germline genes of human antibodies. The additional proteins can have similarities in relation to the template protein, but the functional region of the template protein may be absent from the additional proteins. For example, the additional proteins can correspond to antibodies, but the antibodies may not bind to the antigen that binds to the functional region of the template protein. In illustrative implementations, the template protein can be produced by a first mammal and the additional proteins can correspond to antibodies produced by a second mammal, such as a human. In these situations, the amino acid sequences included in the second data can include amino acid sequences of human antibodies. In various implementations, the second data can be used as training data for a generative adversarial network.</p><p id="p-0105" num="0104">In addition, at operation <b>606</b>, the method <b>600</b> can include determining position modification data indicating probabilities that amino acids located at positions of the template protein are modifiable. In one or more illustrative examples, the position modification data can indicate that first probabilities to modify amino acids located in a binding region are no greater than about 5% and that second probabilities to modify amino acids located in one or more portions of additional, non-binding regions of a protein are at least 40%. The position modification data can also include penalties for changing amino acids of the amino acid sequence of the template protein. In various examples, the position modification data can be based on a type of amino acid at a position of the amino acid sequence of the template protein. Additionally, the position modification data can be based on a type of amino acid that is replacing an amino acid located at a position of the template protein. For example, the position modification data can indicate a first penalty for modifying amino acids of the template protein having one or more hydrophobic regions and a second penalty that is different than the first penalty for modifying an amino acid of the template protein that is positively charged. Further, the position modification data can indicate a first penalty for modifying an amino acid of the template protein having one or more hydrophobic regions to another amino acid having one or more hydrophobic regions and a second penalty that is different from the first penalty for modifying the amino acid of the template protein having one or more hydrophobic regions to a positively charged amino acid.</p><p id="p-0106" num="0105">Further, at operation <b>608</b>, the method <b>600</b> can include generating amino acid sequences that are variants of the amino acid sequence of the template protein and that have at least a portion of the one or more specified characteristics. The amino acid sequences of the target proteins can be generated using one or more machine learning techniques. In various examples, the amino acid sequences of the variant proteins can be produced using a conditional generative adversarial network.</p><p id="p-0107" num="0106">The amino acid sequences of the variant proteins can have a region that corresponds to the functional region of the template protein, but that have supporting scaffolds or underlying structures, such as one or more framework regions, that are different from that of the template protein. For example, the template protein can be an antibody that binds to an antigen, while the variant proteins can include antibodies having one or more features that are different from features of the template protein that also bind to the antigen, but would not otherwise have a binding region for the antigen without first being modified. In an illustrative example, the template protein can include a human antibody that includes a binding region that binds to an antigen and the additional amino acid sequences can include human antibodies that have one or more biophysical properties that are different from the biophysical properties of the template protein and that do not bind to the antigen. After being trained using the additional amino acid sequences, the amino acid sequence of the template protein, and the position modification data, a generative adversarial network can produce amino acid sequences of variant antibodies that include the binding region of the template protein and that include at least a portion of the biophysical properties of the additional proteins.</p><p id="p-0108" num="0107">In additional illustrative examples, the template protein can correspond to an antibody produced by a mouse that includes a binding region that binds to an antigen. Further, the additional amino acid sequences can correspond to human antibodies that do not bind to the antigen. After being trained using the additional amino acid sequences, the amino acid sequence of the template protein, and the position modification data, a generative adversarial network can produce amino acid sequences of variant antibodies that correspond to human antibodies instead of mouse antibodies and that include the binding region of the template antibody to bind to the antigen. In various examples, the generative adversarial network can modify framework regions of the variable regions of the template mouse antibody to correspond to framework regions of human antibodies. Additionally, the generative adversarial network can produce the variant amino acid sequences of the human antibody such that the amino acid sequence of the binding region of the mouse antibody is present in the variant amino acid sequences and such that the binding region is stable and forms a shape that binds to the antigen.</p><p id="p-0109" num="0108"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flow diagram illustrating an example method <b>700</b> for producing target protein sequences using a generative adversarial network based on template protein sequences, in accordance with some implementations. At <b>702</b>, the method <b>700</b> includes obtaining first data indicating an amino acid sequence of a template antibody produced by a non-human mammal, where the template antibody binds an antigen. The template antibody can include a functional region, such as a CDR, that causes the template antibody to bind to the antigen.</p><p id="p-0110" num="0109">At operation <b>704</b>, the method <b>700</b> includes obtaining second data indicating a plurality of amino acid sequences corresponding to human antibodies. In addition, at operation <b>706</b>, the method <b>700</b> includes determining position modification data indicating probabilities that amino acids located at positions of the template antibody are modifiable. The position modification data can indicate that some positions of the template antibody have relatively high probabilities of being modified and that other positions of the template antibody can have relatively low probabilities of being modified. Positions of the template antibody having relatively high probabilities of being modified can include amino acids at positions that, if modified, are less likely to affect a functional region of the template antibody. Further, the positions of the template antibody having relatively low probabilities of being modified can include amino acids at positions that, if modified, are more likely to affect a functional region of the template antibody. In one or more illustrative examples, the position modification data can indicate that first probabilities to modify amino acids located in an antigen binding region are no greater than about 5% and that second probabilities to modify amino acids located in one or more portions of at least one of the one or more heavy chain framework regions or the one or more light chain framework regions of an antibody are at least 40%. In various examples, the position modification data can indicate penalties that are to be applied by a generative adversarial network to modification of amino acids at positions of the template protein when the generative adversarial network is generating amino acid sequences of target antibodies.</p><p id="p-0111" num="0110">At <b>708</b>, the method <b>700</b> includes generating, using a generative adversarial network, a model to produce amino acid sequences that correspond to human antibodies and that have at least a threshold amount of identity with respect to a binding region of the template antibody. Further, at <b>710</b>, the method <b>700</b> includes generating, using the model, target amino acid sequences based on the position modification data and the template antibody amino acid sequence. In illustrative examples, the amino acid sequences produced by the generative adversarial network can have a scaffolding or underlying structure of human antibodies while having a region that corresponds to the functional region of the template antibody. For example, the amino acid sequences can have constant regions having at least a threshold amount of identity with human antibodies and additional regions, such as CDRs, having a second threshold amount of identity with the functional region of the template antibody.</p><p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a diagrammatic representation of a machine <b>800</b> in the form of a computer system within which a set of instructions can be executed for causing the machine <b>800</b> to perform any one or more of the methodologies discussed herein, according to an example implementation. Specifically, <figref idref="DRAWINGS">FIG. <b>8</b></figref> shows a diagrammatic representation of the machine <b>800</b> in the example form of a computer system, within which instructions (e.g., software, a program, an application, an applet, an app, or other executable code) for causing the machine <b>800</b> to perform any one or more of the methodologies discussed herein can be executed. For example, the instructions <b>824</b> can cause the machine <b>800</b> to implement the frameworks <b>100</b>, <b>200</b>, <b>300</b>, <b>400</b>, <b>500</b> described with respect to <figref idref="DRAWINGS">FIGS. <b>1</b>, <b>2</b>, <b>3</b>, <b>4</b>, and <b>5</b></figref> respectively, and to execute the methods <b>600</b>, <b>700</b> described with respect to <figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b></figref>, respectively. Additionally, the machine <b>900</b> can include or be a part of one or more of the computing devices <b>144</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> and/or the computing devices <b>530</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0113" num="0112">The instructions <b>824</b> transform the general, non-programmed machine <b>800</b> into a particular machine <b>800</b> programmed to carry out the described and illustrated functions in the manner described. In additional implementations, the machine <b>800</b> operates as a standalone device or may be coupled (e.g., networked) to other machines. In a networked deployment, the machine <b>800</b> can operate in the capacity of a server machine or a client machine in a server-client network environment, or as a peer machine in a peer-to-peer (or distributed) network environment. The machine <b>800</b> can comprise, but not be limited to, a server computer, a client computer, a personal computer (PC), a tablet computer, a laptop computer, a netbook, a personal digital assistant (PDA), a mobile computing device, a wearable device (e.g., a smart watch), a web appliance, a network router, a network switch, a network bridge, or any machine capable of executing the instructions <b>824</b>, sequentially or otherwise, that specify actions to be taken by the machine <b>800</b>. Further, while only a single machine <b>800</b> is illustrated, the term &#x201c;machine&#x201d; shall also be taken to include a collection of machines <b>800</b> that individually or jointly execute the instructions <b>824</b> to perform any one or more of the methodologies discussed herein.</p><p id="p-0114" num="0113">Examples of computing device <b>800</b> can include logic, one or more components, circuits (e.g., modules), or mechanisms. Circuits are tangible entities configured to perform certain operations. In an example, circuits can be arranged (e.g., internally or with respect to external entities such as other circuits) in a specified manner. In an example, one or more computer systems (e.g., a standalone, client or server computer system) or one or more hardware processors (processors) can be configured by software (e.g., instructions, an application portion, or an application) as a circuit that operates to perform operations as described herein. Software can reside (1) on a non-transitory machine readable medium or (2) in a transmission signal. In an example, the software, when executed by the underlying hardware of the circuit, causes the circuit to perform the operations.</p><p id="p-0115" num="0114">A circuit can be implemented mechanically or electronically. For example, a circuit can comprise dedicated circuitry or logic that is specifically configured to perform one or more techniques such as discussed above, such as including a special-purpose processor, a field programmable gate array (FPGA) or an application-specific integrated circuit (ASIC). In an example, a circuit can comprise programmable logic (e.g., circuitry, as encompassed within a general-purpose processor or other programmable processor) that can be temporarily configured (e.g., by software) to perform the certain operations. It will be appreciated that the decision to implement a circuit mechanically (e.g., in dedicated and permanently configured circuitry), or in temporarily configured circuitry (e.g., configured by software) can be driven by cost and time considerations.</p><p id="p-0116" num="0115">Accordingly, the term &#x201c;circuit&#x201d; is understood to encompass a tangible entity, be that an entity that is physically constructed, permanently configured (e.g., hardwired), or temporarily (e.g., transitorily) configured (e.g., programmed) to operate in a specified manner or to perform specified operations. In an example, given a plurality of temporarily configured circuits, each of the circuits need not be configured or instantiated at any one instance in time. For example, where the circuits comprise a general-purpose processor configured via software, the general-purpose processor can be configured as respective different circuits at different times. Software can accordingly configure a processor, for example, to constitute a particular circuit at one instance of time and to constitute a different circuit at a different instance of time.</p><p id="p-0117" num="0116">In an example, circuits can provide information to, and receive information from, other circuits. In this example, the circuits can be regarded as being communicatively coupled to one or more other circuits. Where multiple of such circuits exist contemporaneously, communications can be achieved through signal transmission (e.g., over appropriate circuits and buses) that connect the circuits. In embodiments in which multiple circuits are configured or instantiated at different times, communications between such circuits can be achieved, for example, through the storage and retrieval of information in memory structures to which the multiple circuits have access. For example, one circuit can perform an operation and store the output of that operation in a memory device to which it is communicatively coupled. A further circuit can then, at a later time, access the memory device to retrieve and process the stored output. In various examples, circuits can be configured to initiate or receive communications with input or output devices and can operate on a resource (e.g., a collection of information).</p><p id="p-0118" num="0117">The various operations of method examples described herein can be performed, at least partially, by one or more processors that are temporarily configured (e.g., by software) or permanently configured to perform the relevant operations. Whether temporarily or permanently configured, such processors can constitute processor-implemented circuits that operate to perform one or more operations or functions. In an example, the circuits referred to herein can comprise processor-implemented circuits.</p><p id="p-0119" num="0118">Similarly, the methods described herein can be at least partially processor-implemented. For example, at least some of the operations of a method can be performed by one or processors or processor-implemented circuits. The performance of certain of the operations can be distributed among the one or more processors, not only residing within a single machine, but deployed across a number of machines. In an example, the processor or processors can be located in a single location (e.g., within a home environment, an office environment or as a server farm), while in other examples the processors can be distributed across a number of locations.</p><p id="p-0120" num="0119">The one or more processors can also operate to support performance of the relevant operations in a &#x201c;cloud computing&#x201d; environment or as a &#x201c;software as a service&#x201d; For example, at least some of the operations can be performed by a group of computers (as examples of machines including processors), with these operations being accessible via a network (e.g., the Internet) and via one or more appropriate interfaces (e.g., Application Program Interfaces (APIs).)</p><p id="p-0121" num="0120">Example embodiments (e.g., apparatus, systems, or methods) can be implemented in digital electronic circuitry, in computer hardware, in firmware, in software, or in any combination thereof. Example embodiments can be implemented using a computer program product (e.g., a computer program, tangibly embodied in an information carrier or in a machine readable medium, for execution by, or to control the operation of, data processing apparatus such as a programmable processor, a computer, or multiple computers).</p><p id="p-0122" num="0121">A computer program can be written in any form of programming language, including compiled or interpreted languages, and it can be deployed in any form, including as a stand-alone program or as a software module, subroutine, or other unit suitable for use in a computing environment. A computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communication network.</p><p id="p-0123" num="0122">In an example, operations can be performed by one or more programmable processors executing a computer program to perform functions by operating on input data and generating output. Examples of method operations can also be performed by, and example apparatus can be implemented as, special purpose logic circuitry (e.g., a field programmable gate array (FPGA) or an application-specific integrated circuit (ASIC)).</p><p id="p-0124" num="0123">The computing system can include clients and servers. A client and server are generally remote from each other and generally interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In embodiments deploying a programmable computing system, it will be appreciated that both hardware and software architectures require consideration. Specifically, it will be appreciated that the choice of whether to implement certain functionality in permanently configured hardware (e.g., an ASIC), in temporarily configured hardware (e.g., a combination of software and a programmable processor), or a combination of permanently and temporarily configured hardware can be a design choice. Below are set out hardware (e.g., computing device <b>700</b>) and software architectures that can be deployed in example embodiments.</p><p id="p-0125" num="0124">Example computing device <b>800</b> can include a processor <b>802</b> (e.g., a central processing unit CPU), a graphics processing unit (GPU) or both), a main memory <b>804</b> and a static memory <b>806</b>, some or all of which can communicate with each other via a bus <b>808</b>. The computing device <b>800</b> can further include a display unit <b>810</b>, an alphanumeric input device <b>812</b> (e.g., a keyboard), and a user interface (UI) navigation device <b>814</b> (e.g., a mouse). In an example, the display unit <b>810</b>, input device <b>812</b>, and UI navigation device <b>814</b> can be a touch screen display. The computing device <b>800</b> can additionally include a storage device (e.g., drive unit) <b>816</b>, a signal generation device <b>818</b> (e.g., a speaker), a network interface device <b>820</b>, and one or more sensors <b>821</b>, such as a global positioning system (GPS) sensor, compass, accelerometer, or other sensor.</p><p id="p-0126" num="0125">The storage device <b>816</b> can include a machine readable medium <b>822</b> (also referred to herein as a computer-readable medium) on which is stored one or more sets of data structures or instructions <b>824</b> (e.g., software) embodying or utilized by any one or more of the methodologies or functions described herein. The instructions <b>824</b> can also reside, completely or at least partially, within the main memory <b>804</b>, within static memory <b>806</b>, or within the processor <b>802</b> during execution thereof by the computing device <b>800</b>. In an example, one or any combination of the processor <b>802</b>, the main memory <b>804</b>, the static memory <b>806</b>, or the storage device <b>816</b> can constitute machine readable media.</p><p id="p-0127" num="0126">While the machine readable medium <b>822</b> is illustrated as a single medium, the term &#x201c;machine readable medium&#x201d; can include a single medium or multiple media (e.g., a centralized or distributed database, and/or associated caches and servers) that configured to store the one or more instructions <b>824</b>. The term &#x201c;machine readable medium&#x201d; can also be taken to include any tangible medium that is capable of storing, encoding, or carrying instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present disclosure or that is capable of storing, encoding or carrying data structures utilized by or associated with such instructions. The term &#x201c;machine readable medium&#x201d; can accordingly be taken to include, but not be limited to, solid-state memories, and optical and magnetic media. Specific examples of machine-readable media can include non-volatile memory, including, by way of example, semiconductor memory devices (e.g., Electrically Programmable Read-Only Memory (EPROM), Electrically Erasable Programmable Read-Only Memory (EEPROM)) and flash memory devices; magnetic disks such as internal hard disks and removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.</p><p id="p-0128" num="0127">The instructions <b>824</b> can further be transmitted or received over a communications network <b>826</b> using a transmission medium via the network interface device <b>820</b> utilizing any one of a number of transfer protocols (e.g., frame relay, IP, TCP, UDP, HTTP, etc.). Example communication networks can include a local area network (LAN), a wide area network (WAN), a packet data network (e.g., the Internet), mobile telephone networks (e.g., cellular networks), Plain Old Telephone (POTS) networks, and wireless data networks (e.g., IEEE 802.11 standards family known as Wi-Fi&#xae;, IEEE 802.16 standards family known as WiMax&#xae;), peer-to-peer (P2P) networks, among others. The term &#x201c;transmission medium&#x201d; shall be taken to include any intangible medium that is capable of storing, encoding or carrying instructions for execution by the machine, and includes digital or analog communications signals or other intangible medium to facilitate communication of such software.</p><heading id="h-0004" level="1">EXAMPLE IMPLEMENTATIONS</heading><p id="p-0129" num="0128">Implementation 1. A method comprising: obtaining, by a computing system including one or more computing devices having one or more processors and memory, first data indicating a first amino acid sequence of a template protein, the template protein including a functional region that binds to an additional molecule or that chemically reacts with the additional molecule; obtaining, by the computing system, second data indicating second amino acid sequences corresponding to additional proteins having one or more specified characteristics; obtaining, by the computing system, position modification data indicating, for individual positions of the first amino acid sequence, a probability that an amino acid located at an individual position of the first amino acid sequence is modifiable; generating, by the computing system and using a generative adversarial network, a plurality of third amino acid sequences corresponding to the additional proteins, the plurality of third amino acid sequences being variants of the first amino acid sequence of the template protein, wherein the plurality of third amino acid sequences are generated based on the first data, the second data, and the position modification data.</p><p id="p-0130" num="0129">Implementation 2. The method of implementation 1, wherein individual third amino acid sequences of the plurality of third amino acid sequences include one or more regions having at least a threshold amount of identity with respect to the functional region.</p><p id="p-0131" num="0130">Implementation 3. The method of implementation 1 or 2, wherein the first amino acid sequence includes one or more first groups of amino acids that are produced with respect to a first germline gene and the plurality of third amino acid sequences include one or more second groups of amino acids that are produced with respect to a second germline gene that is different from the first germline gene.</p><p id="p-0132" num="0131">Implementation 4. The method of implementation 3, wherein the one or more second groups of amino acids are included in at least a portion of the second amino acid sequences.</p><p id="p-0133" num="0132">Implementation 5. The method of any one of implementations 1-4, wherein the one or more specified characteristics include values of one or more biophysical properties.</p><p id="p-0134" num="0133">Implementation 6. The method of any one of implementations 1-5, wherein: the template protein is a first antibody; the additional proteins include second antibodies; and the one or more specified characteristics include one or more sequences of amino acids included in one or more framework regions of the second amino acid sequences.</p><p id="p-0135" num="0134">Implementation 7. The method of any one of implementations 1-6, wherein the template protein is produced by a mammal that is not a human and the additional proteins correspond to proteins produced by a human.</p><p id="p-0136" num="0135">Implementation 8. The method of any one of implementations 1-7, comprising: training, by the computing system, a first model using the generative adversarial network and based on the first data, the second data, and the position modification data; obtaining, by the computing system, third data indicating additional amino acid sequences of proteins having a set of biophysical properties; training, by the computing system and using the first model as a generating component of the generative adversarial network, a second model based on the third data; and generating, by the computing system and using the second model; a plurality of fourth amino acid sequences that correspond to proteins that are variants of the template protein and that have at least a threshold probability of having one or more biophysical properties of the set of biophysical properties.</p><p id="p-0137" num="0136">Implementation 9. A method comprising: obtaining, by a computing system including one or more computing devices having one or more processors and memory, first data indicating a first amino acid sequence of an antibody produced by a mammal that is different from a human, the antibody having a binding region that binds to an antigen; obtaining, by the computing system, second data indicating a plurality of second amino acid sequences with individual second amino acid sequences of the plurality of amino acid sequences corresponding to a human antibody; obtaining, by the computing system, position modification data indicating, for individual positions of the first amino acid sequence, a probability that an amino acid located at an individual position of the first amino acid sequence is modifiable; generating, by the computing system and using a generative adversarial network, a model to produce amino acid sequences having at least a first threshold amount of identity with respect to the binding region and at least a second threshold amount of identity with respect to one or more heavy chain framework regions and one or more light chain framework regions of the plurality of second amino acid sequences; and generating, by the computing system and using the model, a plurality of third amino acid sequences based on the position modification data and the first amino acid sequence.</p><p id="p-0138" num="0137">Implementation 10. The method of implementation 9, wherein the position modification data indicates that first probabilities to modify amino acids located in the binding region are no greater than about 5% and that second probabilities to modify amino acids located in one or more portions of at least one of the one or more heavy chain framework regions or the one or more light chain framework regions of the antibody are at least 40%.</p><p id="p-0139" num="0138">Implementation 11. The method of implementation 9 or 10, wherein the position modification data indicates penalties to apply to modification of amino acids of the antibody with respect to generating the plurality of third amino acid sequences.</p><p id="p-0140" num="0139">Implementation 12. The method of implementation 11, wherein the position modification data indicates that an amino acid located at a first position of the first amino acid sequence of the antibody has a first penalty for being changed to a first type of amino acid and a second penalty for being changed to a second type of amino acid.</p><p id="p-0141" num="0140">Implementation 13. The method of implementation 12, wherein the amino acid has one or more hydrophobic regions, the first type of amino acid corresponds to hydrophobic amino acids, and the second type of amino acid corresponds to positively charged amino acids.</p><p id="p-0142" num="0141">Implementation 14. A system comprising: one or more hardware processors; one or more non-transitory computer-readable storage media storing instructions that, when executed by the one or more hardware processors, cause the one or more hardware processors to perform operations comprising: obtaining first data indicating a first amino acid sequence of a template protein, the template protein including a functional region that binds to an additional molecule or that chemically reacts with the additional molecule; obtaining second data indicating second amino acid sequences corresponding to additional proteins having one or more specified characteristics; obtaining position modification data indicating, for individual positions of the first amino acid sequence, a probability that an amino acid located at an individual position of the first amino acid sequence is modifiable; generating, using a generative adversarial network, a plurality of third amino acid sequences corresponding to the additional proteins, the plurality of third amino acid sequences being variants of the first amino acid sequence of the template protein, wherein the plurality of third amino acid sequences are generated based on the first data, the second data, and the position modification data.</p><p id="p-0143" num="0142">Implementation 15. The system of implementation 14, wherein individual third amino acid sequences of the plurality of third amino acid sequences include one or more regions having at least a threshold amount of identity with respect to the functional region.</p><p id="p-0144" num="0143">Implementation 16. The system of implementation 14 or 15, wherein the first amino acid sequence includes one or more first groups of amino acids that are produced with respect to a first germline gene and the plurality of third amino acid sequences include one or more second groups of amino acids that are produced with respect to a second germline gene that is different from the first germline gene.</p><p id="p-0145" num="0144">Implementation 17. The system of implementation 16, wherein the one or more second groups of amino acids are included in at least a portion of the second amino acid sequences.</p><p id="p-0146" num="0145">Implementation 18. The system of any one of implementations 14-17, wherein the one or more specified characteristics include values of one or more biophysical properties.</p><p id="p-0147" num="0146">Implementation 19. The system of any one of implementations 14-18, wherein: the template protein is a first antibody; the additional proteins include second antibodies; and the one or more specified characteristics include one or more sequences of amino acids included in one or more framework regions of the second amino acid sequences.</p><p id="p-0148" num="0147">Implementation 20. The system of any one of implementations 14-19, wherein the template protein is produced by a mammal that is not a human and the additional proteins correspond to proteins produced by a human.</p><p id="p-0149" num="0148">Implementation 21. The system of any one of implementations 14-20, wherein the one or more non-transitory computer-readable storage media storing additional instructions that, when executed by the one or more hardware processors, cause the one or more hardware processors to perform additional operations comprising: training a first model using the generative adversarial network and based on the first data, the second data, and the position modification data; obtaining third data indicating additional amino acid sequences of proteins having a set of biophysical properties; training, using the first model as a generating component of the generative adversarial network, a second model based on the third data; and generating, using the second model, a plurality of fourth amino acid sequences that correspond to proteins that are variants of the template protein and that have at least a threshold probability of having one or more biophysical properties of the set of biophysical properties.</p><p id="p-0150" num="0149">Implementation 22. A system comprising: one or more hardware processors; one or more non-transitory computer-readable storage media storing instructions that, when executed by the one or more hardware processors, cause the one or more hardware processors to perform operations comprising: obtaining first data indicating a first amino acid sequence of an antibody produced by a mammal that is different from a human, the antibody having a binding region that binds to an antigen; obtaining second data indicating a plurality of second amino acid sequences with individual second amino acid sequences of the plurality of amino acid sequences corresponding to a human antibody; obtaining position modification data indicating, for individual positions of the first amino acid sequence, a probability that an amino acid located at an individual position of the first amino acid sequence is modifiable; generating, using a generative adversarial network, a model to produce amino acid sequences having at least a first threshold amount of identity with respect to the binding region and at least a second threshold amount of identity with respect to one or more heavy chain framework regions and one or more light chain framework regions of the plurality of second amino acid sequences; and generating, using the model, a plurality of third amino acid sequences based on the position modification data and the first amino acid sequence.</p><p id="p-0151" num="0150">Implementation 23. The system of implementation 22, wherein the position modification data indicates that first probabilities to modify amino acids located in the binding region are no greater than about 5% and that second probabilities to modify amino acids located in one or more portions of at least one of the one or more heavy chain framework regions or the one or more light chain framework regions of the antibody are at least 40%.</p><p id="p-0152" num="0151">Implementation 24. The system of implementation 22 or 23, wherein the position modification data indicates penalties to apply to modification of amino acids of the antibody with respect to generating the plurality of third amino acid sequences.</p><p id="p-0153" num="0152">Implementation 25. The system of implementation 24, wherein the position modification data indicates that an amino acid located at a first position of the first amino acid sequence of the antibody has a first penalty for being changed to a first type of amino acid and a second penalty for being changed to a second type of amino acid.</p><p id="p-0154" num="0153">Implementation 26. The system of implementation 25, wherein the amino acid has one or more hydrophobic regions, the first type of amino acid corresponds to hydrophobic amino acids, and the second type of amino acid corresponds to positively charged amino acids.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system comprising:<claim-text>one or more hardware processors;</claim-text><claim-text>one or more non-transitory computer-readable storage media storing instructions that, when executed by the one or more hardware processors, cause the one or more hardware processors to perform operations comprising:<claim-text>obtaining first data indicating a first amino acid sequence of an antibody produced by a mammal that is different from a human, the antibody having a binding region that binds to an antigen;</claim-text><claim-text>obtaining second data indicating a plurality of second amino acid sequences with individual second amino acid sequences of the plurality of amino acid sequences corresponding to a human antibody;</claim-text><claim-text>determining position modification data indicating, for individual positions of the first amino acid sequence, a probability that an amino acid located at an individual position of the first amino acid sequence is modifiable;</claim-text><claim-text>generating, using a generative adversarial network, a model to produce amino acid sequences having at least a first threshold amount of identity with respect to the binding region and at least a second threshold amount of identity with respect to one or more heavy chain framework regions and one or more light chain framework regions of the plurality of second amino acid sequences; and</claim-text><claim-text>generating, using the model, a plurality of third amino acid sequences based on the position modification data and the first amino acid sequence.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the position modification data indicates that first probabilities to modify amino acids located in the binding region are no greater than about 5% and that second probabilities to modify amino acids located in one or more portions of at least one of the one or more heavy chain framework regions or the one or more light chain framework regions of the antibody are at least 40%.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the position modification data indicates penalties to apply to modification of amino acids of the antibody with respect to generating the plurality of third amino acid sequences.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the position modification data indicates that an amino acid located at a first position of the first amino acid sequence of the antibody has a first penalty for being changed to a first type of amino acid and a second penalty for being changed to a second type of amino acid.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the amino acid has one or more hydrophobic regions, the first type of amino acid corresponds to hydrophobic amino acids, and the second type of amino acid corresponds to positively charged amino acids.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more non-transitory computer-readable storage media store additional instructions that, when executed by the one or more hardware processors, cause the one or more hardware processors to perform additional operations comprising:<claim-text>performing a training process to produce the model that includes:<claim-text>producing, by a generating component of the generative adversarial network, first amino acid sequences using amino acid sequences of template proteins and the position modification data;</claim-text><claim-text>analyzing, by a challenging component of the generative adversarial network, the first amino acid sequences with respect to amino acid sequences of target proteins to determine classification output that is provided to the generating component, the classification input indicating amounts of differences between respective first amino acid sequences and respective second amino acid sequences; and</claim-text><claim-text>determining at least one of parameters or coefficients of the model based on the amount of differences between the respective first amino acid sequences and the respective second amino acid sequences being minimized</claim-text></claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the one or more non-transitory computer-readable storage media storing additional instructions that, when executed by the one or more hardware processors, cause the one or more hardware processors to perform additional operations comprising:<claim-text>obtaining additional data indicating additional amino acid sequences of proteins having a set of biophysical properties;</claim-text><claim-text>performing an additional training process of an additional model, using the model as an additional generating component of the generative adversarial network, that includes:<claim-text>producing, by the additional generating component, third amino acid sequences using input data;</claim-text><claim-text>analyzing, by an additional challenging component of the generative adversarial network, the third amino acid sequences with respect to the additional amino acid sequences to determine additional classification output that is provided to the additional generating component, the additional classification input indicating amounts of differences between respective third amino acid sequences and respective additional amino acid sequences; and</claim-text><claim-text>determining at least one of parameters or coefficients of the additional model based on the amount of differences between the respective third amino acid sequences and the respective additional amino acid sequences being minimized</claim-text></claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A method comprising:<claim-text>obtaining, by a computing system including one or more computing devices having one or more processors and memory, first data indicating a first amino acid sequence of a template protein, the template protein including a functional region that binds to an additional molecule or that chemically reacts with the additional molecule;</claim-text><claim-text>obtaining, by the computing system, second data indicating second amino acid sequences corresponding to additional proteins having one or more specified characteristics;</claim-text><claim-text>determining, by the computing system, position modification data indicating, for individual positions of the first amino acid sequence, a probability that an amino acid located at an individual position of the first amino acid sequence is modifiable; and</claim-text><claim-text>generating, by the computing system and using a generative adversarial network, a plurality of third amino acid sequences corresponding to the additional proteins, the plurality of third amino acid sequences being variants of the first amino acid sequence of the template protein, wherein the plurality of third amino acid sequences are generated based on the first data, the second data, and the position modification data.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein individual third amino acid sequences of the plurality of third amino acid sequences include one or more regions having at least a threshold amount of identity with respect to the functional region.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first amino acid sequence includes one or more first groups of amino acids that are produced with respect to a first germline gene and the plurality of third amino acid sequences include one or more second groups of amino acids that are produced with respect to a second germline gene that is different from the first germline gene.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the one or more second groups of amino acids are included in at least a portion of the second amino acid sequences.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the one or more specified characteristics include values of one or more biophysical properties.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein:<claim-text>the template protein is a first antibody;</claim-text><claim-text>the additional proteins include second antibodies; and</claim-text><claim-text>the one or more specified characteristics include one or more sequences of amino acids included in one or more framework regions of the second amino acid sequences.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the template protein is produced by a mammal that is not a human and the additional proteins correspond to proteins produced by a human.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, comprising:<claim-text>training, by the computing system, a first model using the generative adversarial network and based on the first data, the second data, and the position modification data;</claim-text><claim-text>obtaining, by the computing system, third data indicating additional amino acid sequences of proteins having a set of biophysical properties;</claim-text><claim-text>training, by the computing system and using the first model as a generating component of the generative adversarial network, a second model based on the third data; and</claim-text><claim-text>generating, by the computing system and using the second model; a plurality of fourth amino acid sequences that correspond to proteins that are variants of the template protein and that have at least a threshold probability of having one or more biophysical properties of the set of biophysical properties.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A method comprising:<claim-text>obtaining, by a computing system including one or more computing devices having one or more processors and memory, first data indicating a first amino acid sequence of an antibody produced by a mammal that is different from a human, the antibody having a binding region that binds to an antigen;</claim-text><claim-text>obtaining, by the computing system, second data indicating a plurality of second amino acid sequences with individual second amino acid sequences of the plurality of amino acid sequences corresponding to a human antibody;</claim-text><claim-text>determining, by the computing system, position modification data indicating, for individual positions of the first amino acid sequence, a probability that an amino acid located at an individual position of the first amino acid sequence is modifiable;</claim-text><claim-text>generating, by the computing system and using a generative adversarial network, a model to produce amino acid sequences having at least a first threshold amount of identity with respect to the binding region and at least a second threshold amount of identity with respect to one or more heavy chain framework regions and one or more light chain framework regions of the plurality of second amino acid sequences; and</claim-text><claim-text>generating, by the computing system and using the model, a plurality of third amino acid sequences based on the position modification data and the first amino acid sequence.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the position modification data indicates that first probabilities to modify amino acids located in the binding region are no greater than about 5% and that second probabilities to modify amino acids located in one or more portions of at least one of the one or more heavy chain framework regions or the one or more light chain framework regions of the antibody are at least 40%.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the position modification data indicates penalties to apply to modification of amino acids of the antibody with respect to generating the plurality of third amino acid sequences.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the position modification data indicates that an amino acid located at a first position of the first amino acid sequence of the antibody has a first penalty for being changed to a first type of amino acid and a second penalty for being changed to a second type of amino acid.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the amino acid has one or more hydrophobic regions, the first type of amino acid corresponds to hydrophobic amino acids, and the second type of amino acid corresponds to positively charged amino acids.</claim-text></claim></claims></us-patent-application>
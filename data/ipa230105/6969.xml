<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230006970A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230006970</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17900907</doc-number><date>20220901</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>9</main-group><subgroup>40</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>23</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>955</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>9535</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>51</main-group><subgroup>42</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>63</main-group><subgroup>0245</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>2379</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>955</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>9535</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>63</main-group><subgroup>0421</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>51</main-group><subgroup>42</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEM AND METHOD FOR DETECTING POTENTIALLY HARMFUL DATA</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15982747</doc-number><date>20180517</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11463406</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17900907</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>ZixCorp Systems, Inc.</orgname><address><city>Dallas</city><state>TX</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Dubin</last-name><first-name>Jonathan Daniel</first-name><address><city>Milan</city><state>MI</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Foster</last-name><first-name>Christopher Dylan Bruch</first-name><address><city>Ann Arbor</city><state>MI</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method includes receiving electronic data, extracting a first identifier from the electronic data, extracting first attributes from the electronic data, and searching a database for identifiers that match the first identifier to determine a number of matching identifiers. The method also includes determining that the number of matching identifiers exceeds a first threshold and searching the database for attributes associated with each of the matching identifiers to determine a subset of matching attributes. The method further includes calculating a specificity for the subset of matching attributes, determining that the specificity of the subset of matching attributes is less than or equal to a second threshold, and creating a filter based at least in part on the determination that the specificity of the subset of matching attributes is less than or equal to the second threshold.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="188.04mm" wi="142.75mm" file="US20230006970A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="196.93mm" wi="144.78mm" file="US20230006970A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="247.73mm" wi="146.30mm" orientation="landscape" file="US20230006970A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="222.93mm" wi="138.35mm" file="US20230006970A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="71.04mm" wi="154.35mm" file="US20230006970A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This is a continuation of, and claims a benefit of priority under 35 U.S.C. &#xa7; 120 from, U.S. patent application Ser. No. 15/982,747, filed May 17, 2018, entitled &#x201c;SYSTEM AND METHOD FOR DETECTING POTENTIALLY HARMFUL DATA,&#x201d; the contents of which are fully incorporated by reference herein.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">Certain embodiments of this disclosure relate generally to systems and methods for detecting potentially harmful data, and more specifically, for creating filters to automatically detect and filter potentially harmful electronic data.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Networks allow users to share information, such as electronic data, with each other. This shared information may be harmful to the recipient. For example, a recipient may receive unsolicited information. As another example, the recipient may receive information that contains dangerous content. For instance, a recipient of information over a network may be susceptible to attacks by unauthorized users trying to gain access to sensitive information being communicated across the network. Unauthorized access to a network may compromise the security of the data and information being communicated by the network.</p><heading id="h-0004" level="1">SUMMARY OF THE DISCLOSURE</heading><p id="p-0005" num="0004">According to one embodiment, a filtering system includes an interface, one or more extraction generators, one or more specificity generators, and a filter generator. The interface receives electronic data. The one or more extraction generators extract a first identifier from the electronic data and extract first attributes from the electronic data. The one or more specificity generators search a database for identifiers that match the first identifier to determine a number of matching identifiers. The one or more specificity generators may determine that the number of matching identifiers exceeds a first threshold. The one or more specificity generators also search the database for attributes associated with each of the matching identifiers to determine a subset of matching attributes. The first attributes and the attributes associated with each of the matching identifiers each comprise the subset of matching attributes. The one or more specificity generators further calculate a specificity for the subset of matching attributes. The filter generator determines that the specificity of the subset of matching attributes is less than or equal to a second threshold and creates a filter based at least in part on the determination that the specificity of the subset of matching attributes is less than or equal to the second threshold.</p><p id="p-0006" num="0005">In particular embodiments, the electronic data is an email message. The first identifier may be associated with one of the following: an HTML pattern, a link, a domain, and a phone number. The first attributes may include one of the following: a number of links in the email message, a country where the email message originated, and a number of attachments attached to the email message.</p><p id="p-0007" num="0006">In particular embodiments, the system further includes a threat detector that applies the filter to the electronic data, detects a threat in the electronic data based at least in part on the applied filter, rejects delivery of the electronic data to the electronic data's specified destination based at least in part on the applied filter, and automatically updates the database to include the filter, wherein the filter is associated with the first identifier and the subset of matching attributes.</p><p id="p-0008" num="0007">In particular embodiments, the system further includes one or more normalization generators and one or more anonymization generators. The one or more normalization generators normalize the first identifier and normalize each of the first attributes. The one or more anonymization generators anonymize the first identifier and anonymize each of the first attributes. The one or more specificity generators may further calculate a specificity for the first attributes and calculate a specificity for the first identifier.</p><p id="p-0009" num="0008">In particular embodiments, the system further includes a probability generator that calculates a threat probability for the first attributes. Creating the filter may be based on the threat probability.</p><p id="p-0010" num="0009">In particular embodiments, calculating the specificity for the subset of matching attributes is based at least in part on the following: a number of total electronic data associated with an accepted count of each matching attribute and a number of the total electronic data associated with a rejected count of each matching attribute.</p><p id="p-0011" num="0010">In particular embodiments, the interface receives a plurality of electronic data. The first threshold is a predetermined number of matching identifiers received within a predetermined time period and the second threshold is an average attribute specificity calculated by averaging the attribute specificities associated with each of the plurality of electronic data. Each attribute specificity is calculated using all of the attributes associated with the corresponding electronic data.</p><p id="p-0012" num="0011">According to another embodiment, a method includes receiving electronic data, extracting a first identifier from the electronic data, extracting first attributes from the electronic data, and searching a database for identifiers that match the first identifier to determine a number of matching identifiers. The method also includes determining that the number of matching identifiers exceeds a first threshold and searching the database for attributes associated with each of the matching identifiers to determine a subset of matching attributes. The first attributes and the attributes associated with each of the matching identifiers may each include the subset of matching attributes. The method further includes calculating a specificity for the subset of matching attributes, determining that the specificity of the subset of matching attributes is less than or equal to a second threshold, and creating a filter based at least in part on the determination that the specificity of the subset of matching attributes is less than or equal to the second threshold.</p><p id="p-0013" num="0012">In particular embodiments, the method further includes applying the filter to the electronic data, detecting a threat in the electronic data based at least in part on the applied filter, rejecting delivery of the electronic data to the electronic data's specified destination based at least in part on the applied filter, and automatically updating the database to include the filter, wherein the filter is associated with the first identifier and the subset of matching attributes.</p><p id="p-0014" num="0013">In particular embodiments, the method further includes normalizing the first identifier, anonymizing the first identifier, calculating a specificity for the first identifier, normalizing each of the first attributes, anonymizing each of the first attributes, and calculating a specificity for the first attributes.</p><p id="p-0015" num="0014">In particular embodiments, the method further includes calculating a threat probability for the first attributes. Creating the filter may be based on the threat probability.</p><p id="p-0016" num="0015">In particular embodiments, the method further includes receiving a plurality of electronic data. The first threshold may be a predetermined number of matching identifiers received within a predetermined time period and the second threshold may be an average attribute specificity calculated by averaging the attribute specificities associated with each of the plurality of electronic data. Each attribute specificity may be calculated using all of the attributes associated with the corresponding electronic data.</p><p id="p-0017" num="0016">According to yet another embodiment, a non-transitory computer readable medium includes instructions for causing processing circuitry to receive electronic data, extract a first identifier from the electronic data, and extract first attributes from the electronic data. The instructions also cause the processing circuitry to search a database for identifiers that match the first identifier to determine a number of matching identifiers, determine that the number of matching identifiers exceeds a first threshold, and search the database for attributes associated with each of the matching identifiers to determine a subset of matching attributes. The first attributes and the attributes associated with each of the matching identifiers may each include the subset of matching attributes. The instructions further cause the processing circuitry to calculate a specificity for the subset of matching attributes, determine that the specificity of the subset of matching attributes is less than or equal to a second threshold, and create a filter based at least in part on the determination that the specificity of the subset of matching attributes is less than or equal to the second threshold.</p><p id="p-0018" num="0017">In particular embodiments, the instructions further cause the processing circuitry to dynamically update a list of the identifiers in the database based on one or more pre-determined criteria and dynamically update a list of the attributes in the database based on one or more pre-determined criteria.</p><p id="p-0019" num="0018">In particular embodiments, the instructions further cause the processing circuitry to apply the filter to the electronic data, detect a threat in the electronic data based at least in part on the applied filter, reject delivery of the electronic data to the electronic data's specified destination based at least in part on the applied filter, and automatically update the database to include the filter, wherein the filter is associated with the first identifier and the subset of matching attributes.</p><p id="p-0020" num="0019">In particular embodiments, the instructions further cause the processing circuitry to normalize the first identifier, anonymize the first identifier, calculate a specificity for the first identifier, normalize each of the first attributes, anonymize each of the first attributes, and calculate a specificity for the first attributes.</p><p id="p-0021" num="0020">In particular embodiments, the instructions further cause the processing circuitry to calculate a threat probability for the first attributes. Creating the filter may be based on the threat probability.</p><p id="p-0022" num="0021">In particular embodiments, calculating the specificity for the subset of matching attributes is based at least in part on the following: a number of total electronic data associated with an accepted count of each matching attribute and a number of the total electronic data associated with a rejected count of each matching attribute.</p><p id="p-0023" num="0022">Certain embodiments may provide one or more technical advantages. For example, certain embodiments detect threats (e.g., spam, viruses) embedded inside electronic data (e.g., email messages). As another example, certain embodiments detect threats (e.g., a new form of malware attachment or a link to a fake site) that originate from the same source with the same goal (e.g., a campaign). As another example, certain embodiments may detect identifiers associated with electronic data (e.g., email messages) that correspond to one and only one campaign. As still another example, certain embodiments may create a filter with matching attributes of messages containing a campaign identifier. As another example, certain embodiments may apply the created filter of matching attributes to electronic data to detect and block harmful data within the electronic data from reaching its specified destination.</p><p id="p-0024" num="0023">Certain embodiments may include none, some, or all of the above technical advantages. One or more other technical advantages may be readily apparent to one skilled in the art from the figures, descriptions, and claims included herein.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0025" num="0024">For a more complete understanding of the present disclosure, reference is now made to the following description, taken in conjunction with the accompanying drawings, in which:</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example system for filtering electronic data, according to certain embodiments.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example method for filtering electronic data that may be used by the system of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to some embodiments.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> illustrates an example attributes database that may be used in the embodiment of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to certain embodiments.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>3</b>B</figref> illustrates an example attributes database that may be used in the embodiment of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to certain embodiments.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example of elements that may be included in the system of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to certain embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0031" num="0030">Embodiments of the present disclosure and its advantages are best understood by referring to <figref idref="DRAWINGS">FIGS. <b>1</b> through <b>4</b></figref> of the drawings, like numerals being used for like and corresponding parts of the various drawings.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example system <b>100</b> for filtering electronic data, according to certain embodiments. System <b>100</b> includes a network <b>110</b>, an identifier engine <b>120</b>, an attribute engine <b>140</b>, a filter engine <b>160</b>, and databases <b>180</b><i>a</i>-<i>n</i>, where n represents any suitable integer.</p><p id="p-0033" num="0032">System <b>100</b> or portions thereof may be associated with an entity, which may include any entity, such as a person, business, or company, that filters electronic data. Throughout this description, this entity is referred to as the entity associated with system <b>100</b>. In one embodiment, network <b>110</b>, identifier engine <b>120</b>, attribute engine <b>140</b>, filter engine <b>160</b>, and databases <b>180</b><i>a</i>-<i>n </i>may be included within an entity and connected by network <b>110</b>. The elements of system <b>100</b> may be implemented using any suitable combination of hardware, firmware, and software.</p><p id="p-0034" num="0033">Although <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a particular arrangement of network <b>110</b>, identifier engine <b>120</b>, attribute engine <b>140</b>, filter engine <b>160</b>, and databases <b>180</b><i>a</i>-<i>n</i>, this disclosure contemplates any suitable arrangement of network <b>110</b>, identifier engine <b>120</b>, attribute engine <b>140</b>, filter engine <b>160</b>, and databases <b>180</b><i>a</i>-<i>n</i>. As an example and not by way of limitation, two or more of network <b>110</b>, identifier engine <b>120</b>, attribute engine <b>140</b>, and filter engine <b>160</b> and one or more of databases <b>180</b><i>a</i>-<i>n </i>may be connected to each other directly, bypassing network <b>110</b>. As another example, two or more of network <b>110</b>, identifier engine <b>120</b>, attribute engine <b>140</b>, and filter engine <b>160</b> and one or more of databases <b>180</b><i>a</i>-<i>n </i>may be physically or logically co-located with each other in whole or in part. Moreover, although <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a particular number of networks <b>110</b>, identifier engines <b>120</b>, attribute engines <b>140</b>, filter engines <b>160</b>, and databases <b>180</b><i>a</i>-<i>n</i>, this disclosure contemplates any suitable number of networks <b>110</b>, identifier engines <b>120</b>, attribute engines <b>140</b>, filter engines <b>160</b>, and databases <b>180</b><i>a</i>-<i>n. </i></p><p id="p-0035" num="0034">This disclosure contemplates any suitable network <b>110</b>. As an example and not by way of limitation, one or more portions of network <b>110</b> may include an ad hoc network, an intranet, an extranet, a virtual private network (VPN), a local area network (LAN), a wireless LAN (WLAN), a wide area network (WAN), a wireless WAN (WWAN), a metropolitan area network (MAN), a portion of the Internet, a portion of the Public Switched Telephone Network (PSTN), a cellular telephone network, or a combination of two or more of these. Network <b>110</b> may include one or more networks <b>110</b>. Network <b>110</b> may be any communications network, such as a private network, a public network, a connection through the internet, a mobile network, a WI-FI network, etc. One or more components of system <b>100</b> may communicate over network <b>100</b>. For example, filter engine <b>160</b> may communicate over network <b>110</b>, including receiving data from identifier engine <b>120</b>, attribute engine <b>140</b>, and/or databases <b>180</b><i>a</i>-<i>n</i>. As another example, identifier database <b>180</b><i>a </i>may receive one or more identifiers from identifier engine <b>120</b>. As still another example, attributes database <b>180</b><i>b </i>may receive one or more attributes from attribute engine <b>140</b>.</p><p id="p-0036" num="0035">In some embodiments, identifier engine <b>120</b> is a computer program for analyzing electronic data to identify characteristics (e.g., one or more identifiers) of the data. In the illustrated embodiment, identifier engine <b>120</b> includes an interface <b>122</b>, a memory <b>124</b>, and a processor <b>126</b>. Memory <b>124</b> of identifier engine <b>120</b> includes extraction generator <b>130</b>, normalization generator <b>132</b>, anonymization generator <b>134</b>, and specificity generator <b>136</b>. The elements of identifier engine <b>120</b> may be implemented using any suitable combination of hardware, firmware, and software.</p><p id="p-0037" num="0036">Identifier engine <b>120</b> may be implemented using one or more computer systems at one or more locations. Each computer system may include any appropriate input devices, output devices, mass storage media, processors, memory, or other suitable components for receiving, processing, storing, and communicating data. For example, each computer system may include a personal computer, workstation, network computer, kiosk, wireless data port, PDA, one or more IP telephones, one or more servers, a server pool, switch, router, one or more processors within these or other devices, or any other suitable processing device. Identifier engine <b>120</b> may be a stand-alone computer or may be a part of a larger network of computers associated with an entity.</p><p id="p-0038" num="0037">Interface <b>122</b> of identifier engine <b>120</b> represents any suitable computer element that can receive information from network <b>110</b>, transmit information through network <b>110</b>, perform suitable processing of the information, communicate to other components (e.g., identifier database <b>180</b><i>a</i>) of system <b>100</b>, or any combination of the preceding. For example, interface <b>122</b> may receive electronic data (e.g., an email message) from a server (e.g., a client server) external to the enterprise associated with system <b>100</b> via network <b>110</b>. As another example, interface <b>122</b> may receive electronic data from one or more databases <b>180</b><i>a</i>-<i>n </i>(e.g., a database that stores incoming email messages). As still another example, interface <b>122</b> may transmit electronic data to one or more computer programs stored in memory <b>124</b> of identifier engine <b>120</b>. Interface <b>122</b> represents any port or connection, real or virtual, including any suitable combination of hardware, firmware, and software, including protocol conversion and data processing capabilities, to communicate through a Local Area Network (&#x201c;LAN&#x201d;), Wide Area Network (&#x201c;WAN&#x201d;), or other communication system that allows the entity associated with system <b>100</b> to exchange information between components of system <b>100</b>.</p><p id="p-0039" num="0038">Memory <b>124</b> of identifier engine <b>120</b> stores, permanently and/or temporarily, received and transmitted information, as well as system software, control software, other software for identifier engine <b>120</b>, and a variety of other information. Memory <b>124</b> may store information for execution by processor <b>126</b>. In the illustrated embodiment, memory <b>124</b> stores extraction generator <b>130</b>, normalization generator <b>132</b>, anonymization generator <b>134</b>, and specificity generator <b>136</b> of identifier engine <b>120</b>. In some embodiments, identifier engine <b>120</b> may store one or more databases <b>180</b><i>a</i>-<i>n </i>(e.g., a database that stores incoming email messages and/or identifier database <b>180</b><i>a</i>).</p><p id="p-0040" num="0039">Memory <b>124</b> includes any one or a combination of volatile or non-volatile local or remote devices suitable for storing information. For example, memory <b>124</b> may include Random Access Memory (&#x201c;RAM&#x201d;), Read-only Memory (&#x201c;ROM&#x201d;), magnetic storage devices, optical storage devices, or any other suitable information storage device or a combination of these devices. Memory <b>124</b> may include any suitable information for use in the operation of identifier engine <b>120</b>. Additionally, memory <b>124</b> may be a component external to (or may be partially external to) identifier engine <b>120</b>. Memory <b>124</b> may be located at any location suitable for memory <b>124</b> to communicate with identifier engine <b>120</b>.</p><p id="p-0041" num="0040">Processor <b>126</b> of identifier engine <b>120</b> controls certain operations of identifier engine <b>120</b> by processing information received from interface <b>122</b> and memory <b>124</b> or otherwise accessed by processor <b>126</b>. Processor <b>126</b> communicatively couples to interface <b>122</b> and memory <b>124</b>. Processor <b>126</b> includes any hardware and/or software that operates to control and process information. Processor <b>126</b> may be a programmable logic device, a microcontroller, a microprocessor, any suitable processing device, or any suitable combination of the preceding. Additionally, processor <b>126</b> may be a component external to identifier engine <b>120</b>. Processor <b>126</b> may be located in any location suitable for processor <b>126</b> to communicate with identifier engine <b>120</b>. Processor <b>126</b> controls the operation of extraction generator <b>130</b>, normalization generator <b>132</b>, anonymization generator <b>134</b>, and specificity generator <b>136</b>.</p><p id="p-0042" num="0041">In the illustrated embodiment, extraction generator <b>130</b> of identifier engine <b>120</b> accesses electronic data, processes and analyzes the accessed data, and arranges this data for input into one or more components of system <b>100</b>. For example, extraction generator <b>130</b> may receive electronic data from interface <b>122</b>, extract one or more identifiers from the electronic data, and arrange the one or more identifiers for input into identifier database <b>180</b><i>a</i>. An identifier is any identifier used to identify similarities between electronic data. As an example, the same identifier may be extracted from multiple email messages, indicating potential similarities between the multiple email messages. Extraction generator <b>130</b> may search the electronic data for a list of pre-determined identifiers. The list of pre-determined identifiers may change over time. For example, the list of pre-determined identifiers may be dynamically updated based on one or more pre-determined criteria (e.g., a new action item based on a new communication protocol.) In certain embodiments, the one or more identifiers may be associated with one or more of the following: an HTML pattern, a link, a portion of a link (e.g., a domain, a subdomain, or a directory contained within a link), an action item (e.g., a phone number or email address referenced within the message), an attachment, a sending IP address, and an envelope sender.</p><p id="p-0043" num="0042">The one or more identifiers may identify a campaign (e.g., an email campaign). For example, an identifier (e.g., an attachment or a link) may originate from the same source with the same goal (e.g., a new form of malware attachment or a link to a fake medications website). In certain embodiments, the identifier may accurately identify a campaign. In some embodiments, the identifier may not correspond to a single campaign. Interface <b>122</b> may transmit the one or more identifiers to normalization generator <b>132</b>.</p><p id="p-0044" num="0043">Normalization generator <b>132</b> of identifier engine <b>120</b> normalizes electronic data received from one or more components of system <b>100</b>. In the illustrated embodiment, normalization generator <b>132</b> receives the extracted identifiers from extraction generator <b>130</b> and normalizes the identifiers that are logically equivalent. For example, extraction generator may receive email addresses john@doe.com and John@Doe.com and normalize these two email addresses so that they are recognized as being equivalent. Interface <b>122</b> may transmit the normalized identifiers to anonymization generator <b>134</b>.</p><p id="p-0045" num="0044">In the illustrated embodiment, anonymization generator <b>134</b> of identifier engine <b>120</b> anonymizes data received from one or more components of system <b>100</b>. For example, anonymization generator <b>132</b> may receive the one or more identifiers from extraction generator <b>130</b> and anonymize the one or more identifiers. As another example, anonymization generator <b>132</b> may receive the one or more normalized identifiers from normalization generator <b>132</b> and anonymize the one or more normalized identifiers. The identifiers may be anonymized to secure the data. For example, an identifier may contain client information, and the identifier may be anonymized to prevent leakage of the client information. In certain embodiments, the identifiers are anonymized through cryptographic hash functions. For example, a cryptographic hash function (e.g., SHA-256) may convert each identifier into a hash value (e.g., a unique 256-bit signature). Interface <b>122</b> may transmit the anonymized identifiers to specificity generator <b>136</b>.</p><p id="p-0046" num="0045">In certain embodiments, specificity generator <b>136</b> of identifier engine <b>120</b> determines whether the extracted identifiers identify a campaign and, based on that determination, calculates a specificity. For example, specificity generator <b>136</b> may search identifier database <b>180</b><i>a </i>for identifiers that match the one or more extracted identifiers to determine a number of matching identifiers. If the number of matching identifiers is greater than a first predetermined threshold, a specificity for the matching attributes of the received electronic data is calculated. The specificity of the matching attributes may be calculated using the specificity equation provided and described below in the description of specificity generator <b>156</b> of attribute engine <b>140</b>.</p><p id="p-0047" num="0046">In the illustrated embodiment, attribute engine <b>140</b> is a computer program for analyzing electronic data to identify characteristics (e.g., one or more attributes) of the data. In the illustrated embodiment, attribute engine <b>140</b> includes an interface <b>142</b>, a memory <b>144</b>, and a processor <b>146</b>. Memory <b>144</b> of attribute engine <b>140</b> includes extraction generator <b>150</b>, normalization generator <b>152</b>, anonymization generator <b>154</b>, and specificity generator <b>156</b>. The elements of attribute engine <b>140</b> may be implemented using any suitable combination of hardware, firmware, and software.</p><p id="p-0048" num="0047">Attribute engine <b>140</b> may be implemented using one or more computer systems at one or more locations. Each computer system may include any appropriate input devices, output devices, mass storage media, processors, memory, or other suitable components for receiving, processing, storing, and communicating data. For example, each computer system may include a personal computer, workstation, network computer, kiosk, wireless data port, PDA, one or more IP telephones, one or more servers, a server pool, switch, router, one or more processors within these or other devices, or any other suitable processing device. Attribute engine <b>140</b> may be a stand-alone computer or may be a part of a larger network of computers associated with an entity.</p><p id="p-0049" num="0048">Interface <b>142</b> of attribute engine <b>140</b> represents any suitable computer element that can receive information from network <b>110</b>, transmit information through network <b>110</b>, perform suitable processing of the information, communicate to other components (e.g., attributes database <b>180</b><i>b</i>) of system <b>100</b>, or any combination of the preceding. For example, interface <b>142</b> may receive electronic data (e.g., an email message) from a server (e.g., a client server) external to the enterprise associated with system <b>100</b> via network <b>110</b>. As another example, interface <b>142</b> may receive electronic data from one or more databases <b>180</b><i>a</i>-<i>n </i>(e.g., a database that stores incoming email messages). As still another example, interface <b>142</b> may transmit electronic data to one or more computer programs stored in memory <b>144</b> of attribute engine <b>140</b>. Interface <b>142</b> represents any port or connection, real or virtual, including any suitable combination of hardware, firmware, and software, including protocol conversion and data processing capabilities, to communicate through a Local Area Network (&#x201c;LAN&#x201d;), Wide Area Network (&#x201c;WAN&#x201d;), or other communication system that allows the entity associated with system <b>100</b> to exchange information between components of system <b>100</b>.</p><p id="p-0050" num="0049">Memory <b>144</b> of attribute engine <b>140</b> stores, permanently and/or temporarily, received and transmitted information, as well as system software, control software, other software for attribute engine <b>140</b>, and a variety of other information. Memory <b>144</b> may store information for execution by processor <b>146</b>. In the illustrated embodiment, memory <b>144</b> stores extraction generator <b>150</b>, normalization generator <b>152</b>, anonymization generator <b>154</b>, and specificity generator <b>156</b> of attribute engine <b>140</b>. In some embodiments, attribute engine <b>140</b> may store one or more databases <b>180</b><i>a</i>-<i>n </i>(e.g., a database that stores incoming email messages and/or attributes database <b>180</b><i>b</i>).</p><p id="p-0051" num="0050">Memory <b>144</b> includes any one or a combination of volatile or non-volatile local or remote devices suitable for storing information. For example, memory <b>144</b> may include Random Access Memory (&#x201c;RAM&#x201d;), Read-only Memory (&#x201c;ROM&#x201d;), magnetic storage devices, optical storage devices, or any other suitable information storage device or a combination of these devices. Memory <b>144</b> may include any suitable information for use in the operation of attribute engine <b>140</b>. Additionally, memory <b>144</b> may be a component external to (or may be partially external to) attribute engine <b>140</b>. Memory <b>144</b> may be located at any location suitable for memory <b>144</b> to communicate with attribute engine <b>140</b>.</p><p id="p-0052" num="0051">Processor <b>146</b> of attribute engine <b>140</b> controls certain operations of attribute engine <b>140</b> by processing information received from interface <b>142</b> and memory <b>144</b> or otherwise accessed by processor <b>146</b>. Processor <b>146</b> communicatively couples to interface <b>142</b> and memory <b>144</b>. Processor <b>146</b> includes any hardware and/or software that operates to control and process information. Processor <b>146</b> may be a programmable logic device, a microcontroller, a microprocessor, any suitable processing device, or any suitable combination of the preceding. Additionally, processor <b>146</b> may be a component external to attribute engine <b>140</b>. Processor <b>146</b> may be located in any location suitable for processor <b>146</b> to communicate with attribute engine <b>140</b>. Processor <b>146</b> controls the operation of extraction generator <b>150</b>, normalization generator <b>152</b>, anonymization generator <b>154</b>, specificity generator <b>156</b>, and probability generator <b>158</b>.</p><p id="p-0053" num="0052">In the illustrated embodiment, extraction generator <b>150</b> of attribute engine <b>140</b> accesses electronic data, processes and analyzes the accessed data, and arranges this data for input into one or more components of system <b>100</b>. For example, extraction generator <b>150</b> may receive electronic data from interface <b>152</b>, extract one or more attributes from the electronic data, and arrange the one or more attributes for input into attributes database <b>180</b><i>b</i>. An attribute is any characteristic or property of electronic data. For example, an attribute may be a country where an email message originated or whether the electronic data passed or failed the Sender Policy Framework (&#x201c;SPF&#x201d;).</p><p id="p-0054" num="0053">In certain embodiments, extraction generator <b>150</b> generates a value associated with each electronic data (e.g., an email message). For example, extraction generator <b>150</b> may determine that an email message contains 3 Hypertext Transfer Protocol (&#x201c;HTTP&#x201d;) links and generate a value of 3 for that particular message. In some embodiments, an attribute is a key/value pair. A key/value pair is a set of two linked data items. A key/value pair may be one of the following: a number of links in an email message, a number of attachments in an email message, or a number of emails blocked from the sender's IP address. Extraction generator <b>150</b> may search the electronic data for a list of pre-determined attributes (e.g., key/value pairs). The list of pre-determined attributes may change over time. In certain embodiments, the pre-determined list of attributes may be dynamically updated based on one or more pre-determined criteria. For example, a regular expression to search for text content may be updated to include additional variations. The one or more attributes may identify a campaign (e.g., an email campaign). Interface <b>142</b> may transmit the one or more attributes to normalization generator <b>152</b>.</p><p id="p-0055" num="0054">Normalization generator <b>152</b> of attribute engine <b>140</b> normalizes electronic data received from one or more components of system <b>100</b>. In the illustrated embodiment, normalization generator <b>152</b> receives the extracted attributes from extraction generator <b>130</b> and normalizes the attributes that are logically equivalent. Interface <b>142</b> may transmit the normalized attributes to anonymization generator <b>154</b>.</p><p id="p-0056" num="0055">In the illustrated embodiment, anonymization generator <b>154</b> of attribute engine <b>140</b> anonymizes data received from one or more components of system <b>100</b>. For example, anonymization generator <b>154</b> may receive the one or more attributes from extraction generator <b>150</b> and anonymize the one or more attributes. As another example, anonymization generator <b>154</b> may receive the one or more normalized attributes from normalization generator <b>152</b> and anonymize the one or more normalized attributes. The attributes may be anonymized to secure the data. For example, an attribute may contain client information, and the attribute may be anonymized to prevent leakage of the client information. In certain embodiments, the normalized attributes are anonymized through cryptographic hash functions. For example, a cryptographic has function (e.g., SHA-256) may convert each attribute into a hash value (e.g., a unique 256-bit signature). Interface <b>122</b> may transmit the anonymized attributes to specificity generator <b>156</b>.</p><p id="p-0057" num="0056">In certain embodiments, specificity generator <b>156</b> of attribute engine <b>140</b> determines a specificity value for each electronic data (e.g., email message, document, or text message). The specificity value for each electronic data may be calculated using the attributes found in each respective electronic data. For example, extraction generator <b>150</b> may determine that a first email message includes the following first, second, and third attributes: Links/3, Domains/3, and HTTP Secure (&#x201c;HTTPS&#x201d;) Links/4. Specificity generator <b>156</b> may calculate a specificity value for the first email message based on these three attributes. In certain embodiments, the specificity value is calculated using the following equation:</p><p id="p-0058" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Specificity=<i>P</i>(reject)&#x3a0;<sub>i-0</sub><sup>N</sup><i>P</i>(attribute/reject)+<i>P</i>(accept)&#x3a0;<sub>i-0</sub><sup>N</sup><i>P</i>(attribute/accept)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0059" num="0057">where:</p><p id="p-0060" num="0058">P (reject)=(total rejected count/total messages)</p><p id="p-0061" num="0059">P (accept)=(total accepted count/total messages)</p><p id="p-0062" num="0060">P(attribute/reject)=(rejected attribute count/total rejected count)</p><p id="p-0063" num="0061">P(attribute/accept)=(accepted attribute count/total accepted count)</p><p id="p-0064" num="0062">In the example, the first email message with the first, second, and third attributes may be one of 115 email messages received by system <b>100</b>. Thus, the total number of messages (i.e., &#x201c;total messages&#x201d;) is 115. Extraction generator <b>150</b> may determine that the first attribute, Links/3, was rejected in 15 of the 115 messages and was accepted in 10 of the 115 messages. Thus, the rejected attribute count for the first attribute is 15 and the accepted attribute count for the first attribute is 10. Extraction generator <b>150</b> may determine that the second attribute, Domains/3, was rejected in 20 of the 115 messages and was accepted in 5 of the 115 messages. Thus, the rejected attribute count for the second attribute is 20 and the accepted attribute count for the second attribute is 5. Extraction generator <b>150</b> may determine that the third attribute, HTTPS Links/4, was rejected in 5 of the 115 messages but was accepted in 23 of the 115 messages. Thus, the rejected attribute count for the third attribute is 5 and the accepted attribute count for the third attribute is 23.</p><p id="p-0065" num="0063">The 115 email messages may contain additional attributes that are not in the first email message. For example, extraction generator <b>150</b> may determine that a fourth attribute, Subject matter contains/&#x201c;Free,&#x201d; was rejected in 30 of the 115 messages and was accepted in 2 of the 115 messages. Thus, the rejected attribute count for the fourth attribute is 30 and the accepted attribute count for the fourth attribute is 2. The total rejected count in this example is 15+20+5+30, which is 70, and the total accepted count is 10+5+23+2, which is 40. The first part of the equation, P(reject)&#x3a0;<sub>i-0</sub><sup>N </sup>P (attribute/reject), is (70/110)*(15/70)*(20/70)*(5/70)=0.00278; the second part of the equation, P(accept)&#x3a0;<sub>i-0</sub><sup>N </sup>P (attribute/accept), is (40/110)*(10/70)*(5/70)*(23/70)=0.00122; and the specificity value for the first email message is 0.004.</p><p id="p-0066" num="0064">In certain embodiments, specificity generator <b>156</b> calculates an average specificity value for all electronic data. For example, system <b>100</b> may receive 2,000 email messages, and specificity generator <b>156</b> may calculate a specificity value for each of the 2,000 email messages. Specificity generator <b>156</b> may then calculate an average specificity value for the 2,000 calculated specificity values.</p><p id="p-0067" num="0065">In certain embodiments, specificity generator <b>136</b> of identifier engine <b>120</b> calculates a matching attributes specificity value using the specificity equation above. For example, specificity generator <b>136</b> may determine which attributes are included in email messages associated with an identified campaign and calculate a specificity using the matching attributes from the email messages with matching identifiers. Specificity generator <b>136</b> may then determine whether the calculated matching attribute specificity value is less than or equal to a second predetermined threshold. In certain embodiments, the second predetermined threshold is the average of the specificity values calculated for all electronic data. If the matching attributes specificity value is less than or equal to the average single electronic data specificity value, interface <b>122</b> of identifier engine <b>120</b> may send the matching attributes to filter engine <b>160</b>, which may create a filter that includes the matching attributes.</p><p id="p-0068" num="0066">In some embodiments, probability generator <b>158</b> of attribute engine <b>140</b> determines a rejection probability value for each electronic data (e.g., email message, document, or text message). The rejection probability value represents a percentage chance that system <b>100</b> should reject the electronic data. For example, extraction generator <b>150</b> may determine that a first email message includes the following first, second, and third attributes: Links/3, Domains/3, and HTTP Secure (&#x201c;HTTPS&#x201d;) Links/4. Specificity generator <b>156</b> may calculate a specificity value for the first email message based on these three attributes (e.g., 0.0076). In certain embodiments, the rejection probability value is calculated using the following equations:</p><p id="p-0069" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>n=P</i>(reject)&#x3a0;<sub>i-0</sub><sup>N</sup><i>P</i>(attribute/reject)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0070" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>rejection probability=<i>n</i>/(<i>n</i>+(<i>P</i>(accept)&#x3a0;<sub>i-0</sub><sup>N</sup><i>P</i>(attribute/accept))<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0071" num="0067">where:</p><p id="p-0072" num="0068">P (reject)=(total rejected count/total messages)</p><p id="p-0073" num="0069">P (accept)=(total accepted count/total messages)</p><p id="p-0074" num="0070">P(attribute/reject)=(rejected attribute count/total rejected count)</p><p id="p-0075" num="0071">P(attribute/accept)=(accepted attribute count/total accepted count)</p><p id="p-0076" num="0072">In this example, the value of n=P(reject)&#x3a0;<sub>i-0</sub><sup>N </sup>P (attribute/reject), is (70/110)*(15/70)*(20/70)*(5/70)=0.00278; the value of P(accept)&#x3a0;<sub>i-0</sub><sup>N </sup>P (attribute/accept), is (40/110)*(10/70)*(5/70)*(23/70)=0.00122; and the rejection probability value for the first email message is 0.00278/(0.00278+0.00122)=0.00278/(0.004)=0.70, or 70 percent (70%).</p><p id="p-0077" num="0073">In the illustrated embodiment, filter engine <b>160</b> of system <b>100</b> is a computer program for filtering electronic data. In certain embodiments, filter engine <b>160</b> creates filters, applies filters to electronic data, and determines whether to filter the electronic data (e.g., an email message) based at least in part on the applied filters. In some embodiments, filter engine <b>160</b> determines whether an email message presents a threat and, based on that determination, either rejects or delivers the email message to its intended recipient. In the illustrated embodiment, filter engine <b>160</b> includes an interface <b>162</b>, a memory <b>164</b>, and a processor <b>166</b>. Memory <b>164</b> of filter engine <b>160</b> includes filter generator <b>170</b> and threat detector <b>172</b>. The elements of filter engine <b>160</b> may be implemented using any suitable combination of hardware, firmware, and software.</p><p id="p-0078" num="0074">Filter engine <b>160</b> may be implemented using one or more computer systems at one or more locations. Each computer system may include any appropriate input devices, output devices, mass storage media, processors, memory, or other suitable components for receiving, processing, storing, and communicating data. For example, each computer system may include a personal computer, workstation, network computer, kiosk, wireless data port, PDA, one or more IP telephones, one or more servers, a server pool, switch, router, one or more processors within these or other devices, or any other suitable processing device. Filter engine <b>160</b> may be a stand-alone computer or may be a part of a larger network of computers associated with an entity.</p><p id="p-0079" num="0075">Interface <b>162</b> of filter engine <b>160</b> represents any suitable computer element that can receive information from network <b>110</b>, transmit information through network <b>110</b>, perform suitable processing of the information, communicate to other components (e.g., attribute engine <b>140</b>) of system <b>100</b>, or any combination of the preceding. For example, interface <b>162</b> may receive electronic data (e.g., an email message) from a server (e.g., a client server) external to the enterprise associated with system <b>100</b> via network <b>110</b>. As another example, interface <b>162</b> may receive electronic data from one or more databases <b>180</b><i>a</i>-<i>n </i>(e.g., filter database <b>180</b><i>c</i>). As still another example, interface <b>162</b> may transmit electronic data to one or more computer programs stored in memory <b>164</b> of filter engine <b>160</b>. Interface <b>162</b> represents any port or connection, real or virtual, including any suitable combination of hardware, firmware, and software, including protocol conversion and data processing capabilities, to communicate through a Local Area Network (&#x201c;LAN&#x201d;), Wide Area Network (&#x201c;WAN&#x201d;), or other communication system that allows the entity associated with system <b>100</b> to exchange information between components of system <b>100</b>.</p><p id="p-0080" num="0076">Memory <b>164</b> of filter engine <b>160</b> stores, permanently and/or temporarily, received and transmitted information, as well as system software, control software, other software for filter engine <b>160</b>, and a variety of other information. Memory <b>164</b> may store information for execution by processor <b>166</b>. In the illustrated embodiment, memory <b>164</b> stores filter generator <b>170</b> and threat detector <b>172</b> of filter engine <b>160</b>. In some embodiments, filter engine <b>140</b> may store one or more databases <b>180</b><i>a</i>-<i>n </i>(e.g., a database that stores incoming email messages and/or attributes database <b>180</b><i>b</i>).</p><p id="p-0081" num="0077">Memory <b>164</b> of filter engine <b>160</b> includes any one or a combination of volatile or non-volatile local or remote devices suitable for storing information. For example, memory <b>164</b> may include Random Access Memory (&#x201c;RAM&#x201d;), Read-only Memory (&#x201c;ROM&#x201d;), magnetic storage devices, optical storage devices, or any other suitable information storage device or a combination of these devices. Memory <b>164</b> may include any suitable information for use in the operation of filter engine <b>160</b>. Additionally, memory <b>164</b> may be a component external to (or may be partially external to) filter engine <b>160</b>. Memory <b>164</b> may be located at any location suitable for memory <b>164</b> to communicate with filter engine <b>160</b>.</p><p id="p-0082" num="0078">Processor <b>166</b> of filter engine <b>160</b> controls certain operations of filter engine <b>160</b> by processing information received from interface <b>162</b> and memory <b>164</b> or otherwise accessed by processor <b>166</b>. Processor <b>166</b> communicatively couples to interface <b>162</b> and memory <b>164</b>. Processor <b>166</b> includes any hardware and/or software that operates to control and process information. Processor <b>166</b> may be a programmable logic device, a microcontroller, a microprocessor, any suitable processing device, or any suitable combination of the preceding. Additionally, processor <b>166</b> may be a component external to filter engine <b>160</b>. Processor <b>164</b> may be located in any location suitable for processor <b>166</b> to communicate with filter engine <b>160</b>. Processor <b>166</b> controls the operation of filter generator <b>170</b> and threat detector <b>172</b>.</p><p id="p-0083" num="0079">In the illustrated embodiment, filter generator <b>170</b> of filter engine <b>160</b> creates filters based on data obtained from one or more components of system <b>100</b>. In some embodiments, filter generator <b>170</b> creates filters based on attributes extracted from the electronic data. For example, filter generator <b>170</b> may create a filter based on matching attributes in electronic data (e.g., email messages) associated with the same identifier. As another example, filter generator may identify a campaign based on the calculated matching attribute specificity value being below a certain threshold (e.g., an average specificity value) and create a filter based on the identified campaign. As still another example, filter generator <b>170</b> may create a filter based on the identified campaign and the rejection probability value. In certain embodiments, the rejection probability may be used to confirm that the identified campaign is actually a threat or unwanted information. In certain embodiments, another factor may be used to confirm the identified campaign is actually a threat or unwanted information, such as a manual acknowledgement by a threat analyst and/or feedback from a recipient of the electronic data.</p><p id="p-0084" num="0080">In certain embodiments, threat detector <b>172</b> of filter engine <b>160</b> detects threats in electronic data. Threat detector <b>172</b> may determine whether the electronic data presents a threat (e.g., a virus) to its intended recipient by applying one or more filters. For example, threat detector <b>172</b> may apply one or more filters created by filter generator <b>170</b> to determine whether the electronic data presents a threat. As another example, threat detector <b>172</b> may apply one or more filters stored in filter database <b>180</b><i>c </i>to determine whether the electronic data presents a threat. In certain embodiments, threat detector <b>172</b> determines whether to reject or deliver the electronic data to its intended recipient. For example, threat detector <b>172</b> may determine, based on the one or more applied filters, that an email message presents a threat and, based on this determination, reject delivery of the email. As another example, threat detector <b>172</b> may determine, based on the one or more applied filters, that an email message is free from threat and, based on this determination, deliver the email.</p><p id="p-0085" num="0081">In the illustrated embodiment, system <b>100</b> includes databases <b>180</b><i>a</i>-<i>n</i>, where n is any suitable integer. Databases <b>180</b><i>a</i>-<i>n </i>are any databases that can store data associated with system <b>100</b>. Databases <b>180</b><i>a</i>-<i>n </i>may store certain types of information for the entity associated with system <b>100</b>. In certain embodiments, databases <b>180</b><i>a</i>-<i>n </i>may be a single database. In some embodiments, each database <b>180</b><i>a</i>-<i>n </i>may store a particular type of information. For example, database <b>180</b><i>n </i>may store electronic data received by system <b>100</b>.</p><p id="p-0086" num="0082">In some embodiments, database <b>180</b><i>a </i>stores identifiers associated with system <b>100</b>. For example, database <b>180</b><i>a </i>may store identifiers extracted from extraction generator <b>130</b> of identifier engine <b>120</b>. The identifiers stored in database <b>180</b><i>a </i>may be fluid and change over time. For example, a user may add or delete one or more identifiers to or from identifier database <b>180</b><i>a</i>. As another example, system <b>100</b> may automatically add or delete one or more identifiers to or from identifier database <b>180</b><i>a </i>through machine learning.</p><p id="p-0087" num="0083">In certain embodiments, database <b>180</b><i>b </i>stores attributes associated with system <b>100</b>. For example, database <b>180</b><i>b </i>may store attributes extracted from extraction generator <b>150</b> of attribute engine <b>140</b>. The attributes stored in database <b>180</b><i>b </i>may be fluid and change over time. For example, a user may add or delete one or more attributes to or from attribute database <b>180</b><i>b</i>. As another example, system <b>100</b> may automatically add or delete one or more attributes to or from attribute database <b>180</b><i>b </i>through machine learning.</p><p id="p-0088" num="0084">Filter database <b>180</b><i>c </i>of system <b>100</b> may store one or more filters associated with system <b>100</b>. For example, filter database <b>180</b><i>c </i>may store blacklists (e.g., an IP address blacklist or a URL/Phone/action item blacklist). As another example, filter database <b>180</b><i>c </i>may store filters created by filter generator <b>170</b>. The filters stored in database <b>180</b><i>c </i>may be fluid and change over time. For example, a user may add or delete one or more filters to or from filter database <b>180</b><i>c</i>. As another example, system <b>100</b> may automatically add or delete one or more filters to or from filter database <b>180</b><i>c </i>through machine learning (e.g., system <b>100</b> may automatically store filters created by filter generator <b>170</b> in real-time).</p><p id="p-0089" num="0085">Databases <b>180</b><i>a</i>-<i>n </i>include any one or a combination of volatile or non-volatile local or remote devices suitable for storing information. For example, databases <b>180</b><i>a</i>-<i>n </i>may include Random Access Memory (&#x201c;RAM&#x201d;), Read-only Memory (&#x201c;ROM&#x201d;), magnetic storage devices, optical storage devices, or any other suitable information storage device or a combination of these devices. While databases <b>180</b><i>a</i>-<i>n </i>are shown separate from identifier engine <b>120</b>, attribute engine <b>140</b>, and filter engine <b>160</b>, in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, databases <b>180</b><i>a</i>-<i>n </i>may be located in any location suitable for communication with identifier engine <b>120</b>, attribute engine <b>140</b>, and filter engine <b>160</b>. For example, databases <b>180</b><i>a</i>-<i>n </i>may be externally located from system <b>100</b>. As another example, identifier database <b>180</b><i>a </i>of databases <b>180</b><i>a</i>-<i>n </i>may be located in identifier engine <b>120</b>, attributes database <b>180</b><i>b </i>may be located in attribute engine <b>140</b>, and database <b>180</b><i>c </i>may be located in filter engine <b>160</b>. Although described as a database, databases <b>180</b><i>a</i>-<i>n </i>may be implemented as any suitable type of volatile or non-volatile memory. Databases <b>180</b><i>a</i>-<i>n </i>may include one or more interfaces and/or processors.</p><p id="p-0090" num="0086"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example method <b>200</b> for filtering electronic data that can be used by system <b>100</b>, according to some embodiments. Method <b>200</b> begins at step <b>205</b>. Method <b>200</b> then proceeds to step <b>210</b>, where system <b>100</b> receives electronic data (e.g., an email message). In certain embodiments, the electronic data may be received from a source external to the entity associated with system <b>100</b>. For example, the electronic data may be received from a customer of the entity associated with system <b>100</b>.</p><p id="p-0091" num="0087">At step <b>215</b>, one or more identifiers are extracted from the electronic data. Identifiers may include HTML pattern <b>216</b>, a link <b>217</b>, or another identifier <b>218</b>, such as an IP address. Method <b>200</b> may then advance to step <b>225</b>, where the one or more extracted identifiers are normalized and/or anonymized. For example, normalization generator <b>132</b> of identifier engine <b>120</b> of system <b>100</b> may normalize identifiers that are logically equivalent. As another example, anonymization generator <b>134</b> of identifier engine <b>120</b> may anonymize the identifier to secure the data. For instance, the identifier may be anonymized through cryptographic hash functions.</p><p id="p-0092" num="0088">At step <b>220</b>, one or more attributes are extracted from the received electronic data. Attributes may include a number of links in an email message <b>221</b> (e.g., 3 links), a country where the message originated <b>222</b> (e.g., USA), or another attribute <b>223</b>, such as a number of emails blocked from the sender's IP address (e.g., <b>3</b> blocked emails). In certain embodiments, the extracted attributes are key/value pairs. Method <b>200</b> may then advance to step <b>230</b>, where the one or more extracted attributes are normalized and/or anonymized. For example, normalization generator <b>152</b> of attribute engine <b>140</b> of system <b>100</b> may normalize attributes that are logically equivalent. As another example, anonymization generator <b>154</b> of attribute engine <b>140</b> may anonymize attributes to secure the data. For example, the attributes may be anonymized through cryptographic hash functions. At step <b>240</b>, a specificity is calculated for the received electronic data. In certain embodiments, the specificity value is calculated based on the specificity equation provided in the description of <figref idref="DRAWINGS">FIG. <b>1</b></figref> above. In certain embodiments, the specificities calculated for all incoming electronic data (e.g., email messages) are averaged to determine an average specificity value. The average specificity value may be updated automatically. For example, system <b>100</b> may recalculate the average specificity value in real-time after calculating the attribute specificity value for each incoming electronic data.</p><p id="p-0093" num="0089">In certain embodiments, identifier database <b>180</b><i>a </i>is searched for identifiers that match the one or more extracted identifiers to determine a number of matching identifiers. For example, identifier database <b>180</b><i>a </i>may extract a first identifier from an email message and determine that the first identifier matches a certain number (e.g., 1500) of identifiers extracted from other email messages and stored in database <b>180</b><i>a</i>. If number of matching identifiers is greater than a first predetermined threshold (e.g., 1,000), then method <b>200</b> proceeds to step <b>235</b>, where a specificity for the matching attributes of the received electronic data is calculated. If the number of matching identifiers is less than or equal to the first predetermined threshold, then the method proceeds to step <b>290</b>, where method <b>200</b> ends. The determination that the first identifier matches a certain number of identifiers extracted from other email messages may have a temporal component. For example, system may determine that the first identifier matches a certain number of identifiers extracted from other email messages within a certain time period (e.g., 5 minutes, 10 minutes, or an hour) and compare that number to the first predetermined threshold.</p><p id="p-0094" num="0090">At step <b>235</b>, a matching attribute specificity value is calculated for the received electronic data. In certain embodiments, the matching attribute specificity value is calculated based on matching attributes from multiple electronic data (e.g., multiple email messages) that have matching identifiers. For example, the first identifier of the electronic data received at step <b>210</b> may be matched to identifiers in 1,500 messages. System <b>100</b> may then determine which attributes are included in all 1,500 messages (i.e., the matching attributes) and calculate a specificity value using the matching attributes in the 1,500 messages with matching identifiers. In certain embodiments, the matching attribute specificity value is calculated based on the specificity equation provided in the description of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0095" num="0091">In certain embodiments, system <b>100</b> determines whether the matching attribute specificity value calculated at step <b>235</b> is less than or equal to a second predetermined threshold. In certain embodiments, the second predetermined threshold is the average of the specificity values calculated for each incoming electronic data (e.g., email message) at step <b>240</b>. If the matching attributes specificity value is less than or equal to the average single electronic data specificity value, method <b>200</b> advances to step <b>260</b>, where a filter may be created based at least in part on the matching attributes. If the matching attributes specificity value is greater than the average single electronic data specificity value, method <b>200</b> advances to step <b>290</b>, where method <b>200</b> ends.</p><p id="p-0096" num="0092">At step <b>245</b>, a rejection probability (e.g., a threat probability) is calculated for the received electronic data. For example, the rejection probability value may be calculated based on the rejection probability equation provided above in the description of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In certain embodiments, the rejection probability represents a probability that system <b>100</b> should reject (e.g., block) the electronic data from being delivered to its intended recipient.</p><p id="p-0097" num="0093">At step <b>250</b>, one or more identifiers, attributes, attribute specificities, and rejection probabilities may be stored in one or more databases <b>180</b><i>a</i>-<i>n</i>. For example, the identifiers extracted in step <b>215</b> from the received email may be stored in identifier database <b>180</b><i>a</i>. As another example, the attributes extracted in step <b>220</b> from the received email may be stored in attributes database <b>180</b><i>b</i>. In certain embodiments, the identifiers and attributes are stored after they have been normalized and/or anonymized in steps <b>225</b> and <b>230</b>, respectively. In some embodiments, the calculated specificities and/or probabilities may be stored in a database at step <b>250</b>. For example, the matching attributes specificity values calculated at step <b>235</b> may be stored in identifier database <b>180</b><i>a</i>. As another example, the attribute specificity values and the average attribute specificity values calculated at step <b>240</b> may be stored in attributes database <b>180</b><i>a</i>. As still another example, the rejection probabilities calculated at step <b>245</b> may be stored in attributes database <b>180</b><i>a. </i></p><p id="p-0098" num="0094">At step <b>260</b>, one or more filters are created based on the identifiers and/or attributes extracted from the received electronic data. In certain embodiments, a filter is created based at least in part on the calculated matching attribute specificity value and the calculated average specificity value. For example, if the matching attribute specificity value is less than or equal to the average specificity value, a filter may be created that includes the matching attributes. In some embodiments, a filter may be created based at least in part on the calculated rejection probability value. For example, a filter may be created using the matching attributes if the calculated rejection probability value is greater than a certain value (e.g., 50 percent or 90 percent).</p><p id="p-0099" num="0095">At step <b>270</b>, one or more filters are applied to the received electronic data. The one or more filters may include an IP blacklist <b>271</b>, a URL and/or phone blacklist <b>272</b>, or another filter <b>273</b>, such as the one or more filters created at step <b>260</b>. The one or more applied filters may be stored in filter database <b>180</b><i>c </i>of system <b>100</b>.</p><p id="p-0100" num="0096">Method <b>200</b> then proceeds to step <b>280</b>. At step <b>280</b>, system <b>100</b> determines whether a threat is detected in the received electronic data. For example, system <b>100</b> may detect a threat in the received email if the received email includes one of the filters (e.g., an item listed in IP blacklist <b>271</b> and/or the matching attributes of a created filter) applied at step <b>270</b>. If system <b>100</b> detects a threat in the electronic data, method <b>200</b> moves to step <b>281</b>, where system <b>100</b> rejects the electronic data (e.g., blocks an email message from being delivered to its recipient). If system <b>100</b> determines that the electronic data is free from threat, method <b>200</b> advances to step <b>282</b>, where the system delivers the electronic data to its recipient.</p><p id="p-0101" num="0097">Method <b>200</b> then advances to step <b>285</b>, where attributes database <b>180</b><i>b </i>may be updated for each extracted attribute based on the result of step <b>280</b>. For example, the rejected count for a particular attribute (e.g., Links/4) will be incremented by one (e.g., from <b>5</b> to <b>6</b>) in the event system <b>100</b> determines the received electronic data should be rejected (see, e.g., step <b>281</b>) and the received electronic data contains the particular attribute. Method <b>200</b> then proceeds to step <b>290</b>, where method <b>200</b> ends.</p><p id="p-0102" num="0098">Particular embodiments may repeat one or more steps of the method of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, where appropriate. Although this disclosure describes and illustrates particular steps of the method of <figref idref="DRAWINGS">FIG. <b>2</b></figref> as occurring in a particular order, this disclosure contemplates any suitable steps of the method of <figref idref="DRAWINGS">FIG. <b>2</b></figref> occurring in any suitable order. Moreover, although this disclosure describes and illustrates an example method for detecting potentially harmful data, including the particular steps of the method of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, this disclosure contemplates any suitable method for detecting potentially harmful data including any suitable steps, which may include all, some, or none of the steps of the method of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, where appropriate. Furthermore, although this disclosure describes and illustrates particular components, devices, or systems carrying out particular steps of the method of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, this disclosure contemplates any suitable combination of any suitable components, devices, or systems carrying out any suitable steps of the method of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0103" num="0099"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> illustrates an example attributes database <b>300</b> that may be used in the embodiment of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to certain embodiments. Attributes database <b>300</b> may include electronic data (e.g., messages <b>310</b><i>a</i>-<i>n</i>, where n represents any suitable integer). Message <b>310</b><i>a </i>may include attributes extracted from message <b>310</b><i>a</i>, such as attributes <b>320</b><i>a</i>, <b>320</b><i>b</i>, <b>320</b><i>c</i>, <b>320</b><i>d</i>, <b>320</b><i>e</i>, <b>320</b><i>f</i>, and <b>320</b><i>n</i>. Message <b>310</b><i>b </i>may include attributes extracted from message <b>310</b><i>b</i>, such as attributes <b>320</b><i>a</i>, <b>320</b><i>c</i>, <b>320</b><i>d</i>, <b>320</b><i>e</i>, <b>320</b><i>f</i>, and <b>320</b><i>n</i>. Message <b>310</b><i>c </i>may include attributes extracted from message <b>310</b><i>c</i>, such as attributes <b>320</b><i>a</i>, <b>320</b><i>b</i>, <b>320</b><i>e</i>, <b>320</b><i>f</i>, and <b>320</b><i>n</i>. Message <b>310</b><i>n </i>may include attributes extracted from message <b>310</b><i>n</i>, such as attributes <b>320</b><i>a</i>, <b>320</b><i>b</i>, <b>320</b><i>f</i>, and <b>320</b><i>n. </i></p><p id="p-0104" num="0100">An attribute specificity value may be calculated for each message <b>310</b><i>a</i>, message <b>310</b><i>b</i>, message <b>310</b><i>c</i>, and message <b>310</b><i>n</i>. In certain embodiments, the calculated attribute specificity values for message <b>310</b><i>a</i>, message <b>310</b><i>b</i>, message <b>310</b><i>c</i>, and message <b>310</b><i>n </i>may be averaged to determine an average specificity value. In some embodiments, the average specificity value represents the second predetermined threshold described in <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref> above.</p><p id="p-0105" num="0101"><figref idref="DRAWINGS">FIG. <b>3</b>B</figref> illustrates an example attributes database <b>350</b> that may be used in the embodiment of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to certain embodiments. Attributes <b>320</b><i>a</i>-<i>n</i>, where n represents any integer, represent the attributes extracted from messages <b>310</b><i>a</i>-<i>n </i>of <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>. The accepted count represents the number of messages <b>310</b><i>a</i>-<i>n </i>that system <b>100</b> accepted (see step <b>282</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>). The rejected count represents the number of messages <b>310</b><i>a</i>-<i>n </i>that system <b>100</b> rejected (see step <b>281</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>).</p><p id="p-0106" num="0102">Attribute <b>320</b><i>a </i>is the key/value pair Links/3, which represents 3 links extracted from the electronic data. The accepted count for Links/3 from messages <b>310</b><i>a</i>-<i>n </i>of <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> is 10 and the rejected count is 15. Attribute <b>320</b><i>b </i>is the key/value pair Domains/3, which represents 3 domains extracted from the electronic data. The accepted count for Domains/3 from messages <b>310</b><i>a</i>-<i>n </i>of <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> is 5 and the rejected count is 20. Attribute <b>320</b><i>c </i>is the key/value pair Subject contains/&#x201c;Free&#x201d;, which represents the term &#x201c;Free&#x201d; extracted from the subject of the electronic data. The accepted count for Subject contains/&#x201c;Free&#x201d; from messages <b>310</b><i>a</i>-<i>n </i>of <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> is 2 and the rejected count is 30. Attribute <b>320</b><i>n </i>is the key/value pair HTTP Links/4, which represents 4 HTTP links extracted from the subject of the electronic data. The accepted count for HTTP Links/4 from messages <b>310</b><i>a</i>-<i>n </i>of <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> is 28 and the rejected count is 5. The total accepted count for all messages is 45 and the total rejected count for all messages is 70. These values are used for the specificity and probability equations described above in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0107" num="0103"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example of elements <b>400</b> that may be included in system <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to certain embodiments. For example, any of network <b>110</b>, identifier engine <b>120</b>, attribute engine <b>140</b>, filter engine <b>160</b>, and/or databases <b>180</b><i>a</i>-<i>n </i>may include one or more interface(s) <b>410</b>, processing circuitry <b>420</b>, memory(ies) <b>430</b>, and/or other suitable element(s). Interface <b>410</b> receives input, sends output, processes the input and/or output, and/or performs other suitable operation. Interface <b>410</b> may comprise hardware and/or software.</p><p id="p-0108" num="0104">Processing circuitry <b>420</b> performs or manages the operations of the component. Processing circuitry <b>420</b> may include hardware and/or software. Examples of a processing circuitry include one or more computers, one or more microprocessors, one or more applications, etc. In certain embodiments, processing circuitry <b>420</b> executes logic (e.g., instructions) to perform actions (e.g., operations), such as generating output from input. The logic executed by processing circuitry <b>520</b> may be encoded in one or more tangible, non-transitory computer readable media (such as memory <b>530</b>). For example, the logic may comprise a computer program, software, computer executable instructions, and/or instructions capable of being executed by a computer. In particular embodiments, the operations of the embodiments may be performed by one or more computer readable media storing, embodied with, and/or encoded with a computer program and/or having a stored and/or an encoded computer program.</p><p id="p-0109" num="0105">Memory <b>430</b> (or memory unit) stores information. Memory <b>430</b> may comprise one or more non-transitory, tangible, computer-readable, and/or computer-executable storage media. Examples of memory <b>430</b> include computer memory (for example, Random Access Memory (RAM) or Read Only Memory (ROM)), mass storage media (for example, a hard disk), removable storage media (for example, a Compact Disk (CD) or a Digital Video Disk (DVD)), database and/or network storage (for example, a server), and/or other computer-readable medium.</p><p id="p-0110" num="0106">While several embodiments have been provided in the present disclosure, it should be understood that the disclosed systems and methods might be embodied in many other specific forms without departing from the spirit or scope of the present disclosure. The present examples are to be considered as illustrative and not restrictive, and the intention is not to be limited to the details given herein. For example, the various elements or components may be combined or integrated in another system or certain features may be omitted, or not implemented.</p><p id="p-0111" num="0107">Herein, &#x201c;or&#x201d; is inclusive and not exclusive, unless expressly indicated otherwise or indicated otherwise by context. Therefore, herein, &#x201c;A or B&#x201d; means &#x201c;A, B, or both,&#x201d; unless expressly indicated otherwise or indicated otherwise by context. Moreover, &#x201c;and&#x201d; is both joint and several, unless expressly indicated otherwise or indicated otherwise by context. Therefore, herein, &#x201c;A and B&#x201d; means &#x201c;A and B, jointly or severally,&#x201d; unless expressly indicated otherwise or indicated otherwise by context.</p><p id="p-0112" num="0108">In addition, techniques, systems, subsystems, and methods described and illustrated in the various embodiments as discrete or separate may be combined or integrated with other systems, modules, techniques, or methods without departing from the scope of the present disclosure. Other items shown or discussed as coupled or directly coupled or communicating with each other may be indirectly coupled or communicating through some interface, device, or intermediate component whether electrically, mechanically, or otherwise. Other examples of changes, substitutions, and alterations are ascertainable by one skilled in the art and could be made without departing from the spirit and scope disclosed herein.</p><p id="p-0113" num="0109">To aid the Patent Office, and any readers of any patent issued on this application in interpreting the claims appended hereto, applicant notes that it does not intend any of the appended claims to invoke 35 U.S.C. &#xa7; 112(f) as it exists on the date of filing hereof unless the words &#x201c;means for&#x201d; or &#x201c;step for&#x201d; are explicitly used in the particular claim.</p><p id="p-0114" num="0110">The scope of this disclosure encompasses all changes, substitutions, variations, alterations, and modifications to the example embodiments described or illustrated herein that a person having ordinary skill in the art would comprehend. The scope of this disclosure is not limited to the example embodiments described or illustrated herein. Moreover, although this disclosure describes and illustrates respective embodiments herein as including particular components, elements, feature, functions, operations, or steps, any of these embodiments may include any combination or permutation of any of the components, elements, features, functions, operations, or steps described or illustrated anywhere herein that a person having ordinary skill in the art would comprehend. Furthermore, reference in the appended claims to an apparatus or system or a component of an apparatus or system being adapted to, arranged to, capable of, configured to, enabled to, operable to, or operative to perform a particular function encompasses that apparatus, system, component, whether or not it or that particular function is activated, turned on, or unlocked, as long as that apparatus, system, or component is so adapted, arranged, capable, configured, enabled, operable, or operative. Additionally, although this disclosure describes or illustrates particular embodiments as providing particular advantages, particular embodiments may provide none, some, or all of these advantages.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A filtering system, comprising:<claim-text>a processor;</claim-text><claim-text>a non-transitory computer readable medium, comprising instruction for:<claim-text>obtaining a first identifier extracted from first electronic data;</claim-text><claim-text>determining a number of matching identifiers for the first identifier from a set of identifiers;</claim-text><claim-text>when the number of matching identifiers exceeds a threshold, extracting a first set of attributes from the first electronic data;</claim-text><claim-text>determining a specificity of each of the set of attributes;</claim-text><claim-text>generating a filter based on the set of attributes and the specificity determined for each of the set of attributes; and</claim-text><claim-text>applying the filter to second electronic data to reject or accept second electronic data.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The filtering system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein applying the filter to second electronic data comprises determining a rejection probability associated with the second electronic data.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The filtering system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the set of identifiers were extracted from received electronic data.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The filtering system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the specificity of each of the set of attributes is determined based on matching attributes from multiple electronic data.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The filtering system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first electronic data is the same as the second electronic data.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The filtering system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second electronic data is an email message.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The filtering system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first identifier is an HTML pattern, a link, a domain, or a phone number.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A method, comprising:<claim-text>obtaining a first identifier extracted from first electronic data;</claim-text><claim-text>determining a number of matching identifiers for the first identifier from a set of identifiers;</claim-text><claim-text>when the number of matching identifiers exceeds a threshold, extracting a first set of attributes from the first electronic data;</claim-text><claim-text>determining a specificity of each of the set of attributes;</claim-text><claim-text>generating a filter based on the set of attributes and the specificity determined for each of the set of attributes; and</claim-text><claim-text>applying the filter to second electronic data to reject or accept second electronic data.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein applying the filter to second electronic data comprises determining a rejection probability associated with the second electronic data.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the set of identifiers were extracted from received electronic data.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the specificity of each of the set of attributes is determined based on matching attributes from multiple electronic data.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first electronic data is the same as the second electronic data.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the second electronic data is an email message.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first identifier is an HTML pattern, a link, a domain, or a phone number.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A non-transitory computer readable medium comprising instructions for:<claim-text>obtaining a first identifier extracted from first electronic data;</claim-text><claim-text>determining a number of matching identifiers for the first identifier from a set of identifiers;</claim-text><claim-text>when the number of matching identifiers exceeds a threshold, extracting a first set of attributes from the first electronic data;</claim-text><claim-text>determining a specificity of each of the set of attributes;</claim-text><claim-text>generating a filter based on the set of attributes and the specificity determined for each of the set of attributes; and</claim-text><claim-text>applying the filter to second electronic data to reject or accept second electronic data.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein applying the filter to second electronic data comprises determining a rejection probability associated with the second electronic data.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the set of identifiers were extracted from received electronic data.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the specificity of each of the set of attributes is determined based on matching attributes from multiple electronic data.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the first electronic data is the same as the second electronic data.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the second electronic data is an email message.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the first identifier is an HTML pattern, a link, a domain, or a phone number.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004823A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004823</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17363249</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>02</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>9032</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>022</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>90332</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">DISCOVERING NEW QUESTION AND ANSWER KNOWLEDGE FROM CONVERSATION</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>International Business Machines Corporation</orgname><address><city>Armonk</city><state>NY</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Mei</last-name><first-name>Lijun</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Li</last-name><first-name>Qi Cheng</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Han</last-name><first-name>Xue</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Zhou</last-name><first-name>Xin</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Huang</last-name><first-name>Zi Ming</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>Dang</last-name><first-name>Ya Bin</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">New question and answer (QA) pairs can be automatically discovered from a corpus of data such as online chats and conversations. Newly discovered QA pairs can augment QA database, which can be used by a computer processor or device, e.g., by a chatbot, an automated machine, and/or another. Existing QA knowledge can be used to learn the structures of QA knowledge distribution in conversations, and new QA knowledge can be automatically learned through the structure of learned QA knowledge distribution in conversations. The structure of learned QA knowledge distribution can be refined by adding more semantics based on labeled data.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="123.36mm" wi="140.63mm" file="US20230004823A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="205.57mm" wi="143.43mm" orientation="landscape" file="US20230004823A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="142.66mm" wi="143.85mm" orientation="landscape" file="US20230004823A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="142.24mm" wi="143.09mm" orientation="landscape" file="US20230004823A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="181.69mm" wi="129.62mm" orientation="landscape" file="US20230004823A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="190.58mm" wi="115.91mm" orientation="landscape" file="US20230004823A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="152.23mm" wi="153.08mm" orientation="landscape" file="US20230004823A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="178.05mm" wi="152.48mm" orientation="landscape" file="US20230004823A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">The present application relates generally to computers and computer applications, and more particularly to natural language processing and discovering new question and answer knowledge from conversations, and automated processor or robot that can carry on a conversation with a user.</p><p id="p-0003" num="0002">A computer, e.g., such as one running a chatbot can conduct an on-line chat conversation, for example, by text or speech, with a user. Such a computer and/or chatbot may access or learn from existing conversations, for example, dialogs including questions and answers, to continue to tune and test, to improve itself. For instance, a chatbot that provides customer care experiences may need to recognize and follow various goal-driven patterns in conversations in servicing a customer.</p><heading id="h-0002" level="1">BRIEF SUMMARY</heading><p id="p-0004" num="0003">The summary of the disclosure is given to aid understanding of a computer system and method of discovering new question and answer knowledge from conversations, and not with an intent to limit the disclosure or the invention. It should be understood that various aspects and features of the disclosure may advantageously be used separately in some instances, or in combination with other aspects and features of the disclosure in other instances. Accordingly, variations and modifications may be made to the computer system and/or their method of operation to achieve different effects.</p><p id="p-0005" num="0004">A system of discovering new question and answer knowledge from conversation, in an aspect, can include a processor and a memory device coupled with the processor. The processor can be configured to receive a question and answer pair including a question and a corresponding answer. The processor can also be configured to search a corpus of conversations to find first conversation segments containing the question and answer pair, the conversation segments containing statements including the question, the answer and intermediate statements in-between the question and the corresponding answer. The processor can also be configured to tag the statements in the first conversation segments with dialog labels. For example, the first conversation segments can be transformed into sequences of dialog labels, a sequence of dialog labels representing a question and answer structure pattern of a first conversation segment, where question and answer structure patterns are formed respectively corresponding to the first conversation segments. The processor can also be configured to search the corpus of conversations to find second conversation segments having at least one of the question and answer structure patterns. For each of the question and answer structure patterns, the processor can be configured to receive labels associated with the second conversation segments. The processor can also be configured to compute effectiveness of each of the question and answer structure patterns based on the received labels. The processor can also be configured to select a question and answer structure pattern meeting an effectiveness threshold. The processor can also be configured to transform the selected question and answer structure pattern into a new question and answer.</p><p id="p-0006" num="0005">A computer-implemented method, in an aspect, can include receiving a question and answer pair including a question and a corresponding answer. The method can also include searching a corpus of conversations to find first conversation segments containing the question and answer pair. The first conversation segments can contain statements including the question and the answer and intermediate statements in-between the question and the corresponding answer. The method can also include tagging the statements in the first conversation segments with dialog labels. For example, the first conversation segments can be transformed into sequences of dialog labels. A sequence of dialog labels can represent a question and answer structure pattern of a first conversation segment, where question and answer structure patterns are formed respectively corresponding to the first conversation segments. The method can also include searching the corpus of conversations to find second conversation segments having at least one of the question and answer structure patterns. The method can also include, for each of the question and answer structure patterns, receiving labels associated with the second conversation segments. The method can also include, based on the received labels, computing effectiveness of each of the question and answer structure patterns. The method can also include selecting a question and answer structure pattern meeting an effectiveness threshold. The method can also include transforming the selected question and answer structure pattern into a new question and answer.</p><p id="p-0007" num="0006">A computer readable storage medium storing a program of instructions executable by a machine to perform one or more methods described herein also may be provided.</p><p id="p-0008" num="0007">Further features as well as the structure and operation of various embodiments are described in detail below with reference to the accompanying drawings. In the drawings, like reference numbers indicate identical or functionally similar elements.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a flow diagram showing domain-based QA pair pattern discovery in an embodiment, for example, discovering a question and answer pair.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flow diagram illustrating automatic refinement of dialog pattern in an embodiment.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow diagram illustrating a method in an embodiment of discovering question and answer pair in conversations.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram showing components of a system in one embodiment that discovers new question and answer (QA) knowledge from one or more conversations.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a schematic of an example computer or processing system that may implement a system in one embodiment.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a cloud computing environment in one embodiment.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a set of functional abstraction layers provided by cloud computing environment in one embodiment of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0016" num="0015">Systems and methods can be provided, which can automatically identify, decompose, model and automate question and answer (QA) patterns and provide for fine-grained learning and orchestration at runtime. By way of example, customer care experience is one example area, where conversations are often composed of various goal-driven flow and add-on flow patterns. In one or more embodiments, systems and methods can discover QA pair structure patterns, which can support subject matter expert (SME) building QA knowledge from on-going large-scale conversations. The systems and methods in one or more embodiments can leverage existing QA knowledge to learn the typical structures of QA knowledge distribution in conversations, automatically discover new QA knowledge through the structure of learned QA knowledge distribution in conversations, and refine the structure of learned QA knowledge distribution by adding more semantics based on labeled data.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a flow diagram showing domain-based QA pair pattern discovery in an embodiment, for example, discovering a question and answer pair. The component shown can be implement and/or run on one or more computer processors, e.g., hardware processors. One or more hardware processors, for example, may include components such as programmable logic devices, microcontrollers, memory devices, and/or other hardware components, which may be configured to perform respective tasks described in the present disclosure. Coupled memory devices may be configured to selectively store instructions executable by one or more hardware processors.</p><p id="p-0018" num="0017">A processor may be a central processing unit (CPU), a graphics processing unit (GPU), a field programmable gate array (FPGA), an application specific integrated circuit (ASIC), another suitable processing component or device, or one or more combinations thereof. The processor may be coupled with a memory device. The memory device may include random access memory (RAM), read-only memory (ROM) or another memory device, and may store data and/or processor instructions for implementing various functionalities associated with the methods and/or systems described herein. The processor may execute computer instructions stored in the memory or received from another computer device or medium.</p><p id="p-0019" num="0018">In an embodiment, a conversation segment starts from an identified question utterance and ends at an answer utterance, include all dialog utterances between the question utterance and answer utterance. In an embodiment, an existing corpus of conversations or dialogs, for example switch board corpus or dialog corpus or data including dialogs, for example, question and answer type of conversations, which have been tagged can be used. For instance, existing databases may include labeled dialogs or utterances (e.g., referred to as dialog labels). For instance, Dialog Act Markup in Several Layers (DAMSL) is an example methodology, which includes annotated dialogs. By way of example, an existing dialog labeling methodology uses the following labels that annotate statements or utterances in a dialog to indicate the types of statements: statement-non-opinion (e.g., &#x201c;me, I'm in the legal department&#x201d;), acknowledge (backchannel) (e.g., &#x201c;Uh-huh&#x201d;), statement-opinion (e.g., &#x201c;I think it's great&#x201d;), agree/accept (e.g., &#x201c;That's exactly it&#x201d;), abandoned or turn-exit (e.g., &#x201c;So, --&#x201d;), appreciation (e.g., &#x201c;I can imagine&#x201d;), yes-no-question (e.g., &#x201c;Do you have any special training?&#x201d;), non-verbal (e.g., [Laughter], [Throat_clearing]), yes answer (e.g., &#x201c;Yes&#x201d;), conventional-closing (e.g., &#x201c;Well, it's been nice talking to you&#x201d;), uninterpretable (e.g., &#x201c;But, uh, yeah&#x201d;, wh-question (e.g., &#x201c;Well, how old is it?&#x201d;), no answers (e.g., &#x201c;No&#x201d;), response acknowledgment (e.g., &#x201c;Oh, okay&#x201d;), hedge (e.g., &#x201c;I don't know if I'm making any sense or not&#x201d;), declarative yes-no-question (e.g., &#x201c;So you can afford to get it?&#x201d;), other (e.g., &#x201c;Well, give me a break, you know&#x201d;), backchannel in question form (e.g., &#x201c;Is that right?&#x201d;), quotation.</p><p id="p-0020" num="0019">An example of a conversation or dialog can include a conversation or chat between a customer and an automated online customer service (e.g., a chatbot) for providing a service to the customer. For instance, a customer can type in or utter a question, and a chatbot can automatically answer the question or ask further questions, carrying on a dialog with the customer, in order to provide the answer. The chatbot, for example, can use natural language processing and machine learning techniques for conversing with the user. In an embodiment, a question and answer dialog can be discovered and saved for future use, for instance, in servicing a customer online. For instance, an automated processor or a robot may provide answers to a customer's questions on based on the discovered similar dialog.</p><p id="p-0021" num="0020">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, at <b>102</b>, there can exist a corpus of pre-defined (e.g., manually defined) QA pairs, which can be used. For instance, one or more pre-defined QA pairs can be received.</p><p id="p-0022" num="0021">At <b>104</b>, content search is performed. For example, a processor can search a corpus or database of conversations or chats, to find a conversation that contains a pre-defined QA pair, for example, received at <b>102</b>. This may be done for each of the pre-defined QA pairs in the corpus. For example, a conversation that contains a question and answer segment that is like the pre-defined QA pair can be identified. One or more natural language processing techniques can be used to find such conversations.</p><p id="p-0023" num="0022">At <b>122</b>, optionally, conversations that do not actually contain the QA pairs can be excluded, for example, manually. For instance, conversations segments or snippets identified or labeled as containing a QA pair may not actually have a question statement or answer statement. Such segments can be verified manually (e.g., by a user) and omitted.</p><p id="p-0024" num="0023">At <b>106</b>, a processor may perform labeling and semantic analysis of conversation segments in the conversation. For instance, sentences appearing between the question and answer like the QA pair, in the conversation can be labeled. For example, for each sentence, there can be one label such as a dialog act label or tag. A conversation segment containing the question and the answer, and one or more statements occurring in between the question and the answer can be labeled, forming a sequence of labels. For instance, a conversation segment is transformed into a sequence of labels, for example, dialog acts. A sequence of labels forms a domain-based QA pair structure pattern. There can be a plurality of such domain-base QA pair structure patterns, for example, since there can be different conversation segments which include the question and the answer. In an aspect, the labeling and analysis are domain-based, for example, pertains to a particular domain.</p><p id="p-0025" num="0024">At <b>108</b>, a processor may perform a domain-based QA pair structure pattern discovery. For example, a conversation segment containing a sequence of labels (e.g., a sequence of dialog acts) corresponding to the question and the answer, and in-between statements can be discovered. A sequence of labels for a conversation segment is also referred to as a QA pair structure pattern. There can be multiple different QA pair structure patterns.</p><p id="p-0026" num="0025">At <b>110</b>, a processor may search a conversation database or corpus containing the QA pair structure patterns, e.g., sequences of labels. For instance, the existing conversations are searched based on label patterns rather than their literary content.</p><p id="p-0027" num="0026">At <b>112</b>, a processor may sample the identified conversation segments that contain the sequence of labels to reduce the number of the identified conversation segments to a smaller set of conversation segments. In an embodiment, sampling can be performed by randomly selecting a subset of conversations that contain QA pair structure patterns, from the original whole set of conversations found at <b>110</b>.</p><p id="p-0028" num="0027">At <b>114</b>, each sample conversation can be labeled. In an embodiment, this labeling can be done manually. For instance, a user or an agent may manually determine whether the sampled conversation contains a question and a corresponding answer. For example, given a conversation segment, a user or an agent may label whether that conversation segment contains a question and a corresponding answer, for example, in the form of at least one of the QA pair structure patterns. In an embodiment, manual labeling can be performed based on human judgment on whether a question and a corresponding answer appear in the sample conversation. When labeling, the user may find a question statement, and after that, look for a corresponding answer statement.</p><p id="p-0029" num="0028">At <b>116</b>, based on the labeled data, a processor may conduct self-learning on the QA pair structure patterns. This self-learning optimizes the result of pattern discovery and can rank the patterns. For example, based on the labeled data, the processor can compute effectiveness (e.g., an effectiveness score) associated with each of the QA pair structure patterns. This self-learning is described further with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0030" num="0029">At <b>118</b>, a processor may select one or more QA pair structure patterns having a confidence score that is higher than a predefined threshold score. The predefined threshold score can be configurable.</p><p id="p-0031" num="0030">At <b>120</b>, for example, at run time of an online QA system, a processor may select the chosen QA pair structure pattern to generate a new QA pair. For example, a method disclosed herein can be enabled for an online conversation system, e.g., during a conversation conducted between a user and a customer support or service, and/or a chat application or the like running on a computer or a hardware processor. In an embodiment, a conversation carried on thusly can be checked to determine whether the conversation flow satisfies one or more of the identified QA pair structure patterns, and if yes, a QA pair identified in the conversation can be extracted and stored. For instance, question and answer from a conversation segment containing the chosen QA pair structure pattern, can be extracted. Such question and answer can be different from the question and answer received at <b>102</b>, for instance, since the discovery is performed based on the QA pair structure pattern and not the literal content of the question. For instance, the generated new QA pair can be about a different subject or topic in the domain from the question and answer received at <b>102</b>. The new QA pair can be stored, for example, for automatically conducting an online conversation with a user.</p><p id="p-0032" num="0031">In an embodiment, the methodology disclosed herein can provide a powerful tool for the subject matter expert (SME) to handle large volume of data, for example, for QA discovery. Such a tool can be used to generated more effective and accurate online automated conversations which a machine such as a computer or an autobot (e.g., a robot) can carry on with a user.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flow diagram illustrating automatic refinement of dialog pattern in an embodiment. The processor or flow shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> can be run on or implemented by one or more computer processors, for example, including one or more hardware processors. At <b>202</b>, a sequence of dialog labels or acts are discovered, e.g., a structural pattern of a conversation segment is discovered based on the labels of the statements in the conversation segment. For example, a frequent pattern of dialog acts or labels (based on a frequency threshold) can be discovered. For instance, one or more patterns that occur most frequently in conversations or based on a frequency threshold can be selected or identified.</p><p id="p-0034" num="0033">At <b>204</b>, pattern discovery effectiveness on the labeled data can be checked. A number of conversation segments can be labeled to indicate whether those conversation segments contain the structural pattern. For example, a user labeled conversation segments can be received. For instance, consider an example pattern P1 containing dialog labels or acts &#x3c;a1, a2, a3, a4&#x3e;, which occurs in conversations. Also consider another example pattern P2 containing dialog labels or acts &#x3c;a3, a5, a6, a7&#x3e;. Consider the following labeled conversations as applied to P1 pattern: C1(Y), C2(Y), C3(N), C4(Y). Out of the 4 conversation segments C1, C2, C3, and C4, a user labeled C1, C2 and C4 with &#x201c;Y&#x201d;, indicating that those conversation segments contain the example pattern P1 with a question and a corresponding answer. In this example case, 3 out of 4 conversation segments are correctly identified as containing the question and answer, and hence the effectiveness or score is &#xbe; or 0.75. Similarly, consider the following labeled conversations as applied to P2 pattern: C5(N), C6(N), C8(Y), C9(Y). In this example case, 2 out of 4 conversation segments are correctly identified as containing the question and answer, and hence the effectiveness or score associated with P2 pattern is 2/4 or 0.5.</p><p id="p-0035" num="0034">If the threshold score is set to 0.7, then only P1 is selected. Such conversation pattern can be used in a real time online conversation in conversing with a user. The method at <b>204</b> also illustrates the self-learning and choosing high confidence QA pair structure pattern or patterns shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> at <b>116</b> and <b>118</b>.</p><p id="p-0036" num="0035">For example, at <b>206</b>, it is determined whether the pattern discovery effectiveness is greater than the threshold. If yes, then the pattern is generated as a candidate at <b>210</b>. For example, consider that the threshold is 0.7. Considering the above P1 pattern as an example, and that the effectiveness of P1 pattern is computed to be 0.75, the P1 pattern is generated as a candidate pattern, for example, and saved for future use.</p><p id="p-0037" num="0036">If the pattern discovery effectiveness is not greater than the threshold, further refining of the pattern can be performed. For instance, considering the above P2 pattern as an example, P2 can be further refined into P2&#x2032; pattern. At <b>208</b>, a dialog label or act can be randomly selected and a corresponding semantics can be added. For example, in the example pattern P2 containing dialog labels or acts &#x3c;a3, a5, a6, a7&#x3e;, a label can be selected randomly, e.g., &#x3c;a5&#x3e;, and using a natural language technique, semantics such as intent associated with the statement corresponding to &#x3c;a5&#x3e; label in a conversation (e.g., any one or more original conversation where the pattern was discovered), can be extracted, and added to the pattern. So for example, P2 is transformed or refined to P2&#x2032;, which includes &#x3c;a3, &#x3c;a5, intent1&#x3e;, a6, a7&#x3e;. In this example, only conversations having the pattern of &#x3c;a3, &#x3c;a5, intent1&#x3e;, a6, a7&#x3e; would be identified, e.g., C5(N), C8(Y), C9(Y). In this example, using the refined P2&#x2032; pattern eliminated C6(N) from the above example conversations segments of P2 pattern: C5(N), C6(N), C8(Y), C9(Y), because C6 segment did not contain &#x3c;a5, intent1&#x3e;. In this example, at <b>204</b>, the effectiveness of P2&#x2032; is computed to be &#x2154; (e.g., 2 out of 3 conversations have been correctly identified as relating to the question and answer pair). At <b>206</b>, since &#x2154; is still not greater than the threshold score in this example (e.g., 0.7), the processing can repeat again at <b>208</b>.</p><p id="p-0038" num="0037">For instance, P2&#x2032; can be further transformed to P2&#x2033; to include the semantics of another randomly selected dialog label, e.g., &#x3c;a6&#x3e; to contain its intent, &#x3c;a6, intent2&#x3e;. So for example, the transformed P2&#x2033; can be &#x3c;a3, &#x3c;a5, intent1&#x3e;, &#x3c;a6, intent2&#x3e;, a7&#x3e;. Searching in C5(N), C8(Y), C9(Y) for the pattern P2&#x2033; may further eliminate additional incorrectly identified conversation segment, e.g., C5(N), for instance, if C5(N) does not include &#x3c;a6, intent2&#x3e;. So in this example, pattern discovery effectiveness associated with P2&#x2033; is computed to be 2/2, e.g., C8(Y), C9(Y). Since 2/2 is larger than 0.7, P2&#x2033; can be generated as a pattern candidate at <b>210</b>.</p><p id="p-0039" num="0038">In an embodiment, &#x3c;a3, &#x3c;a5, intent1&#x3e;, &#x3c;a6, intent2&#x3e;, a7&#x3e; can be then stored or saved in a database of QA pairs and associated structures for future use.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow diagram illustrating a method in an embodiment. The method can be performed or implemented on one or more computer processors, for example, including one or more hardware processors. At <b>302</b>, a predefined question and answer can be received. Such a question and answer pair includes a question and a corresponding answer. A question and corresponding answer are also referred to as a question and answer (QA) pair. Such predefined question and answer pair can be retrieved from a corpus of existing QA pairs.</p><p id="p-0041" num="0040">At <b>304</b>, a corpus of conversations (e.g., a database of online chats, conversations and/or the like is searched to find first conversation segments containing the question and answer pair. The conversation segments contain statements or utterances including the question and the answer and intermediate statements in-between the question and the corresponding answer. For instance, a conversation can contain a question such as &#x201c;Would length L fit size S?&#x201d; and a corresponding answer such as &#x201c;Size S is too small for length L.&#x201d; In between such question and answer in the conversation, e.g., after the question and before the answer is given, there can be one or more intermediate statements or utterances, which provide addition information for leading to the answer, e.g., &#x201c;Is the width standard?&#x201d;, &#x201c;no width is W&#x201d;, and/or others.</p><p id="p-0042" num="0041">At <b>306</b>, the statements in the first conversation segments are tagged or labeled with dialog labels. By tagging or labeling the statements, the first conversation segments can be transformed into sequences of dialog labels. For instance, a sequence of dialog labels represents a question and answer structure pattern of a first conversation segment. Question and answer (QA) structure patterns are formed respectively corresponding to the first conversation segments, for example, one QA structure pattern per one conversation segment.</p><p id="p-0043" num="0042">At <b>308</b>, the corpus of conversations is searched to find second conversation segments having at least one of the question and answer structure patterns. In an embodiment, the second conversation segments found in the search can be further sampled to reduce the number of the second conversation segments for processing.</p><p id="p-0044" num="0043">At <b>310</b>, for each of the question and answer structure patterns, labels or annotations associated with the second conversation segments are received. These labels or annotations indicate which one of the second conversation segments include a question and an answer sequence of statements that follow a question and answer structure patterns. In an embodiment, a conversation segment (e.g., a second conversation segment) has a corresponding label or annotation indicating whether that conversation segment follows a given question and answer structure pattern. The conversation segments are labeled or annotated based on each of the question and answer structure patterns. So, for example, if there are 5 different question and answer structure patterns, a conversation segment would be labeled 5 times, e.g., would have 5 labels or annotations. In an embodiment, the received labels or annotations are manually labeled labels or annotations, e.g., annotated by a user.</p><p id="p-0045" num="0044">At <b>312</b>, based on the received labels, effectiveness of each of the question and answer structure patterns is computed. For instance, for a question and answer structure pattern, an effectiveness score can be computed using the labels of the second conversation segments pertaining to that question and answer structure pattern. An example computation of such a score is described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref> at <b>204</b>.</p><p id="p-0046" num="0045">At <b>314</b>, a question and answer structure pattern meeting an effectiveness threshold is selected. The effectiveness threshold can be configurable, and/or can be predefined.</p><p id="p-0047" num="0046">At <b>316</b>, the selected question and answer structure pattern is transformed into a new question and answer pair. For example, a conversation segment (second conversation segment) having the selected question and answer structure pattern is identified, and the question and answer in that identified conversation segment is extracted as a new question and answer pair.</p><p id="p-0048" num="0047">In an embodiment, at least one of the question and answer structure patterns can be refined. For instance, a first conversation segment and/or a second conversation segment having a question and answer structure pattern can be further analyzed to determine an intent associated with one or more of the statements in the conversation segments. A natural language technique can be used to determine such intent or semantics associated with a statement or utterance. The determined intent can be added as associated with a dialog label corresponding to the statement having that intent, the dialog label which is contained in the question and answer structure pattern being refined. Example of such refinement is described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>. In an embodiment, a dialog label in the question and answer structure pattern being refined can be randomly selected as a candidate for adding intent to that dialog label (e.g., statement represented by that dialog label). In an embodiment, a question and answer structure pattern that does not meet the effectiveness threshold (e.g., at <b>314</b>), or below the effectiveness threshold, can be selected for further refinement. In an embodiment, applying the refined question and answer structure pattern to one or more of the conversation segments can eliminate those that does not contain the refined question and answer structure pattern. For instance, a conversation segment previously identified as having the question and answer structure pattern may not contain the refined version of the question and answer structure pattern, and thus that conversation segment can be eliminated or excluded from consideration.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram showing components of a system in one embodiment that discovers new question and answer (QA) knowledge from one or more conversations. One or more hardware processors <b>402</b> such as a central processing unit (CPU), a graphic process unit (GPU), and/or a Field Programmable Gate Array (FPGA), an application specific integrated circuit (ASIC), and/or another processor, may be coupled with a memory device <b>404</b>, and generate a prediction model and recommend communication opportunities. A memory device <b>404</b> may include random access memory (RAM), read-only memory (ROM) or another memory device, and may store data and/or processor instructions for implementing various functionalities associated with the methods and/or systems described herein. One or more processors <b>402</b> may execute computer instructions stored in memory <b>404</b> or received from another computer device or medium. A memory device <b>404</b> may, for example, store instructions and/or data for functioning of one or more hardware processors <b>402</b>, and may include an operating system and other program of instructions and/or data.</p><p id="p-0050" num="0049">One or more hardware processors <b>402</b> may receive input including a question and answer (QA) pair. For example, a database or corpus of data including QA pairs, which have been predefined can be received, and used to discover a new QA pair. One or more processors may also receive or access a corpus of conversations such as online chats or other form of conversations. At least one hardware processor <b>402</b> may generate a new QA pair, for example, by using QA pair structure patterns identified in conversations. Data such as conversation data, predefined QA pairs, annotated conversation data may be stored in a storage device <b>406</b> or received via a network interface <b>408</b> from a remote device, and may be temporarily loaded into a memory device <b>404</b> for generating one or more QA structure patterns and new QA pair. One or more hardware processors <b>402</b> may be coupled with interface devices such as a network interface <b>408</b> for communicating with remote systems, for example, via a network, and an input/output interface <b>410</b> for communicating with input and/or output devices such as a keyboard, mouse, display, and/or others.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a schematic of an example computer or processing system that may implement a system in one embodiment. The computer system is only one example of a suitable processing system and is not intended to suggest any limitation as to the scope of use or functionality of embodiments of the methodology described herein. The processing system shown may be operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well-known computing systems, environments, and/or configurations that may be suitable for use with the processing system shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> may include, but are not limited to, personal computer systems, server computer systems, thin clients, thick clients, handheld or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputer systems, mainframe computer systems, and distributed cloud computing environments that include any of the above systems or devices, and the like.</p><p id="p-0052" num="0051">The computer system may be described in the general context of computer system executable instructions, such as program modules, being run by a computer system. Generally, program modules may include routines, programs, objects, components, logic, data structures, and so on that perform particular tasks or implement particular abstract data types. The computer system may be practiced in distributed cloud computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed cloud computing environment, program modules may be located in both local and remote computer system storage media including memory storage devices.</p><p id="p-0053" num="0052">The components of computer system may include, but are not limited to, one or more processors or processing units <b>12</b>, a system memory <b>16</b>, and a bus <b>14</b> that couples various system components including system memory <b>16</b> to processor <b>12</b>. The processor <b>12</b> may include a module <b>30</b> that performs the methods described herein. The module <b>30</b> may be programmed into the integrated circuits of the processor <b>12</b>, or loaded from memory <b>16</b>, storage device <b>18</b>, or network <b>24</b> or combinations thereof.</p><p id="p-0054" num="0053">Bus <b>14</b> may represent one or more of any of several types of bus structures, including a memory bus or memory controller, a peripheral bus, an accelerated graphics port, and a processor or local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnects (PCI) bus.</p><p id="p-0055" num="0054">Computer system may include a variety of computer system readable media. Such media may be any available media that is accessible by computer system, and it may include both volatile and non-volatile media, removable and non-removable media.</p><p id="p-0056" num="0055">System memory <b>16</b> can include computer system readable media in the form of volatile memory, such as random access memory (RAM) and/or cache memory or others. Computer system may further include other removable/non-removable, volatile/non-volatile computer system storage media. By way of example only, storage system <b>18</b> can be provided for reading from and writing to a non-removable, non-volatile magnetic media (e.g., a &#x201c;hard drive&#x201d;). Although not shown, a magnetic disk drive for reading from and writing to a removable, non-volatile magnetic disk (e.g., a &#x201c;floppy disk&#x201d;), and an optical disk drive for reading from or writing to a removable, non-volatile optical disk such as a CD-ROM, DVD-ROM or other optical media can be provided. In such instances, each can be connected to bus <b>14</b> by one or more data media interfaces.</p><p id="p-0057" num="0056">Computer system may also communicate with one or more external devices <b>26</b> such as a keyboard, a pointing device, a display <b>28</b>, etc.; one or more devices that enable a user to interact with computer system; and/or any devices (e.g., network card, modem, etc.) that enable computer system to communicate with one or more other computing devices. Such communication can occur via Input/Output (I/O) interfaces <b>20</b>.</p><p id="p-0058" num="0057">Still yet, computer system can communicate with one or more networks <b>24</b> such as a local area network (LAN), a general wide area network (WAN), and/or a public network (e.g., the Internet) via network adapter <b>22</b>. As depicted, network adapter <b>22</b> communicates with the other components of computer system via bus <b>14</b>. It should be understood that although not shown, other hardware and/or software components could be used in conjunction with computer system. Examples include, but are not limited to: microcode, device drivers, redundant processing units, external disk drive arrays, RAID systems, tape drives, and data archival storage systems, etc.</p><p id="p-0059" num="0058">It is understood in advance that although this disclosure may include a description on cloud computing, implementation of the teachings recited herein are not limited to a cloud computing environment. Rather, embodiments of the present invention are capable of being implemented in conjunction with any other type of computing environment now known or later developed. Cloud computing is a model of service delivery for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g. networks, network bandwidth, servers, processing, memory, storage, applications, virtual machines, and services) that can be rapidly provisioned and released with minimal management effort or interaction with a provider of the service. This cloud model may include at least five characteristics, at least three service models, and at least four deployment models.</p><p id="p-0060" num="0059">Characteristics are as follows:</p><p id="p-0061" num="0060">On-demand self-service: a cloud consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with the service's provider.</p><p id="p-0062" num="0061">Broad network access: capabilities are available over a network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, laptops, and PDAs).</p><p id="p-0063" num="0062">Resource pooling: the provider's computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to demand. There is a sense of location independence in that the consumer generally has no control or knowledge over the exact location of the provided resources but may be able to specify location at a higher level of abstraction (e.g., country, state, or datacenter).</p><p id="p-0064" num="0063">Rapid elasticity: capabilities can be rapidly and elastically provisioned, in some cases automatically, to quickly scale out and rapidly released to quickly scale in. To the consumer, the capabilities available for provisioning often appear to be unlimited and can be purchased in any quantity at any time.</p><p id="p-0065" num="0064">Measured service: cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Resource usage can be monitored, controlled, and reported providing transparency for both the provider and consumer of the utilized service.</p><p id="p-0066" num="0065">Service Models are as follows:</p><p id="p-0067" num="0066">Software as a Service (SaaS): the capability provided to the consumer is to use the provider's applications running on a cloud infrastructure. The applications are accessible from various client devices through a thin client interface such as a web browser (e.g., web-based e-mail). The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited user-specific application configuration settings.</p><p id="p-0068" num="0067">Platform as a Service (PaaS): the capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages and tools supported by the provider. The consumer does not manage or control the underlying cloud infrastructure including networks, servers, operating systems, or storage, but has control over the deployed applications and possibly application hosting environment configurations.</p><p id="p-0069" num="0068">Infrastructure as a Service (IaaS): the capability provided to the consumer is to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can include operating systems and applications. The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, deployed applications, and possibly limited control of select networking components (e.g., host firewalls).</p><p id="p-0070" num="0069">Deployment Models are as follows:</p><p id="p-0071" num="0070">Private cloud: the cloud infrastructure is operated solely for an organization. It may be managed by the organization or a third party and may exist on-premises or off-premises.</p><p id="p-0072" num="0071">Community cloud: the cloud infrastructure is shared by several organizations and supports a specific community that has shared concerns (e.g., mission, security requirements, policy, and compliance considerations). It may be managed by the organizations or a third party and may exist on-premises or off-premises.</p><p id="p-0073" num="0072">Public cloud: the cloud infrastructure is made available to the general public or a large industry group and is owned by an organization selling cloud services.</p><p id="p-0074" num="0073">Hybrid cloud: the cloud infrastructure is a composition of two or more clouds (private, community, or public) that remain unique entities but are bound together by standardized or proprietary technology that enables data and application portability (e.g., cloud bursting for load-balancing between clouds).</p><p id="p-0075" num="0074">A cloud computing environment is service oriented with a focus on statelessness, low coupling, modularity, and semantic interoperability. At the heart of cloud computing is an infrastructure that includes a network of interconnected nodes.</p><p id="p-0076" num="0075">Referring now to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, illustrative cloud computing environment <b>50</b> is depicted. As shown, cloud computing environment <b>50</b> includes one or more cloud computing nodes <b>10</b> with which local computing devices used by cloud consumers, such as, for example, personal digital assistant (PDA) or cellular telephone <b>54</b>A, desktop computer <b>54</b>B, laptop computer <b>54</b>C, and/or automobile computer system <b>54</b>N may communicate. Nodes <b>10</b> may communicate with one another. They may be grouped (not shown) physically or virtually, in one or more networks, such as Private, Community, Public, or Hybrid clouds as described hereinabove, or a combination thereof. This allows cloud computing environment <b>50</b> to offer infrastructure, platforms and/or software as services for which a cloud consumer does not need to maintain resources on a local computing device. It is understood that the types of computing devices <b>54</b>A-N shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> are intended to be illustrative only and that computing nodes <b>10</b> and cloud computing environment <b>50</b> can communicate with any type of computerized device over any type of network and/or network addressable connection (e.g., using a web browser).</p><p id="p-0077" num="0076">Referring now to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, a set of functional abstraction layers provided by cloud computing environment <b>50</b> (<figref idref="DRAWINGS">FIG. <b>6</b></figref>) is shown. It should be understood in advance that the components, layers, and functions shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref> are intended to be illustrative only and embodiments of the invention are not limited thereto. As depicted, the following layers and corresponding functions are provided:</p><p id="p-0078" num="0077">Hardware and software layer <b>60</b> includes hardware and software components. Examples of hardware components include: mainframes <b>61</b>; RISC (Reduced Instruction Set Computer) architecture based servers <b>62</b>; servers <b>63</b>; blade servers <b>64</b>; storage devices <b>65</b>; and networks and networking components <b>66</b>. In some embodiments, software components include network application server software <b>67</b> and database software <b>68</b>.</p><p id="p-0079" num="0078">Virtualization layer <b>70</b> provides an abstraction layer from which the following examples of virtual entities may be provided: virtual servers <b>71</b>; virtual storage <b>72</b>; virtual networks <b>73</b>, including virtual private networks; virtual applications and operating systems <b>74</b>; and virtual clients <b>75</b>.</p><p id="p-0080" num="0079">In one example, management layer <b>80</b> may provide the functions described below. Resource provisioning <b>81</b> provides dynamic procurement of computing resources and other resources that are utilized to perform tasks within the cloud computing environment. Metering and Pricing <b>82</b> provide cost tracking as resources are utilized within the cloud computing environment, and billing or invoicing for consumption of these resources. In one example, these resources may include application software licenses. Security provides identity verification for cloud consumers and tasks, as well as protection for data and other resources. User portal <b>83</b> provides access to the cloud computing environment for consumers and system administrators. Service level management <b>84</b> provides cloud computing resource allocation and management such that required service levels are met. Service Level Agreement (SLA) planning and fulfillment <b>85</b> provide pre-arrangement for, and procurement of, cloud computing resources for which a future requirement is anticipated in accordance with an SLA.</p><p id="p-0081" num="0080">Workloads layer <b>90</b> provides examples of functionality for which the cloud computing environment may be utilized. Examples of workloads and functions which may be provided from this layer include: mapping and navigation <b>91</b>; software development and lifecycle management <b>92</b>; virtual classroom education delivery <b>93</b>; data analytics processing <b>94</b>; transaction processing <b>95</b>; and QA discovery processing <b>96</b>.</p><p id="p-0082" num="0081">The present invention may be a system, a method, and/or a computer program product at any possible technical detail level of integration. The computer program product may include a computer readable storage medium (or media) having computer readable program instructions thereon for causing a processor to carry out aspects of the present invention.</p><p id="p-0083" num="0082">The computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device. The computer readable storage medium may be, for example, but is not limited to, an electronic storage device, a magnetic storage device, an optical storage device, an electromagnetic storage device, a semiconductor storage device, or any suitable combination of the foregoing. A non-exhaustive list of more specific examples of the computer readable storage medium includes the following: a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), a static random access memory (SRAM), a portable compact disc read-only memory (CD-ROM), a digital versatile disk (DVD), a memory stick, a floppy disk, a mechanically encoded device such as punch-cards or raised structures in a groove having instructions recorded thereon, and any suitable combination of the foregoing. A computer readable storage medium, as used herein, is not to be construed as being transitory signals per se, such as radio waves or other freely propagating electromagnetic waves, electromagnetic waves propagating through a waveguide or other transmission media (e.g., light pulses passing through a fiber-optic cable), or electrical signals transmitted through a wire.</p><p id="p-0084" num="0083">Computer readable program instructions described herein can be downloaded to respective computing/processing devices from a computer readable storage medium or to an external computer or external storage device via a network, for example, the Internet, a local area network, a wide area network and/or a wireless network. The network may comprise copper transmission cables, optical transmission fibers, wireless transmission, routers, firewalls, switches, gateway computers and/or edge servers. A network adapter card or network interface in each computing/processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium within the respective computing/processing device.</p><p id="p-0085" num="0084">Computer readable program instructions for carrying out operations of the present invention may be assembler instructions, instruction-set-architecture (ISA) instructions, machine instructions, machine dependent instructions, microcode, firmware instructions, state-setting data, configuration data for integrated circuitry, or either source code or object code written in any combination of one or more programming languages, including an object oriented programming language such as Smalltalk, C++, or the like, and procedural programming languages, such as the &#x201c;C&#x201d; programming language or similar programming languages. The computer readable program instructions may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider). In some embodiments, electronic circuitry including, for example, programmable logic circuitry, field-programmable gate arrays (FPGA), or programmable logic arrays (PLA) may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to personalize the electronic circuitry, in order to perform aspects of the present invention.</p><p id="p-0086" num="0085">Aspects of the present invention are described herein with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems), and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer readable program instructions.</p><p id="p-0087" num="0086">These computer readable program instructions may be provided to a processor of a computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks. These computer readable program instructions may also be stored in a computer readable storage medium that can direct a computer, a programmable data processing apparatus, and/or other devices to function in a particular manner, such that the computer readable storage medium having instructions stored therein comprises an article of manufacture including instructions which implement aspects of the function/act specified in the flowchart and/or block diagram block or blocks.</p><p id="p-0088" num="0087">The computer readable program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other device to cause a series of operational steps to be performed on the computer, other programmable apparatus or other device to produce a computer implemented process, such that the instructions which execute on the computer, other programmable apparatus, or other device implement the functions/acts specified in the flowchart and/or block diagram block or blocks.</p><p id="p-0089" num="0088">The flowchart and block diagrams in the Figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods, and computer program products according to various embodiments of the present invention. In this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of instructions, which comprises one or more executable instructions for implementing the specified logical function(s). In some alternative implementations, the functions noted in the blocks may occur out of the order noted in the Figures. For example, two blocks shown in succession may, in fact, be accomplished as one step, run concurrently, substantially concurrently, in a partially or wholly temporally overlapping manner, or the blocks may sometimes be run in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.</p><p id="p-0090" num="0089">The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the invention. As used herein, the singular forms &#x201c;a&#x201d;, &#x201c;an&#x201d; and &#x201c;the&#x201d; are intended to include the plural forms as well, unless the context clearly indicates otherwise. As used herein, the term &#x201c;or&#x201d; is an inclusive operator and can mean &#x201c;and/or&#x201d;, unless the context explicitly or clearly indicates otherwise. It will be further understood that the terms &#x201c;comprise&#x201d;, &#x201c;comprises&#x201d;, &#x201c;comprising&#x201d;, &#x201c;include&#x201d;, &#x201c;includes&#x201d;, &#x201c;including&#x201d;, and/or &#x201c;having,&#x201d; when used herein, can specify the presence of stated features, integers, steps, operations, elements, and/or components, but do not preclude the presence or addition of one or more other features, integers, steps, operations, elements, components, and/or groups thereof. As used herein, the phrase &#x201c;in an embodiment&#x201d; does not necessarily refer to the same embodiment, although it may. As used herein, the phrase &#x201c;in one embodiment&#x201d; does not necessarily refer to the same embodiment, although it may. As used herein, the phrase &#x201c;in another embodiment&#x201d; does not necessarily refer to a different embodiment, although it may. Further, embodiments and/or components of embodiments can be freely combined with each other unless they are mutually exclusive.</p><p id="p-0091" num="0090">The corresponding structures, materials, acts, and equivalents of all means or step plus function elements, if any, in the claims below are intended to include any structure, material, or act for performing the function in combination with other claimed elements as specifically claimed. The description of the present invention has been presented for purposes of illustration and description, but is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the invention. The embodiment was chosen and described in order to best explain the principles of the invention and the practical application, and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system comprising:<claim-text>a processor; and</claim-text><claim-text>a memory device coupled with the processor;</claim-text><claim-text>the processor configured to:<claim-text>receive a question and answer pair including a question and a corresponding answer;</claim-text><claim-text>search a corpus of conversations to find first conversation segments containing the question and answer pair, the first conversation segments containing statements including the question and the corresponding answer, and intermediate statements in-between the question and the corresponding answer;</claim-text><claim-text>tag the statements in the first conversation segments with dialog labels, the first conversation segments transformed into sequences of dialog labels, a sequence of dialog labels representing a question and answer structure pattern of a first conversation segment, wherein question and answer structure patterns are formed respectively corresponding to the first conversation segments;</claim-text><claim-text>search the corpus of conversations to find second conversation segments having at least one of the question and answer structure patterns;</claim-text><claim-text>for each of the question and answer structure patterns, receive labels associated with the second conversation segments;</claim-text><claim-text>based on the received labels, compute effectiveness of each of the question and answer structure patterns;</claim-text><claim-text>select a question and answer structure pattern meeting an effectiveness threshold; and</claim-text><claim-text>transform the selected question and answer structure pattern into a new question and answer.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is further configured to sample the second conversation segments found in the search to reduce the number of the second conversation segments for processing.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the received labels are manually labeled labels, indicating which of the second conversation segments include statements that follow the question and answer structure patterns.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is further configured to refine at least one of the question and answer structure patterns by further analyzing at least one of the first conversation segment and the second conversation segment having said at least one of the question and answer structure patterns, and adding an intent associated with a dialog label contained in said at least one of the question and answer structure patterns.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the dialog label is randomly selected for adding the intent.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the processor is configured to refine said at least one of the question and answer structure patterns, which is below the effectiveness threshold.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the refined question and answer structure pattern eliminates at least one labeled conversation segment having said at least one of the question and answer structure patterns.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the received question and answer pair includes a predefined question and answer pair retrieved from a database storing manually defined question and answer pairs.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A computer-implemented method comprising:<claim-text>receiving a question and answer pair including a question and a corresponding answer;</claim-text><claim-text>searching a corpus of conversations to find first conversation segments containing the question and answer pair, the first conversation segments containing statements including the question and the corresponding answer and intermediate statements in-between the question and the corresponding answer;</claim-text><claim-text>tagging the statements in the first conversation segments with dialog labels, the first conversation segments transformed into sequences of dialog labels, a sequence of dialog labels representing a question and answer structure pattern of a first conversation segment, wherein question and answer structure patterns are formed respectively corresponding to the first conversation segments;</claim-text><claim-text>searching the corpus of conversations to find second conversation segments having at least one of the question and answer structure patterns;</claim-text><claim-text>for each of the question and answer structure patterns, receiving labels associated with the second conversation segments;</claim-text><claim-text>based on the received labels, computing effectiveness of each of the question and answer structure patterns;</claim-text><claim-text>selecting a question and answer structure pattern meeting an effectiveness threshold; and</claim-text><claim-text>transforming the selected question and answer structure pattern into a new question and answer.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further including sampling the second conversation segments found in the search to reduce the number of the second conversation segments for processing.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the received labels are manually labeled labels, indicating which of the second conversation segments include statements that follow the question and answer structure patterns.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further including refining at least one of the question and answer structure patterns by further analyzing at least one of the first conversation segment and the second conversation segment having said at least one of the question and answer structure patterns, and adding an intent associated with a dialog label contained in said at least one of the question and answer structure patterns.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the dialog label is randomly selected for adding the intent.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the refining includes refining said at least one of the question and answer structure patterns, which is below the effectiveness threshold.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the refined question and answer structure pattern eliminates at least one labeled conversation segment having said at least one of the question and answer structure patterns.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions readable by a device to cause the device to:<claim-text>receive a question and answer pair including a question and a corresponding answer;</claim-text><claim-text>search a corpus of conversations to find first conversation segments containing the question and answer pair, the conversation segments containing statements including the question and the answer and intermediate statements in-between the question and the corresponding answer;</claim-text><claim-text>tag the statements in the first conversation segments with dialog labels, the first conversation segments transformed into sequences of dialog labels, a sequence of dialog labels representing a question and answer structure pattern of a first conversation segment, wherein question and answer structure patterns are formed respectively corresponding to the first conversation segments;</claim-text><claim-text>search the corpus of conversations to find second conversation segments having at least one of the question and answer structure patterns;</claim-text><claim-text>for each of the question and answer structure patterns, receive labels associated with the second conversation segments;</claim-text><claim-text>based on the received labels, compute effectiveness of each of the question and answer structure patterns;</claim-text><claim-text>select a one question and answer structure pattern meeting an effectiveness threshold; and</claim-text><claim-text>transform the selected question and answer structure pattern into a new question and answer.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The computer program product of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the processor is further configured to sample the second conversation segments found in the search to reduce the number of the second conversation segments for processing.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The computer program product of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the received labels are manually labeled labels, indicating which of the second conversation segments include statements that follow the question and answer structure patterns.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The computer program product of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the processor is further configured to refine at least one of the question and answer structure patterns by further analyzing at least one of the first conversation segment and the second conversation segment having said at least one of the question and answer structure patterns, and adding an intent associated with a dialog label contained in said at least one of the question and answer structure patterns.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The computer program product of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the dialog label is randomly selected for adding the intent.</claim-text></claim></claims></us-patent-application>
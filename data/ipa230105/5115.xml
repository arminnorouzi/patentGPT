<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005116A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005116</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17822322</doc-number><date>20220825</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>5</main-group><subgroup>50</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>21</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>38</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>5</main-group><subgroup>50</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>211</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>5</main-group><subgroup>002</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>38</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10016</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>20221</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">IMAGE PROCESSING METHOD AND APPARATUS, AND NON-TRANSITORY COMPUTER READABLE STORAGE MEDIUM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/CN2020/076670</doc-number><date>20200225</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17822322</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>GUANGDONG OPPO MOBILE TELECOMMUNICATIONS CORP., LTD.</orgname><address><city>Dongguan</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MA</last-name><first-name>Yuanjiao</first-name><address><city>Yokohama</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>LUO</last-name><first-name>Jun</first-name><address><city>Yokohama</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>QUAN</last-name><first-name>Wei</first-name><address><city>Yokohama</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An image processing method and apparatus, and a non-transitory computer-readable storage medium are provided. The method includes: acquiring an exposure duration and at least one motion component corresponding to at least one direction within the exposure duration of a current video frame; performing a first noise reduction operation on the current video frame in a two-dimensional space domain in response to a first motion component of the at least one motion component being greater than a preset motion component threshold; and performing a second noise reduction operation on the current video frame in a three-dimensional space domain in response to the at least one motion component being less than the preset motion component threshold.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="219.88mm" wi="158.75mm" file="US20230005116A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="124.63mm" wi="112.27mm" file="US20230005116A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="116.67mm" wi="145.80mm" file="US20230005116A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="187.54mm" wi="157.73mm" orientation="landscape" file="US20230005116A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="229.79mm" wi="161.54mm" file="US20230005116A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="191.26mm" wi="128.35mm" file="US20230005116A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="84.41mm" wi="151.89mm" file="US20230005116A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of International Patent Application No. PCT/CN2020/076670, filed Feb. 25, 2020, the entire disclosure of which is incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">Embodiments of the present disclosure relate to the technical field of image processing, and more specifically, to an image processing method, an image processing apparatus, and a non-transitory computer-readable storage medium.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">At present, in order to reduce a noise in a video and improve an image display effect of the video, multi-frame noise reduction algorithm is used to reduce the noise of a video frame of the video. Specifically, a frame alignment is performed on a denoised previous video frame and a current video frame having noise, and then a fusion operation is performed on aligned video frames to achieve the multi-frame noise reduction for the video frames.</p><p id="p-0005" num="0004">However, an effect of a multi-frame alignment is poor when the mobile phone is moving fast, thereby leading to an unsatisfactory effect of the multi-frame noise reduction. Generally, an alignment accuracy between two frames is increased by adding algorithms. However, adding the algorithms will lead to a long time of image processing and a low speed of image processing.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0006" num="0005">Embodiments of the present disclosure provide an image processing method, an image processing apparatus, and a non-transitory computer-readable storage medium.</p><p id="p-0007" num="0006">Technical solutions in some embodiments of the present disclosure are achieved below.</p><p id="p-0008" num="0007">An image processing method is provided in some embodiments of the present disclosure, the method includes: acquiring an exposure duration of a current video frame and at least one motion component corresponding to at least one direction within the exposure duration; performing a first noise reduction operation on the current video frame in a two-dimensional space domain in response to a first motion component of the at least one motion component being greater than a preset motion component threshold; and performing a second noise reduction operation on the current video frame in a three-dimensional space domain in response to the at least one motion component being less than the preset motion component threshold.</p><p id="p-0009" num="0008">An image processing apparatus is further provided in some embodiments of the present disclosure. The image processing apparatus includes: a processor, a memory storing instructions executable by the processor, a communication interface, and a bus configured to connect the processor, the memory, and the communication interface. When the instructions are executed, the processor performs above method, and the method comprises: acquiring an exposure duration of a current video frame and at least one motion component corresponding to at least one direction within the exposure duration; performing a first noise reduction operation on the current video frame in a two-dimensional space domain in response to a first motion component of the at least one motion component being greater than a preset motion component threshold; and performing a second noise reduction operation on the current video frame in a three-dimensional space domain in response to the at least one motion component being less than the preset motion component threshold.</p><p id="p-0010" num="0009">A non-transitory computer-readable storage medium is provided in some embodiments of the present disclosure. The non-transitory computer-readable storage medium stores a program applied to an image processing apparatus, and the program is executed by a processor to implement above method, and the method comprises: acquiring an exposure duration of a current video frame and at least one motion component corresponding to at least one direction within the exposure duration; performing a first noise reduction operation on the current video frame in a two-dimensional space domain in response to a first motion component of the at least one motion component being greater than a preset motion component threshold; and performing a second noise reduction operation on the current video frame in a three-dimensional space domain in response to the at least one motion component being less than the preset motion component threshold.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b> (<i>a</i>)</figref> is a schematic diagram illustrating a current video frame shot by a shooting device in the related art when the shooting device is moving by a small distance.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>1</b> (<i>b</i>)</figref> is a schematic diagram illustrating a current video frame shot by the shooting device in the related art when the shooting device is moving quickly.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flowchart of an image processing method according to some embodiments of the present disclosure.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram illustrating an exemplary image processing device acquiring angular velocity components of a gyroscope in three directions of X, Y, and Z according to some embodiments of the present disclosure.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic diagram of an exemplary image processing device acquiring motion radians of the gyroscope in the three directions of X, Y, and Z according to some embodiments of the present disclosure.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic flowchart of an exemplary image processing method according to some embodiments of the present disclosure.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a displayed diagram illustrating that no &#x201c;ghost&#x201d; exists in the current video frame shot by a shooting device according to some embodiments of the present disclosure when the shooting device is moved quickly.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a first structural block diagram of an image processing apparatus according to some embodiments of the present disclosure.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a second structural block diagram of an image processing apparatus according to some embodiments of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0020" num="0019">The technical solutions in some embodiments of the present disclosure will be clearly and completely described below in conjunction with drawings in the embodiments of the present disclosure. It should be understood that the embodiments described here are only used to explain the related disclosure, but not to limit the disclosure. In addition, it should be noted that, for ease of description, only parts related to the present disclosure are shown in the drawings.</p><p id="p-0021" num="0020">When a still photo is shot or a shooting device is fixed, a mobile phone can be kept as still as possible since a shooting time is short. Thus, in this case, a camera may be moved by a small distance, and less serious &#x201c;ghost&#x201d; may be generated in multi-frame noise reduction fusion. As shown in <figref idref="DRAWINGS">FIG. <b>1</b> (<i>a</i>)</figref>, the shooting device is moving by a small distance or having a small motion amplitude when shooting or capturing a current video frame, in this case, the current video frame captured may have less &#x201c;ghost&#x201d;. Herein, the terms &#x201c;motion amplitude&#x201d; of a device means the moving degree (distance and/or angle) of the device. As shown in <figref idref="DRAWINGS">FIG. <b>1</b>(<i>b</i>)</figref>, in case that a user is holding the shooting device to shoot a video such that it is difficult for the user to maintain a posture within dozens of seconds, or in case that the user enormously and dynamically moves the shooting device to capture various dynamic scenes, motion vectors of a previous frame and a next frame may vary greatly, such that the alignment accuracy is insufficient, thereby generating serious &#x201c;ghost&#x201d; during a synthesis of last two frames. In addition, a video frame having the &#x201c;ghost&#x201d; will continue to be used for a synthesis of a next video frame, such that the &#x201c;ghost&#x201d; will be present in all subsequent video frames, which affects an effect of the noise reduction of the video. In order to solve above problems, technical solutions of the present disclosure may be provided.</p><p id="p-0022" num="0021">The technical solutions in the embodiments of the present disclosure will be clearly and completely described below in conjunction with the drawings in the embodiments of the present disclosure.</p><p id="p-0023" num="0022">In some embodiments of the present disclosure, an image processing method may be provided. <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flowchart of the image processing method according to some embodiments of the present disclosure. The method may include following operations.</p><p id="p-0024" num="0023">In operation S<b>101</b>, an exposure duration of a current video frame and at least one motion component corresponding to at least one direction within the exposure duration may be acquired.</p><p id="p-0025" num="0024">The image processing method provided in some embodiments of the present disclosure is applicable to a scene where a multi-frame noise reduction operation is performed for video frames in an acquired or captured video.</p><p id="p-0026" num="0025">In some embodiments, an image processing apparatus may be any apparatus with image acquisition and image processing functions, such as a tablet computer, a mobile phone, a personal computer (PC), a notebook computer, a camera, a network TV, a wearable apparatus, and so on.</p><p id="p-0027" num="0026">In some embodiments, the image processing apparatus may acquire the exposure duration of the current video frame in response to the image processing apparatus receiving the current video frame to be processed. Specifically, the image processing apparatus may acquire a Start of Frame (SOF) Timestamp and an End of Frame (EOF) Timestamp from a metadata of the current video frame. After that, the image processing apparatus may determine a duration between the EOF and the SOF as the exposure duration of the current video frame.</p><p id="p-0028" num="0027">In some embodiments, the image processing apparatus may acquire at least one motion component of the image processing apparatus in or corresponding to at least one direction within the exposure duration. The motion component may be an angular velocity component or an acceleration component, etc., which may be specifically selected according to actual conditions, and which may not be specifically limited in some embodiments of the present disclosure.</p><p id="p-0029" num="0028">In some embodiments, the image processing apparatus may include an angular velocity sensor. The image processing apparatus may acquire an angular velocity component in at least one dimension from the angular velocity sensor within the exposure duration. The image processing apparatus may determine the angular velocity component in the at least one dimension to be the at least one motion component corresponding to the at least one direction. Specifically, the image processing apparatus may divide the exposure duration into a set of time samples. The image processing apparatus may acquire at least one set of angular-velocity-component samples in the least one dimension within or during the set of time samples from the angular velocity sensor, and each of the at least one dimension corresponds to one of the at least one set of angular-velocity-component samples within or during the set of time samples. Then, the image processing apparatus may determine the angular velocity component in the at least one dimension within the exposure duration according to or based on the at least one set of angular-velocity-component samples, and determine the angular velocity component in the at least one dimension as the at least one motion component corresponding to the at least one direction.</p><p id="p-0030" num="0029">In some embodiments, the angular velocity sensor may be a device configured to perform an angular velocity measurement, such as a gyroscope. The number of the gyroscopes may be determined according to the at least one dimension acquired based on actual needs, which is not specifically limited in some embodiments of the present disclosure.</p><p id="p-0031" num="0030">In some embodiments, the angular velocity component in the at least one dimension may be a two-dimensional angular velocity component or a three-dimensional angular velocity component, etc., which may be specifically selected according to actual conditions, and which may not be specifically limited in some embodiments of the present disclosure. Taking the three-dimensional angular velocity component as an example, the image processing apparatus may use the gyroscope to collect an X-axis angular velocity component, a Y-axis angular velocity component, and a Z-axis angular velocity component within the exposure duration.</p><p id="p-0032" num="0031">It should be noted that, the angular velocity component in the at least one dimension is configured to represent or indicate whether the image processing apparatus is moving quickly. Therefore, in response to the image processing apparatus acquiring the angular velocity component in the at least one dimension within the exposure duration, the image processing apparatus may determine a degree of motion or the motion amplitude thereof based on an integral of an absolute value of the angular velocity component within the exposure duration without needing to consider a specific direction of motion.</p><p id="p-0033" num="0032">Exemplarily, as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the image processing apparatus may determine the duration between the SOF Timestamp and the EOF Timestamp as the exposure duration. The image processing apparatus may divide the exposure duration into N time samples, and acquire angular velocity components of the gyroscope in three directions of X, Y, and Z during each time sample of the N time samples. The gyroscope may be configured to calibrate angles in the three directions of X, Y, and Z through Cartesian coordinates. In this way, the image processing apparatus may acquire a set of angular velocity components X<sub>0</sub>, X<sub>1</sub>, . . . X<sub>N </sub>of the gyroscope in the X axis within the exposure duration. The image processing apparatus may determine the angular velocity component of the image processing apparatus in the X axis by using the set of angular velocity components X<sub>0</sub>, X<sub>1</sub>, . . . , X<sub>N</sub>, which is specifically shown in formula (1).</p><p id="p-0034" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>angular</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>velocity</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>component</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>of</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>X</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>axis</mi>     </mrow>     <mo>=</mo>     <mrow>      <munderover>       <mo>&#x2211;</mo>       <mrow>        <mi>N</mi>        <mo>=</mo>        <mn>0</mn>       </mrow>       <mrow>        <mi>N</mi>        <mo>=</mo>        <mrow>         <mi>n</mi>         <mo>-</mo>         <mn>1</mn>        </mrow>       </mrow>      </munderover>      <mrow>       <semantics definitionURL="">        <mo>&#x2758;</mo>        <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>       </semantics>       <msub>        <mi>X</mi>        <mi>N</mi>       </msub>       <semantics definitionURL="">        <mo>&#x2758;</mo>        <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>       </semantics>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>1</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0035" num="0033">The image processing apparatus may acquire a set of angular velocity components Y<sub>0</sub>, Y<sub>1</sub>, . . . , Y<sub>N </sub>of the gyroscope in the Y axis within the exposure duration. The image processing apparatus may determine the angular velocity component of the image processing apparatus in the Y axis through or by using the set of angular velocity components Y<sub>0</sub>, Y<sub>1</sub>, . . . , Y<sub>N</sub>, which is specifically shown in formula (2).</p><p id="p-0036" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>angular</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>velocity</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>component</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>of</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>Y</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>axis</mi>     </mrow>     <mo>=</mo>     <mrow>      <munderover>       <mo>&#x2211;</mo>       <mrow>        <mi>N</mi>        <mo>=</mo>        <mn>0</mn>       </mrow>       <mrow>        <mi>N</mi>        <mo>=</mo>        <mrow>         <mi>n</mi>         <mo>-</mo>         <mn>1</mn>        </mrow>       </mrow>      </munderover>      <mrow>       <semantics definitionURL="">        <mo>&#x2758;</mo>        <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>       </semantics>       <msub>        <mi>Y</mi>        <mi>N</mi>       </msub>       <semantics definitionURL="">        <mo>&#x2758;</mo>        <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>       </semantics>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>2</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0037" num="0034">The image processing apparatus may acquire a set of angular velocity components Z<sub>0</sub>, Z<sub>1</sub>, . . . , Z<sub>N </sub>of the gyroscope in the Z axis within the exposure duration. The image processing apparatus may determine the angular velocity component of the image processing apparatus in the Z axis through or by using the set of angular velocity components Z<sub>0</sub>, Z<sub>1</sub>, . . . , Z<sub>N</sub>, which is specifically shown in formula (3).</p><p id="p-0038" num="0000"><maths id="MATH-US-00003" num="00003"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>angular</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>velocity</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>component</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>of</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>Z</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>axis</mi>     </mrow>     <mo>=</mo>     <mrow>      <munderover>       <mo>&#x2211;</mo>       <mrow>        <mi>N</mi>        <mo>=</mo>        <mn>0</mn>       </mrow>       <mrow>        <mi>N</mi>        <mo>=</mo>        <mrow>         <mi>n</mi>         <mo>-</mo>         <mn>1</mn>        </mrow>       </mrow>      </munderover>      <mrow>       <semantics definitionURL="">        <mo>&#x2758;</mo>        <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>       </semantics>       <msub>        <mi>Z</mi>        <mi>N</mi>       </msub>       <semantics definitionURL="">        <mo>&#x2758;</mo>        <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>       </semantics>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>3</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0039" num="0035">In operation S<b>102</b>, in response to a first motion component of the at least one motion component being greater than a preset motion component threshold, a first noise reduction operation may be performed on the current video frame in a two-dimensional space domain. The first noise reduction operation may be an intraframe noise reduction operation performed on the current video frame without using a previous video frame prior to the current video frame and a next video frame next to the current video frame.</p><p id="p-0040" num="0036">After the image processing apparatus acquires the exposure duration and the at least one motion component corresponding to the at least one direction within the exposure duration, the image processing apparatus may compare the at least one motion component with the preset motion component threshold. In response to the first motion component of the at least one motion component being greater than the preset motion component threshold, the image processing apparatus may perform the first noise reduction operation on the current video frame in the two-dimensional space domain.</p><p id="p-0041" num="0037">In some embodiments, the image processing apparatus may be preset with the preset motion component threshold, and the image processing apparatus may compare the at least one motion component with the preset motion component threshold. In response to the first motion component greater than the preset motion component threshold existing in the at least one motion component, it indicates that the motion amplitude of the image processing apparatus is too great or overlarge when the image processing apparatus is capturing the current video frame. In this case, the image processing apparatus may perform the first noise reduction operation on the current video frame in the two-dimensional space domain, and prohibit or disable the current video frame from being fused with an adjacent historical video frame and an adjacent next video frame. It should be noted that the adjacent historical video frame is the previous video frame prior to the current video frame, and the adjacent next video frame is next to the current video frame.</p><p id="p-0042" num="0038">In some embodiments, the image processing apparatus may perform the first noise reduction operation on the current video frame in the two-dimensional space domain through noise reduction methods, such as Gaussian filter, Bilateral filter, or the like.</p><p id="p-0043" num="0039">In some embodiments, in response to the image processing apparatus determining that the first motion component is greater than the preset motion component threshold, in order to improve an accuracy of detecting the motion of the image processing apparatus, the image processing apparatus may further acquire at least one motion radian corresponding to the at least one direction within the exposure duration, and compare the at least one motion radian with a preset radian threshold. In response to the image processing apparatus determining that a first motion radian of the at least one motion radian is greater than the preset radian threshold, the image processing apparatus may perform the first noise reduction operation on the current video frame in the two-dimensional space domain.</p><p id="p-0044" num="0040">Exemplarily, as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the image processing apparatus may acquire angular velocity components of the gyroscope in the three directions along the X axis, Y axis, and Z axis during N time samples. Then, the image processing apparatus may acquire a set of angular velocity components X<sub>0</sub>, X<sub>1</sub>, . . . , X<sub>N </sub>of the gyroscope in or along the X axis within or during time samples t<sub>0</sub>, t<sub>1</sub>, . . . , t<sub>N</sub>. The image processing apparatus may determine the motion radian of the image processing apparatus along the X axis by using the set of angular velocity components X<sub>0</sub>, X<sub>1</sub>, . . . , X<sub>N</sub>, which is specifically shown in formula (4).</p><p id="p-0045" num="0000"><maths id="MATH-US-00004" num="00004"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>motion</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>radian</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>of</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>X</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>axis</mi>     </mrow>     <mo>=</mo>     <mrow>      <munderover>       <mo>&#x2211;</mo>       <mrow>        <mi>N</mi>        <mo>=</mo>        <mn>1</mn>       </mrow>       <mrow>        <mi>N</mi>        <mo>=</mo>        <mrow>         <mi>n</mi>         <mo>-</mo>         <mn>1</mn>        </mrow>       </mrow>      </munderover>      <mrow>       <mrow>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>        </semantics>        <msub>         <mi>X</mi>         <mi>N</mi>        </msub>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>        </semantics>       </mrow>       <mo>&#xd7;</mo>       <mrow>        <mo>(</mo>        <mrow>         <msub>          <mi>t</mi>          <mi>N</mi>         </msub>         <mo>-</mo>         <msub>          <mi>t</mi>          <mrow>           <mi>N</mi>           <mo>-</mo>           <mn>1</mn>          </mrow>         </msub>        </mrow>        <mo>)</mo>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>4</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0046" num="0041">The image processing apparatus may acquire a set of angular velocity components Y<sub>0</sub>, Y<sub>1</sub>, . . . , Y<sub>N </sub>of the gyroscope along the Y axis during time samples t<sub>0</sub>, t<sub>1</sub>, . . . , t<sub>N</sub>. The image processing apparatus may determine the motion radian of the image processing apparatus along the Y axis by using the set of angular velocity components Y<sub>0</sub>, Y<sub>1</sub>, . . . , Y<sub>N</sub>, which is specifically shown in formula (5).</p><p id="p-0047" num="0000"><maths id="MATH-US-00005" num="00005"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>motion</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>radian</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>of</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>Y</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>axis</mi>     </mrow>     <mo>=</mo>     <mrow>      <munderover>       <mo>&#x2211;</mo>       <mrow>        <mi>N</mi>        <mo>=</mo>        <mn>1</mn>       </mrow>       <mrow>        <mi>N</mi>        <mo>=</mo>        <mrow>         <mi>n</mi>         <mo>-</mo>         <mn>1</mn>        </mrow>       </mrow>      </munderover>      <mrow>       <mrow>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>        </semantics>        <msub>         <mi>Y</mi>         <mi>N</mi>        </msub>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>        </semantics>       </mrow>       <mo>&#xd7;</mo>       <mrow>        <mo>(</mo>        <mrow>         <msub>          <mi>t</mi>          <mi>N</mi>         </msub>         <mo>-</mo>         <msub>          <mi>t</mi>          <mrow>           <mi>N</mi>           <mo>-</mo>           <mn>1</mn>          </mrow>         </msub>        </mrow>        <mo>)</mo>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>5</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0048" num="0042">The image processing apparatus may acquire a set of angular velocity components Z<sub>0</sub>, Z<sub>1</sub>, . . . , Z<sub>N </sub>of the gyroscope along the Z axis during time samples t<sub>0</sub>, t<sub>1</sub>, . . . , t<sub>N</sub>. The image processing apparatus may determine the motion radian of the image processing apparatus along the Z axis by using the set of angular velocity components Z<sub>0</sub>, Z<sub>1</sub>, . . . , Z<sub>N</sub>, which is specifically shown in formula (6).</p><p id="p-0049" num="0000"><maths id="MATH-US-00006" num="00006"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>motion</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>radian</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>of</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>Z</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>axis</mi>     </mrow>     <mo>=</mo>     <mrow>      <munderover>       <mo>&#x2211;</mo>       <mrow>        <mi>N</mi>        <mo>=</mo>        <mn>1</mn>       </mrow>       <mrow>        <mi>N</mi>        <mo>=</mo>        <mrow>         <mi>n</mi>         <mo>-</mo>         <mn>1</mn>        </mrow>       </mrow>      </munderover>      <mrow>       <mrow>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>        </semantics>        <msub>         <mi>Z</mi>         <mi>N</mi>        </msub>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>        </semantics>       </mrow>       <mo>&#xd7;</mo>       <mrow>        <mo>(</mo>        <mrow>         <msub>          <mi>t</mi>          <mi>N</mi>         </msub>         <mo>-</mo>         <msub>          <mi>t</mi>          <mrow>           <mi>N</mi>           <mo>-</mo>           <mn>1</mn>          </mrow>         </msub>        </mrow>        <mo>)</mo>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>6</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0050" num="0043">In operation S<b>103</b>, in response to the at least one motion component being less than the preset motion component threshold, a multi-frame noise reduction operation may be performed on the current video frame in a three-dimensional space domain. Herein, the multi-frame noise reduction operation may also be referred as a second noise reduction operation in the following, and the multi-frame noise reduction operation may be an interframe noise reduction operation during which the current video frame may be fused with the previous video frame and the next video frame.</p><p id="p-0051" num="0044">After the image processing apparatus acquires the exposure duration and the at least one motion component corresponding to the at least one direction within the exposure duration of the current video frame, the image processing apparatus may compare the at least one motion component with the preset motion component threshold. In response to the image processing apparatus determining that all of the at least one motion component is less than the preset motion component threshold, the image processing apparatus may perform the multi-frame noise reduction operation on the current video frame in the three-dimensional space domain.</p><p id="p-0052" num="0045">Exemplarily, the image processing apparatus may acquire the motion components in the X, Y, and Z three directions of the gyroscope within the exposure duration, and compare the motion components in the X, Y, and Z directions with the preset motion component threshold. In response to the motion components in the X, Y, and Z three directions being all less than the preset motion component threshold, it indicates that the motion amplitude of the image processing apparatus satisfies a condition of the multi-frame noise reduction operation when the image processing apparatus is collecting the current video frame. In this case, the image processing apparatus may perform the multi-frame noise reduction operation on the current video frame in the three-dimensional space domain.</p><p id="p-0053" num="0046">In some embodiments, in order to improve the accuracy of detecting the motion of the image processing apparatus, the image processing apparatus may further acquire the at least one motion radian corresponding to the at least one direction within the exposure duration, and compare the at least one motion radian with the preset radian threshold. In response to the image processing apparatus determining that the first motion radian of the at least one motion radian is less than the preset radian threshold, the image processing apparatus may align the current video frame with the adjacent historical video frame and the adjacent next video frame, thereby performing the multi-frame noise reduction operation on the current video frame.</p><p id="p-0054" num="0047">Exemplarily, as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the flow chart for the image processing apparatus to determine whether to perform the first noise reduction operation in the two-dimensional space domain on the current frame according to the motion amplitude of the image processing apparatus within the exposure duration is described below.</p><p id="p-0055" num="0048">1. The image processing apparatus may synchronize the exposure duration of the current video frame and angular velocity data of the gyroscope in the X, Y, and Z directions within the exposure duration. The X direction is substantially perpendicular to the Y direction and the Z direction, and the Y direction is substantially perpendicular to the Z direction.</p><p id="p-0056" num="0049">2. The image processing apparatus may acquire motion velocity values in the X, Y, and Z three directions according to the angular velocity data of the gyroscope in the X, Y, and Z directions within the exposure duration.</p><p id="p-0057" num="0050">3. The image processing apparatus may compare the motion velocity values in the X, Y, and Z directions with a preset motion velocity value threshold.</p><p id="p-0058" num="0051">4. In response to the motion velocity values in the X, Y, and Z directions being all less than the preset motion velocity value threshold, an operation <b>9</b> may be executed.</p><p id="p-0059" num="0052">5. In response to at least one of the motion velocity values in the X, Y, and Z directions among the motion velocity values being greater than the preset motion velocity value threshold, the image processing apparatus may acquire motion angles in the X, Y, and Z directions.</p><p id="p-0060" num="0053">6. The image processing apparatus may compare the motion angles in the X, Y, and Z three directions with a preset motion angle threshold.</p><p id="p-0061" num="0054">7. In response to the motion angles in the X, Y, and Z directions being all less than the preset motion angle threshold, the operation <b>9</b> may be executed.</p><p id="p-0062" num="0055">8. In response to at least one motion angle of the motion angles in the X, Y, and Z directions being greater than the preset motion angle threshold, an operation <b>10</b> may be executed.</p><p id="p-0063" num="0056">9. The image processing apparatus may perform a 3D interframe noise reduction fusion operation on the current video frame, the adjacent previous video frame prior to the current video frame, and the adjacent next video frame next to the current video frame. That is to say, the current video frame may be fused with the adjacent previous video frame, and further fused with the adjacent next video frame.</p><p id="p-0064" num="0057">10. The image processing apparatus may perform the 2D intraframe noise reduction operation on the current video frame in the 2D space domain.</p><p id="p-0065" num="0058">It can be understood that, when the image processing apparatus is performing the noise reduction on the current video frame, the image processing apparatus may first acquire the at least one motion component in the at least one direction of the image processing apparatus within the exposure duration of the current video frame, and then determine the motion component of the image processing apparatus based on the at least one motion component within the exposure duration. In response to the at least one motion component of the image processing apparatus within the exposure duration being greater than the preset motion component threshold, the image processing apparatus may directly perform the first noise reduction operation on the current video frame in the two-dimensional space domain to reduce the operations for processing the alignment accuracy of multiple frames, thereby shortening the time duration of an image processing, and improving the speed of the image processing. In some embodiments, as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, when the image processing apparatus is moving quickly, the image processing apparatus may only perform the 2D noise reduction operation on the current video frame, and may not perform the fusion of the previous frame and the next frame, thereby reducing the occurrence of the &#x201c;ghost&#x201d;.</p><p id="p-0066" num="0059">Based on above-mentioned embodiments, in some other embodiments of the present disclosure, <figref idref="DRAWINGS">FIG. <b>7</b></figref> is a first schematic diagram of a configuration structure of the image processing apparatus according to some embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the image processing apparatus <b>1</b> according to some embodiments of the present disclosure may include an acquisition part <b>10</b>, a two-dimensional noise reduction part <b>11</b>, and a multi-frame noise reduction part <b>12</b>.</p><p id="p-0067" num="0060">The acquisition part <b>10</b> is configured to acquire an exposure duration of a current video frame and at least one motion component corresponding to at least one direction within the exposure duration.</p><p id="p-0068" num="0061">The two-dimensional noise reduction part <b>11</b> is configured to perform a first noise reduction operation on the current video frame in a two-dimensional space domain in response to a first motion component of the at least one motion component being greater than a preset motion component threshold.</p><p id="p-0069" num="0062">The multi-frame noise reduction part <b>12</b> is configured to perform a multi-frame noise reduction operation on the current video frame in a three-dimensional space domain in response to the at least one motion component being less than the preset motion component threshold.</p><p id="p-0070" num="0063">Further, the image processing apparatus <b>1</b> includes a calculation part.</p><p id="p-0071" num="0064">The calculation part is configured to acquire at least one motion radian corresponding to the at least one direction within the exposure duration in response to the first motion component being greater than the preset motion component threshold.</p><p id="p-0072" num="0065">The two-dimensional noise reduction part <b>11</b> is further configured to perform the first noise reduction operation on the current video frame in the two-dimensional space domain in response to a first motion radian of the at least one motion radian being greater than a preset radian threshold.</p><p id="p-0073" num="0066">Further, the image processing apparatus includes an angular velocity sensor. The image processing apparatus further includes a division part and a determination part.</p><p id="p-0074" num="0067">The division part is configured to divide the exposure duration into a set of time samples.</p><p id="p-0075" num="0068">The acquisition part <b>10</b> is configured to acquire at least one set of angular-velocity-component samples in at least one dimension during the set of time samples from the angular velocity sensor, and each of the at least one dimension corresponds to one of the at least one set of angular-velocity-component samples during the set of time samples.</p><p id="p-0076" num="0069">The determination part is configured to determine an angular velocity component in the at least one dimension within the exposure duration based on the at least one set of angular-velocity-component samples. The determination part is also configured to determine the angular velocity component in the at least one dimension as the at least one motion component corresponding to the at least one direction.</p><p id="p-0077" num="0070">Further, the image processing apparatus includes a prohibition part.</p><p id="p-0078" num="0071">The prohibition part is configured to prohibit or disable the current video frame from being fused with an adjacent historical video frame and an adjacent next video frame in response to the at least one motion component being greater than the preset motion component threshold and/or the at least one motion radian being greater than the preset radian threshold. In other words, the prohibition part may be configured to prohibit the current video frame from being fused with an adjacent historical video frame and an adjacent next video frame in response to satisfying at least one following condition: the at least one motion component is greater than the preset motion component threshold, and the at least one motion radian being greater than the preset radian threshold. It should be noted that, the term &#x201c;A and/or B&#x201d; includes A existing alone, B existing alone, and A and B existing simultaneously.</p><p id="p-0079" num="0072">Further, the multi-frame noise reduction part <b>12</b> is configured to perform the multi-frame noise reduction operation on the current video frame by performing the multi-frame alignment on the current video frame with the adjacent historical video frame and the adjacent next video frame in response to the first motion component being less than the preset motion component threshold and/or the first motion radian being less than the preset radian threshold.</p><p id="p-0080" num="0073"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a second schematic diagram of the composition structure of the image processing apparatus according to some embodiments of the disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the image processing apparatus <b>1</b> may further include a processor <b>110</b>, a memory <b>111</b> storing instructions executable by the processor <b>110</b>, a communication interface <b>112</b>, and a bus <b>113</b> configured to connect the processor <b>110</b>, the memory <b>111</b>, and the communication interface <b>112</b>.</p><p id="p-0081" num="0074">In some embodiments of the present disclosure, the processor <b>110</b> may be at least one of an Application Specific Integrated Circuit (ASIC), a Digital Signal Processor (DSP), a Digital Signal Processing Device (DSPD), a Programmable Logic Device (PLD), a Field Programmable Gate Array (FPGA), a Central Processing Unit (CPU), a controller, a microcontroller, and a microprocessor. It should be understood that, for different devices, electronic components configured to implement the above-mentioned functions of the processor may also be other electronic components, which is not specifically limited in some embodiments of the present disclosure. The image processing apparatus <b>1</b> may also include the memory <b>111</b> connected to the processor <b>110</b>, and the memory <b>111</b> is configured to store executable program codes including computer operation instructions. The memory <b>111</b> may include a high-speed Random Access Memory (RAM) or a non-volatile memory, for example, at least two disk memories.</p><p id="p-0082" num="0075">In some embodiments, the bus <b>113</b> is configured to connect the communication interface <b>112</b>, the processor <b>110</b>, and the memory <b>111</b>. The bus <b>113</b> is also configured to achieve the communication among these components.</p><p id="p-0083" num="0076">In some embodiments, the memory <b>111</b> is configured to store the instructions and data.</p><p id="p-0084" num="0077">Further, in some embodiments, the processor <b>110</b> is configured to acquire the exposure duration of the current video frame and the at least one motion component corresponding to the at least one direction within the exposure duration. In response to the first motion component of the at least one motion component being greater than the preset motion component threshold, the processor <b>110</b> is configured to perform the first noise reduction operation on the current video frame in the two-dimensional space domain. In response to the at least one motion component being less than the preset motion component threshold, the processor <b>110</b> is configured to perform the multi-frame noise reduction operation on the current video frame in the three-dimensional space domain.</p><p id="p-0085" num="0078">Further, in some embodiments, the processor <b>110</b> is configured to acquire the at least one motion radian corresponding to the at least one direction within the exposure duration in response to the first motion component being greater than the preset motion component threshold. In response to the first motion radian of the at least one motion radian being greater than a preset radian threshold, the processor <b>110</b> is configured to perform the first noise reduction operation on the current video frame in the two-dimensional space domain.</p><p id="p-0086" num="0079">Further, in some embodiments, the processor <b>110</b> is configured to acquire the angular velocity component in at least one dimension within the exposure duration from the angular velocity sensor. The processor <b>110</b> is configured to determine the angular velocity component in the at least one dimension as the at least one motion component corresponding to the at least one direction.</p><p id="p-0087" num="0080">Further, in some embodiments, the processor <b>110</b> is configured to prohibit or disable the current video frame from being fused with the adjacent historical video frame and the adjacent next video frame in response to the at least one motion component being greater than the preset motion component threshold and/or the at least one motion radian being greater than the preset radian threshold.</p><p id="p-0088" num="0081">Further, in some embodiments, the processor <b>110</b> is configured to perform the multi-frame noise reduction operation on the current video frame by performing the multi-frame alignment on the current video frame with the adjacent historical video frame and the adjacent next video frame in response to the first motion component being less than the preset motion component threshold and/or the first motion radian being less than the preset radian threshold.</p><p id="p-0089" num="0082">In practical applications, the memory <b>111</b> may be a volatile memory, such as a Random-Access Memory (RAM). The memory <b>111</b> may also be a non-volatile memory, such as a Read-Only Memory (ROM), a flash memory, a Hard Disk Drive (HDD), a Solid-State Drive (SSD). Or, the memory <b>111</b> may be a combination of the above-mentioned types of memories, and the memory <b>111</b> may be configured to provide instructions and data to the processor <b>110</b>.</p><p id="p-0090" num="0083">In addition, in some embodiments of the present disclosure, all function modules may be integrated into one processing unit. Alternatively, each unit may exist alone physically, or two or more units may be integrated into one unit. The above-mentioned integrated unit may be implemented in form of a hardware or a software function module.</p><p id="p-0091" num="0084">When the integrated unit is implemented in form of the software function module and is not sold or used as an independent product, the integrated unit may be stored in a non-transitory computer-readable storage medium. In this way, the technical solution of some embodiments may be essentially embodied in form of a software product. Alternatively, a part that contributes to the related technology may be embodied in form of the software product. Alternatively, all or part of the technical solution may be embodied in form of the software product. The computer software product is stored in the non-transitory computer-readable storage medium including several instructions to enable a computer device (such as a personal computer, a server, or a network device, etc.) or a processor to execute all or part of operations of the methods in some embodiments of the present disclosure. The computer-readable storage medium includes various kinds of medium storing program codes such as a U disk, a mobile hard disk, a Read Only Memory (ROM), a Random Access Memory (RAM), a magnetic disk or an optical disk.</p><p id="p-0092" num="0085">Some embodiments of the present disclosure discloses an image processing method, and the method includes: acquiring an exposure duration of a current video frame and at least one motion component corresponding to at least one direction within the exposure duration; performing a first noise reduction operation on the current video frame in a two-dimensional space domain in response to a first motion component of the at least one motion component being greater than a preset motion component threshold; and performing a second noise reduction operation on the current video frame in a three-dimensional space domain in response to the at least one motion component being less than the preset motion component threshold.</p><p id="p-0093" num="0086">In some embodiments, the performing a noise reduction operation on the current video frame in a two-dimensional space domain in response to a first motion component of the at least one motion component being greater than a preset motion component threshold, includes: acquiring at least one motion radian corresponding to the at least one direction in response to the first motion component being greater than the preset motion component threshold; and performing the first noise reduction operation on the current video frame in the two-dimensional space domain in response to a first motion radian of the at least one motion radian being greater than a preset radian threshold.</p><p id="p-0094" num="0087">In some embodiments, the acquiring at least one motion component corresponding to at least one direction within the exposure duration, includes: dividing the exposure duration into a set of time samples; acquiring at least one set of angular-velocity-component samples in at least one dimension during the set of time samples, wherein each of the at least one dimension corresponds to one of the at least one set of angular-velocity-component samples during the set of time samples; determining an angular velocity component in the at least one dimension within the exposure duration based on the at least one set of angular-velocity-component samples; and determining the angular velocity component in the at least one dimension as the at least one motion component corresponding to the at least one direction.</p><p id="p-0095" num="0088">In some embodiments, the method further includes: prohibiting the current video frame from being fused with an adjacent historical video frame and an adjacent next video frame in response to satisfying at least one following condition: the at least one motion component being greater than the preset motion component threshold; and the at least one motion radian being greater than the preset radian threshold.</p><p id="p-0096" num="0089">In some embodiments, the method further includes: performing the second noise reduction operation on the current video frame by performing a multi-frame alignment on the current video frame with an adjacent historical video frame and an adjacent next video frame in response to satisfying at least one following condition: the first motion component being less than the preset motion component threshold; and the first motion radian being less than the preset radian threshold.</p><p id="p-0097" num="0090">In some embodiments, the performing a second noise reduction operation on the current video frame in a three-dimensional space domain in response to the at least one motion component being less than the preset motion component threshold further includes: performing the second noise reduction operation on the current video frame by aligning the current video frame with an adjacent historical video frame and an adjacent next video frame in response to all of the at least one motion component being less than the preset motion component threshold.</p><p id="p-0098" num="0091">In some embodiments, the at least one motion component includes an angular velocity component and an acceleration component.</p><p id="p-0099" num="0092">In some embodiments, the method further includes: in response to the at least one motion component including the angular velocity component in at least one dimension, determining a motion amplitude within the exposure duration based on an integral of an absolute value of the angular velocity component.</p><p id="p-0100" num="0093">In some embodiments, the acquiring an exposure duration of a current video frame and at least one motion component corresponding to at least one direction within the exposure duration, includes: synchronizing the exposure duration of the current video frame and angular velocity data in first, second, and third directions within the exposure duration, wherein the first direction is substantially perpendicular to the second direction and the third direction, and the second direction is substantially perpendicular to the third direction; and acquiring motion velocity values in the first, second, and third directions according to the angular velocity data in the first, second, and third directions within the exposure duration.</p><p id="p-0101" num="0094">In some embodiments, the performing a first noise reduction operation on the current video frame in a two-dimensional space domain in response to a first motion component of the at least one motion component being greater than a preset motion component threshold, includes: acquiring motion angles in the first, second, and third directions in response to at least one of the motion velocity values among the motion velocity values in the first, second, and third directions being greater than a preset motion velocity value threshold; and performing the first noise reduction operation on the current video frame in the two-dimensional space domain in response to at least one of the motion angles in the first, second, and third directions being greater than a preset motion angle threshold.</p><p id="p-0102" num="0095">The image processing apparatus according to some embodiments of the present disclosure may be configured to acquire the exposure duration of the current video frame and the at least one motion component corresponding to the at least one direction within the exposure duration. In response to the first motion component of the at least one motion component being greater than the preset motion component, the image processing apparatus is configured to perform the first noise reduction operation on the current video frame in the two-dimensional space domain. In response to the at least one motion component being less than the preset motion component threshold, the image processing apparatus is configured to perform the multi-frame noise reduction operation on the current video frame in the three-dimensional space domain. It can be seen that, in some embodiment of the present disclosure, when the image processing apparatus is performing the noise reduction on the current video frame, the image processing apparatus may first acquire the at least one motion component in the at least one direction of the image processing apparatus within the exposure duration, and then determine the motion value of the image processing apparatus based on the at least one motion component within the exposure duration. In response to the at least one motion component of the image processing apparatus within the exposure duration being greater than the preset motion component threshold, the image processing apparatus directly performs the first noise reduction operation on the current video frame in the two-dimensional space domain to reduce the operations of the processing of the alignment accuracy of multiple frames, thereby shortening the time of an image processing, and improving the speed of the image processing.</p><p id="p-0103" num="0096">Some embodiments of the present disclosure further disclose an image processing apparatus and the image processing apparatus includes: a processor, a memory storing instructions executable by the processor, a communication interface, and a bus configured to connect the processor, the memory, and the communication interface, wherein when the instructions are executed, the processor performs the above-mentioned image processing methods.</p><p id="p-0104" num="0097">Some embodiments of the present disclosure provide a non-transitory computer-readable storage medium storing a program, and the program is executed by the processor to implement the above-mentioned image processing methods.</p><p id="p-0105" num="0098">Specifically, in some embodiments, the program instructions corresponding to the image processing method may be stored in a non-transitory computer-readable storage medium such as an optical disk, a hard disk, a USB flash drives, etc. In response to the program instructions corresponding to the image processing method stored in the non-transitory computer-readable storage medium being read or executed by an electronic device, the image processing methods described above may be implemented.</p><p id="p-0106" num="0099">Those skilled in the art should understand that some embodiments of the present disclosure may provide a method, a system, or a computer program product. Therefore, some embodiments of the present disclosure may be in form of hardware embodiments, software embodiments, or some embodiments combining software with hardware. Moreover, some embodiments of the present disclosure may be in form of computer program products implemented on one or more computer-usable storage media (including but not limited to a disk storage, an optical storage, etc.) storing computer-usable program codes.</p><p id="p-0107" num="0100">The present disclosure is described with reference to schematic flowcharts and/or block diagrams for implementing operations of methods, equipment (systems), and computer program products according to some embodiments of the present disclosure. It should be understood that each operation and/or block in the schematic flowcharts and/or block diagrams and a combination of the operations and/or blocks in the schematic flowcharts and/or block diagrams may be implemented by computer program instructions. The computer program instructions may be provided to the processor of a general-purpose computer, a special-purpose computer, an embedded processor, or other programmable data processing devices to generate a machine, so that the instructions executed by the processor of the computer or other programmable data processing devices are configured to generate an apparatus for implementing specified functions in one or more operations in the schematic flowcharts and/or one or more blocks in the block diagrams.</p><p id="p-0108" num="0101">The computer program instructions may also be stored in a computer-readable memory that may direct a computer or other programmable data processing devices to work in a specific manner, so that the instructions stored in the computer-readable memory produce a product including an instruction device. The instruction device implements the specified functions in one or more processes in the schematic flowcharts and/or one or more blocks in the block diagrams.</p><p id="p-0109" num="0102">The computer program instructions may also be loaded on a computer or other programmable data processing devices, so that a series of operation blocks are executed on the computer or the other programmable equipment to produce computer-implemented operations. In this way, the instructions executed on the computer or other programmable equipment may implement specified functions in one or more processes in the schematic flowcharts and/or one or more blocks in the block diagrams.</p><p id="p-0110" num="0103">The foregoing description are only some embodiments of the present disclosure, and are not used to limit the protection scope of the present disclosure.</p><heading id="h-0007" level="1">INDUSTRIAL APPLICABILITY</heading><p id="p-0111" num="0104">The image processing apparatus is provided in some embodiments of the present disclosure. When the image processing apparatus is performing the noise reduction on the current video frame, the image processing apparatus first acquires the at least one motion component in at least one direction of the image processing apparatus within the exposure duration, and then determines the motion amplitude of the image processing apparatus based on the at least one motion component within the exposure duration. In response to the at least one motion component of the image processing apparatus within the exposure duration being greater than the preset motion component threshold, the image processing apparatus directly performs the first noise reduction operation on the current video frame in the two-dimensional space domain to reduce the operations of the processing of the alignment accuracy of multiple frames, thereby shortening the time duration of the image processing, and improving the speed of the image processing.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230005116A1-20230105-M00001.NB"><img id="EMI-M00001" he="8.13mm" wi="76.20mm" file="US20230005116A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230005116A1-20230105-M00002.NB"><img id="EMI-M00002" he="8.13mm" wi="76.20mm" file="US20230005116A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00003" nb-file="US20230005116A1-20230105-M00003.NB"><img id="EMI-M00003" he="8.13mm" wi="76.20mm" file="US20230005116A1-20230105-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00004" nb-file="US20230005116A1-20230105-M00004.NB"><img id="EMI-M00004" he="8.13mm" wi="76.20mm" file="US20230005116A1-20230105-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00005" nb-file="US20230005116A1-20230105-M00005.NB"><img id="EMI-M00005" he="8.13mm" wi="76.20mm" file="US20230005116A1-20230105-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00006" nb-file="US20230005116A1-20230105-M00006.NB"><img id="EMI-M00006" he="8.13mm" wi="76.20mm" file="US20230005116A1-20230105-M00006.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image processing method, comprising:<claim-text>acquiring an exposure duration of a current video frame and at least one motion component corresponding to at least one direction within the exposure duration;</claim-text><claim-text>performing a first noise reduction operation on the current video frame in a two-dimensional space domain in response to a first motion component of the at least one motion component being greater than a preset motion component threshold; and</claim-text><claim-text>performing a second noise reduction operation on the current video frame in a three-dimensional space domain in response to the at least one motion component being less than the preset motion component threshold.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The image processing method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein performing the first noise reduction operation on the current video frame in the two-dimensional space domain in response to the first motion component of the at least one motion component being greater than the preset motion component threshold, comprises:<claim-text>acquiring at least one motion radian corresponding to the at least one direction in response to the first motion component being greater than the preset motion component threshold; and</claim-text><claim-text>performing the first noise reduction operation on the current video frame in the two-dimensional space domain in response to a first motion radian of the at least one motion radian being greater than a preset radian threshold.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The image processing method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein acquiring at least one motion component corresponding to at least one direction within the exposure duration, comprises:<claim-text>dividing the exposure duration into a set of time samples;</claim-text><claim-text>acquiring at least one set of angular-velocity-component samples in at least one dimension during the set of time samples, wherein each of the at least one dimension corresponds to one of the at least one set of angular-velocity-component samples during the set of time samples;</claim-text><claim-text>determining an angular velocity component in the at least one dimension within the exposure duration based on the at least one set of angular-velocity-component samples; and</claim-text><claim-text>determining the angular velocity component in the at least one dimension as the at least one motion component corresponding to the at least one direction.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The image processing method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising:<claim-text>prohibiting the current video frame from being fused with an adjacent historical video frame and an adjacent next video frame in response to satisfying at least one of the following conditions:</claim-text><claim-text>the at least one motion component being greater than the preset motion component threshold; and</claim-text><claim-text>the at least one motion radian being greater than the preset radian threshold.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The image processing method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising:<claim-text>performing the second noise reduction operation on the current video frame by performing a multi-frame alignment on the current video frame with an adjacent historical video frame and an adjacent next video frame in response to satisfying at least one of the following conditions:</claim-text><claim-text>the first motion component being less than the preset motion component threshold; and</claim-text><claim-text>the first motion radian being less than the preset radian threshold.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The image processing method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein performing the second noise reduction operation on the current video frame in the three-dimensional space domain in response to the at least one motion component being less than the preset motion component threshold further comprises:<claim-text>performing the second noise reduction operation on the current video frame by aligning the current video frame with an adjacent historical video frame and an adjacent next video frame in response to all of the at least one motion component being less than the preset motion component threshold.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The image processing method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one motion component comprises an angular velocity component and an acceleration component.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The image processing method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, further comprising:<claim-text>in response to the at least one motion component comprising the angular velocity component in at least one dimension, determining a motion amplitude within the exposure duration based on an integral of an absolute value of the angular velocity component.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The image processing method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein acquiring the exposure duration of the current video frame and at least one motion component corresponding to at least one direction within the exposure duration, comprises:<claim-text>synchronizing the exposure duration of the current video frame and angular velocity data in first, second, and third directions within the exposure duration, wherein the first direction is substantially perpendicular to the second direction and the third direction, and the second direction is substantially perpendicular to the third direction; and</claim-text><claim-text>acquiring motion velocity values in the first, second, and third directions according to the angular velocity data in the first, second, and third directions within the exposure duration.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The image processing method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein performing the first noise reduction operation on the current video frame in the two-dimensional space domain in response to the first motion component of the at least one motion component being greater than the preset motion component threshold, comprises:<claim-text>acquiring motion angles in the first, second, and third directions in response to at least one of the motion velocity values among the motion velocity values in the first, second, and third directions being greater than a preset motion velocity value threshold; and</claim-text><claim-text>performing the first noise reduction operation on the current video frame in the two-dimensional space domain in response to at least one of the motion angles in the first, second, and third directions being greater than a preset motion angle threshold.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. An image processing apparatus, comprising:<claim-text>a processor, a memory storing instructions executable by the processor, a communication interface, and a bus configured to connect the processor, the memory, and the communication interface, wherein when the instructions are executed, the processor performs an image processing method, the method comprising:</claim-text><claim-text>acquiring an exposure duration of a current video frame and at least one motion component corresponding to at least one direction within the exposure duration;</claim-text><claim-text>performing a first noise reduction operation on the current video frame in a two-dimensional space domain in response to a first motion component of the at least one motion component being greater than a preset motion component threshold; and</claim-text><claim-text>performing a second noise reduction operation on the current video frame in a three-dimensional space domain in response to the at least one motion component being less than the preset motion component threshold.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The image processing apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein performing the first noise reduction operation on the current video frame in the two-dimensional space domain in response to the first motion component of the at least one motion component being greater than a preset motion component threshold, comprises:<claim-text>acquiring at least one motion radian corresponding to the at least one direction in response to the first motion component being greater than the preset motion component threshold; and</claim-text><claim-text>performing the first noise reduction operation on the current video frame in the two-dimensional space domain in response to a first motion radian of the at least one motion radian being greater than a preset radian threshold.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The image processing apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein acquiring at least one motion component corresponding to at least one direction within the exposure duration, comprises:<claim-text>dividing the exposure duration into a set of time samples;</claim-text><claim-text>acquiring at least one set of angular-velocity-component samples in at least one dimension during the set of time samples, wherein each of the at least one dimension corresponds to one of the at least one set of angular-velocity-component samples during the set of time samples;</claim-text><claim-text>determining an angular velocity component in the at least one dimension within the exposure duration based on the at least one set of angular-velocity-component samples; and</claim-text><claim-text>determining the angular velocity component in the at least one dimension as the at least one motion component corresponding to the at least one direction.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The image processing apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the method further comprises:<claim-text>prohibiting the current video frame from being fused with an adjacent historical video frame and an adjacent next video frame in response to satisfying at least one of the following conditions:</claim-text><claim-text>the at least one motion component being greater than the preset motion component threshold; and</claim-text><claim-text>the at least one motion radian being greater than the preset radian threshold.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The image processing apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the method further comprises:<claim-text>performing the second noise reduction operation on the current video frame by performing a multi-frame alignment on the current video frame with an adjacent historical video frame and an adjacent next video frame in response to satisfying at least one of the following conditions:</claim-text><claim-text>the first motion component being less than the preset motion component threshold; and</claim-text><claim-text>the first motion radian being less than the preset radian threshold.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A non-transitory computer-readable storage medium, storing a program applied to an image processing apparatus, wherein the program is executed by a processor to implement an image processing method, the method comprising:<claim-text>acquiring an exposure duration of a current video frame and at least one motion component corresponding to at least one direction within the exposure duration;</claim-text><claim-text>performing a first noise reduction operation on the current video frame in a two-dimensional space domain in response to a first motion component of the at least one motion component being greater than a preset motion component threshold; and</claim-text><claim-text>performing a second noise reduction operation on the current video frame in a three-dimensional space domain in response to the at least one motion component being less than the preset motion component threshold.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein performing the first noise reduction operation on the current video frame the two-dimensional space domain in response to the first motion component of the at least one motion component being greater than the preset motion component threshold, comprises:<claim-text>acquiring at least one motion radian corresponding to the at least one direction in response to the first motion component being greater than the preset motion component threshold; and</claim-text><claim-text>performing the first noise reduction operation on the current video frame in the two-dimensional space domain in response to a first motion radian of the at least one motion radian being greater than a preset radian threshold.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein acquiring at least one motion component corresponding to at least one direction within the exposure duration, comprises:<claim-text>dividing the exposure duration into a set of time samples;</claim-text><claim-text>acquiring at least one set of angular-velocity-component samples in at least one dimension during the set of time samples, wherein each of the at least one dimension corresponds to one of the at least one set of angular-velocity-component samples during the set of time samples;</claim-text><claim-text>determining an angular velocity component in the at least one dimension within the exposure duration based on the at least one set of angular-velocity-component samples; and</claim-text><claim-text>determining the angular velocity component in the at least one dimension as the at least one motion component corresponding to the at least one direction.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the method further comprises:<claim-text>prohibiting the current video frame from being fused with an adjacent historical video frame and an adjacent next video frame in response to satisfying at least one of the following conditions:</claim-text><claim-text>the at least one motion component being greater than the preset motion component threshold; and</claim-text><claim-text>the at least one motion radian being greater than the preset radian threshold.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the method further comprises:<claim-text>performing the second noise reduction operation on the current video frame by performing a multi-frame alignment on the current video frame with an adjacent historical video frame and an adjacent next video frame in response to satisfying at least one of the following conditions:</claim-text><claim-text>the first motion component is less than the preset motion component threshold; and</claim-text><claim-text>the first motion radian is less than the preset radian threshold.</claim-text></claim-text></claim></claims></us-patent-application>
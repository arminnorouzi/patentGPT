<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004174A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004174</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17857662</doc-number><date>20220705</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>10</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>64</class><subclass>C</subclass><main-group>39</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>104</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>0088</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>64</class><subclass>C</subclass><main-group>39</main-group><subgroup>024</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>64</class><subclass>C</subclass><main-group>2201</main-group><subgroup>145</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>64</class><subclass>C</subclass><main-group>2201</main-group><subgroup>146</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">Vehicle Autonomy Architecture</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63218113</doc-number><date>20210702</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Joby Aero, Inc.</orgname><address><city>Santa Cruz</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Burghardt</last-name><first-name>Michael</first-name><address><city>Santa Cruz</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Scott</last-name><first-name>Simon</first-name><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Laurenzi</last-name><first-name>Michael</first-name><address><city>Santa Cruz</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Primiani</last-name><first-name>Rurik</first-name><address><city>Coral Gables</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Haderer</last-name><first-name>Andreas</first-name><address><city>Santa Cruz</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Systems and methods for controlling aerial vehicles are provided. An aerial vehicle includes a single circuit board with a number of processor devices and a memory including instructions to perform autonomy operations. The autonomy operations include obtaining GNSS data from GNSS assemblies electrically connected to the processor devices, APNT data from APNT assemblies electrically connected to the processor devices, and radar data from the radar assemblies electrically connected to the processor devices. Each of the assemblies are disposed on the same circuit board that includes the number of processor devices. The processor devices determine a vehicle location based on the GNSS data, the APNT data, and the radar data, identify airborne objects based on the radar data, generate a motion plan based on the vehicle location and the identified objects, and initiate a motion of the aerial vehicle based on the vehicle location.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="110.91mm" wi="158.75mm" file="US20230004174A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="241.47mm" wi="169.42mm" orientation="landscape" file="US20230004174A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="208.87mm" wi="93.73mm" orientation="landscape" file="US20230004174A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="192.19mm" wi="163.66mm" orientation="landscape" file="US20230004174A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="234.27mm" wi="169.08mm" orientation="landscape" file="US20230004174A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="222.17mm" wi="161.71mm" orientation="landscape" file="US20230004174A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="238.34mm" wi="162.56mm" orientation="landscape" file="US20230004174A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="237.41mm" wi="116.08mm" orientation="landscape" file="US20230004174A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="191.77mm" wi="136.31mm" file="US20230004174A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="173.06mm" wi="139.28mm" orientation="landscape" file="US20230004174A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="131.23mm" wi="149.27mm" file="US20230004174A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="117.26mm" wi="149.10mm" file="US20230004174A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="105.41mm" wi="72.14mm" file="US20230004174A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="180.09mm" wi="126.24mm" orientation="landscape" file="US20230004174A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims priority to and the benefit of U.S. Provisional Patent Application No. 63/218,113, filed Jul. 2, 2021, which is hereby incorporated by reference in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">The present disclosure relates generally to vehicle technology. More particularly, the present disclosure relates to an autonomy computing architecture for aerial vehicles.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">A wide variety of modes of transport are available within cities. For example, people can walk, ride a bike, drive a car, take public transit, or use a ride sharing service. As population densities and demand for land increase, however, many cities are experiencing problems with traffic congestion and the associated pollution. Consequently, there is a need to expand the available modes of transport in ways that can reduce the amount of traffic without requiring the use of large amounts of land. Air travel within cities can reduce travel time over purely ground-based approaches and alleviate problems associated with traffic congestion. Vertical takeoff and landing (VTOL) aircraft provide opportunities to incorporate aerial transportation into transport networks for cities and metropolitan areas. VTOL aircraft require much less space to take-off and land than other types of aircraft, making them more suitable for densely populated urban environments.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0005" num="0004">Aspects and advantages of embodiments of the present disclosure will be set forth in part in the following description, or can be learned from the description, or can be learned through practice of the embodiments.</p><p id="p-0006" num="0005">Aspects of the present disclosure are directed to a circuit board in communication with one or more device controllers of an aerial vehicle. The circuit board includes a processor device and a plurality of sensor assemblies electrically connected to the processor device. The plurality of sensor assemblies include one or more global navigation satellite system (GNSS) assemblies, one or more alternative position navigation and timing (APNT) assemblies, and one or more radio detection and ranging (RADAR) assemblies. In addition, the circuit board includes one or more memory devices storing computer-readable instructions that when executed cause the processor device to implement a guidance system and a flight control system. The guidance system is configured to generate one or more motion plans for an aerial vehicle and the flight control system is configured to provide one or more actuator commands associated with the one or more motion plans to the one or more device controllers.</p><p id="p-0007" num="0006">Other aspects of the present disclosure are directed to an aerial vehicle. The aerial vehicle includes an arrangement of a plurality of circuit boards mounted to the aerial vehicle. Each circuit board of the plurality of circuit boards is located at a different position onboard the aerial vehicle. The arrangement of the plurality of circuit boards includes a control hierarchy indicative of a primary circuit board and one or more redundant circuit boards for performing each of one or more aerial vehicle tasks. Each circuit board of the plurality of circuit boards includes a processor device and a plurality of sensor assemblies electrically connected to the processor device. The plurality of sensor assemblies include one or more global navigation satellite system (GNSS) assemblies, one or more alternative position navigation and timing (APNT) assemblies, and one or more radio detection and ranging (RADAR) assemblies. In addition, each circuit board includes one or more memory devices storing computer-readable instructions that when executed cause the processor device to implement a surveillance system, a localization system, a guidance system, and a flight control system. The surveillance system, the localization system, the guidance system, and the flight control system are configured to perform the one or more aerial vehicle tasks.</p><p id="p-0008" num="0007">Yet other example aspects of the present disclosure are directed to another aerial vehicle. The vehicle includes one or more processor devices and one or more non-transitory computer-readable media that collectively store instructions that, when executed by the one or more processors, cause the computing system to perform operations. The operations include obtaining global navigation satellite system (GNSS) data from one or more GNSS assemblies electrically connected to the one or more processor devices. The operations include obtaining alternative position navigation and time (APNT) data from one or more APNT assemblies electrically connected to the one or more processor devices. The operations include obtaining radio detection and ranging (radar) data from the one or more radar assemblies electrically connected to the one or more processor devices. The operations include determining a vehicle location based, at least in part, on the GNSS data, the APNT data, and the radar data. The operations include initiating a motion of the aerial vehicle based, at least in part, on the vehicle location.</p><p id="p-0009" num="0008">Other aspects of the present disclosure are directed to various systems, apparatuses, non-transitory computer-readable media, user interfaces, and electronic devices. These and other features, aspects, and advantages of various embodiments of the present disclosure will become better understood with reference to the following description and appended claims. The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate example embodiments of the present disclosure and, together with the description, serve to explain the related principles.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0009">Detailed discussion of embodiments directed to one of ordinary skill in the art is set forth in the specification, which makes reference to the appended figures, in which:</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a block diagram of an example system for an autonomous vehicle according to example embodiments of the present disclosure;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts an example multi-modal transportation itinerary according to example embodiments of the present disclosure;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts an example system for facilitating a multi-modal transportation itinerary according to example embodiments of the present disclosure;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts a block diagram of an example autonomy computing system according to example embodiments of the present disclosure;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts an example radar assembly design according to example embodiments of the present disclosure;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts a reconfigurable autonomy computing system environment according to example embodiments of the present disclosure;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts a number of reference points for an example aerial vehicle according to example embodiments of the present disclosure;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>8</b></figref> depicts an example arrangement of autonomy computing systems relative to an example aerial vehicle according to example embodiments of the present disclosure;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>9</b></figref> depicts an example control hierarchy for an autonomous vehicle with a number of redundant autonomy computing systems according to example embodiments of the present disclosure;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>10</b></figref> depicts an example method for controlling the motion of an aerial vehicle according to example embodiments of the present disclosure;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>11</b></figref> depicts an example method for localizing an aerial vehicle according to example embodiments of the present disclosure;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>12</b></figref> depicts an example system with various means for performing operations and functions according to example embodiments of the present disclosure; and</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>13</b></figref> depicts an example computing system according to example embodiments of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0024" num="0023">Example aspects of the present disclosure are directed to improved autonomy computing architectures and techniques for aerial vehicles. An aerial vehicle can include a number of different hardware and software components for facilitating autonomous flight. Such components can include a number of different propulsion devices (e.g., rotor assemblies, electric motors, turbines, etc.) and an autonomy system configured to communicate with the propulsion devices to initiate motion of the aerial vehicle. For example, the aerial vehicle can be a vertical takeoff and landing (VTOL) aircraft that is all-electric powered, hybrid-electric powered, etc. In order to lower weight, size, power, cost, and bandwidth requirements for implementing various functions of an autonomy computing system, the present disclosure presents a single circuit board including the components that allow an aerial vehicle to autonomously travel. The circuit board can include a number of processor devices (e.g., a system on a chip platform including a number of processors, a field-programmable gate array, internal storage, etc.) and a number of different hardware sensor assemblies (e.g., global navigation satellite systems, alternative position navigation and timing systems, radar systems, etc.) electrically connected (e.g., via circuit tracks, conductive wiring, etc. of the circuit board) to the processor devices. In addition, the circuit board can include a number of memories storing software (e.g., computer-readable instructions) for implementing various autonomy systems (e.g., surveillance systems, localization systems, guidance systems, flight control systems, etc.) to enable autonomous flight. This can allow for improved location tracking through the implementation of triple redundant localization techniques. Moreover, as will be further described herein, the circuit board can be reconfigurable to allow for efficient integration with various vehicles and redundant for intelligent and selective distribution of autonomy tasks. In this manner, the technology of the present disclosure can improve autonomy systems in general by decreasing bandwidth requirements and increasing processing speeds for sensor data used for safely performing autonomous operations. For instance, the autonomy system of the present disclosure can minimize the amount of data copied from one location (e.g., a receiver, etc.) to another (e.g., a processing system, etc.) by digitizing sensor data (e.g., analog data) received at an antenna receiver with processor device(s) (e.g., device(s) configured to implement autonomy functions of the aerial vehicle) mounted to the same board as the receiver.</p><p id="p-0025" num="0024">The autonomy system of the present disclosure can be mounted to a vehicle of any modality such as, for example, an aerial-based vehicle, as well as a ground-based, water-based, and/or space-based modalities. For instance, the vehicle can include an aerial vehicle. As an example, the aerial vehicle can include any type of vertical take-off and landing aircraft (e.g., VTOL, electric VTOL, etc.), fixed-wing aircraft, rotorcraft, tilt-rotor aircraft, tilt-prop aircraft, tilt-wing aircraft, helicopter, jet craft, and/or other types of aerial vehicle. The aerial vehicle can include one or more propulsion devices (e.g., rotor assemblies, electric motors, turbines, etc.) for initiating motion (e.g., flight maneuvers, take-off maneuvers, landing maneuvers, etc.) of the aerial vehicle. Each propulsion device can include a corresponding device controller (e.g., electric speed controllers, etc.) for controlling the speed, direction, and/or any other characteristic of the propulsion device. For instance, each device controller can receive actuator commands (e.g., from an onboard computing system, a remote computing system, one or more input devices, etc.) and generate instructions for a corresponding propulsion device based, at least in part, on the received actuator commands. The actuator commands, for example, can be data packets, signals, etc. generated and provided to the device controllers by an autonomy computing system onboard the aerial vehicle.</p><p id="p-0026" num="0025">For instance, the aerial vehicle can be an autonomous and/or semi-autonomous aerial vehicle controlled (e.g., at least partly) by an autonomy computing system. The autonomy computing system can include components and circuitry to enable the aerial vehicle to travel autonomously, without human input for at least some time period. For instance, the autonomy computing system can include a single circuit board (e.g., a printed circuit board (PCB), substrate, and/or any other physical sheet of insulating material for mounting and connecting electrical equipment) configured to receive raw sensor data and control propulsion device(s) to autonomously operate the aerial vehicle. The circuit board can include one or more board layers (e.g., a single-sided circuit board, a double sided circuit board, a multi-layered circuit board, etc.). The board layer(s) can include at least one substrate layer and at least one conductive layer. For example, the circuit board can include a physical board that can mechanically support and electrically connect electrical components using conductive tracks, pads, and/or other features etched from one or more sheet layers of a conductive material (e.g., copper and/or any other conductive material) laminated onto and/or between sheet layers of non-conductive substrate. The circuit board can include electrical components to enable the performance of aerial vehicle task(s) for safe autonomous mobility. For example, each board can include hardware and software for implementing one or more surveillance system(s), localization system(s), guidance system(s), and/or flight control system(s).</p><p id="p-0027" num="0026">In some implementations, the aerial vehicle can include one or more external components onboard the aerial vehicle in addition to the circuit board (e.g., autonomy computing system). For example, the vehicle can include one or more external memories (e.g., a high speed data recorder, random access memory(s), solid state drive(s), etc.), one or more sensors (e.g., LiDAR sensors, external radar sensors, image sensors, correctional sensor networks, etc.), a power network (e.g., battery(s) configured to power the components onboard the aircraft, etc.), and/or one or more flight network device(s) (e.g., external communication interfaces and/or other aerial vehicle instruments configured to consume outputs of the autonomy system and/or provide external inputs to the autonomy system, etc.). Each external component can be connected to the circuit board via one or more communication interfaces such as, for example, via one more ethernet connections. The ethernet connections, for example, can include a distribution network of one or more power over ethernet cables (e.g., gigabit ethernet cables, etc.) configured to distribute power and data across a plurality of different device(s) onboard the aerial vehicle.</p><p id="p-0028" num="0027">Ethernet and/or other wired (or wireless) data transfer connections can have limited bandwidth capabilities and require information to be copied from (e.g., via a wired or wireless connection) a source location (e.g., a sensor receiver/digitizing front end, etc.) to a destination location (e.g., a flight computer, processor devices, etc.). Such limitations can be disadvantageous for transferring data used in real-time autonomy operations. To overcome such limitations, the circuit board (e.g., the autonomy computing system) of the present disclosure can connect components used in real-time autonomous flight via one or more conductive layer connections of the circuit board. For example, the circuit board can include at least one conductive layer with a plurality of circuit tracks for electrically connecting all of the components (e.g., to allow for autonomous flight, etc.) disposed on (e.g., mounted to, located on, etc.) the circuit board.</p><p id="p-0029" num="0028">More particularly, the circuit board can include one or more processor devices (e.g., a flight computer) and a plurality of sensor assemblies disposed on (e.g., mounted to, attached to, located on, etc.) the circuit board. The one or more processor devices can include a system on a chip platform including a programmable logic, a processing system, an internal memory, and/or I/O interface(s). The processing system, for example, can include a plurality of processors such as one or more microprocessors (e.g., ARM A53 processor(s), ARM R5 processor(s), etc.) and/or one or more graphics processing units (e.g., Mali-400 MP2(s), etc.). The programmable logic can include one or more field-programmable gate arrays with a plurality (e.g., nine hundred and thirty thousand, etc.) of logic cells (e.g., single level cells, etc.), a plurality (e.g., four thousand two hundred and seventy two, etc.) of arithmetic logic units (e.g., DSP48s, etc.), and/or a programmable memory.</p><p id="p-0030" num="0029">The plurality of sensor assemblies can include global navigation satellite system (GNSS) assembly(s), alternative position navigation and timing (APNT) assembly(s), and/or radio detection and ranging (radar) assembly(s). In some implementations, the circuit board can include additional sensor(s) such as, for example, one or more inertial measurement unit (IMU) sensor(s) (e.g., three IMU sensor(s), one or more barometer(s) (e.g., three barometers, etc.), magnetometer(s) (e.g., three magnetometers, etc.), and/or any other sensor for autonomous flight. By way of example, the inertial measurement unit(s) can include a three axis gyroscope and a three axis accelerometer. In addition, or alternatively, the additional sensor(s) can include one or more external air data sensor(s) such as, for example, one or more pitot tubes, one or more multi-function probes or vanes, and/or any combination thereof.</p><p id="p-0031" num="0030">The plurality of sensor assemblies (and/or additional sensor(s)) can be disposed on (e.g., mounted to, attached to, located on, etc.) the circuit board and electrically connected to the processor device(s) (e.g., the field-programmable gate array) via one or more circuit tracks etched into conductive layer(s) of the circuit board or otherwise implemented on the circuit board (e.g., by conductive traces, etc.). In this manner, sensor information (e.g., analog sensor signals, digitalized sensor signals, etc.) can be communicated directly to the processor device(s).</p><p id="p-0032" num="0031">The GNSS assembly(s) can include at least one GNSS receiver antenna disposed on (e.g., mounted, attached, located, etc.) the circuit board and/or a software defined receiver for providing GNSS data to the processor devices via board circuitry (e.g., internal bus circuitry, circuit tracks, and/or any other circuitry of the circuit board) of the circuit board. In this manner, GNSS data (e.g., analog signals, etc.) received by GNSS receiver antenna(s) can be directly communicated to a field-programmable gate array configured to process the GNSS data (e.g., digitalize the GNSS data, etc.). The GNSS assembly(s) can include any type of GNSS assembly such as, for example, one or more global positioning system(s) (GPS), European satellite navigation system(s) (Galileo), global navigation satellite system(s) (GLONASS), BeiDou system(s), etc. In some implementations, the GNSS assemblies can include at least two GPS receivers (e.g., one or more L1/L5 receivers) and/or at least two Galileo receivers (e.g., one or more E1/E5 receivers).</p><p id="p-0033" num="0032">The APNT assembly(s) can include at least one APNT receiving antenna disposed on (e.g., mounted, attached, located, etc.) the circuit board and a software defined receiver (e.g., down samplers, etc.) for providing APNT data (e.g., analog signals, etc.) to the processor devices via board circuitry (e.g., internal bus circuitry, circuit tracks, and/or any other circuitry of the circuit board) of the circuit board. In this manner, APNT data received by APNT receiver antenna(s) can be directly communicated to a field-programmable gate array configured to process (digitalize, etc.) the APNT data. The APNT assembly(s) can include any type of APNT assembly such as, for example, one or more cellular network receivers, pseudolite receivers, ultra-wide band receivers, etc. In some implementations, the APNT assembly(s) can include radar assemblies and the APNT data can include alternative positioning and navigation radar data. For instance, in some implementations, the APNT assembly(s) can include radar assemblies such that the APNT assembly(s) can use the radar signal to communicate directly with ground beacons. This implementation may provide for the omission of separate and/or additional hardware dedicated to APNT functionality while still providing capability for explicit processing of the APNT functionality.</p><p id="p-0034" num="0033">The radar assemblies can include at least one radar receiving antenna and at least one radar transmitter antenna disposed on the circuit board and software defined receivers (e.g., radio frequency up/down converters, etc.) for providing radar data (e.g., analog signals, etc.) to the processor devices via board circuitry (e.g., internal bus circuitry, circuit tracks, and/or any other circuitry of the circuit board) of the circuit board. In this manner, radar data received by the radar receiver antenna(s) can be directly communicated to a field-programmable gate array configured to process (e.g., digitalize, etc.) the radar data. In some implementations, the radar assembly(s) can include a plurality (e.g., four, sixteen, etc.) of radar receiving antennas and a plurality (e.g., four, sixteen, etc.) of radar transmitter antennas.</p><p id="p-0035" num="0034">The circuit board (and/or the processor device(s) thereof) can include one or more memory(s) storing computer-readable instructions for controlling one or more (e.g., in some cases all) aspects of autonomous flight. For example, the instructions can include instructions for implementing a surveillance system, a localization system, a guidance system, and/or a flight control system. Each of the systems can be configured to perform one or more aerial vehicle task(s). For example, the surveillance system can be configured to perform surveillance task(s) such as, for example, identifying object(s), identifying and/or assessing one or more weather conditions, identifying and/or assessing one or more terrains, landing zones, emergency landing zone, etc. within the surrounding environment of the aerial vehicle. The localization system can be configured to perform localization task(s) such as, for example, determining a current location, velocity, attitude, angular velocity, etc. for the aerial vehicle. The guidance system can be configured to perform motion planning task(s) such as, for example, generating motion plan(s) for the aerial vehicle based, at least in part, on the current location of the vehicle and identified object(s) within the surrounding environment of the vehicle. The flight control system can be configured to perform actuator command task(s) such as, for example, generating and/or providing actuator command(s) associated with the motion plan(s) to one or more device controller(s) of the aerial vehicle.</p><p id="p-0036" num="0035">In this manner, the autonomy computing system (e.g., the processor devices of the circuit board) can receive sensor data (e.g., radar, GNSS, APNT data, etc.) directly from the respective sensor assembly(s) (e.g., radar, GNSS, APNT assemblies, etc.) disposed on the circuit board via board circuitry (e.g., internal bus circuitry, circuit tracks, and/or any other circuitry of the circuit board) of the circuit board and process the sensor data to generate actuator command(s). For example, the autonomy computing system can determine a vehicle location for the aerial vehicle based, at least in part, on the radar data, the GNSS data, and the APNT data. For instance, as described herein, the system can perform triple redundant dissimilar location techniques to determine accurate vehicle location estimates.</p><p id="p-0037" num="0036">In addition, the system can determine one or more object locations for object(s) proximate to the aerial vehicle based, at least in part, on the radar data. For example, the radar data (e.g., digitalized analog radio signals, etc.) can be input to an object detection algorithm including one or more classical algorithm(s), machine-learning model(s) (e.g., a neural network, etc.) and/or any other computing function configured to detect (and/or facilitate the detection of) one or more airborne objects (e.g., location, speed, altitude, etc.) based on raw radar data samples. The object detection algorithm, for example, can be implemented and/or trained (e.g., using one or more machine-learning techniques (e.g., unsupervised, supervised, etc.)) to identify and/or track airborne (and/or other) objects. As an example, an object detection machine-learning model can be trained via backpropagation using labelled training data indicative of raw sensor signals and corresponding objects (and/or the location, speed, altitude, etc. thereof). In some implementations, the radar data can be used in conjunction with and/or to validate data from other sensor systems or positioning systems, such as automatic dependent surveillance-broadcast (ADS-B) data.</p><p id="p-0038" num="0037">Moreover, the system can determine flight maneuver(s) based, at least in part, on the vehicle location and/or the object location(s). For instance, the system can determine the flight maneuver(s) based, at least in part, on the performance of trajectory planning and/or obstacle avoidance. The flight maneuver(s), for example, can include one or more directional movements to avoid an airborne object, create a buffer distance between the aerial vehicle and the airborne object, and/or perform one or more landing/take-off/navigation procedures.</p><p id="p-0039" num="0038">By way of example, the system can be configured to perform a landing zone assessment in preparation for a landing maneuver. To do so, the system can input raw radar signals (e.g., digitalized analog radio signals) indicative of a landing area to a semantic landing assessment algorithm including one or more classical algorithm(s), machine-learned model(s) (e.g., neural network, etc.) configured (e.g., trained, etc.) to output one or more semantic labels based, at least in part, on the input radar signals. The semantic labels, for example, can identify one or more object(s) within a landing area of the aerial vehicle. As another example, the system can determine an occupancy grid. The system can determine an equation of a plane for each grid point of the occupancy grid and determine whether a landing area is occupied based on the slope, altitude, and/or variance of the equation. This approach can be implemented through one or more classical computing algorithms.</p><p id="p-0040" num="0039">As another example, the autonomy computing system can initiate a motion of the aerial vehicle based, at least in part, on the vehicle location, the flight maneuvers, and/or the object(s) proximate to the aerial vehicle. To do so, the system can generate actuator command(s) based, at least in part, on the one or more flight maneuvers and provide the actuator command(s) to one or more device controller(s) of the aircraft.</p><p id="p-0041" num="0040">In some implementations, the autonomy computing system can store (e.g., in a high speed data recorder) data indicative of the vehicle location, the object location(s), and/or the flight maneuver(s) in memory (e.g., an external memory external to the circuit board) onboard the aerial vehicle. The stored data can be compared to correctional data to determine one or more modification(s) for the autonomy system (e.g., processor device(s) thereof and/or instruction(s) stored therein). For example, the autonomy computing system can receive, via one or more communication interfaces (e.g., wired/wireless interfaces, etc.), correctional data from an external sensor network onboard the aerial vehicle. The correctional data can include, for example, additional data (e.g., LiDAR data, image data, etc.) recorded by one or more external sensor(s) (e.g., LiDAR sensors, cameras, etc. connected via one or more wired/wireless interface(s)) of the external sensor network onboard the aerial vehicle but not disposed on the circuit board. The autonomy computing system can store the correctional data on a high speed data recorder onboard the aerial vehicle. In this manner, the data indicative of the vehicle location, the object location(s), and/or the flight maneuver(s) can be compared to the correctional data (e.g., out-of-the-loop such as when the vehicle is grounded, etc.) to determine modification(s) for the autonomy computing system (e.g., debug software, maintain hardware, etc.).</p><p id="p-0042" num="0041">As described herein, the autonomy computing system can utilize a plurality of sensor processing techniques for determining a current vehicle location. As an example, the system can perform triple redundant localization using at least three dissimilar signal receivers electrically connected to the circuit board. The current vehicle location, for example, can include a geospatial position (and/or any other positional reference) including lateral coordinate(s), longitudinal coordinate(s), and/or altitude measurement(s). The system can determine a current vehicle location based, at least in part, on a plurality of position estimates generated using at least three dissimilar localization techniques. The vehicle location can be determined by applying a voting algorithm (e.g., stored in memory of the circuit board, etc.) to the plurality of position estimates to obtain a consensus current vehicle location.</p><p id="p-0043" num="0042">By way of example, the autonomy computing system can determine one or more first, second, and/or third position estimates for the aerial vehicle at a respective time. The first position estimate(s) can be determined based, at least in part, on GNSS data received from the one or more GNSS assemblies. The GNSS data, for example, can include one or more navigation satellite signals (e.g., GPS satellite signals, Galileo satellite signals, etc.). The navigation satellite signals, for instance, can include one or more radio time signals received along a line of sight from one or more of a constellation of navigation satellites by the GNSS assembly(s) (e.g., antennas thereof). The one or more radio time signals (e.g., digitalized signals, etc.) can be processed by the autonomy computing system (via one or more GNSS processing techniques) to determine at least one first position estimate for the aerial vehicle.</p><p id="p-0044" num="0043">The autonomy computing system can determine the second position estimate(s) for the aerial vehicle at the respective time based, at least in part, on APNT data received from the APNT assembly(s). The APNT data, for example, can include one or more network signal(s) (e.g., cellular network signals, pseudolite signals, ultra-wide band signals, etc.). The network signal(s), for instance, can include one or more radio signals received from one or more network access points (and/or pseudolites, etc.) by the APNT assembly(s) (e.g., antennas thereof). As an example, the network signals can include cellular network signals indicative of one or more cellular access points within range of the APNT assembly(s). In such a case, the autonomy computing system can determine an access point location for each of the cellular access points (e.g., via a look-up table and/or information from the network signals) and determine at least one second position estimate based, at least in part, on the access point location for each of the cellular access points. As other examples, the network signals can include one or more radio signals received from pseudolite(s), ultra-wide band access point(s), and/or any other alternative positioning, navigation, and timing sources. In such a case, the radio signals can be processed (e.g., via one or more respective APNT processing techniques) to determine additional second position estimates for the aerial vehicle.</p><p id="p-0045" num="0044">The autonomy computing system can determine the third position estimate(s) for the aerial vehicle at the respective time based, at least in part, on radar data received from the radar assembly(s). The radar data can include one or more radar signals. The radar signals can be processed by the autonomy computing system, via one or more processing techniques, to determine a third position estimate. For example, the radar signal(s) can be processed using one or more radar odometry techniques. The radar odometry techniques, for example, can include determining a positional change for the aerial vehicle from a starting time to the respective time based, at least in part, on the radar signals and determining at least one of the one or more third position estimates by applying the positional change to a starting position of the aerial vehicle. As another example, the radar signal(s) can be processed using one or more radar terrain reference navigation techniques. For example, the radar signal(s) (e.g., digitalized analog radio signals, etc.) can be indicative of a terrain within a surrounding environment of the aerial vehicle. In such a case, the autonomy system can determine a third position estimate based, at least in part, on a comparison between the terrain and a pre-determined terrain navigation map. As yet another example, the radar signal(s) can be processed using one or more radar beacon techniques. For instance, the radar data can be indicative of beacon signals received from one or more passive and/or active radar beacons. The autonomy system can determine one or more beacon positions for the one or more radar beacons based, at least in part, on the beacon signals and determine at least one third position estimate based, at least in part, on the beacon position(s) (and/or an estimated distance therefrom).</p><p id="p-0046" num="0045">In some implementations, the autonomy computing system (e.g., the circuit board) can be reconfigurable to apply to a plurality of different vehicle types. By way of example, the same autonomy computing system (e.g., circuit board) can be reconfigured (e.g., without hardware changes) to control any of a plurality of different types of aerial vehicles. For example, an aerial vehicle can be associated with an aerial vehicle type (e.g., subscale vehicles, full scale vehicles, eVTOLs, etc.). Each respective aerial vehicle type of the plurality of aerial vehicle types can be associated with one or more respective aerodynamic models (e.g., data descriptive of a pitch, roll, yaw, torque, speed, center of gravity, and/or any other characteristic of a vehicle type) and/or radar sampling parameters (e.g., expected signal noise, sampling frequencies, etc.). The aerodynamic models/sampling parameters, for example, can be based, at least in part, on the size, weight, layout, and/or any other physical/electrical characteristics of a respective vehicle type. The autonomy computing system can be configured for a respective aerial vehicle associated with a respective vehicle type by storing one or more motion models (e.g., descriptive of motion parameters (e.g., pitch, roll, yaw, torque, and/or any other parameters for generating desired movements based on a center of gravity and/or other characteristics of an aircraft)) and/or radar sampling parameters (e.g., expected signal noise, sampling frequencies, etc.) corresponding to the respective aerial vehicle type on one or more memories of the autonomy computing system.</p><p id="p-0047" num="0046">By way of example, the autonomy computing system can be initially configured for a first aerial vehicle associated with a first vehicle type. In such a case, the one or more memories of the autonomy computing system can include one or more computer-readable instructions for implementing the various systems of the autonomy computing system (e.g., surveillance system, localization system, guidance system, flight control system, etc.) that include one or more first motion parameters and/or first radar sampling parameters corresponding to the first vehicle type. The one or more first motion parameters and/or first radar sampling parameters can be based, at least in part, on the one or more respective aerodynamic models associated with the first vehicle type.</p><p id="p-0048" num="0047">The one or more memories of the same autonomy computing system can be modified to reconfigure the reconfigurable circuit board for use on a second aerial vehicle. The one or more modified memories can include modified computer-readable instructions for implementing the various systems of the autonomy computing system (e.g., surveillance system, localization system, guidance system, flight control system, etc.) that include one or more second motion parameters and/or second radar sampling parameters corresponding to the second vehicle type. The one or more second motion parameters and/or second radar sampling parameters, for example, can be based, at least in part, on the one or more respective aerodynamic models associated with the second vehicle type.</p><p id="p-0049" num="0048">In some implementations, the aerial vehicle can include multiple redundant autonomy computing systems. For example, the aerial vehicle can include a plurality of circuit boards, with each circuit board capable of performing all aerial vehicle tasks to enable autonomous flight. The multiple redundant circuit boards can be placed in a plurality of different arrangements relative to the aerial vehicle. For example, the aerial vehicle can include an arrangement of a plurality of circuit boards disposed on the aerial vehicle. Each respective circuit board in the arrangement of the plurality of circuit boards can be associated with a respective position relative to the aerial vehicle. For example, the aerial vehicle can define a front side, a first lateral side, a second lateral side opposite the first lateral side, and/or a rear side opposite the front side. The plurality of circuit boards can include a front circuit board disposed on (e.g., mounted to, attached to, affixed to, located at, etc.) the front side (e.g., where the field of view of the sensors of the circuit board are facing forward/downward from the aerial vehicle, etc.) of the aerial vehicle, a first lateral side circuit board disposed on (e.g., mounted to, attached to, affixed to, located at, etc.) the first lateral side of the aerial vehicle, and a second lateral side circuit board disposed on (e.g., mounted to, attached to, affixed to, located at, etc.) the second lateral side of the aerial vehicle.</p><p id="p-0050" num="0049">In some implementations, the arrangement of the plurality of circuit boards can include a control hierarchy identifying which board controls each autonomy task for the aerial vehicle. For example, the control hierarchy can identify one or more primary circuit board(s) (e.g., controlling board(s)) and/or one or more redundant circuit boards (e.g., noncontrolling board(s)) for performing each of the one or more aerial vehicle tasks. The control hierarchy can be based, at least in part, on the respective position of each respective circuit board in the arrangement of the plurality of circuit boards. For instance, the control hierarchy can identify the front circuit board as the primary circuit board for the performance of surveillance (e.g., object detection, weather assessment, terrain assessment, landing zone assessment, emergency landing zone assessment, etc.), motion planning, and/or actuator command task(s). In addition, or alternatively, the control hierarchy can identify the first lateral side circuit board and the second lateral side circuit board as the primary circuit boards for the performance of the localization task(s) (e.g., determining a current location, velocity attitude, angular velocity, etc. for the aerial vehicle).</p><p id="p-0051" num="0050">Additionally and/or alternatively, in some implementations, the control hierarchy can identify each of the one or more circuit boards as redundant (e.g., noncontrolling) circuit boards for performing each of the one or more vehicle tasks. For instance, the control hierarchy may not include a primary circuit board in some implementations. Signals from each redundant circuit board can be treated equally, and signals representing a majority value (e.g., a voting-based majority) can be used for performance of surveillance (e.g., object detection, weather assessment, terrain assessment, landing zone assessment, emergency landing zone assessment, etc.), motion planning, and/or actuator command task(s). Signals from boards can be considered individually for determining majority values.</p><p id="p-0052" num="0051">In some implementations, the control hierarchy can dynamically change based, at least in part, on the direction of travel and/or the phase of flight of the aerial vehicle. A phase of flight, for example, can be indicative of whether the aerial vehicle is in a planning phase, a take-off phase, a climb phase, a cruise phase, a descent phase, an approach phase, a taxi phase, etc. By way of example, the control hierarchy can identify the primary board for the performance of the surveillance, motion planning, and/or actuator command task(s) as the board (e.g., sensors thereof) with a field of view overlapping the aerial vehicle's direction of travel. In such a case, the control hierarchy can identify the primary board for the performance of the localization task(s) as the boards (e.g., sensors thereof) with a field of view that does not overlap the aerial vehicle's direction of travel. As an example, the primary board for the performance of the surveillance, motion planning, and/or actuator command task(s) can include the front board in the event that the aerial vehicle is traveling up, down, or straight and/or generally in the forward direction. In addition, or alternatively, the primary board for the performance of the surveillance, motion planning, and/or actuator command task(s) can include the first and/or second lateral side circuit boards in the event the aerial vehicle is hovering (and/or otherwise moving) laterally (e.g., in a first lateral direction, a second lateral direction, or both). This allows for a reconfigurable and real-time selection of onboard computing resources to perform the various autonomous functions of the aerial vehicle in a manner tailored to the current operating parameters of the aerial vehicle.</p><p id="p-0053" num="0052">The systems and methods described herein provide a number of technical effects and benefits. For instance, the present disclosure provides an improved autonomy architecture for facilitating autonomous flight. The autonomy architecture can be included on a single circuit board, therefore allowing sensor data to be digitalized directly to a flight computer configured to process the data for autonomy operations. As a result, the autonomy computing system of the present disclosure can reduce latency in autonomy systems by reducing data copies needed to perform autonomous operations. Moreover, including all of the components on a single board can reduce the weight, size, power, and cost requirements for aerial computing systems therefore enabling lighter, smaller, and more cost efficient aircraft. In addition, example aspects of the present disclosure can provide an improvement to computing technology, such as localization computing technology. For instance, the system of the present disclosure provides for a triple redundant dissimilar localization technique for improving localization accuracy for aircraft by combining newly available combinations of data (e.g., GNSS, APNT, RADAR, etc.) to reduce localization error. Moreover, by implementing the same localization techniques across a plurality of redundant circuit boards, the system of the present disclosure can provide SW redundancy. This, in turn, can reduce overall system positioning error for evaluating aircraft. Additionally, the circuit board of the present disclosure can be reconfigured for use on any vehicle without hardware changes, thereby reducing wasted computing resources and ensuring cross-compatibility across a plurality of different aerial vehicles in a fleet. In this way, the disclosed technology provides a practical improvement to aerial vehicle navigation generally and, more particularly, to the autonomous aerial vehicles.</p><p id="p-0054" num="0053">With reference now to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>13</b></figref>, example embodiments of the present disclosure will be discussed in further detail.</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a block diagram of an example system <b>100</b> for a vehicle <b>102</b> according to example embodiments of the present disclosure. The system <b>100</b> can include a vehicle <b>102</b> with a vehicle computing system <b>110</b>. The vehicle computing system <b>110</b> can include an onboard vehicle computing system disposed on (e.g., mounted to, affixed to, located in, etc.) the vehicle <b>102</b>. The vehicle computing system <b>110</b> can be in communication over one or more network(s) <b>108</b> with remote computing device(s) <b>106</b> and/or an operations computing system <b>104</b>.</p><p id="p-0056" num="0055">The operations computing system <b>104</b> can be associated with a service provider that can provide one or more vehicle services to a plurality of users via a fleet of vehicles that includes, for example, the vehicle <b>102</b>. The vehicle services can include transportation services (e.g., rideshare services), courier services, delivery services, and/or other types of services.</p><p id="p-0057" num="0056">The operations computing system <b>104</b> can include multiple components for performing various operations and functions. For example, the operations computing system <b>104</b> can be configured to monitor and communicate with the vehicle <b>102</b> and/or passengers thereof to coordinate a vehicle service provided by the vehicle <b>102</b>. To do so, the operations computing system <b>104</b> can communicate with the one or more remote computing device(s) <b>106</b> and/or the vehicle <b>102</b> via one or more communications networks including the communications network <b>108</b>.</p><p id="p-0058" num="0057">The communications network <b>108</b> can send and/or receive signals (e.g., electronic signals) or data (e.g., data from a computing device) and include any combination of various wired (e.g., twisted pair cable) and/or wireless communication mechanisms (e.g., cellular, wireless, satellite, microwave, and/or radio frequency) and/or any desired network topology (or topologies). For example, the communications network <b>108</b> can include a local area network (e.g., intranet), wide area network (e.g., the Internet), wireless LAN network (e.g., via Wi-Fi), cellular network, a SATCOM network, VHF network, a HF network, a WiMAX based network, airborne network, ATN based channels, and/or any other suitable communications network (or combination thereof) for transmitting data to/from/between the vehicle <b>102</b>, the remote device(s) <b>106</b>, and/or the operations computing system <b>104</b>.</p><p id="p-0059" num="0058">Each of the one or more remote computing device(s) <b>106</b> can include one or more processors and one or more memory devices. The one or more memory devices can be used to store instructions that when executed by the one or more processors of the one or more remote computing device(s) <b>106</b> cause the one or more processors to perform operations and/or functions including operations and/or functions associated with the vehicle <b>102</b> including sending and/or receiving data or signals to and from the vehicle <b>102</b>, monitoring the state of the vehicle <b>102</b>, and/or controlling the vehicle <b>102</b>.</p><p id="p-0060" num="0059">The remote computing device(s) <b>106</b> can include one or more computing devices such as, for example, one or more operator devices (e.g., pilot device(s), driver device(s), etc.) associated with one or more vehicle operators (e.g., pilot(s), drivers, etc.), passenger devices associated with one or more vehicle passengers, developer devices associated with one or more vehicle developers (e.g., a laptop/tablet computer configured to access computer software of the vehicle computing system <b>110</b>, the autonomy computing system <b>112</b>, etc.), etc. The remote computing device(s) <b>106</b> can receive input instructions from a user (e.g., pilot, driver, passenger, developer, etc.) or exchange signals or data with an item or other computing device or computing system (e.g., the operations computing system <b>104</b>). Further, the remote computing device(s) <b>106</b> can be used to determine and/or modify one or more states of the vehicle <b>102</b> including a location (e.g., a latitude and longitude), a velocity, an acceleration, a trajectory, a heading, noise level, and/or a path of the vehicle <b>102</b> based, at least in part, on signals or data exchanged with the vehicle <b>102</b>. In some implementations, the operations computing system <b>104</b> can include one or more of the remote computing device(s) <b>106</b>.</p><p id="p-0061" num="0060">In some implementations, the operations computing system <b>104</b>, the remote computing device(s) <b>106</b>, and the vehicle <b>102</b> can facilitate one or more portions of a multi-modal transportation itinerary. By way of example, <figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts a graphical diagram of an example multi-modal transportation service itinerary <b>200</b> according to example embodiments of the present disclosure. The itinerary <b>200</b> can include two or more transportation legs to transport a passenger from an origin <b>202</b> to a destination <b>208</b>. For example, the itinerary <b>200</b> can include a first, ground-based (e.g., car-based) transportation leg <b>250</b> which transports the passenger from the origin <b>202</b> to a departure transportation node <b>204</b>; a second, flight-based transportation leg <b>252</b> which transports the passenger from the departure transportation node <b>204</b> to an arrival transportation node <b>206</b>; and a third, ground-based (e.g., car-based) transportation leg <b>254</b> which transports the passenger from the arrival transportation node <b>206</b> to the destination <b>208</b>.</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts an example system <b>300</b> for facilitating a multi-modal transportation itinerary according to example embodiments of the present disclosure. The system <b>300</b> can include the operations computing system <b>104</b> that can operate to control, route, monitor, and/or communicate with aircraft (e.g., VTOL aircraft) and/or one or more other transportation service entities (e.g., ground-based vehicle(s), etc.) to facilitate a multi-modal transportation service. The operations computing system <b>104</b> can be associated with a ride-sharing service platform <b>305</b> that can provide a multi-modal transportation service for passengers, for example, including travel by ground vehicle, travel by aircraft (e.g., VTOL aircraft), travel by watercraft, travel by spacecraft, and/or any combination therebetween. In some implementations, the operations computing system may be a portion of the ridesharing platform and/or controlled by the same entity. In some implementations, the operations computing system can communicate with a computing device of a ridesharing platform operated by a different entity.</p><p id="p-0063" num="0062">The operations computing system <b>104</b> can be communicatively connected over the network(s) <b>108</b> to one or more vehicle provider device(s) <b>310</b>, one or more passenger computing device(s) <b>315</b>, one or more service provider computing devices <b>320</b> for a first transportation modality, one or more service provider computing devices <b>325</b> for a second transportation modality, one or more service provider computing devices <b>330</b> for an Nth transportation modality, and/or one or more infrastructure and operations computing devices <b>335</b>. Each of the computing devices <b>310</b>, <b>315</b>, <b>320</b>, <b>325</b>, <b>330</b>, <b>335</b> can include any type of computing device such as a smartphone, tablet, hand-held computing device, wearable computing device, embedded computing device, navigational computing device, vehicle computing device, etc. A computing device can include one or more processors and a memory. Although service provider devices are shown for N different transportation modalities, any number of different transportation modalities can be used, including, for example, less than the three illustrated modalities (e.g., two modalities can be used).</p><p id="p-0064" num="0063">The operations computing system <b>104</b> includes one or more processors <b>340</b> and a memory <b>345</b>. The one or more processors <b>340</b> can be any suitable processor device (e.g., a processor core, a microprocessor, an ASIC, a GPU, a FPGA, a controller, a microcontroller, etc.) and can be one processor or a plurality of processors that are operatively connected. The memory <b>345</b> can include one or more non-transitory computer-readable storage media, such as RAM, ROM, EEPROM, EPROM, one or more memory devices, flash memory devices, etc., and combinations thereof.</p><p id="p-0065" num="0064">The memory <b>345</b> can store information that can be accessed by the one or more processors <b>340</b>. For instance, the memory <b>345</b> (e.g., one or more non-transitory computer-readable storage mediums, memory devices) can store data <b>350</b> that can be obtained, received, accessed, written, manipulated, created, and/or stored. In some implementations, the operations computing system <b>104</b> can obtain data from one or more memory device(s) that are remote from the system <b>104</b>. The memory <b>345</b> can also store computer-readable instructions <b>355</b> that can be executed by the one or more processors <b>340</b>. The instructions <b>355</b> can be software written in any suitable programming language or can be implemented in hardware. Additionally, or alternatively, the instructions <b>355</b> can be executed in logically and/or virtually separate threads on processor(s) <b>340</b>.</p><p id="p-0066" num="0065">The operations computing system <b>104</b> can facilitate the ability of the passenger to receive transportation on one or more of the transportation legs included in an itinerary. As one example, the operations computing system <b>104</b> can interact with one or more ride-sharing networks to match the user with one or more transportation service providers <b>320</b>, <b>325</b>, <b>330</b>. As another example, the operations computing system <b>104</b> can book or otherwise reserve a seat in, space on, or usage of one or more of the transportation modalities for a passenger. Additionally, or alternatively, the operations computing system <b>104</b> can provide information for options to be provided by one or more third parties for one or more of the transportation legs.</p><p id="p-0067" num="0066">For instance, the operations computing system <b>104</b> can respond to a passenger's request for transportation (e.g., provided by a passenger computing device <b>315</b>) by generating one or more transportation itineraries. As an example, the operations computing system <b>104</b> can evaluate an origin and/or destination location associated with the request to identify modes of transportation that are usable at such location (e.g., able to access such locations). For example, the operations computing system <b>104</b> can communicate with the vehicle provider computing device(s) <b>310</b> and/or the service provider computing device(s) <b>320</b>, <b>325</b>, <b>330</b> to determine whether one or more service(s) are available for the origin/destination location(s). The operations computing system <b>104</b> can provide one or more of the generated itineraries to the passenger (e.g., via the passenger computing device <b>315</b>). For example, one or more of the best itineraries (e.g., as evaluated based on various characteristics such as cost, time, etc.) can be suggested to the passenger. The passenger can select one of the suggested itineraries to receive transportation services in accordance with the selected itinerary.</p><p id="p-0068" num="0067">In another example, a user can request transportation via a ridesharing network (e.g., ridesharing, ride hailing, etc.). The ridesharing network can communicate with the operations computing system <b>104</b> to determine whether aerial transport would be available for the user, cost, times, etc. The operations computing system <b>104</b> can provide data associated with aerial transport (e.g., departure/arrival transportation node, flight times, options, etc.). The ridesharing network can obtain this data and generate an itinerary for the user based at least in part on the data (e.g., a three leg itinerary with an aerial transport leg). The user can accept the trip and the ridesharing network can communicate with the operations computing system <b>104</b> to reserve a seat for the user for aerial transport.</p><p id="p-0069" num="0068">Turning back to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the system <b>100</b> can include a vehicle <b>102</b>. The vehicle <b>102</b> can be configured to perform one or more services such as, for example, one or more transportation service(s) (e.g., at least one leg of an itinerary, etc.). For example, the vehicle <b>102</b> can be capable of, assigned to, requested to, programmed for, etc. the service(s). The vehicle <b>102</b> can be associated with one or more of the remote device(s) <b>106</b> such as, for example, any of the device(s) described with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref> (e.g., vehicle provider computing device(s) <b>310</b>, service provider computing device(s) <b>320</b>, <b>325</b>, <b>330</b>, etc.). As an example, the vehicle <b>102</b> can be associated with a vehicle provider (e.g., corresponding to a vehicle provider device <b>310</b>, etc.), a vehicle operator (e.g., corresponding to a service provider computing device <b>320</b>, <b>325</b>, <b>330</b>, etc.), and/or any other entity associated with the performance of a transportation, delivery, etc. service.</p><p id="p-0070" num="0069">The vehicle <b>102</b> can be a vehicle of any modality such as, for example, an aerial-based vehicle and/or other modalities (a ground-based, water-based, space-based, etc.). For instance, the vehicle <b>102</b> can include an aerial vehicle. As an example, the aerial vehicle can include any type of vertical take-off and landing aircraft (e.g., VTOL, electric VTOL, etc.), short take-off and landing (STOL) aircraft, fixed-wing aircraft, rotorcraft, tilt-rotor aircraft, tilt-prop aircraft, tilt-wing aircraft, helicopter, jet craft, and/or other types of aerial vehicle. The aerial vehicle travels via combustible fuel, electric, hydrogen propelled, and/or other mechanisms. For example, the vehicle <b>102</b> can include one or more propulsion devices (e.g., rotor assemblies, electric motors, turbines, etc.) for initiating motion (e.g., flight maneuvers, take-off maneuvers, landing maneuvers, etc.) of the vehicle <b>102</b>. By way of example, a propulsion device can include an aerodynamic actuator such as, for example, actuators that make use of an articulated or semi-rigid hub (e.g., wherein connection of blades to the hub can be articulated, flexible, rigid, and/or otherwise connected) and/or actuators that make use of a rigid hub (e.g., wherein the connection of blades to the hub can be articulated, flexible, rigid, and/or otherwise connected). Each propulsion device can include a corresponding device controller <b>122</b> (e.g., electric speed controllers, etc.) for controlling the speed, direction, and/or any other characteristic of the propulsion device.</p><p id="p-0071" num="0070">The vehicle <b>102</b> can include and/or otherwise be associated with a vehicle computing system <b>110</b>. The vehicle computing system <b>110</b>, for example, can be disposed (e.g., mounted, attached, positioned, located, etc.) on/within the vehicle <b>102</b>. The vehicle computing system <b>110</b> can include one or more autonomy computing system(s) <b>112</b> and/or one or more device(s) <b>114</b>, <b>116</b>, <b>118</b>, <b>120</b>, <b>122</b>. The device(s) can include an external memory(s) <b>114</b> onboard the vehicle computing system <b>110</b> and/or external to the autonomy computing system(s) <b>112</b>, an external sensor network(s) <b>116</b> onboard the vehicle computing system <b>110</b> and/or external to the autonomy computing system(s) <b>112</b>, one or more flight network device(s) <b>118</b> onboard the vehicle computing system <b>110</b> and/or external to the autonomy computing system(s) <b>112</b>, one or more power device(s) <b>120</b> onboard the vehicle computing system <b>110</b> and/or external to the autonomy computing system(s) <b>112</b>, and/or one or more control device(s) <b>122</b> onboard the vehicle computing system <b>110</b> and/or external to the autonomy computing system(s) <b>112</b>.</p><p id="p-0072" num="0071">For instance, in some implementations, the vehicle <b>102</b> can be an autonomous and/or semi-autonomous aerial vehicle controlled (e.g., at least partly) by at least one of the autonomy computing system(s) <b>112</b> of the vehicle computing system <b>110</b>. Each autonomy computing system <b>112</b> can include components and circuitry to enable the vehicle <b>102</b> to travel autonomously, without human input, for at least some time period. For instance, each autonomy computing system <b>112</b> can include a single circuit board (e.g., a printed circuit board (PCB), substrate, and/or any other physical sheet of insulating material for mounting and/or connecting electrical equipment) configured to receive raw sensor data (e.g., via sensor assembly(s) <b>124</b>, additional sensor(s) <b>126</b>, etc.) and control propulsion device(s) (e.g., via actuator commands to the control device(s) <b>122</b>, etc.) to autonomously operate the vehicle <b>102</b>.</p><p id="p-0073" num="0072">The circuit board, for example, can include one or more board layers (e.g., a single-sided circuit board, a double-sided circuit board, a multi-layered circuit board, etc.). The board layer(s) can include at least one substrate layer and at least one conductive layer. For example, the circuit board can include a physical board that can mechanically support and electrically connect electrical components using board circuitry such as, for example, conductive tracks, pads, wiring, and/or other features etched from (and/or affixed to) one or more sheet layers of a conductive material (e.g., copper and/or any other conductive material) laminated onto and/or between sheet layers of non-conductive substrate. The circuit board can include electrical components to enable the performance of aerial vehicle task(s) for safe autonomous mobility. For example, each board can include hardware and software for implementing one or more surveillance system instance(s) <b>130</b>, localization system instance(s) <b>132</b>, guidance system instance(s) <b>134</b>, and/or flight control system instance(s) <b>136</b>.</p><p id="p-0074" num="0073">The autonomy computing system(s) <b>112</b> can be configured to interface with one or more components <b>114</b>, <b>116</b>, <b>118</b>, <b>120</b>, <b>122</b> onboard the aerial vehicle in addition to the autonomy computing system <b>112</b> (e.g., circuit board). For example, the vehicle <b>102</b> can include one or more external memory(s) <b>114</b>. The external memory(s) <b>114</b> can include any memory device such as, for example, one or more non-transitory computer-readable storage media, such as RAM, ROM, EEPROM, EPROM, flash memory devices, solid state drive(s), etc., and/or combinations thereof. In some implementations, the external memory(s) <b>114</b> can include a high speed data recorder (e.g., data logger, etc.) configured to record data over time and/or in relation to a location (e.g., as determined by the data recorder, the localization system instance(s) <b>132</b>, etc.) of the vehicle <b>102</b>. The high speed data recorder, for example, can include a digital data logger configured to interface (e.g., via interface(s) <b>140</b>) with the autonomy computing system(s) <b>112</b> to record data received by the autonomy computing system(s) <b>112</b> (e.g., sensor data, etc.), data processed by the autonomy computing system(s) <b>112</b> (e.g., localization data, object detection data, motion planning data, etc.), and/or data output by the autonomy computing system(s) <b>112</b> (e.g., actuator command(s), etc.).</p><p id="p-0075" num="0074">In addition, the vehicle <b>102</b> can include one or more external sensor network(s) <b>116</b> and/or one or more flight network device(s) <b>118</b> (e.g., as further illustrated with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>). The external sensor network(s) <b>116</b>, for example, can include one or more LiDAR sensor(s), image sensor(s), correctional sensor network(s), temperature sensor(s), acoustic sensor(s), pressure sensor(s), altimeter(s), and/or any other sensor configured to interface with the autonomy computing system(s) <b>112</b> and/or not used in real-time for autonomous flight. As an example, the external sensor network(s) <b>116</b> can include a correctional sensor network including a plurality of correctional sensors. The plurality of correctional sensors can be configured to obtain correctional sensor data for use (e.g., out-of-loop when the vehicle <b>102</b> is not in use) in modifying one or more functions of the autonomy computing system <b>112</b>. As other examples, the external sensor network(s) <b>116</b> can include an emergency sensor network including a plurality of sensors configured to detect emergency conditions (e.g., loss of cabin pressure, increased temperature, etc.).</p><p id="p-0076" num="0075">The flight network device(s) <b>118</b> can include communication interfaces and/or aerial vehicle instruments configured to consume outputs of the autonomy computing system <b>112</b> and/or provide external inputs to the autonomy computing system <b>112</b>. As an example, the flight network device(s) <b>118</b> can include component controllers configured to control aircraft surface(s) such as, for example, ailerons, flaps, rudder fins, landing gears, and/or any other operable component of the vehicle <b>102</b>.</p><p id="p-0077" num="0076">Additionally, or alternatively, the vehicle <b>102</b> can include one or more control device(s) <b>122</b>. The control device(s) <b>122</b> can correspond to each of one or more propulsion device(s) (e.g., propeller blades, turbines, etc.) of the vehicle <b>102</b>. Each control device <b>122</b> can receive actuator commands (e.g., from at least one autonomy computing system <b>112</b>, remote computing device(s) <b>106</b>, operations computing system <b>104</b>, etc.). The actuator commands, for example, can include data packets, signals, etc. generated and provided to the control device(s) <b>122</b> by the autonomy computing system <b>112</b> onboard the vehicle <b>102</b> to initiate a motion of the vehicle <b>102</b>. The control device(s) <b>122</b> can receive the actuator commands and generate one or more instructions for a corresponding propulsion device. The control device(s) <b>122</b> can execute the one or more instructions to implement the received actuator commands by initiating movement of one or more of the propulsion device(s) (e.g., motors, blades, etc. thereof).</p><p id="p-0078" num="0077">The vehicle <b>102</b> can include one or more power device(s) <b>120</b> (e.g., battery(s), generator(s), fuel cell(s), fuel tank(s), etc.) configured to provide power to facilitate the operation of each of the components <b>112</b>, <b>114</b>, <b>116</b>, <b>118</b>, <b>122</b> of the vehicle computing system <b>110</b>. For example, each external component <b>114</b>, <b>116</b>, <b>118</b>, <b>122</b> can be connected to the circuit board via one or more communication interfaces <b>140</b> of the autonomy computing system <b>112</b> such as, for example, via one more ethernet connections. The ethernet connections, for example, can include a distribution network of one or more power over ethernet cables (e.g., gigabit ethernet cables, etc.) configured to distribute power and data across a plurality of different device(s) onboard the vehicle <b>102</b>. For instance, the distribution network can operate over a shared power and data transmission protocol such as, for example, a Power-over-Ethernet protocol (e.g., ad-hoc, or standardized according to IEEE 802.3 standard, IEEE 802.3af-2003, IEEE 802.3at-2009, PoE+/PoE plus, 802.3bt, Alternative A, Alternative B, 4PPoE, a custom protocol, power over data link protocols (&#x201c;PoDL&#x201d;), Aeronautical Radio, Incorporated (&#x201c;ARINC&#x201d;) protocols, etc.).</p><p id="p-0079" num="0078">The distribution network, for example, can include a physical connection between the power device(s) <b>120</b> and each of the components <b>112</b>, <b>114</b>, <b>116</b>, <b>118</b>, <b>122</b> onboard the vehicle <b>102</b> that use electricity to operate. The physical connection can function to transmit electrical power from the power device(s) <b>120</b> to each component <b>112</b>, <b>114</b>, <b>116</b>, <b>118</b>, <b>122</b>. The physical connection can include a first direct connection between at least one battery of the power device(s) <b>120</b> and a respective power switch (e.g., a power and data switch, a PoE switch, etc.) and second direct connection between the respective power switch and each respective component <b>112</b>, <b>114</b>, <b>116</b>, <b>118</b>, <b>122</b>, such that the power switch can mediate the power provision to each component <b>112</b>, <b>114</b>, <b>116</b>, <b>118</b>, <b>122</b>. In some implementations, the first physical connection between the battery and the respective power switch(s) can include a direct conductive connection (e.g., a wired connection) such as, for example, via a high voltage transmission line, high power transmission cabling, etc. and the second physical connection between the respective switch(s) and each component <b>112</b>, <b>114</b>, <b>116</b>, <b>118</b>, <b>122</b> can include an Ethernet-compatible form factor such as, for example, a category <b>5</b> cable, category <b>3</b> cable, etc.</p><p id="p-0080" num="0079">In this manner, the distribution network can include one or more cables that can communicatively, electrically, and/or physically connect the autonomy computing system(s) <b>112</b> to each of the external component(s) <b>114</b>, <b>116</b>, <b>118</b>, <b>122</b> of the vehicle computing system <b>110</b>. The cables can include network cables (e.g., local area network cables), power and data cables (e.g., PoE cables, optical fiber, coaxial cable, serial cable, USB, a bus, etc.), and/or a set of power cables, data cables, etc. By way of example, the cabling can include twisted pair Ethernet cabling, custom cabling, and/or any other set of cabling. The cabling used to connect different component sets can be the same and/or different. Each cable can connect two, three, and/or any number of the components <b>112</b>, <b>114</b>, <b>116</b>, <b>118</b>, <b>122</b> together.</p><p id="p-0081" num="0080">Ethernet and/or other wired (or wireless) data transfer connections can have limited bandwidth capabilities and require information to be copied from (e.g., via a wired or wireless connection) a source location (e.g., a sensor receiver/digitizing front end, etc.) to a destination location (e.g., the autonomy computing system <b>112</b>, processor device(s) <b>128</b>, etc.). Such limitations can be disadvantageous for transferring data used in real-time autonomy operations. To overcome such limitations, the circuit board (e.g., the autonomy computing system <b>112</b>) of the present disclosure can connect components used in real-time autonomous flight via one or more board circuitry (e.g., conductive layer connections of the circuit board). For example, the circuit board can include at least one conductive layer with a plurality of circuit tracks (and/or other forms of board circuitry) for electrically connecting all of the components (e.g., to allow for autonomous flight, etc.) disposed on (e.g., mounted to, located on, etc.) the circuit board.</p><p id="p-0082" num="0081">More particularly, the autonomy computing system <b>112</b> can include a circuit board with one or more processor device(s) <b>128</b> (e.g., a flight computer, one or more processor(s), one or more programmable logic device(s), etc.) and/or one or more sensor assemblies <b>124</b> disposed (e.g., mounted/attached to, located on, etc.) thereon. The sensor assembly(s) <b>124</b> can include radio detection and ranging (radar) assembly(s) <b>124</b>(A), alternative position navigation and timing (APNT) assembly(s) <b>124</b>(B), and/or global navigation satellite system (GNSS) assembly(s) <b>124</b>(C). In addition, or alternatively, the autonomy computing system <b>112</b> can include sensor(s) <b>126</b>, one or more internal memory device(s) <b>138</b>, and/or one or more communication interface(s) <b>140</b> disposed on (e.g., mounted/attached to, located on, etc.) thereon. The sensor(s) <b>126</b> can include, for example, one or more inertial measurement unit(s), barometer(s), magnetometer(s), and/or any other sensor(s) usable for real-time autonomous flight.</p><p id="p-0083" num="0082">More particularly, <figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts a block diagram of an example autonomy computing system <b>112</b> according to example embodiments of the present disclosure. As depicted, each autonomy computing system <b>112</b> can be a circuit board <b>400</b> that includes radar assemblies <b>124</b>A, APNT assemblies <b>124</b>B, GNSS assemblies <b>124</b>C, processor device(s) <b>128</b>, sensor(s) <b>126</b>, internal memory device(s) <b>138</b>A, <b>138</b>B, <b>138</b>C, and communication interface(s) <b>140</b>A, <b>140</b>B, <b>140</b>C, <b>140</b>D, <b>140</b>E, <b>140</b>F, <b>140</b>G.</p><p id="p-0084" num="0083">The processor device(s) <b>128</b> can include a processing system <b>405</b> and a programmable logic <b>410</b>. For instance, in some implementations, the processor device(s) <b>128</b> can include a heterogeneous compute platform that can include a processing system <b>405</b> (e.g., microprocessors, etc.) and a programmable logic <b>410</b> (e.g., programmable logic architecture) tied together within a high-bandwidth network-on-chip architecture. By way of example, processor device(s) <b>128</b> can include a system on a chip platform including a processing system <b>405</b>, programmable logic <b>410</b>, an internal memory <b>138</b>A, and/or I/O interface(s) such as, for example, route port(s) <b>415</b> (e.g., interfacing circuitry, internal bus, PCI bus, etc.).</p><p id="p-0085" num="0084">The processing system <b>405</b>, for example, can include a plurality of processors such as one or more microprocessors (e.g., ARM A53 processor(s), ARM R5 processor(s), etc.), one or more graphics processing units (e.g., Mali-400 MP2(s), etc.), one or more single instruction, multiple data processors (e.g., SIMD processors, etc.). The programmable logic <b>410</b> can include one or more field-programmable gate arrays with a plurality (e.g., nine hundred and thirty thousand, etc.) of logic cells (e.g., single level cells, etc.), a plurality (e.g., four thousand two hundred and seventy two, etc.) of arithmetic logic units (e.g., DSP48s, etc.), and/or a programmable memory (e.g., RAM, ROM, etc.). In addition, or alternatively, the programmable logic <b>410</b> can include one or more other programmable logic device(s) such as, for example, any other type of programmable logic arrays, programmable array logics, generic array logics, complex programmable logic device(s), erasable programmable logic device(s), graphics processing units, etc.</p><p id="p-0086" num="0085">The programmable logic <b>410</b> can include a plurality of digital circuits configured to implement one or more of a plurality of processing pipelines based, at least in part, on a loaded configuration (e.g., bitstream, etc.). The programmable logic <b>410</b> can be configured to support dynamic full/partial reconfiguration. By way of example, a respectively loaded processing pipeline for the programmable logic <b>410</b> can be dynamically modified, replaced, etc. during, before, and/or after operation of an aerial vehicle based, at least in part, on the state (e.g., operational state, planned trajectory, location, speed, weather conditions, etc.) of the aerial vehicle. In this manner, the operation of the programmable logic <b>410</b> can be dynamically modified to provide on demand processing based, at least in part, on the current state of an aerial vehicle. In this manner, one autonomy computing system <b>112</b> can be reconfigured to facilitate a plurality of different aerial functions thereby resulting in lighter aircraft (e.g., requiring less hardware than aircraft using a plurality of single configuration programmable logic configurations) and increased redundancy in aircraft components.</p><p id="p-0087" num="0086">As examples and as further described with reference to <figref idref="DRAWINGS">FIGS. <b>6</b> and <b>9</b></figref>, a processing pipeline for the programmable logic <b>410</b> of at least one of a plurality of redundant autonomy computing systems <b>112</b> (e.g., of the vehicle computing system <b>110</b>) can be modified to load different sensor processing pipelines based, at least in part, on an aerial task (e.g., and/or type of sensor (e.g., radar, etc.) processing needed for a respective task) associated with a respective autonomy computing system <b>112</b>. As an example, different radar processing pipelines can be tailored to one or more flight modes (e.g., autonomous flight, semi-autonomous flight, manual flight, passenger carrying mode, package carrying mode, etc.), one or more environmental conditions (e.g., rain, heat, fog, etc.), and/or any other factor associated with the operation of an aerial vehicle and/or one or more aerial vehicle tasks associated with a respective autonomy computing system <b>112</b>. As another example, different sensor processing pipelines can be tailored to identified obstacle types. By way of example, the identification of an obstacle of a certain type (e.g., aerial vehicle type (autonomous, manual, VTOL, etc.), animal type (e.g., birds, etc.), etc.) can trigger (e.g., via a &#x201c;wake up big brother&#x201d; architecture) the loading of a respective processing pipeline tailored to the obstacle type. As yet another example, an allocation of GNSS and/or APNT processing pipelines can be distributed among the programmable logic <b>410</b> of one or more redundant autonomy computing systems <b>112</b> based, at least in part, on a relative signal strength and/or confidence in localization.</p><p id="p-0088" num="0087">The programmable logic <b>410</b> can include one or more interface(s) <b>415</b> (e.g., one or more route port(s), etc.) to read/write to programmable logic memory device(s) <b>138</b>A (e.g., one or more solid state drive(s) (SSD(s)) such as (e.g., four SSDs with 2.5 gigabyte/second sequential write per drive, etc.), etc.). The interface(s) <b>415</b>, for example, can include one or more component interconnect express (PCIe) route port(s) for transferring data (e.g., read/write, etc.) between the programmable logic <b>410</b> and the memory device(s) <b>138</b>A. The interface(s) <b>415</b> can include a high-speed computer expansion bus standard defined by a number of lanes <b>420</b>. In some implementations, the interface(s) <b>415</b> can include four PCIe (e.g., PCIe 3.0) route ports with sixteen lanes <b>420</b> (e.g., four lanes (e.g., two read/two write) per route port) capable of transferring data at one hundred and twenty-six gigabits per second.</p><p id="p-0089" num="0088">The processor device(s) <b>128</b> (e.g., processing system <b>405</b>, programmable logic <b>410</b>, etc.) can include one or more additional interface(s) <b>470</b>A-<b>470</b>G communicatively connecting one or more component(s) of the vehicle computing system. For instance, the processing system <b>405</b> can be connected via a primary interface <b>470</b>A (e.g., one or more SATA-III interface(s), etc.) to one or more processing memory device(s) <b>138</b>B (e.g., one or more SATA-III solid state drive(s), etc.). The programmable logic <b>410</b> can be connected via one or more secondary interface(s) <b>470</b>B (e.g., low-speed serial via one or more select I/O pins) to one or more sensor(s) <b>126</b> (e.g., inertial measurement unit(s), etc.). In addition, or alternatively, the processor device(s) <b>128</b> can be connected via one or more ancillary interface(s) <b>470</b>C (e.g., one or more circuit tracks, conductive wiring, etc.) to one or more ancillary memories <b>138</b>C (e.g., DDR4 memory device(s), etc.). In some implementations, the one or more sensor(s) <b>126</b> can be polled by the programmable logic <b>410</b>.</p><p id="p-0090" num="0089">In some implementations, the processor device(s) <b>128</b> can be connected to one or more external device(s) <b>114</b>, <b>116</b>, <b>118</b>, <b>122</b> (e.g., device(s) onboard the vehicle computing system and/or not disposed on the circuit board <b>400</b>). For instance, the processor device(s) <b>128</b> (e.g., processing system <b>405</b>) can include one or more intermediate ethernet interface(s) <b>470</b>D (e.g., gigabit ethernet lines, reduced gigabit media independent interface(s), etc.), <b>470</b>E (ethernet PHY, etc.) connecting the processor device(s) <b>128</b> to the flight network device(s) <b>118</b>. As another example, the processor device(s) <b>128</b> (e.g., programmable logic <b>410</b>) can include one or more interfaces(s) <b>470</b>E (e.g., ten gigabit ethernet line, etc.), <b>470</b>F (one hundred gigabit ethernet line, etc.) and/or one or more additional interface(s) (e.g., power over data link (PoDL) lines, lines with one or more bandwidth limits such as 10 Mb/s, 100 Mb/s, 1 Gb/s, 10 Gb/s, 40 Gb/s, etc.) connecting the processor device(s) <b>128</b> (e.g., programmable logic <b>410</b>) to one or more sensor network(s) <b>116</b> and/or an external memory <b>114</b>. As yet another example, the processor device(s) <b>128</b> can include one or more interface(s) <b>470</b>G (e.g., ethernet lines, circuit tracks, conductive wiring, etc.) for connecting the processor device(s) <b>128</b> (e.g., programmable logic <b>410</b>) to the one or more control device(s) <b>122</b>.</p><p id="p-0091" num="0090">The radio detection and ranging (radar) assembly(s) <b>124</b>A, alternative position navigation and timing (APNT) assembly(s) <b>124</b>B, global navigation satellite system (GNSS) assembly(s) <b>124</b>C, and/or other sensor(s) <b>126</b> can be disposed on (e.g., mounted to, attached to, located on, etc.) the circuit board <b>400</b> and electrically connected to the processor device(s) <b>128</b> (e.g., the programmable logic <b>410</b>) via board circuitry <b>455</b>, <b>460</b>, <b>465</b> (e.g., circuit tracks etched into conductive layer(s) of the circuit board <b>400</b>, one or more conductive wires, internal, peripheral buses, etc.) or otherwise implemented on the circuit board <b>400</b> (e.g., by conductive traces, conductive wiring, etc.). In this manner, sensor information (e.g., analog/digitalized sensor signals, etc.) can be communicated directly to the processor device(s) <b>128</b>.</p><p id="p-0092" num="0091">The APNT assembly(s) <b>124</b>B can include one or more APNT receiving antenna <b>425</b> disposed on (attached, mounted, located, etc.) the circuit board <b>400</b> and a APNT radio frequency front end <b>430</b> (e.g., software defined receiver, etc.) for providing APNT data (e.g., analog/digitalized radio frequency data) to the processor device(s) <b>128</b> (e.g., the programmable logic <b>410</b>) via one or more interface(s) <b>455</b> (e.g., circuit tracks, radio frequency in/out cable(s), etc.) of the circuit board <b>400</b>. In this manner, APNT data (e.g., radio frequency data, analog data, digitalized radio frequency data, etc.) received by APNT receiver antenna(s) <b>425</b> can be directly communicated to a field-programmable gate array (e.g., programmable logic <b>410</b>) configured to process (e.g., digitalize, etc.) the APNT data. The APNT antenna(s) <b>425</b> can include any type of APNT antenna(s) such as, for example, one or more cellular network receivers, pseudolite receivers, ultra-wide band receivers, etc. In some implementations, the APNT antenna(s) <b>425</b> can include at least two antennas, for example, to make aircraft heading observable through local real-time kinematic techniques. In some implementations, the APNT assembly(s) can include radar assemblies and the APNT data can include alternative positioning and navigation radar data.</p><p id="p-0093" num="0092">The GNSS assembly(s) <b>124</b>C can include one or more GNSS receiver antenna(s) <b>435</b> disposed on (attached, mounted, located, etc.) the circuit board <b>400</b> and an GNSS radio frequency front end <b>440</b> (e.g., software defined receiver, etc.) for providing GNSS data to the processor device(s) <b>128</b> (e.g., programmable logic <b>410</b>) via one or more interface(s) <b>460</b> (e.g., circuit tracks, radio frequency in/out cable(s), etc.) of the circuit board <b>400</b>. In this manner, GNSS data (e.g., radio frequency data, analog/digitalized radio frequency signals, etc.) received by GNSS receiver antenna(s) <b>435</b> can be directly communicated to a field-programmable gate array (e.g., programmable logic <b>410</b>) configured to process the GNSS data. The GNSS antenna(s) <b>435</b> can include any type of GNSS antenna(s) such as, for example, one or more global positioning system(s) (GPS), European satellite navigation system(s) (Galileo), global navigation satellite system(s) (GLONASS), BeiDou system(s), etc. In some implementations, the GNSS assembly(s) <b>124</b>C can include at least two GPS receivers (e.g., one or more L1/L5 receivers) and/or at least two Galileo receivers (e.g., one or more E1/E5 receivers).</p><p id="p-0094" num="0093">The radar assemblies <b>124</b>A can include one or more radar receiving antenna(s) <b>445</b> and one or more radar transmitter antenna <b>445</b> disposed on (attached, mounted, located, etc.) the circuit board <b>400</b> and a radar radio frequency front end <b>450</b> (e.g., software defined receiver, radio frequency up/down converter blocks, etc.) for providing radar data to the processor device(s) <b>128</b> (e.g., programmable logic <b>410</b>) via interface(s) <b>465</b> (e.g., circuit tracks, radio frequency in/out cable(s), etc.) of the circuit board <b>400</b>. In this manner, radar data (e.g., radio frequency data, digitalized/analog radio frequency data, etc.) received by the radar receiver antenna(s) <b>445</b> can be directly communicated to a field-programmable gate array (e.g., programmable logic <b>410</b>) configured to process (e.g., digitalize, etc.) the radar data. In some implementations, the radar assembly(s) <b>124</b>A can include a plurality (e.g., four, sixteen, etc.) of radar receiving antennas <b>445</b> and a plurality (e.g., four, sixteen, etc.) of radar transmitter antennas <b>445</b>.</p><p id="p-0095" num="0094">The radio frequency front end(s) <b>430</b>, <b>440</b>, <b>450</b> can be configured to provide data indicative of one or more signals to the processor device(s) <b>128</b> (e.g., programmable logic <b>410</b>). The signal(s) can include one or more antenna signal(s) (e.g., received via one or more respective antenna(s), etc.) and/or simulated signal(s) (e.g., recorded and/or generated radio signals, etc.). For instance, the front end(s) <b>430</b>, <b>440</b>, <b>450</b> can be connected to one or more remote simulation device(s) configured to provide simulation data to the autonomy computing system <b>112</b>. In this manner, the autonomy computing system <b>112</b> can be tested and/or trained using one or more hardware in the loop simulations. By way of example, at least one sensor assembly of the plurality of sensor assemblies <b>124</b>A-C can include at least one radiofrequency front end <b>430</b>, <b>440</b>, <b>450</b> disposed on the circuit board (e.g., autonomy computing system). The at least one radiofrequency front end <b>430</b>, <b>440</b>, <b>450</b> can be configured to receive one or more antenna signals from at least one antenna of the at least one sensor assembly or one or more simulated signals from at least one simulation device. The at least one radiofrequency front end can be configured to provide data indicative of the one or more antenna signals or the one or more simulated signals to the processor device(s) <b>128</b> (e.g., programmable logic <b>410</b>).</p><p id="p-0096" num="0095">For example, <figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts an example radar assembly design <b>500</b> according to example embodiments of the present disclosure. The radar assembly design <b>500</b> can include one or more of radar antenna arrays (e.g., bistatic, monostatic, quasi-monostatic, etc.) <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B disposed on the circuit board <b>400</b>. The circuit board <b>400</b> can include a radar RF front end <b>450</b> and programmable logic <b>410</b> for receiving, transmitter, and processing radar signals (e.g., electromagnetic waves within various frequencies such as radio, microwave, or millimeter frequencies, etc.) via the one or more radar antenna arrays <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B. The board <b>400</b> can include power distribution device(s) <b>515</b> for distributing power from one or more power device(s) <b>120</b> (e.g., onboard an aerial vehicle) to components (e.g., programmable logic <b>410</b>, radar RF front end <b>450</b>, radar antenna array(s) <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B, etc.) of the circuit board <b>400</b>.</p><p id="p-0097" num="0096">The radar antenna array(s) <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B can include a plurality of transmitter antenna arrays <b>505</b>A, <b>505</b>B and/or a plurality of receiver antenna arrays <b>510</b>A, <b>510</b>B. The plurality of transmitter antenna arrays <b>505</b>A, <b>505</b>B can include any number of transmitter antennas. By way of example, in some implementations, the transmitter antenna arrays <b>505</b>A, <b>505</b>B can include four, eight, twelve, sixteen, twenty, or any other number of transmitter antennas (e.g., antennas configured to transmit electromagnetic waves within various frequencies based on analog signals). In some implementations, for example, the transmitter antenna arrays <b>505</b>A, <b>505</b>B can include sixteen transmitter antennas. The plurality of receiver antenna arrays <b>510</b>A, <b>510</b>B can include any number of receiver antennas (e.g., antennas configured to receive electromagnetic waves within various frequencies). By way of example, in some implementations, the receiver antenna arrays <b>510</b>A, <b>510</b>B can include four, eight, twelve, sixteen, twenty and/or any other number receiver antennas. In some implementations, for example, the receiver antenna arrays <b>510</b>A, <b>510</b>B can include sixteen receiver antennas.</p><p id="p-0098" num="0097">The radar antenna array(s) <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B can include any number of different radar antennas configured to operate over any number of radio frequency ranges (e.g., as defined by professional associations such as, for example, the institute of electrical and electronics engineers (IEEE), etc.). For example, the radar antenna array(s) <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B can include a plurality of X-band antennas (e.g., configured to operate over an X-band (e.g., 8-12 GHz) frequency range), KU-band antennas (e.g., configured to operate over a KU-band (e.g., 12-18 GHz) frequency range), K-band antennas (e.g., configured to operate over a K-band (e.g., 18-26 GHz) frequency range), Ka-band (e.g., configured to operate over a Ka-band (e.g., 32.3-33.4 GHz) frequency range) and/or any other antenna types or combinations thereof. By way of example, in some implementations, the radar antenna array(s) <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B can include X-band antennas configured to operate over a 9.3-9.8 GHz frequency range.</p><p id="p-0099" num="0098">The radar antenna array(s) <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B can be positioned in one or more of a plurality of different orientations. As an example, one or more antenna(s) of a respective radar antenna array (e.g., radar antenna array(s) <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B) can be oriented in different configurations to create one or more virtual array patterns. As another example, the one or more antenna(s) of a respective radar antenna array (e.g., radar antenna array(s) <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B) can be oriented in one or more different polarized antenna configurations.</p><p id="p-0100" num="0099">Each of the radar antenna array(s) <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B can be disposed on (e.g., attached, mounted, located, etc.) the circuit board <b>400</b> via a respective radio frequency converter <b>520</b>A, <b>520</b>B, <b>525</b>A, <b>525</b>B. The radio frequency converter(s) <b>520</b>A, <b>520</b>B, <b>525</b>A, <b>525</b>B, for example, can include one or more radio frequency up converter(s) <b>520</b>A, <b>520</b>B corresponding to the transmitter antenna arrays <b>505</b>A, <b>505</b>B and/or one or more radio frequency in converter(s) <b>525</b>A, <b>525</b>B corresponding to the receiver antenna arrays <b>510</b>A, <b>510</b>B.</p><p id="p-0101" num="0100">The radio frequency in converter(s) <b>525</b>A, <b>525</b>B can include radio frequency down converter blocks configured to receive analog signals from the receiver antenna arrays <b>510</b>A, <b>510</b>B and communicate the analog signals (and/or digital signal(s)) to the programmable logic <b>410</b>. By way of example, the down converter blocks can include hardware and/or logic for converting high frequency signals (e.g., X-band frequency signals, etc.) to one or more lower frequencies for processing. The radio frequency up converter(s) <b>520</b>A, <b>520</b>B can include radio frequency up-converter blocks configured to receive the one or more analog signal(s) and cause the plurality of receiver antenna arrays <b>510</b>A, <b>510</b>B to output one or more radio signals based, at least in part, on the analog signal(s). By way of example, the up-converter blocks can include hardware and/or logic for converting and/or amplifying low frequency signals (e.g., intermediate frequency signals, etc.) to one or more higher frequencies for transmission. As described herein, the radio frequency converter(s) <b>520</b>A, <b>520</b>B, <b>525</b>A, <b>525</b>B can enable multi-modal radar assemblies.</p><p id="p-0102" num="0101">The programmable logic <b>410</b> can include circuitry/logic for receiving/processing analog/digitalized radar signals and controlling the radar antenna arrays <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B. For instance, the programmable logic <b>410</b> can include one or more analog to digital converter(s) (ADCs) <b>530</b>. The ADCs <b>530</b> can be configured to digitalize the analog radio signal(s) (e.g., down converted intermediate signals, etc.) to generate digitalized radar data (e.g., radar data <b>480</b>). For example, the ADCs <b>530</b> can include integrated circuits configured to receive and convert analog radio signal(s) into one or more digital signal(s). The digital signal(s), for example, can include a two's complement binary number proportional to the respective analog radio signal(s) and/or any other digital representation of analog radio signal(s).</p><p id="p-0103" num="0102">In addition, or alternatively, the programmable logic <b>410</b> can include one or more digital to analog converter(s) (DACs) <b>550</b>. The DACs can receive the digital signals/waveforms (e.g., output by radar controller <b>545</b>, multi-waveform distribution channel <b>565</b>, etc.) and convert the digital waveforms to analog data (e.g., intermediate signals, etc.) for transmission by the transmitter antenna(s) <b>505</b>A, <b>505</b>B. For example, the DACs <b>550</b> can include integrated circuits configured to receive and convert digital signal(s) into one or more analog signal(s). The analog signal(s) can be communicated to the radio frequency up converter(s) <b>520</b>A, <b>520</b>B. The radio frequency up converter(s) <b>520</b>A, <b>520</b>B can convert and/or amplify the analog signal(s) for transmission.</p><p id="p-0104" num="0103">The programmable logic <b>410</b> (e.g., via radar processor <b>535</b>) can process digitalized radar data, store (e.g., via memory device <b>540</b>, etc.) the digitalized radar data (and/or information derived from the digitalized radar data), and/or communicate (e.g., via communication interface(s) <b>590</b>, etc.) the digitalized radar data (and/or information derived from the digitalized radar data) to one or more external device(s) (e.g., external memory device(s) <b>114</b>, user interface(s) <b>595</b>, etc.). For example, the programmable logic <b>410</b> can include radar processing logic (e.g., radar processor <b>535</b>). The radar processor <b>535</b> can process (e.g., via one or more algorithms, machine-learning models, etc.) the radar data to perform one or more tasks (e.g., determine a current location, object detection, terrain mapping, etc.) described herein. The radar data and/or information derived thereof (e.g., a vehicle location, object location, etc.) can be stored in memory device(s) <b>540</b> (e.g., RAM memory (e.g., DDR4), ROM, etc.) and/or output (e.g., via communication interface <b>590</b>) to one or more remote device(s) such as, for example, external memory(s) <b>114</b> (e.g., a high-speed recorder) and/or user device(s) (e.g., remote device(s) <b>106</b> described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>) for display via user interface(s) <b>595</b>.</p><p id="p-0105" num="0104">In addition, or alternatively, the programmable logic <b>410</b> can include radar controller logic (e.g., radar controller <b>545</b>) configured to synchronize and/or otherwise control radar signal output by the radar antenna array(s) <b>510</b>A, <b>510</b>B. The radar controller <b>545</b> can be configured to control each of the radar antenna array(s) <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B to perform radar scans for collecting the radar data. The radar controller <b>545</b> can include and/or be associated with one or more oscillator(s) <b>570</b> (e.g., STALO, etc.), one or more control interface(s) <b>575</b> (e.g., RFFE COMMS, etc.), one or more timing device(s) <b>580</b> (e.g., timing clock, etc.) and/or any other hardware/software components for synchronizing/controlling one or more parameter(s) (e.g., pulse length, timing, width, power, etc.) for completing one or more different radar observations (e.g., terrain mapping, moving object detection, etc.). For example, the radar controller <b>545</b> can be configured to generate one or more transmission (TX) waveforms <b>555</b>, reference waveforms <b>560</b>, etc. The transmission waveforms <b>555</b> (and/or other transmission parameter(s)) can be input to a multi-antenna waveform distribution logic <b>565</b> for processing based, at least in part, on the radar antenna array(s) <b>510</b>A, <b>510</b>B. Digital instructions can be converted to analog signal(s) (e.g., via DAC(s) <b>550</b>) for transmission by radar antenna array(s) <b>510</b>A, <b>510</b>B.</p><p id="p-0106" num="0105">The radar assembly design <b>500</b> can enable multi-modal radar antenna array(s) <b>505</b>A, <b>505</b>B, <b>510</b>A, <b>510</b>B capable of operating in a number of different modes (e.g., pulsed mode(s) (e.g., noncoherent, coherent (e.g., low, medium, high pulse repetition frequency, etc.), continuous wave mode(s) (e.g., frequency modulated, etc.), etc.) to obtain radar data tailored to each aerial vehicle task for autonomous flight (e.g., via electronic beam steering, electronic beam forming, etc.). For example, the radar controller <b>545</b> can cause the transmitter antenna array(s) <b>505</b>A, <b>505</b>B to operate according to a first mode to obtain radar data indicative of one or more moving objects. In addition, or alternatively, the radar controller <b>545</b> can cause the transmitter antenna array(s) <b>505</b>A, <b>505</b>B to operate according to other modes for localizing the aircraft, determining an aircraft maneuver, etc. In some implementations, the radar assembly design <b>500</b> can include one or more radar lenses (e.g., optical lenses, etc.) on top of the antenna array(s) to filter one or more received signals, etc.</p><p id="p-0107" num="0106">With reference to <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>4</b></figref>, the autonomy computing system <b>112</b> (e.g., processor device(s) <b>128</b> of the circuit board <b>400</b>) can receive sensor data <b>475</b>A (e.g., radar data <b>480</b>, APNT data <b>485</b>, GNSS data <b>490</b>, etc.) directly from the respective sensor assembly(s) (e.g., radar <b>124</b>A, APNT <b>124</b>B, GNSS <b>124</b>C assemblies, etc.) disposed on the circuit board <b>400</b> via one or more interface(s) <b>455</b>, <b>460</b>, <b>465</b> (e.g., circuit tracks, conductive wiring, computer buses, etc.) of the circuit board <b>400</b> and process the sensor data <b>475</b>A to generate actuator command(s) <b>495</b> (e.g., for the control device(s) <b>122</b>). In addition, or alternatively, the autonomy computing system <b>112</b> (e.g., processor device(s) <b>128</b> of the circuit board <b>400</b>) can receive additional sensor data <b>475</b>B (e.g., IMU data, etc.) directly from the sensor(s) <b>126</b> (e.g., IMU sensor(s), etc.) disposed on the circuit board <b>400</b> via one or more interface(s) <b>470</b>B (e.g., circuit tracks, conductive wiring, computer buses, etc.) of the circuit board <b>400</b> and process the additional sensor data <b>475</b>B to generate actuator command(s) <b>495</b> (e.g., for the control device(s) <b>122</b>). For example, the autonomy computing system <b>112</b> can determine a vehicle location for the aerial vehicle based, at least in part, on the radar data <b>480</b>, the GNSS data <b>490</b>, the APNT data <b>485</b>, and/or the additional sensor data <b>475</b>B. For instance, as described herein, the system <b>112</b> can perform triple redundant dissimilar location techniques to accurately determine vehicle location estimates.</p><p id="p-0108" num="0107">The autonomy computing system <b>112</b> (e.g., circuit board <b>400</b>) can include one or more internal memory(s) <b>138</b> storing computer-readable instructions for controlling one or more (e.g., in some cases all) aspects of autonomous flight. For example, the instructions can include instructions for implementing surveillance system instance(s) <b>130</b>, localization system instance(s) <b>132</b>, guidance system instance(s) <b>134</b>, and/or flight control system instance(s) <b>136</b>. Each of the systems can be configured to perform one or more vehicle task(s). For example, the surveillance system <b>130</b> can be configured to perform surveillance task(s) such as, for example, identifying object(s), identifying and/or assessing one or more weather conditions, identifying and/or assessing one or more terrains, landing zones, emergency landing zone, etc. within the surrounding environment of the aerial vehicle <b>102</b>. The localization system <b>132</b> can be configured to perform localization task(s) such as, for example, determining a current location, velocity, attitude, angular velocity, etc. for the vehicle <b>102</b>. The guidance system <b>134</b> can be configured to perform motion planning task(s) such as, for example, generating motion plan(s) for the vehicle <b>102</b> based, at least in part, on the current location of the vehicle <b>102</b> and/or identified object(s) within the surrounding environment of the vehicle <b>102</b>. The flight control system <b>136</b> can be configured to perform actuator command task(s) such as, for example, generating and/or providing actuator command(s) associated with the motion plan(s) to one or more control device(s) <b>122</b> of the vehicle <b>102</b>.</p><p id="p-0109" num="0108">By way of example, the system <b>112</b> (e.g., the surveillance system instance <b>130</b>) can determine one or more object location(s) for object(s) proximate to the vehicle <b>102</b> based, at least in part, on the radar data <b>480</b> (e.g., received via the radar assemblies <b>124</b>A). For example, the radar data <b>480</b> can be input to an object detection algorithm including one or more classical algorithms, machine-learning model(s) (e.g., supervised model(s), unsupervised model(s), neural network, linear model(s), non-linear model(s), etc.), etc. configured to detect one or more airborne objects (e.g., location, speed, altitude, etc.), landing areas, landmarks, etc. based on radar data samples (e.g., digitalized radar signal(s), etc.). The object detection algorithms, for example, can include one or more machine-learning model(s) trained using one or more machine-learning techniques (e.g., unsupervised, supervised, etc.) to identify and/or track airborne (and/or other) objects. As an example, the object detection algorithms can include machine-learning model(s) trained via backpropagation using labelled training data indicative of radar signals and corresponding objects (and/or the location, speed, altitude, etc. thereof).</p><p id="p-0110" num="0109">As another example, the system <b>112</b> (e.g., guidance system instance(s) <b>134</b>) can determine flight maneuver(s) based, at least in part, on the vehicle location (e.g., as determined by the localization system instance(s) <b>132</b>) and/or the object location(s) (e.g., as determined by the surveillance system instance <b>130</b>). For instance, the system <b>112</b> (e.g., guidance system instance(s) <b>134</b>) can determine the flight maneuver(s) based, at least in part, on the performance of trajectory planning and/or obstacle avoidance. The flight maneuver(s), for example, can include one or more directional movements to avoid an airborne object, create a buffer distance between the vehicle <b>102</b> and the airborne object, and/or perform one or more landing/take-off/navigational procedures. The guidance system instance(s) <b>134</b> can receive one or more constraint(s) such as, for example, a localization constraint (e.g., indicative of a current location for the vehicle <b>102</b>) and/or an obstacle detection constraint (e.g., indicative of one or more objects within the surrounding environment if the vehicle <b>102</b>), model predictive control for the vehicle <b>102</b> based, at least in part, on the constraints, and determine one or more aircraft maneuvers.</p><p id="p-0111" num="0110">As one example, the system <b>112</b> (e.g., guidance system instance(s) <b>134</b>) can be configured to perform a landing zone assessment in preparation for a landing maneuver. To do so, the system <b>112</b> (e.g., guidance system instance(s) <b>134</b>) can input radar signals indicative of a landing area to a semantic landing assessment machine-learned model (e.g., neural network, non-linear model(s), linear model(s), etc.) configured (e.g., trained, etc.) to output one or more semantic labels based, at least in part, on the input radar signals. The semantic labels, for example, can identify one or more object(s) within a landing area of the vehicle <b>102</b>. As another example, the system <b>112</b> (e.g., guidance system instance(s) <b>134</b>) can determine an occupancy grid (e.g., via one or more classical algorithms, etc.). The system <b>112</b> (e.g., guidance system instance(s) <b>134</b>) can determine an equation of a plane for each grid point of the occupancy grid and determine whether a landing area is occupied based on the slope, altitude, and/or variance of the equation. The guidance system instance(s) <b>134</b> can model the predicted control for the vehicle <b>102</b> based, at least in part, on whether the landing zone is occupied and determine one or more landing maneuvers based, at least in part, the predicted control for the vehicle <b>102</b> and the occupancy of the landing zone.</p><p id="p-0112" num="0111">The autonomy computing system <b>112</b> (e.g., flight control system instance(s) <b>136</b>) can initiate a motion of the vehicle <b>102</b> based, at least in part, on the vehicle location, the flight maneuvers, and/or the object(s) proximate to the vehicle <b>102</b>. To do so, the system <b>112</b> can generate actuator command(s) (e.g., actuator command(s) <b>495</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>) based, at least in part, on the one or more flight maneuvers and provide the actuator command(s) to one or more control device(s) <b>122</b> of the vehicle <b>102</b>. In some cases, the actuator command(s) can be generated based, at least in part, on one or more control parameter(s) (e.g., types of firmware, max speed, max current, controller ratings, energy consumption, phase(s), etc.) associated with the control device(s) <b>122</b>. In this manner, the flight control system instance(s) <b>136</b> can generate different actuator command(s) <b>495</b> for different control device(s) <b>122</b> to initiate the same motion of the aerial vehicle.</p><p id="p-0113" num="0112">In some implementations, the autonomy computing system <b>112</b> can store (e.g., in a high speed data recorder) data indicative of the vehicle location, the object location(s), the flight maneuver(s), raw radio-frequency data (e.g., GNSS data, APNT data, Radar data, etc.), and/or other sensor data (e.g., inertial data, etc.) in external memory device(s) <b>114</b>. The data, for example, can be stored to enable offline testing (e.g., via data replay) for algorithms (e.g., classical algorithms, machine-learning algorithms, etc.) utilized by the autonomy computing system <b>112</b>. By way of example, raw radio-frequency data (and/or other sensor data) can be used to test algorithms offline using data replay techniques.</p><p id="p-0114" num="0113">In addition, or alternatively, the stored data can be compared to correctional data to determine one or more modification(s) for the autonomy computing system <b>112</b> (e.g., surveillance system(s) <b>130</b>, localization system(s) <b>132</b>, guidance system(s) <b>134</b>, flight control system(s) <b>136</b>, etc.). For example, the autonomy computing system <b>112</b> can receive, via one or more communication interfaces <b>140</b> (e.g., wired/wireless interfaces, etc.), correctional data from the external sensor network(s) <b>116</b>. The correctional data can include, for example, additional data (e.g., LiDAR data, image data, etc.) recorded by one or more sensor(s) (e.g., LiDAR sensors, cameras, etc.) of the external sensor network(s) <b>116</b>. The autonomy computing system <b>112</b> can store the correctional data to the external memory device(s) (e.g., high speed data recorder). In this manner, the data indicative of the vehicle location, the object location(s), and/or the flight maneuver(s) can be compared to the correctional data (e.g., out-of-the-loop such as when the vehicle is grounded, etc.) to determine modification(s) for the autonomy computing system <b>112</b> (e.g., debug software, maintain hardware, etc.).</p><p id="p-0115" num="0114">The autonomy computing system <b>112</b> (e.g., localization system instance(s) <b>132</b>) can utilize a plurality of sensor processing techniques for determining a current vehicle location. As an example, the system <b>112</b> (e.g., localization system instance(s) <b>132</b>) can perform triple redundant localization using at least three dissimilar signal receivers (e.g., radar assemblies <b>124</b>A, APNT assemblies <b>124</b>B, GNSS assemblies <b>124</b>C, etc.) electrically connected to the circuit board <b>400</b>. The current vehicle location, for example, can include a geospatial position (and/or any other positional reference) including lateral coordinate(s), longitudinal coordinate(s), and/or altitude measurement(s). The system <b>112</b> (e.g., localization system instance(s) <b>132</b>) can determine a current vehicle location based, at least in part, on a plurality of position estimates generated using at least three dissimilar localization techniques. The vehicle location can be determined by applying a voting algorithm (e.g., deterministic voting algorithms, distributed voting algorithms, etc.) to the plurality of position estimates to obtain a consensus current vehicle location. In some implementations, a consensus, multi-board voting algorithm can be applied to multiple consensus current vehicle locations determined by a plurality of redundant autonomy computing systems. In this way, the consensus, multi-board voting algorithm can provide additional localization redundancy to compensate for potential failures (e.g., due to power failures, bad sensor field of views, loss of sensor connection, etc.) of one or more multiple redundant autonomy computing systems configured to run the same (and/or similar) algorithms.</p><p id="p-0116" num="0115">By way of example, the autonomy computing system <b>112</b> (e.g., localization system instance(s) <b>132</b>, each of a plurality of redundant autonomy computing systems) can determine one or more first, second, and/or third position estimates for the aerial vehicle at a respective time. The first position estimate(s) can be determined based, at least in part, on GNSS data (e.g., GNSS data <b>490</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>) received from the one or more GNSS assemblies <b>124</b>C. The GNSS data <b>490</b>, for example, can include one or more navigation satellite signals (e.g., GPS satellite signals, Galileo satellite signals, etc.). The navigation satellite signals, for instance, can include one or more radio time signals received along a line of sight from one or more of a constellation of navigation satellites by the GNSS assembly(s) <b>124</b>C (e.g., antennas <b>435</b> thereof). The one or more radio time signals can be processed (e.g., digitalized, etc.) by the autonomy computing system <b>112</b> (e.g., localization system instance(s) <b>132</b>) via one or more GNSS processing techniques to determine at least one first position estimate for the vehicle <b>102</b>.</p><p id="p-0117" num="0116">The autonomy computing system <b>112</b> (e.g., localization system instance(s) <b>132</b>) can determine the second position estimate(s) for the vehicle <b>102</b> at the respective time based, at least in part, on APNT data (e.g., APNT data <b>485</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>) received from the APNT assembly(s) <b>124</b>B. The APNT data <b>485</b>, for example, can include one or more network signal(s) (e.g., cellular network signals, pseudolite signals, ultra-wide band signals, etc.). The network signal(s), for instance, can include one or more radio signals received from one or more network access points (and/or pseudolites, etc.) by the APNT assembly(s) <b>124</b>B (e.g., antennas <b>425</b> thereof). As an example, the network signals can include cellular network signals indicative of one or more cellular access points within range of the APNT assembly(s) <b>124</b>B. In such a case, the autonomy computing system <b>112</b> (e.g., localization system instance(s) <b>132</b>) can determine an access point location for each of the cellular access points (e.g., via a look-up table and/or information from the network signals) and determine at least one second position estimate based, at least in part, on the access point location for each of the cellular access points. As other examples, the network signals can include one or more radio signals received from pseudolite(s), ultra-wide band access point(s), and/or any other alternative positioning, navigation, and timing sources. In such a case, the radio signals can be processed (e.g., by the localization system instance(s) <b>132</b>) (e.g., via one or more respective APNT processing techniques) to determine additional second position estimates for the vehicle <b>102</b>.</p><p id="p-0118" num="0117">The autonomy computing system <b>112</b> (e.g., localization system instance(s) <b>132</b>) can determine the third position estimate(s) for the vehicle <b>102</b> at the respective time based, at least in part, on radar data (e.g., radar data <b>480</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>) received from the radar assembly(s) <b>124</b>A. The radar data <b>480</b> can include one or more radar signals. The radar signals can be processed by the autonomy computing system <b>112</b> (e.g., localization system instance(s) <b>132</b>), via one or more processing techniques, to determine a third position estimate. For example, the radar signal(s) can be processed using one or more radar odometry techniques. The radar odometry techniques, for example, can include determining a positional change for the vehicle <b>102</b> from a starting time to the respective time based, at least in part, on the radar signals and determining at least one of the one or more third position estimates by applying the positional change to a starting position of the vehicle <b>102</b>. As another example, the radar signal(s) can be processed using one or more radar terrain reference navigation techniques. For example, the radar signal(s) (e.g., digitalized radar signals, etc.) can be indicative of a terrain within a surrounding environment of the vehicle <b>102</b>. In such a case, the autonomy system <b>112</b> (e.g., localization system instance(s) <b>132</b>) can determine a third position estimate based, at least in part, on a comparison between the terrain and a pre-determined terrain navigation map. As yet another example, the radar signal(s) can be processed using one or more radar beacon techniques. For instance, the radar data can be indicative of beacon signals received from one or more passive and/or active radar beacons. The autonomy system <b>112</b> (e.g., localization system instance(s) <b>132</b>) can determine one or more beacon positions for the one or more radar beacons based, at least in part, on the beacon signals and determine at least one third position estimate based, at least in part, on the beacon position(s).</p><p id="p-0119" num="0118">Each of the systems <b>130</b>, <b>132</b>, <b>134</b>, <b>136</b> can be configured to perform the one or more vehicle task(s) (e.g., localization, etc.) for a plurality of different vehicle types. For example, the autonomy computing system <b>112</b> (e.g., the circuit board, the surveillance system <b>130</b>, localization system <b>132</b>, guidance system <b>134</b>, flight control system <b>136</b>, etc.) can be reconfigurable to apply to a plurality of different vehicle types. By way of example, the same autonomy computing system <b>112</b> (e.g., circuit board) can be reconfigured (e.g., without hardware changes) to control any of a plurality of different types of aerial vehicles. In this manner, the autonomy computing system <b>112</b> can be transferable between a number of different aircraft without hardware changes.</p><p id="p-0120" num="0119">For example, <figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts a reconfigurable autonomy computing system environment <b>600</b> according to example embodiments of the present disclosure. As depicted, the reconfigurable autonomy computing system <b>112</b> can include an internal memory <b>138</b> and be associated with a plurality of different vehicle types <b>605</b>, <b>610</b>, <b>615</b>, <b>620</b>. For instance, an aerial vehicle (e.g., aerial vehicle(s) <b>605</b>A, <b>605</b>B, <b>605</b>C, <b>610</b>A, <b>610</b>B, <b>610</b>C, <b>615</b>A, <b>615</b>B, <b>615</b>C, <b>620</b>A, <b>620</b>B, <b>620</b>C, etc.) can be associated with an aerial vehicle type <b>605</b>, <b>610</b>, <b>615</b>, <b>620</b> (e.g., subscale vehicles, full scale vehicles, eVTOLs, etc.). A respective vehicle type can define a group of aerial vehicles with one or more similar physical attributes. For instance, each vehicle type <b>605</b>, <b>610</b>, <b>615</b>, <b>620</b> can include one or more characteristic(s) of an aerial vehicle such as, for example, an aircraft design, device manufacture(s) (e.g., vehicle provider(s), etc.), type of propulsion device(s) (e.g., propeller(s), turbine engine, ramjet, rocket, etc.), number of propulsion device(s) (e.g., one, two, four, eight, etc.), size, weight, and/or any other characteristic defining the flight capabilities of an aerial vehicle. By way of example, a first example vehicle type <b>605</b> can include full-scale electric vertical take-off and landing vehicle(s) <b>605</b>A, <b>605</b>B, <b>605</b>C manufactured at least in part by a first vehicle provider; a second example vehicle type <b>610</b> can include subscale (e.g., smaller version of the first example vehicle type <b>605</b>) electric vertical take-off and landing vehicle(s) <b>610</b>A, <b>610</b>B, <b>610</b>C manufactured at least in part by the first vehicle provider; a third example vehicle type <b>615</b> can include second aircraft <b>615</b>A, <b>615</b>B, <b>615</b>C manufactured at least in part by the first vehicle provider with one or more different design choices; and a fourth example vehicle type <b>620</b> can include another aircraft <b>620</b>A, <b>620</b>B, <b>620</b>C manufactured at least in part by a second vehicle provider.</p><p id="p-0121" num="0120">Each respective aerial vehicle type <b>605</b>, <b>610</b>, <b>615</b>, <b>620</b> of the plurality of aerial vehicle types can be associated with one or more respective aerodynamic models <b>625</b>, <b>640</b>, <b>655</b>, <b>670</b> and/or radar sampling parameters <b>635</b>, <b>650</b>, <b>665</b>, <b>680</b>. The aerodynamic models/sampling parameters, for example, can be based, at least in part, on the vehicle characteristics (e.g., size, weight, layout, etc.) of the respective vehicle type <b>605</b>, <b>610</b>, <b>615</b>, <b>620</b>. The aerodynamic model(s) <b>625</b>, <b>640</b>, <b>655</b>, <b>670</b>, for example, can include airflow information, resistance information, drag information, weight information, lift information, thrust information, blade tip speed(s) (e.g., maximum speeds, etc.), rotor speed(s) (maximum rotations per minute, etc.), pitch/yaw/roll information, trim information, and/or any other information affecting the aerodynamics of a respective vehicle type <b>605</b>, <b>610</b>, <b>615</b>, <b>620</b>. The radar sampling parameter(s) <b>635</b>, <b>650</b>, <b>665</b>, <b>680</b>, for example, can include power (e.g., emission power) information, pulse-width information, filter information, amplifier information, clutter processing information, expected signal noise information, sampling frequency information, and/or any other information affecting radar processing onboard a vehicle of a respective vehicle type <b>605</b>, <b>610</b>, <b>615</b>, <b>620</b>.</p><p id="p-0122" num="0121">The autonomy computing system(s) <b>112</b> can be configured for a respective aerial vehicle (e.g., <b>605</b>A, <b>610</b>A, <b>615</b>A, <b>620</b>A) associated with a respective vehicle type (e.g., <b>605</b>, <b>610</b>, <b>615</b>, <b>620</b>) by storing the aerodynamic models <b>625</b>, <b>640</b>, <b>655</b>, <b>670</b> (e.g., descriptive of motion parameters <b>630</b>, <b>645</b>, <b>660</b>, <b>675</b> (e.g., pitch, roll, yaw, torque, and/or any other parameters for generating desired movements based on a center of gravity and/or other characteristics of an aircraft)) and/or radar sampling parameters <b>635</b>, <b>650</b>, <b>665</b>, <b>680</b> (e.g., expected signal noise, sampling frequencies, etc.) corresponding to the respective aerial vehicle type (e.g., <b>605</b>, <b>610</b>, <b>615</b>, <b>620</b>) on the internal memory <b>138</b> of the autonomy computing system <b>112</b>.</p><p id="p-0123" num="0122">By way of example, the autonomy computing system <b>112</b> can be initially configured for a first aerial vehicle <b>605</b>A associated with a first vehicle type <b>605</b>. In such a case, the one or more memories <b>138</b> of the autonomy computing system <b>112</b> can include one or more computer-readable instructions for implementing the various systems of the autonomy computing system <b>112</b> (e.g., surveillance system, localization system, guidance system, flight control system, etc.) that include one or more first motion parameters <b>630</b> and/or first radar sampling parameters <b>635</b> (e.g., expected sensor noise, sampling frequencies, etc.) corresponding to the first vehicle type <b>605</b>. The one or more first motion parameters <b>630</b> and/or first radar sampling parameters <b>635</b> can be based, at least in part, on the one or more respective aerodynamic models <b>625</b> associated with the first vehicle type <b>605</b>.</p><p id="p-0124" num="0123">The one or more memories <b>138</b> of the same autonomy computing system <b>112</b> can be modified to reconfigure the reconfigurable circuit board for use on a second aerial vehicle <b>610</b>. The one or more modified memories <b>138</b> can include modified computer-readable instructions for implementing the various systems of the autonomy computing system <b>112</b> (e.g., surveillance system, localization system, guidance system, flight control system, etc.) that include one or more second motion parameters <b>645</b> and/or second radar sampling parameters <b>650</b> corresponding to the second vehicle type <b>610</b>. The one or more second motion parameters <b>645</b> and/or second radar sampling parameters <b>650</b>, for example, can be based, at least in part, on the one or more respective aerodynamic models <b>640</b> associated with the second vehicle type <b>610</b>.</p><p id="p-0125" num="0124">Turning again to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the autonomy computing system(s) <b>112</b> can include one or a plurality of redundant systems. For example, in some implementations, the vehicle <b>102</b> can include multiple redundant autonomy computing systems <b>112</b>. For instance, the vehicle <b>102</b> (e.g., vehicle computing system <b>110</b>) can include a plurality of circuit boards, with each circuit board capable of performing all aerial vehicle tasks to enable autonomous flight. The multiple redundant circuit boards can be placed in a plurality of different arrangements relative to the vehicle <b>102</b>. For example, the vehicle <b>102</b> can include an arrangement of a plurality of circuit boards disposed on the vehicle <b>102</b>. Each respective circuit board in the arrangement of the plurality of circuit boards can be associated with a respective position relative to the vehicle <b>102</b>.</p><p id="p-0126" num="0125">For example, <figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts a number of reference points of example aerial vehicles <b>700</b> according to example embodiments of the present disclosure. The vehicles <b>700</b> can define a number of reference points, axes, and/or planes. In some implementations, the vehicles <b>700</b> can define: a lateral axis (e.g., pitch axis), vertical axis (e.g., yaw axis), a center point (e.g., unloaded center of gravity, loaded center of gravity, geometric center, intersection point of axes, etc.), and/or any other positional reference. The vehicles <b>700</b> can define a number of reference frames such as a local North-East-Down (NED) frame defined at a prescribed geodetic position (the current state estimate), cartesian (x, y, z) coordinates relative to frame origin at point, earth-centered/earth-fixed frame Cartesian coordinates relative to frame origin at Earth's center, geodetic frame&#x2014;elliptical coordinates (latitude, longitude, altitude) relative to frame origin at Earth's center, vehicle body-fixed frame relative to frame origin (e.g., defined as the center of mass), sensor-fixed frame&#x2014;cartesian coordinates relative to frame origin at sensor's measurement origin, and/or any other suitable reference frame.</p><p id="p-0127" num="0126"><figref idref="DRAWINGS">FIG. <b>8</b></figref> depicts an example arrangement <b>800</b> of autonomy computing systems relative to an example aerial vehicle <b>850</b> according to example embodiments of the present disclosure. The aerial vehicle <b>850</b> can define a front side <b>855</b>, a first lateral side <b>860</b>, and/or a second lateral side <b>865</b> opposite the first lateral side <b>860</b>, and/or a rear side <b>870</b> opposite the front side <b>855</b>. The sides <b>855</b>, <b>860</b>, <b>865</b>, <b>870</b>, for example, can be defined with respect to the vehicle's <b>850</b> center of gravity (e.g., as described with reference to <figref idref="DRAWINGS">FIG. <b>7</b></figref>).</p><p id="p-0128" num="0127">In some implementations, the plurality of autonomy computing system(s) <b>805</b>, <b>815</b>, <b>825</b> (e.g., circuit boards) can include a front circuit board <b>805</b> disposed on (e.g., mounted to, attached to, affixed to, located at, etc.) the front side <b>855</b> (e.g., where the field of view <b>810</b> of the sensors of the circuit board <b>805</b> are facing forward and/or downward from the aerial vehicle <b>850</b>, etc.) of the aerial vehicle <b>850</b>, a first lateral side circuit board <b>815</b> disposed on the first lateral side <b>860</b> of the aerial vehicle <b>850</b> (e.g., where the field of view <b>820</b> of the sensors of the circuit board <b>815</b> are facing outward from the first lateral side <b>860</b>), and a second lateral side circuit board <b>825</b> disposed on the second lateral side <b>865</b> of the aerial vehicle <b>850</b> (e.g., where the field of view <b>830</b> of the sensors of the circuit board <b>825</b> are facing outward from the second lateral side <b>865</b>).</p><p id="p-0129" num="0128">The plurality of autonomy computing systems <b>805</b>, <b>810</b>, <b>815</b> can include one or more components and/or be disposed on the aerial vehicle <b>850</b> in a particular manner that limits the system(s) <b>805</b>, <b>810</b>, <b>815</b> effect on drag without sacrificing radio frequency and/or aero-structural performance. By way of example, the plurality of autonomy computing systems <b>805</b>, <b>810</b>, <b>815</b> can be mounted within the aerial vehicle <b>850</b> (e.g., via a structure internal to the aerial vehicle <b>850</b>). In addition, or alternatively, each of the plurality of autonomy computing systems <b>805</b>, <b>810</b>, <b>815</b> can include a plurality of radar radomes (e.g., corresponding to respective radar assemblies) and/or conformal GNSS and APNT antennas.</p><p id="p-0130" num="0129"><figref idref="DRAWINGS">FIG. <b>9</b></figref> depicts an example control hierarchy <b>900</b> for an autonomous vehicle with a number of redundant autonomy computing systems according to example embodiments of the present disclosure. In some implementations, the arrangement of the plurality of circuit boards <b>805</b>, <b>815</b>, <b>825</b> can include a control hierarchy <b>900</b> identifying which board controls each autonomy task <b>930</b> for the aerial vehicle <b>950</b>. For example, the control hierarchy <b>900</b> can identify one or more primary circuit board(s) (e.g., controlling board(s)) and/or one or more redundant circuit boards (e.g., noncontrolling board(s)) for performing each of the one or more aerial vehicle tasks <b>930</b>. The control hierarchy <b>900</b> can be based, at least in part, on the respective position of each respective circuit board in the arrangement of the plurality of circuit boards <b>805</b>, <b>815</b>, <b>825</b>. For instance, the control hierarchy <b>900</b> can identify the front circuit board <b>805</b> as the primary circuit board for the performance of surveillance <b>905</b> (e.g., object detection, weather assessment, terrain assessment, landing zone assessment, emergency landing zone assessment, etc.), motion planning <b>910</b>, and/or actuator command task(s) <b>915</b>. In addition, or alternatively, the control hierarchy <b>900</b> can identify the first lateral side circuit board <b>815</b> and the second lateral side circuit board <b>825</b> as the primary circuit boards for the performance of the localization task(s) <b>920</b>.</p><p id="p-0131" num="0130">Additionally and/or alternatively, in some implementations, the control hierarchy <b>900</b> can identify each of the circuit boards <b>805</b>, <b>815</b>, <b>825</b> as redundant (e.g., noncontrolling) circuit boards for performing each of the one or more vehicle tasks <b>930</b>. For instance, the control hierarchy <b>900</b> may not include a primary circuit board in some implementations. Signals from each redundant circuit board <b>805</b>, <b>815</b>, <b>825</b> can be treated equally, and signals representing a majority value (e.g., a voting-based majority) can be used for performance of surveillance <b>905</b> (e.g., object detection, weather assessment, terrain assessment, landing zone assessment, emergency landing zone assessment, etc.), motion planning <b>910</b>, and/or actuator command task(s) <b>915</b>. Signals from boards <b>805</b>, <b>815</b>, <b>825</b> can be considered individually for determining majority values.</p><p id="p-0132" num="0131">In some implementations, the control hierarchy <b>900</b> can dynamically change based, at least in part, on the direction of travel <b>925</b> and/or a phase of flight of the aerial vehicle <b>950</b>. The phase of flight, for example, can be indicative of whether the aerial vehicle is in a planning phase, a take-off phase, a climb phase, a cruise phase, a descent phase, an approach phase, a taxi phase, etc. By way example, the control hierarchy <b>900</b> can identify the primary board for the performance of the surveillance <b>905</b>, motion planning <b>910</b>, and/or actuator command <b>915</b> task(s) as the board <b>805</b>, <b>815</b>, <b>825</b> (e.g., sensors thereof) with a field of view overlapping (at least partially) the aerial vehicle's direction of travel <b>925</b>. In such a case, the control hierarchy <b>900</b> can identify the primary board for the performance of the localization task(s) <b>920</b> as the boards (e.g., sensors thereof) with a field of view that does not overlap the aerial vehicle's direction of travel <b>925</b>. As an example, the primary board for the performance of the surveillance <b>905</b>, motion planning <b>910</b>, and/or actuator command task(s) <b>915</b> can include the front board <b>805</b> in the event that the aerial vehicle <b>950</b> is traveling up, down, or straight and/or generally in the forward direction (e.g., as depicted by direction of travel <b>925</b>). In addition, or alternatively, the primary board for the performance of the surveillance <b>905</b>, motion planning <b>910</b>, and/or actuator command <b>915</b> task(s) can include the first and/or second lateral side circuit boards <b>815</b>, <b>825</b> in the event the aerial vehicle <b>950</b> is hovering (and/or otherwise moving) laterally (e.g., from side to side). This allows for a reconfigurable and real-time selection of onboard computing resources to perform the various autonomous functions of the aerial vehicle <b>950</b> in a manner tailored to the current operating parameters of the aerial vehicle <b>950</b>.</p><p id="p-0133" num="0132"><figref idref="DRAWINGS">FIG. <b>10</b></figref> depicts an example method <b>1000</b> for controlling the motion of an aerial vehicle according to example embodiments of the present disclosure. One or more portion(s) of the method <b>1000</b> can be implemented by a computing system that includes one or more computing devices such as, for example, the computing systems described with reference to the other figures (e.g., the vehicle computing system <b>110</b>, autonomy computing system <b>112</b>, circuit board <b>400</b>, etc.). Each respective portion of the method <b>1000</b> can be performed by any (or any combination) of one or more computing devices. Moreover, one or more portion(s) of the method <b>1000</b> can be implemented as an algorithm on the hardware components of the device(s) described herein (e.g., as in <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>9</b>, <b>12</b>-<b>13</b></figref>, etc.), for example, to perform aerial vehicle tasks. <figref idref="DRAWINGS">FIG. <b>10</b></figref> depicts elements performed in a particular order for purposes of illustration and discussion. Those of ordinary skill in the art, using the disclosures provided herein, will understand that the elements of any of the methods discussed herein can be adapted, rearranged, expanded, omitted, combined, and/or modified in various ways without deviating from the scope of the present disclosure. <figref idref="DRAWINGS">FIG. <b>10</b></figref> is described with reference to elements/terms described with respect to other systems and figures for exemplary illustrated purposes and is not meant to be limiting. One or more portions of method <b>1000</b> can be performed additionally, or alternatively, by other systems.</p><p id="p-0134" num="0133">At <b>1005</b>, the method <b>1000</b> can include obtaining, at a processor device of a circuit board, sensor data from one or more sensors connected to the circuit board. For example, a computing system (e.g., autonomy computing system <b>112</b>, etc.) can obtain, at the processor device of the circuit board, the sensor data from the one or more sensors connected to the circuit board.</p><p id="p-0135" num="0134">At <b>1010</b>, the method <b>1000</b> can include determining a vehicle location based on the sensor data. For example, the computing system (e.g., autonomy computing system <b>112</b>, etc.) can determine the vehicle location based on the sensor data.</p><p id="p-0136" num="0135">At <b>1015</b>, the method <b>1000</b> can include identifying one or more objects proximate to an aerial vehicle based, at least in part, on the sensor data. For example, the computing system (e.g., autonomy computing system <b>112</b>, etc.) can identify the one or more objects proximate to the aerial vehicle based, at least in part, on the sensor data.</p><p id="p-0137" num="0136">At <b>1020</b>, the method <b>1000</b> can include generating one or more motion plans for the aerial vehicle based, at least in part, on the sensor data and the vehicle location. For example, the computing system (e.g., autonomy computing system <b>112</b>, etc.) can generate the one or more motion plans for the aerial vehicle based, at least in part, on the sensor data and the vehicle location.</p><p id="p-0138" num="0137">At <b>1025</b>, the method <b>1000</b> can include determining one or more actuator commands based, at least in part, on the one or more motion plans. For example, the computing system (e.g., autonomy computing system <b>112</b>, etc.) can determine the one or more actuator commands based, at least in part, on the one or more motion plans.</p><p id="p-0139" num="0138">At <b>1030</b>, the method <b>1000</b> can include providing the one or more actuator commands to one or more device controllers of the aerial vehicle. For example, the computing system (e.g., autonomy computing system <b>112</b>, etc.) can provide the one or more actuator commands to one or more device controllers of the aerial vehicle.</p><p id="p-0140" num="0139"><figref idref="DRAWINGS">FIG. <b>11</b></figref> depicts an example method <b>1100</b> for localizing an aerial vehicle according to example embodiments of the present disclosure. One or more portion(s) of the method <b>1100</b> can be implemented by a computing system that includes one or more computing devices such as, for example, the computing systems described with reference to the other figures (e.g., the vehicle computing system <b>110</b>, autonomy computing system <b>112</b>, circuit board <b>400</b>, etc.). Each respective portion of the method <b>1100</b> can be performed by any (or any combination) of one or more computing devices. Moreover, one or more portion(s) of the method <b>1000</b> can be implemented as an algorithm on the hardware components of the device(s) described herein (e.g., as in <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>9</b>, <b>12</b>-<b>13</b></figref>, etc.), for example, to determine a current location for an aircraft. <figref idref="DRAWINGS">FIG. <b>11</b></figref> depicts elements performed in a particular order for purposes of illustration and discussion. Those of ordinary skill in the art, using the disclosures provided herein, will understand that the elements of any of the methods discussed herein can be adapted, rearranged, expanded, omitted, combined, and/or modified in various ways without deviating from the scope of the present disclosure. <figref idref="DRAWINGS">FIG. <b>11</b></figref> is described with reference to elements/terms described with respect to other systems and figures for exemplary illustrated purposes and is not meant to be limiting. One or more portions of method <b>1100</b> can be performed additionally, or alternatively, by other systems.</p><p id="p-0141" num="0140">At <b>1105</b>, the method <b>1100</b> can include obtaining GNSS data from one or more GNSS devices connected to a circuit board. For example, a computing system (e.g., autonomy computing system <b>112</b>, etc.) can obtain the GNSS data from the one or more GNSS devices connected to the circuit board.</p><p id="p-0142" num="0141">At <b>1110</b>, the method <b>1100</b> can include obtaining APNT data from one or more APNT devices connected to the circuit board. For example, the computing system (e.g., autonomy computing system <b>112</b>, etc.) can obtain the APNT data from the one or more APNT devices connected to the circuit board.</p><p id="p-0143" num="0142">At <b>1115</b>, the method <b>1100</b> can include obtaining radar data from one or more radar devices connected to the circuit board. For example, the computing system (e.g., autonomy computing system <b>112</b>, etc.) can obtain the radar data from the one or more radar devices connected to the circuit board.</p><p id="p-0144" num="0143">At <b>1120</b>, the method <b>1100</b> can include determining a vehicle location based on the GNSS data, the APNT data, and/or the radar data. For example, the computing system (e.g., autonomy computing system <b>112</b>, etc.) can determine the vehicle location based on the GNSS data, the APNT data, and/or the radar data. In some implementations, the vehicle location can be based on additional information such as, as examples, inertial data (e.g., from one or more inertial measurement units), communication data (e.g., indicative of relative vehicle locations, third party location predictions, etc.), and/or any other information associated with the location of an aerial vehicle.</p><p id="p-0145" num="0144">At <b>1125</b>, the method <b>1100</b> can include initiating a motion of an aerial vehicle based on the vehicle location. For example, the computing system (e.g., autonomy computing system <b>112</b>, etc.) can initiate the motion of the aerial vehicle based on the vehicle location.</p><p id="p-0146" num="0145"><figref idref="DRAWINGS">FIG. <b>12</b></figref> depicts an example system <b>1200</b> with various means for performing operations and functions according to example embodiments of the present disclosure. One or more operations and/or functions in <figref idref="DRAWINGS">FIG. <b>12</b></figref> can be implemented and/or performed by one or more devices (e.g., one or more computing devices of the autonomy computing system <b>112</b>) or systems including, for example, the autonomy computing system <b>112</b> shown in <figref idref="DRAWINGS">FIGS. <b>1</b>, <b>4</b>, and <b>5</b></figref>.</p><p id="p-0147" num="0146">Various means can be configured to perform the methods and processes described herein. For example, the system <b>1200</b> can include localization unit(s) <b>1205</b>, surveillance unit(s) <b>1210</b>, motion planning unit(s) <b>1215</b>, command unit(s) <b>1220</b>, and/or other means for performing the operations and functions described herein. In some implementations, one or more of the units may be implemented separately. In some implementations, one or more units may be a part of or included in one or more other units. These means can include processor(s), microprocessor(s), graphics processing unit(s), logic circuit(s), dedicated circuit(s), application-specific integrated circuit(s), programmable array logic, field-programmable gate array(s), controller(s), microcontroller(s), and/or other suitable hardware. The means can also, or alternately, include software control means implemented with a processor or logic circuitry, for example. The means can include or otherwise be able to access memory such as, for example, one or more non-transitory computer-readable storage media, such as random-access memory, read-only memory, electrically erasable programmable read-only memory, erasable programmable read-only memory, flash/other memory device(s), data registrar(s), database(s), and/or other suitable hardware.</p><p id="p-0148" num="0147">The means can be programmed to perform one or more algorithm(s) for carrying out the operations and functions described herein. For instance, the means (e.g., localization unit(s) <b>1205</b>, etc.) can be configured to determine a current location for an aerial vehicle. The means (e.g., surveillance unit(s) <b>1210</b>, etc.) can be configured to identify object(s) within the surrounding environment of the aerial vehicle. The means (e.g., motion planning unit(s) <b>1215</b>, etc.) can be configured to generate motion plan(s) for the aerial vehicle based, at least in part, on the current location of the vehicle and/or identified object(s) within the surrounding environment of the vehicle. The means (e.g., command unit(s) <b>1220</b>, etc.) can be configured to generate and/or provide actuator command(s) associated with the motion plan(s) to one or more control device(s) of the aerial vehicle.</p><p id="p-0149" num="0148"><figref idref="DRAWINGS">FIG. <b>13</b></figref> depicts an example computing system <b>1300</b> according to example embodiments of the present disclosure. The system <b>1300</b> includes an autonomy computing system <b>1305</b> and a server computing system <b>1350</b> that are communicatively coupled over a network <b>1345</b>.</p><p id="p-0150" num="0149">The autonomy computing system <b>1305</b> includes one or more processors <b>1310</b> and a memory <b>1315</b>. The one or more processors <b>1310</b> can be any suitable processor device (e.g., a processor core, a microprocessor, an ASIC, a GPU, an FPGA, a controller, a microcontroller, etc.) and can be one processor or a plurality of processors that are operatively connected. The memory <b>1315</b> can include one or more non-transitory computer-readable storage media, such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, etc., and combinations thereof. The memory <b>1315</b> can store data <b>1320</b> and instructions <b>1325</b> which are executed by the processor <b>1310</b> to cause the autonomy computing system <b>1305</b> to perform operations.</p><p id="p-0151" num="0150">In some implementations, the autonomy computing system <b>1305</b> can store or include one or more machine-learning models <b>1335</b> and/or one or more non-machine-learning algorithms. The machine-learning models <b>1335</b> can be or can otherwise include various machine-learned models such as neural networks (e.g., deep neural networks) or other types of machine-learned models, including non-linear models and/or linear models. Neural networks can include feed-forward neural networks, recurrent neural networks (e.g., long short-term memory recurrent neural networks), convolutional neural networks or other forms of neural networks. Some example machine-learned models can leverage an attention mechanism such as self-attention. For example, some example machine-learned models can include multi-headed self-attention models (e.g., transformer models).</p><p id="p-0152" num="0151">In some implementations, the machine-learning models <b>1335</b> can be received from the server computing system <b>1350</b> over network <b>1345</b>, stored in the autonomy computing system memory <b>1315</b>, and then used or otherwise implemented by the one or more processors <b>1310</b>. In some implementations, the autonomy computing system <b>1305</b> can implement multiple parallel instances of machine-learning models <b>1335</b>.</p><p id="p-0153" num="0152">More particularly, the machine-learning models <b>1335</b> can be utilized to perform one or more aerial vehicle tasks. By way of example, the machine-learning models <b>1335</b> can include one or more object detection model(s) configured to identify and/or track one or more airborne objects based, at least in part, on raw radar sensor signals. In addition, or alternatively, the machine-learning models <b>1335</b> can include one or more localization model(s) configured to determine a current location for an aircraft, one or more motion planning model(s) for determining an optimal motion plan for an aircraft, and/or any other machine-learning models for performing autonomy tasks for an aerial vehicle.</p><p id="p-0154" num="0153">Additionally, or alternatively, one or more machine-learning models <b>1380</b> can be included in or otherwise stored and implemented by the server computing system <b>1350</b> that communicates with the autonomy computing system <b>1305</b>. The server computing system <b>1350</b> includes one or more processors <b>1355</b> and a memory <b>1360</b>. The one or more processors <b>1355</b> can be any suitable processor device (e.g., a processor core, a microprocessor, an ASIC, a GPU, an FPGA, a controller, a microcontroller, etc.) and can be one processor or a plurality of processors that are operatively connected. The memory <b>1360</b> can include one or more non-transitory computer-readable storage media, such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, etc., and combinations thereof. The memory <b>1360</b> can store data <b>1365</b> and instructions <b>1370</b> which are executed by the processor <b>1355</b> to cause the server computing system <b>1350</b> to perform operations.</p><p id="p-0155" num="0154">In some implementations, the server computing system <b>1350</b> includes or is otherwise implemented by one or more server computing devices. In instances in which the server computing system <b>1350</b> includes plural server computing devices, such server computing devices can operate according to sequential computing architectures, parallel computing architectures, or some combination thereof.</p><p id="p-0156" num="0155">As described above, the server computing system <b>1350</b> can store or otherwise include one or more machine-learning models <b>1380</b>. For example, the models <b>1380</b> can be or can otherwise include various machine-learned models. Example machine-learned models include neural networks or other multi-layer non-linear models. Example neural networks include feed forward neural networks, deep neural networks, recurrent neural networks, and convolutional neural networks. Some example machine-learned models can leverage an attention mechanism such as self-attention. For example, some example machine-learned models can include multi-headed self-attention models (e.g., transformer models).</p><p id="p-0157" num="0156">The autonomy computing system <b>1305</b> and/or the server computing system <b>1350</b> can train the models <b>1335</b> and/or <b>1380</b> via interaction with a model trainer <b>1385</b>. The model trainer <b>1385</b> can be configured to train the machine-learned models <b>1335</b> and/or <b>1380</b> stored at the e autonomy computing system <b>1305</b> and/or the server computing system <b>1350</b> using various training or learning techniques, such as, for example, backwards propagation of errors. For example, a loss function can be backpropagated through the model(s) to update one or more parameters of the model(s) (e.g., based on a gradient of the loss function). Various loss functions can be used such as mean squared error, likelihood loss, cross entropy loss, hinge loss, and/or various other loss functions. Gradient descent techniques can be used to iteratively update the parameters over a number of training iterations.</p><p id="p-0158" num="0157">In some implementations, performing backwards propagation of errors can include performing truncated backpropagation through time. The model trainer <b>1385</b> can perform a number of generalization techniques (e.g., weight decays, dropouts, etc.) to improve the generalization capability of the models being trained. In particular, the model trainer <b>1385</b> can train the machine-learning models <b>1335</b> and/or <b>1380</b> based on a set of training data <b>1390</b>. The training data <b>1390</b> can include, for example, previously recorded radar signals labeled for one or more tasks. As an example, the radar signals can be labeled to indicate whether the signals correspond to the presence of one or more objects, a speed of the objects, an object type associated with the object(s), etc.</p><p id="p-0159" num="0158">The model trainer <b>1385</b> includes computer logic utilized to provide desired functionality. The model trainer <b>1385</b> can be implemented in hardware, firmware, and/or software controlling a general purpose processor. For example, in some implementations, the model trainer <b>1385</b> includes program files stored on a storage device, loaded into a memory and executed by one or more processors. In other implementations, the model trainer <b>1385</b> includes one or more sets of computer-executable instructions that are stored in a tangible computer-readable storage medium such as RAM, hard disk, or optical or magnetic media.</p><p id="p-0160" num="0159">The network <b>1345</b> can be one or more of any type of communications network, such as a local area network (e.g., intranet), wide area network (e.g., Internet), or some combination thereof and can include any number of wired or wireless links. In general, communication over the network <b>180</b> can be carried through one or more of any type of wired and/or wireless connection, using a wide variety of communication protocols (e.g., TCP/IP, HTTP, SMTP, FTP), encodings or formats (e.g., HTML, XML), and/or protection schemes (e.g., VPN, secure HTTP, SSL).</p><p id="p-0161" num="0160"><figref idref="DRAWINGS">FIGS. <b>1</b>-<b>13</b></figref> illustrate example embodiments and methods that can be used to implement the present disclosure. Other computing systems can be used as well. The use of computer-based systems allows for a great variety of possible configurations, combinations, and divisions of tasks and functionality between and among components. Computer-implemented operations can be performed on a single component or across multiple components. Computer-implemented tasks and/or operations can be performed sequentially or in parallel. Data and instructions can be stored in a single memory device or across multiple memory devices. While the present subject matter has been described in detail with respect to specific example embodiments and methods thereof, it will be appreciated that those skilled in the art, upon attaining an understanding of the foregoing can readily produce alterations to, variations of, and equivalents to such embodiments. Accordingly, the scope of the present disclosure is by way of example rather than by way of limitation, and the subject disclosure does not preclude inclusion of such modifications, variations and/or additions to the present subject matter as would be readily apparent to one of ordinary skill in the art.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A circuit board in communication with one or more device controllers, the circuit board comprising:<claim-text>a processor device;</claim-text><claim-text>a plurality of sensor assemblies electrically connected to the processor device, the plurality of sensor assemblies comprising one or more global navigation satellite system (GNSS) assemblies, one or more alternative position navigation and timing (APNT) assemblies, and one or more radio detection and ranging (RADAR) assemblies; and</claim-text><claim-text>one or more memory devices storing computer-readable instructions that when executed cause the processor device to implement a guidance system and a flight control system, wherein the guidance system is configured to generate one or more motion plans for an aerial vehicle and the flight control system is configured to provide one or more actuator commands associated with the one or more motion plans to the one or more device controllers.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The circuit board of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the computer-readable instructions comprise first computer-readable instructions that when executed cause the processor device to implement a first guidance system configured to generate one or more first motion plans for a first aerial vehicle type and a first flight control system configured to provide one or more first actuator commands associated with the one or more first motion plans to one or more first device controllers of the first aerial vehicle type.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The circuit board of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the first aerial vehicle type is one of a plurality of vehicle types, wherein each respective aerial vehicle type of the plurality of vehicle types is associated with one or more respective aerodynamic models.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The circuit board of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the first computer-readable instructions comprise one or more first motion parameters or one or more first radar sampling parameters corresponding to the first aerial vehicle type, wherein the one or more first motion parameters or the one or more first radar sampling parameters are based, at least in part, on one or more first respective aerodynamic models associated with the first aerial vehicle type.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The circuit board of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the computer-readable instructions are modifiable to reconfigure the circuit board for use on a second vehicle of a second aerial vehicle type, wherein modified computer-readable instructions comprise instructions that when executed cause the processor device to implement a second guidance system configured to generate one or more second motion plans for the second aerial vehicle type and a second flight control system configured to provide one or more second actuator commands associated with the one or more second motion plans to one or more second device controllers of the second aerial vehicle type.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The circuit board of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the modified computer-readable instructions comprise one or more second motion parameters or one or more second radar sampling parameters corresponding to the second aerial vehicle type, wherein the one or more second motion parameters are based, at least in part, on one or more second respective aerodynamic models associated with the second aerial vehicle type.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The circuit board of any of the claims (e.g., <claim-ref idref="CLM-00001">claim 1</claim-ref>), further comprising one or more board layers, the one or more board layers comprising at least one substrate layer and at least one conductive layer, wherein the at least one conductive layer comprises a plurality of circuit tracks for electrically connecting the processor device, the plurality of sensor assemblies, and the one or more memory devices.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The circuit board of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the plurality of sensor assemblies are disposed on the circuit board and electrically connected to the processor device via the plurality of circuit tracks of the at least one conductive layer.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The circuit board of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein at least one sensor assembly of the plurality of sensor assemblies comprises at least one radiofrequency front end disposed on the circuit board, wherein the at least one radiofrequency front end is configured to receive one or more antenna signals from at least one antenna of the at least one sensor assembly or one or more simulated signals from at least one simulation device, wherein the at least one radiofrequency front end is configured to provide data indicative of the one or more antenna signals or the one or more simulated signals to the processor device.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The circuit board of any of the claims (e.g., <claim-ref idref="CLM-00008">claim 8</claim-ref> or <claim-ref idref="CLM-00009">9</claim-ref>), wherein the one or more GNSS assemblies comprise at least one GNSS receiver antenna disposed on the circuit board and electrically connected to the processor device via at least a first track of the plurality of circuit tracks,<claim-text>wherein the one or more APNT assemblies comprise at least one APNT receiving antenna disposed on the circuit board and electrically connected to the processor device via at least a second track of the plurality of circuit tracks, and</claim-text><claim-text>wherein the one or more radar assemblies comprise at least one radar receiving antenna and at least one radar transmitter antenna disposed on the circuit board and electrically connected to the processor device via at least a third track of the plurality of circuit tracks.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The circuit board of any of the claims (e.g., <claim-ref idref="CLM-00001">claim 1</claim-ref>), wherein the processor device is a field-programmable gate array, wherein the field-programmable gate array is configured to receive sensor data directly from the plurality of sensor assemblies and perform sensor processing on the sensor data.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. An aerial vehicle comprising:<claim-text>an arrangement of a plurality of circuit boards mounted to the aerial vehicle, wherein each circuit board of the plurality of circuit boards is located at a different position onboard the aerial vehicle, wherein the arrangement of the plurality of circuit boards comprises a control hierarchy indicative of a primary circuit board and one or more redundant circuit boards for performing each of one or more aerial vehicle tasks, and wherein each circuit board of the plurality of circuit boards comprises:<claim-text>a processor device;</claim-text><claim-text>a plurality of sensor assemblies electrically connected the processor device, the plurality of sensor assemblies comprising one or more global navigation satellite system (GNSS) assemblies, one or more alternative position navigation and timing (APNT) assemblies, and one or more radio detection and ranging (RADAR) assemblies; and</claim-text><claim-text>one or more memory devices storing computer-readable instructions that when executed cause the processor device to implement a surveillance system, a localization system, a guidance system, and a flight control system, wherein the surveillance system, the localization system, the guidance system, and the flight control system are configured to perform the one or more aerial vehicle tasks.</claim-text></claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The aerial vehicle of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein each respective circuit board in the arrangement of the plurality of circuit boards is associated with a respective position relative to the aerial vehicle, and wherein the control hierarchy is based, at least in part, on the respective position of each respective circuit board in the arrangement of the plurality of circuit boards.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The aerial vehicle of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the control hierarchy is further based, at least in part, on a direction of travel or a phase of flight of the aerial vehicle.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The aerial vehicle of <claim-ref idref="CLM-00013">claim 13</claim-ref> or <claim-ref idref="CLM-00014">14</claim-ref>, wherein the aerial vehicle defines a front side, a first lateral side, a second lateral side opposite the first lateral side, and a rear side opposite the front side, and wherein the plurality of circuit boards comprise a front circuit board located at the front side of the aerial vehicle, a first lateral side circuit board located at the first lateral side of the aerial vehicle, and a second lateral side circuit board located at the second lateral side of the aerial vehicle.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The aerial vehicle of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the surveillance system is configured to perform one or more surveillance tasks, the localization system is configured to perform one or more localization tasks, the guidance system is configured to perform one or more motion planning tasks, and the flight control system is configured to perform one or more actuator command tasks, wherein the control hierarchy identifies the front circuit board as primary circuit board for performance of the one or more surveillance tasks, the one or more motion planning tasks, and the one or more actuator command tasks, and wherein the control hierarchy identifies the first lateral side circuit board and the second lateral side circuit board as primary circuit boards for performance of the one or more localization tasks.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. An aerial vehicle comprising:<claim-text>one or more processor devices; and</claim-text><claim-text>one or more non-transitory computer-readable media that collectively store instructions that, when executed by the one or more processor devices, cause the one or more processor devices to perform operations, the operations comprising:</claim-text><claim-text>obtaining global navigation satellite system (GNSS) data from one or more GNSS assemblies electrically connected to the one or more processor devices;</claim-text><claim-text>obtaining alternative position navigation and time (APNT) data from one or more APNT assemblies electrically connected to the one or more processor devices;</claim-text><claim-text>obtaining radio detection and ranging (radar) data from the one or more radar assemblies electrically connected to the one or more processor devices;</claim-text><claim-text>determining a vehicle location based, at least in part, on the GNSS data, the APNT data, and the radar data; and</claim-text><claim-text>initiating a motion of the aerial vehicle based, at least in part, on the vehicle location.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The aerial vehicle of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the operations further comprise:<claim-text>determining one or more first position estimates for the aerial vehicle at a respective time based, at least in part, on the GNSS data;</claim-text><claim-text>determining one or more second position estimates for the aerial vehicle at the respective time based, at least in part, on the APNT data; and</claim-text><claim-text>determining one or more third position estimates for the aerial vehicle at the respective time based, at least in part, on the radar data.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The aerial vehicle of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the vehicle location is determined by applying a voting algorithm to the one or more first position estimates, the one or more second position estimates, and the one or more third position estimates.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The aerial vehicle of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein initiating the motion of the aerial vehicle comprises:<claim-text>determining one or more object locations for one or more objects proximate to the aerial vehicle based, at least in part, on the radar data;</claim-text><claim-text>determining one or more flight maneuvers based, at least in part, on the vehicle location and the one or more object locations; and</claim-text><claim-text>generating one or more actuator commands for initiating the motion of the aerial vehicle based, at least in part, on the one or more flight maneuvers.</claim-text></claim-text></claim></claims></us-patent-application>
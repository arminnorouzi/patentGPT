<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007107A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007107</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17364817</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>29</main-group><subgroup>08</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>05</class><subclass>B</subclass><main-group>13</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>R</subclass><main-group>16</main-group><subgroup>023</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>69</main-group><subgroup>325</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>B</subclass><main-group>13</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>12</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>R</subclass><main-group>16</main-group><subgroup>0231</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">CONVERTING CONTROL AREA NETWORK DATA TO ROBOTIC OPERATING SYSTEM DATA</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>GM Cruise Holdings LLC</orgname><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Guo</last-name><first-name>ShuTing</first-name><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Raut</last-name><first-name>Ashwin</first-name><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Leighton</last-name><first-name>Joshua</first-name><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Miller</last-name><first-name>Nick</first-name><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Methods and systems are provided for facilitating communications between an internal computing system and vehicle electronic control units. In some aspects, methods and systems are provided and can include receiving data from a plurality of vehicle electronic control units, the data from the plurality of vehicle electronic control units being processed by utilizing a control area network protocol, processing the data received from the plurality of vehicle electronic control units by utilizing a robotic operating system protocol, and providing robotic operating system data based on the data processed by utilizing the robotic operating system protocol to an internal computing system.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="87.04mm" wi="158.75mm" file="US20230007107A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="192.87mm" wi="158.75mm" orientation="landscape" file="US20230007107A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="254.34mm" wi="153.42mm" orientation="landscape" file="US20230007107A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="146.81mm" wi="174.67mm" file="US20230007107A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="181.44mm" wi="126.15mm" orientation="landscape" file="US20230007107A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><heading id="h-0002" level="1">1. Technical Field</heading><p id="p-0002" num="0001">The subject technology provides solutions for autonomous vehicles, and in particular, for facilitating communications between an internal computing system and vehicle electronic control units.</p><heading id="h-0003" level="1">2. Introduction</heading><p id="p-0003" num="0002">Autonomous vehicles are vehicles having computers and control systems that perform driving and navigation tasks that are conventionally performed by a human driver. As autonomous vehicle technologies continue to advance, ride-sharing services will increasingly utilize autonomous vehicles to improve service efficiency and safety. However, autonomous vehicles will be required to perform many of the functions that are conventionally performed by human drivers, such as avoiding dangerous or difficult routes, and performing other navigation and routing tasks necessary to provide a safe and efficient transportation. Such tasks may require the collection and processing of large quantities of data disposed on the autonomous vehicle.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0004" num="0003">Certain features of the subject technology are set forth in the appended claims. However, the accompanying drawings, which are included to provide further understanding, illustrate disclosed aspects and together with the description serve to explain the principles of the subject technology. In the drawings:</p><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example system environment that can be used to facilitate autonomous vehicle navigation and routing operations, according to some aspects of the disclosed technology.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example system environment that can be used to facilitate autonomous vehicle navigation and routing operations with an advanced driving interface module driver, according to some aspects of the disclosed technology.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example process of facilitating communications between an internal computing system and vehicle electronic control units, according to some aspects of the disclosed technology.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example processor-based system with which some aspects of the subject technology can be implemented.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0009" num="0008">The detailed description set forth below is intended as a description of various configurations of the subject technology and is not intended to represent the only configurations in which the subject technology can be practiced. The appended drawings are incorporated herein and constitute a part of the detailed description. The detailed description includes specific details for the purpose of providing a more thorough understanding of the subject technology. However, it will be clear and apparent that the subject technology is not limited to the specific details set forth herein and may be practiced without these details. In some instances, structures and components are shown in block diagram form in order to avoid obscuring the concepts of the subject technology.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example system environment <b>100</b> that can be used to facilitate AV dispatch and operations, according to some aspects of the disclosed technology. Autonomous vehicle <b>102</b> can navigate about roadways without a human driver based upon sensor signals output by sensor systems <b>104</b>-<b>106</b> of autonomous vehicle <b>102</b>. Autonomous vehicle <b>102</b> includes a plurality of sensor systems <b>104</b>-<b>106</b> (a first sensor system <b>104</b> through an Nth sensor system <b>106</b>). Sensor systems <b>104</b>-<b>106</b> are of different types and are arranged about the autonomous vehicle <b>102</b>. For example, first sensor system <b>104</b> may be a camera sensor system and the Nth sensor system <b>106</b> may be a Light Detection and Ranging (LIDAR) sensor system. Other exemplary sensor systems include radio detection and ranging (RADAR) sensor systems, Electromagnetic Detection and Ranging (EmDAR) sensor systems, Sound Navigation and Ranging (SONAR) sensor systems, Sound Detection and Ranging (SODAR) sensor systems, Global Navigation Satellite System (GNSS) receiver systems such as Global Positioning System (GPS) receiver systems, accelerometers, gyroscopes, inertial measurement units (IMU), infrared sensor systems, laser rangefinder systems, ultrasonic sensor systems, infrasonic sensor systems, microphones, or a combination thereof. While four sensors <b>180</b> are illustrated coupled to the autonomous vehicle <b>102</b>, it is understood that more or fewer sensors may be coupled to the autonomous vehicle <b>102</b>.</p><p id="p-0011" num="0010">Autonomous vehicle <b>102</b> further includes several mechanical systems that are used to effectuate appropriate motion of the autonomous vehicle <b>102</b>. For instance, the mechanical systems can include but are not limited to, vehicle propulsion system <b>130</b>, braking system <b>132</b>, and steering system <b>134</b>. Vehicle propulsion system <b>130</b> may include an electric motor, an internal combustion engine, or both. The braking system <b>132</b> can include an engine brake, brake pads, actuators, and/or any other suitable componentry that is configured to assist in decelerating autonomous vehicle <b>102</b>. In some cases, braking system <b>132</b> may charge a battery of the vehicle through regenerative braking. Steering system <b>134</b> includes suitable componentry that is configured to control the direction of movement of the autonomous vehicle <b>102</b> during navigation.</p><p id="p-0012" num="0011">Autonomous vehicle <b>102</b> further includes a safety system <b>136</b> that can include various lights and signal indicators, parking brake, airbags, etc. Autonomous vehicle <b>102</b> further includes a cabin system <b>138</b> that can include cabin temperature control systems, in-cabin entertainment systems, etc.</p><p id="p-0013" num="0012">Autonomous vehicle <b>102</b> additionally comprises an internal computing system <b>110</b> that is in communication with sensor systems <b>180</b> and systems <b>130</b>, <b>132</b>, <b>134</b>, <b>136</b>, and <b>138</b>. Internal computing system <b>110</b> includes at least one processor and at least one memory having computer-executable instructions that are executed by the processor. The computer-executable instructions can make up one or more services responsible for controlling autonomous vehicle <b>102</b>, communicating with remote computing system <b>150</b>, receiving inputs from passengers or human co-pilots, logging metrics regarding data collected by sensor systems <b>180</b> and human co-pilots, etc.</p><p id="p-0014" num="0013">Internal computing system <b>110</b> can include a control service <b>112</b> that is configured to control operation of vehicle propulsion system <b>130</b>, braking system <b>132</b>, steering system <b>134</b>, safety system <b>136</b>, and cabin system <b>138</b>. Control service <b>112</b> receives sensor signals from sensor systems <b>180</b> as well communicates with other services of internal computing system <b>110</b> to effectuate operation of autonomous vehicle <b>102</b>. In some embodiments, control service <b>112</b> may carry out operations in concert one or more other systems of autonomous vehicle <b>102</b>.</p><p id="p-0015" num="0014">Internal computing system <b>110</b> can also include constraint service <b>114</b> to facilitate safe propulsion of autonomous vehicle <b>102</b>. Constraint service <b>116</b> includes instructions for activating a constraint based on a rule-based restriction upon operation of autonomous vehicle <b>102</b>. For example, the constraint may be a restriction upon navigation that is activated in accordance with protocols configured to avoid occupying the same space as other objects, abide by traffic laws, circumvent avoidance areas, etc. In some embodiments, the constraint service can be part of control service <b>112</b>.</p><p id="p-0016" num="0015">The internal computing system <b>110</b> can also include communication service <b>116</b>. The communication service <b>116</b> can include both software and hardware elements for transmitting and receiving signals from/to the remote computing system <b>150</b>. Communication service <b>116</b> is configured to transmit information wirelessly over a network, for example, through an antenna array that provides connectivity using one or more cellular transmission standards, such as long-term evolution (LTE), 3G, 5G, or the like.</p><p id="p-0017" num="0016">In some embodiments, one or more services of the internal computing system <b>110</b> are configured to send and receive communications to remote computing system <b>150</b> for such reasons as reporting data for training and evaluating machine learning algorithms, requesting assistance from remoting computing system or a human operator via remote computing system <b>150</b>, software service updates, ridesharing pickup and drop off instructions etc.</p><p id="p-0018" num="0017">Internal computing system <b>110</b> can also include latency service <b>118</b>. Latency service <b>118</b> can utilize timestamps on communications to and from remote computing system <b>150</b> to determine if a communication has been received from the remote computing system <b>150</b> in time to be useful. For example, when a service of the internal computing system <b>110</b> requests feedback from remote computing system <b>150</b> on a time-sensitive process, the latency service <b>118</b> can determine if a response was timely received from remote computing system <b>150</b> as information can quickly become too stale to be actionable. When the latency service <b>118</b> determines that a response has not been received within a threshold, latency service <b>118</b> can enable other systems of autonomous vehicle <b>102</b> or a passenger to make necessary decisions or to provide the needed feedback.</p><p id="p-0019" num="0018">Internal computing system <b>110</b> can also include a user interface service <b>120</b> that can communicate with cabin system <b>138</b> in order to provide information or receive information to a human co-pilot or human passenger. In some embodiments, a human co-pilot or human passenger may be required to evaluate and override a constraint from constraint service <b>114</b>, or the human co-pilot or human passenger may wish to provide an instruction to the autonomous vehicle <b>102</b> regarding destinations, requested routes, or other requested operations.</p><p id="p-0020" num="0019">As described above, the remote computing system <b>150</b> is configured to send/receive a signal from the autonomous vehicle <b>140</b> regarding reporting data for training and evaluating machine learning algorithms, requesting assistance from remote computing system <b>150</b> or a human operator via the remote computing system <b>150</b>, software service updates, rideshare pickup and drop off instructions, etc.</p><p id="p-0021" num="0020">Remote computing system <b>150</b> includes an analysis service <b>152</b> that is configured to receive data from autonomous vehicle <b>102</b> and analyze the data to train or evaluate machine learning algorithms for operating the autonomous vehicle <b>102</b>. The analysis service <b>152</b> can also perform analysis pertaining to data associated with one or more errors or constraints reported by autonomous vehicle <b>102</b>.</p><p id="p-0022" num="0021">Remote computing system <b>150</b> can also include a user interface service <b>154</b> configured to present metrics, video, pictures, sounds reported from the autonomous vehicle <b>102</b> to an operator of remote computing system <b>150</b>. User interface service <b>154</b> can further receive input instructions from an operator that can be sent to the autonomous vehicle <b>102</b>.</p><p id="p-0023" num="0022">Remote computing system <b>150</b> can also include an instruction service <b>156</b> for sending instructions regarding the operation of the autonomous vehicle <b>102</b>. For example, in response to an output of the analysis service <b>152</b> or user interface service <b>154</b>, instructions service <b>156</b> can prepare instructions to one or more services of the autonomous vehicle <b>102</b> or a co-pilot or passenger of the autonomous vehicle <b>102</b>.</p><p id="p-0024" num="0023">Remote computing system <b>150</b> can also include rideshare service <b>158</b> configured to interact with ridesharing applications <b>170</b> operating on (potential) passenger computing devices. The rideshare service <b>158</b> can receive requests to be picked up or dropped off from passenger ridesharing app <b>170</b> and can dispatch autonomous vehicle <b>102</b> for the trip. The rideshare service <b>158</b> can also act as an intermediary between the ridesharing app <b>170</b> and the autonomous vehicle wherein a passenger might provide instructions to the autonomous vehicle to <b>102</b> go around an obstacle, change routes, honk the horn, etc.</p><p id="p-0025" num="0024">As described herein, one aspect of the present technology is to provide an autonomous vehicle system that can provide communications between an internal computing system and vehicle electronic control units. The present disclosure contemplates that in some instances, the communications between the internal computing system and the vehicle electronic control units include processing control area network (CAN) data received from various sensors throughout the system into robotic operating system (ROS) data.</p><p id="p-0026" num="0025">Currently, a large amount of data is received from various sensors utilized by autonomous vehicles at any given time. For example, data is received from sensors associated with vehicle propulsion, braking, steering, and safety. For autonomous vehicles, the data from the sensors are constantly being received by the autonomous to provide real-time decisions and determinations. In some examples, if the sensors detect that a pedestrian is entering the zone of travel of the autonomous vehicle, it is imperative that the autonomous vehicle react accordingly, and quickly. However, as a large amount of data is constantly being received from all of the sensors, the data associated with the above-mentioned pedestrian may not be processed by the autonomous vehicle in a timely manner that avoids the pedestrian. Another factor that contributes to the delayed reaction of the autonomous vehicle is the processing time and effort to process raw sensor data into a useable form, e.g., into robotic operating system data.</p><p id="p-0027" num="0026">Aspects of the disclosed technology address the foregoing limitations of conventional receipt of raw sensor data by an autonomous vehicle system by processing the raw sensor data into robotic operating system data that can be utilized by the autonomous vehicle system.</p><p id="p-0028" num="0027">As discussed in further detail below, methods and systems are provided for facilitating communications between an internal computing system and vehicle electronic control units. In some aspects, methods and systems are provided and can include receiving data from a plurality of vehicle electronic control units, the data from the plurality of vehicle electronic control units being processed by utilizing a control area network protocol, processing the data received from the plurality of vehicle electronic control units by utilizing a robotic operating system protocol, and providing robotic operating system data based on the data processed by utilizing the robotic operating system protocol to an internal computing system.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example system environment that can be used to facilitate autonomous vehicle navigation and routing operations with an advanced driving interface module driver <b>200</b>, according to some aspects of the disclosed technology. In some implementations, the autonomous vehicle system <b>200</b> can include an autonomous vehicle <b>102</b> (e.g., as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>) including an internal computing system <b>110</b>, vehicle electronic control units (ECUs) <b>202</b>, an advanced driving interface module (ADIM) <b>204</b>, and an ADIM driver <b>206</b>.</p><p id="p-0030" num="0029">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the internal computing system <b>110</b> of the autonomous vehicle system <b>200</b> can include a control service <b>112</b>, a constraint service <b>114</b>, a communication service <b>116</b>, a latency service <b>118</b>, a user interface service <b>120</b>, as described herein, and any other autonomous vehicle services suitable for the intended purpose and understood by a person of ordinary skill in the art. The above-mentioned services of the internal computing system <b>110</b> can be utilized to control and operate the autonomous vehicle <b>102</b>.</p><p id="p-0031" num="0030">In other implementations, the vehicle ECUs <b>202</b> of the autonomous vehicle system <b>200</b> can include a vehicle propulsion system <b>130</b>, a braking system <b>132</b>, a steering system <b>134</b>, a safety system <b>136</b>, a cabin system <b>138</b>, as described herein, and any other ECU suitable for the intended purpose and understood by a person of ordinary skill in the art to control various aspects of the autonomous vehicle <b>102</b>. Each of the above-mentioned systems can further include and utilize sensors (e.g., sensor A <b>104</b>, sensor B, <b>106</b>, sensor N <b>108</b>, etc.) that are configured to receive data. For example, accelerometer sensors can provide acceleration data, camera sensors can provide image data, and temperature sensors can provide cabin temperature data to the autonomous vehicle system <b>200</b>.</p><p id="p-0032" num="0031">In some examples, the ADIM <b>204</b> of the autonomous vehicle system <b>200</b> can be communicatively coupled to the vehicle ECUs <b>202</b> and the internal computing system <b>110</b>. For example, the ADIM <b>204</b> can utilize a control area network (CAN) protocol <b>208</b> to communicate with the vehicle ECUs <b>202</b>. In some implementations, the vehicle propulsion system <b>130</b>, the braking system <b>132</b>, the steering system <b>134</b>, the safety system <b>136</b>, and the cabin system <b>138</b> can convert their respective raw sensor data into CAN data by utilizing a CAN protocol, or their respective raw sensor data can initially be CAN data that may be distributed throughout via a CAN bus. The CAN data can be provided to the ADIM <b>204</b> to then to be provided to the internal computing system <b>110</b> via an Ethernet connection <b>210</b>. In some examples, the ADIM <b>204</b> can utilize a CAN database file (&#x201c;DBC&#x201d;) to decode the CAN data to a pre-determined format. In some implementations, the vehicle ECUs <b>202</b> of the autonomous vehicle <b>102</b> can generate CAN messages that can then be passed through via the ADIM <b>204</b> to the ADIM driver <b>206</b>. The ADIM driver <b>206</b> can convert the CAN messages into usable information for a variety of vehicle controls and decision making processes such as vehicle motion controls, auxiliary controls (e.g., door, window, HVAC, etc.), and system state computing (e.g., the control service <b>112</b>, the constraint service <b>114</b>, the communication service <b>116</b>, the latency service <b>118</b>, and the user interface service <b>120</b>).</p><p id="p-0033" num="0032">Once the CAN data is decoded by the ADIM <b>204</b> of the autonomous vehicle system <b>200</b>, the ADIM <b>204</b> can utilize an Ethernet protocol to convert the data received from the vehicle ECUs <b>202</b> into a format that can then be provided to the internal computing system <b>110</b>. In some examples, the data provided by the ADIM <b>205</b> can also be provided to the ADIM driver <b>206</b> to further process the data so that the data may be usable by the internal computing system <b>110</b>. The conversion process of the ADIM driver <b>206</b> can establish an abstraction layer between the internal computing system <b>110</b> and the vehicle ECUs <b>202</b> of the autonomous vehicle system <b>200</b> to consume information and data from various sensors of the vehicle ECUs <b>202</b>.</p><p id="p-0034" num="0033">In some implementations, the ADIM driver <b>206</b> of the autonomous vehicle system <b>200</b> may be a part of the internal computing system <b>110</b>. The ADIM <b>204</b> and the ADIM driver <b>206</b> can include corresponding Ethernet interfaces to utilize an Ethernet connection <b>210</b> to communicate with one another. In some examples, the ADIM driver <b>206</b> can utilize a robotic operating system (ROS) protocol to decode the data received from the ADIM <b>204</b>, which can then be provided to the respective systems of the internal computing system <b>110</b> (e.g., the control service <b>112</b>, the constraint service <b>114</b>, the communication service <b>116</b>, the latency service <b>118</b>, and the user interface service <b>120</b>). Utilizing a ROS protocol can provide the autonomous vehicle system <b>200</b> with hardware abstraction, low-level device control, implementation of device functionality, message-passing between systems and processes, and package management. The autonomous vehicle system <b>200</b> can reference a set of DBC files that can include definitions of all of the CAN messages, which can be utilized by the ADIM driver <b>206</b> to automatically generate corresponding message structures for the conversions of the raw CAN data into usable information that can be recognized and understood by the internal computing system <b>110</b>.</p><p id="p-0035" num="0034">Having disclosed some example system components and concepts, the disclosure now turns to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, which illustrates an example method <b>300</b> for facilitating communications between an internal computing system and vehicle electronic control units. The steps outlined herein are exemplary and can be implemented in any combination thereof, including combinations that exclude, add, or modify certain steps.</p><p id="p-0036" num="0035">At step <b>302</b>, method <b>300</b> can include receiving, at an advanced driving interface module driver, data from a plurality of vehicle electronic control units, the data from the plurality of vehicle electronic control units being processed by utilizing a control area network protocol. The receiving of the data from the plurality of vehicle electronic control units can be over an Ethernet connection. Control area network data can be processed by utilizing an Ethernet protocol. The processing of the data received from the plurality of vehicle electronic control units can include processing the control area network data by utilizing the Ethernet protocol.</p><p id="p-0037" num="0036">In some implementations, the data from the plurality of vehicle electronic control units can include sensor data from a plurality of sensors distributed throughout an autonomous vehicle.</p><p id="p-0038" num="0037">At step <b>304</b>, method <b>300</b> can include processing, by the advanced driving interface module driver, the data received from the plurality of vehicle electronic control units by utilizing a robotic operating system protocol. The processing of the data received from the plurality of vehicle electronic control units can include converting control area network data into robotic operating system data.</p><p id="p-0039" num="0038">At step <b>306</b>, method <b>300</b> can include providing, by the advanced driving interface module driver, robotic operating system data based on the data processed by utilizing the robotic operating system protocol to an internal computing system.</p><p id="p-0040" num="0039">The method <b>300</b> can further include processing, by an advanced driving interface module, control area network data received from the plurality of vehicle electronic control units into Ethernet data, and providing, by the advanced driving interface module, the Ethernet data to the advanced driving interface module driver.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example processor-based system with which some aspects of the subject technology can be implemented. For example, processor-based system <b>400</b> that can be any computing device making up internal computing system <b>110</b>, remote computing system <b>150</b>, a passenger device executing the rideshare app <b>170</b>, internal computing device <b>130</b>, or any component thereof in which the components of the system are in communication with each other using connection <b>405</b>. Connection <b>405</b> can be a physical connection via a bus, or a direct connection into processor <b>410</b>, such as in a chipset architecture. Connection <b>405</b> can also be a virtual connection, networked connection, or logical connection.</p><p id="p-0042" num="0041">In some embodiments, computing system <b>400</b> is a distributed system in which the functions described in this disclosure can be distributed within a datacenter, multiple data centers, a peer network, etc. In some embodiments, one or more of the described system components represents many such components each performing some or all of the function for which the component is described. In some embodiments, the components can be physical or virtual devices.</p><p id="p-0043" num="0042">Example system <b>400</b> includes at least one processing unit (CPU or processor) <b>410</b> and connection <b>405</b> that couples various system components including system memory <b>415</b>, such as read-only memory (ROM) <b>420</b> and random-access memory (RAM) <b>425</b> to processor <b>410</b>. Computing system <b>400</b> can include a cache of high-speed memory <b>412</b> connected directly with, in close proximity to, and/or integrated as part of processor <b>410</b>.</p><p id="p-0044" num="0043">Processor <b>410</b> can include any general-purpose processor and a hardware service or software service, such as services <b>432</b>, <b>434</b>, and <b>436</b> stored in storage device <b>430</b>, configured to control processor <b>410</b> as well as a special-purpose processor where software instructions are incorporated into the actual processor design. Processor <b>410</b> may essentially be a completely self-contained computing system, containing multiple cores or processors, a bus, memory controller, cache, etc. A multi-core processor may be symmetric or asymmetric.</p><p id="p-0045" num="0044">To enable user interaction, computing system <b>400</b> includes an input device <b>445</b>, which can represent any number of input mechanisms, such as a microphone for speech, a touch-sensitive screen for gesture or graphical input, keyboard, mouse, motion input, speech, etc. Computing system <b>400</b> can also include output device <b>435</b>, which can be one or more of a number of output mechanisms known to those of skill in the art. In some instances, multimodal systems can enable a user to provide multiple types of input/output to communicate with computing system <b>400</b>. Computing system <b>400</b> can include communications interface <b>440</b>, which can generally govern and manage the user input and system output. The communication interface may perform or facilitate receipt and/or transmission wired or wireless communications via wired and/or wireless transceivers, including those making use of an audio jack/plug, a microphone jack/plug, a universal serial bus (USB) port/plug, an Apple&#xae; Lightning&#xae; port/plug, an Ethernet port/plug, a fiber optic port/plug, a proprietary wired port/plug, a BLUETOOTH&#xae; wireless signal transfer, a BLUETOOTH&#xae; low energy (BLE) wireless signal transfer, an IBEACON&#xae; wireless signal transfer, a radio-frequency identification (RFID) wireless signal transfer, near-field communications (NFC) wireless signal transfer, dedicated short range communication (DSRC) wireless signal transfer, 802.11 Wi-Fi wireless signal transfer, wireless local area network (WLAN) signal transfer, Visible Light Communication (VLC), Worldwide Interoperability for Microwave Access (WiMAX), Infrared (IR) communication wireless signal transfer, Public Switched Telephone Network (PSTN) signal transfer, Integrated Services Digital Network (ISDN) signal transfer, 3G/4G/5G/LTE cellular data network wireless signal transfer, ad-hoc network signal transfer, radio wave signal transfer, microwave signal transfer, infrared signal transfer, visible light signal transfer, ultraviolet light signal transfer, wireless signal transfer along the electromagnetic spectrum, or some combination thereof.</p><p id="p-0046" num="0045">Communications interface <b>440</b> may also include one or more Global Navigation Satellite System (GNSS) receivers or transceivers that are used to determine a location of the computing system <b>400</b> based on receipt of one or more signals from one or more satellites associated with one or more GNSS systems. GNSS systems include, but are not limited to, the US-based Global Positioning System (GPS), the Russia-based Global Navigation Satellite System (GLONASS), the China-based BeiDou Navigation Satellite System (BDS), and the Europe-based Galileo GNSS. There is no restriction on operating on any particular hardware arrangement, and therefore the basic features here may easily be substituted for improved hardware or firmware arrangements as they are developed.</p><p id="p-0047" num="0046">Storage device <b>430</b> can be a non-volatile and/or non-transitory computer-readable memory device and can be a hard disk or other types of computer readable media which can store data that are accessible by a computer, such as magnetic cassettes, flash memory cards, solid state memory devices, digital versatile disks, cartridges, a floppy disk, a flexible disk, a hard disk, magnetic tape, a magnetic strip/stripe, any other magnetic storage medium, flash memory, memristor memory, any other solid-state memory, a compact disc read only memory (CD-ROM) optical disc, a rewritable compact disc (CD) optical disc, digital video disk (DVD) optical disc, a blu-ray disc (BDD) optical disc, a holographic optical disk, another optical medium, a secure digital (SD) card, a micro secure digital (microSD) card, a Memory Stick&#xae; card, a smartcard chip, a EMV chip, a subscriber identity module (SIM) card, a mini/micro/nano/pico SIM card, another integrated circuit (IC) chip/card, random access memory (RAM), static RAM (SRAM), dynamic RAM (DRAM), read-only memory (ROM), programmable read-only memory (PROM), erasable programmable read-only memory (EPROM), electrically erasable programmable read-only memory (EEPROM), flash EPROM (FLASHEPROM), cache memory (L1/L2/L3/L4/L5/L#), resistive random-access memory (RRAM/ReRAM), phase change memory (PCM), spin transfer torque RAM (STT-RAM), another memory chip or cartridge, and/or a combination thereof.</p><p id="p-0048" num="0047">Storage device <b>430</b> can include software services, servers, services, etc., that when the code that defines such software is executed by the processor <b>410</b>, it causes the system to perform a function. In some embodiments, a hardware service that performs a particular function can include the software component stored in a computer-readable medium in connection with the necessary hardware components, such as processor <b>410</b>, connection <b>405</b>, output device <b>435</b>, etc., to carry out the function.</p><p id="p-0049" num="0048">As understood by those of skill in the art, machine-learning based classification techniques can vary depending on the desired implementation. For example, machine-learning classification schemes can utilize one or more of the following, alone or in combination: hidden Markov models; recurrent neural networks; convolutional neural networks (CNNs); deep learning; Bayesian symbolic methods; general adversarial networks (GANs); support vector machines; image registration methods; applicable rule-based system. Where regression algorithms are used, they may include including but are not limited to: a Stochastic Gradient Descent Regressor, and/or a Passive Aggressive Regressor, etc.</p><p id="p-0050" num="0049">Machine learning classification models can also be based on clustering algorithms (e.g., a Mini-batch K-means clustering algorithm), a recommendation algorithm (e.g., a Miniwise Hashing algorithm, or Euclidean Locality-Sensitive Hashing (LSH) algorithm), and/or an anomaly detection algorithm, such as a Local outlier factor. Additionally, machine-learning models can employ a dimensionality reduction approach, such as, one or more of: a Mini-batch Dictionary Learning algorithm, an Incremental Principal Component Analysis (PCA) algorithm, a Latent Dirichlet Allocation algorithm, and/or a Mini-batch K-means algorithm, etc.</p><p id="p-0051" num="0050">Embodiments within the scope of the present disclosure may also include tangible and/or non-transitory computer-readable storage media or devices for carrying or having computer-executable instructions or data structures stored thereon. Such tangible computer-readable storage devices can be any available device that can be accessed by a general purpose or special purpose computer, including the functional design of any special purpose processor as described above. By way of example, and not limitation, such tangible computer-readable devices can include RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices, or any other device which can be used to carry or store desired program code in the form of computer-executable instructions, data structures, or processor chip design. When information or instructions are provided via a network or another communications connection (either hardwired, wireless, or combination thereof) to a computer, the computer properly views the connection as a computer-readable medium. Thus, any such connection is properly termed a computer-readable medium. Combinations of the above should also be included within the scope of the computer-readable storage devices.</p><p id="p-0052" num="0051">Computer-executable instructions include, for example, instructions and data which cause a general purpose computer, special purpose computer, or special purpose processing device to perform a certain function or group of functions. By way of example computer-executable instructions can be used to implement perception system functionality for determining when sensor cleaning operations are needed or should begin. Computer-executable instructions also include program modules that are executed by computers in stand-alone or network environments. Generally, program modules include routines, programs, components, data structures, objects, and the functions inherent in the design of special-purpose processors, etc. that perform tasks or implement abstract data types. Computer-executable instructions, associated data structures, and program modules represent examples of the program code means for executing steps of the methods disclosed herein. The particular sequence of such executable instructions or associated data structures represents examples of corresponding acts for implementing the functions described in such steps.</p><p id="p-0053" num="0052">Other embodiments of the disclosure may be practiced in network computing environments with many types of computer system configurations, including personal computers, hand-held devices, multi-processor systems, microprocessor-based or programmable consumer electronics, network PCs, minicomputers, mainframe computers, and the like. Embodiments may also be practiced in distributed computing environments where tasks are performed by local and remote processing devices that are linked (either by hardwired links, wireless links, or by a combination thereof) through a communications network. In a distributed computing environment, program modules can be located in both local and remote memory storage devices.</p><p id="p-0054" num="0053">The various embodiments described above are provided by way of illustration only and should not be construed to limit the scope of the disclosure. For example, the principles herein apply equally to optimization as well as general improvements. Various modifications and changes may be made to the principles described herein without following the example embodiments and applications illustrated and described herein, and without departing from the spirit and scope of the disclosure. Claim language reciting &#x201c;at least one of&#x201d; a set indicates that one member of the set or multiple members of the set satisfy the claim.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer-implemented method comprising:<claim-text>receiving, at an advanced driving interface module driver, data from a plurality of vehicle electronic control units, the data from the plurality of vehicle electronic control units being processed by utilizing a control area network protocol;</claim-text><claim-text>processing, by the advanced driving interface module driver, the data received from the plurality of vehicle electronic control units by utilizing a robotic operating system protocol; and</claim-text><claim-text>providing, by the advanced driving interface module driver, robotic operating system data based on the data processed by utilizing the robotic operating system protocol to an internal computing system.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the receiving of the data from the plurality of vehicle electronic control units is over an Ethernet connection.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computer-implemented method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein control area network data is processed by utilizing an Ethernet protocol.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computer-implemented method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the processing of the data received from the plurality of vehicle electronic control units includes processing the control area network data by utilizing the Ethernet protocol.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the data from the plurality of vehicle electronic control units includes sensor data from a plurality of sensors distributed throughout an autonomous vehicle.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing of the data received from the plurality of vehicle electronic control units includes converting control area network data into robotic operating system data.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>processing, by an advanced driving interface module, control area network data received from the plurality of vehicle electronic control units into Ethernet data; and</claim-text><claim-text>providing, by the advanced driving interface module, the Ethernet data to the advanced driving interface module driver.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A system comprising:<claim-text>one or more processors; and</claim-text><claim-text>at least one computer-readable storage medium having stored therein instructions which, when executed by the one or more processors, cause the simulation system to:<claim-text>receive data from a plurality of vehicle electronic control units, the data from the plurality of vehicle electronic control units being processed by utilizing a control area network protocol;</claim-text><claim-text>process the data from the plurality of vehicle electronic control units by utilizing a robotic operating system protocol; and</claim-text><claim-text>provide robotic operating system data based on the data processed by utilizing the robotic operating system protocol to an internal computing system.</claim-text></claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the receipt of the data from the plurality of vehicle electronic control units is over an Ethernet connection.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein control area network data is processed by utilizing an Ethernet protocol.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the data received from the plurality of vehicle electronic control units includes the control area network data that is processed by utilizing the Ethernet protocol.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the data from the plurality of vehicle electronic control units includes sensor data from a plurality of sensors distributed throughout an autonomous vehicle.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the data received from the plurality of vehicle electronic control units includes control area network data that is converted into robotic operating system data.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the instructions which, when executed by the one or more processors, cause the system to:<claim-text>process control area network data received from the plurality of vehicle electronic control units into Ethernet data; and</claim-text><claim-text>provide the Ethernet data to the internal computing system.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A non-transitory computer-readable storage medium comprising:<claim-text>instructions stored on the non-transitory computer-readable storage medium, the instructions, when executed by one more processors, cause the one or more processors to:<claim-text>receive data from a plurality of vehicle electronic control units, the data from the plurality of vehicle electronic control units being processed by utilizing a control area network protocol;</claim-text><claim-text>process the data from the plurality of vehicle electronic control units by utilizing a robotic operating system protocol; and</claim-text><claim-text>provide robotic operating system data based on the data processed by utilizing the robotic operating system protocol to an internal computing system.</claim-text></claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the receipt of the data from the plurality of vehicle electronic control units is over an Ethernet connection.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein control area network data is processed by utilizing an Ethernet protocol.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the data received from the plurality of vehicle electronic control units includes the control area network data that is processed by utilizing the Ethernet protocol.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the data from the plurality of vehicle electronic control units includes sensor data from a plurality of sensors distributed throughout an autonomous vehicle.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer-readable storage medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the data received from the plurality of vehicle electronic control units includes control area network data that is converted into robotic operating system data.</claim-text></claim></claims></us-patent-application>
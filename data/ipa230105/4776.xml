<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004777A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004777</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17857602</doc-number><date>20220705</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2021-0088122</doc-number><date>20210705</date></priority-claim><priority-claim sequence="02" kind="national"><country>KR</country><doc-number>10-2022-0002101</doc-number><date>20220106</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>063</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>063</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e79">SPIKE NEURAL NETWORK APPARATUS BASED ON MULTI-ENCODING AND METHOD OF OPERATION THEREOF</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Electronics and Telecommunications Research Institute</orgname><address><city>Daejeon</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Sung Eun</first-name><address><city>Daejeon</city><country>KR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>KANG</last-name><first-name>Tae Wook</first-name><address><city>Daejeon</city><country>KR</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Hyuk</first-name><address><city>Daejeon</city><country>KR</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>BAE</last-name><first-name>Young Hwan</first-name><address><city>Daejeon</city><country>KR</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>BYUN</last-name><first-name>Kyung Jin</first-name><address><city>Daejeon</city><country>KR</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>OH</last-name><first-name>Kwang IL</first-name><address><city>Daejeon</city><country>KR</country></address></addressbook></inventor><inventor sequence="06" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Jae-Jin</first-name><address><city>Daejeon</city><country>KR</country></address></addressbook></inventor><inventor sequence="07" designation="us-only"><addressbook><last-name>JEON</last-name><first-name>In San</first-name><address><city>Daejeon</city><country>KR</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Electronics and Telecommunications Research Institute</orgname><role>03</role><address><city>Daejeon</city><country>KR</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Disclosed are a spike neural network apparatus based on a multi-encoding and an operating method thereof. The method of operating a spike neural network (SNN) apparatus that performs a multi-encoding, includes receiving an input signal by an encoding module, performing a rate coding and a temporal coding on the received input signal by the encoding module, generating an SNN input signal based on the performance result of the rate coding and the temporal coding, and transmitting the generated SNN input signal to a neuromorphic chip that performs a spike neural network (SNN) operation.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="150.54mm" wi="151.89mm" file="US20230004777A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="177.72mm" wi="153.92mm" file="US20230004777A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="198.04mm" wi="148.34mm" orientation="landscape" file="US20230004777A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="72.98mm" wi="147.74mm" file="US20230004777A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="160.87mm" wi="147.74mm" file="US20230004777A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="188.98mm" wi="125.56mm" file="US20230004777A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="88.73mm" wi="109.90mm" file="US20230004777A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="161.71mm" wi="133.35mm" file="US20230004777A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="242.06mm" wi="144.02mm" orientation="landscape" file="US20230004777A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="138.68mm" wi="115.82mm" file="US20230004777A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="144.53mm" wi="115.74mm" file="US20230004777A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims priority under 35 U.S.C. &#xa7; 119 to Korean Patent Application Nos. 10-2021-0088122, filed on Jul. 5, 2021, and 10-2022-0002101, filed on Jan. 6, 2022, respectively, in the Korean Intellectual Property Office, the disclosures of which are incorporated by reference herein in their entireties.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Embodiments of the present disclosure described herein relate to a spike neural network apparatus, and more particularly, relate to a spike neural network apparatus performing a plurality of encoding methods on an input signal, and an operating method thereof.</p><p id="p-0004" num="0003">Interest in artificial intelligence technologies that process information by applying human thinking, inference, and learning processes to electronic devices is increasing, and technologies for processing information by mimicking neurons and synapses included in a human brain are also being developed. There are various types of neurons and synapses constituting the human brain, and research on signal processing between neurons or between synapses is still ongoing. Most of the currently developed SNN-based neuromorphic systems are based on leaky-integrate-and-fire (LIF) neuron models, but the neuromorphic system based on the LIF neuron model does not fully utilize characteristics of various neuronal models studied in the human brain.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0005" num="0004">Embodiments of the present disclosure provide a spike neural network apparatus and an operating method thereof, which pre-process an input signal through mixing a plurality of encoding methods, and perform signal processing based thereon.</p><p id="p-0006" num="0005">According to an embodiment of the present disclosure, a method of operating a spike neural network (SNN) apparatus that performs a multi-encoding, includes receiving an input signal by an encoding module, performing a rate coding and a temporal coding on the received input signal by the encoding module, generating an SNN input signal based on the performance result of the rate coding and the temporal coding, and transmitting the generated SNN input signal to a neuromorphic chip that performs a spike neural network (SNN) operation.</p><p id="p-0007" num="0006">According to an embodiment, the performing of the rate coding and the temporal coding on the received input signal by the encoding module may include performing the rate coding on the input signal, and performing the temporal coding on the performance result of the rate coding.</p><p id="p-0008" num="0007">According to an embodiment, the method may further include performing at least one of a phase coding and a synchronous coding on the performance result of the rate coding and the temporal coding.</p><p id="p-0009" num="0008">According to an embodiment, the temporal coding may be performed based on a frequency or a time margin of spike signals of the input signal.</p><p id="p-0010" num="0009">According to an embodiment, the performing of the SNN operation may include generating an SNN output signal representing a classification result of the SNN input signal.</p><p id="p-0011" num="0010">According to an embodiment, the SNN output signal may be one of at least four signals classified according to an identity.</p><p id="p-0012" num="0011">According to an embodiment, the SNN output signal may be one of the at least four signals classified according to the identity from two output neurons.</p><p id="p-0013" num="0012">According to an embodiment, the SNN output signal may represent the classification result based on the rate coding and the temporal coding.</p><p id="p-0014" num="0013">According to an embodiment of the present disclosure, a spike neural network (SNN) apparatus that performs a multi-encoding, includes a neuromorphic chip that receives an input signal and generates an SNN input signal and an SNN output signal, and a memory that stores the SNN input signal and the SNN output signal, and the neuromorphic chip performs a rate coding and a temporal coding on the received input signal, generates the SNN input signal based on the performance result, and generates the SNN output signal from the generated SNN input signal by performing a spike neural network (SNN) operation.</p><p id="p-0015" num="0014">According to an embodiment, the SNN output signal may represent a classification result of the SNN input signal based on the rate coding and the temporal coding.</p><p id="p-0016" num="0015">According to an embodiment, the SNN output signal may be one of at least four signals classified according to an identity.</p><p id="p-0017" num="0016">According to an embodiment, the SNN output signal may be one of the at least four signals classified according to the identity from two output neurons.</p><p id="p-0018" num="0017">According to an embodiment, the neuromorphic chip may be implemented with a network-on-chip (NoC) including first to N-th clusters (where &#x2018;N&#x2019; is a natural number equal to or greater than 4).</p><p id="p-0019" num="0018">According to an embodiment, the NoC may be implemented with one of a mesh structure and a tree structure.</p><p id="p-0020" num="0019">According to an embodiment, the first cluster may perform the rate coding on the input signal, and the second cluster may perform the temporal coding on an output of the first cluster.</p><p id="p-0021" num="0020">According to an embodiment, the third cluster may perform a phase coding on an output of the second cluster, and the fourth cluster may perform a synchronous coding on the output of the second cluster or an output of the third cluster.</p><p id="p-0022" num="0021">According to an embodiment, with respect to the input signal, the first cluster may perform the rate coding, the second cluster may perform the temporal coding, the third cluster may perform a phase coding, and the fourth cluster may perform a synchronous coding, and the neuromorphic chip may generate the SNN input signal by interfacing the performance results of each of the first to fourth clusters.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE FIGURES</heading><p id="p-0023" num="0022">The above and other objects and features of the present disclosure will become apparent by describing in detail embodiments thereof with reference to the accompanying drawings.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of a spike neural network apparatus, according to an embodiment of the present disclosure.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an encoding module, according to an embodiment of the present disclosure.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example of an encoding module, according to an embodiment of the present disclosure.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref> are diagrams illustrating performance results of each operation of the spike neural network apparatus, according to an embodiment of the present disclosure.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart illustrating an operation of a spike neural network apparatus, according to an embodiment of the present disclosure.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram of a spike neural network apparatus, according to an embodiment of the present disclosure.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref> are diagrams illustrating configurations for implementing a neuromorphic chip function, according to an embodiment of the present disclosure.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating an operation of a spike neural network apparatus, according to an embodiment of the present disclosure.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an operation of a spike neural network apparatus, according to an embodiment of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0033" num="0032">Hereinafter, with reference to the accompanying drawings, embodiments of the present disclosure will be described clearly and in detail such that those skilled in the art may easily carry out the present disclosure. In addition, a signal in the present specification may include a plurality of signals in some cases. A signal in the present specification may include a plurality of signals in some cases, and the plurality of signals may be different signals.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a block diagram of a spike neural network apparatus <b>100</b>, according to an embodiment of the present disclosure. Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the spike neural network apparatus <b>100</b> may include an encoding module <b>200</b>, processors <b>110</b>, a neuromorphic chip <b>120</b>, and a memory <b>130</b>.</p><p id="p-0035" num="0034">The processors <b>110</b> may function as a central processing unit of the spike neural network apparatus <b>100</b>. At least one of the processors <b>110</b> may drive the encoding module <b>200</b>. The processors <b>110</b> may include at least one general purpose processor, such as a central processing unit <b>111</b> (CPU), an application processor <b>112</b> (AP), etc. The processors <b>110</b> may also include at least one special purpose processor, such as a neural processing unit <b>113</b>, a neuromorphic processor <b>114</b>, a graphics processing unit <b>115</b> (GPU), etc. The processors <b>110</b> may include two or more homogeneous processors. As another example, at least one (or at least the other) of the processors <b>110</b> may be manufactured to implement various machine learning or deep learning modules.</p><p id="p-0036" num="0035">At least one of the processors <b>110</b> may execute the encoding module <b>200</b>. The encoding module <b>200</b> may perform at least two encoding methods with respect to an input signal received to the encoding module <b>200</b>. At least one of the processors <b>110</b> may execute the encoding module <b>200</b> to perform an encoding method suitable for extracting a characteristic desired by a user. For example, the encoding module <b>200</b> may perform a rate coding and a temporal coding with respect to the input signal received to the encoding module <b>200</b>. In this case, the encoding module <b>200</b> may perform the rate coding and the temporal coding simultaneously or sequentially.</p><p id="p-0037" num="0036">For example, when the encoding module <b>200</b> performs the rate coding on an input signal, a signal including first characteristic information (e.g., strength of an input signal) may be generated as a performance result of the rate coding. When the encoding module <b>200</b> performs the temporal coding on the input signal, a signal including second characteristic information (e.g., frequency or time information of the input signal) may be generated as a performance result of the temporal coding.</p><p id="p-0038" num="0037">For example, when the encoding module <b>200</b> performs the rate coding on an input signal and performs the temporal coding on the performance result of the rate coding, the encoding module <b>200</b> may generate a signal including the first characteristic information (e.g., the strength of the input signal) and the second characteristic information (e.g., a frequency or time margin between spike signals generated as a performance result of the rate coding).</p><p id="p-0039" num="0038">For example, when at least one of the processors <b>110</b> executes the encoding module <b>200</b> to perform the rate coding, the encoding module <b>200</b> may generate a number of spike signals proportional to the strength of the input signal as a performance result of the rate coding. When at least one of the processors <b>110</b> executes the encoding module <b>200</b> to perform the temporal coding, the encoding module <b>200</b> may represent the strength or identity of the input signal based on the time margin of the spike signals of the input signal or the frequency of the spike signals of the input signal.</p><p id="p-0040" num="0039">As another example, at least one of the processors <b>110</b> may execute the encoding module <b>200</b> to perform the phase coding or the synchronous coding on the input signal received to the encoding module <b>200</b>. For example, when at least one of the processors <b>110</b> executes the encoding module <b>200</b> to perform the phase coding, the performance result may include a change characteristic depending on a time of the input signal. In addition, when at least one of the processors <b>110</b> executes the encoding module <b>200</b> to perform the synchronous coding, the encoding module <b>200</b> may generate an output signal in an emergency situation (e.g., when a plurality of input spike signals are simultaneously fired).</p><p id="p-0041" num="0040">At least one of the processors <b>110</b> may execute the encoding module <b>200</b> to generate an SNN input signal based on a performance result of encoding the input signal. At least one of the processors <b>110</b> may transmit the generated SNN input signal to the neuromorphic chip <b>120</b>.</p><p id="p-0042" num="0041">At least one of the processors <b>110</b> may request the neuromorphic chip <b>120</b> to perform an SNN operation on signals or data. For example, at least one of the processors <b>110</b> may transmit the SNN input signal generated from the encoding performance result to the neuromorphic chip <b>120</b>, and may request the neuromorphic chip <b>120</b> that receives the SNN input signal to perform the SNN operation. In this case, the neuromorphic chip <b>120</b> may generate an SNN output signal representing a classification result of the SNN input signal as a result of the SNN operation.</p><p id="p-0043" num="0042">The encoding module <b>200</b> may be implemented in the form of instructions (or codes) executed by at least one of the processors <b>110</b>. In this case, at least one of the processors <b>110</b> may store the instructions (or codes) of the encoding module <b>200</b> in the memory <b>130</b>.</p><p id="p-0044" num="0043">At least one (or at least another) of the processors <b>110</b> may be manufactured to implement the encoding module <b>200</b>. For example, the at least one processor may be a dedicated processor implemented in hardware based on the encoding module <b>200</b> generated by learning of the encoding module <b>200</b>.</p><p id="p-0045" num="0044">The neuromorphic chip <b>120</b> may perform an SNN operation. For example, the neuromorphic chip <b>120</b> may perform the SNN operation on the SNN input signal received from the encoding module <b>200</b> and may generate an SNN output signal representing a classification result of the SNN input signal.</p><p id="p-0046" num="0045">The neuromorphic chip <b>120</b> may be implemented with a network-on-chip (NoC) including first to N-th clusters (where &#x2018;N&#x2019; is a natural number equal to or greater than 4). In this case, the NoC may be implemented in the form of a mesh type, a tree (e.g., a quad-tree or a binary tree) type, or a torus (e.g., a folded-torus) type.</p><p id="p-0047" num="0046">The memory <b>130</b> may store data and process codes being processed or to be processed by the processors <b>110</b>. For example, in some embodiments, the memory <b>130</b> may store data to be input to the spike neural network apparatus <b>100</b> or data generated or trained in a process of performing encoding by the processors <b>110</b>. For example, the memory <b>130</b> may store the SNN input signal generated from the encoding module <b>200</b> and the SNN output signal generated from the neuromorphic chip <b>120</b>.</p><p id="p-0048" num="0047">The memory <b>130</b> may be used as a main memory device of the spike neural network apparatus <b>100</b>. The memory <b>130</b> may include a dynamic random access memory (DRAM), a static RAM (SRAM), a phase-change RAM (PRAM), a magnetic RAM (MRAM), a ferroelectric RAM (FeRAM), a resistive RAM (RRAM), etc.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates the encoding module <b>200</b>, according to an embodiment of the present disclosure. Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the encoding module <b>200</b> may include a rate coding unit <b>210</b> and a temporal coding unit <b>220</b>. The rate coding unit <b>210</b> may perform a rate coding on an input signal. The temporal coding unit <b>220</b> may perform a temporal coding on the input signal or a performance result of the rate coding.</p><p id="p-0050" num="0049">Unlike that illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the encoding module <b>200</b> may include a phase coding unit performing a phase coding or a synchronous coding unit performing a synchronous coding. In addition, the encoding module <b>200</b> may further include a separate coding units for performing various encodings.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example of the encoding module <b>200</b>, according to an embodiment of the present disclosure. Referring to <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>, the encoding module <b>200</b> may receive an input signal, and the rate coding unit <b>210</b> may perform the rate coding on the received input signal. The temporal coding unit <b>220</b> may perform a temporal coding on a performance result of the rate coding. The encoding module <b>200</b> may generate an SNN input signal from a performance result of the temporal coding.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref> illustrate performance results of each operation of the spike neural network apparatus, according to an embodiment of the present disclosure. Referring to <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>, the encoding module <b>200</b> may receive an input signal including a first region having a relatively high strength and a second region having a relatively weak strength. When the rate coding is performed on an input signal including the first region and the second region, the rate coding performance result corresponding to the first region may include more spike signals than the rate coding performance result corresponding to the second region. When the temporal coding is performed on the result of performing the rate coding, the result of performing the temporal coding may include information (e.g., a frequency of the spike signals of the input signal including the first region and the second region or a time margin of the spike signals of the input signal including the first region and the second region) associated with a time of spike signals generated by performing the rate coding.</p><p id="p-0053" num="0052">Referring to <figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref>, the encoding module <b>200</b> may generate the SNN input signal based on a result of performing encoding. In this case, the SNN input signal may include signals corresponding to the first region and the second region. The neuromorphic chip <b>120</b> may perform an SNN operation on the generated SNN input signal and may generate an SNN output signal representing a classification result of the SNN input signal. In this case, the SNN output signal may be one of at least four signals classified according to an identity. In addition, the SNN output signal may be one of at least four signals classified according to the identity from two output neurons.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a flowchart of an operation of the spike neural network apparatus <b>100</b>, according to an embodiment of the present disclosure. Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the spike neural network apparatus <b>100</b> may perform operations S<b>110</b> to S<b>160</b>.</p><p id="p-0055" num="0054">In operation S<b>110</b>, the encoding module <b>200</b> may receive an input signal.</p><p id="p-0056" num="0055">In operation S<b>120</b>, the encoding module <b>200</b> may perform the rate coding on the received input signal under the control of at least one of the processors <b>110</b>. In this case, the rate coding unit <b>210</b> of the encoding module <b>200</b> may perform the rate coding.</p><p id="p-0057" num="0056">In operation S<b>130</b>, the encoding module <b>200</b> may perform the temporal coding on the performance result of the rate coding under the control of at least one of the processors <b>110</b>. In this case, the temporal coding unit <b>220</b> of the encoding module <b>200</b> may perform the temporal coding.</p><p id="p-0058" num="0057">In operation S<b>140</b>, the encoding module <b>200</b> may generate the SNN input signal based on a result of performing the temporal coding under the control of at least one of the processors <b>110</b>.</p><p id="p-0059" num="0058">In operation S<b>150</b>, the encoding module <b>200</b> may transmit the generated SNN input signal to the neuromorphic chip <b>120</b> under the control of at least one of the processors <b>110</b>.</p><p id="p-0060" num="0059">In operation S<b>160</b>, the neuromorphic chip <b>120</b> may perform the SNN operation on the SNN input signal received from the encoding module <b>200</b> and may generate the SNN output signal representing a classification result of the SNN input signal. The neuromorphic chip <b>120</b> may classify the identity based on the relative strength of the SNN input signal, and the SNN output signal may be one of at least four signals classified according to the identity. In this case, the SNN input signal is respectively input to at least two input neurons of an input layer of the spike neural network, and at least four signals classified according to their identities may be output from at least two output neurons of an output layer of the spike neural network.</p><p id="p-0061" num="0060">The signals or data generated in operations S<b>110</b> to S<b>160</b> (e.g., the rate coding performance result, the temporal coding performance result, the SNN input signal, and the SNN output signal) may be stored in the memory <b>130</b>.</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a block diagram of a spike neural network apparatus <b>500</b>, according to an embodiment of the present disclosure. Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the spike neural network apparatus <b>500</b> may include a neuromorphic chip <b>510</b> and a memory <b>520</b>.</p><p id="p-0063" num="0062">The neuromorphic chip <b>510</b> may receive an input signal from the outside, and may perform at least two encoding methods on the received input signal. The neuromorphic chip <b>510</b> may simultaneously or sequentially perform at least two encoding methods. The neuromorphic chip <b>510</b> may perform an encoding method suitable for extracting a characteristic desired by a user.</p><p id="p-0064" num="0063">For example, the neuromorphic chip <b>510</b> may receive an input signal, and may perform the rate coding and the temporal coding on the received input signal. The neuromorphic chip <b>510</b> may generate an SNN input signal based on a result of performing encoding, and may perform an SNN operation to generate an SNN output signal from the SNN input signal. In this case, the SNN output signal may represent a classification result of the SNN input signal based on the encoding performance result.</p><p id="p-0065" num="0064">The neuromorphic chip <b>510</b> may correspond to the neuromorphic chip <b>120</b> described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Therefore, the neuromorphic chip <b>510</b> is implemented with a network-on-chip (NoC), and the NoC may be implemented in the form of a mesh type, a tree (e.g., a quad tree or a binary tree) type, or a torus (e.g., a folded-torus) type.</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref> illustrate configurations for implementing the function of the neuromorphic chip <b>510</b>, according to an embodiment of the present disclosure. Referring to <figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref>, the neuromorphic chip <b>510</b> may be implemented with a mesh-type NoC or a tree-type NoC. In <figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref>, the components are illustrated in a planar shape for convenience, but according to an embodiment of the present disclosure, the components illustrated in <figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref> may be arranged in a three-dimensional shape.</p><p id="p-0067" num="0066">The neuromorphic chip <b>510</b> may include a plurality of clusters and a plurality of routers corresponding to the plurality of clusters. For example, the neuromorphic chip <b>510</b> may include first to N-th clusters (where &#x2018;N&#x2019; is a natural number equal to or greater than 4), and may include at least one router corresponding to each cluster. The plurality of routers may be reconfigurable routers that perform signal connections between the plurality of clusters. Although not illustrated, the neuromorphic chip <b>510</b> may include a plurality of interconnects for transferring information between a plurality of routers.</p><p id="p-0068" num="0067">Each of the plurality of clusters may receive input information through at least one router, and may perform an operation on the received input information to transmit the operation result through the router. For example, each of the plurality of clusters may provide an operation result, and may output path information representing the cluster to receive the operation result through a router. In this case, at least one interconnect between routers may provide the operation result to at least one other cluster.</p><p id="p-0069" num="0068">Each of the plurality of clusters may perform different encoding methods on the signal received to the neuromorphic chip <b>510</b>. In this case, each of the plurality of clusters may simultaneously or sequentially perform different encoding methods. For example, with respect to the SNN input signal received by the neuromorphic chip <b>510</b>, a first cluster may perform the rate coding, a second cluster may perform the temporal coding, a third cluster may perform the phase coding, and a fourth cluster may perform the synchronous coding.</p><p id="p-0070" num="0069">As another example, with respect to the SNN input signal received by the neuromorphic chip <b>510</b>, a first cluster may perform the rate coding, a second cluster may perform the temporal coding on an output of the first cluster, a third The cluster may perform the phase coding on an output of the second cluster, and the fourth cluster may perform the synchronous coding on the output of the second cluster or an output of the third cluster.</p><p id="p-0071" num="0070">The memory <b>520</b> may correspond to the memory <b>130</b> described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The memory <b>520</b> may store data to be input to the spike neural network apparatus <b>500</b>, data generated during encoding of the neuromorphic chip <b>510</b>, or data generated during an SNN operation of the neuromorphic chip <b>510</b>. In addition, the memory <b>520</b> may be used as a main memory device of the spike neural network apparatus <b>500</b>.</p><p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a flowchart of an operation of the spike neural network apparatus <b>500</b>, according to an embodiment of the present disclosure. Referring to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the spike neural network apparatus <b>500</b> may perform operations S<b>210</b> to S<b>240</b>.</p><p id="p-0073" num="0072">In operation S<b>210</b>, the neuromorphic chip <b>510</b> may receive an input signal.</p><p id="p-0074" num="0073">In operation S<b>220</b>, the neuromorphic chip <b>510</b> may perform the rate coding and the temporal coding on the received input signal. The neuromorphic chip <b>510</b> may perform the rate coding and the temporal coding simultaneously or sequentially. For example, the first cluster may perform the rate coding, and the second cluster may perform the temporal coding on the output of the first cluster.</p><p id="p-0075" num="0074">In operation S<b>230</b>, the neuromorphic chip <b>510</b> may generate the SNN input signal based on the results of performing the rate coding and the temporal coding.</p><p id="p-0076" num="0075">In operation S<b>240</b>, the neuromorphic chip <b>510</b> may perform an SNN operation on the generated SNN input signal and may generate an SNN output signal representing a classification result of the SNN input signal. The neuromorphic chip <b>510</b> may classify the identity based on the relative strength of the SNN input signal, and the SNN output signal may be one of at least four signals classified according to the identity. In this case, the SNN input signal is respectively input to at least two input neurons of an input layer of the spike neural network, and at least four signals classified according to their identities may be output from at least two output neurons of an output layer of the spike neural network.</p><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a flowchart of an operation of the spike neural network apparatus <b>500</b>, according to an embodiment of the present disclosure. Referring to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the spike neural network apparatus <b>500</b> may perform operations S<b>310</b> to S<b>340</b>.</p><p id="p-0078" num="0077">In operation S<b>310</b>, the neuromorphic chip <b>510</b> may receive an input signal.</p><p id="p-0079" num="0078">In operation S<b>320</b>, the neuromorphic chip <b>510</b> may perform the rate coding, the temporal coding, the phase coding, and the synchronous coding on the received input signal. The neuromorphic chip <b>510</b> may perform the rate coding, the temporal coding, the phase coding, and the synchronous coding simultaneously or sequentially. For example, the first cluster may perform the rate coding, the second cluster may perform the temporal coding on an output of the first cluster, the third cluster may perform the phase coding on an output of the second cluster, and the fourth cluster may perform the synchronous coding on the output of the second cluster or an output of the third cluster. For example, one of the phase coding and the synchronous coding may be omitted.</p><p id="p-0080" num="0079">For example, with respect to the SNN input signal received by the neuromorphic chip <b>510</b>, the first cluster may perform the rate coding, the second cluster may perform the temporal coding, the third cluster may perform the phase coding, and the fourth cluster may perform the synchronous coding.</p><p id="p-0081" num="0080">In operation S<b>330</b>, the neuromorphic chip <b>510</b> may generate the SNN input signal based on performance results of the rate coding, the temporal coding, the phase coding, and the synchronous coding.</p><p id="p-0082" num="0081">As another example, when the first to fourth clusters each perform different encoding on the input signal received by the neuromorphic chip <b>510</b>, the neuromorphic chip <b>510</b> may generate the SNN input signal by interfacing the performance results of each of the first to fourth clusters.</p><p id="p-0083" num="0082">In operation S<b>340</b>, the neuromorphic chip <b>510</b> may perform an SNN operation on the generated SNN input signal and may generate an SNN output signal representing a classification result of the SNN input signal. The neuromorphic chip <b>510</b> may classify the identity based on the relative strength of the SNN input signal, and the SNN output signal may be one of at least four signals classified according to the identity. In this case, the SNN input signal is respectively input to at least two input neurons of an input layer of the spike neural network, and at least four signals classified according to their identities may be output from at least two output neurons of an output layer of the spike neural network.</p><p id="p-0084" num="0083">According to an embodiment of the present disclosure, a spike neural network apparatus may contain more information in the input signal by remodeling the input signal by mixing various encoding methods. Accordingly, it is possible to improve the operation efficiency or the signal processing efficiency of the spike neural network apparatus, and to minimize the configuration of hardware required to process signals.</p><p id="p-0085" num="0084">The above description refers to embodiments for implementing the present disclosure. Embodiments in which a design is changed simply or which are easily changed may be included in the present disclosure as well as an embodiment described above. In addition, technologies that are easily changed and implemented by using the above embodiments may be included in the present disclosure. Accordingly, the scope of the present disclosure should not be limited to the above-described embodiments and should be defined by equivalents of the claims as well as the claims to be described later.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of operating a spike neural network (SNN) apparatus that performs a multi-encoding, the method comprising:<claim-text>receiving an input signal by an encoding module;</claim-text><claim-text>performing a rate coding and a temporal coding on the received input signal by the encoding module;</claim-text><claim-text>generating an SNN input signal based on the performance result of the rate coding and the temporal coding; and</claim-text><claim-text>transmitting the generated SNN input signal to a neuromorphic chip that performs a spike neural network (SNN) operation.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the performing of the rate coding and the temporal coding on the received input signal by the encoding module includes:<claim-text>performing the rate coding on the input signal; and</claim-text><claim-text>performing the temporal coding on the performance result of the rate coding.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>performing at least one of a phase coding and a synchronous coding on the performance result of the rate coding and the temporal coding.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the temporal coding is performed based on a frequency or a time margin of spike signals of the input signal.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the performing of the SNN operation includes generating an SNN output signal representing a classification result of the SNN input signal.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the SNN output signal is one of at least four signals classified according to an identity.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the SNN output signal is one of the at least four signals classified according to the identity from two output neurons.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the SNN output signal represents the classification result based on the rate coding and the temporal coding.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A spike neural network (SNN) apparatus that performs a multi-encoding comprising:<claim-text>a neuromorphic chip configured to receive an input signal and to generate an SNN input signal and an SNN output signal; and</claim-text><claim-text>a memory configured to store the SNN input signal and the SNN output signal, and</claim-text><claim-text>wherein the neuromorphic chip:</claim-text><claim-text>performs a rate coding and a temporal coding on the received input signal;</claim-text><claim-text>generates the SNN input signal based on the performance result; and</claim-text><claim-text>generates the SNN output signal from the generated SNN input signal by performing a spike neural network operation.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The spike neural network apparatus of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the SNN output signal represents a classification result of the SNN input signal based on the rate coding and the temporal coding.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The spike neural network apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the SNN output signal is one of at least four signals classified according to an identity.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The spike neural network apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the SNN output signal is one of the at least four signals classified according to the identity from two output neurons.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The spike neural network apparatus of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the neuromorphic chip is implemented with a network-on-chip (NoC) including first to N-th clusters (where &#x2018;N&#x2019; is a natural number equal to or greater than 4).</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The spike neural network apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the NoC is implemented with one of a mesh structure and a tree structure.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The spike neural network apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the first cluster performs the rate coding on the input signal, and the second cluster performs the temporal coding on an output of the first cluster.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The spike neural network apparatus of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the third cluster performs a phase coding on an output of the second cluster, and the fourth cluster performs a synchronous coding on the output of the second cluster or an output of the third cluster.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The spike neural network apparatus of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein, with respect to the input signal,<claim-text>the first cluster performs the rate coding;</claim-text><claim-text>the second cluster performs the temporal coding;</claim-text><claim-text>the third cluster performs a phase coding; and</claim-text><claim-text>the fourth cluster performs a synchronous coding, and</claim-text><claim-text>wherein the neuromorphic chip generates the SNN input signal by interfacing the performance results of each of the first to fourth clusters.</claim-text></claim-text></claim></claims></us-patent-application>
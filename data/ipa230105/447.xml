<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000448A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221220" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000448</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17904704</doc-number><date>20210218</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>20</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>20</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>743</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>20</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>20</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">GOAL MANAGEMENT SYSTEM</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>62979262</doc-number><date>20200220</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Becton, Dickinson and Company</orgname><address><city>Franklin Lakes</city><state>NJ</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>McClure</last-name><first-name>Douglas</first-name><address><city>Framingham</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Memmelaar</last-name><first-name>Bryan Edward</first-name><address><city>Hopkinton</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Wilson</last-name><first-name>Dylan G.</first-name><address><city>Raleigh</city><state>NC</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Bedell</last-name><first-name>Ryan Francis</first-name><address><city>Waltham</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Butler</last-name><first-name>Danielle V.</first-name><address><city>New York City</city><state>NY</state><country>US</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>Rourke</last-name><first-name>Bryan</first-name><address><city>Ridgewood</city><state>NJ</state><country>US</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/US2021/018529</doc-number><date>20210218</date></document-id><us-371c12-date><date>20220819</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method for displaying content items to a user based on selected goals from the user includes performing an initial assessment of a user, which includes retrieving at least one of measured patient disease management data and user-inputted patient disease management data from a user database, requesting additional information from the user for determining one or more goals, and receiving the additional information from the user via a user interface. The method includes recommending a plurality of goals based on the initial assessment and stored protocols related to disease management retrieved from a content database, receiving a selection of a goal from the user, receiving goal tracking information indicative of progress toward the selected goal, selecting one or more content items from the content database based on at least one of the selected goal and the goal tracking information, and displaying the selected one or more content items.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="107.19mm" wi="158.75mm" file="US20230000448A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="206.16mm" wi="146.90mm" orientation="landscape" file="US20230000448A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="193.04mm" wi="138.18mm" file="US20230000448A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="180.42mm" wi="145.29mm" orientation="landscape" file="US20230000448A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="238.42mm" wi="140.29mm" orientation="landscape" file="US20230000448A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="186.52mm" wi="99.65mm" file="US20230000448A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="177.55mm" wi="112.01mm" file="US20230000448A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="180.76mm" wi="112.44mm" file="US20230000448A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="238.84mm" wi="143.17mm" orientation="landscape" file="US20230000448A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="194.31mm" wi="152.32mm" file="US20230000448A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="208.53mm" wi="102.19mm" file="US20230000448A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="224.37mm" wi="152.23mm" orientation="landscape" file="US20230000448A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="169.76mm" wi="133.01mm" orientation="landscape" file="US20230000448A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="159.17mm" wi="143.85mm" orientation="landscape" file="US20230000448A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="176.28mm" wi="149.61mm" orientation="landscape" file="US20230000448A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="235.37mm" wi="152.23mm" orientation="landscape" file="US20230000448A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="189.99mm" wi="95.08mm" file="US20230000448A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="229.87mm" wi="157.31mm" orientation="landscape" file="US20230000448A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="237.24mm" wi="145.63mm" orientation="landscape" file="US20230000448A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="162.05mm" wi="144.78mm" orientation="landscape" file="US20230000448A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="143.85mm" wi="154.01mm" orientation="landscape" file="US20230000448A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="85.51mm" wi="158.24mm" orientation="landscape" file="US20230000448A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="195.58mm" wi="152.65mm" orientation="landscape" file="US20230000448A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00023" num="00023"><img id="EMI-D00023" he="97.87mm" wi="113.79mm" orientation="landscape" file="US20230000448A1-20230105-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">RELATED U.S. APPLICATIONS</heading><p id="p-0002" num="0001">This application claims priority to U.S. Provisional Appl. No. 62/979262, filed on Feb. 20, 2020, which is hereby incorporated by reference in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Field</heading><p id="p-0003" num="0002">Embodiments relate to systems and methods for managing illnesses and diseases, and, in particular, to systems and methods that provide smart, connected, end-to-end solutions for delivering personalized insights to patients or other users.</p><heading id="h-0004" level="1">Description</heading><p id="p-0004" num="0003">Diabetes is a group of diseases marked by high levels of blood glucose resulting from defects in insulin production, insulin action, or both. Diabetes can lead to serious complications and premature death. There are, however, well-known products and strategies available to patients with diabetes to help control the disease and lower the risk of complications.</p><p id="p-0005" num="0004">Treatment options for diabetics include, for example, specialized diets, oral medications, and insulin therapy. A primary goal of diabetes treatment is to control a diabetic's blood glucose level in order to increase the chance of a complication-free life. Because of the nature of diabetes and its short-term and long-term complications, it is important that diabetics are constantly aware of the level of glucose in their blood and closely monitor their diet. For patients who take insulin therapy, it is important to administer insulin in a manner that maintains glucose levels, and accommodates the tendency of glucose concentration in the blood to fluctuate as a result of meals and other activities.</p><p id="p-0006" num="0005">Healthcare professionals, such as doctors or certified diabetes educators (CDEs), offer counseling to diabetic patients regarding managing diet, exercise, lifestyle, and general health. When followed, this counseling can reduce complications associated with diabetes and allow diabetics to lead healthier and happier lives. Often, however, such counseling is only available by appointment, leaving diabetics without simple, quick, and readily available counseling regarding a healthy diabetic lifestyle.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0007" num="0006">For purposes of summarizing the described technology, certain objects and advantages of the described technology are described herein. Not all such objects or advantages may be achieved in any particular embodiment of the described technology. Thus, for example, those skilled in the art will recognize that the described technology may be embodied or carried out in a manner that achieves or optimizes one advantage or group of advantages as taught herein without necessarily achieving other objects or advantages as may be taught or suggested herein.</p><p id="p-0008" num="0007">One embodiment is a method for displaying content items to a user based on selected goals from the user. The method includes performing an initial assessment of a user. The initial assessment includes retrieving at least one of measured patient disease management data and user-inputted patient disease management data from a user database, requesting additional information from the user for determining one or more goals, and receiving the additional information from the user via a user interface. The method also includes recommending a plurality of goals to the user based on the at least one of measured patient disease management data and user-inputted patient disease management data and the additional information from the user received while performing the initial assessment and stored protocols related to disease management retrieved from a content database, receiving a selection of a goal from the plurality of goals from the user via the user interface, receiving goal tracking information indicative of progress toward the selected goal, the goal tracking information including at least one of measured patient disease management data related to the selected goal and user-inputted patient disease management data related to the selected goal, selecting one or more content items from the content database based on at least one of the selected goal and the goal tracking information, and displaying the selected one or more content items to the user via the user interface.</p><p id="p-0009" num="0008">Another embodiment is a goal management system. The system includes a user database including at least one of measured patient disease management data and user-inputted patient disease management data, a content database including content items related to recommended lifestyle choices and protocols for disease management, an interactive user interface configured to display and receive user information, and a memory. The memory has instructions that when run on a processor will perform a method that includes performing an initial assessment of a user. Performing the initial assessment includes retrieving at least one of measured patient disease management data and user-inputted patient disease management data from the user database, requesting additional information from the user for determining one or more goals via the user interface, and receiving the additional information from the user via the user interface. The method also includes recommending a plurality of goals to the user based on the at least one of measured patient disease management data and user-inputted patient disease management data and the additional information from the user received while performing the initial assessment and stored protocols related to disease management retrieved from the content database, receiving a selection of a goal from the plurality of goals from the user via the user interface, receiving goal tracking information indicative of progress toward the selected goal, the goal tracking information including at least one of measured patient disease management data related to the selected goal and user-inputted patient disease management data related to the selected goal, selecting one or more content items from the content database based on at least one of the selected goal and the goal tracking information, and displaying the selected one or more content items to the user via the user interface.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0009">The disclosed aspects will hereinafter be described in conjunction with the appended drawings, provided to illustrate and not to limit the disclosed aspects, wherein like designations denote like elements.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating an integrated disease management (IDM) system according to one embodiment.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an embodiment of a learning management system for an integrated disease management system.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart illustrating an example process for updating content using the learning management system of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating an example process for selecting and displaying content to a user based on a triggering event using the learning management system of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart illustrating an example process for displaying content based on a scheduled event using the learning management system of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating an example workflow process for structured education content.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart illustrating an example process for determining a patient goal or goals in an integrated disease management system.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating an example process for storing patient data in an integrated disease management system.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example process for displaying contextualized insights along with a graphical representation of patient data in an integrated disease management system.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is an example screen capture of a user interface of the integrated disease management system according to one embodiment.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is an example screen capture of the user interface illustrating a voice input function of the user interface.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is an example screen capture of the user interface illustrating a text-based response to a user voice input according to one embodiment.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flow chart illustrating an embodiment of a method for a voice input module of an integrated disease management system.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flow chart illustrating an embodiment of another method for a voice input module of an integrated disease management system.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIGS. <b>15</b> and <b>16</b></figref> are example screen captures of home screens of a user interface of an integrated disease management system according to an embodiment.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIGS. <b>17</b> and <b>18</b></figref> are example screen captures of a learn module of a user interface of an integrated disease management system according to an embodiment.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIGS. <b>19</b>, <b>20</b>, <b>21</b>, and <b>22</b></figref> are example screen captures of a goals module of a user interface of an integrated disease management system according to an embodiment.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIGS. <b>23</b>, <b>24</b>, and <b>25</b></figref> are example screen captures of a logging module of a user interface of an integrated disease management system according to an embodiment.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>26</b></figref> is an example screen capture of a data module of a user interface of an integrated disease management system according to an embodiment.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIGS. <b>27</b>, <b>28</b>, <b>29</b>, <b>30</b>, <b>31</b>, and <b>32</b></figref> are example screen captures of a goals module of a user interface of an integrated disease management system according to an embodiment.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIGS. <b>33</b>, <b>34</b>, <b>35</b>, <b>36</b>, <b>37</b>, <b>38</b>, and <b>39</b></figref> are example screen captures of a goals module of a user interface of an integrated disease management system according to an embodiment.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>40</b></figref> is an example screen capture of a chatbot interface of a user interface of an integrated disease management system according to an embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><heading id="h-0008" level="2">Introduction</heading><p id="p-0033" num="0032">Integrated disease management (IDM) systems and methods are described herein. As will be appreciated by one skilled in the art, there are numerous ways of carrying out the examples, improvements, and arrangements of the IDM systems and methods in accordance with embodiments of the present invention disclosed herein. Although reference will be made to the illustrative embodiments depicted in the drawings and the following descriptions, the embodiments disclosed herein are not meant to be exhaustive of the various alternative designs and embodiments that are encompassed by the disclosed invention, and those skilled in the art will readily appreciate that various modifications may be made, and various combinations can be made, without departing from the invention.</p><p id="p-0034" num="0033">Although described herein primarily in the context of diabetes, the IDM systems or methods detailed below can be used to manage other types of diseases as well. These systems and methods can be used by many types of users, including, but not limited to, diabetic patients, non-diabetic persons, caregivers, and healthcare professionals or healthcare entities such as disease management companies, pharmacies, disease management-related product suppliers, insurers and other payers.</p><p id="p-0035" num="0034">The IDM systems can be beneficial for all types of diabetic patients, including those with type 1 diabetes, type 2 diabetes, or a pre-diabetic condition. The IDM systems described herein can allow users to access readily available counseling information regarding a healthy diabetic lifestyle. The IDM systems can engage users in a manner that encourages them to maintain continuous (e.g., daily, weekly, or monthly) interaction with the IDM system to gain knowledge about diabetes and encourage them to lead an increasingly healthy lifestyle. Diabetes patients who engage with an IDM system such as described herein will often feel more in control of their diabetes management, which, in turn, to better patient outcomes. Often, the more a diabetic patient engages with the IDM system, the more satisfied they will feel with their life with diabetes (providing a desirable feeling of control). The IDM systems can use engagement, behavior design, and behavior change approaches to tailor the experience to each patient. The IDM system experiences can be designed to create more contextual, meaningful education that leads to more self-efficacy.</p><p id="p-0036" num="0035">In an illustrative embodiment, the IDM systems include an interactive interface that is engaging, and that provides a way for users to seek information and support when needed so that they feel more in control of their condition. One or more features of the IDM systems can be based on behavioral science techniques that are designed to modify patient behavior.</p><p id="p-0037" num="0036">In some embodiments, the IDM systems can use uploaded user health information to customize interactions with users. User health information can include data entered via the interactive interface, data uploaded from internet-enabled (&#x201c;smart&#x201d;) devices (such as smart insulin pens or pumps, diabetes monitors, fitness trackers, diet trackers, etc.), and other types of information. The IDM systems can analyze the uploaded health information to provide customized information to the user. The IDM system can be connected to additional outside services. For example, the IDM system can be connected to Apple&#xae; Healthkit&#xae;. Connecting the IDM system to outside services, such as Apple&#xae; Healthkit&#xae; and others, may further strengthen the IDM system's ability to tailor content for the user. For example, accessing Apple&#xae; Healthkit&#xae; may provide the IDM system additional information about the user. Additionally, the IDM system may provide information to the outside services connected to the system.</p><p id="p-0038" num="0000">Example Devices that can Interface with the IDM Systems and Methods</p><p id="p-0039" num="0037"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram that illustrates an integrated disease management (IDM) system <b>100</b> according to one embodiment in the context of diabetes management, as well as several additional devices that can communicate with the IDM system <b>100</b> over a network <b>5</b>. In the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, these additional devices include an internet-enabled user device <b>10</b>, a smart diabetes monitor <b>12</b>, a smart insulin pen <b>14</b>, a smart insulin pump <b>16</b>, and a fitness tracker <b>18</b>. These illustrated devices are provided by example only and other types of devices can also connect to the system <b>100</b> over the network <b>5</b>. In some embodiments, one or more of these devices may be omitted and/or additional devices may be included.</p><p id="p-0040" num="0038">The internet-enabled user device <b>10</b> can be any type of internet-enabled device without limit, including, a smartphone, tablet, laptop, computer, personal digital assistant (PDA), smartwatch, etc. In some instances, the internet-enabled user device <b>10</b> is a mobile device, such as any mobile device known in the art, including, but not limited to, a smartphone, a tablet computer, or any telecommunication device with computing ability, a mobile device connection module, and an adaptable user interface such as, but not limited to a touchscreen. A user typically possesses an internet-enabled user device <b>10</b>, which can be used for various functions, such as sending and receiving phone calls, sending and receiving text messages, and/or browsing the internet.</p><p id="p-0041" num="0039">The smart diabetes monitor <b>12</b> can be any type of internet-enabled diabetes monitor without limit. The smart diabetes monitor <b>12</b> can be configured to measure a user's blood glucose level, such as an electronic blood glucose meter or a continuous glucose monitor (CGM) system. The smart diabetes monitor <b>12</b> may be configured to upload information regarding a user's blood glucose level measurements to the IDM system <b>100</b>. The measured blood glucose level and the time of measurement can be uploaded to the IDM system <b>100</b>. In some embodiments, uploaded blood glucose level measurements are further associated with recently eaten foods and/or physical activity and this information can be uploaded to the IDM system <b>100</b> as well.</p><p id="p-0042" num="0040">In some embodiments, a conventional, non-internet-enabled diabetes monitor can be used with the IDM system. Measurements from the conventional diabetes monitor can be entered or otherwise obtained via the internet-enabled user device <b>10</b> and uploaded to the IDM system <b>100</b> over the network <b>5</b>.</p><p id="p-0043" num="0041">The smart insulin pen <b>14</b> can be any internet-enabled device for self-injection of insulin without limit. Insulin pens typically provide the ability for a user to set and inject a dose of insulin. Accordingly, a user can determine how much insulin they need and set the appropriate dose, then use the pen device to deliver that dose. In an illustrative embodiment, a smart insulin pen <b>14</b> transmits information regarding the timing and dose of an insulin injection to the IDM system <b>100</b> over the network <b>5</b>. In some embodiments, information about uploaded insulin injections is further associated with recently eaten foods or physical activity and this information can be uploaded to the IDM system <b>100</b> as well.</p><p id="p-0044" num="0042">In some embodiments, a conventional, non-internet-enabled insulin pen can be used. Information about insulin injections from conventional insulin pens can be entered or otherwise obtained via the internet-enabled user device <b>10</b> and uploaded to the IDM system <b>100</b> over the network <b>5</b>.</p><p id="p-0045" num="0043">The smart insulin pump <b>16</b> can be any type of insulin pump including those that are internet-connected. The smart insulin pump <b>16</b> can be a traditional insulin pump, a patch pump, or any other type of insulin pump. The smart insulin pump <b>16</b> can upload information regarding the delivery of insulin to the patient to the IDM system <b>100</b> over the network <b>5</b>. In some embodiments, the smart insulin pump <b>16</b> uploads information regarding the rate and quantity of insulin delivered by the pump.</p><p id="p-0046" num="0044">In some embodiments, a conventional insulin pump can be used. Information about insulin delivery by the conventional insulin pump can be entered or otherwise obtained via the internet-enabled user device <b>10</b> and uploaded to the IDM system <b>100</b> over the network <b>5</b>.</p><p id="p-0047" num="0045">The fitness tracker <b>18</b> can be any device which measures (or otherwise obtains) health information (or other types of information) about the user. The fitness tracker <b>18</b> can be a device which measures patient vitals. In an illustrative embodiment, patient vital data includes, but is not limited to, heart rate, blood pressure, temperature, blood oxygen level, and/or blood glucose level. The patient vital data measurement values can be measured using sensors on the fitness tracker <b>18</b>.</p><p id="p-0048" num="0046">The information uploaded to the IDM system <b>100</b> by the internet-enabled device <b>10</b>, the smart diabetes monitor <b>12</b>, the smart insulin pen <b>14</b>, the smart insulin pump <b>16</b>, and/or the fitness tracker <b>18</b> or one or more additional devices can be associated with a particular user. The information can be used to customize interaction between the user and the IDM system <b>100</b>, for example, allowing the IDM system <b>100</b> to provide better answers or recommendations for the user. In some embodiments, the IDM system <b>100</b> analyzes the uploaded information to evaluate the health of the user.</p><p id="p-0049" num="0047">Also shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a web server <b>20</b>. The web server may provide online content <b>22</b>, which can be referred to, referenced by, or otherwise used by the IDM system <b>100</b>. In an illustrative embodiment, the web server <b>20</b> provides a website accessible by users over the network <b>5</b>. The website can include online content <b>22</b> related to diabetes, food choices, exercise, or other topics. As will be described below, the IDM system <b>100</b> can link users to the web server <b>20</b> to access the online content <b>22</b> in response to user questions.</p><p id="p-0050" num="0048">The network <b>5</b> can include any type of communication network without limit, including the internet and/or one or more private networks, as well as wired and/or wireless networks.</p><heading id="h-0009" level="2">Example IDM Systems and Methods</heading><p id="p-0051" num="0049">The IDM system <b>100</b> will now be described with reference to the embodiment illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The IDM system <b>100</b> may be embodied in a single device (e.g., a single computer or server) or distributed across a plurality of devices (e.g., a plurality of computers or servers). The modules or elements of the IDM system <b>100</b> can be embodied in hardware, software, or a combination thereof. The modules or elements may comprise instructions stored in one or more memories and executed by one or more processors.</p><p id="p-0052" num="0050">Each memory can be a RAM memory, a flash memory, a ROM memory, an EPROM memory, an EEPROM memory, a register, a hard disk, a removable disk, a CD-ROM, or any other form of storage medium known in the art. Each of the processors may be a central processing unit (CPU) or other type of hardware processor, such as a general purpose processor, a digital signal processor (DSP), an application specific integrated circuit (ASIC), a field programmable gate array (FPGA) or other programmable logic device, discrete gate or transistor logic, discrete hardware components, or any combination thereof designed to perform the functions described herein. A general purpose processor may be a microprocessor, or in the alternative, the processor may be any conventional processor, controller, microcontroller, or state machine. A processor may also be implemented as a combination of computing devices, for example, a combination of a DSP and a microprocessor, a plurality of microprocessors, one or more microprocessors in conjunction with a DSP core, or any other such configuration. Exemplary memories are coupled to the processors such that the processors can read information from and write information to the memories. In some embodiments, the memories may be integral to the processors. The memories can store an operating system that provides computer program instructions for use by the processors or other elements included in the system in the general administration and operation of the IDM system <b>100</b>.</p><p id="p-0053" num="0051">In the illustrative embodiment shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the IDM system <b>100</b> includes a user interface <b>120</b>, an interactive engine <b>130</b>, a user database <b>140</b>, and a content database <b>150</b>. In some embodiments, one or more of these elements can be omitted. In some embodiments, the IDM system <b>100</b> contains additional elements.</p><p id="p-0054" num="0052">The user database <b>140</b> can comprise a single database or a plurality of databases. In an exemplary embodiment, users of the IDM system <b>100</b> each have an account with the IDM system <b>100</b>. Information regarding user accounts can be stored in the user database <b>140</b>. The user database <b>140</b> can also store additional information associated with the user account. For example, the user database <b>140</b> can store IDM history data <b>142</b> and uploaded health data <b>144</b>.</p><p id="p-0055" num="0053">In an illustrative embodiment, IDM history data <b>142</b> is data generated and stored during a user's previous interactions with the IDM system <b>100</b>. This can include previous inquiries submitted by the user; previous responses provided by the user; user-entered preferences; and/or a log indicating the timing of the user's interactions with the IDM system <b>100</b>, among other things. The IDM system <b>100</b> can automatically add IDM history data <b>142</b> as the user continues to use and/or interact with the IDM system <b>100</b>. The IDM history data <b>142</b> can be used by a predictive analytics module <b>136</b> and a machine learning module <b>138</b> of the interactive engine <b>130</b> (or other modules of the IDM system <b>100</b>) to customize future interactions between the IDM system <b>100</b> and the user. As a user interacts with the IDM system <b>100</b>, the IDM history data <b>142</b> associated with the user's account in the user database <b>140</b> grows, allowing the IDM system <b>100</b> to know the user better, provide better content, and create a more engaging experience. In some embodiments, this increases the efficacy of the IDM system <b>100</b>.</p><p id="p-0056" num="0054">The user database <b>140</b> also stores uploaded health data <b>144</b> associated with a user's account. The uploaded health data <b>144</b> can include the information entered by a user on the internet-enabled user device <b>10</b> or uploaded by the smart diabetes monitor <b>12</b>, smart insulin pen <b>14</b>, smart insulin pump <b>16</b>, and/or fitness tracker <b>18</b> (described above). The uploaded health data <b>144</b> can also include additional information produced by the IDM system <b>100</b> upon analysis of the user's uploaded data. For example, upon analysis of the user's uploaded data, the IDM system may generate health trend information, which can also be stored among the uploaded health data <b>144</b> associated with the user's account in the user database <b>140</b>. In some embodiments, uploaded health data <b>144</b> can include information uploaded or entered by a healthcare provider, such as a doctor, nurse or caregiver. Data that is gathered or measured by connected devices and stored in the user database <b>140</b> may include measured patient disease management data. Data that is entered by the user into the user database <b>140</b> may include user-derived patient disease management data.</p><p id="p-0057" num="0055">In the illustrative embodiment, the IDM system <b>100</b> also includes a content database <b>150</b>. The content database <b>150</b> can be a single database or a plurality of databases. The content database <b>150</b> includes content that is delivered to users during user interaction with the IDM system <b>100</b>. The content can include diabetes education information. In some instances, the content is developed, selected, and/or curated by healthcare professionals, such as doctors or CDEs. The content can be similar to that which is provided by healthcare professionals during in-person counseling sessions. However, content on the IDM system <b>100</b> is available to the user at any time and accessible, for example, on the internet-enabled device <b>10</b>.</p><p id="p-0058" num="0056">In the illustrated embodiment, the content database <b>150</b> includes food content <b>152</b>, diabetes information content <b>154</b>, and activity content <b>156</b>. In an illustrative embodiment, food content <b>152</b> can be developed and curated to encourage users to eat healthy, while still allowing them to eat foods that they enjoy.</p><p id="p-0059" num="0057">Diabetes information content <b>154</b> can be developed and curated to provide answers to common questions asked by diabetic patients. Other types of diabetes information content <b>154</b> can also be included, such as protocols for managing diabetes or other diseases.</p><p id="p-0060" num="0058">Activity content <b>156</b> can be developed and curated to provide information about healthy lifestyle choices and physical activities for diabetics. The activity content <b>156</b> can be developed by healthcare professionals.</p><p id="p-0061" num="0059">Food content <b>152</b>, diabetes information content <b>154</b>, and activity content <b>156</b> are shown by way of example of certain types of content only, and other types of content can be included in addition to or in place of one or more of the illustrated types of content.</p><p id="p-0062" num="0060">The IDM system <b>100</b> can include a user interface <b>120</b> and an interactive engine <b>130</b>. The user interface <b>120</b> can provide an interface by which the IDM system <b>100</b> interacts with or displays information to users. The user interface <b>120</b> can be accessible to the user over the network <b>5</b>. For example, a user can access the user interface <b>120</b> on the internet-enabled user device <b>10</b>. The user interface <b>120</b> can include an interactive interface <b>122</b> and a user data viewer <b>124</b>. In some embodiments, the interactive interface <b>122</b> is an interactive application, such as a smartphone, tablet, or computer application. In some embodiments, the interactive interface <b>122</b> is an interactive website. In a non-limiting example, the interactive interface <b>122</b> is a chatbot.</p><p id="p-0063" num="0061">The interactive interface <b>122</b> relays inputs and outputs between a user and the interactive engine <b>130</b>. The interactive engine <b>130</b> processes inputs and outputs to provide an interactive experience for the user. The interactive engine <b>130</b> also retrieves information from the user database <b>140</b> and the content database <b>150</b>. For example, in interacting with a user, the interactive engine <b>130</b> may access the user database <b>140</b> to obtain the user's IDM history data <b>142</b> and uploaded health data <b>144</b>. In an illustrative embodiment, the interaction with the user is customized based on the user's IDM history data <b>142</b> and uploaded health data <b>144</b>. Similarly, the interactive engine <b>130</b> can retrieve content from the content database <b>150</b>. The interactive engine <b>130</b> can retrieve content from the content database <b>150</b> based on user inputs (e.g., questions, responses, and selections), as well as user information stored in the user database <b>140</b>. Through the interactive interface <b>122</b>, the interactive engine <b>130</b> provides engaging and informative interactions with the user that allows the user to feel in control of his or her diabetes management and gain diabetes education.</p><p id="p-0064" num="0062">The interactive engine <b>130</b> can include a natural language processor <b>132</b>, a response generator <b>134</b>, a predictive analytics module <b>136</b>, and a machine learning module <b>138</b>. In some embodiments, one or more of these elements can be omitted or combined with another element. In some embodiments, the interactive engine <b>130</b> contains additional elements.</p><p id="p-0065" num="0063">The natural language processor <b>132</b> and the response generator <b>134</b> can allow the interactive interface <b>130</b> to provide a simple interaction experience via the interactive interface <b>122</b>. For example, in an illustrative embodiment, the natural language processor <b>132</b> and the response generator <b>134</b> allow a user to have an interactive chat (written or spoken) with the IDM system <b>100</b>.</p><p id="p-0066" num="0064">The natural language processor <b>132</b> can parse user inputs into a machine-understandable format. For example, in an illustrative embodiment, the interactive interface <b>122</b> allows a user to enter a natural language question. The natural language processor <b>132</b> can parse the question such that it can be understood by the interactive engine <b>130</b>. As another embodiment, the interactive interface <b>122</b> can allow the user to speak a question. The natural language processor <b>132</b> can include a voice recognition module that can recognize the spoken question and parse the question such that it can be understood by the interactive engine <b>130</b>.</p><p id="p-0067" num="0065">The response generator <b>134</b> formulates responses to user inputs. The response generator <b>134</b> can receive information from the natural language processor <b>132</b>. In an illustrative embodiment, responses generated by the response generator <b>134</b> include an answer to the user's question. Alternatively, the responses can include requests for additional information from the user. The request for additional information can be provided as a question prompt or one or more options from which the user can select. The response generated by the response generator <b>140</b> can be stylized in the &#x201c;personality&#x201d; of the IDM system <b>100</b> as mentioned above.</p><p id="p-0068" num="0066">The interactive engine <b>130</b> can also include a predictive analytics module <b>136</b> and a machine learning module <b>138</b>. In an illustrative embodiment, the predictive analytics module <b>136</b> uses information in the user database <b>140</b> (such as IDM history data <b>142</b> and uploaded health data <b>144</b>) to predict content that a user will enjoy or that will be beneficial to the user. For example, based on uploaded health data <b>144</b>, the predictive analytics module <b>136</b> can select content to present to the user designed to help the user manage his or her blood sugar.</p><p id="p-0069" num="0067">In an illustrative embodiment, the machine learning module <b>138</b> analyzes information in the user database <b>140</b> (such as IDM history data <b>142</b> and uploaded health data <b>144</b>) to provide inputs which can be communicated to the predictive analytics module <b>126</b>. For example, the machine learning module <b>138</b> can learn about a user based on past interactions with the IDM system <b>100</b> and generate data which is used by the predictive analytics module <b>136</b> to customize content for future interactions. Thus, the more a user interacts with the IDM system <b>100</b>, the more personalized interaction with the system will become. In some instances, personalized interaction increases the efficacy of the IDM system <b>100</b>.</p><p id="p-0070" num="0068">The user interface <b>120</b> can also include a user data viewer <b>124</b>. The user data viewer <b>124</b> can be a portal that allows a user to access information related to their account.</p><p id="p-0071" num="0069"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an embodiment of a learning management system (LMS) <b>2100</b> that is configured to deliver personalized content to a user based on an evolving user profile. The LMS <b>2100</b> can be implemented by the IDM <b>100</b> described above. For example, the LMS <b>2100</b> can be implemented by the interactive engine <b>130</b> described above. In the illustrated embodiment, the LMS <b>2100</b> includes a content management system <b>2102</b>, a rules engine <b>2104</b>, and a content selector <b>2106</b>.</p><p id="p-0072" num="0070">In some embodiments, the LMS <b>2100</b> is driven, at least in part, by rules and user profiling. Over time, the LMS <b>2100</b> builds a user profile for each user. The user profile can be based on initial onboarding questions (e.g., questions asked of the user at the time of initial account creation) as well as additional information learned about the user as the user continues to interact with the LMS <b>2100</b>. In some embodiments, rules applied by the LMS <b>2100</b> can be either explicit or non-explicit (i.e., &#x201c;fuzzy&#x201d;). Non-explicit or fuzzy rules can be based on a distance algorithm that determines a distance value between different types of content and returns content that is within a threshold range. For example, as will be described in more detail below, content in the LMS <b>2100</b> can be labeled with one or more tags. Relations between the tags can be used to determine distances between the content that can be used by the non-explicit of fuzzy rules of the LMS <b>2100</b>.</p><p id="p-0073" num="0071">Interactions between the LMS <b>2100</b> and the user (e.g., dialog and testing) can be dynamic based on user selections and answers. As the user provides additional information to the LMS <b>2100</b>, the LMS <b>2100</b> adds this information to a dynamic user profile. Thus, the LMS <b>2100</b> can be said to involve continuous profiling of the users. As the profile for each user continues to evolve, this leads to new workflows and content that will be made available to the user in a customized and tailored way.</p><p id="p-0074" num="0072">In the LMS <b>2100</b>, the content management system (CMS) <b>2102</b> can store the universe of content items available for all users. The CMS <b>2102</b> can be a database or other method of storing the content. Various types of content items are available, including tutorials, videos, recipes, activities, tips, announcements, insights, follow-ups, praise, quizzes, patient health goals, etc. In some embodiments, the content items in the CMS <b>2102</b> are provided and/or curated by health care professionals or CDEs.</p><p id="p-0075" num="0073">Each content item in the CMS <b>2102</b> can be labeled with one or more tags. The tags can be initially assigned when content is created and added to CMS <b>2102</b>. In some embodiments, tags can be added, modified, or reassigned over time. The tags can be used for labeling and organizing content items within the CMD <b>2102</b>. The tags can also be used for content selection (e.g., deciding which content to make available to which users) as described below.</p><p id="p-0076" num="0074">Example tags can include &#x201c;activity_less,&#x201d; &#x201c;activity_daily,&#x201d; &#x201c;activity_more,&#x201d; &#x201c;activity_no,&#x201d; &#x201c;gender_male,&#x201d; &#x201c;gender_female,&#x201d; &#x201c;gender_noanswer,&#x201d; among many others. These tags can be used to identify content items that may be relevant to users that have profiles that relate to the tags. For example, a user's profile may indicate that they are generally active on a daily basis. As such, content items associated with the &#x201c;activity_daily&#x201d; tag may be deemed to be relevant to the particular user.</p><p id="p-0077" num="0075">As mentioned above, onboarding questions may be initially used to identify which tags are relevant for a user. Then, as the users profile dynamically grows over time, the LMS <b>2100</b> may use the additionally learned information to change the group of tags that may be relevant for a user. In this way, users can be dynamically associated with changing groups of tags to provide an individualized content pool that is tailored to their particular profile.</p><p id="p-0078" num="0076">In some embodiments, tags can be related to other tags. For example, a tag can be associated with an affinity tag. An affinity tag can be a tag related to the initial tag that may also be selected when the initial tag is selected. For example, a recipe can be tagged specifically with a tag indicative of a type of food. For example, a quiche recipe can be tagged with &#x201c;quiche.&#x201d; &#x201c;Eggs&#x201d; may be an affinity tag associated with the tag &#x201c;quiche.&#x201d; Affinity tags can be used to identify content items that are not specifically related to the initial tag. For example, the LMS <b>2100</b> can identify that the user is interested in a quiche recipe, and then can follow up with additional information about other eggs recipes using the affinity tag. This may allow the LMS <b>2100</b> to continue to develop the user's profile in other ways that are not directly related to the initial tag &#x201c;quiche.&#x201d;</p><p id="p-0079" num="0077">In some embodiments, tags can also be associated with anti-affinity tags. Anti-affinity tags can be the opposite of affinity tags. For example, these can be tags that are cannot be selected with another tag. As one example, the user's profile may indicate that they are currently using a non-injection based therapy for treating their diabetes. Anti-affinity tags can be used to ensure that injection-based content (which is irrelevant to this particular user) is not provided.</p><p id="p-0080" num="0078">Content items can be tagged with one or more tags. For example, a content item can be associated, with one, two, three, four, five, six, or more content tags. Tags themselves can be associated with other tags using affinity and anti-affinity tags as described above.</p><p id="p-0081" num="0079">In some embodiments, content items can be organized into clusters. For example, based on the tags, each content item can be part of a cluster. Each cluster can use distance rules to determine the distance to every other cluster in the CMS <b>2102</b>. Content recommendations can begin with the user's closest cluster and head outward in a simple fashion. For example, after recommending content items in the user's closest cluster, the LMS <b>2100</b> can move to the next closest cluster, and so on. This can ensure that the content is presented to the user beginning with the most relevant content, and then branching outward to continue to develop the user's profile.</p><p id="p-0082" num="0080">There are several ways that distances can be calculated between content items or between data clusters. For example, content items with matching tags can be determined to have a distance of 0 between them. Content items with affinity tag matches can be determined to have a distance of 1 between them. For example, tags A and B can be determined to be affinity tags. Thus, a content item tagged with A and a content item tagged with B can be determined to have a distance of 1 between them. Content items with anti-affinity tag matches can be determined to have a distance of 1000 between them. For example, tags A and C can be determined to be anti-affinity tags. Thus, a content item tagged with A and a content item tagged with C can be determined to have a distance of the 1000 between them. Content items that include tags that are associated with matching affinity tags can be determined to have a distance of 10 between them. For example, tag A can be an affinity tag of D, and tag D can be an affinity tag of E. Thus, a content item tagged with A and a content item tagged with E can be determined to have a distance of 10 between them. As the relationships between affinity tags becomes more distant, the determined distance between tags can increase. For example, assume A and G are affinity tags, I and K are affinity tags, and G and K are affinity tags. A and I are distantly related through several affinity tag connections. Thus, a distance between content tagged with A and content tagged with I can be 25, for example. In some embodiments, content tagged with wholly unrelated tags can be determined to have a distance of 50. In some embodiments, distance is determined by taking the average for all pairwise distances between any two items and that is the distance between the two items. In some embodiments, if the tags are an exact match between two items taking a pairwise comparison is not necessary and the distance is determined to be 0. The distance calculation methods described in this paragraph are provided by way of example only, and other methods for determining distances between tagged content items are possible.</p><p id="p-0083" num="0081">The rules engine <b>2104</b> may be configured to maintain a personalized content pool for each individual user. The content pool comprises a subset of content items from the CMS <b>2102</b> that are available for display to a particular user. Items in the user's content pool are chosen based on rules, tags, and user's profile. Thus, while the CMS <b>2102</b> includes the universe of content which can be available to all users, the rules engine <b>2104</b> selects particular content from the CMS <b>2102</b> for each individual user based on the user's profile and the content tags. As described below, the content can include patient goals, and the rules engine <b>2104</b> can determine particular goals from the CMS <b>2102</b> for the user.</p><p id="p-0084" num="0082">In some embodiments, the rules can be scheduled rules or triggered rules. Scheduled rules can be rules that are scheduled to run at a particular time. For example, a scheduled rule may be: do X every Sunday at 6:15 PM, or do Y every data at 7 AM. In contrast with scheduled rules, triggered rules are configured to occur do to a particular event occurring for the user. For example, a triggered rule may be: when X occurs, do Y. Triggered rules can be triggered by many different types of events. For example, triggers can include: BGM events; fasting BGM Events; pre-prandial BGM event; post-prandial BGM events; insulin events; basal insulin events; bolus insulin events; study start events; next appointment events; meal events; step events; mood events; communication events; chat message sent events; chat message received events; content updated events; profile updated events; content viewed events; content expired events; launch events; etc.</p><p id="p-0085" num="0083">Rules can also include an indication of how content items can be sent/displayed to the user. For example, some rules can specify that a content item should be immediately sent or displayed to the user. Content can be sent to the user the text (SMS), push notification, email, or other communication methods. Other rules can specify that the content item should be added to the content pool for possible display to the user later. For example, a rule can indicate that 15 new recipes should be added to the user's content pool. As will be discussed below, the content selector <b>2104</b> can be used to select and display individual content items from the user's content pool to the user.</p><p id="p-0086" num="0084">Some rules can identify a particular item of content. For example, a rule may specify a particular ID of a content item. This would be an example of an explicit rule. In other cases, a rule may not explicitly identify a particular item of content. For example, a rule may specify a content type generally (e.g., recipes) and then may provide content based on a distance-matching algorithm as described above. This would be an example of non-explicit or fuzzy rule. In this case, content is selected for the user based on the user's profile and the distance-matching algorithm.</p><p id="p-0087" num="0085">In some embodiments, rules can include a specified priority. For example, the rules engine <b>2104</b> may buffer incoming changes for a short period of time (e.g., seconds), and multiple rules can fire based on the same trigger. Thus, for each content type, only one rule may be allowed to generate output for each firing run (per user). To control which rule takes priority in the case, rules can include priorities, and rules with higher priorities will trump rules with lower priorities. Priority values can be specified in a number of ways. For example, priority values can range from 1 to 2100, or general priority categories (e.g., Low, Medium, High) can be used.</p><p id="p-0088" num="0086">Similarly, certain rules can be set to supersede other rules. For example, a supersedes indicator followed by a rule identifier can express the concept that one rule will always take precedence over another (and remove existing content from the pool from the superseded rule). Rules can include additional limits on how often a rule can be executed. Some limits can be set on a per day, per week, per month, or per user basis. In some embodiments, rules can further include additional conditions that must be met for the rule to be executed. For example, rules can be configured with when clauses that cause the rule to be executed only when specified user state conditions are met. For example, a rule can include a when clause that causes the rule to only be executed when the BGM measurement is within a normal range. Other examples can include: when last 1 BGM&#x3e;200; when last 3 BGM&#x3e;280; when BGM count&#x3c;1 in last 5 days; when insulin count&#x3e;3 in last 12 hours; and many others. In some embodiments, rules can include optional active or activation clauses. Activation clauses can put temporal boundaries on rules. These may be useful when have patient appointments or want to schedule something relative to another date. Finally, rules can also optionally include an expiration term. This can limit how long a particular content item remains in the user's content pool.</p><p id="p-0089" num="0087">Several example rules that can be executed by the rule engine <b>2104</b> will now be described. These rules are provided by way of non-limiting example, and many other types of rules are possible.</p><p id="p-0090" num="0088">In a first example, a rule may state:</p><p id="p-0091" num="0089">Rule Announcement</p><p id="p-0092" num="0090">Triggered By Content Update</p><p id="p-0093" num="0091">Add up to 5 Announcement</p><p id="p-0094" num="0092">Do Not Reuse</p><p id="p-0095" num="0093">Priority 2100</p><p id="p-0096" num="0094">This rule queues up to 5 announcements that haven't been seen by the user with highest priority. &#x2018;Do Not Reuse&#x2019; indicates that the rule engine <b>2104</b> not re-add previously viewed content for a user. In some embodiments, if not specified, the default is to reuse content. When executed the rule will query for all announcements sorted by newest, and add up to five to the user's pool.</p><p id="p-0097" num="0095">As another example, a rule may state:</p><p id="p-0098" num="0096">Rule InitRecipes</p><p id="p-0099" num="0097">Triggered By Launch</p><p id="p-0100" num="0098">Add up to 15 recipe</p><p id="p-0101" num="0099">With Max Distance 200</p><p id="p-0102" num="0100">This rule may be executed each time the user launches or change their profile and is configured to add recipes to the queue up to 15 total recipes (not 15 new recipes). The term &#x201c;With Max Distance&#x201d; specifies how &#x2018;different&#x2019; content can be and still be added to the User's Pool. The higher the value, the less appropriate content can be. This allows implementations of non-explicit or fuzzy rules as mentioned above.</p><p id="p-0103" num="0101">As another two rules may state:</p><p id="p-0104" num="0102">Rule ONEBGHIGH</p><p id="p-0105" num="0103">Triggered By BGM</p><p id="p-0106" num="0104">Add insights</p><p id="p-0107" num="0105">When Last BGM&#x3e;200</p><p id="p-0108" num="0106">Contentld: Z3WbRWKjkcAkwAWMMq42O</p><p id="p-0109" num="0107">Priority 95</p><p id="p-0110" num="0108">Limit 1 per 7 days</p><p id="p-0111" num="0109">Expire in 24 hours</p><p id="p-0112" num="0110">Rule THREEBGHIGH</p><p id="p-0113" num="0111">Triggered By BGM</p><p id="p-0114" num="0112">Add insights</p><p id="p-0115" num="0113">When Last3 BGM&#x3e;200</p><p id="p-0116" num="0114">ContentId: Z3WbRWKjkcAkwAWMMq42O</p><p id="p-0117" num="0115">Priority 95</p><p id="p-0118" num="0116">Supersedes ONEBGHIGH</p><p id="p-0119" num="0117">Limit 1 per 7 days</p><p id="p-0120" num="0118">Expire in 24 hours</p><p id="p-0121" num="0119">These rules add specific content items when triggered by certain BGM measurements. Thus, these rules queue the BGM high insight max once a week on high BG measurement. Rule THREEBGHIGH supersedes Rule ONEBGHIGH because it includes &#x201c;Supersedes ONEBGHIGH.&#x201d; Thus, ONEBGHIGH cannot be executed if THREEBGHIGH is already queued.</p><p id="p-0122" num="0120">As another example, a rule may state:</p><p id="p-0123" num="0121">Rule FollowUpRecipe</p><p id="p-0124" num="0122">Queue FollowUp</p><p id="p-0125" num="0123">Triggered By recipe Viewed</p><p id="p-0126" num="0124">Expire in 15 days</p><p id="p-0127" num="0125">Priority 97</p><p id="p-0128" num="0126">This rule queues a follow up after a recipe has been viewed. This may allow the LMS <b>2100</b> to continue to develop the user's profile by requesting additional information about whether a user liked a recipe after trying the recipe. This additional information can be used to tailor additional content to the user in the future. These rules may be stored in a memory of the system as executable instructions and then executed by a processor that is configured to run the rules from executable instructions.</p><p id="p-0129" num="0127">As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the LMS <b>2100</b> also includes a content selector <b>2106</b>. The content selector <b>2106</b> determines which content from the content pool to display to the user. Selections can be made based on triggering/reactive events (described with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>) or scheduled events (described with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>). Thus, the content selector <b>2106</b> determines when and how to display individual content items from the content pool to the user. In the case of patient goals, the content selector <b>2106</b> can identify a particular subset of patient goals for display to the user. Additional examples of triggers and non-limiting examples of corresponding reactive events are provided in Table 1.</p><p id="p-0130" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="133pt" align="left"/><colspec colname="2" colwidth="126pt" align="left"/><thead><row><entry namest="1" nameend="2" rowsep="1">TABLE 1</entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row><row><entry>Example Trigger</entry><entry>Example Reactive Event</entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>Number of steps has increased by 1,000</entry><entry>Conversation with direction to</entry></row><row><entry>steps over 3 consecutive days</entry><entry>personalized article content</entry></row><row><entry>Number of steps has decreased by 500</entry><entry>Conversation with recommendation</entry></row><row><entry>steps over 3 consecutive days</entry><entry>personalized goal setting</entry></row><row><entry>Connected to application such as Apple</entry><entry>Conversation with recommendation</entry></row><row><entry>Health</entry><entry>personalized goal setting</entry></row><row><entry>Took 5,000 steps 3 times in a 7-day period</entry><entry>Congratulatory message with</entry></row><row><entry/><entry>recommendation for personalized goal</entry></row><row><entry/><entry>setting</entry></row><row><entry>BG &#x3c; 70 mg/dl logged and an increase of</entry><entry>Conversation with direction to</entry></row><row><entry>500 steps</entry><entry>personalized article content</entry></row><row><entry>Increased activity, BG in desired range</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>Decreased activity, increased blood</entry><entry>Conversation with direction to</entry></row><row><entry>glucose</entry><entry>personalized article content</entry></row><row><entry>BG high, corresponding insulin not logged</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>BG &#x26; insulin both logged 3 days in a row</entry><entry>Congratulatory message with</entry></row><row><entry/><entry>recommendation for personalized</entry></row><row><entry/><entry>goal setting</entry></row><row><entry>Restless sleep, BG &#x3e;180 mg/dl logged</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>2 nights &#x3c; 2 waking with BG in range after</entry><entry>Congratulatory message with direction </entry></row><row><entry>restless sleep, &#x3e;180 mg/dl</entry><entry>to personalized article content</entry></row><row><entry>2 consecutive breakfast blood glucose</entry><entry>Conversation with direction to</entry></row><row><entry>readings &#x3e; 180 mg/dl</entry><entry>personalized article content</entry></row><row><entry>2 non-morning BG readings &#x3e; 180 mg/dl</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>2 consecutive dinner BG readings &#x3e; 180</entry><entry>Conversation with direction to</entry></row><row><entry>mg/dl</entry><entry>personalized article content</entry></row><row><entry>3 consecutive bedtime BG readings &#x3e; 180</entry><entry>Conversation with direction to</entry></row><row><entry>mg/dl</entry><entry>personalized article content</entry></row><row><entry>BG &#x3c; 70 mg/dl</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>BG &#x3c; 70 mg/dl, twice in a 7 day period</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>BG &#x3c; 80 mg/dl in the morning</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>BG &#x3c; 80 mg/dl at lunch time</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>BG &#x3c; 80 mg/dl at dinner time</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>BG &#x3c; 80 mg/dl at bedtime</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>Blood glucose readings two days in a row</entry><entry>Conversation with direction to</entry></row><row><entry>are between 80-180 mg/dl, following one</entry><entry>personalized article content</entry></row><row><entry>to two readings over 180mg/dl</entry><entry/></row><row><entry>Did not log blood glucose at lunch, after</entry><entry>Conversation with direction to</entry></row><row><entry>logging last 3 days</entry><entry>personalized article content</entry></row><row><entry>Did not log blood glucose that day, after</entry><entry>Conversation with direction to</entry></row><row><entry>logging last 2 days</entry><entry>personalized article content</entry></row><row><entry>Did not log blood glucose at bedtime, after</entry><entry>Conversation with direction to</entry></row><row><entry>logging last 3 days</entry><entry>personalized article content</entry></row><row><entry>BG logged 3 days in a row</entry><entry>Congratulatory message with</entry></row><row><entry/><entry>recommendation for personalized goal</entry></row><row><entry/><entry>setting</entry></row><row><entry>Connected to blood glucose meter, such as</entry><entry>Congratulatory message with direction to</entry></row><row><entry>Accu-Chek meter</entry><entry>personalized article content and/or</entry></row><row><entry/><entry>instructions related to use of meter with</entry></row><row><entry/><entry>App</entry></row><row><entry>Blood glucose readings three days in a row</entry><entry>Conversation with direction to</entry></row><row><entry>include ones that are lower than 80 or</entry><entry>personalized article content</entry></row><row><entry>higher than 180 mg/dl</entry><entry/></row><row><entry>Second BG &#x3e; 180 mg/dl</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content and/or</entry></row><row><entry/><entry>instructions</entry></row><row><entry>BG &#x3e;180 mg/dl more than one time in 7</entry><entry>Conversation with direction to</entry></row><row><entry>days</entry><entry>personalized article content</entry></row><row><entry>BG &#x3e;180 mg/dl 3&#xd7; in 7 days</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>Asked 3+ questions over 3 consecutive</entry><entry>Conversation with direction to</entry></row><row><entry>days</entry><entry>personalized article content</entry></row><row><entry>Read 3+ articles over 3 consecutive days</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>Open the app and engaged (chat, read, log)</entry><entry>Congratulatory and request for review</entry></row><row><entry>at least once consecutively over 5 days</entry><entry/></row><row><entry>Read article twice (example: &#x201c;Fast Food</entry><entry>Conversation with question to ask user if</entry></row><row><entry>Options for People with Diabetes&#x201d; article&#x201d;)</entry><entry>they'd like to read another article (example:</entry></row><row><entry/><entry>&#x201c;10 Tips for Healthier Fast Food Choices&#x201d;)</entry></row><row><entry>Read a recipe</entry><entry>Conversation with direction to more recipe</entry></row><row><entry/><entry>or food content x hours after trigger</entry></row><row><entry>Insulin dose was not logged in that day,</entry><entry>Conversation with direction to</entry></row><row><entry>after logging for the last 2 days</entry><entry>personalized article content</entry></row><row><entry>Insulin dose was not logged in for lunch,</entry><entry>Conversation with direction to</entry></row><row><entry>after logging for the last 2 days</entry><entry>personalized article content</entry></row><row><entry>Insulin dose was not logged in for, bedtime</entry><entry>Conversation with direction to</entry></row><row><entry>after logging for the last 2 days</entry><entry>personalized article content</entry></row><row><entry>Insulin logged 3 days in a row</entry><entry>Congratulatory message with</entry></row><row><entry/><entry>recommendation for personalized goal</entry></row><row><entry/><entry>setting</entry></row><row><entry>Change in dose leads to low BG</entry><entry>Conversation with instruction to consult</entry></row><row><entry/><entry>care provider</entry></row><row><entry>Change in insulin brand</entry><entry>Conversation with question to user asking</entry></row><row><entry/><entry>if they meant to select a change in brand;</entry></row><row><entry/><entry>continued conversation with questions to</entry></row><row><entry/><entry>understand why there was change</entry></row><row><entry>Addition of bolus insulin</entry><entry>Conversation to confirm addition of bolus</entry></row><row><entry/><entry>insulin, and, following receipt of</entry></row><row><entry/><entry>confirmation, direction to article, such as</entry></row><row><entry/><entry>&#x201c;What is Basal-Bolus Insulin Therapy&#x201d;</entry></row><row><entry/><entry>article</entry></row><row><entry>1st time logging insulin</entry><entry>Conversation with question to user asking</entry></row><row><entry/><entry>if they're new to insulin, and if so, direction</entry></row><row><entry/><entry>to article, such as &#x201c;Starting Insulin? Here's</entry></row><row><entry/><entry>What You Need to Know&#x201d; article</entry></row><row><entry>User exported data report</entry><entry>Conversation with questions to user</entry></row><row><entry/><entry>regarding identity of recipient of report</entry></row><row><entry/><entry>and/or content of report 24 hours after</entry></row><row><entry/><entry>trigger</entry></row><row><entry>Waking up 2 or more times during the night</entry><entry>Conversation with direction to</entry></row><row><entry/><entry>personalized article content</entry></row><row><entry>Blood glucose readings two days in a row</entry><entry>Conversation with direction to</entry></row><row><entry>are between 80-180 mg/dl, following one</entry><entry>personalized article content</entry></row><row><entry>to two readings over 180mg/dl</entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0131" num="0128">The relationships between the example triggers and example reactive events in Table 1 are for illustrative purposes only. It is contemplated that the example triggers of Table 1 may be associated with reactive events different from, or in addition to, the example reactive events listed in Table 1. The &#x201c;conversations&#x201d; and/or &#x201c;messages&#x201d; described in the example reactive events may be performed using any content display or communication method described herein. For example, the &#x201c;conversations&#x201d; and/or &#x201c;messages&#x201d; can be displayed in the app or provided via text message, email, or some other communication method. As described above, in some embodiments, rules such as those described in Table 1 can include a specified priority. Certain rules can supersede other rules. In some embodiments, certain rules may be designed to repeat automatically or to repeat after a certain period of time. Certain rules may be designed to repeat a finite number of times or to occur only once.</p><p id="p-0132" num="0129">As described above, interactions (e.g., dialog and testing) between the LMS <b>2100</b> and the user can be dynamic based on user selections and answers. For example, in Table 1, the reactive event for the trigger &#x201c;BG&#x3c;70 mg/dl&#x201d; is &#x201c;Conversation with direction to personalized article content.&#x201d; The conversation with the user, for example using a chatbot interface, can result in the IDM providing a recommendation for an article about exercise, a recommendation for a recipe, or an option of either an article about exercise or a recipe, depending on the user's selections, answers, and/or user profile.</p><p id="p-0133" num="0130">In some embodiments, rules may be assigned to a particular user based on a number of factors including region, diabetes type, treatment type, or other information in the user's profile. In some embodiments, certain rules can be activated or deactivated by the user.</p><p id="p-0134" num="0131">In some embodiments, a trigger can be activated when a user scans a machine-identifiable code such as a barcode or QR code using a device connected to the IDM, such a camera, optical scanner, or barcode reader. In some embodiments, the user device <b>10</b> can include a camera configured to capture and read a machine-identifiable code. In some embodiments, scanning of a machine-identifiable code, for example on a website, product, or packaging, can initiate a reactive event in which new content is shown to or made available to the user, the user is navigated to a different part of the IDM, or a different chat dialogue is presented to the user. For example, scanning a code on an insulin pen, such as the BD Nano PRO&#x2122; from Becton Dickinson, or the packaging of the insulin pen can make content related to the insulin pen, such as instructions for use or educational content related to insulin delivery, available to the user. As another example, scanning a machine-identifiable code on a package for pen needles, such as a BD pen needle box, can provide access to educational content related to injection technique, such as the BD and Mc&#x2122; interface from Becton Dickinson. In some embodiments, the IDM may store such content in a memory prior to scanning of the machine-identifiable code, but restrict the user from accessing the content until the machine-identifiable code is scanned.</p><p id="p-0135" num="0132"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart illustrating an example process or method <b>2200</b> for updating content in an individual user's content pool using the learning management system <b>2100</b>. The method <b>2200</b> can begin at block <b>2211</b> at which content in the CMS <b>2102</b> is added or modified. Updating or modifying content in the CMS <b>2102</b> can trigger the LMS <b>2100</b> to update the content pool for each user so that the new or modified content can be disseminated to the users.</p><p id="p-0136" num="0133">The method <b>2200</b> can move to block <b>2212</b> at which, for each user, the content pool is updated using with rules engine <b>2104</b>. At this step, the rules are applied for each user, taking into consideration each user's dynamically customized profile. This selects contents items from the CMS <b>2102</b> and adds them to each user's content pool. In some embodiments, the content pool for each user is customized or tailored specifically for them based on the user's dynamically customized profile, the tags associated with the content items, and the distance algorithm described above.</p><p id="p-0137" num="0134">Next, the method <b>2200</b> can move to block <b>2213</b>, at which, for each user, the user's content pool is synced to the application. For example, the content can be downloaded (or otherwise linked) onto the user's mobile device. In some instances, the content is not yet displayed to the user. Rather, at block <b>2213</b>, the content pool is merely made available for future display to the user.</p><p id="p-0138" num="0135">Finally, at block <b>2214</b>, the content selector <b>2106</b> selects and displays content to the user when scheduled or triggered. That is, from among the content items in the content pool, the content selector <b>2104</b> chooses and displays content information to the user.</p><p id="p-0139" num="0136"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating an example process <b>2300</b> for selecting and displaying one or more content items to a user based on a triggering event using the learning management system <b>2100</b>. The method <b>2321</b> may begin at block <b>2321</b> when a triggering event occurs. Several example of triggering events have been described above. As one example, the user may send a message using the system requesting a pizza recipe. At block <b>2322</b>, the content selector <b>2322</b> is executed to select a content item from the content pool. Continuing with the pizza recipe example, the content selector may determine if the content pool contains a pizza recipe. Because the content pool has been previously updated and customized for the specific user, the likelihood that a pizza recipe that the user will like is increased. If the content pool does not include a pizza recipe, the content selector may return the most relevant content based on the content tags and the distance-matching algorithm.</p><p id="p-0140" num="0137">At block <b>2323</b>, the returned content item is displayed to the user. For example, the content item can be displayed in the app or provided via text message, email, or some other communication method. At block <b>2324</b>, information about the displayed content is used to update the user's profile. The content may be removed from the user's pool as already having been displayed. One or more follow-ups with the user regarding the content may be set. At block <b>2325</b>, the updated user's profile is used to update the user's content pool with the rules engine <b>2325</b>. That is, based on this interaction, the content pool available to the user for future interactions may be dynamically adjusted.</p><p id="p-0141" num="0138"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart illustrating an example process or method <b>2400</b> for displaying content based on a scheduled event using the learning management system <b>2100</b>. In this example, a scheduled event occurs at block <b>2431</b>. Content associated with the scheduled event is displayed to the user at block <b>2432</b>. Then, similar to the method <b>2300</b>, the user's profile can be updated (block <b>2433</b>) and the user's content pool can be updated (block <b>2434</b>) based on the interaction.</p><p id="p-0142" num="0139">In some embodiments, the LMS <b>2100</b> described above can be used to provide structured education content and workflows to users. The LMS <b>2100</b> may guide the user through the content in manner designed to facilitate understanding and learning. In this example, the structured education content is focused on injection therapy. The content can be tagged in the CMS <b>2102</b> with an &#x201c;injection therapy&#x201d; tag. Further, the IDM can personalize the content to the user's emotional and functional need. For example, the content can be dynamic to the particular patient's type of injection therapy. This can ensure the patient's comfort and understanding of the subject and support the patient at home as if they were sitting with a CDE or other healthcare professional.</p><p id="p-0143" num="0140">In some embodiments, content can be divided into different topics, with different subjects available under each topic. Again, content tags can be used to identify topics and subjects. In some embodiments, the content can be delivered to the user as text or video tutorials. After completing a topic plan, the user's comfort level can be assessed. If the user is comfortable with the material, the LMS will advance to additional material. If not, the content is offered again. In some embodiments, upon completion of the topic, the user receives a summary of the subject matter.</p><p id="p-0144" num="0141">In the context of injection therapy, example topic plans can include overcoming mental hurdles, an introduction to injection mechanics, how to injection (segmented for syringe and pen users), injection best practices, learning how to deal with hypos/hypers, advanced injection therapy, understanding diabetes, and blood glucose tracking and best practices.</p><p id="p-0145" num="0142"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating an example workflow process for structured education content. Rules in the LMS <b>2100</b> may guide the user through the workflow process to ensure comfort and mastery of the material. As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the workflow begins after the user has been provided an initial tutorial or information on learning how to keep track of injections. The user is given selectable options to assess his or her comfort level. For example, in the illustrated embodiment, the options include, &#x201c;I've got what I need and can start,&#x201d; &#x201c;Confident that I know how to start,&#x201d; &#x201c;Worried that I still don't know,&#x201d; and &#x201c;uncertain about injecting any way.&#x201d; Depending on the user's selection, the user is directed to additional content or to review the previous content to gain confidence and mastery. As the user progresses through the workflow, the user's profile can be continually and dynamically updated to provide additional customization and tailored content for future interactions.</p><p id="p-0146" num="0143">In some embodiments, an IDM, such as the IDM <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, can include a voice input module, which can for example, be part of the user interface <b>120</b>. The voice input module may be configured to allow a user to input data into the system by speaking. An example screen <b>3200</b>B of an interactive interface that includes a voice input module is shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, which is described in more detail below.</p><p id="p-0147" num="0144">Example use of the system <b>100</b> will now be described with reference to the example screens shown in <figref idref="DRAWINGS">FIGS. <b>10</b>, <b>11</b>, and <b>12</b></figref>. <figref idref="DRAWINGS">FIG. <b>10</b></figref> is an example screen <b>3100</b> of the interactive interface <b>122</b> of the IDM system <b>100</b> according to one embodiment. As illustrated, the screen <b>3100</b> represents a home screen or initial screen for the interactive interface <b>122</b>. This screen <b>3100</b> can be the first to be displayed to the user upon accessing the system <b>100</b>.</p><p id="p-0148" num="0145">In this example, the screen <b>3100</b> includes an insight portion <b>3102</b>. The insight portion <b>3102</b> can be configured to display insights to the user that are customized based on the user's previous interactions to the system <b>100</b>. In some embodiments, the insights can include conversations or messages such as those described in the Example Reactive Events of Table 1. The insight portion <b>3102</b> can include user selectable options <b>3104</b> that allow a user to indicate whether he or she wishes to learn more about the offered insight. For example, the user selectable element <b>3104</b> can include a &#x201c;Not Now&#x201d; or a &#x201c;Tell Me More&#x201d; graphical indicia which may be selectable by the user. Pressing the &#x201c;Tell Me More&#x201d; graphical indicia would bring up additional data on the displayed subject, while selecting the &#x201c;Not Now&#x201d; graphical indicia may clear the screen. The additional data can include additional conversations, messages, or articles. In some embodiments, the &#x201c;Tell Me More&#x201d; graphical indicia can prompt the user to set personalized goals, for example, using the goal workflow described herein.</p><p id="p-0149" num="0146">The screen <b>3100</b> also provides user-selectable options <b>3106</b> in the form of swipe cards that flow laterally from side to side on the displayed GUI and that allow a user to access content that has been selected for the user. Each card may display content that can include diabetes related information that has been customized for the user. Depressing each card on the touchscreen may activate the element <b>3106</b> and allow the users to move the cards from right to left, choosing which cards to become active on the display. In some embodiments, the cards show content which comprises customized learning workflows as described in the above.</p><p id="p-0150" num="0147">As shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the screen <b>3100</b> also includes a voice input option <b>3110</b> located at the lower, center, portion of the GUI. A user may select the voice input option <b>3110</b> to input user voice data into the system <b>100</b>. Upon selecting the voice input option <b>3110</b>, screen <b>3200</b>B of <figref idref="DRAWINGS">FIG. <b>11</b></figref> may be displayed, and the system <b>100</b> may be configured to record user voice data, as will be described below. Entering user voice data may comprise, for example, recording an audio signal using a microphone on a user device. The audio signal may be processed by the natural language processor <b>132</b> so that spoken commands or questions contained therein are converted to a machine-understandable format for further processing by the system <b>100</b>.</p><p id="p-0151" num="0148">The screen <b>3100</b> in <figref idref="DRAWINGS">FIG. <b>10</b></figref> also includes a text-based input option <b>3112</b>. The user may select the text-based user input option <b>3112</b> to input text-based user data into the system <b>100</b>. Text-based user data may comprise written data provided by the user. For example, a user can input written data using a keyboard on a user device. Upon selecting the text-based user input option <b>3112</b>, screen <b>3300</b> of <figref idref="DRAWINGS">FIG. <b>12</b></figref> may be displayed, and the system <b>100</b> may be configured to receive text-based user input, as will be described below. Text-based user input can processed by the natural language processor <b>132</b> so that commands or questions contained therein can be converted to a machine-understandable format for further processing by the system <b>100</b>.</p><p id="p-0152" num="0149">The screen <b>3100</b> also includes a blood glucose user input option <b>3114</b>. The user may select the blood glucose user input option <b>3114</b> to input a blood glucose reading into the system. The screen <b>3100</b> also includes a data viewer user option <b>3116</b>. The user may select the data viewer option <b>3116</b> to view user data, such as blood glucose data. In some embodiments, the data viewer user option <b>3116</b> may be used to access a screen <b>3400</b>, as shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, which displays blood glucose data.</p><p id="p-0153" num="0150"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is an example screen <b>3200</b>B of the interactive interface <b>122</b> illustrating a voice input function of the user interface <b>3020</b>. In some embodiments, the voice input function is access by selecting the voice input option <b>3110</b> on the screen <b>3100</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>. In some embodiments, the voice input function is configured to receive user voice input. The user voice input can be passed to the natural language processor <b>132</b> and response generator <b>134</b> of the interactive engine <b>130</b> as mentioned above. The natural language processor <b>132</b> and response generator <b>134</b> can parse the user voice input and generate responses that can be customized for the user.</p><p id="p-0154" num="0151">As shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the screen <b>3200</b>B can be configured to provide a visual indication that audio information is being recorded. For example, wave line <b>3221</b> can move in response to the audio signal being measured by a microphone of the user device to provide a visual indication of the recording. Similarly, in some embodiments, the voice input option <b>3110</b> can pulsate as an indication that audio information is being recorded.</p><p id="p-0155" num="0152">In some embodiments, the voice input function can allow users to log data into the system <b>100</b>. Such data can be stored as uploaded health data <b>144</b>, for example. As one example, the user can select the voice input option <b>3110</b> and speak a command to log a blood glucose measurement. For example, the user can say &#x201c;Log blood glucose 3400.&#x201d; The natural language processor <b>132</b> can parse this input and understand that the user is entering a blood glucose measurement. The system <b>100</b> can then process the request, storing the blood glucose reading as user health data <b>144</b>. This data will then available to the system <b>100</b> to further customize future interactions.</p><p id="p-0156" num="0153">The voice input function can also be used to input and log other types of data as well. For example, a user can input data related to insulin injections, foods eaten, exercise performed, mood, stress, etc. In another example, the user can input data related to injection site location for insulin pens, patches, and continuous glucose monitoring devices. Injection site location data can be tracked so that the user can effectively rotate injection site location.</p><p id="p-0157" num="0154">In some embodiments, the system <b>100</b> associates the voice input data with additional information known by the system <b>100</b>, such as, for example, the date and time. This can facilitate tracking of the data.</p><p id="p-0158" num="0155"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is an example screen <b>3300</b> of the interactive interface <b>122</b> illustrating a text-based response to a user voice input according to one embodiment. In some embodiments, after the user provides a user voice input, the interactive interface <b>122</b> can enter the text-based response screen <b>3300</b> to continue the interaction.</p><p id="p-0159" num="0156">In some embodiments, the screen <b>3300</b> can show, for example, data <b>3332</b> from previous interactions. The screen <b>3300</b> can also show information related to the currently provided user voice data. For example, as illustrated, the screen <b>3300</b> shows a transcription <b>3334</b> of the provided user voice data. Continuing the blood glucose logging example described above, the transcription <b>3334</b> indicates that the user spoke &#x201c;Log BG 3400.&#x201d;</p><p id="p-0160" num="0157">The screen <b>3300</b> can also include a text-based response <b>3336</b> to the input user voice data. In the illustrated example, response <b>3336</b> states: &#x201c;Would you like to log a BG level of <b>3400</b> on 8/20/2018 at 1:29 PM?&#x201d; Thus, response <b>3336</b> can provide a confirmation of the provided user voice data. In some embodiments, the response <b>3336</b> can include other information. For example, the response <b>3336</b> can request additional information from the user.</p><p id="p-0161" num="0158">The screen <b>3300</b> can also include user-selectable options <b>3338</b>. The user-selectable options <b>3338</b> can be related to the response <b>3336</b>. For example, as illustrated, user-selectable options <b>3338</b> of &#x201c;Yes, that is correct&#x201d; and &#x201c;No, that is wrong&#x201d; allow the user to quickly verify the response <b>3336</b>. Providing user-selectable options <b>3338</b> may streamline the interaction by providing the user with possible options that can be quickly and easily selected. The user-selectable options are described in more detail further below with reference to <figref idref="DRAWINGS">FIG. <b>13</b></figref>.</p><p id="p-0162" num="0159">Finally, as shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, upon selecting the user-selectable option <b>238</b> &#x201c;Yes, that is correct,&#x201d; the system <b>100</b> may provide a confirmation <b>3340</b> of the action taken. In the illustrated example, the confirmation <b>3340</b> indicates &#x201c;Ok, I have logged a bg value of <b>3400</b> on 8/30/2018 at 1:29 PM for you.&#x201d;</p><p id="p-0163" num="0160"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flow chart illustrating an embodiment of a method <b>3500</b> for a voice input module <b>3023</b> of an IDM system. The method <b>3500</b> begins at block <b>3501</b> at which user voice input is received by the system <b>100</b>. In some embodiments, this occurs when the user selects the voice input option <b>3110</b> on the screen <b>3100</b> (<figref idref="DRAWINGS">FIG. <b>10</b></figref>) and speaks a command or question. The system <b>100</b> can record the user voice input and pass it to the interactive engine <b>130</b> for processing.</p><p id="p-0164" num="0161">The method <b>3500</b> can then move to block <b>3503</b> at which the user voice input is parsed. In some embodiments, the natural language processor <b>132</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>) parses the user voice input. This can include, for example, identifying spoken words and parsing the meaning thereof.</p><p id="p-0165" num="0162">Next, at block <b>3505</b>, the method <b>3500</b> generates and displays one or more text-based options to the user. The text-based options can be based on the parsed user voice input. The text-based options can be for example, the user-selectable options <b>238</b> displayed on the screen <b>3300</b> of <figref idref="DRAWINGS">FIG. <b>12</b></figref>.</p><p id="p-0166" num="0163">In some embodiments, the text-based options provide the user with easily selectable options related to the question or command input by the user. For example, in the illustrated example of logging a blood glucose measurement, the options allow the user to quickly confirm or deny the measurement using user-selectable options provided on the screen.</p><p id="p-0167" num="0164">In other embodiments, the text-based options can provide links to curated content related to the spoken command or question. For example, if the user asks about a particular food, the text-based options can include user-selectable links to recipes to related food, nutritional information, restaurants, etc.</p><p id="p-0168" num="0165">Providing text-based options in response to the user's voice input data can streamline the process of interacting with the system <b>100</b> by predicting possible response and providing them to the user as easily selectable options.</p><p id="p-0169" num="0166">From block <b>3505</b>, the method <b>3500</b> moves to decision state <b>3506</b> at which is determined whether and which type of additional user input is received. From decision state <b>3506</b>, the method <b>3500</b> can move to blocks <b>3507</b>, <b>3509</b>, or <b>3511</b> depending upon how the user responds. For example, at block <b>3507</b>, the method <b>3500</b> can receive a user selection of one of the text-based options provided at block <b>3505</b>. Alternatively, at block <b>3509</b>, the method <b>3500</b> can receive an additional user voice input <b>3509</b>, or at block <b>3511</b> the method <b>3500</b> can receive additional user text input.</p><p id="p-0170" num="0167"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flow chart illustrating an embodiment of another method <b>3600</b> for a voice input module <b>3023</b> of the IDM system <b>100</b>. The method <b>3600</b> can be used, for example, by the natural language processor <b>132</b> to parse the voice input data at block <b>3603</b> of the method <b>3500</b> of <figref idref="DRAWINGS">FIG. <b>13</b></figref>. In some embodiments, the method <b>3600</b> can be used to determine when the user has finished providing voice input data. The method <b>3600</b> can be triggered when the user selects the voice input option <b>3110</b> (<figref idref="DRAWINGS">FIG. <b>10</b></figref>).</p><p id="p-0171" num="0168">At block <b>3601</b>, the method <b>3600</b> can include calculating the root means square (RMS) for the audio signal strength of an audio signal received during a time block. In one embodiment, the time block is <b>100</b>, <b>200</b>, <b>300</b>, <b>400</b>, <b>500</b>, <b>600</b>, <b>750</b>, <b>1000</b>, <b>2000</b> or <b>3000</b> ms, although other blocks both longer and shorter are possible.</p><p id="p-0172" num="0169">At block <b>3603</b>, the calculated RMS is stored in both an ambient total recording list and a recent recording list. In some embodiments, the ambient total recording list includes all calculated RMS values for each time block of the recording. In some embodiments, the recent recording list includes all calculated RMS values for each time block in a recent portion of the recording. In some embodiments, the recent portion of the recording includes the time blocks in the last <b>1</b>.<b>5</b> seconds of the recording, although other portions of the recording, both longer and shorter, can also be used.</p><p id="p-0173" num="0170">At block <b>3605</b>, an average RMS value for each of the total recording list and the recent recording list is calculated. At decision state <b>3607</b>, the average RMS values for each of the total recording list and the recent recording list are compared against each other. If the average RMS value for the recent recording list is higher, the method <b>3600</b> continues by returning to block <b>3601</b>. If the average RMS value for the total recording list is higher, the method <b>3600</b> moves to block <b>3609</b> at which the recording is ended.</p><p id="p-0174" num="0171">As described above, an IDM system can include a user interface configured to interact, present or display information in a way to drive engagement with a user. The IDM system can be configured to deliver tailored engagement to the user in a manner configured to best help the user manage his or her disease. The tailored engagement can be based on, for example, stored user data, data received from various connected device (see <figref idref="DRAWINGS">FIG. <b>1</b></figref>), data entered by the user, stored content, etc. In some embodiments, the tailored engagement can be derived based at least in part on a user's previous interactions with the IDM system. To facilitate this engagement, the user interface of the IDM can include various modules. Certain modules are illustrated below with reference to example screen captures of an embodiment of an IDM. It should be appreciated that one or more of the modules can be included in and or executed by any of the IDM systems and/or user interfaces described above. Further, the following screen captures only provide examples and are not intended to be limiting of the disclosure.</p><heading id="h-0010" level="2">Example IDM System Methods</heading><p id="p-0175" num="0172">IDM systems, such as the IDM system <b>100</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>) can implement various methods to facilitate disease management. In some embodiments, these methods are executed by the interactive engine <b>130</b>. The methods may be involve the system <b>100</b> interacting or engaging with the user through the user interface <b>120</b>. The methods can include accessing and storing various data in the user database <b>140</b> and content database <b>152</b>.</p><p id="p-0176" num="0173">An IDM system can include a goal module that can be configured to provide another mechanism of engagement between the user and the IDM system. Within the goal module, the user can be prompted with goals that the user can select and complete. In some embodiments, a list of categories of goals, a list of goals, and/or a level of difficulty of goals can be provided to the user to facilitate selection of a goal for completion. In some embodiments, one or more goals may be recommended to the user based on an initial assessment of the user. An initial assessment may be performed based on data previously collected from the user, such as fitness data, health data, or treatment adherence data. During the initial assessment, the IDM system may alternatively or additionally request information from the user for the determination of one or more initial goals, such as for example, areas of interest, strengths, and weaknesses of the user. Following the initial assessment, one or more categories of goals, goals, and/or levels of difficulty of goals can be recommended to the user.</p><p id="p-0177" num="0174">The goals can be configured to match the user's current fitness and health level. As the user completes goals, more difficult goals can be suggested by the IDM system, which the user can select and complete. If a user fails to complete a goal, an easier goal can be selected and attempted.</p><p id="p-0178" num="0175">In some embodiments, the goal module can include several categories of goals. Each category can include a number of goals of different difficulty levels. If a goal is completed, the goal module can recommend a new goal within the same category at a higher difficulty level or a new goal from a different category that may be of the same difficulty level or a higher or lower difficulty level. In some embodiments, if a goal is failed, the goal module can recommend a new goal within the same category at a lower difficulty level or a new goal from a different category that may be of the same difficulty level or a higher or lower difficulty level.</p><p id="p-0179" num="0176">Table 2 depicts an example of goals of various difficulty levels within a &#x201c;Blood Glucose&#x201d; category of goals, ranging from level 1 (easiest) to level 4 (hardest). Table 2 shows an example duration for each goal and an example description that can be provided to the user.</p><p id="p-0180" num="0000"><tables id="TABLE-US-00002" num="00002"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="21pt" align="left"/><colspec colname="2" colwidth="77pt" align="left"/><colspec colname="3" colwidth="35pt" align="left"/><colspec colname="4" colwidth="126pt" align="left"/><thead><row><entry namest="1" nameend="4" rowsep="1">TABLE 2</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row><row><entry>Lvl.</entry><entry>Goal</entry><entry>Duration</entry><entry>Description</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>1</entry><entry>Read blood glucose</entry><entry>3 days</entry><entry>To reach this goal, just go to the next</entry></row><row><entry/><entry>article</entry><entry/><entry>screen and read the article. Then, for the</entry></row><row><entry/><entry/><entry/><entry>next 3 days, take a moment to think about</entry></row><row><entry/><entry/><entry/><entry>what you learned.</entry></row><row><entry>2</entry><entry>Once-a-day blood sugar</entry><entry>3 times in</entry><entry>This goal will help you get in the habit of</entry></row><row><entry/><entry>tracking</entry><entry>a week</entry><entry>checking your blood sugar. Check your</entry></row><row><entry/><entry/><entry/><entry>blood sugar 3 days this week at different</entry></row><row><entry/><entry/><entry/><entry>times of the day.</entry></row><row><entry>3</entry><entry>Once-a-day blood sugar</entry><entry>Daily for</entry><entry>Your goal is to check your blood sugar</entry></row><row><entry/><entry>tracking</entry><entry>7 days</entry><entry>before breakfast every day for a week. Set</entry></row><row><entry/><entry/><entry/><entry>yourself up for success by tracking your</entry></row><row><entry/><entry/><entry/><entry>goal progress here!</entry></row><row><entry>4</entry><entry>Twice-a-day blood sugar</entry><entry>Daily for</entry><entry>Nail this goal by checking your blood</entry></row><row><entry/><entry>tracking</entry><entry>7 days</entry><entry>sugar every morning and evening before</entry></row><row><entry/><entry/><entry/><entry>your meal. Set yourself up for success by</entry></row><row><entry/><entry/><entry/><entry>tracking your goal progress here!</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0181" num="0177">Table 3 depicts an example of goals of various difficulty levels within an &#x201c;Insulin&#x201d; category of goals, ranging from level 1 (easiest) to level 4 (hardest). Table 3 shows an example duration for each goal and an example description that can be provided to the user.</p><p id="p-0182" num="0000"><tables id="TABLE-US-00003" num="00003"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="21pt" align="left"/><colspec colname="2" colwidth="77pt" align="left"/><colspec colname="3" colwidth="35pt" align="left"/><colspec colname="4" colwidth="126pt" align="left"/><thead><row><entry namest="1" nameend="4" rowsep="1">TABLE 3</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row><row><entry>Lvl.</entry><entry>Goal</entry><entry>Duration</entry><entry>Description</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>1</entry><entry>Read insulin article</entry><entry>7 days</entry><entry>To reach this goal, just go to the next</entry></row><row><entry/><entry/><entry/><entry>screen and read one of the articles. Then,</entry></row><row><entry/><entry/><entry/><entry>for the next 7 days, take a moment to think</entry></row><row><entry/><entry/><entry/><entry>about what you learned.</entry></row><row><entry>2</entry><entry>Take basal insulin on</entry><entry>Daily for</entry><entry>To meet this goal, remember to take your</entry></row><row><entry/><entry>time</entry><entry>7 days</entry><entry>basal insulin as prescribed every day for</entry></row><row><entry/><entry/><entry/><entry>the next 7 days and log it in the app.</entry></row><row><entry>3</entry><entry>Rotate injection sites</entry><entry>3 times in</entry><entry>To nail this goal, rotate your injection sites</entry></row><row><entry/><entry/><entry>a week</entry><entry>at least three times this week.</entry></row><row><entry>4</entry><entry>Take mealtime insulin on</entry><entry>Daily for</entry><entry>To meet this goal, remember your</entry></row><row><entry/><entry>time</entry><entry>7 days</entry><entry>mealtime insulin as prescribed for the next</entry></row><row><entry/><entry/><entry/><entry>7 days, and log it in the app.</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0183" num="0178">Table 4 depicts an example of goals of various difficulty levels within a first &#x201c;Activity&#x201d; category of goals, ranging from level 1 (easiest) to level 4 (hardest). Table 4 shows an example duration for each goal and an example description that can be provided to the user.</p><p id="p-0184" num="0000"><tables id="TABLE-US-00004" num="00004"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="21pt" align="left"/><colspec colname="2" colwidth="70pt" align="left"/><colspec colname="3" colwidth="35pt" align="left"/><colspec colname="4" colwidth="133pt" align="left"/><thead><row><entry namest="1" nameend="4" rowsep="1">TABLE 4</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row><row><entry>Lvl.</entry><entry>Goal</entry><entry>Duration</entry><entry>Description</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>1</entry><entry>Read exercise article</entry><entry>7 days</entry><entry>To achieve this goal, just go to the next</entry></row><row><entry/><entry/><entry/><entry>screen to read one of the articles. Then, for</entry></row><row><entry/><entry/><entry/><entry>the next 7 days, take a moment each day</entry></row><row><entry/><entry/><entry/><entry>to think about it.</entry></row><row><entry>2</entry><entry>Walk 500 steps</entry><entry>3 times in</entry><entry>To achieve this goal, walk 500 steps 3</entry></row><row><entry/><entry/><entry>a week</entry><entry>times this week. That'll take you 4-8</entry></row><row><entry/><entry/><entry/><entry>minutes, depending on your pace.</entry></row><row><entry>3</entry><entry>Walk 2,000 steps</entry><entry>4 times in</entry><entry>To nail this goal, walk 2,000 steps 4 times</entry></row><row><entry/><entry/><entry>a week</entry><entry>this week. Depending on your pace, each</entry></row><row><entry/><entry/><entry/><entry>session should be 25-30 minutes-but go</entry></row><row><entry/><entry/><entry/><entry>at a speed that feels comfortable.</entry></row><row><entry>4</entry><entry>Walk 5,000 steps</entry><entry>4 times in</entry><entry>To master this goal, you'll need to walk</entry></row><row><entry/><entry/><entry>a week</entry><entry>5,000 steps 4 times this week. Depending</entry></row><row><entry/><entry/><entry/><entry>on your pace, this will probably take you</entry></row><row><entry/><entry/><entry/><entry>about an hour-but go at a speed that feels</entry></row><row><entry/><entry/><entry/><entry>comfortable.</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0185" num="0179">Table 5 depicts an example of goals of various difficulty levels within a second &#x201c;Activity&#x201d; category of goals, ranging from level 1 (easiest) to level 4 (hardest). Table 5 shows an example duration for each goal and an example description that can be provided to the user.</p><p id="p-0186" num="0000"><tables id="TABLE-US-00005" num="00005"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="21pt" align="left"/><colspec colname="2" colwidth="77pt" align="left"/><colspec colname="3" colwidth="35pt" align="left"/><colspec colname="4" colwidth="126pt" align="left"/><thead><row><entry namest="1" nameend="4" rowsep="1">TABLE 5</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row><row><entry>Lvl.</entry><entry>Goal</entry><entry>Duration</entry><entry>Description</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>1</entry><entry>Read exercise article</entry><entry>7 days</entry><entry>To achieve this goal, just go to the next</entry></row><row><entry/><entry/><entry/><entry>screen to read one of the articles. Then, for</entry></row><row><entry/><entry/><entry/><entry>the next 7 days, take a moment each day</entry></row><row><entry/><entry/><entry/><entry>to think about what you learned.</entry></row><row><entry>2</entry><entry>Choosing the farthest</entry><entry>3 times in</entry><entry>To meet this goal, park far away from your</entry></row><row><entry/><entry>parking spot</entry><entry>a week</entry><entry>workplace, grocery store or place of</entry></row><row><entry/><entry/><entry/><entry>worship 3 times this week so you'll have</entry></row><row><entry/><entry/><entry/><entry>to walk a ways to the entrance.</entry></row><row><entry>3</entry><entry>Take the stairs instead of</entry><entry>4 times in</entry><entry>To meet this goal, take the stairs instead of</entry></row><row><entry/><entry>an elevator or escalator</entry><entry>a week</entry><entry>an elevator or escalator 4 times this week.</entry></row><row><entry>4</entry><entry>Talk a 10-minute walk</entry><entry>Daily for</entry><entry>To meet this goal, find time to fit a 10-</entry></row><row><entry/><entry/><entry>7 days</entry><entry>minute walk into your day every day for 7</entry></row><row><entry/><entry/><entry/><entry>days.</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0187" num="0180">Table 6 depicts an example of goals of various difficulty levels within a &#x201c;Nutrition&#x201d; category of goals, ranging from level 1 (easiest) to level 4 (hardest). Table 6 shows an example duration for each goal and an example description that can be provided to the user.</p><p id="p-0188" num="0000"><tables id="TABLE-US-00006" num="00006"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="21pt" align="left"/><colspec colname="2" colwidth="70pt" align="left"/><colspec colname="3" colwidth="35pt" align="left"/><colspec colname="4" colwidth="133pt" align="left"/><thead><row><entry namest="1" nameend="4" rowsep="1">TABLE 6</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row><row><entry>Lvl.</entry><entry>Goal</entry><entry>Duration</entry><entry>Description</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>1</entry><entry>Read healthy eating</entry><entry>7 days</entry><entry>To reach this goal, just go to the next</entry></row><row><entry/><entry>article</entry><entry/><entry>screen and read one of the articles. Then,</entry></row><row><entry/><entry/><entry/><entry>every day this week, take a moment to</entry></row><row><entry/><entry/><entry/><entry>think about what you've learned.</entry></row><row><entry>2</entry><entry>Make one new healthy</entry><entry>7 days</entry><entry>To reach this goal, make one of the</entry></row><row><entry/><entry>recipe</entry><entry/><entry>delicious, diabetes-friendly recipes on the</entry></row><row><entry/><entry/><entry/><entry>next screen. And there are more to choose</entry></row><row><entry/><entry/><entry/><entry>from in the app: Just chat with me and I</entry></row><row><entry/><entry/><entry/><entry>can help you find them.</entry></row><row><entry>3</entry><entry>Make healthy food</entry><entry>3 times in</entry><entry>To reach this goal, swipe through our</entry></row><row><entry/><entry>sways</entry><entry>a week</entry><entry>guide to healthy food swaps on the next</entry></row><row><entry/><entry/><entry/><entry>screen and make a healthy food swap 3</entry></row><row><entry/><entry/><entry/><entry>times this week.</entry></row><row><entry>4</entry><entry>Keep a food diary</entry><entry>7 days</entry><entry>To reach this goal, jot down everything</entry></row><row><entry/><entry/><entry/><entry>you eat and drink for the next week in a</entry></row><row><entry/><entry/><entry/><entry>notebook, or put it in a notes program on</entry></row><row><entry/><entry/><entry/><entry>your smartphone. (Don't forget sneaky</entry></row><row><entry/><entry/><entry/><entry>items like salad dressing and coffee</entry></row><row><entry/><entry/><entry/><entry>creamer.)</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0189" num="0181">Table 7 depicts an example of goals of various difficulty levels within an &#x201c;Risk Reduction&#x201d; category of goals, ranging from level 1 (easiest) to level 4 (hardest). Table 7 shows an example duration for each goal and an example description that can be provided to the user.</p><p id="p-0190" num="0000"><tables id="TABLE-US-00007" num="00007"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="21pt" align="left"/><colspec colname="2" colwidth="77pt" align="left"/><colspec colname="3" colwidth="35pt" align="left"/><colspec colname="4" colwidth="126pt" align="left"/><thead><row><entry namest="1" nameend="4" rowsep="1">TABLE 7</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row><row><entry>Lvl.</entry><entry>Goal</entry><entry>Duration</entry><entry>Description</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>1</entry><entry>Read diabetes health risk</entry><entry>7 days</entry><entry>To achieve this goal, just go to the next</entry></row><row><entry/><entry>article</entry><entry/><entry>screen and read one of the articles. Then,</entry></row><row><entry/><entry/><entry/><entry>for the next 7 days, take a moment each</entry></row><row><entry/><entry/><entry/><entry>day to think about what you learned.</entry></row><row><entry>2</entry><entry>Check feet for blisters,</entry><entry>3 times in</entry><entry>To achieve this goal, check your feet for</entry></row><row><entry/><entry>sores, or swollen areas</entry><entry>a week</entry><entry>blisters, sores or swollen areas 3 times</entry></row><row><entry/><entry/><entry/><entry>this week.</entry></row><row><entry>3</entry><entry>Practice stress reduction</entry><entry>Daily for</entry><entry>To achieve this goal, just go to the next</entry></row><row><entry/><entry>techniques</entry><entry>7 days</entry><entry>screen and read one of the articles. Then</entry></row><row><entry/><entry/><entry/><entry>practice what you learned every day this</entry></row><row><entry/><entry/><entry/><entry>week.</entry></row><row><entry>4</entry><entry>Schedule an appointment</entry><entry>7 days</entry><entry>To achieve this goal, tap the link on the</entry></row><row><entry/><entry>with a diabetes educator</entry><entry/><entry>next screen to make an appointment with</entry></row><row><entry/><entry/><entry/><entry>a certified diabetes educator.</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0191" num="0182">The IDM system can monitor progress and engage with the user during performance of a goal to enhance adherence to the goal or determine issues related to the goal experienced by the user. For example, the IDM can provide addition content to user, such as articles or recipes, related to the goal. In some embodiments, the IDM can provide recommendations to the user for completion of the goal or ask questions to the user regarding progress towards the goal. In some embodiments, the IDM module can provide additional content and/or recommendations based on the user's answers and/or progress.</p><p id="p-0192" num="0183">The IDM system can also generate content in other modules based on the goals that user is pursuing in the goal module. For example, if the user is pursuing a goal related to physical activity, a learning plan related to physical activity can be suggested in the learn module. Similarly, if a user is pursuing a goal related to diet, a learning plan relating to diet can be presented in the learn module.</p><p id="p-0193" num="0184">If a user fails to complete a goal, the IDM system can engage with the user to try and figure out why the user did not complete the goal. For example, the user can be prompted with an assessment to determine the user's feelings about the goal. The results of the assessment can be used to derive new goals that are configured to drive engagement between the user and the system. The goal module can modify goals based on the user's past experiences in the goal module as well as in other parts of the user interface of the IDM system. In some embodiments, if a user fails to complete a goal, the initial assessment can be repeated. The results of repeated initial assessment, either alone, or in combination with the users past experiences in the goal module, past experiences in other parts of the user interface of the IDM system, and/or the results of the assessment of the user's feelings about the previous goal, can be used to determine a recommendation of one or more goals to the user.</p><p id="p-0194" num="0185"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart illustrating an example process <b>700</b> for determining a patient goal or goals in an integrated disease management system. The process <b>700</b> begins at a start step. Next, the process moves to a step <b>702</b>, at which the system stores user information related to a patient having a disease. User information can be stored in a user database. The user information can include at least one of measured patient disease management data and user-inputted patient disease management data. Measured patient disease management data can be data received from an external device, such as any of the devices shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> as connected to the IDM <b>100</b>. For example, the measured patient disease management data can be received from a smart diabetes monitor, a smart insulin pen, a smart insulin pump, and a fitness tracker. User-inputted patient disease management data can be similar data that the user has entered through the IDM system. Such user-inputted patient disease management data can be entered, for example, using the logging method described below with reference to <figref idref="DRAWINGS">FIG. <b>8</b></figref>. The user data can be data related to the patient's disease. In an example, where the disease is diabetes. The user data can be data related to blood glucose, insulin injections, diet, physical activity, etc. In some embodiments, the user-inputted patient disease management data can include data collected during an initial assessment by the goals module.</p><p id="p-0195" num="0186">At a step <b>704</b>, the IDM system stores content items related to recommended lifestyle choices for improving patient outcomes and protocols for disease management. Content items may be stored in a content database. Content related to recommend lifestyle choices for improving patient outcomes can include, for example, content curated to help the user manage his or her disease. This can include for example, curated courses or information on managing injections, information related to diet, information related to exercise, etc. Protocols for disease management can include protocols that determine how to improve the user's disease status. For example, if the user is experiencing high blood sugar, a protocol can be provided with parameters that define steps that can be taken to lower the user's blood sugar. Protocols can be developed by medical professionals, such as CDEs.</p><p id="p-0196" num="0187">Next, at a step <b>706</b>, the system updates the user information in the user database based on a user interaction with an interactive user interface for providing integrated disease management. For example, when the user engages with the IDM system, this interaction may cause the system to store additional information about the user in the user database. Such information can be used to tailor future interactions with the system. In some embodiments, the user interaction can be at least one of the user providing user-inputted patient disease management data with the interactive interface and the user providing measured patient disease management data from one or more patient monitoring devices. This can include the user manually entering data, or the IDM system receiving data automatically from a smart, connected device. In some embodiments, this can include data provided during an initial assessment by the goals module.</p><p id="p-0197" num="0188">At a step <b>708</b>, the system determines a patient goal related to improving disease management based on the user information and the stored protocols for disease management and displaying the patient goal to the user on the interactive user interface. The system may analyze the user information to determine a goal that will be helpful to the user for managing his or her disease. The determination can be based on the stored protocols as well as previously entered user data, such as data entered during an initial assessment by the goals module. The system can determine a goal that is &#x201c;within the patient's reach&#x201d; based on knowledge of the user from past interactions between the system and the user. Example goal module, displaying goals to a user and interacting with the user are shown in <figref idref="DRAWINGS">FIGS. <b>19</b>-<b>22</b> and <b>33</b>-<b>39</b></figref>, described below.</p><p id="p-0198" num="0189">In some embodiments, the system can determine a plurality of patient goals to display to the user to allow the user to select a patient goal. In some embodiments, the system can determine a category of patient goals, such as for example blood glucose goals, insulin goals, exercise or activity goals, nutrition goals, or risk reduction goals, to display to the user to allow the user to select a category of goals prior to determining the patient goal. In some embodiments, the system can determine a difficulty level of a goal to display to the user.</p><p id="p-0199" num="0190">At a step <b>710</b>, the system can also select one or more content items from the content database based on at least the determined patient goal and the user information and display the selected one or more content items to the user on the interactive user interface. Thus, in addition to providing a recommended goal the user, the system may provide related content to the user as well. An example is shown in <figref idref="DRAWINGS">FIG. <b>21</b></figref>.</p><p id="p-0200" num="0191"><figref idref="DRAWINGS">FIGS. <b>27</b>-<b>32</b></figref> are example screen captures of a user interface to a goal module of an IDM system depicting an example of an initial assessment workflow for determining and providing a goal recommendation to a user.</p><p id="p-0201" num="0192"><figref idref="DRAWINGS">FIG. <b>27</b></figref> shows an example screen <b>6400</b> of the user interface to a goal module according to one embodiment. The screen <b>6400</b> includes a prompt to the user to begin the initial assessment with the text &#x201c;Let's set some goals together that are just right for you.&#x201d; The screen <b>6400</b> further includes a selectable option to begin the initial assessment labeled &#x201c;Okay, let's go.&#x201d;</p><p id="p-0202" num="0193">After the user decides to begin an assessment the goal module can ask a series of questions to the user and allow the user to select responses as shown on example screens <b>6410</b>, <b>6420</b>, <b>6430</b>, <b>6440</b> of <figref idref="DRAWINGS">FIGS. <b>28</b>, <b>29</b>, <b>30</b>, and <b>31</b></figref>, respectively. Screen <b>6410</b> of <figref idref="DRAWINGS">FIG. <b>28</b></figref> shows that the user has selected options of &#x201c;Tracking blood sugar more&#x201d; and &#x201c;Reducing health risks&#x201d; in response to the question &#x201c;How do you want to take control of your diabetes?&#x201d; Screen <b>6420</b> shows that the user has selected the option of &#x201c;I know I need to track more&#x201d; in response to the question &#x201c;When you think about checking your blood sugar, how do you feel?&#x201d; Screen <b>6430</b> shows that the user has selected the option of &#x201c;I check every once in a while&#x201d; in response to the question &#x201c;How often are you checking your blood sugar?&#x201d; Screen <b>6440</b> shows that the user has selected the option of &#x201c;I'm scared of what might happen and want to learn more&#x201d; in response to the question &#x201c;How do you feel about the ways diabetes can affect your health?&#x201d;</p><p id="p-0203" num="0194">After the user answers questions from the goal module, a list of recommended goals that can be selected by the user are displayed on a screen <b>6450</b>, as shown in <figref idref="DRAWINGS">FIG. <b>32</b></figref>. The screen <b>6450</b> of the example workflow lists a selectable goal of &#x201c;Try once-a-day tracking&#x201d; which can be based at least in part on the user's answers to the questions of screens <b>6410</b>, <b>6420</b>, <b>6430</b>, and <b>6440</b>.</p><p id="p-0204" num="0195"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating an example process <b>800</b> for logging patient data in an integrated disease management system. The process <b>800</b> can be implemented by a logging module that can provide the user with a quick and efficient method for logging diabetes care related information. As will be shown, in some embodiments, the logging module may utilize voice logging. The voice logging may provide a number of sample log prompts, including blanks that the user can easily fill in.</p><p id="p-0205" num="0196">The process <b>800</b> begins at a start step and moves to a step <b>802</b> at which the system displays a plurality of sample logging prompts. The sample logging prompts can be displayed on an interactive user interface. Each of the sample logging prompts can include a phrase relating to a type of patient data associated with a disease of the user and including at least one blank. The sample logging prompts can help guide the user in understanding how to log data with the IDM system, and help the user understand the types of data that can be logged. <figref idref="DRAWINGS">FIG. <b>24</b></figref>, described below, illustrates several sample logging prompts in the context of diabetes.</p><p id="p-0206" num="0197">The sample logging prompts can be based at least in part on the disease of the user and previously stored patient data. For example, the system can understand which type of data is useful for treating the disease as well as which types of data the user has entered in the past to determine the sample logging prompts. In the case of diabetes, for example, the sample logging prompts can be related to are related to one or more of blood glucose measurement, insulin dosing, diet, and physical activity</p><p id="p-0207" num="0198">At a step <b>804</b>, the system receives a spoken user input. The spoken user input can be recorded with a microphone of a user device. The spoken user input can include the user verbally repeating one the sample logging prompts with patient data inserted into the at least one blank. Receiving the spoken user input can include parsing an audio signal using the method of <figref idref="DRAWINGS">FIG. <b>14</b></figref>, described above.</p><p id="p-0208" num="0199">At a step <b>806</b>, the system can extract the patient data from the spoken user input with a natural language processor. This can include interpreting the spoken user input and translating the spoken user input into a computer-readable format.</p><p id="p-0209" num="0200">At a step <b>808</b>, stores the patient data in a user database of the integrated disease management system. In this way, the user can simply and quickly use vocal commands to log patient data into the system</p><p id="p-0210" num="0201">In some embodiments of the process <b>800</b>, the system, after receipt of the spoken user input, removes the displayed sample logging prompt associated with the spoken user input from the display and displays a new sample logging prompt to replace the removed sample logging prompt. This can encourage the user to continue logging data as additional prompts are provided. In some embodiments, the system also displays the text of the spoken user input to the user. This can allow the user to verify that the system has understood correctly. The system may also prompt the user to confirm that the data is correct.</p><p id="p-0211" num="0202"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example process <b>900</b> for displaying contextualized insights along with a graphical representation of patient data in an integrated disease management system. The system can analyze the data displayed to the user and provide beneficial, contextualized insights that can help the user to understand and apply the data.</p><p id="p-0212" num="0203">The process <b>900</b> begins at a start step and then moves to a step <b>902</b>, at which the system stores user information related to a patient having a disease. The user information can be stored in the user database. The user information can include at least one of measured patient disease management data and user-inputted patient disease management data. Measured patient disease management data can include data received from one or more patient monitoring devices. The one or more patient monitoring devices can be, for example, a smart diabetes monitor, a smart insulin pen, a smart insulin pump, and a fitness tracker or others. User-inputted patient disease management data can be data entered by the user.</p><p id="p-0213" num="0204">At a step <b>904</b>, the system stores, in a content database, protocols for disease management. The protocols can provide steps for managing a user's disease as described above. At a step <b>906</b>, the system a graphical representation of at least a portion of the stored user information. The graphical representation can be for example, one or more graphs or plots of patient data for a given time period such as a day, a week, or a month.</p><p id="p-0214" num="0205">At a step <b>908</b>, the system analyzes the at least a portion of stored user information displayed on the interactive display based at least in part on the protocols for disease management to determine a contextualized insight related to the at least a portion of stored user information. The system can determine trends in the displayed data that may not be readily apparent to the user and provide insights regarding these trends so as to help the user manage the disease.</p><p id="p-0215" num="0206">At a step <b>910</b>, the system displays, on the interactive display, the contextualized insight along with the graphical representation. An example of this feature is shown in <figref idref="DRAWINGS">FIG. <b>26</b></figref>, described below. The process <b>900</b> can be helpful because it can allow a user to understand and apply their patient data in a way that may not readily apparent to the user based on the patient data alone.</p><heading id="h-0011" level="2">Example IDM System Screens</heading><p id="p-0216" num="0207"><figref idref="DRAWINGS">FIGS. <b>15</b> and <b>16</b></figref> are example screen captures of home screen of a user interface of an IDM system according to an embodiment. The home screen can be presented to the user after the user has completed an onboarding module or when the user first accesses the IDM system after having completed the onboarding module. The home screen can present the user with information and provide links for accessing various other modules of the IDM system.</p><p id="p-0217" num="0208"><figref idref="DRAWINGS">FIG. <b>15</b></figref> shows an initial example of a home screen <b>4200</b>. As illustrated, the screen <b>4200</b> includes a user-selectable button <b>4202</b> labeled &#x201c;Ask Briight.&#x201d; The user-selectable button <b>4202</b> can also be labeled differently in other examples. The user-selectable button <b>4202</b> can be accessed to allow the user to access an interactive portion of the user interface. For example, the user-selectable button <b>4202</b> can be used to access a chatbot, which as described above can allow the user to interact with the user interface in a natural language fashion. For example, the user can interact with the user interface by typing natural language questions or by speaking natural language questions verbally to the system after selecting the user-selectable button <b>4202</b>. In the illustrated example, the user-selectable button includes a sample of the type of question that can be asked to the system. As illustrated, the sample is &#x201c;How many carbs are in French fries?&#x201d; By providing the user with the sample, the IDM system may intuitively prompt the user to understand which types of questions can be asked to the system after selecting the user-depressible button <b>4202</b>. Other samples can be included or the sample can be omitted.</p><p id="p-0218" num="0209">In the illustrated example, the screen <b>4200</b> also includes a series of selectable cards that can be selected to access various tools available to the user in the IDM system. For example, as illustrated, cards for &#x201c;Carbs calculator&#x201d; and &#x201c;Insulin calculator&#x201d; are presented. In some instances, cards for frequently access tools may be displayed. In some environments, access to tools may be provided in other ways such as drop down menus, user-selectable buttons, etc.</p><p id="p-0219" num="0210"><figref idref="DRAWINGS">FIG. <b>16</b></figref> presents an additional example of a home screen <b>4300</b>. In some embodiments, the home screen <b>4300</b> can be accessed by scrolling down from the screen <b>4200</b> of <figref idref="DRAWINGS">FIG. <b>15</b></figref>. As shown, the screen <b>4300</b> may include links <b>4302</b> for accessing certain content within the IDM system. For example, the links <b>4302</b> may be used access frequently used articles or tutorials. In the illustrated example, links for &#x201c;Remind me to change IDD position,&#x201d; &#x201c;How to change my IDD position?,&#x201d; &#x201c;How to refill insulin tank?,&#x201d; and view &#x201c;BD Strive Instructions.&#x201d; Accessing any of the links <b>4302</b> can take the user immediately to the selected content.</p><p id="p-0220" num="0211">As shown, the screen <b>4300</b> also includes additional content <b>4303</b> for the user. Links to content <b>4303</b> &#x201c;Type 2 Diabetes: How to Calculate Insulin Doses&#x201d; and &#x201c;Reading Food Labels: Tips If You Have Diabetes&#x201d; are presented. The content <b>4303</b> can be tailored for the user. For example, the IDM system may select specific content based on the user's past experiences with the IDM system and display links to the content directly on the home screen <b>4300</b>. The content <b>4303</b> may change over time, for example, as the system learns more about the user's preferences and as the user has more experiences with the system.</p><p id="p-0221" num="0212">As shown on the screen <b>4300</b>, the home screen may include a menu with different icons for accessing different modules of the IDM system. As illustrated, the screen <b>4300</b> includes an icon <b>4304</b> for accessing a data module, an icon <b>4305</b> for accessing a learn module, an icon <b>4306</b> for accessing a goals module, an icon <b>4307</b> for accessing a chatbot module, and an icon <b>4308</b> for entering user data with a logging module. Example screens for each of these modules are shown and described below.</p><p id="p-0222" num="0213"><figref idref="DRAWINGS">FIGS. <b>17</b> and <b>18</b></figref> are example screen captures of a learn module of a user interface of an IDM system according to an embodiment. The learn module may be accessed, in some examples, by selecting the icon <b>4305</b> on the home screen (see <figref idref="DRAWINGS">FIG. <b>16</b></figref>). The learn module can be configured to provide customized or tailored curriculum or learning plans for the user. The curriculum can be selected and curated based on the user's past interactions with the system. The curriculum can be selected based on the user's level of knowledge and comfort with various topics. The learn module can provide the user with context specific insights and profile specific curriculum. The content provide by the learn module may be determined at least in part, by the information in the user's profile and the rules described above (see, for example, <figref idref="DRAWINGS">FIGS. <b>21</b>-<b>29</b></figref> and related text). Further, at the end of a piece of curriculum/interaction the learn module can engage the user with behavioral conversation (e.g., to assess the user's comfort level with the material, which is a psychological indicator of success) to guide future content.</p><p id="p-0223" num="0214"><figref idref="DRAWINGS">FIG. <b>16</b></figref> presents an initial screen <b>4600</b> of the learn module. As shown the screen <b>4600</b> can present the user with one or more learning plans. In the illustrated example, a first learning plan <b>4602</b>, entitled &#x201c;Living with Diabetes,&#x201d; and a second learning plan <b>4604</b>, entitled &#x201c;Injection Basics,&#x201d; are presented to the user. The user may access either of the learning plans <b>4602</b>, <b>4604</b> by selecting them on the screen <b>4600</b>. The learning plans <b>4602</b>, <b>4604</b> shown on the screen <b>4600</b> are only examples of learning plans. Various other learning plans can be provided to the user on the screen <b>4600</b>. As will be described in more detail below, a learning plan can comprise a guided curriculum that can be customized for the user. For example, a learning plan can be configured to teach material to a user in a manner that is best suited to the users learning style and knowledge base.</p><p id="p-0224" num="0215">The screen <b>4600</b> may display learning plans that are recommended for the user by the system. For example, the learning plans <b>4602</b>, <b>4604</b> shown in <figref idref="DRAWINGS">FIG. <b>16</b></figref> relate to the basics of diabetes care. These learning plans may be presented to a new user or to a user that is unfamiliar with the basics of diabetes care. A user with more experience with the IDM system or with more knowledge of diabetes care may be presented with more complex learning plans that are more suited to that user's knowledge base. As noted previously, the system may customize content based on the user's profile and the user's past experiences with the system.</p><p id="p-0225" num="0216"><figref idref="DRAWINGS">FIG. <b>18</b></figref> illustrates an example screen <b>4700</b> of the learn module. The screen <b>4700</b> may be displayed after the user selects the learning plan <b>4602</b>, &#x201c;Living with Diabetes,&#x201d; from the screen <b>4600</b> of <figref idref="DRAWINGS">FIG. <b>16</b></figref>. As shown, in the illustrated example, the screen <b>4700</b> presents the user with two options related to the selected learning plan. Specifically, in the illustrated example, the user is presented with a beginner option <b>4702</b> and a not-a-beginner option <b>4704</b>. The options <b>4702</b>, <b>4704</b> allow the user to indicate their familiarity with the material. For example, if the user is new to living with diabetes, the user may select the beginner option <b>4702</b>. As Illustrated, the beginner option asks, &#x201c;Are you a beginner?&#x201d; Start your journey here with the basics!&#x201d; If the user selects the option <b>4702</b>, the user can be guided to more beginner material. For example, if the user selects the option <b>4702</b>, the user may begin at the very beginning of the learning plan. The not-a-beginner option <b>4704</b> asks, &#x201c;Not a beginner?&#x201d; Take a quick placement test to tailor your lessons.&#x201d; This option <b>4704</b> may be selected by users who already have some familiarity with the material of the learning plan. Selection of the option <b>4704</b> may take the user to a placement test to determine the user's familiarity with the material. Based on the outcome of the placement test, the user may be inserted into the learning plan at various points that correspond to the user's familiarity with the material.</p><p id="p-0226" num="0217">In many cases, the user will move through the lessons sequentially before moving on to the next course. However, based on the interactions with the learning plan, the learn module may customize the learning plan by moving the user through the course in a different order to best suit the user's learning style and knowledge base. <figref idref="DRAWINGS">FIG. <b>6</b></figref>, described above, is a flow chart illustrating example movement of a user through a learning plan. The learn module can pose questions that may be configured to assess the user's comfort and knowledge related to the learning plan so as to place the user into the learning plan at the spot that best matches the user's current knowledge and experience. As a result of the assessment, the user may be placed into the middle of a learning plan. If the initial assessment reveals that the user is already familiar with the material, then this information can be inserted into the learning plan at this point or at any suitable point based on the assessment. In this example, the user has passed the introduction and preparation courses without needing to take the additional course material based on the initial assessment.</p><p id="p-0227" num="0218"><figref idref="DRAWINGS">FIGS. <b>19</b>, <b>20</b>, <b>21</b>, and <b>22</b></figref> are example screen captures of a user interface to a goal module of an IDM system. <figref idref="DRAWINGS">FIG. <b>19</b></figref> shows an example screen <b>6500</b> of a goals module according to an embodiment. The screen <b>6500</b> can be configured to display possible goals to a user. The possible goals can be suggested by the IDM system. The goals can be suggested by the IDM system based at least in part on, for example, the user's profile and the user's past interactions with the IDM system. In some embodiments, the goals can be suggested based on an initial assessment conducted by the goal module, as described herein. As illustrated, two possible goals are displayed on the screen <b>6500</b>. A first example goal states &#x201c;Walk 10,000 steps for 7 days.&#x201d; The system may suggest this goal based on the user's known activity level based on interactions with the system (e.g., previous user data inputs) or data received from connected devices, such as step counters of fitness trackers. For example, the goal module may suggest a step goal that is, for example, 10%, 20%, 25%, or 30% higher than a number of steps that the user has averaged over the past day, week, or month. Other metrics for determining the step goal are also possible (e.g., calories burned, exercise minutes, etc.). Where the user profile does not include past activity data on which to base the goal, the goal module may suggest a moderate goal based on, for example, a scientific recommended daily step-count.</p><p id="p-0228" num="0219">As shown in <figref idref="DRAWINGS">FIG. <b>19</b></figref>, the screen <b>6500</b> includes a second suggested goal of &#x201c;log blood glucose for 7 days.&#x201d; Although two suggested goals are shown on the screen <b>6500</b>, other numbers of suggested goals may be included in other embodiments. Further, the illustrated goals are provided for example only. Other goals may also be included.</p><p id="p-0229" num="0220">For each suggested goal, the screen <b>6500</b> can include a start button that the user can select if they wish to try the goal. Additionally, the screen <b>6500</b> can include a menu with icons that allow the user to select additional modules of the user interface. For example, the menu includes the icon <b>4304</b> for accessing the data module, the icon <b>4305</b> for accessing the learn module, the icon <b>4306</b> for accessing the goals module, and the icon <b>4307</b> for accessing the chatbot module. These icons may also appear on the home screen <b>4300</b>, as shown in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, described above. These icons can allow for quick and easy access to other modules directly from within the goal module.</p><p id="p-0230" num="0221"><figref idref="DRAWINGS">FIG. <b>20</b></figref> illustrates an example screen <b>6900</b> that can be displayed if the user is not meeting his or her goals. As shown, the system may prompt the user to inquire why the user has not met the goal. For example, the screen <b>6900</b> asks, &#x201c;Have you been struggling to achieve your goals? Do you want to talk about it? Let's chat.&#x201d; Selecting the let's chat option may bring the user to the chatbot interface. The IDM system may then inquire about why the user has not been able to meet the goal. The user may respond either written or orally to the system. In this way, the goals module can receive feedback about why the user has not met the goals. Such feedback may be used to adjust the goals going forward. This system may create a more customized and tailored experience for the user that may help the user to achieve his or her goals.</p><p id="p-0231" num="0222">While <figref idref="DRAWINGS">FIG. <b>20</b></figref> illustrates one example of a prompt from the system when a user is not meeting his or her goals, other prompts may be initiated during an attempt to complete a goal. For example, prompts to chat with the IDM system may be a) initiated at predetermined times within the duration of the goal, b) in response to meeting a goal milestone, such as for example, walking 10,000 steps in one day for a goal of &#x201c;Walk 10,000 steps for 7 days,&#x201d; or c) based on other measured or user-inputted data received by the IDM. Additionally, an option to chat may be presented to the user throughout the duration of a goal to facilitate questions or feedback from the user.</p><p id="p-0232" num="0223"><figref idref="DRAWINGS">FIG. <b>21</b></figref> illustrates an example screen <b>7200</b> for tracking a &#x201c;no soda every day for 14 days goal.&#x201d; As shown, the user is on day <b>12</b> of <b>14</b>. A status indicator circle indicates how close the user is to complete in the goal. In this example, below the status indicator the user has the option to enter whether they completed the goal for each day. As illustrated by a checkmark, the user has completed the goal for today. In this example, the user has not indicated that they have completed the goal for yesterday or Monday. However, they may still enter that they completed the goal on this day by selecting the plus icon associated with the day.</p><p id="p-0233" num="0224">Below the goal tracking portion of the screen <b>6700</b>, the goal module may include a portion of the screen <b>6700</b> for displaying content to the user. The content can be related to the goal being tracked. In this example, the goal relates to not drinking soda and the display content includes an article for &#x201c;5 healthy alternatives to soda and sugary drinks during your meals&#x201d; and an article for &#x201c;20 minute recipes of juices and blends to substitute soda.&#x201d; Because the user is currently pursuing a goal related to not drinking soda, the content related to alternatives to soda may be highly relevant to the user. Thus, it may be likely that the user may select the article to read the content. In some embodiments, the additional content displayed to the user can be displayed a) at a predetermined time within the duration of the goal, b) based on the user's progress towards completing the goal, c) in response to a request from the user, or d) in response to comments from the user during a chat with the IDM system.</p><p id="p-0234" num="0225"><figref idref="DRAWINGS">FIG. <b>22</b></figref> illustrates an example screen <b>8000</b> that displays the user's goals. The screen <b>8000</b> also includes an example of a notification that has popped up to remind a user to record user inputs into the system. In the illustrated example, the notification states &#x201c;Don't forget to log your blood glucose in your data tab.&#x201d; Thus, when the user is in the goal module, the IDM system may prompt the user to access additional modules, such as the data logging module, by providing the user with a notification, for example as shown in <figref idref="DRAWINGS">FIG. <b>22</b></figref>. Such notifications can be provided to the user while the user is accessing any of the modules.</p><p id="p-0235" num="0226"><figref idref="DRAWINGS">FIGS. <b>33</b>-<b>39</b></figref> are example screen captures of a user interface to a goal module of an IDM system depicting an example workflow for a goal of &#x201c;Log blood glucose for 7 days.&#x201d;</p><p id="p-0236" num="0227"><figref idref="DRAWINGS">FIG. <b>33</b></figref> shows an example screen <b>6500</b> of a goals module according to an embodiment. As illustrated, two possible goals are displayed on the screen <b>6500</b>. A first example goal states &#x201c;Walk 10,000 steps for 7 days, and a second goal states &#x201c;Log blood glucose for 7 days.&#x201d; As described herein, for each goal, the screen <b>6500</b> can include a start button that the user can select if they wish to try the goal. For the example workflow depicted in <figref idref="DRAWINGS">FIGS. <b>33</b>-<b>39</b></figref>, the goal &#x201c;Log blood glucose for 7 days&#x201d; is selected.</p><p id="p-0237" num="0228">After selection of the goal &#x201c;Log blood glucose for 7 days,&#x201d; the goal module can display a screen <b>6510</b>, as shown in <figref idref="DRAWINGS">FIG. <b>34</b></figref>. The screen <b>6510</b> includes status indicator circle indicating how close the user is to completing the goal. As shown in <figref idref="DRAWINGS">FIG. <b>34</b></figref>, the status indicator circle shows no current progress towards the goal. The screen <b>6510</b> also includes a description of the goal and an explanation of the relevance of the goal. The screen <b>6510</b> further includes a start button that the user can select to begin the goal.</p><p id="p-0238" num="0229">After selection of the start button of the screen <b>6510</b>, the goal module can display a screen <b>6520</b>, as shown in <figref idref="DRAWINGS">FIG. <b>35</b></figref>. The status indicator circle on the screen <b>6520</b> indicates that the goal has been initiated but that no progress has been made. The user is on day 0 of 7. Below the status indicator is an option for the user to enter whether they completed the goal for each day. The plus sign indicates that the user has not yet indicated that they have completed the goal of logging blood glucose for the day. Below, the option for the user to enter whether they completed the goal for each day, the screen <b>6520</b> includes a chat prompt. The chat prompt asks &#x201c;We can all use some support in blood glucose tracking. Anything I can help you with?&#x201d; Selecting the &#x201c;let's chat&#x201d; option below the chat prompt can bring the user to the chatbot interface, as described herein. In some embodiments, the chat prompt may be present throughout the duration of the goal. In other embodiments, the chat prompt may appear only at certain times or may change based on the user's progress within the goal. Below the chat prompt, the screen <b>6520</b> includes a portion of the screen for displaying content to the user. The content can be related to the goal being tracked. In this example, the display content includes an article for &#x201c;What do all those Diabetes Numbers Mean?&#x201d; and an article for &#x201c;Understanding if Your Diabetes Management Plan is Working.&#x201d;</p><p id="p-0239" num="0230">After the user enters that the goal has been complete for the first day, the goal module can display a screen <b>6530</b>, as shown in <figref idref="DRAWINGS">FIG. <b>36</b></figref>. The status indicator circle on the screen <b>6530</b> indicates that the user has completed day 1 of 7. Below the status indicator, the checkmark indicates that the user has completed the goal for today.</p><p id="p-0240" num="0231"><figref idref="DRAWINGS">FIG. <b>37</b></figref> shows an example screen <b>6540</b> of a goal module after the user has completed <b>6</b> of 7 days of the goal. As demonstrated by the checkmarks next to the options for indicating goal completion, the user completed the goal yesterday and Sunday. The plus sign indicates that the user has not yet completed the goal today.</p><p id="p-0241" num="0232">After the user indicates that the goal has been completed for today on screen <b>6540</b>, the goal module can display screen <b>6550</b>, as shown in <figref idref="DRAWINGS">FIG. <b>38</b></figref>. The screen <b>6550</b> shows a congratulatory message stating &#x201c;Congrats! Goal completed.&#x201d; The status indicator circle on the screen <b>6550</b> indicates that the user has completed day 7 of 7. The screen <b>6550</b> further shows an animation to indicate successful completion of the goal. In the example of screen <b>6550</b>, the animation is an animation of confetti.</p><p id="p-0242" num="0233">After the screen <b>6550</b> has been displayed, the goal module can display the screen <b>6560</b>, as shown in <figref idref="DRAWINGS">FIG. <b>39</b></figref>. The screen <b>6560</b> also shows an animation of confetti to indicate a congratulations or celebration to the user for completing a goal. In comparison to the screen <b>6550</b>, the screen <b>6550</b> has replaced the text stating &#x201c;7 of 7 days&#x201d; with an icon representing the goal. On the screen <b>6550</b>, the icon is a syringe.</p><p id="p-0243" num="0234">After a goal has been completed or failed, the goal module can recommend a new goal as described herein.</p><p id="p-0244" num="0235"><figref idref="DRAWINGS">FIG. <b>40</b></figref> is an example screen capture <b>6570</b> of a chatbot interface based on a user selection during use of the goal module, such as, for example, during the workflow shown in <figref idref="DRAWINGS">FIGS. <b>33</b>-<b>39</b></figref>. If a user selects to initiate a chat, for example by selecting the &#x201c;let's chat option&#x201d; of the screen <b>6570</b>, the chatbot interface may display a question related to the goal such as &#x201c;How are you feeling about the goal so far?&#x201d; with optional user responses such as &#x201c;So far, so good!&#x201d; and &#x201c;I'm struggling a bit,&#x201d; as shown in screen <b>6570</b>. The chatbot can provide different recommendations to the user depending on the user's answer. For example, if the user indicates &#x201c;So far, so good,&#x201d; the chatbot can provide a message such as &#x201c;That's great. Remember: It's important to be kind to yourself when &#x2018;the number&#x2019; isn't what you'd hoped for&#x201d; with a link to a first article such as &#x201c;Understanding if Your Diabetes Management Plan is Working.&#x201d; If the user indicates &#x201c;I'm struggling a bit,&#x201d; the chatbot can provide a message such as &#x201c;Hang in there. Developing a new habit isn't easy at first, but you've made a great start just by trying for this goal&#x201d; with a link to a second article such as &#x201c;How to Stay Motivated.&#x201d;</p><p id="p-0245" num="0236"><figref idref="DRAWINGS">FIGS. <b>23</b>, <b>24</b>, and <b>25</b></figref> are example screen captures of a logging module of a user interface of an IDM system according to an embodiment. <figref idref="DRAWINGS">FIG. <b>23</b></figref> illustrates an example screen <b>8600</b> of a logging module. As shown, the screen <b>8600</b> includes a prompt asking the user, &#x201c;Hey, Daniel, how have you been?&#x201d; Following the prompts, the screen <b>8600</b> includes one or more potential data entry sources. For example, the screen <b>8600</b> includes data entry sources for blood sugar, Lantus&#xae; (a diabetes medication), activity, sleep, no soda, and walk 10,000 steps. Accordingly, the screen <b>8600</b> provides a simple method by which the user can enter data in each of these categories. Other categories may be included in other embodiments. Not all categories need be included in all embodiments.</p><p id="p-0246" num="0237">As shown, the data entry categories can relate to various information pertinent to diabetes care. For example, data entry sources or categories can be included for various things such as physical measurements related to diabetes care such as blood sugar measurements, dosing information for medications taken related to diabetes (such as insulin and others), activity information such as a number of steps or number of minutes performing physical activity, number of hours slept, etc. Additionally data entry sources or categories can include items related to goals. For example, as illustrated, data entry sources or categories for &#x201c;no soda&#x201d; and &#x201c;walk 10,000 steps,&#x201d; goals described previously above in relation to the goals module, can be included.</p><p id="p-0247" num="0238">The user can enter data for any of the data categories by selecting the data category on the screen <b>8600</b>. Additional data categories may be available by scrolling down. The screen <b>8600</b> also includes a voice data entry button <b>8602</b> that the user can select to enter data vocally. Selecting the voice data entry by an <b>8602</b> may allow the user to speak the data that the user wishes to enter into the logging module. The logging module will then input the user's natural language and record the entered data as a voice file. The screen <b>8600</b> also includes a voice data entry button <b>8602</b> that the user can select to enter data vocally. Selecting the voice data entry button <b>8602</b> may allow the user to speak the data that the user wishes to enter into the logging module, and the logging module will parse the natural language and record the data.</p><p id="p-0248" num="0239"><figref idref="DRAWINGS">FIG. <b>24</b></figref> illustrates an example screen <b>8800</b> that can be displayed to the user after speaking one of the sample logging phrases. As shown, the user has spoken &#x201c;my blood sugar is 105 mg/dl&#x201d; and &#x201c;I took <b>12</b> units of Humalog.&#x201d; additional sample logging phrases are still displayed to the user providing additional prompts for logging data. Further, the screen <b>8800</b> can prompt the user to enter additional information by saying &#x201c;you can say another phrase as shown.&#x201d; As shown in <figref idref="DRAWINGS">FIG. <b>24</b></figref>, as the user enters data through the logging prompts the logging module transcribes the user spoken data onto the screen. This can allow the user to verify that the spoken data has been transcribed correctly. When the user selects done, each of the spoken data entries can be saved did IDM system for future use.</p><p id="p-0249" num="0240"><figref idref="DRAWINGS">FIG. <b>25</b></figref> illustrates an example screen <b>9000</b> that can be shown after data has been entered. The data may have been entered manually, for example by typing, or vocally by speaking as shown in the preceding examples. The screen <b>9000</b> presents the user with the data so that the user can verify and save the data.</p><p id="p-0250" num="0241"><figref idref="DRAWINGS">FIG. <b>26</b></figref> is an example screen capture of a data module of a user interface of an IDM system according to an embodiment. The data module can be configured to provide contextualized insights on the data screen based on the information available. Such information can include data entered by the user, for example, the logging module, or other data known the IDM system. Further, the data module can provide contextualized insights related to the data or content that the user is currently looking at. For example, if the user is looking at data, the data module will give contextual insights based on the data. As another example, if the user is looking at curriculum (for example, in the learn module), the user can be presented with contextual insights based on the curriculum. The data module can be configured to analyze combinations of data sets to produce insights, and then engage with the user with the chatbot, notifications, or other prompts. In some embodiments, example data sets include insulin, blood sugar, steps, and sleep. Analysis of the data sets can be defined by rules (as described above) or other algorithms</p><p id="p-0251" num="0242"><figref idref="DRAWINGS">FIG. <b>26</b></figref> illustrates an example screen <b>9100</b> that includes a contextualized insight as described above. In this example, the user is viewing data related to blood sugar. A graph depicts the user's blood sugar over the past week. The data module can analyze this data while the user is viewing it and provide a contextualized insight in the form of a comment or notification. As shown, the screen <b>9100</b> displays &#x201c;Your blood sugar has been out of target range for the last four Wednesdays. Are you doing something different? Let's chat about it.&#x201d; In this case, this system has analyzed the blood sugar data set and determined that the user is consistently out of target range on Wednesdays, and then has engaged the user to determine why this may be. The screen <b>9100</b> includes a prompt that would allow the user to enter the chatbot so as to engage with the system through natural language, either entered on a keyboard or spoken vocally.</p><p id="p-0252" num="0243">The screen <b>9100</b> also includes a menu with icons that take the user to different modules of the IDM system. For example, the menu includes the icon <b>4304</b> for accessing the data module, the icon <b>4305</b> for accessing the learn module, the icon <b>4306</b> for accessing the goals module, the icon <b>4307</b> for accessing the chatbot module, and the icon <b>4308</b> for entering user data with a logging module. These icons may also appear on the home screen <b>4300</b>, as shown in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, described above. These icons can allow for quick and easy access to other modules directly from within the learn module.</p><heading id="h-0012" level="2">Example Implementing Systems</heading><p id="p-0253" num="0244">Implementations disclosed herein provide systems and methods for IDM systems and related devices or modules. One skilled in the art will recognize that these embodiments may be implemented in hardware, software, firmware, or any combination thereof. Those of skill would further appreciate that the various illustrative logical blocks, modules, circuits, and algorithm steps described in connection with the embodiments disclosed herein may be implemented as electronic hardware, computer software, or combinations of both. To clearly illustrate this interchangeability of hardware and software, various illustrative components, blocks, modules, circuits, and steps have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans may implement the described functionality in varying ways for each particular application, but such implementation decisions should not be interpreted as causing a departure from the scope of the present invention. A software module may reside in random access memory (RAM), flash memory, ROM, EPROM, EEPROM, registers, hard disk, a removable disk, a CD-ROM, or any other form of storage medium known in the art. An exemplary storage medium is coupled to the processor such the processor can read information from, and write information to, the storage medium. In the alternative, the storage medium may be integral to the processor. In other words, the processor and the storage medium may reside in an integrated circuit or be implemented as discrete components.</p><p id="p-0254" num="0245">The functions described herein may be stored as one or more instructions on a processor-readable or computer-readable medium. The term &#x201c;computer-readable medium&#x201d; refers to any available medium that can be accessed by a computer or processor. By way of example, and not limitation, such a medium may comprise RAM, ROM, EEPROM, flash memory, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices, or any other medium that can be used to store desired program code in the form of instructions or data structures and that can be accessed by a computer. Disk and disc, as used herein, includes compact disc (CD), laser disc, optical disc, digital versatile disc (DVD), floppy disk and Blu-ray&#xae; disc where disks usually reproduce data magnetically, while discs reproduce data optically with lasers. It should be noted that a computer-readable medium may be tangible and non-transitory. The term &#x201c;computer-program product&#x201d; refers to a computing device or processor in combination with code or instructions (e.g., a &#x201c;program&#x201d;) that may be executed, processed or computed by the computing device or processor. As used herein, the term &#x201c;code&#x201d; may refer to software, instructions, code or data that is/are executable by a computing device or processor.</p><p id="p-0255" num="0246">Software or instructions may also be transmitted over a transmission medium. For example, if the software is transmitted from a website, server, or other remote source using a coaxial cable, fiber optic cable, twisted pair, digital subscriber line (DSL), or wireless technologies such as infrared, radio, and microwave, then the coaxial cable, fiber optic cable, twisted pair, DSL, or wireless technologies such as infrared, radio, and microwave are included in the definition of transmission medium.</p><p id="p-0256" num="0247">The methods disclosed herein comprise one or more steps or actions for achieving the described method. The method steps and/or actions may be interchanged with one another without departing from the scope of the claims. In other words, unless a specific order of steps or actions is required for proper operation of the method that is being described, the order and/or use of specific steps and/or actions may be modified without departing from the scope of the claims.</p><p id="p-0257" num="0248">It should be noted that the terms &#x201c;couple,&#x201d; &#x201c;coupling,&#x201d; &#x201c;coupled&#x201d; or other variations of the word couple as used herein may indicate either an indirect connection or a direct connection. For example, if a first component is &#x201c;coupled&#x201d; to a second component, the first component may be either indirectly connected to the second component or directly connected to the second component. As used herein, the term &#x201c;plurality&#x201d; denotes two or more. For example, a plurality of components indicates two or more components.</p><p id="p-0258" num="0249">The term &#x201c;determining&#x201d; encompasses a wide variety of actions and, therefore, &#x201c;determining&#x201d; can include calculating, computing, processing, deriving, investigating, looking up (e.g., looking up in a table, a database or another data structure), ascertaining and the like. Also, &#x201c;determining&#x201d; can include receiving (e.g., receiving information), accessing (e.g., accessing data in a memory) and the like. Also, &#x201c;determining&#x201d; can include resolving, selecting, choosing, establishing and the like.</p><p id="p-0259" num="0250">The phrase &#x201c;based on&#x201d; does not mean &#x201c;based only on,&#x201d; unless expressly specified otherwise. In other words, the phrase &#x201c;based on&#x201d; describes both &#x201c;based only on&#x201d; and &#x201c;based at least on.&#x201d;</p><p id="p-0260" num="0251">In the foregoing description, specific details are given to provide a thorough understanding of the examples. However, it will be understood by one of ordinary skill in the art that the examples may be practiced without these specific details. For example, electrical components/devices may be shown in block diagrams in order not to obscure the examples in unnecessary detail. In other instances, such components, other structures and techniques may be shown in detail to further explain the examples.</p><p id="p-0261" num="0252">It is also noted that the examples may be described as a process, which is depicted as a flowchart, a flow diagram, a finite state diagram, a structure diagram, or a block diagram. Although a flowchart may describe the operations as a sequential process, many of the operations can be performed in parallel, or concurrently, and the process can be repeated. In addition, the order of the operations may be re-arranged. A process is terminated when its operations are completed. A process may correspond to a method, a function, a procedure, a subroutine, a subprogram, etc. When a process corresponds to a software function, its termination corresponds to a return of the function to the calling function or the main function.</p><p id="p-0262" num="0253">The previous description of the disclosed implementations is provided to enable any person skilled in the art to make or use the present invention. Various modifications to these implementations will be readily apparent to those skilled in the art, and the generic principles defined herein may be applied to other implementations without departing from the spirit or scope of the invention. Thus, the present invention is not intended to be limited to the implementations shown herein but is to be accorded the widest scope consistent with the principles and novel features disclosed herein.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for displaying content items to a user based on selected goals from the user, the method comprising:<claim-text>performing an initial assessment of a user, wherein performing the initial assessment comprises:<claim-text>retrieving at least one of measured patient disease management data and user-inputted patient disease management data from a user database;</claim-text><claim-text>requesting additional information from the user for determining one or more goals; and</claim-text><claim-text>receiving the additional information from the user via a user interface;</claim-text></claim-text><claim-text>recommending a plurality of goals to the user based on the at least one of measured patient disease management data and user-inputted patient disease management data and the additional information from the user received while performing the initial assessment and stored protocols related to disease management retrieved from a content database;</claim-text><claim-text>receiving a selection of a goal from the plurality of goals from the user via the user interface;</claim-text><claim-text>receiving goal tracking information indicative of progress toward the selected goal, the goal tracking information comprising at least one of measured patient disease management data related to the selected goal and user-inputted patient disease management data related to the selected goal;</claim-text><claim-text>selecting one or more content items from the content database based on at least one of the selected goal and the goal tracking information; and</claim-text><claim-text>displaying the selected one or more content items to the user via the user interface.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein recommending a plurality of goals comprises recommending one or more categories of goals.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein each category of goals includes a plurality of goals having different difficulty levels.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the one or more categories of goals comprises one or more of blood glucose goals, insulin goals, exercise or activity goals, nutrition goals, and risk reduction goals.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein recommending a plurality of goals comprises recommending one or more difficulty levels of goals.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one of measured patient disease management data and user-inputted patient disease management data retrieved in performing the initial assessment comprises at least one of fitness data, health data, and treatment adherence data.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein requesting additional information from the user for determining one or more goals comprises requesting additional information related to at least one of areas of interest, strengths, and weaknesses.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>determining completion of the selected goal based on the goal tracking information; and</claim-text><claim-text>determining a recommendation for a new goal after completion of the selected goal based at least in part on the goal tracking information.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the new goal comprises a goal having a higher difficulty than the selected goal or belonging to a different category of goals from the selected goal.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>determining failure of the selected goal based on the goal tracking information; and</claim-text><claim-text>determining a recommendation for a new goal after failure of the selected goal based at least in part on the goal tracking information.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the new goal comprises a goal having a lower difficulty than the selected goal or belonging to a different category of goals from the selected goal.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>determining failure of the selected goal based on the goal tracking information; and</claim-text><claim-text>repeating performing the initial assessment of the user in response to determining failure of the selected goal.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more content items comprise a prompt to initiate a communication with a chatbot.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more content items comprise an article or recipe related to the selected goal.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein selecting one or more content items from the content database is based at least partially on a predetermined time duration within a duration of the selected goal.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein selecting one or more content items from the content database is based at least partially on a determined level of progress towards completing the selected goal based on the goal tracking information.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein selecting one or more content items from the content database is based at least partially on a request received from the user via the user interface.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein selecting one or more content items from the content database is based at least partially on information received from the user during a communication with a chatbot.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A goal management system, comprising:<claim-text>a user database comprising at least one of measured patient disease management data and user-inputted patient disease management data;</claim-text><claim-text>a content database comprising content items related to recommended lifestyle choices and protocols for disease management;</claim-text><claim-text>an interactive user interface configured to display and receive user information; and</claim-text><claim-text>a memory having instructions that when run on a processor will perform a method comprising:<claim-text>performing an initial assessment of a user, wherein performing the initial assessment comprises:<claim-text>retrieving at least one of measured patient disease management data and user-inputted patient disease management data from the user database;</claim-text><claim-text>requesting additional information from the user for determining one or more goals via the user interface; and</claim-text><claim-text>receiving the additional information from the user via the user interface;</claim-text></claim-text><claim-text>recommending a plurality of goals to the user based on the at least one of measured patient disease management data and user-inputted patient disease management data and the additional information from the user received while performing the initial assessment and stored protocols related to disease management retrieved from the content database;</claim-text><claim-text>receiving a selection of a goal from the plurality of goals from the user via the user interface;</claim-text><claim-text>receiving goal tracking information indicative of progress toward the selected goal, the goal tracking information comprising at least one of measured patient disease management data related to the selected goal and user-inputted patient disease management data related to the selected goal;</claim-text><claim-text>selecting one or more content items from the content database based on at least one of the selected goal and the goal tracking information; and</claim-text><claim-text>displaying the selected one or more content items to the user via the user interface.</claim-text></claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein recommending a plurality of goals comprises recommending one or more categories of goals.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein each category of goals includes a plurality of goals having different difficulty levels.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the one or more categories of goals comprises one or more of blood glucose goals, insulin goals, exercise or activity goals, nutrition goals, and risk reduction goals.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein recommending a plurality of goals comprises recommending one or more difficulty levels of goals.</claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the at least one of measured patient disease management data and user-inputted patient disease management data retrieved in performing the initial assessment comprises at least one of fitness data, health data, and treatment adherence data.</claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein requesting additional information from the user for determining one or more goals comprises requesting additional information related to at least one of areas of interest, strengths, and weaknesses.</claim-text></claim><claim id="CLM-00026" num="00026"><claim-text><b>26</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the memory comprises instructions that when run on the processor will perform a method comprising:<claim-text>determining completion of the selected goal based on the goal tracking information; and</claim-text><claim-text>determining a recommendation for a new goal after completion of the selected goal based at least in part on the goal tracking information.</claim-text></claim-text></claim><claim id="CLM-00027" num="00027"><claim-text><b>27</b>. The system of <claim-ref idref="CLM-00026">claim 26</claim-ref>, wherein the new goal comprises a goal having a higher difficulty than the selected goal or belonging to a different category of goals from the selected goal.</claim-text></claim><claim id="CLM-00028" num="00028"><claim-text><b>28</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the memory comprises instructions that when run on the processor will perform a method comprising:<claim-text>determining failure of the selected goal based on the goal tracking information; and</claim-text><claim-text>determining a recommendation for a new goal after failure of the selected goal based at least in part on the goal tracking information.</claim-text></claim-text></claim><claim id="CLM-00029" num="00029"><claim-text><b>29</b>. The system of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the new goal comprises a goal having a lower difficulty than the selected goal or belonging to a different category of goals from the selected goal.</claim-text></claim><claim id="CLM-00030" num="00030"><claim-text><b>30</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the memory comprises instructions that when run on the processor will perform a method comprising:<claim-text>determining failure of the selected goal based on the goal tracking information; and</claim-text><claim-text>repeating performing the initial assessment of the user in response to determining failure of the selected goal.</claim-text></claim-text></claim><claim id="CLM-00031" num="00031"><claim-text><b>31</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising a chatbot, wherein the one or more content items comprise a prompt to initiate a communication with the chatbot.</claim-text></claim><claim id="CLM-00032" num="00032"><claim-text><b>32</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the one or more content items comprise an article or recipe related to the selected goal.</claim-text></claim><claim id="CLM-00033" num="00033"><claim-text><b>33</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein selecting one or more content items from the content database is based at least partially on a predetermined time duration within a duration of the selected goal.</claim-text></claim><claim id="CLM-00034" num="00034"><claim-text><b>34</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein selecting one or more content items from the content database is based at least partially on a determined level of progress towards completing the selected goal based on the goal tracking information.</claim-text></claim><claim id="CLM-00035" num="00035"><claim-text><b>35</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein selecting one or more content items from the content database is based at least partially on a request received from the user via the user interface.</claim-text></claim><claim id="CLM-00036" num="00036"><claim-text><b>36</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising a chatbot, wherein selecting one or more content items from the content database is based at least partially on information received from the user during a communication with a chatbot.</claim-text></claim></claims></us-patent-application>
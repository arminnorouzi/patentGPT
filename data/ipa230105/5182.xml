<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005183A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005183</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17943738</doc-number><date>20220913</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>18178983.5</doc-number><date>20180621</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20170101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>80</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>7</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20200101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>931</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>07</class><subclass>C</subclass><main-group>5</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>9</main-group><subgroup>31</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>R</subclass><main-group>11</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20200101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>13</main-group><subgroup>931</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>7</main-group><subgroup>497</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>80</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>7</main-group><subgroup>4021</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>931</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>07</class><subclass>C</subclass><main-group>5</main-group><subgroup>0808</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>9</main-group><subgroup>3185</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>R</subclass><main-group>11</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>13</main-group><subgroup>931</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>7</main-group><subgroup>4972</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>07</class><subclass>C</subclass><main-group>5</main-group><subgroup>0841</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30252</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>R</subclass><main-group>2300</main-group><subgroup>402</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">SYSTEM AND METHOD OF CALIBRATING AN OPTICAL SENSOR MOUNTED ON BOARD OF A VEHICLE</invention-title><us-related-documents><continuation-in-part><relation><parent-doc><document-id><country>US</country><doc-number>17701362</doc-number><date>20220322</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17943738</doc-number></document-id></child-doc></relation></continuation-in-part><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16447918</doc-number><date>20190620</date></document-id><parent-status>ABANDONED</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17701362</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Mahle Aftermarket Italy S.p.A.</orgname><address><city>Paema</city><country>IT</country></address></addressbook><residence><country>IT</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Cantadori</last-name><first-name>Andrea</first-name><address><city>Parma</city><country>IT</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Scaramuzza</last-name><first-name>Tiberio</first-name><address><city>Parma</city><country>IT</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A system and method for calibrating a vehicle optical sensor includes positioning the vehicle in a test station having a projection surface in view of the optical sensor, positioning targets on two hubs of the vehicle, and positioning lasers left to right that are mounted on a graduated mounting bar in front of the vehicle. The graduated mounting bar includes gradations indicative of a lateral position of the lasers on the graduated mounting bar. The lasers are configured to obtain a distance to the targets and distances along respective axes and between the lasers. The calibration is performed based on the obtained distances and once the vehicle's position in the test station is known with respect to the test station.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="78.40mm" wi="158.75mm" file="US20230005183A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="209.97mm" wi="161.29mm" orientation="landscape" file="US20230005183A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="237.49mm" wi="137.33mm" orientation="landscape" file="US20230005183A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="237.57mm" wi="137.33mm" orientation="landscape" file="US20230005183A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="235.20mm" wi="157.82mm" file="US20230005183A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="216.49mm" wi="165.86mm" file="US20230005183A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="229.19mm" wi="169.84mm" orientation="landscape" file="US20230005183A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="240.96mm" wi="163.07mm" orientation="landscape" file="US20230005183A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="241.47mm" wi="150.79mm" orientation="landscape" file="US20230005183A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="206.42mm" wi="159.09mm" file="US20230005183A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CLAIM FOR PRIORITY</heading><p id="p-0002" num="0001">This application is Continuation-In-Part (CIP) of U.S. application Ser. No. 17/701,362, which was filed on Mar. 22, 2022, which is a Continuation of U.S. application Ser. No. 16/447,918 filed on Jun. 20, 2019 and now abandoned, which claims priority to European Application No. 18178983.5, which was filed on Jun. 21, 2018, the contents of which are fully incorporated by reference herein in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">The subject matter described herein relates to a system and method of calibrating an optical sensor mounted on board of a vehicle.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Over recent years, the attention of those developing the safety of motor vehicles has extended from the traditional passive safety systems (airbags, seat belts, impact resistance, etc.) to advanced active safety systems, known to specialists as Advanced Driver Assistance Systems ADAS.</p><p id="p-0005" num="0004">ADAS are electronic driving assistance systems for vehicles that support the driver for the purpose of increasing safety and/or driving comfort. Such systems have been classified into six levels according to the degree of autonomy, as indicated below:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0005">Level 0 (no automation): the driver is in charge of all the driving aspects, even when he/she is facilitated by the systems installed on board of the vehicle.</li>        <li id="ul0002-0002" num="0006">Level 1 (driver assistance): in some situations the vehicle can accelerate, brake or steer autonomously, but the driver must be ready at all times to regain control of the vehicle.</li>        <li id="ul0002-0003" num="0007">Level 2 (partial automation): the vehicle has full control of the accelerator, brake and steering, but the driver must still monitor the surrounding environment.</li>        <li id="ul0002-0004" num="0008">Level 3 (conditioned automation): the vehicle has full control of the accelerator, brake, steering and monitoring of the environment, but the driver must be ready to intervene if required by the system.</li>        <li id="ul0002-0005" num="0009">Level 4 (high automation): the automatic system is able to handle any event, but must not be activated in extreme driving conditions such as in bad weather.</li>        <li id="ul0002-0006" num="0010">Level 5 (complete automation): the automatic driving system is able to handle all driving situations; there is no longer any need for intervention by a human driver.</li>    </ul>    </li></ul></p><p id="p-0006" num="0011">Currently, vehicles are often equipped with level 3 systems. The objective over coming years is to reach level 5.</p><p id="p-0007" num="0012">By way of example, ADAS that are already widespread include adaptive cruise control, automatic full-beam headlamp adjustment, automatic headlamp orientation, automatic parking system, navigation system with traffic information, night vision system, blind spot monitor, frontal collision warning system, automatic emergency braking, etc.</p><p id="p-0008" num="0013">At the technological level, ADAS are based on sensors (e.g., television cameras, radar, Lidar, etc.) able to detect different information that can possibly be used as the input data for a smart algorithm that oversees the degree of autonomy of the vehicle.</p><p id="p-0009" num="0014">Before the vehicle is placed on the market, the sensors are typically calibrated directly by the manufacturer. For example, the initial calibration of a television camera is performed through a simulation environment specifically provided by the manufacturer in which the television camera is placed opposite a monitor onto which settable dynamic scenarios are projected (e.g. a pedestrian crossing the road).</p><p id="p-0010" num="0015">After the vehicle has been placed on the market, the sensors are calibrated periodically (e.g. when the vehicle is serviced) or after exceptional events (e.g., replacement of the sensor following a defect, damage due to an accident, or if there is breakdown warning).</p><p id="p-0011" num="0016">Often, ADAS include features that include manual measurement of various features of the vehicle being calibrated and/or of the calibration system itself with respect to the vehicle. The measurements may include manual measurement (such as with a tape measure) of a relative location of a vehicle with respect to feature of the test bay, or manual measurement of the vehicle with respect to a projection screen and the like. The measurements may include physical horizontal distances or vertical distances off of, for instance, a floor in the bay. In some instances, manual measurements are made with respect to an arbitrarily placed target that, when positioned in the test bay, provide feature(s) that themselves must be measured for relative location in order to determine a relative location of the vehicle with respect to the test bay. Measurements are made by a technician and manually transcribed into a computer system that performs the calibration. However, such systems can be time consuming, cumbersome, and can be prone to human error, as there can be any number of measurements that must be performed and then transcribed to the computer to determine the vehicle's relative position.</p><p id="p-0012" num="0017">Thus, there is a need for an improved ADAS.</p><heading id="h-0004" level="1">BRIEF SUMMARY</heading><p id="p-0013" num="0018">According to one aspect, a calibration system for calibrating an optical sensor on board a vehicle. The system includes a control unit, a projection screen having a projection surface positionable within a test station and viewable by an optical sensor positioned in a vehicle, the projection surface electrically coupled to the control unit, and a graduated mounting bar having gradations indicative of a lateral position of the graduated mounting bar. A first target is positionable on a first hub of the vehicle, a second target positionable on a second hub of the vehicle, a first laser mounted to the graduated mounting bar and positionable left to right with respect to the vehicle and along the graduated mounting bar, the first laser electrically coupled to the control unit, the first laser configured to obtain a first distance to the first target along a first axis, and a second laser mounted to the graduated mounting bar and positionable left to right with respect to the vehicle and along the graduated mounting bar, the second laser electrically coupled to the control unit, the second laser configured to obtain a second distance to the second target along a second axis. The control unit is configured to automatically obtain the first distance from the first laser, obtain the second distance from the second laser, obtain a lateral distance from the first laser to the second laser along a third axis that is orthogonal to the first axis and to the second axis, and based on the gradations, and calibrate the optical sensor based on the obtained first distance, the second distance, and the lateral distance.</p><p id="p-0014" num="0019">According to another aspect, a method of calibrating an optical sensor on board a vehicle, includes positioning a vehicle in a test station and proximate a projection surface, the vehicle having an optical sensor, the projection surface in view of the optical sensor, positioning a first target on a first hub of the vehicle, and positioning a second target on a second hub of the vehicle. The method further includes positioning a first laser left to right, the first laser mounted on a graduated mounting bar that is in front of the vehicle, the graduated mounting bar having gradations indicative of a lateral position of the first laser on the graduated mounting bar, the first laser configured to obtain a first distance to the first target along a first axis, positioning a second laser left to right, the second laser mounted on the graduated mounting bar, the second laser configured to obtain a second distance along a second axis to the second target based on a position on of the second laser on the graduated mounting bar, obtaining the first distance from the first laser, obtaining the second distance from the second laser, obtaining a lateral distance along a third axis from the first laser to the second laser based on the gradations, the third axis orthogonal to the first axis and to the second axis, and calibrating the optical sensor based on the obtained first distance, the second distance, and the lateral distance.</p><p id="p-0015" num="0020">The foregoing is a summary and thus may contain simplifications, generalizations, and omissions of detail; consequently, those skilled in the art will appreciate that the summary is illustrative only and is not intended to be in any way limiting.</p><p id="p-0016" num="0021">For a better understanding of the embodiments, together with other and further features and advantages thereof, reference is made to the following description, taken in conjunction with the accompanying drawings. The scope of the invention will be pointed out in the appended claims.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGS</heading><p id="p-0017" num="0022"><figref idref="DRAWINGS">FIG. <b>1</b></figref> schematically illustrates a system of calibrating an optical sensor mounted on board of a vehicle, according to an embodiment;</p><p id="p-0018" num="0023"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an arrangement of a vehicle in a test station and a projection surface of the calibration system of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in a perspective view, in which the projection surface projects a pattern;</p><p id="p-0019" num="0024"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an arrangement of a vehicle in a test station and a projection surface of the calibration system of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in a perspective view, in which the projection surface projects a photo or video;</p><p id="p-0020" num="0025"><figref idref="DRAWINGS">FIG. <b>4</b></figref> schematically illustrates the communication between a scan tool and a calibration unit of the calibration system of <figref idref="DRAWINGS">FIG. <b>1</b></figref>;</p><p id="p-0021" num="0026"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a laser target positioned on a hub of the vehicle;</p><p id="p-0022" num="0027"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates placement of the laser target of <figref idref="DRAWINGS">FIG. <b>5</b></figref> on a hub of the vehicle;</p><p id="p-0023" num="0028"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates use of a laser rangefinder to determine positional information on its mounting structure according to the disclosure;</p><p id="p-0024" num="0029"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a front view of the projection surface and including other aspects of the disclosed calibration system;</p><p id="p-0025" num="0030"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a top view of the vehicle and showing obtained distances and misalignment of the vehicle in the test station; and</p><p id="p-0026" num="0031"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a graphical illustration of a keystone effect for correction in the ADAS.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0027" num="0032">It will be readily understood that the components of the embodiments, as generally described and illustrated in the figures herein, may be arranged and designed in a wide variety of different configurations in addition to the described example embodiments. Thus, the following more detailed description of the example embodiments, as represented in the figures, is not intended to limit the scope of the embodiments, as claimed, but is merely representative of example embodiments.</p><p id="p-0028" num="0033">Reference throughout this specification to &#x201c;one embodiment&#x201d; or &#x201c;an embodiment&#x201d; (or the like) means that a particular feature, structure, or characteristic described in connection with the embodiment is included as part of the disclosure. Thus, the appearance of the phrases &#x201c;in one embodiment&#x201d; or &#x201c;in an embodiment&#x201d; or the like in various places throughout this specification are not necessarily all referring to the same embodiment.</p><p id="p-0029" num="0034">Furthermore, the described features, structures, or characteristics may be combined in any suitable manner in one or more embodiments. In the following description, numerous specific details are provided to give a thorough understanding of embodiments. One skilled in the relevant art will recognize, however, that the various embodiments can be practiced without one or more of the specific details, or with other methods, components, materials, et cetera. In other instances, well known structures, materials, or operations are not shown or described in detail to avoid obfuscation.</p><p id="p-0030" num="0035">Two types of calibration are typically performed in the aftermarket: static and dynamic.</p><p id="p-0031" num="0036">Static calibration is performed in a closed environment (generally the workshop) through a portable device&#x2014;known in the sector as a &#x201c;scan tool&#x201d;&#x2014;connected to the vehicle's EOBD (European On Board Diagnostic) diagnostic socket and using specific target panels for each type of sensor (e.g. photo camera, radar, Lidar, etc.) usually placed on the front of the stationary vehicle (they can also be positioned on the side or the rear of the vehicle). An example of such a calibration method is proposed in patent US 2013/0325252.</p><p id="p-0032" num="0037">The main criticality of the static calibration methods known to date is connected with a wide variety of parameters at stake. As manufacturers typically include ad hoc calibration settings for each vehicle model and for each type of sensor, workshops are generally affiliated to only some manufacturers, for which they are typically equipped with the related target panels (numerous ones as they differ in terms of shape, size and pattern).</p><p id="p-0033" num="0038">Furthermore, for reliable calibration, it is important to correct transverse and longitudinal alignment of the target panels with respect to the vehicle. At each calibration, the panel alignment step can take a long time.</p><p id="p-0034" num="0039">The movement of the panels also includes special care to prevent damage and breakages. In fact, the panels are made of plastic material, generally forex, and have a significant extension with respect to the thickness, which is reduced (usually max 5 mm).</p><p id="p-0035" num="0040">Furthermore, static calibration typically does not take place outdoors so there is a well-defined contrast of the panels.</p><p id="p-0036" num="0041">For some types of vehicles, static calibration is not sufficient, so an on-road test is desired.</p><p id="p-0037" num="0042">In that case, dynamic calibration methods are applied, i.e., performed while driving the vehicle. Two scenarios are possible:<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0043">dynamic calibration performed automatically by the vehicle systems while a generic driver is driving,</li>        <li id="ul0004-0002" num="0044">dynamic calibration using a scan tool connected to the vehicle's EOBD diagnostic socket for performing specific calibration procedures established by the manufacturer, performed by an authorized repairer.</li>    </ul>    </li></ul></p><p id="p-0038" num="0045">One problem with dynamic calibration is the fact that it is desirable to be performed under good weather conditions, with possible planning difficulties due to time availability of the vehicle, technicians, etc. . . . . A second problem is regarding the need to provide paths with determined characteristics (e.g., horizontal signage, vertical signage, etc.) for performing the calibration.</p><p id="p-0039" num="0046">Furthermore, during dynamic calibration the vehicle could have unexpected reactions (precisely due to calibration errors), which can put the driver's safety at risk.</p><p id="p-0040" num="0047">The aftermarket calibration methods known to date (static and dynamic) typically include long performance times to guarantee the reliability of the results.</p><p id="p-0041" num="0048">From US 2018/100783 it is already known a calibration system for optical sensors using a screen or other projection surface disposed within the field of view of an optical sensor system onboard a vehicle. From WO 2018/067354 it is disclosed an ADAS calibration support structure in which it is possible to project indicia on a screen and to correct parallax distortion by means of mechanical rotation of a laser emitter.</p><p id="p-0042" num="0049">From WO 2014/192347 it is also known an inspection system for an optical sensor. In U.S. Pat. No. 9,247,222 a projection display for images is disclosed, that may be applied to a vehicle. In DE 10 2006060 553 there is disclosed a method for testing a motor vehicle driver assistance system.</p><p id="p-0043" num="0050">In this context, the technical task underpinning an embodiment is to provide a system and method of calibrating an optical sensor mounted on board of a vehicle, that obviate the above-cited drawbacks.</p><p id="p-0044" num="0051">In particular, one embodiment provides a universal system of calibrating an optical sensor mounted on board of a vehicle, i.e. that can be used for the sensors of any vehicle, regardless of the manufacturer, the specific model and the ADAS being implemented and, at the same time, more reliable and compact with respect to known solutions.</p><p id="p-0045" num="0052">An embodiment provides a method for calibrating an optical sensor mounted on board of a vehicle that can be performed in a shorter time and more easily with respect to the calibration methods known to date.</p><p id="p-0046" num="0053">A further embodiment provides a system and method of calibrating an optical sensor mounted on board of a vehicle, which are reliably applicable also to vehicles that normally include an on-road test, i.e. dynamic calibration.</p><p id="p-0047" num="0054">The stated technical tasks are substantially achieved by a system of calibrating an optical sensor mounted on board of a vehicle, including a test station for the stationary vehicle, a projection surface for images or videos, which is located in front of the test station, at least one memory containing a plurality of images and/or videos archived by type of optical sensor, a calibration unit for calibrating the optical sensor configured to adjust the position of the optical axis of the optical sensor, and a control unit which, in response to a signal representing the type of the optical sensor. The control unit is configured to search in the memory for at least one image or video archived in association with the type of optical sensor, command the projection onto the projection surface of the image or video found in the memory or a processed version of the image or video, and interface with the calibration unit.</p><p id="p-0048" num="0055">In accordance with one embodiment, the control unit is also configured to determine, in response to the signal representing the type of optical sensor, a spatial position of the projection surface with respect to the optical sensor mounted on board of the vehicle arranged in the test station.</p><p id="p-0049" num="0056">In accordance with one embodiment, the control unit is also configured to adapt or deform the image or video found in the memory to the dimensions of the projection surface, in response to the signal representing the type of optical sensor.</p><p id="p-0050" num="0057">In accordance with one embodiment, the calibration system further includes a screen or monitor located in front of the test station, the projection surface being the display of said monitor.</p><p id="p-0051" num="0058">In accordance with one embodiment, the calibration system further includes a television set, said monitor being the monitor of said television set.</p><p id="p-0052" num="0059">In accordance with one embodiment, the calibration system further includes a multimedia interactive board, said monitor being the monitor of the multimedia interactive board.</p><p id="p-0053" num="0060">In accordance with one embodiment, the calibration system further includes a computer, said monitor being the monitor of the computer.</p><p id="p-0054" num="0061">In accordance with one embodiment, the projection surface is obtained from a sheet made of PVC.</p><p id="p-0055" num="0062">In accordance with one embodiment, the calibration system further includes a projector or a luminous board, said control unit being configured to command the projector or luminous board to project the image or video found in the memory onto the projection surface.</p><p id="p-0056" num="0063">Preferably, in response to the signal representing the type of optical sensor, the control unit is configured to project a set of parameters or initial calibration conditions onto said projection surface.</p><p id="p-0057" num="0064">The calibration system also includes an automatic means for adjusting the spatial position of the projection surface with respect to the test station.</p><p id="p-0058" num="0065">The stated technical task and specified objects are substantially achieved by a method of calibrating an optical sensor mounted on board of a vehicle, including the steps of positioning the vehicle in a test station, arranging a projection surface for images or videos in front of said test station, identifying the type of optical sensor, selecting in a memory an image or video associated with the type of said optical sensor, projecting the image or video selected or a processed version thereof onto the projection surface, and adjusting the position of the optical axis of the optical sensor starting from said projected image or video.</p><p id="p-0059" num="0066">In accordance with one embodiment, the calibration method further includes a step of determining, according to the type of optical sensor, a spatial measurement position that the projection surface assumes with respect to the optical sensor during calibration.</p><p id="p-0060" num="0067">In accordance with one embodiment, the calibration method further includes a step of adapting or deforming the image or video selected based on the size of the projection surface and the distance from the optical sensor.</p><p id="p-0061" num="0068">Further characteristics and advantages will become more apparent from the indicative and thus non-limiting description of a preferred, but not exclusive, embodiment of a system and method of calibrating an optical sensor mounted on board of a vehicle, as illustrated in the accompanying drawings.</p><p id="p-0062" num="0069">With reference to the figures, a calibration system <b>1</b> of calibrating includes an optical sensor <b>2</b> mounted on board of a vehicle <b>100</b>, in particular a motor vehicle such as an automobile, a bus, a lorry, a road tractor, a tractor trailer, an articulated lorry, a farm machinery, a working vehicle, a self-propelled vehicle, etc.</p><p id="p-0063" num="0070">As one example, optical sensor <b>2</b> is a CMOS or CCD type sensor of a television camera installed on vehicle <b>100</b>.</p><p id="p-0064" num="0071">Calibration system <b>1</b> includes a test station <b>3</b> for stationary vehicle <b>100</b>, and a projection surface <b>4</b> for projecting images or videos. Test station <b>3</b> included a horizontal or inclined support zone for supporting vehicle <b>100</b>. Stationary vehicle <b>100</b> is arranged in test station <b>3</b> according to techniques and as known, which are not the subject matter this disclosure.</p><p id="p-0065" num="0072">Projection surface <b>4</b> is arranged in front of test station <b>3</b> so that optical sensor <b>2</b> can acquire images or videos projected onto such projection surface <b>4</b>. In one example, projection surface <b>4</b> is rectangular shaped. In one example, calibration system <b>1</b> includes a screen or monitor, whose display constitutes projection surface <b>4</b>. The monitor including projection surface <b>4</b> may be a monitor of a television set <b>40</b>, as illustrated in <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>.</p><p id="p-0066" num="0073">In one example, the monitor of the television set <b>40</b> may be plasma, liquid crystal, OLED. In one example, a television set <b>40</b> can be used with a 65&#x2033; or greater anti-glare monitor. Alternatively, the monitor comprising the projection surface <b>4</b> is the monitor of a multimedia interactive whiteboard (often indicated by the acronym IWB), or the monitor of a computer.</p><p id="p-0067" num="0074">In accordance with another embodiment, calibration system <b>1</b> comprises a projector or a video projector or a luminous board that projects images or videos onto projection surface <b>4</b>, preferably made of (polarised or lenticular) high-contrast PVC fabric. For example, projection surface <b>4</b> is the surface of a fabric sheet which when unrolled and taut, has a planarity of +/&#x2212;2 millimetres per linear metre. Preferably, the fabric is opaque white so as to have a good contrast. Calibration system <b>1</b> includes a control unit <b>5</b> which receives at least one input signal (indicated as S<b>1</b>) representing the type of optical sensor <b>2</b>. In response to such signal S<b>1</b>, the control unit <b>5</b> is configured for selecting an image or a video in a memory <b>6</b>, and for commanding the projection onto the projection surface <b>4</b> of the image or video selected or a processed version thereof.</p><p id="p-0068" num="0075">In particular, memory <b>6</b> is part of calibration system <b>1</b> and contains a plurality of images and/or videos archived by type of optical sensor. In fact, on board of vehicle <b>100</b>, different television cameras, stereo pairs etc. can be installed. Each of such devices has optical sensors of different types that together form an ADAS. Above all, according to the manufacturer and the model, vehicle <b>100</b> has its own ADAS, therefore each optical sensor includes ad hoc calibration.</p><p id="p-0069" num="0076">The selection of the image or video by control unit <b>5</b> is performed by searching in memory <b>6</b> for at least one image or video that is archived in association with the type of that particular optical sensor <b>2</b> subject to calibration. For example, the image projected onto projection surface <b>4</b> can reproduce the shape, size and pattern of a target panel for the calibration of a specific optical sensor. In the case of a video, it is possible to display a real dynamic scenario or a simulated one, which reproduces an on-road test of the vehicle. For example, control unit <b>5</b> is housed in a portable device <b>20</b> (generally known in the sector as a scan tool) which can be connected to an EOBD diagnostic socket <b>31</b> of vehicle <b>100</b>.</p><p id="p-0070" num="0077">In one example, memory <b>6</b> can be housed in the same portable device <b>20</b>. Alternatively, memory <b>6</b> may be the computer memory, or an external memory (e.g., USB memory connectible directly to television set <b>40</b>).</p><p id="p-0071" num="0078">If projection surface <b>4</b> is composed of the fabric sheet, then control unit <b>5</b> is configured to command the projector or video projector or luminous board to project the image or video onto such projection surface <b>4</b>.</p><p id="p-0072" num="0079">Preferably, in a preliminary step it is necessary to configure calibration system <b>1</b>. For this reason, control unit <b>5</b> is configured to project onto projection surface <b>4</b> a set of parameters or initial calibration conditions, in response to the signal S<b>1</b> representing the type of optical sensor <b>2</b>.</p><p id="p-0073" num="0080">The calibration of optical sensor <b>2</b>, meaning the adjustment of the position of the optical axis, takes place by a calibration unit <b>30</b> that interfaces with the control unit <b>5</b>. Calibration unit <b>30</b> is preferably part of an electronic control unit for vehicle <b>100</b> and calibration unit <b>30</b> interfaces with control unit <b>5</b> of scan tool <b>20</b> through the connection to EOBD diagnostic socket <b>31</b>.</p><p id="p-0074" num="0081">In accordance with one embodiment, control unit <b>5</b> is also configured to determine a spatial position of projection surface <b>4</b> with respect to optical sensor <b>2</b> mounted on board of vehicle <b>100</b> arranged in test station <b>3</b>. Such determination is performed based on the signal S<b>1</b> representing the type of optical sensor <b>2</b>.</p><p id="p-0075" num="0082">Preferably, calibration system <b>1</b> also includes an automatic means for adjusting (i.e., regulating) the spatial position of projection surface <b>4</b> with respect to test station <b>3</b>, which is known type and will not be described further. The position adjustment of projection surface <b>4</b> is usually used in the event in which vehicle <b>100</b> is placed on a horizontal support surface.</p><p id="p-0076" num="0083">In accordance with another embodiment, control unit <b>5</b> is also configured to process the images or videos resident in memory <b>6</b>. In particular, control unit <b>5</b> is configured to adapt or deform the selected image or video to the size of the projection surface <b>4</b>. Such adaptation is performed in response to the signal S<b>1</b> representing the type of optical sensor <b>2</b>.</p><p id="p-0077" num="0084">For example, if vehicle <b>100</b> in test station <b>3</b> is placed on an inclined plane, the image or video is to be deformed rather than adjusting the spatial position of projection surface <b>4</b> with respect to optical sensor <b>2</b>. For example, the support plane for vehicle <b>100</b> is inclined forwards by a maximum of 1&#xb0; with respect to the horizontal. Or, as another example, the support plane for vehicle <b>100</b> is inclined backwards by a maximum of 3&#xb0; with respect to the horizontal.</p><p id="p-0078" num="0085">It is also envisaged that control unit <b>5</b> is configured to perform both a determination of the spatial position of projection surface <b>4</b> with respect to optical sensor <b>2</b> mounted on board of vehicle <b>100</b> in test station <b>3</b> and a deformation of the selected images or videos. In that case, the determination of the spatial position is rough, and is performed from a deformed projection of the image or video.</p><p id="p-0079" num="0086">The method of calibrating an optical sensor mounted on board of a vehicle, according to an embodiment, is described below.</p><p id="p-0080" num="0087">First, vehicle <b>100</b> is parked in test station <b>3</b>, according to known techniques, as already mentioned above. Projection surface <b>4</b> (e.g., the display of a monitor) is arranged in front of test station <b>3</b> and is transverse to the longitudinal axis AA of vehicle <b>100</b>, as seen in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The operator then connects portable device <b>20</b> (scan tool) to EOBD diagnostic socket <b>31</b> of vehicle <b>100</b>.</p><p id="p-0081" num="0088">Portable device <b>20</b> has a screen <b>21</b> on which a graphical interface is displayed, configured to allow text or instructions to be entered by an operator. In particular, the operator can select which vehicle <b>100</b> to be calibrated, by choosing from different types of vehicles split into brands (manufacturers) and models. Alternatively, portable device <b>20</b> performs such selection automatically or semi-automatically, asking the operator to confirm that vehicle <b>100</b> detected is the correct one.</p><p id="p-0082" num="0089">The operator also selects the ADAS to be calibrated, specifically which optical sensor <b>2</b> to be calibrated. Also in this case, the selection can take place manually, automatically or semi-automatically. These detection or selection steps of vehicle <b>100</b> and of the type of optical sensor <b>2</b> to be calibrated are known in themselves and therefore are not the subject matter of this disclosure.</p><p id="p-0083" num="0090">Once the type of optical sensor <b>2</b> has been identified, control unit <b>5</b> (in scan tool <b>20</b>) can determine the spatial measurement position that the monitor assumes with respect to optical sensor <b>2</b> during calibration. Such determination takes place, for example, in the case of vehicle <b>100</b> placed on a horizontal support surface. The spatial measurement position is preferably displayed in the form of instructions on projection surface <b>4</b>.</p><p id="p-0084" num="0091">It is known that the mutual position of the optical sensor and its target (in this case the display or, in general, the projection surface) is adjusted according to the type of optical sensor and the position that it occupies in vehicle <b>100</b>. Preferably, other parameters or initial calibration conditions are also projected onto projection surface <b>4</b>.</p><p id="p-0085" num="0092">The operator then manually adjusts projection surface <b>4</b> until the latter assumes the spatial measurement position. Alternatively, the adjustment of the position of projection surface <b>4</b> takes place automatically. Once this adjustment has been performed, the operator confirms to portable device <b>20</b> (still through the graphical interface that can be loaded onto its screen <b>21</b>) that the preliminary step has been performed and the actual calibration can take place. The operator can choose whether to perform a calibration with a static image or a dynamic video.</p><p id="p-0086" num="0093">Control unit <b>5</b> searches inside memory <b>6</b> for the image (in the former case) or the video (in the latter case) associated with the type of optical sensor <b>2</b> to be calibrated. The image or video selected can then be displayed on the projection surface <b>4</b>. Once the target (which in this case is projection surface <b>4</b>) has been adjusted and the image or video has been projected, the calibration is performed by calibration unit <b>30</b> which communicates with scan tool <b>20</b>. The actual calibration, meaning the adjustment of the position of the optical axis of optical sensor <b>2</b>, takes place according to an algorithm of the known type.</p><p id="p-0087" num="0094">Once optical sensor <b>2</b> has been calibrated, the operator can easily repeat the aforesaid method for other optical sensors located on board of vehicle <b>100</b>. Alternative to the determination of the spatial position that projection surface <b>4</b> has, and its subsequent adjustment, it is possible to project a deformed image or video onto projection surface <b>4</b>. Such solution, used in particular when vehicle <b>100</b> is on a horizontal support surface, is particularly advantageous because it prevents having to adjust the position of projection surface <b>4</b>.</p><p id="p-0088" num="0095">Finally, it is also possible to adopt a combined solution, in which the spatial adjustment is performed on both the position of projection surface <b>4</b> and a projection of the deformed image/video.</p><p id="p-0089" num="0096">A similar calibration system may also be applied for the calibration of a radar mounted on board of a vehicle, i.e., a frontal radar.</p><p id="p-0090" num="0097">According to prior art solutions, the calibration of the frontal radar is achieved by means of a plane reflector arranged at a certain distance D from the radar and perpendicular to the axis of the radar. Usually, the manufacturers declare a certain tolerance &#x394;D range for the distance D, i.e., D&#xb1;&#x394;D, in the arrangement of the plane reflector with respect to the radar. Nevertheless, it is well-known in this field that a deviation, even of a few degrees, in the orthogonal arrangement of the plane reflector with respect to the radar can result in failure of the calibration.</p><p id="p-0091" num="0098">Applying to the frontal radar a system and the method similar proposed herewith for the optical sensor, the user simply places the plane reflector in front of the radar at the distance D recommended by the manufacturer, then he inserts the relevant distances obtained by means of laser meters, and the system calculates the magnitude of the angle that the plane reflector needs to be rotated. Furthermore, the system indicates to the user whether and of which amount the plane reflector shall slide right or left to be centred with respect to the radar. In practice, in the calibration of a radar, the radar substitutes optical sensor <b>2</b>, while the plane reflector substitutes projection surface <b>4</b>.</p><p id="p-0092" num="0099">The characteristics and the advantages of the system and method of calibrating an optical sensor mounted on board of a vehicle, according to an embodiment, are clear, as are the advantages. In particular, the use of a surface onto which the images are projected prevents the storage or delicate handling in the workshop of numerous target panels having different shapes, sizes, and patterns. In the solution using a screen, e.g. of a television set, the calibration system proposed herein further allows a contrast to be achieved that is also compatible with use in an open environment.</p><p id="p-0093" num="0100">Furthermore, the screen also allows videos that reproduce real dynamic or simulated scenarios to be projected. Therefore, even for static calibration (i.e. with the vehicle stationary), comparable performance levels are obtained to those of dynamic calibration, which can therefore be prevented for vehicles which usually include an on-road test. Preventing the on-road test simplifies planning (connected with weather and road conditions) and prevents risks for the driver.</p><p id="p-0094" num="0101">The method and system disclosed can also be used in the event of inclination of the vehicle (within certain limits) because it is sufficient to suitably deform the image/video to be projected onto the screen instead of performing the spatial adjustment of the screen with respect to the vehicle.</p><p id="p-0095" num="0102">In addition, in case of calibration of the radar, the user may save, as an example, up to 20 minutes times for each vehicle.</p><p id="p-0096" num="0103">The disclosed ADAS measures the relative position of the vehicle undergoing calibration and of the calibration frame showing targets for sensors to be calibrated (i.e., cameras or radars). And, ADAS in general rely on knowing relative positions as indicated. Thus, the disclosed system and method are applicable to other ADAS than that described herein. And, the disclosed system and method obtains an image of the vehicle's camera target on a screen and adapts this image based on the position of the vehicle (such as when the vehicle is not squarely aligned in the test station, such as test station <b>3</b> above). Other known systems, on the other hand, typically obtain external measurements of the vehicle relative to the calibration system to achieve proper alignment.</p><p id="p-0097" num="0104">Thus, according to the disclosure and referring back to <figref idref="DRAWINGS">FIGS. <b>1</b>, <b>2</b>, <b>3</b>, and <b>4</b></figref>, calibration system <b>1</b> includes a graduated mounting bar <b>200</b> that has positioned thereon a first laser <b>202</b> and a second laser <b>204</b>. As will be further described, graduated mounting bar <b>200</b> includes physical and/or visual gradations that are picked up by elements positioned in mounting structures for both first and second lasers <b>202</b>, <b>204</b>. Calibration system <b>1</b> includes a first laser target assembly <b>206</b> that is positioned on a left front wheel hub <b>207</b> of a left front wheel <b>211</b>. Calibration system <b>1</b> also includes a second laser target assembly <b>208</b> that is positioned on a right front wheel hub <b>209</b> of a right front wheel <b>213</b>. As also will be further described, first laser <b>202</b> emits a first laser beam <b>210</b> along a first axis <b>215</b> toward first laser target assembly <b>206</b>, and second laser <b>204</b> emits a second laser beam <b>212</b> along a second axis <b>217</b> toward second laser target assembly <b>208</b>. Information, such as first and second distances measured by the mounting structures off of graduated mounting bar for first and second lasers <b>202</b>, <b>204</b>, is conveyed to control unit <b>5</b> via a communication line <b>214</b>. In one example, communication line <b>214</b>, though illustrated as a physical communication line, instead is made via a wireless communication from lasers <b>202</b>, <b>204</b> to calibration unit <b>30</b>, eliminating the need for physical wires to extend therebetween.</p><p id="p-0098" num="0105">Referring now to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, first laser target assembly <b>206</b> of the previous figures is illustrated, mounted to left front wheel hub <b>207</b>. The following description applies to both first laser target assembly <b>206</b> as well as second laser target assembly <b>208</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, noting the obvious differences due to the chirality between left and right assemblies&#x2014;the left being shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and the right shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. For instance, <figref idref="DRAWINGS">FIG. <b>6</b></figref> is illustrative of alignment of a hub assembly on a wheel hub, but pertains to second laser target assembly <b>208</b> mounted on right front wheel hub <b>209</b>, whereas <figref idref="DRAWINGS">FIG. <b>5</b></figref> pertains to the left side of the vehicle.</p><p id="p-0099" num="0106">Each assembly <b>206</b>, <b>208</b> includes a respective left target <b>216</b> and right target <b>218</b>, with each facing <b>220</b> toward a front of the vehicle. Left and right targets <b>216</b>, <b>218</b> are manually adjusted to be vertical by use of a conventional level. For instance, a level <b>222</b> may be permanently or temporarily affixed to its respective assembly <b>206</b>, <b>208</b>, level <b>222</b> including a gas bubble contained within a clear enclosure and having level gradation marks <b>226</b> that provide an indication of when level <b>222</b> is, in fact, level, via rotation of targets <b>216</b>, <b>218</b> via a rotational handle <b>230</b> and, in one example, via a use of a rotational gear or other known elements or assemblies that cause targets <b>216</b>, <b>218</b> to rotate and level via a rotation of a respective handle <b>230</b>.</p><p id="p-0100" num="0107"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates use of a laser rangefinder to determine positional information on its mounting structure according to the disclosure, and with respect to front left wheel <b>211</b> and its respective elements described herein. Once left target <b>216</b> is vertically adjusted, first laser <b>202</b> is activated to emit first laser beam <b>210</b> along first axis <b>215</b>, and first laser <b>202</b> is manually moved left/right <b>238</b> until first laser beam <b>210</b> is directed toward left target <b>216</b>. Second laser <b>204</b> is similarly adjusted left/right and along second axis <b>217</b>. Incidentally, it is contemplated that reference to &#x201c;left/right&#x201d; in the present disclosure refers to both &#x201c;left to right&#x201d; as well as &#x201c;right to left&#x201d;, and generally referring to lateral motion with respect to the vehicle and also along graduated mounting bar <b>200</b>. Distances thereby corresponding with laser beams <b>210</b>, <b>212</b> are thereby determined once each laser beam <b>210</b>, <b>212</b> is directed toward its respective target <b>216</b>, <b>218</b> and via operation of each laser <b>202</b>, <b>204</b>. In one example the distance measurements for laser beams <b>210</b>, <b>212</b> are automatically determined once lasers <b>202</b>, <b>204</b> are placed, being automatically determined by an operator directing the measurements to be made by, for example, triggering a &#x201c;read&#x201d; command during execution of the calibration steps.</p><p id="p-0101" num="0108">As will be further described, the location in 3-space (i.e., in frame of reference <b>221</b>) of first laser <b>202</b> is known, both vertically and transversely. Such knowledge derives from its position on the known (i.e., pre-measured) graduated mounting bar. More specifically, a vertical elevation <b>239</b> of graduated mounting bar <b>200</b> is known and established in its configuration in test station <b>3</b>. Graduated mounting bar <b>200</b> is pre-set to be parallel with the floor of test station <b>3</b>, and as first laser <b>202</b> is moved left/right <b>238</b> its elevation with respect to vehicle is known and remains constant.</p><p id="p-0102" num="0109">And, as further illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, first laser <b>202</b> is mounted to graduated mounting bar <b>200</b> and its lateral location is known due to gradations (i.e., visible markings or physical breaks in the surface of graduated mounting bar <b>200</b>) and due to &#x201c;pickups&#x201d; that are affiliated with first laser <b>202</b>. As such, lateral locations of first laser <b>202</b> are known and transmitted via communication line <b>214</b> from first laser <b>202</b> to calibration unit <b>30</b>, as first laser <b>202</b> is moved left/right <b>238</b>. As indicated above, line <b>214</b> may be via a physical connection, or may be a wireless communication such as via Bluetooth or other known wireless systems.</p><p id="p-0103" num="0110">Referring still to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, lasers <b>202</b>, <b>204</b> are mounted to graduated mounting bar <b>200</b> via a first laser mount <b>240</b> and a second laser mount <b>242</b>. Laser mounts <b>240</b>, <b>242</b> serve at least two purposes: to allow left/right motion <b>238</b> of each laser <b>202</b>, <b>204</b> while they remain affixed to graduated mounting bar <b>200</b>, while moving along graduated mounting bar, to provide a measurement of a latter location of each laser <b>202</b>, <b>204</b>. Graduated mounting bar <b>200</b> includes gradations <b>244</b> that can be visibly, electrically, magnetically, or mechanically &#x201c;picked up&#x201d; via mounts <b>240</b>, <b>242</b>. Gradations <b>244</b> may be affixed or marked onto graduated mounting bar <b>200</b> at fixed intervals, and as each laser <b>202</b>, <b>204</b> is moved left/right <b>238</b>, pickups <b>241</b>, <b>243</b> within or affixed respectively to laser mounts <b>240</b>, <b>242</b> sense and are configured to provide a count of the number of gradations passed (or use other indicators of distance as lasers <b>202</b>, <b>204</b> are moved left/right <b>238</b>), providing distance measurements that are transmitted to control unit <b>5</b> via communication line(s) <b>214</b> or via wireless operation. As indicated, gradations <b>244</b> can be visibly, electrically, or mechanically &#x201c;picked up&#x201d; via mounts <b>240</b>, <b>242</b>, as mounts <b>240</b>, <b>242</b> include pickups for sensing when each of gradations <b>244</b> is passed.</p><p id="p-0104" num="0111">According to the disclosure, and as known, the distance measurements transmitted from mounts <b>240</b>, <b>242</b> are relative to one another, and as such absolute measurements are determined based on a zero or a &#x201c;baseline&#x201d; measurement for each laser <b>202</b>, <b>204</b> that may be made on graduated mounting bar <b>200</b>. As one example, graduated mounting bar <b>200</b> includes a first zero point <b>246</b> corresponding to first laser <b>202</b>, and a second zero point <b>248</b> corresponding to second laser <b>204</b>. As such, during a calibration procedure each laser <b>202</b>, <b>204</b> may be moved to its respective zero point <b>246</b>, <b>248</b> to be &#x201c;zeroed out&#x201d;. Given that the locations of zero points <b>246</b>, <b>248</b> are known and fixed on graduated mounting bar <b>200</b>, the absolute locations of lasers <b>202</b>, <b>204</b> thereby known, as well as the relative distance therebetween. As such, lateral locational measurements of each laser <b>202</b>, <b>204</b> result in known dimensions or measurements <b>252</b> and <b>254</b> (distances from arbitrary zero points <b>246</b>, <b>248</b>), from which relative or lateral distance <b>256</b> can be derived along third axis <b>219</b>, and in one example may be automatically obtained by execution of a &#x201c;read&#x201d; command during calibration. That is, <b>252</b> is a distance to first laser <b>202</b> from zero point <b>246</b>, <b>254</b> is a distance to second laser <b>204</b> from zero point <b>248</b>, and <b>256</b> is determined therefrom via known locations of arbitrary locations or zero points <b>246</b> and <b>248</b> on graduated mounting bar <b>200</b>. And, it is contemplated that, as indicated, zero points <b>246</b> and <b>248</b> are arbitrarily located and can be positioned anywhere along graduated mounting bar <b>200</b>, and then used to determine distance <b>256</b> between lasers <b>202</b>, <b>204</b> via the distances determined via the pickups as each laser <b>202</b>, <b>204</b> is moved along graduated mounting bar <b>200</b>.</p><p id="p-0105" num="0112">And, given the known elevation <b>239</b> of each laser <b>202</b>, <b>204</b>, the locations of lasers <b>202</b>, <b>204</b> in 3-space is known and with respect to projection surface <b>4</b> as well as each of targets <b>216</b>, <b>218</b>. That is, in general the physical features of the various components are fixed with respect to one another (i.e., projection surface <b>4</b>, or by adjusting elevation to a known location for a particular vehicle), and as such the above disclosure results in a known location in 3-space of each of hubs <b>207</b>, <b>209</b> with respect to projection surface <b>4</b>. Likewise, each vehicle being calibrated in the test bay includes its own specific parameters of its optical sensor <b>2</b> with respect to its hubs <b>207</b>, <b>209</b>.</p><p id="p-0106" num="0113">Thus, according to the disclosure, the measurements of shifting lasers <b>202</b>, <b>204</b> left/right <b>238</b> are picked up via graduated mounting bar <b>200</b>, and distance measurements via laser beams <b>210</b>, <b>212</b>, are automatically uploaded to calibration unit <b>30</b> during a calibration procedure. As such, manual transcription of such measurements is avoided.</p><p id="p-0107" num="0114">As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, a mirror <b>250</b> is likewise included in calibration system <b>1</b>, for use with respect to laser calibration as well. Furthermore, according to the disclosure and as an alternative, distances between lasers <b>202</b>, <b>204</b> may be measured directly by mounting a laser <b>266</b> at the location and on top of laser <b>202</b>, or in lieu of laser <b>202</b>, directed toward laser <b>204</b>. And, a target <b>268</b> may be included on top of laser <b>204</b> or in lieu of laser <b>204</b>. As such, a laser beam <b>270</b> may also be used to establish a distance therebetween and along a third axis <b>219</b>. Furthermore, and in general, laser beams are illustrated for example as elements <b>210</b>, <b>212</b>, and <b>270</b>, whereas the corresponding axes along which they project are illustrated respectively as elements <b>215</b>, <b>217</b>, and <b>219</b>. As such, the various distances are determined by directing a laser along their respective axes, and the axes with measured distances are measured these axes (via the laser and directed toward its respective target), all of which are directed toward determining an angle a that defines an angular position of the vehicle in the test bay or station, and with respect to a central frame of reference <b>221</b> illustrated in <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref> in their perspective views, but also applicable to establish the frame of reference for the test station also in the other figures, defining axes <b>215</b>/<b>217</b> and <b>219</b>, as well as a vertical axis such that angle &#x3b1; for the vehicle is established via the measurements made and as disclosed herein.</p><p id="p-0108" num="0115"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a top view of vehicle <b>100</b> and showing obtained distances, such as measured distances via laser beams <b>210</b>, <b>212</b>, along their respective axes <b>215</b>, <b>217</b> as well as measured or calculated distance <b>256</b> as obtained above and along third axis <b>219</b>, and misalignment of vehicle <b>100</b> in test station <b>3</b>. As understood via the above discussion, vehicle <b>100</b> may be positioned on an angle &#x3b1; with respect to a longitudinal axis BB of test station <b>3</b>, and projection surface <b>4</b>, as seen in <figref idref="DRAWINGS">FIG. <b>9</b></figref>. Thus, although according to the disclosure calibration may be performed by having optical sensor <b>2</b> detect a location of the illustrated pattern on projection surface <b>4</b> and then correcting sensor <b>2</b>, such a calibration would not be complete since the angle a of the vehicle in the test station has not been corrected for. As such, according to the disclosure the aforementioned measurements are obtained via both lasers <b>202</b>, <b>204</b> and via the known locations of the lasers <b>202</b>, <b>204</b>, as well as known parameters of the test station and the vehicle being calibrated. It is further noted that the measurements obtained herein and to calibrate optical sensor <b>2</b> are performed expressly without use of an optical or other device that is used external to the vehicle. That is, once the vehicle is positioned in the test station (having its own reference frame <b>221</b>), then the location of the vehicle is obtained with respect to the reference frame (to include determination of angle &#x3b1;) such that its orientation with respect to the reference frame <b>21</b> can be accounted for when the calibration of the optical sensor is performed using projection surface <b>4</b>.</p><p id="p-0109" num="0116">As such, angle &#x3b1; and other parameters and/or distances, both laterally and horizontally, may be determined based on the various measurements taken during calibration and as discussed above. A graphical illustration of the primary measurements is shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, and the various known geometric and trigonometric measurements may be made to perform the translation to obtain correction factors to complete the calibration, such as determining angle &#x3b1; and other distances.</p><p id="p-0110" num="0117"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a graphical illustration of a keystone effect for correction in the ADAS, according to the disclosure. Vehicle <b>100</b> illustrates front wheels <b>211</b>, <b>213</b> having targets <b>216</b>, <b>218</b>. Laser beams <b>210</b>, <b>212</b> are shown that correspond to measured distances from graduated mounting bar <b>200</b>. As illustrated, graduated mounting bar <b>200</b> is at an angle &#x3b1; of longitudinal axis of vehicle <b>100</b> AA, and with respect to longitudinal axis of test station <b>3</b> BB. A distance from optical sensor <b>2</b> to graduated mounting bar <b>200</b> is obtained via measurements and known parameters of test station <b>3</b> and vehicle <b>100</b>, as well as the measured distance (discussed above) to determine relative positions or distances between lasers <b>202</b>, <b>204</b>.</p><p id="p-0111" num="0118">Thus, using known geometric and trigonometric techniques, and the obtained measurements, a mathematical translation to a virtual location of graduated mounting bar <b>258</b>, and having virtual distance <b>260</b> (the same from each laser <b>216</b>, <b>218</b> to the virtual location of graduated mounting bar <b>258</b>), based on optical sensor <b>2</b> &#x201c;seeing&#x201d; point <b>262</b> based on point <b>264</b> on graduated mounting bar <b>200</b>. Other corrections may be made, as well, based on corrections to the elevations of the targets. Also, it is contemplated that generally an influence of a rotational position of the steering wheel is generally negligible (such as if the wheels are slightly turned with respect to the body of the vehicle), as well as the thrust angle itself and with respect to the body of the vehicle.</p><p id="p-0112" num="0119">Thus, disclosed is a calibration system that calibrates an optical sensor mounted on board of a vehicle that includes a test station consisting of a horizontal or inclined support zone for supporting the vehicle, a projection surface for images or videos, said projection surface being located in front of said test station, at least one memory containing a plurality of images and/or videos archived by type of optical sensor, a calibration unit for calibrating the optical sensor configured to adjust the position of the optical axis of said optical sensor, and a control unit which, in response to a signal representing the type of said optical sensor, is configured to search in said memory for at least one image or video archived in association with the type of said optical sensor, command the projection onto said projection surface of the image or video found in said memory or a processed version of said image or said video, interface with said calibration unit, and adapt or deform the image or video found in said memory to the size of the projection surface.</p><p id="p-0113" num="0120">The calibration system may include a screen or monitor located in front of said test station, said projection surface being the display of said monitor. The calibration system may include a television set, said monitor being the monitor of said television set. The calibration system may include a multimedia interactive board, said monitor being the monitor of the multimedia interactive board. The calibration system may include a computer, said monitor being the monitor of the computer. The calibration may include that the projection surface is obtained from a sheet made of PVC. The calibration system may include a projector or a luminous board, said control unit being configured to command the projector or luminous board to project the image or video found in said memory onto said projection surface. The calibration system may also, in response to the signal representing the type of said optical sensor, have the control unit configured to project a set of parameters or initial calibration conditions onto said projection surface. The calibration system may include a projector or a luminous board, said control unit being configured to command the projector or luminous board to project the image or video found in said memory onto said projection surface.</p><p id="p-0114" num="0121">Also disclosed is a method of calibrating an optical sensor mounted on board of a vehicle, including the steps of positioning the vehicle in a test station consisting of a horizontal or inclined support zone for supporting the vehicle, arranging a projection surface for images or videos in front of said test station, identifying the type of said optical sensor, selecting in a memory an image or video associated with the type of said optical sensor, adapting or deforming the image or video selected in said memory (<b>6</b>) to the size of the projection surface, projecting the image or video selected or the adapted or deformed version thereof onto said projection surface, and adjusting the position of the optical axis of said optical sensor starting from said projected image or video.</p><p id="p-0115" num="0122">As will be appreciated by one skilled in the art, various aspects may be embodied as a system, method or device program product. Accordingly, aspects may take the form of an entirely hardware embodiment or an embodiment including software that may all generally be referred to herein as a &#x201c;circuit,&#x201d; &#x201c;module&#x201d; or &#x201c;system.&#x201d; Furthermore, aspects may take the form of a device program product embodied in one or more device readable medium(s) having device readable program code embodied therewith.</p><p id="p-0116" num="0123">It should be noted that the various functions described herein may be implemented using instructions stored on a device readable storage medium such as a non-signal storage device that are executed by a processor. A storage device may be, for example, a system, apparatus, or device (e.g., an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, or device) or any suitable combination of the foregoing. More specific examples of a storage device/medium include the following: a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, a portable compact disc read-only memory (CD-ROM), an optical storage device, a magnetic storage device, or any suitable combination of the foregoing. In the context of this document, a storage device is not a signal and &#x201c;non-transitory&#x201d; includes all media except signal media.</p><p id="p-0117" num="0124">Program code embodied on a storage medium may be transmitted using any appropriate medium, including but not limited to wireless, wireline, optical fiber cable, RF, et cetera, or any suitable combination of the foregoing.</p><p id="p-0118" num="0125">Program code for carrying out operations may be written in any combination of one or more programming languages. The program code may execute entirely on a single device, partly on a single device, as a stand-alone software package, partly on single device and partly on another device, or entirely on the other device. In some cases, the devices may be connected through any type of connection or network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made through other devices (for example, through the Internet using an Internet Service Provider), through wireless connections, e.g., near-field communication, or through a hard wire connection, such as over a USB connection.</p><p id="p-0119" num="0126">Example embodiments are described herein with reference to the figures, which illustrate example methods, devices and program products according to various example embodiments. It will be understood that the actions and functionality may be implemented at least in part by program instructions. These program instructions may be provided to a processor of a device, a special purpose information handling device, or other programmable data processing device to produce a machine, such that the instructions, which execute via a processor of the device implement the functions/acts specified.</p><p id="p-0120" num="0127">It is worth noting that while specific blocks are used in the figures, and a particular ordering of blocks has been illustrated, these are non-limiting examples. In certain contexts, two or more blocks may be combined, a block may be split into two or more blocks, or certain blocks may be re-ordered or re-organized as appropriate, as the explicit illustrated examples are used only for descriptive purposes and are not to be construed as limiting.</p><p id="p-0121" num="0128">As used herein, the singular &#x201c;a&#x201d; and &#x201c;an&#x201d; may be construed as including the plural &#x201c;one or more&#x201d; unless clearly indicated otherwise.</p><p id="p-0122" num="0129">This disclosure has been presented for purposes of illustration and description but is not intended to be exhaustive or limiting. Many modifications and variations will be apparent to those of ordinary skill in the art. The example embodiments were chosen and described in order to explain principles and practical application, and to enable others of ordinary skill in the art to understand the disclosure for various embodiments with various modifications as are suited to the particular use contemplated.</p><p id="p-0123" num="0130">Thus, although illustrative example embodiments have been described herein with reference to the accompanying figures, it is to be understood that this description is not limiting and that various other changes and modifications may be affected therein by one skilled in the art without departing from the scope or spirit of the disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A calibration system for calibrating an optical sensor on board a vehicle, comprising:<claim-text>a control unit;</claim-text><claim-text>a projection screen having a projection surface positionable within a test station and viewable by an optical sensor positioned in a vehicle, the projection surface electrically coupled to the control unit;</claim-text><claim-text>a graduated mounting bar having gradations indicative of a lateral position of the graduated mounting bar;</claim-text><claim-text>a first target positionable on a first hub of the vehicle;</claim-text><claim-text>a second target positionable on a second hub of the vehicle;</claim-text><claim-text>a first laser mounted to the graduated mounting bar and positionable left to right with respect to the vehicle and along the graduated mounting bar, the first laser electrically coupled to the control unit, the first laser configured to obtain a first distance to the first target along a first axis;</claim-text><claim-text>a second laser mounted to the graduated mounting bar and positionable left to right with respect to the vehicle and along the graduated mounting bar, the second laser electrically coupled to the control unit, the second laser configured to obtain a second distance to the second target along a second axis;</claim-text><claim-text>the control unit configured to automatically:<claim-text>obtain the first distance from the first laser;</claim-text><claim-text>obtain the second distance from the second laser; and</claim-text><claim-text>obtain a lateral distance from the first laser to the second laser along a third axis that is orthogonal to the first axis and to the second axis, and based on the gradations; and</claim-text></claim-text><claim-text>calibrate the optical sensor based on the obtained first distance, the second distance, and the lateral distance.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The calibration system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the control unit is further configured to establish a frame of reference of the vehicle in the test station, and determine an angle of the vehicle within the frame of reference based on the first distance along the first axis, the second distance along the second axis, and the lateral distance along the third axis, and calibrate the optical sensor based on the determined angle.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The calibration system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the control unit is further configured to correct for an angular position of the vehicle in the test station based on the first distance along the first axis, the second distance along the second axis, and the lateral distance along the third axis prior to calibrating the optical sensor.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The calibration system of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the control unit is further configured to:<claim-text>determine a position of the optical sensor in the frame of reference and with respect to the projection surface;</claim-text><claim-text>select an image to be displayed;</claim-text><claim-text>display the image of the projection surface;</claim-text><claim-text>adapt the image displayed on the projection surface to a size of the projection screen based on the size of the projection surface and the position of the optical sensor; and</claim-text><claim-text>calibrate the optical sensor by adjusting a position of an optical axis of the optical sensor based on the image.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The calibration system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the control unit is further configured to select the image by selecting an image from a video.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The calibration system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first laser is mounted to the graduated mounting bar via a first laser mount, the laser mount having a pickup that provides an indication of a location of the first laser mount on the graduated mounting bar.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The calibration system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the pickup provides the indication of the location via one of a visibly, electrically, magnetically, or mechanically pickup.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The calibration system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the control unit is external to the vehicle.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The calibration system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the control unit is further configured to adapt the image displayed on the projection surface by deforming the image to a size of the projection surface.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The calibration system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the control unit is further configured display the image on the projection surface by projecting the image on no more than one projection surface.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A method of calibrating an optical sensor on board a vehicle, comprising:<claim-text>positioning a vehicle in a test station and proximate a projection surface, the vehicle having an optical sensor, the projection surface in view of the optical sensor;</claim-text><claim-text>positioning a first target on a first hub of the vehicle;</claim-text><claim-text>positioning a second target on a second hub of the vehicle;</claim-text><claim-text>positioning a first laser left to right, the first laser mounted on a graduated mounting bar that is in front of the vehicle, the graduated mounting bar having gradations indicative of a lateral position of the first laser on the graduated mounting bar, the first laser configured to obtain a first distance to the first target along a first axis;</claim-text><claim-text>positioning a second laser left to right, the second laser mounted on the graduated mounting bar, the second laser configured to obtain a second distance to the second target along a second axis and based on a position on of the second laser on the graduated mounting bar;</claim-text><claim-text>obtaining the first distance along the first axis from the first laser;</claim-text><claim-text>obtaining the second distance along the second axis from the second laser;</claim-text><claim-text>obtaining a lateral distance along a third axis that from the first laser to the second laser based on the gradations, the third axis orthogonal to the first axis and to the second axis; and</claim-text><claim-text>calibrating the optical sensor based on the obtained first distance, second distance, and lateral distance.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising providing operating a controller electrically coupled to the projection surface, to the first laser, and to the second laser.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising establishing a frame of reference of the vehicle in the test station, and determining an angle of the vehicle within the frame of reference, based on the obtained first distance along the first axis, the second distance along the second axis, and the lateral distance along the third axis, and calibrating the optical sensor based on the determined angle.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising correcting for an angular position of the vehicle in the test station based on the first distance, the second distance, and the lateral distance prior to calibrating the optical sensor.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:<claim-text>determining a position of the optical sensor in the frame of reference and with respect to the projection surface;</claim-text><claim-text>selecting an image to be displayed;</claim-text><claim-text>displaying the image of the projection surface;</claim-text><claim-text>adapting the image displayed on the projection surface to a size of the projection screen based on the size of the projection surface and the position of the optical sensor; and</claim-text><claim-text>calibrating the optical sensor by adjusting a position of an optical axis of the optical sensor based on the image.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising selecting the image by selecting an image from a video.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising mounting the first laser to the graduated mounting bar via a first laser mount, the laser mount having a pickup that provides an indication of a location of the first laser mount on the graduated mounting bar.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising providing an indication of the location via one of a visibly, electrically, magnetically, or mechanically pickup and via the pickup.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising positioning the control unit external to the vehicle.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising adapting the image displayed on the projection surface by deforming the image to a size of the projection surface.</claim-text></claim></claims></us-patent-application>
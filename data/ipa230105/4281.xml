<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004282A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004282</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17856822</doc-number><date>20220701</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2021-110701</doc-number><date>20210702</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>04845</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>04883</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0485</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>04845</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>04883</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0485</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0425</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">IMAGE PROCESSING METHOD AND IMAGE PROCESSING DEVICE</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>SEIKO EPSON CORPORATION</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>TOMOTOSHI</last-name><first-name>Akio</first-name><address><city>SAPPORO-SHI ATSUBETSU-KU</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>FUJIMORI</last-name><first-name>Toshiki</first-name><address><city>CHINO-SHI</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>SEIKO EPSON CORPORATION</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An image processing method includes displaying a first screen on a display surface, the first screen including at least a part of a drawing area in which at least one object image drawn by a user is arranged, excluding an area in which at least a part of an object image included in the first screen is arranged from the drawing area when an operation of erasing the at least a part of the object is received, and displaying a reduced screen on the display surface when an operation is received, the reduced screen being obtained by reducing a whole of the drawing area into a size of the display surface.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="111.84mm" wi="146.30mm" file="US20230004282A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="204.05mm" wi="148.34mm" file="US20230004282A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="146.30mm" wi="103.97mm" file="US20230004282A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="248.33mm" wi="157.40mm" file="US20230004282A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="151.55mm" wi="124.12mm" file="US20230004282A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="250.53mm" wi="157.23mm" file="US20230004282A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="193.38mm" wi="157.14mm" file="US20230004282A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="248.75mm" wi="157.48mm" file="US20230004282A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="253.15mm" wi="157.56mm" file="US20230004282A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="178.99mm" wi="145.88mm" file="US20230004282A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="243.84mm" wi="157.06mm" file="US20230004282A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="250.11mm" wi="157.56mm" file="US20230004282A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="247.57mm" wi="157.65mm" file="US20230004282A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="248.58mm" wi="157.23mm" file="US20230004282A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="209.89mm" wi="143.51mm" file="US20230004282A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="185.08mm" wi="103.38mm" file="US20230004282A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="138.77mm" wi="95.17mm" file="US20230004282A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><p id="p-0002" num="0001">The present application is based on, and claims priority from JP Application Serial Number 2021-110701, filed Jul. 2, 2021, the disclosure of which is hereby incorporated by reference herein in its entirety.</p><heading id="h-0001" level="1">BACKGROUND</heading><heading id="h-0002" level="1">1. Technical Field</heading><p id="p-0003" num="0002">The present disclosure relates to an image processing method and an image processing device.</p><heading id="h-0003" level="1">2. Related Art</heading><p id="p-0004" num="0003">In the past, there has been known a device which displays a drawn image based on a drawing input from the user, and which is capable of expanding a drawing area in which a drawn object is arranged. For example, when the drawing input to a drawing input screen is made, a drawing processing device described in JP-A-2010-134897 performs screen display of drawing information based on the drawing input, and at the same time, converts a coordinate of the drawing information into a two-dimensional coordinate on an imaginary imaging space, and then stores the result. When scrolling the drawing input screen and performing the drawing input, the coordinate of the drawing space is expanded so as to include the drawing information. Further, a total drawing information display processor displays a total drawing information display screen including total drawing information.</p><p id="p-0005" num="0004">It is unachievable for the related-art technology described above to change a size of the imaginary drawing space having once been expanded. Therefore, there is room for improvement in operability since there is a possibility that the size of the total drawing information display screen does not change even when, for example, a part of the drawing information is erased, and the remaining drawing information is displayed in a small size.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0006" num="0005">An image processing method according to an aspect of the present disclosure includes the steps of displaying a first screen on a display surface, the first screen including at least a part of a drawing area as an area in which at least one object image drawn by a user is arranged, excluding an area in which at least a part of an object image included in the first screen is arranged from the drawing area when an operation of erasing the at least a part is performed, and displaying a reduced screen on the display surface when a predetermined operation is received, the reduced screen being obtained by reducing a whole of the drawing area into a size of the display surface.</p><p id="p-0007" num="0006">An image processing device according to an aspect of the present disclosure includes a display device, and at least one processing unit, wherein the processing unit executes the steps of displaying a first screen on a display surface using the display device, the first screen including at least apart of a drawing area as an area in which at least one object image drawn by a user is arranged, excluding an area in which at least a part of an object image included in the first screen is arranged from the drawing area when an operation of erasing the at least a part is performed, and displaying a reduced screen on the display surface when a predetermined operation is received, the reduced screen being obtained by reducing a whole of the drawing area into a size of the display surface.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram showing a projector system <b>1</b> including a projector according to a first embodiment.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram showing an example of a configuration of a pointer.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram showing an example of a configuration of the projector.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram showing an example of a drawing reception screen.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram schematically showing a drawing area.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram showing an example of a table of parameters representing a correspondence relationship between a projection range and the drawing area.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram showing an example of the drawing reception screen.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram schematically showing the drawing area.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram showing an example of the drawing reception screen.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram schematically showing the drawing area.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram showing an example of the table of parameters representing the correspondence relationship between the projection range and the drawing area.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram showing an example of the drawing reception screen.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram schematically showing the drawing area.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram schematically showing the drawing area.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram schematically showing the drawing area.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram showing an example of a whole display screen.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a diagram showing an example of the table of the parameters representing the correspondence relationship between the projection range and the drawing area.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a diagram showing an example of the drawing reception screen.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a diagram schematically showing the drawing area.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a diagram schematically showing the drawing area.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>21</b></figref> is a diagram showing an example of the whole display screen.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>22</b></figref> is a diagram showing an example of the drawing reception screen.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>23</b></figref> is a diagram schematically showing the drawing area.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>24</b></figref> is a diagram schematically showing the drawing area.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>25</b></figref> is a diagram showing an example of the whole display screen.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>26</b></figref> is an enlarged view of drawing menu icons.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>27</b></figref> is a diagram schematically showing a trajectory of a contact position of the pointer.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>28</b></figref> is a diagram schematically showing a drawing datum.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>29</b></figref> is a flowchart showing a flow of an image processing method to be executed by a processing unit of the projector in accordance with a control program.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>30</b></figref> is a flowchart showing the flow of the image processing method to be executed by the processing unit of the projector in accordance with the control program.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DESCRIPTION OF AN EXEMPLARY EMBODIMENT</heading><p id="p-0038" num="0037">A preferred embodiment related to the present disclosure will hereinafter be described with reference to the accompanying drawings. It should be noted that in the drawings, dimensions or scale sizes of each section are arbitrarily different from the reality, and some portions are shown schematically in order to make understanding easy. Further, the scope or the spirit of the present disclosure is not limited to the embodiment unless there is a particular description of limiting the present disclosure in the following explanation.</p><heading id="h-0007" level="1">A. OUTLINE OF PROJECTOR SYSTEM <b>1</b></heading><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram showing a projector system <b>1</b> including a projector <b>10</b> according to the embodiment. The projector system <b>1</b> includes the projector <b>10</b> and a pointer <b>20</b>.</p><p id="p-0040" num="0039">The projector <b>10</b> is installed in a portion of a wall W located above an upper end Re<b>1</b> of a projection range R. The projector <b>10</b> can be installed on, for example, a desk, a table, or the floor, or can also be suspended from the ceiling instead of being installed on the wall W. In the present embodiment, the projection range R is, for example, a part of the wall W. The projection range R can be a screen, a door, a whiteboard, or the like besides the part of the wall W. The projection range R is an example of a display surface. The projector <b>10</b> projects an image on the projection range R to thereby display the image in the projection range R. The projector <b>10</b> is an example of an image processing device.</p><p id="p-0041" num="0040">The pointer <b>20</b> is, for example, a pen-type pointing tool. The shape of the pointer <b>20</b> is not limited to a shape of a pen, and can also be, for example, a circular cylinder, a prismatic column, a circular cone, or a pyramidal shape. The user grips, for example, a shaft <b>20</b><i>b </i>of the pointer <b>20</b>, and translates the pointer <b>20</b> on the projection range R while making a tip <b>20</b><i>a </i>have contact with the projection range R.</p><p id="p-0042" num="0041">The projector <b>10</b> images the projection range R with a camera <b>15</b> to thereby generate an imaging datum representing a taken image. The projector <b>10</b> analyzes the taken image to thereby identify a position of the pointer <b>20</b>. As described later, in the present embodiment, a position where infrared light emitted from a first light source <b>23</b> of the pointer <b>20</b> has been detected on an infrared light taken image is assumed as a contact position where the tip <b>20</b><i>a </i>of the pointer <b>20</b> has contact with the projection range R.</p><p id="p-0043" num="0042">The projector <b>10</b> can operate in a drawing mode in which a drawing input from the user is received. Although the details will be described later, in the drawing mode, the user performs drawing using the pointer <b>20</b> like a writing tool. The projector <b>10</b> detects a movement trajectory of the pointer <b>20</b> in a period in which the pointer <b>20</b> has contact with the projection range R, and then display a line along the movement trajectory in the projection range R. In the present embodiment, the trajectory of the contact position in a period from when the pointer <b>20</b> makes contact with the projection range R to when the pointer <b>20</b> is separated from the projection range R is treated as a single object image O. In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the drawing reception screen <b>30</b> including a plurality of object images O drawn by the user is displayed in the projection range R. Further, in the drawing mode, the drawing menu icons <b>40</b> are displayed in the projection range R. It is possible for the user to switch a variety of operations in the drawing mode by selecting the drawing menu icons <b>40</b>. The details of the drawing menu icons <b>40</b> will be described later.</p><heading id="h-0008" level="1">B. CONFIGURATION OF POINTER <b>20</b></heading><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram showing an example of a configuration of the pointer <b>20</b>. The pointer <b>20</b> includes a first communicator <b>22</b>, a first light source <b>23</b>, a switch <b>24</b>, a pointer storage <b>25</b>, and a pointer controller <b>26</b>.</p><p id="p-0045" num="0044">The first communicator <b>22</b> has a communication circuit, an antenna, and so on, and performs wireless communication with the projector <b>10</b> using Bluetooth. Bluetooth is a registered trademark. Bluetooth is an example of a near field wireless communication system. The near field wireless communication system is not limited to Bluetooth, but can also be, for example, Wi-Fi. Wi-Fi is a registered trademark. The communication system of the wireless communication between the first communicator <b>22</b> and the projector <b>10</b> is not limited to the near field wireless communication system, but can also be other communication systems. Further, when the first communicator <b>22</b> performs wired communication, there are provided a communication circuit, a connector to which communicating lines are connected, and so on.</p><p id="p-0046" num="0045">The first light source <b>23</b> is an LED (Light Emitting Diode) for emitting infrared light. The first light source <b>23</b> is not limited to the LED, but can also be, for example, an LD (Laser Diode) for emitting the infrared light. The first light source <b>23</b> emits the infrared light for making the projector <b>10</b> recognize the contact position of the pointer <b>20</b>.</p><p id="p-0047" num="0046">The switch <b>24</b> turns ON when pressure acts on the tip <b>20</b><i>a </i>of the pointer <b>20</b>, and turns OFF when the pressure applied on the tip <b>20</b><i>a </i>is released. The switch <b>24</b> functions as a sensor for detecting whether or not the tip <b>20</b><i>a </i>has contact with the projection range R. The first light source <b>23</b> turns ON and OFF in tandem with the switch <b>24</b> turning ON and OFF. In other words, when the pressure acts on the tip <b>20</b><i>a </i>of the pointer <b>20</b>, the switch <b>24</b> turns ON, and the first light source <b>23</b> emits light. Further, when the pressure applied on the tip <b>20</b><i>a </i>is released, the switch <b>24</b> turns OFF, and the first light source <b>23</b> stops emitting light.</p><p id="p-0048" num="0047">The pointer storage <b>25</b> is a nonvolatile semiconductor memory such as a flash memory. The pointer storage <b>25</b> stores a control program to be executed by the pointer controller <b>26</b>.</p><p id="p-0049" num="0048">The pointer controller <b>26</b> is constituted by, for example, a single processor, or a plurality of processors. Citing an example, the pointer controller <b>26</b> is formed of a signal CPU (Central Processing Unit) or a plurality of CPUs. Some or all of the functions of the pointer controller <b>26</b> can also be configured by a circuit such as a DSP (Digital Signal Processor), an ASIC (Application Specific Integrated Circuit), a PLD (Programmable Logic Device), or an FPGA (Field Programmable Gate Array). The pointer controller <b>26</b> executes a variety of types of processing in parallel or in sequence.</p><p id="p-0050" num="0049">The pointer controller <b>26</b> executes the control program stored in the pointer storage <b>25</b> to thereby realize a variety of functions. For example, in the circumstance in which the switch <b>24</b> is in an ON state, the pointer controller <b>26</b> puts the first light source <b>23</b> ON when the first communicator <b>22</b> receives a sync signal from the projector <b>10</b>. The sync signal is a signal for synchronizing a lighting timing of the first light source <b>23</b> with an imaging timing of the camera <b>15</b>.</p><heading id="h-0009" level="1">C. CONFIGURATION OF PROJECTOR <b>10</b></heading><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram showing an example of a configuration of the projector <b>10</b>. The projector <b>10</b> includes an operator <b>12</b>, a second communicator <b>13</b>, a projecting unit <b>14</b>, a camera <b>15</b>, a storage <b>16</b>, and a processing unit <b>17</b>.</p><p id="p-0052" num="0051">The operator <b>12</b> is, for example, a variety of operating buttons, operating keys, or a touch panel. The operator <b>12</b> is provided to, for example, a chassis of the projector <b>10</b>. Further, the operator <b>12</b> can be a remote controller disposed separately from the chassis of the projector <b>10</b>. The operator <b>12</b> receives an input operation from the user.</p><p id="p-0053" num="0052">The second communicator <b>13</b> has a communication circuit, an antenna, and so on, and performs the wireless communication with the first communicator <b>22</b> of the pointer <b>20</b> using Bluetooth. As described above, the communication system for the wireless communication is not limited to Bluetooth, but can also be, for example, Wi-Fi. It should be noted that when the second communicator <b>13</b> performs wired communication, there are provided a communication circuit, a connector to which communicating lines are connected, and so on.</p><p id="p-0054" num="0053">The projecting unit <b>14</b> projects an image on the projection range R to thereby display the image in the projection range R. The projecting unit <b>14</b> is an example of a display device, and is provided with an image processing circuit, a frame memory, a liquid crystal light valve, a light valve drive circuit, a light source, a projection optical system, and so on. When the image processing circuit receives an image datum from an image supply device such as the processing unit <b>17</b> or a computer not shown, the image processing circuit develops the image datum in the frame memory, and then performs necessary image processing. This image processing is, for example, processing of converting the resolution of the image datum into the resolution of the liquid crystal light valve, a geometric correction process for resolving a keystone distortion, or the like. The image datum on which the image processing has been performed is converted into an image signal, and by the liquid crystal light valve and so on being driven based on the image signal, the image datum is projected as the image. It should be noted that as the projecting unit <b>14</b>, it is possible to adopt, for example, a DLP (Digital Lighting Processing; a registered trademark) system besides the liquid crystal system using the liquid crystal light valve and so on described above.</p><p id="p-0055" num="0054">The camera <b>15</b> takes an image of the projection range R to thereby generate the imaging datum representing the taken image. The camera <b>15</b> includes alight receiving optical system such as a lens, an imaging element for converting the light collected by the light receiving optical system into an electric signal, and so on. The imaging element is a CCD (Charge Coupled Device) image sensor for receiving the light in, for example, an infrared region or a visible light region. The camera <b>15</b> can also be provided with a filter for blocking apart of the light entering the imaging element. For example, in the camera <b>15</b>, when making the imaging element receive the infrared light, the filter for mainly transmitting the light in the infrared region can be disposed in front of the imaging element. Further, in the camera <b>15</b>, when making the imaging element receive the visible light, the filter for mainly transmitting the light in the visible light region can be disposed in front of the imaging element.</p><p id="p-0056" num="0055">The camera <b>15</b> can be disposed as a separate member from the projector <b>10</b>. In this case, the camera <b>15</b> and the projector <b>10</b> can be connected to each other with a wired or wireless interface so as to be able to perform transmission/reception of data.</p><p id="p-0057" num="0056">When the camera <b>15</b> performs imaging with the visible light, there is taken, for example, the image projected by the projecting unit <b>14</b> on the projection range R. The datum of a visible light taken image generated by the camera <b>15</b> performing imaging with the visible light is hereinafter referred to as a &#x201c;visible light imaging datum.&#x201d; The visible light imaging datum is used in, for example, a calibration described later.</p><p id="p-0058" num="0057">When the camera <b>15</b> performs imaging with the infrared light, there is generated, for example, the imaging datum representing the infrared light emitted by the pointer <b>20</b>. The datum of an infrared taken image generated by the camera <b>15</b> with the infrared light is hereinafter referred to as an &#x201c;infrared light imaging datum.&#x201d; The infrared light imaging datum is used for detecting, for example, the contact position of the pointer <b>20</b> on the projection range R. In other words, the camera <b>15</b> is an example of a detection device for detecting information related to the position of the pointer <b>20</b>.</p><p id="p-0059" num="0058">The storage <b>16</b> is a recording medium which can be read by the processing unit <b>17</b>. The storage <b>16</b> includes, for example, a nonvolatile memory and a volatile memory. As the nonvolatile memory, there can be cited, for example, a ROM (Read Only Memory), an EPROM (Erasable Programmable Read Only Memory), and an EEPROM (Electrically Erasable Programmable Read Only Memory). As the volatile memory, there can be cited, for example, a RAM. The volatile memory includes the frame memory described above.</p><p id="p-0060" num="0059">The storage <b>16</b> stores a control program <b>162</b> to be executed by the processing unit <b>17</b>, and a variety of types of data <b>164</b> to be used by the processing unit <b>17</b>.</p><p id="p-0061" num="0060">The control program <b>162</b> is executed by the processing unit <b>17</b>. The control program <b>162</b> includes an operating system and a plurality of application programs. The plurality of application programs includes an application program for realizing an interactive function.</p><p id="p-0062" num="0061">The data <b>164</b> include data representing processing conditions of a variety of types of processing to be executed by the processing unit <b>17</b>. Further, the data <b>164</b> can also include data to be used in the image processing. Further, the data <b>164</b> include a calibration image datum representing a calibration image. In the calibration image, there are arranged marks having shapes set in advance at intervals.</p><p id="p-0063" num="0062">The processing unit <b>17</b> is formed of, for example, a single processor, or a plurality of processors. Citing an example, the processing unit <b>17</b> is constituted by a signal CPU or a plurality of CPUs. Some or all of the functions of the processing unit <b>17</b> can be configured by a circuit such as a DSP, an ASIC, a PLD, or an FPGA. The processing unit <b>17</b> executes a plurality of types of processing in parallel or in sequence.</p><p id="p-0064" num="0063">The processing unit <b>17</b> retrieves the control program <b>162</b> from the storage <b>16</b> and then executes the control program <b>162</b> to thereby function as an operation controller <b>172</b> and a drawing controller <b>174</b>.</p><p id="p-0065" num="0064">The operation controller <b>172</b> controls a variety of operations of the projector <b>10</b>. The operation controller <b>172</b> executes, for example, the calibration. The calibration is processing of making a coordinate on the frame memory of the projecting unit <b>14</b> and a coordinate on the imaging datum correspond to each other. The coordinate on the frame memory corresponds to a position on the image to be projected on the projection range R. By the position on the frame memory and the position on the imaging datum being made to correspond to each other, it is possible to identify a portion corresponding to the contact position of the pointer <b>20</b> in the projection range R with respect to, for example, the image to be projected on the projection range R. The operation controller <b>172</b> executes the calibration to thereby generate a calibration datum for making the coordinate on the imaging datum by the camera <b>15</b> and the coordinate on the frame memory of the projecting unit <b>14</b> correspond to each other, and then store the calibration datum in the storage <b>16</b>.</p><p id="p-0066" num="0065">Besides the above, the operation controller <b>172</b> establishes the communication between, for example, the second communicator <b>13</b> and the first communicator <b>22</b> of the pointer <b>20</b>. Further, after completing the calibration, the operation controller <b>172</b> makes the camera <b>15</b> perform imaging with the infrared light to generate the infrared light imaging datum at constant time intervals. Further, the operation controller <b>172</b> transmits the sync signal from the second communicator <b>13</b> to the pointer <b>20</b> in sync with the imaging timing of the camera <b>15</b>.</p><p id="p-0067" num="0066">The drawing controller <b>174</b> controls an operation of the projector <b>10</b> during the drawing mode. More particularly, the drawing controller <b>174</b> displays the drawing reception screen <b>30</b> in the projection range R, and then receives the drawing input using the pointer <b>20</b> from the user. Further, the drawing controller <b>174</b> displays the object image O based on the drawing input in the projection range R. The details of the drawing mode will hereinafter be described.</p><heading id="h-0010" level="1">D. DETAILS OF DRAWING MODE</heading><heading id="h-0011" level="1">D-1. Projection Range R and Drawing Area D</heading><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram showing an example of display in the projection range R when selecting the drawing mode. When selecting the drawing mode, the drawing reception screen <b>30</b> is displayed in the projection range R. The drawing reception screen <b>30</b> is a screen for receiving the drawing input from the user. In the drawing reception screen <b>30</b>, there are displayed the drawing menu icons <b>40</b> described later. Hereinafter, when it is necessary to distinguish the individual drawing reception screens <b>30</b> from each other, there are used the descriptions of drawing reception screens <b>30</b>A, <b>30</b>B, . . . .</p><p id="p-0069" num="0068">The coordinate of each point on the projection range R in the drawing reception screen <b>30</b> corresponds to a coordinate on the frame memory. In the present embodiment, the projection range R is located on an X-Y plane along an X axis and a Y axis perpendicular to the X axis. In other words, the X-Y plane is a plane representing a display plane. Hereinafter, an upper left point P<b>1</b> of the projection range R is defined as a reference point, and a coordinate of a point on the projection range R is assumed as (X, Y). Each coordinate corresponds to a single pixel. The projection range R is a range from the point P<b>1</b> (0,0) to a point P<b>2</b> (1919,1079) on the X-Y plane. The drawing reception screen <b>30</b> is substantially the same in area as the projection range R, but it is possible to perform drawing in a region larger in area than the projection range R by expanding the drawing area D.</p><p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram schematically showing the drawing area D. The drawing area D is an imaginary area in which a single object image O or a plurality of object images O drawn by the user is arranged. The object image O is stored in the storage <b>16</b> in reality as such a drawing datum DT as shown in <figref idref="DRAWINGS">FIG. <b>28</b></figref>. Further, the drawing area D is defined in reality by such parameters as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, <figref idref="DRAWINGS">FIG. <b>11</b></figref>, and <figref idref="DRAWINGS">FIG. <b>17</b></figref>. The drawing area D illustrated in the present embodiment is an area obtained by developing the drawing area D defined by the parameters shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> and so on in an imaginary plane. The drawing control section <b>174</b> displays a part or whole of the drawing area D as the drawing reception screen <b>30</b> in the projection range R. In other words, the drawing controller <b>174</b> displays the drawing reception screen <b>30</b> including at least a part of the drawing area D in the display surface. It can be said that the user performs the drawing in the drawing area D via the drawing reception screen <b>30</b>. In the present embodiment, the drawing area D is a plane along an x axis corresponding to the X axis and a y axis corresponding to the Y axis. In other words, the drawing area D is a rectangular area defined by the x axis as a first axis and the y axis as a second axis perpendicular to the x axis.</p><p id="p-0071" num="0070">Hereinafter, an upper left point p<b>1</b> of the drawing area D in <figref idref="DRAWINGS">FIG. <b>5</b></figref> is defined as a reference point, and a coordinate of a point on the drawing area D is assumed as (x,y). In other words, the drawing area D is located on an x-y plane. The drawing area D is a range from the point p<b>1</b> (0,0) to a point p<b>2</b> (1919,1079) on the x-y plane. The range from the point p<b>1</b> (0,0) to the point p<b>2</b> (1919,1079) is an initial drawing area D<b>0</b>. The drawing reception screen <b>30</b> displayed in the projection range R immediately after the drawing mode is started is a screen for receiving drawing to the initial drawing area D<b>0</b>. In the state in which the initial drawing area D<b>0</b> is displayed, a coordinate values in the drawing area D and coordinate values in the projection range R coincide with each other. For example, a coordinate (100,100) in the projection range R corresponds to a coordinate (100,100) in the drawing area D.</p><p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a table of the parameters representing the correspondence relationship between the projection range R shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> and the drawing area D shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. As described above, the projection range R is the range from the point P<b>1</b> (0,0) to the point P<b>2</b> (1919,1079) on the X-Y plane represented by the coordinate (X,Y). The drawing area D is represented by the coordinate (x, y), and is the range from the point p<b>1</b> (0,0) to the point p<b>2</b> (1919, 1079). A projection range displacement represents a displacement of the reference point P<b>1</b> of the projection range R to the reference point p<b>1</b> using the coordinate (x, y) of the drawing area D. The projection range displacement is a numerical value for making a point on the projection range R and a point on the drawing area D correspond to each other. The reference point P<b>1</b> of the projection range R in <figref idref="DRAWINGS">FIG. <b>4</b></figref> coincides with the reference point p<b>1</b> of the drawing area D in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. Therefore, the projection range displacement is zero in both of the x-axis direction and the y-axis direction. Further, a scaling ratio represents a degree of expansion or reduction of display in the projection range R to the object image O in the drawing area D in percentage. In the display in the projection range R in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the drawing area D in <figref idref="DRAWINGS">FIG. <b>5</b></figref> is displayed on an unchanged scale, and thus, the scaling ratio is 100%.</p><p id="p-0073" num="0072">It is assumed that the user performs a drawing input as shown in, for example, <figref idref="DRAWINGS">FIG. <b>7</b></figref> on the drawing reception screen <b>30</b>A shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. The drawing reception screen <b>30</b>B in <figref idref="DRAWINGS">FIG. <b>7</b></figref> is an example of a first screen. The drawing input to the drawing reception screen <b>30</b> is performed by moving the pointer <b>20</b> while keeping contact with the projection range R with a pen icon <b>42</b> described later selected. It should be noted that in terms of visibility, an illustration of the drawing menu icons <b>40</b> will be omitted in the drawings of the projection range R in <figref idref="DRAWINGS">FIG. <b>7</b></figref> and subsequent drawings. In the drawing reception screen <b>30</b>B shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, there are displayed the plurality of object images O<b>1</b> through O<b>5</b> drawn by the user. In the example shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the object images O<b>1</b> and O<b>2</b> constitute a character of &#x201c;A,&#x201d; the object images O<b>3</b> and O<b>4</b> constitute a character of &#x201c;B,&#x201d; and the object image O<b>5</b> constitutes a character of &#x201c;C.&#x201d; In this case, as shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the object images O<b>1</b> through O<b>5</b> are recorded at positions in the drawing area D corresponding to positions of the object images O<b>1</b> through O<b>5</b> in the projection range R.</p><p id="p-0074" num="0073">It is assumed that the user performs scrolling of the drawing reception screen <b>30</b>B shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref> as shown in, for example, <figref idref="DRAWINGS">FIG. <b>9</b></figref>. The scrolling of the drawing reception screen <b>30</b> is performed by moving the pointer <b>20</b> while keeping contact with the projection range R with a scroll icon <b>46</b> described later selected. In <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the scrolling of the drawing reception screen <b>30</b>B is performed in a rightward direction and an upper direction, and the range of the drawing area D displayed in the drawing reception screen <b>30</b>C is shifted to the upper right after the scrolling. In other words, the drawing controller <b>174</b> displays the drawing reception screen <b>30</b>C, which is a new drawing reception screen including the drawing area D corresponding to the scrolling operation on the drawing reception screen <b>30</b>B, in the projection range R. The drawing reception screen <b>30</b>C is an example of a second screen. After the scrolling, the object images O<b>1</b> through O<b>4</b> out of the object images O<b>1</b> through O<b>5</b> are displayed in the drawing reception screen <b>30</b>C, and the object image O<b>5</b> is located outside the display range. In <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the display range of the drawing reception screen <b>30</b>B which has not been scrolled, and the object image O<b>5</b> which is set to a nondisplay state are represented by dotted lines. Further, <figref idref="DRAWINGS">FIG. <b>10</b></figref> shows a positional relationship between the drawing area D and the projection range R. Due to the scrolling, although no change occurs in the drawing area D itself, a change occurs in the range to be displayed as the drawing reception screen <b>30</b> in the projection range R. Specifically, after the scrolling, the reference point P<b>1</b> of the projection range R corresponds to a point P<b>1</b>-D (&#x2212;400,200) in the drawing area D.</p><p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a table of the parameters representing the correspondence relationship between the projection range R shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref> and the drawing area D shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>. Among the parameters, the projection range displacement alone is different form that in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. In other words, since the drawing area D is shifted in the rightward direction and the upward direction with respect to the projection range R, the reference point P<b>1</b>-D of the projection range R is shifted in a leftward direction and a downward direction with respect to the reference point p<b>1</b> of the drawing area D. Therefore, the projection range displacement becomes (&#x2212;400,200).</p><p id="p-0076" num="0075">It is assumed that the user performs drawing on the drawing reception screen <b>30</b>C shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref> as shown in, for example, <figref idref="DRAWINGS">FIG. <b>12</b></figref>. In the drawing reception screen <b>30</b>D shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, there are displayed object images O<b>6</b> through O<b>8</b> newly drawn by the user. The object images O<b>6</b> through O<b>8</b> constitute a character of &#x201c;H.&#x201d; Also in this case, as shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the object images O<b>6</b> through O<b>8</b> are recorded in the drawing area D, but the object images O<b>6</b> through O<b>8</b> are located out of the drawing area D. Therefore, the drawing area D is expanded so that the object images O<b>6</b> through O<b>8</b> which have newly been added fall within the drawing area D. In other words, when an operation of drawing a new object image O in the drawing reception screen <b>30</b>C, the drawing controller <b>174</b> adds an area in which the new object image O is arranged to the drawing area D.</p><heading id="h-0012" level="1">D-2. Expansion of Drawing Area D</heading><p id="p-0077" num="0076">A method of expanding the drawing area D will hereinafter be described. When the pointer <b>20</b> moves on the projection range R in the state in which the pen icon <b>42</b> is selected, the drawing controller <b>174</b> detects the trajectory of the movement of the pointer <b>20</b>. Here, as shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref> and so on, in the state in which the drawing area D has been scrolled, it is necessary to convert the coordinates in the projection range R into the coordinates in the drawing area D. The coordinates in the drawing area D can be obtained by a formula (1) described below. For example, in the drawing reception screen <b>30</b>C shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, when a dot is drawn at a coordinate (100,600) in the projection range R, the dot is located at a coordinate (&#x2212;300, 800) in the drawing area D as a result.</p><p id="p-0078" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>(coordinate in drawing area <i>D</i>)=((coordinate in projection range <i>R</i>)+(projection range displacement))/(scaling ratio)&#x2003;&#x2003; (1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0079" num="0077">Then, the drawing controller <b>174</b> identifies an arrangement area as an area in which the newly drawn object image O is arranged. The arrangement area is assumed as a rectangular area in which a pair of sides extend along the x axis, and the remaining two sides extend along they axis. When all of the coordinates of the vertexes of the arrangement area are included in a range of the current drawing area D, the drawing controller <b>174</b> does not perform the expansion of the drawing area D. In contrast, when any of the vertexes of the arrangement area fails to be included in the range of the current drawing area D, the drawing controller <b>174</b> expands the drawing area D. In other words, the drawing controller <b>174</b> changes the range of the drawing area D so that all of the vertexes in the arrangement area are included within the range of the drawing area D.</p><p id="p-0080" num="0078">A specific description will be presented with reference to <figref idref="DRAWINGS">FIG. <b>14</b></figref> and <figref idref="DRAWINGS">FIG. <b>15</b></figref>. As shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, the arrangement area of the object images O<b>6</b> through O<b>8</b> is a range from a point p<b>3</b> (&#x2212;350,700) to a point p<b>4</b> (&#x2212;110,1150) on the x-y plane. Therefore, the arrangement area of the object images O<b>6</b> through O<b>8</b> is out of the range from the point p<b>1</b> (0,0) to the point p<b>2</b> (1919,1079) as the initial drawing area D<b>0</b>. The drawing controller <b>174</b> expands the drawing area D so that the arrangement area of the object images O<b>6</b> through O<b>8</b> is included. Specifically, as shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, the drawing controller <b>174</b> sets the drawing area D to a range from a point p<b>5</b> (&#x2212;350,0) to a point p<b>6</b> (1919,1150). The drawing area D having been expanded is described as drawing area D<b>1</b>. Thus, the object images O<b>6</b> through O<b>8</b> are included in the drawing area D<b>1</b>. In other words, the drawing area D is an area having a first rectangular shape defined by the x axis and the y axis, and the area in which the new object images O<b>6</b> through O<b>8</b> are arranged is an area having a second rectangular shape surrounding both ends along the x axis of each of the new object images O<b>6</b> through O<b>8</b>, and both ends along the y axis of each of the new object images O<b>6</b> through O<b>8</b>. Adding the arrangement area of the object images O<b>6</b> through O<b>8</b> thus drawn to the drawing area D is expanding the first rectangular shape so that the whole of the second rectangular shape is included in the first rectangular shape.</p><p id="p-0081" num="0079">It should be noted that the arrangement areas of the respective object images O<b>6</b> through O<b>8</b> are united into one area in the explanation described above, but in reality, whether or not the expansion of the drawing area D is necessary is determined every time one of the object images O is drawn, and the drawing area D is expanded as needed. Further, it is possible for the drawing controller <b>174</b> to set a point located at a predetermined distance toward the expansion direction from the arrangement area of the object image O as the range of the drawing area D when expanding the drawing area D. This is for preventing the object image O located in an end portion from being displayed on the edge of the projection range R to improve the visibility when performing the whole display described later.</p><p id="p-0082" num="0080"><figref idref="DRAWINGS">FIG. <b>16</b></figref> shows a display example when performing the whole display of the drawing area D<b>1</b>. When a whole display icon <b>48</b> shown in <figref idref="DRAWINGS">FIG. <b>26</b></figref> is selected after the drawing area D is expanded, the drawing controller <b>174</b> reduces the drawing area D so that the whole of the drawing area D shows up in the projection range R, and displays the result as a whole display screen <b>50</b>. In other words, when the drawing controller <b>174</b> receives an operation of selecting the whole display icon <b>48</b>, the drawing controller <b>174</b> displays a reduced screen obtained by reducing the whole of the drawing area D into the size of the projection range R in the projection range R. The operation of selecting the whole display icon <b>48</b> is an example of a predetermined operation. Hereinafter, when it is necessary to distinguish the individual whole display screens <b>50</b> from each other, there are used the descriptions of whole display screens <b>50</b>A, <b>50</b>B, . . . . The whole display screen <b>50</b>A in <figref idref="DRAWINGS">FIG. <b>16</b></figref> is a screen for displaying the whole of the drawing area D<b>1</b> shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. An aspect ratio of the drawing area D<b>1</b> has a landscape shape having an aspect ratio higher in ratio of the x-axis direction than the aspect ratio of the projection range R. Therefore, the length in the x-axis direction of the drawing area D<b>1</b> is reduced in accordance with the length in the X-axis direction of the projection range R. <figref idref="DRAWINGS">FIG. <b>17</b></figref> is a table of the parameters representing the correspondence relationship between the projection range R shown in <figref idref="DRAWINGS">FIG. <b>16</b></figref> and the drawing area D. A reduction ratio of the projection range R in <figref idref="DRAWINGS">FIG. <b>16</b></figref> is 85%. It should be noted that it is possible to stop the reception of the drawing input during the display of the whole display screen <b>50</b>.</p><heading id="h-0013" level="1">D-3. Reduction of Drawing Area D</heading><p id="p-0083" num="0081">Then, a method of reducing the drawing area D will be described. When the object image O in the drawing reception screen <b>30</b> is erased, the drawing controller <b>174</b> reduces the drawing area D. In other words, when an operation of erasing at least a part of the object image O included in the drawing reception screen <b>30</b> is performed, the drawing controller <b>174</b> excludes an area in which the at least a part has once been arranged from the drawing area D. This is because when the area in which the object image O has been erased is kept included in the drawing area D, the reduction ratio rises when, for example, performing the whole display, and thus, there is a problem that the object image O actually drawn is not eye-friendly. It should be noted that the reduction of the drawing area D is performed only when the object image O located near to the end portion of the drawing reception screen <b>30</b> is erased. The object image O located near to the end portion means, for example, the object image O located so that no other object image O is arranged closer to the end portion than the object image O.</p><p id="p-0084" num="0082">It is assumed that the erasure of the object images O<b>6</b>, O<b>8</b> is performed as in the drawing reception screen <b>30</b>E shown in, for example, <figref idref="DRAWINGS">FIG. <b>18</b></figref> on the drawing reception screen <b>30</b>D in which the object images O<b>1</b> through O<b>4</b>, O<b>6</b> through O<b>8</b> are displayed, and which is shown in, for example, <figref idref="DRAWINGS">FIG. <b>12</b></figref>. The erasure of the object image O is performed by, for example, moving the pointer <b>20</b> on the object image O which is desired to be erased with an erasure icon <b>44</b> described later selected. It should be noted that the whole of the object image O is erased in the following example, but it is possible to partially erase a part of a single object image O.</p><p id="p-0085" num="0083"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a diagram showing the drawing area D<b>1</b> in which the object images O<b>6</b>, O<b>8</b> are erased. As described above, the drawing area D<b>1</b> is the range from the point p<b>5</b> (&#x2212;350,0) to the point p<b>6</b> (1919,1150). The drawing controller <b>174</b> identifies the arrangement areas of all of the object images O located outside the initial drawing area D<b>0</b>, and when an area Dx including the vertexes of the initial drawing area D<b>0</b> and all of the arrangement areas located outside the initial drawing area D<b>0</b> is smaller than the drawing area D<b>1</b>, the drawing controller <b>174</b> sets the area Dx as the drawing area D after the reduction. It should be noted that the area Dx is displayed in <figref idref="DRAWINGS">FIG. <b>20</b></figref>.</p><p id="p-0086" num="0084">In <figref idref="DRAWINGS">FIG. <b>19</b></figref>, the object image O located outside the initial drawing area D<b>0</b> is the object image O<b>7</b> alone. The arrangement area of the object image O<b>7</b> is located in a range from a point p<b>7</b> (&#x2212;120,700) to the point p<b>4</b> (&#x2212;110,1150). Therefore, the area Dx is a range from the point p<b>8</b> (&#x2212;120,0) to the point p<b>6</b> (1919,1150). Since the area Dx is smaller than the drawing area D<b>1</b>, the area Dx is set as a new drawing area D<b>2</b> as shown in <figref idref="DRAWINGS">FIG. <b>20</b></figref>. In other words, excluding the area in which the object image O having been erased has been arranged from the drawing area D is changing the drawing area D into a rectangular shape surrounding both ends along the x axis of one object image O or a plurality of object images O remaining in the drawing area D and both ends along the y axis of the one object image O or the plurality of object images O remaining in the drawing area D. <figref idref="DRAWINGS">FIG. <b>21</b></figref> shows a display example when performing the whole display of the drawing area D<b>2</b>. The whole display screen <b>50</b>B shown in <figref idref="DRAWINGS">FIG. <b>21</b></figref> is made lower in reduction ratio compared to the whole display screen <b>50</b>A of the drawing area D<b>1</b> shown in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, and it is understood that the drawing area D is reduced.</p><p id="p-0087" num="0085">It should be noted that when the area Dx is equal to the drawing area D, the reduction of the drawing area D is not performed. Specifically, when only the object images O<b>7</b>, O<b>8</b> out of the object images O shown in, for example, <figref idref="DRAWINGS">FIG. <b>12</b></figref> are erased, the drawing area D is not reduced.</p><p id="p-0088" num="0086">Further, when the drawing area D is decided based only on, for example, the arrangement area of the object image O, it results in that the drawing area D disappears when all of the object images O in the drawing area D are erased. In order to prevent the above, when reducing the drawing area D, the drawing controller <b>174</b> keeps the size of the drawing area D in at least the size of the projection range R. In the present embodiment, when reducing the drawing area D, the drawing controller <b>174</b> includes the initial drawing area D<b>0</b> in the drawing area D irrespective of the presence or absence of the object image O.</p><heading id="h-0014" level="1">D-4. Initial Drawing Area D<b>0</b></heading><p id="p-0089" num="0087">As described above, the initial drawing area D<b>0</b> is the range from the point p<b>1</b> (0,0) to the point p<b>2</b> (1919,1079), and the drawing reception screen <b>30</b> displayed in the projection range R immediately after the drawing mode is started is the screen for receiving the drawing to the initial drawing area D<b>0</b>. Since no object image O is drawing when starting the drawing mode, it can be said that the initial drawing area D<b>0</b> is a stationary drawing area included in the drawing area D irrespective of the presence or absence of the arrangement of the object image O. In the present embodiment, when keeping the size of the drawing area D in at least the size of the projection range R, the drawing controller <b>174</b> keeps the initial drawing area D<b>0</b> as the drawing area D.</p><p id="p-0090" num="0088">It is assumed that the object images O<b>1</b>, O<b>2</b>, and O<b>7</b> are erased as in the drawing reception screen <b>30</b>F shown in, for example, <figref idref="DRAWINGS">FIG. <b>22</b></figref> in the drawing reception screen <b>30</b>E in which the object images O<b>1</b> through O<b>4</b> and O<b>7</b> are displayed, and which is shown in, for example, <figref idref="DRAWINGS">FIG. <b>12</b></figref>. <figref idref="DRAWINGS">FIG. <b>23</b></figref> shows the drawing area D<b>2</b> corresponding to <figref idref="DRAWINGS">FIG. <b>22</b></figref>. In the drawing area D<b>2</b> shown in <figref idref="DRAWINGS">FIG. <b>22</b></figref>, the object images O<b>1</b>, O<b>2</b>, and O<b>7</b> are erased, and the object images O<b>3</b> through O<b>5</b> remain. Therefore, it is conceivable that the drawing area D is reduced in accordance with the area Dx in which the object images O<b>3</b> through O<b>5</b> are arranged. However, in the present embodiment, the drawing controller <b>174</b> keeps the range of the initial drawing area D<b>0</b> as the drawing area D. <figref idref="DRAWINGS">FIG. <b>24</b></figref> is a diagram showing the state in which the drawing area D is set to the range of the initial drawing area D<b>0</b>. Further, <figref idref="DRAWINGS">FIG. <b>25</b></figref> shows the whole display screen <b>50</b>C obtained by performing the whole display of the initial drawing area D<b>0</b> shown in <figref idref="DRAWINGS">FIG. <b>24</b></figref>. In the whole display screen <b>50</b>C, the object images O<b>3</b> through O<b>5</b> are displayed at substantially the same positions as in the drawing reception screen <b>30</b>B shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0091" num="0089">As described above, by keeping the size of the drawing area D in at least the size of the projection range R, a certain range of the drawing area D is maintained even when there temporarily occurs, for example, the state in which the object image O is not arranged in the process of the drawing operation, and thus, it is possible to enhance the convenience in a drawing work. Further, since the initial drawing area D<b>0</b> is kept as the drawing area D when keeping the size of the drawing area D in at least the size of the projection range R, the area kept as the drawing area D becomes clear, and thus, it is possible to enhance the convenience in the drawing work.</p><heading id="h-0015" level="1">D-5. Drawing Menu Icons <b>40</b></heading><p id="p-0092" num="0090">Then, the drawing menu icons <b>40</b> will be described. <figref idref="DRAWINGS">FIG. <b>26</b></figref> is an enlarged view of the drawing menu icons <b>40</b>. In the drawing reception screen <b>30</b>, there are displayed the drawing menu icons <b>40</b>. In the present embodiment, as the drawing menu icons <b>40</b>, there are displayed the pen icon <b>42</b>, the erasure icon <b>44</b>, the scroll icon <b>46</b>, and the whole display icon <b>48</b>. When the user taps a desired icon with the pointer <b>20</b>, there occurs a state in which that icon is selected. It can be arranged that the selected icon is changed in display configuration such as a color.</p><p id="p-0093" num="0091">In the state in which the pen icon <b>42</b> is selected, when the pointer <b>20</b> moves while keeping contact with the projection range R, a line is displayed along the trajectory of the movement. This line forms the object image O. The state in which the pen icon <b>42</b> is selected is defined as a &#x201c;pen mode.&#x201d; In the state in which the erasure icon <b>44</b> is selected, when the pointer <b>20</b> moves while keeping contact with the projection range R, an area in the object image O located on the trajectory of the movement is erased. The state in which the erasure icon <b>44</b> is selected is defined as an &#x201c;erasure mode.&#x201d; In the state in which the scroll icon <b>46</b> is selected, when the pointer <b>20</b> moves while keeping contact with the projection range R, the drawing reception screen <b>30</b> scrolls along the direction of the movement. The state in which the scroll icon <b>46</b> is selected is defined as a &#x201c;scroll mode.&#x201d; When the whole display icon <b>48</b> is selected, the whole display screen <b>50</b> for displaying the whole of the drawing area D is displayed in the projection range R. During the display of the whole display screen <b>50</b>, an icon for restoring the display in the projection range R to the drawing reception screen <b>30</b> can be displayed. Further, besides the above, it is possible to display a zoom icon for scaling the display image at an arbitrary magnification ratio, a save icon for terminating the drawing to save the drawn image, and so on.</p><heading id="h-0016" level="1">D-6. Method of Drawing Object Image O</heading><p id="p-0094" num="0092">Then, a method of drawing the object image O will be described. As described above, the object image O is a trajectory of the contact position between the pointer <b>20</b> and the projection range R. Therefore, the drawing controller <b>174</b> continuously detects the contact position of the pointer <b>20</b> to detect the trajectory of the contact position of the pointer <b>20</b> in the projection range R during a period from when the pointer <b>20</b> makes contact with the projection range R to when the pointer <b>20</b> is separated therefrom. More particularly, the drawing controller <b>174</b> analyzes the latest infrared light imaging datum every time the infrared light imaging datum is generated to determine whether or not the infrared light is included in the latest infrared light imaging datum. When the infrared light is included in the infrared light imaging datum, the drawing controller <b>174</b> detects a position H of the infrared light on the infrared light imaging datum, and further, converts the position H into a contact position Ha on the frame memory using the calibration datum.</p><p id="p-0095" num="0093">Hereinafter, when the positions H in the infrared light imaging data and the contact positions Ha into which the positions H are converted are each discriminated from each other, there are used the descriptions of the position H(n) and the contact position Ha(n). It is assumed that n is identification information for identifying the generation timing of the infrared light imaging datum, and takes values of contiguous integers. From one infrared light imaging datum, there is obtained one position H, and there is obtained one contact position Ha corresponding to the position H. Therefore, n also functions as identification information for identifying the contact position Ha.</p><p id="p-0096" num="0094"><figref idref="DRAWINGS">FIG. <b>27</b></figref> is a diagram schematically showing a trajectory of the contact position of the pointer <b>20</b>. The trajectory T of the contact position of the pointer <b>20</b> includes a starting point Hs and an ending point He. When the latest contact position Ha(n) is detected, the drawing controller <b>174</b> sets the latest contact position Ha(n) as the starting point Hs of the movement trajectory when the infrared light was not detected in the infrared light imaging datum generated last time, namely when the contact position Ha(n&#x2212;1) does not exist. The drawing controller <b>174</b> associates each of the contact positions Ha(n+1), Ha(n+2), . . . based on the infrared light imaging data subsequently generated with the previous contact position Ha in sequence to generate the trajectory T. Further, when the detection of the infrared light in the infrared light imaging datum stops, the drawing controller <b>174</b> sets the contact position Ha detected lastly as the ending point He of the movement trajectory. In the example shown in <figref idref="DRAWINGS">FIG. <b>27</b></figref>, the contact position is not detected after the contact position Ha(n+x). For example, the contact position Ha(n+x+1) is not detected. Therefore, the contact position Ha(n+x) becomes the ending point He of the trajectory T.</p><p id="p-0097" num="0095">The drawing controller <b>174</b> adds the contact position Ha to the object information of the drawing datum DT every time the contact position Ha is detected. <figref idref="DRAWINGS">FIG. <b>28</b></figref> is a diagram schematically showing the drawing datum DT. Each of the rows of the drawing datum DT shown in <figref idref="DRAWINGS">FIG. <b>28</b></figref> corresponds to the object information as information of individual object image O. The object information is generated when the pointer <b>20</b> makes contact with the projection range R, and the starting point of the trajectory T has been detected. Further, the object information is erased when the object image O is erased by the erasure operation using the erasure icon <b>44</b>.</p><p id="p-0098" num="0096">The object information includes identification information N<b>1</b>, coordinate information N<b>2</b>, color information N<b>3</b>, line type information N<b>4</b>, and width information N<b>5</b> of the object image O. The identification information N<b>1</b> is information for identifying the object image O. The coordinate information N<b>2</b> is information representing the trajectory T of the contact position Ha when the object image O was drawn. The shape of the object image O is defined by the coordinate information N<b>2</b>. The color information N<b>3</b> represents a display color of the object image O in the drawing reception screen <b>30</b>. The line type information N<b>4</b> represents a line type of the object image O in the drawing reception screen <b>30</b>. The width information N<b>5</b> represents a drawing width of the object image O in the drawing reception screen <b>30</b>. The color information N<b>3</b>, the line type information N<b>4</b>, and the width information N<b>5</b> can be designated by the user in the setting screen in, for example, the drawing mode.</p><p id="p-0099" num="0097">The object image O is constituted by dots arranged at points on the frame memory identified by the coordinate information T<b>2</b> described above, and connection lines for connecting the dots adjacent to each other. A central position of this dot is the contact position Ha, and a diameter of this dot is a length corresponding to a drawing width identified by the width information T<b>5</b>. The wider the drawing width is, the larger the diameter of the dot becomes. Further, the line type of the connection lines is identified by the line type information T<b>4</b>. Further, the display color of the dots and the connection lines is identified by the color information T<b>3</b>.</p><heading id="h-0017" level="1">D-7. Flowchart</heading><p id="p-0100" num="0098"><figref idref="DRAWINGS">FIG. <b>29</b></figref> and <figref idref="DRAWINGS">FIG. <b>30</b></figref> show a flowchart showing a flow of an image processing method to be executed by the processing unit <b>17</b> of the projector <b>10</b> in accordance with the control program <b>162</b>. The processing unit <b>17</b> functions as the drawing controller <b>174</b> to thereby execute the steps shown in <figref idref="DRAWINGS">FIG. <b>29</b></figref> and <figref idref="DRAWINGS">FIG. <b>30</b></figref>.</p><p id="p-0101" num="0099">The processing unit <b>17</b> waits until the drawing mode is selected (NO in the step S<b>100</b>), and when it is detected that the drawing mode has been selected (YES in the step S<b>100</b>), the processing unit <b>17</b> displays (step S<b>104</b>) the drawing reception screen <b>30</b> corresponding to the initial drawing area D<b>0</b> in the projection range R. When it is detected that the pointer <b>20</b> makes contact with the projection range R in the scroll mode, and has moved in any direction (YES in the step S<b>106</b>), the processing unit <b>17</b> scrolls (step S<b>108</b>) the display of the drawing area D in the projection range R in the direction in which the pointer <b>20</b> has moved. When a mode other than the scroll mode is selected, when the pointer <b>20</b> does not make contact with the projection range R in the scroll mode, or when the pointer <b>20</b> has made contact with the projection range R but does not move in the scroll mode (NO in the step S<b>106</b>), the processing unit <b>17</b> makes the transition to the step S<b>110</b>.</p><p id="p-0102" num="0100">Further, when it is detected that the pointer <b>20</b> made contact with the projection range R in the pen mode (YES in the step S<b>110</b>), the processing unit <b>17</b> displays (step S<b>112</b>) the trajectory of the movement of the pointer <b>20</b> in the projection range R as the object image O. It should be noted that when the pointer <b>20</b> is separated from the projection range R while being kept unmoved, a dot is displayed at the contact position of the pointer <b>20</b>. Further, the processing unit <b>17</b> records (step S<b>114</b>) the coordinates of the trajectory and so on as the object information. Further, when a mode other than the pen mode is selected, or when the pointer <b>20</b> does not make contact with the projection range R in the pen mode (NO in the step S<b>110</b>), the processing unit <b>17</b> makes the transition to the step S<b>120</b>.</p><p id="p-0103" num="0101">When the object image O is drawn outside the range of the drawing area D (YES in the step S<b>116</b>), the processing unit <b>17</b> expands (step S<b>118</b>) the drawing area D in accordance with the arrangement area of the object image O. When no object image O is drawn outside the range of the drawing area D (NO in the step S<b>116</b>), the processing unit <b>17</b> makes the transition to the step S<b>120</b>.</p><p id="p-0104" num="0102">Further, when the object image O located around the end portion of the drawing area D has been erased (YES in the step S<b>120</b>), whether or not the object image O thus erased is located outside the range of the initial drawing area D<b>0</b> is determined (step S<b>122</b>). When the object image O thus erased is located outside the range of the initial drawing area D<b>0</b> (YES in the step S<b>122</b>), the processing unit <b>17</b> reduces (step S<b>124</b>) the drawing area D in accordance with the arrangement area of the remaining object image O. It should be noted that when the object image O is not erased, or when the object image O located around the center of the drawing area D is erased (NO in the step S<b>120</b>), the processing unit <b>17</b> makes the transition to the step S<b>126</b>. Further, when the object image O thus erased is not located outside the range of the initial drawing area D<b>0</b> (NO in the step S<b>122</b>), namely when the object image O thus erased is located inside the range of the initial drawing area D<b>0</b>, the processing unit <b>17</b> makes the transition to the step S<b>126</b>.</p><p id="p-0105" num="0103">The processing unit <b>17</b> detects that the whole display icon <b>48</b> has been selected to make the whole display instruction (YES in the step S<b>126</b>), the processing unit <b>17</b> displays the whole of the drawing area D at that moment in the projection range R (step S<b>128</b>). When the whole display instruction is not made (NO in the step S<b>126</b>), the processing unit <b>17</b> makes the transition to the step S<b>130</b>. The processing unit <b>17</b> returns to the step S<b>106</b> to repeat the subsequent processing until the user terminates the drawing (NO in the step S<b>130</b>). When the user terminates the drawing (YES in the step S<b>130</b>), the processing unit <b>17</b> ends the processing in the present flowchart.</p><p id="p-0106" num="0104">As described hereinabove, when the operation of erasing at least a part of the object image O included in the drawing reception screen <b>30</b> has been performed, the projector <b>10</b> according to the present embodiment excludes the area in which the part of the object image O thus erased has once been arranged from the drawing area D. Thus, it is possible to prevent the area in which the object image O is no longer arranged from being included in the drawing area D to thereby appropriately maintain the range of the drawing area D, and thus, it is possible to improve the operability in the drawing operation. Further, when the whole display icon <b>48</b> has been selected, the projector <b>10</b> displays the whole display screen <b>50</b> obtained by reducing the whole of the drawing area D into the size of the projection range R in the projection range R. Thus, in particular when performing drawing in a range larger than the projection range R, it is possible for the user to figure out the whole of the image drawn by the user, and thus, it is possible to improve the operability in the drawing operation. Further, in the projector <b>10</b>, since the area in which no object image O is arranged is excluded from the drawing area D, only the portion in which the object image O is arranged is displayed in the whole display screen <b>50</b>. Therefore, it is possible to display only the portion which the user needs as the whole display screen <b>50</b>, and thus, it is possible to enhance the convenience in the drawing work.</p><p id="p-0107" num="0105">Further, when reducing the drawing area D, the projector <b>10</b> keeps the size of the drawing area D in at least the size of the projection range R. Thus, even when there temporarily occurs, for example, the state in which the object image O is not arranged in the process of the drawing operation, a certain range of the drawing area D is maintained, and it is possible to enhance the convenience in the drawing work. Further, when keeping the size of the drawing area D in at least the size of the projection range R, the projector <b>10</b> keeps the initial drawing area D<b>0</b> as the drawing area D. Thus, the area kept as the drawing area D becomes clear, and it is possible to enhance the convenience in the drawing work. Further, when the projector <b>10</b> reduces the drawing area D, the projector <b>10</b> changes the drawing area D to the rectangular shape surrounding the both ends along the x axis and the both ends along the y axis of the object image O remaining in the drawing area D. Thus, it is possible to simply and surely reduce the drawing area D.</p><p id="p-0108" num="0106">Further, when the scrolling operation to the drawing reception screen <b>30</b> has been performed, the projector <b>10</b> displays the new drawing reception screen <b>30</b> including the range of the drawing area D corresponding to the scrolling operation in the projection range R, and when the operation of drawing the new object image O in the new drawing reception screen <b>30</b> has been performed, the area in which the new object image O has been arranged is added to the drawing area D. Thus, it is possible for the user to perform the drawing at an arbitrary position, and thus, it is possible to enhance the convenience in the drawing work. Further, when adding the area in which the new object image O has been arranged to the drawing area D, the projector <b>10</b> expands the rectangular shape defining the drawing area D so that the whole of the rectangular shape surrounding the both ends along the first axis and the both ends along the y axis of the new object image O is included in the rectangular shape defining the drawing area D. Thus, it is possible to simply and surely expand the drawing area D.</p><heading id="h-0018" level="1">E. MODIFIED EXAMPLES</heading><p id="p-0109" num="0107">Each of the aspects illustrated hereinabove can variously be modified. Some aspects of the specific modifications which can be applied to each of the aspects described above will be illustrated below. Two or more aspects arbitrarily selected from the following illustrations can arbitrarily be combined with each other unless conflicting with each other.</p><heading id="h-0019" level="1">E-1. Modified Example 1</heading><p id="p-0110" num="0108">In the embodiment described above, the description is presented assuming that the image processing device is the projector <b>10</b>. This is not a limitation, and the image processing device can be a portable information processing device or the like equipped with a computer coupled to a display or a display. In this case, the display functions as a display device. The display can be, for example, an FPD (Flat Panel Display). The FPD is, for example, a liquid crystal display, a plasma display, or an organic EL (Electro Luminescence) display.</p><heading id="h-0020" level="1">E-2. Modified Example 2</heading><p id="p-0111" num="0109">In the embodiment described above, it is assumed that the position of the pointer <b>20</b> is detected using the infrared light, but the detection method of the position of the pointer <b>20</b> is not limited thereto, and a variety of methods known to the public can be applied. For example, it is possible for the detection device for detecting the position of the pointer <b>20</b> to irradiate the pointer <b>20</b> with light having a predetermined wavelength, and receive the light reflected by the pointer <b>20</b> to thereby detect the position of the pointer <b>20</b>. The detection device can be a device for detecting a position where the light is blocked by the pointer <b>20</b> using a device for emitting the infrared light or a laser source, and a light receiving device. When using these methods, the pointer <b>20</b> can be a finger of the user.</p><heading id="h-0021" level="1">E-3. Modified Example 3</heading><p id="p-0112" num="0110">In the embodiment described above, the size of the drawing area D is kept in at least the size of the projection range R. On this occasion, what is kept as the drawing area D is the initial drawing area D<b>0</b>. This is not a limitation, and an area shifted from the initial drawing area D<b>0</b> can be kept as the drawing area D. For example, in a state in which the object image O is not drawn in the initial drawing area D<b>0</b>, and the object image O is drawn only at the position shifted from the initial drawing area D<b>0</b>, the periphery of the area in which the object image O is drawn can be kept as the drawing area D. Thus, it is possible for the user to keep an arbitrary area as the drawing area D.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image processing method comprising:<claim-text>displaying a first screen on a display surface, the first screen including at least a part of a drawing area in which at least one object image drawn by a user is arranged;</claim-text><claim-text>excluding an area in which at least a part of an object image included in the first screen is arranged from the drawing area when an operation of erasing the at least a part of the object is received; and</claim-text><claim-text>displaying a reduced screen on the display surface when an operation is received, the reduced screen being obtained by reducing a whole of the drawing area into a size of the display surface.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The image processing method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the excluding includes keeping a size of the drawing area in at least the size of the display surface.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The image processing method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the drawing area include a stationary drawing area irrespective of presence or absence of the object image, and</claim-text><claim-text>the keeping includes keeping the stationary drawing area as the drawing area.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The image processing method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the drawing area is an area having a first rectangular shape defined by a first axis and a second axis perpendicular to the first axis, and</claim-text><claim-text>the excluding is changing the drawing area into a rectangular shape surrounding both ends along the first axis of at least one object image remaining in the drawing area and both ends along the second axis of the at least one object image remaining in the drawing area.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The image processing method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising:<claim-text>displaying a second screen on the display surface, the second screen including a range of the drawing area corresponding to a scrolling operation to the first screen; and</claim-text><claim-text>adding an area in which a new object image is arranged to the drawing area when an operation of drawing the new object image in the second screen is received.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The image processing method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein<claim-text>the area is an area having a second rectangular shape surrounding both ends along the first axis of the new object image and both ends along the second axis of the new object image, and</claim-text><claim-text>adding the area is expanding the first rectangular shape to include a whole of the second rectangular shape in the first rectangular shape.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. An image processing device comprising:<claim-text>a display device; and</claim-text><claim-text>at least one processor programmed to<claim-text>display a first screen on a display surface using the display device, the first screen including at least a part of a drawing area in which at least one object image drawn by a user is arranged,</claim-text><claim-text>exclude an area in which at least a part of an object image included in the first screen is arranged from the drawing area when an operation of erasing the at least a part of the object is received, and</claim-text><claim-text>displaying a reduced screen on the display surface using the display device when an operation is received, the reduced screen being obtained by reducing a whole of the drawing area into a size of the display surface.</claim-text></claim-text></claim-text></claim></claims></us-patent-application>
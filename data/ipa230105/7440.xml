<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007441A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007441</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17940418</doc-number><date>20220908</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>W</subclass><main-group>4</main-group><subgroup>029</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>W</subclass><main-group>4</main-group><subgroup>38</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>W</subclass><main-group>24</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>W</subclass><main-group>4</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>W</subclass><main-group>64</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>W</subclass><main-group>4</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20180201</date></cpc-version-indicator><section>H</section><class>04</class><subclass>W</subclass><main-group>4</main-group><subgroup>029</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20180201</date></cpc-version-indicator><section>H</section><class>04</class><subclass>W</subclass><main-group>4</main-group><subgroup>38</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>W</subclass><main-group>24</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>W</subclass><main-group>4</main-group><subgroup>023</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>W</subclass><main-group>64</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180201</date></cpc-version-indicator><section>H</section><class>04</class><subclass>W</subclass><main-group>4</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEM AND METHOD FOR AUTOMATED DATA COLLECTION AND ANCHOR LOCATION EVALUATION</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17219245</doc-number><date>20210331</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11470451</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17940418</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>63039759</doc-number><date>20200616</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>DENSO International America, Inc.</orgname><address><city>Southfield</city><state>MI</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant><us-applicant sequence="01" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>DENSO CORPORATION</orgname><address><city>Kariya-shi</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Cooper</last-name><first-name>Kyle</first-name><address><city>Plainwell</city><state>MI</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Smith</last-name><first-name>Eric J.</first-name><address><city>Holland</city><state>MI</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Vredevoogd</last-name><first-name>Loren</first-name><address><city>Holland</city><state>MI</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A system and method for obtaining location data for a portable device relative to an object. The system and method may include an object device disposed in a fixed position relative to the object, the object device having an antenna configured to communicate wirelessly via UWB with the portable device via a communication link. The system may include a control system, such as a robot and/or a remote controller, configured to obtain one or more samples pertaining to communications between the portable device and the object device.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="234.95mm" wi="154.60mm" file="US20230007441A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="137.41mm" wi="163.24mm" file="US20230007441A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="232.58mm" wi="139.70mm" file="US20230007441A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="200.15mm" wi="154.77mm" file="US20230007441A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="221.66mm" wi="166.88mm" file="US20230007441A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="143.59mm" wi="175.51mm" file="US20230007441A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="229.02mm" wi="171.70mm" file="US20230007441A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="204.30mm" wi="166.37mm" file="US20230007441A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="228.09mm" wi="155.62mm" orientation="landscape" file="US20230007441A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="189.06mm" wi="138.26mm" file="US20230007441A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="235.29mm" wi="178.22mm" file="US20230007441A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="234.70mm" wi="125.14mm" file="US20230007441A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="184.66mm" wi="141.48mm" file="US20230007441A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="182.20mm" wi="151.30mm" file="US20230007441A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="240.54mm" wi="159.09mm" file="US20230007441A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="170.77mm" wi="138.01mm" file="US20230007441A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="217.85mm" wi="161.46mm" file="US20230007441A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="237.91mm" wi="156.72mm" file="US20230007441A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="169.59mm" wi="155.87mm" file="US20230007441A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="141.56mm" wi="149.52mm" file="US20230007441A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="196.17mm" wi="157.99mm" file="US20230007441A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="218.10mm" wi="156.72mm" file="US20230007441A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="233.60mm" wi="139.36mm" file="US20230007441A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00023" num="00023"><img id="EMI-D00023" he="207.60mm" wi="111.68mm" orientation="landscape" file="US20230007441A1-20230105-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00024" num="00024"><img id="EMI-D00024" he="226.14mm" wi="131.74mm" orientation="landscape" file="US20230007441A1-20230105-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00025" num="00025"><img id="EMI-D00025" he="226.57mm" wi="127.42mm" orientation="landscape" file="US20230007441A1-20230105-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00026" num="00026"><img id="EMI-D00026" he="227.33mm" wi="126.15mm" orientation="landscape" file="US20230007441A1-20230105-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00027" num="00027"><img id="EMI-D00027" he="234.27mm" wi="131.15mm" orientation="landscape" file="US20230007441A1-20230105-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00028" num="00028"><img id="EMI-D00028" he="226.14mm" wi="133.52mm" orientation="landscape" file="US20230007441A1-20230105-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00029" num="00029"><img id="EMI-D00029" he="206.59mm" wi="113.88mm" orientation="landscape" file="US20230007441A1-20230105-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD OF INVENTION</heading><p id="p-0002" num="0001">The present disclosure relates to a system and method for data collection with respect to a location system, and more particularly for a location system that determines location of a portable device with respect to an object, such as a vehicle.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Ultra wideband (UWB) technology for cooperative source localization has been actively researched over the last 15 years with predecessors dating back to the 1970s. Using UWB for remote keyless entry to vehicles (via a smartphone and an on-vehicle suite of anchors or devices) is much newer; with industry leaders still looking to develop and standardize such systems. For example, currently, only a single line of smartphones includes UWB capability. One of the many challenges for placing UWB anchors on a vehicle is understanding where they should be placed and what type of performance should be expected with respect to accurate ranging and subsequent localization of the initiator (smartphone).</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">In one embodiment, a system for obtaining location data for a portable device relative to an object is provided. The system may include an object device disposed in a fixed position relative to the object, the object device having an antenna configured to communicate wireles sly via UWB with the portable device via a communication link. The system may include a control system, such as a robot and/or a remote controller, configured to obtain one or more samples pertaining to communications between the portable device and the object device.</p><p id="p-0005" num="0004">The control system may be configured to obtain a first set of the one or more samples with respect to the portable device being at a first position, and to obtain a second set of the one or more samples with respect to the portable device being at a second position.</p><p id="p-0006" num="0005">The system may include a movable body operably coupled to the portable device, where the movable body is configured to position the portable device in accordance with a position directive communicated from the control system.</p><p id="p-0007" num="0006">The control system of the system may be configured to direct movement of the movable body to change a position of the portable device from the first position to the second position.</p><p id="p-0008" num="0007">In one embodiment, the control system may be configured to calculate a set of metrics at each of the first and second positions. The control system may generate a composite score for each of the first and second positions respectively based on the set of metrics.</p><p id="p-0009" num="0008">In one embodiment, the composite score is indicative of a performance of an anchor position for a UWB sensor on the object.</p><p id="p-0010" num="0009">In one embodiment, the control system may be configured to generate one or more candidate anchor positions based on the composite scores generated with respect to the first and second positions.</p><p id="p-0011" num="0010">In general, one innovative aspect of the subject matter described herein can be a system for obtaining location data for a portable device relative to an object. The system may include one or more of the following: an object device disposed in a fixed position relative to the object, the object device having an antenna configured to communicate wirelessly via UWB with the portable device via a communication link; a control system configured to obtain one or more samples pertaining to communications between the portable device and the object device, the control system configured to obtain a first set of the one or more samples with respect to the portable device being at a first position, the control system configured to obtain a second set of the one or more samples with respect to the portable device being at a second position; a movable body operably coupled to the portable device, the movable body being configured to position the portable device in accordance with a position directive communicated from the control system; and the control system configured to direct movement of the movable body to change a position of the portable device from the first position to the second position.</p><p id="p-0012" num="0011">The foregoing and other embodiments can each optionally include one or more of the following features, alone or in combination. In particular, one embodiment includes all the following features in combination.</p><p id="p-0013" num="0012">In some embodiments, the control system may be configured to obtain sensor characteristic data for the first and second positions, where the control system may be configured to generate a composite score for the object device based on the sensor characteristic data.</p><p id="p-0014" num="0013">In some embodiments, the composite score may be indicative of a performance of a sensor position for a UWB sensor on the object.</p><p id="p-0015" num="0014">In some embodiments, the system comprises first and second sensor devices disposed on the object at respective first and second candidate locations, where the first sensor device is the object device.</p><p id="p-0016" num="0015">In some embodiments, the control system may be configured to calculate a first composite score for the first sensor and a second composite score for the second sensor.</p><p id="p-0017" num="0016">In some embodiments, the control system may be configured to identify a relative ranking of the first and second candidate locations based on the first and second composite scores.</p><p id="p-0018" num="0017">In some embodiments, the relative ranking is indicative of a position providing greater accuracy relative to another position in determining a location of the portable device relative to the object, where the location of the portable device may be determined based on communications with the portable device via UWB.</p><p id="p-0019" num="0018">In some embodiments, the composite score is based on an RMSE metric and a FWHM metric of the RMSE metric, where the RMSE metric and the FWHM metric are based on range measurements, where the range measurements are determined with respect UWB communications with the portable device and based on sensor characteristic data obtained for each of the first and second sensors.</p><p id="p-0020" num="0019">In some embodiments, the composite score is based on a detectability metric.</p><p id="p-0021" num="0020">In general, one innovative aspect of the subject matter described herein can include a method of evaluating performance of a first and second sensors disposed on an object at respective first and second candidate location, the performance pertaining to effectiveness for determining a location of a portable device relative to the object. The method may include one or more of the following: communicating wireles sly between the portable device and the first sensor at a first position; obtaining at least one first range measurement with respect to communications between the portable device and the first sensor at the first position; communicating wirelessly between the portable device and the second sensor at the first position; obtaining at least one second range measurement with respect to communications between the portable device and the second sensor at the first position; communicating a directive to a movable body to move the portable device from the first position to a second position; communicating wireles sly between the portable device and the first sensor at the second position; obtaining at least one third range measurement with respect to communications between the portable device and the first sensor at the second position; communicating wirelessly between the portable device and the second sensor at the second position; obtaining at least one fourth range measurement with respect to communications between the portable device and the second sensor at the second position; ranking a performance of the first and second sensors at the respective first and second candidate locations.</p><p id="p-0022" num="0021">The foregoing and other embodiments can each optionally include one or more of the following features, alone or in combination. In particular, one embodiment includes all the following features in combination.</p><p id="p-0023" num="0022">In some embodiments, the method comprises determining a first metric for the first sensor based on the first and third range measurements; determining a second metric for the second sensor based on the second and fourth range measurements; and ranking the performance of the first and second sensors based on the first and second metrics.</p><p id="p-0024" num="0023">In some embodiments, the method comprises determining a third metric for the first sensor based on the first and third range measurements; determining a fourth metric for the second sensor based on the second and fourth range measurements; generating a first composite score for the first sensor based on the first and third metrics; generating a second composite score for the second sensor based on the second and fourth metrics; ranking the performance of the first and second sensors based on the first and second composite scores.</p><p id="p-0025" num="0024">In some embodiments, the method comprises determining a performance score for the first and second sensor with respect to first and second zones, and generating composite scores for the first and second sensors respectively based on the performance score for the first and second zones.</p><p id="p-0026" num="0025">In some embodiments, the method comprises transmitting a position directive to the movable body to travel from the first position to the second position.</p><p id="p-0027" num="0026">In some embodiments, the wireless communications may be UWB communications.</p><p id="p-0028" num="0027">In general, one innovative aspect of the subject matter described herein can include a system for evaluating performance of first and second sensors disposed on an object at respective first and second candidate locations, the performance pertaining to effectiveness for determining a location of a portable device relative to the object. The system may include one or more of the following: a movable body operably coupled to the portable device, the movable body being configured to position the portable device in accordance with a position directive; and a control system configured to obtain first samples pertaining to communications between the portable device and the first sensor at a first position. The control system may be configured to obtain second samples pertaining to communications between the portable device and the second sensor at the first position, and to obtain third samples pertaining to communications between the portable device and the first sensor at a second position. The control system may be configured to obtain fourth samples pertaining to communications between the portable device and the second sensor at the second position, where the control system is configured to communicate the position directive to the movable body to change a position of the portable device from the first position to the second position. The control system may be configured to rank a performance of the first and second sensors at the respective first and second candidate locations.</p><p id="p-0029" num="0028">The foregoing and other embodiments can each optionally include one or more of the following features, alone or in combination. In particular, one embodiment includes all the following features in combination.</p><p id="p-0030" num="0029">In some embodiments, the control system is operable to determine a first metric for the first sensor based on the first and third samples and to determine a second metric for the second sensor based on the second and fourth samples, where the control system is operable to rank the performance of the first and second sensors based on the first and second metrics.</p><p id="p-0031" num="0030">In some embodiments, the control system is operable to determine a performance score for the first and second sensors with respect to first and second zones, where the control system is configured to generate composite scores for the first and second sensors respectively based on the performance score for the first and second zones.</p><p id="p-0032" num="0031">In some embodiments, the communications are UWB communications.</p><p id="p-0033" num="0032">Before the embodiments of the invention are explained in detail, it is to be understood that the invention is not limited to the details of operation or to the details of construction and the arrangement of the components set forth in the following description or illustrated in the drawings. The invention may be implemented in various other embodiments and of being practiced or being carried out in alternative ways not expressly disclosed herein. Also, it is to be understood that the phraseology and terminology used herein are for the purpose of description and should not be regarded as limiting. The use of &#x201c;including&#x201d; and &#x201c;comprising&#x201d; and variations thereof is meant to encompass the items listed thereafter and equivalents thereof as well as additional items and equivalents thereof. Further, enumeration may be used in the description of various embodiments. Unless otherwise expressly stated, the use of enumeration should not be construed as limiting the invention to any specific order or number of components. Nor should the use of enumeration be construed as excluding from the scope of the invention any additional steps or components that might be combined with or into the enumerated steps or components.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a system in accordance with one embodiment of the present disclosure.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a device in accordance with one embodiment.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a locator in accordance with one embodiment.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a system in accordance with one embodiment.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a performance evaluation system in accordance with one embodiment of the present disclosure.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the performance evaluation system of <figref idref="DRAWINGS">FIG. <b>5</b></figref> in perspective.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIGS. <b>7</b> and <b>8</b></figref> show a side view of the performance evaluation system with candidate locations.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>9</b></figref> depicts a data collection path in accordance with one embodiment of the performance evaluation system.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIGS. <b>10</b>A-O</figref> show various types of zones for evaluation in the performance evaluation system of one embodiment.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows a data collection path and zone for the performance evaluation system of one embodiment.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>12</b></figref> depicts the performance evaluation system in accordance with one embodiment.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>13</b></figref> depicts the performance evaluation system in accordance with one embodiment.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>14</b></figref> shows measurements or samples obtained with respect to communication at a position in the performance evaluation system of one embodiment.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>15</b></figref> shows data analysis of the measurements or samples shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>16</b></figref> shows further data analysis of the measurements or examples shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>17</b></figref> shows a method of determining a detectability metric in accordance with one embodiment.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>18</b></figref> shows a visual of the detectability metric in accordance with one embodiment.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>19</b></figref> shows the detectability metric determined with respect to a zone under test in accordance with one embodiment.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>20</b></figref> shows the detectability metric determined with respect to a zone under test in accordance with one embodiment.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>21</b></figref> shows a composite score for the detectability metric of multiple zones under test in accordance with one embodiment.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>22</b></figref> shows an RMSE metric determined with respect to a zone under test in accordance with one embodiment.</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>23</b></figref> shows the RMSE metric determined with respect to multiple zones under test in accordance with one embodiment.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>24</b></figref> shows a method of determining the RMSE metric in one embodiment.</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>25</b></figref> shows a distribution of RMSE for a zone under test in accordance with one embodiment.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>26</b></figref> shows a method of determining an FWHM metric in one embodiment.</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>27</b></figref> shows a visual of the FWHM metric in one embodiment.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>28</b></figref> shows the FWHM metric determined with respect to multiple zones under test in accordance with one embodiment.</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>29</b></figref> shows a delta RMSE metric determined in conjunction with a zone under test in an obstruction based performance evaluation in one embodiment.</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>30</b></figref> shows a distribution of the delta RMSE metric for obstruction and non-obstruction test conditions in accordance with one embodiment.</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>31</b></figref> shows a matrix of detectability for zones under test and candidate locations in accordance with one embodiment.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>32</b></figref> shows a matrix of RMSE for zones under test and candidate locations in accordance with one embodiment.</p><p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. <b>33</b></figref> shows a matrix of FWHM for zones under test and candidate locations in accordance with one embodiment.</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>34</b></figref> shows a matrix of delta RMSE for zones under test and candidate locations in accordance with one embodiment.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>35</b></figref> shows composite rankings of candidate locations for multiple performance metrics in accordance with one embodiment.</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. <b>36</b></figref> shows a distribution of the composite rankings of <figref idref="DRAWINGS">FIG. <b>35</b></figref>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0069" num="0068">In one embodiment, a data collection system that includes automated data collection elements is provided. For example, a robot (or automated device) may be programmed to carry a UWB initiator along a predefined path (like a cornrow pattern), stopping for predefined intervals (e.g., 60 seconds) at predefined spacing (0.2 m). The initiator mounted to the robot may be wirelessly connected to a computer (or data collection device) via a Bluetooth gateway where ranging data is recorded at some sample rate (1 Hz or greater, 3.4 Hz or greater, 10 Hz or greater). Any sampling rate can be used including but not limited to 1Hz, 3.4 Hz, and 10 Hz. In one instance, the sampling rate for a test system may be aligned or matched to a target sampling rate for a deployed or production system.</p><p id="p-0070" num="0069">A set of anchors (e.g., 11 anchors or devices) may be placed in and around a vehicle, and configured to communicate with the initiator to measure range between each anchor and initiator.</p><p id="p-0071" num="0070">Ranging may be achieved via a number of techniques. In one embodiment, a cooperative double sided, two-way ranging technique may be implemented. Because the robot is dwelling at a location for a set amount of time, the computer records an ensemble of range measurements between the initiator and each anchor. The robot dwells at each location in some predefined area and the system collects range data for each data point.</p><p id="p-0072" num="0071">After the data is collected, post processing and analysis may be performed. The robot's position at each point with respect to the anchors may be determined and aligned with the collected range data. This can be done by using the logged, dead reckoning information from the robot along with time stamps in both the robot's logs and the UWB ranging data files to 1) align the robot in a coordinate system and 2) align the time the ranging data was collected to where the robot was located. In this way, ground truth may be established for the robot and, along with knowledge of where the anchors were placed, actual range from each anchor to each ground truth location.</p><p id="p-0073" num="0072">Analysis in accordance with one embodiment may enable the system to determine anchor performance and to compare the performance to different anchor locations around the vehicle. A number of metrics may be employed to determine performance. As an example, the following four metrics may be utilized to evaluate performance: 1) root-mean-square error (RMSE); 2) full width half maximum (FWHM) of root-mean-square error; 3) a bespoke detectability metric; and 4) the change in RMSE when the initiator is in the clear (mounted on a PVC stand on the robot) as compared to when the initiator is placed in a human's back pocket. A composite score based on one or more metrics used to evaluate performance may be generated for each anchor location. As an example, the composite score may be determined by multiplying the metrics as follows: detectability*(1/RMSE)*(1/FWHM)*(1/change in RMSE with back pocket).</p><p id="p-0074" num="0073">In one embodiment, in a remote keyless access system, some areas in relation to the vehicle are considered more significant than others. For example, the area near the driver's side door may be considered important because, in operational parameters for a real system, the door needs to unlock when the driver is proximate. Some areas are considered important for commercial reasons related to car insurance standards, which dictate performance standards for certain locations around a vehicle. Consequently, the metrics used to analyze anchor performance may be computed for different zones to better indicate performance of the anchor in a localization (or zone classification) system in that zone. Performance for the localization system in a zone or area considered to be of high value or significant may be evaluated based on performance for an anchor of that zone or area with respect to other zones.</p><p id="p-0075" num="0074">While any number of zones may be used, in one embodiment, 15 zones around the driver's side zone of the vehicle may be identified and evaluated. Other zones including a mirror symmetrical set on the passenger side of the vehicle may be considered as well as different zones in front or back of the vehicle. By having overlap in the area of the 15 zones, the overall scoring can be weighted to areas considered significant or high value&#x2014;e.g., areas that are in more than one zone.</p><p id="p-0076" num="0075">It is noted that the detectability metric may vary from application to application, and may be evaluated in conjunction with multiple metrics. The detectability metric may indicate a likelihood of correctly classifying a zone based on the range measurements for an anchor at a given point in the zone. However, the present disclosure is not limited to the detectability metric. For instance, a different metric or multiple metrics may be used. As another example, the detectability metric may be provided as one input into a Bayesian zone classifier. That is, a generalized likelihood ratio test (GLRT) may be implemented that determines the likelihood that an initiator was in a zone based on the joint likelihood for each anchor's range measurements. The GLRT may calculate a probability of detection/probability of no detection for each anchor and the zone with the highest value may be determined to be the zone where the initiator is located.</p><p id="p-0077" num="0076">In an alternative embodiment, a system of anchor evaluation may not apply to a vehicle access system. The system can be used to assess anchor or beacon locations for any type of distributed localization system. For example, to configure a set of anchors in a commercial space that localize smartphones distributed in that commercial space, knowledge of where to place the anchors or beacons will be valuable for the same reasons that it is useful for vehicle access systems; namely to mitigate locations that would result in blind spots or anchors that produce deleterious data that erodes localization performance.</p><p id="p-0078" num="0077">In an alternative embodiment, to determine ground truth, a camera may be used along with computer vision (CV) software to determine where the initiator is at each frame of a video feed. The camera may be positioned with a view of the experimental collection field and calibrate pixels via in scene fiducials. Then the CV software may track the initiator, transform the tracked camera coordinates (e.g., pixel location) to a world coordinate system (e.g., Cartesian coordinate with predefined origin).</p><p id="p-0079" num="0078">In an alternative embodiment, the robot may be constrained with the initiator to an area with respect to the vehicle that matches each zone under test. In this way, the range data that is collected can be directly correlated to a zone under test with no knowledge of exact robot position. This approach may aid in determining zone-based metrics and may be used to gather data for a machine learning algorithm that matches range measurements to a zone. However, constraining the robot and associated data collection may be less impactful in conducting localization-centric analysis. In an alternative embodiment, a robot may be absent, and a human may carry the initiator and constrain the initiator to an area that aligns with a zone under test. As with the robot, the range data that is collected can be directly correlated to a zone under test with no knowledge of exact position of the human and the initiator.</p><p id="p-0080" num="0079">In one embodiment, the system and methods described herein may facilitate anchor location performance evaluation with respect to a UWB-based remote access system. As described herein, the system and methods may be adapted for the realm of vehicles but the present disclosure is not so limited. The systems and methods may be adapted for other realms, such as non-vehicle based UWB localization system.</p><p id="p-0081" num="0080">I. Location System Overview</p><p id="p-0082" num="0081">A system in accordance with one embodiment is shown in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>1</b></figref> and generally designated <b>100</b>. The system <b>100</b> may include one or more system components as outlined herein. A system component may be a user <b>60</b> or an electronic system component, which may be the remote device <b>20</b>, a sensor <b>40</b>, or an object device <b>50</b>, or a component including one or more aspects of these devices. The underlying components of the object device <b>50</b>, as discussed herein, may be configured to operate in conjunction with any one or more of these devices. In this sense, in one embodiment, there may be several aspects or features common among the remote device <b>20</b>, the sensor <b>40</b>, and the object device <b>50</b>. The features described in connection with the object device <b>50</b> depicted in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may be incorporated into the remote device <b>20</b> or the sensor <b>40</b>, or both. In one embodiment, the object device <b>50</b> may form an equipment component disposed on an object <b>10</b>, such as a vehicle or a building. The object device <b>50</b> may be communicatively coupled to one or more systems of the object <b>10</b> to control operation of the object <b>10</b>, to transmit information to the one or more systems of the object <b>10</b>, or to receive information from the one or more systems of the object <b>10</b>, or a combination thereof. For instance, the object <b>10</b> may include an object controller configured to control operation of the object <b>10</b>. The object <b>10</b> may include one or more communication networks, wired or wireless, that facilitate communication between the object controller and the object device <b>50</b>. The communication network for facilitating communications between the object device <b>50</b> and the object controller may be a CAN bus; however, it is to be understood that the communication network is not so limited. The communication network may be any type of network, including a wired or wireless network, or a combination of two or more types of networks.</p><p id="p-0083" num="0082">The system <b>100</b> in the illustrated embodiment may be configured to determine location information in real-time with respect to the remote device <b>20</b>. In the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the user <b>60</b> may carry the remote device <b>20</b> (e.g., a smartphone). The system <b>100</b> may facilitate locating the remote device <b>20</b> with respect to the object <b>10</b> (e.g., a vehicle) in real-time with sufficient precision to determine whether the user <b>60</b> is located at a position at which access to the object <b>10</b> or permission for an object <b>10</b> command should be granted.</p><p id="p-0084" num="0083">For instance, in an embodiment where the object <b>10</b> is a vehicle, the system <b>100</b> may facilitate determining whether the remote device <b>20</b> is outside the vehicle but in close proximity, such as within 5 feet, 3 feet, or 2 feet or less, to the driver-side door <b>15</b>. This determination may form the basis for identifying whether the system <b>100</b> should unlock the vehicle. On the other hand, if the system <b>100</b> determines the remote device <b>20</b> is outside the vehicle and not in close proximity to the driver-side door (e.g., outside the range of 2 feet, 3 feet, or 5 feet), the system <b>100</b> may determine to lock the driver-side door. As another example, if the system <b>100</b> determines the remote device <b>20</b> is in close proximity to the driver-side seat but not in proximity to the passenger seat or the rear seat, the system <b>100</b> may determine to enable mobilization of the vehicle. Conversely, if the remote device <b>20</b> is determined to be outside close proximity to the driver-side seat, the system <b>100</b> may determine to immobilize or maintain immobilization of the vehicle.</p><p id="p-0085" num="0084">The object <b>10</b> may include multiple object devices <b>50</b> or a variant thereof, such as an object device <b>50</b> including a sensor <b>40</b> coupled to an antenna array <b>30</b>, in accordance with one or more embodiments described herein.</p><p id="p-0086" num="0085">Micro-location of the remote device <b>20</b> may be determined in a variety of ways, such as using information obtained from a global positioning system, one or more signal characteristics of communications from the remote device <b>20</b>, and one or more sensors (e.g., a proximity sensor, a limit switch, or a visual sensor), or a combination thereof. An example of microlocation techniques for which the system <b>100</b> can be configured are disclosed in U.S. Nonprovisional patent application Ser. No. 15/488,136 to Raymond Michael Stitt et al., entitled SYSTEM AND METHOD FOR ESTABLISHING REAL-TIME LOCATION, filed Apr. 14, 2017&#x2014;the disclosure of which is hereby incorporated by reference in its entirety.</p><p id="p-0087" num="0086">In one embodiment, in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>1</b>-<b>3</b></figref>, the object device <b>50</b> (e.g., a system control module (SCM)) and a plurality of sensors <b>40</b> (coupled to an antenna array <b>30</b> shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>) may be disposed on or in a fixed position relative to the object <b>10</b>. Example use cases of the object <b>10</b> include the vehicle identified in the previous example, or a building for which access is controlled by the object device <b>50</b>.</p><p id="p-0088" num="0087">The remote device <b>20</b> may communicate wirelessly with the object device <b>50</b> via a communication link <b>140</b>, such as a BLE communication link or an Ultra Wideband (UWB) communication link. The plurality of sensors <b>40</b> may be configured to sniff the communications of the communication link <b>140</b> between the remote device <b>20</b> and the object device <b>50</b> to determine one or more signal characteristics of the communications, such as signal strength, time of arrival, time of flight, or angle of arrival, or a combination thereof. The determined signal characteristics may be communicated or analyzed and then communicated to the object device <b>50</b> via a communication link <b>130</b> separate from the communication link between the remote device <b>20</b> and the object device <b>50</b>. Additionally, or alternatively, the remote device <b>20</b> may establish a direct communication link with one or more of the sensors <b>40</b>, and the one or more signal characteristics may be determined based on this direct communication link.</p><p id="p-0089" num="0088">For instance, an alternative configuration of the system is shown in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, and generally designated <b>100</b>&#x2032;. The system <b>100</b>&#x2032; may include a remote device <b>20</b>, a user <b>60</b>, and an object <b>10</b>, similar to the system <b>100</b> described in conjunction with <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The object <b>10</b> in accordance with one embodiment may include an object device <b>50</b>, an object control <b>12</b>, and a plurality of sensors, which may be similar to the sensors <b>40</b> described herein.</p><p id="p-0090" num="0089">In the illustrated embodiment, the remote device <b>20</b> may include both UWB and BTLE communication capabilities. For instance, the remote device <b>20</b> may be a portable device in the form of a smartphone with both UWB and BLE radios.</p><p id="p-0091" num="0090">The system <b>100</b>&#x2032; in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>4</b></figref> may include one or more sensors <b>40</b> (which may also be described as anchors) that are disposed on the object <b>10</b>. The one or more sensors <b>40</b> may be disposed in a variety of positions on the object <b>10</b>, such as the positions described herein, including for instance, one or more sensors <b>40</b> in the door panel and one or more other sensors in the B pillar, as shown and described, for example, in connection with <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref>.</p><p id="p-0092" num="0091">One or more of the sensors <b>40</b> may be operable to communicate via at least one communication link according to a communication protocol. The communication link may be established via one or more channels. As described in connection with <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>2</b></figref>, the sensor <b>40</b> may be operable to communicate by sniffing or receiving communications via at least one communication link <b>140</b> established between the object device <b>50</b> and the remote device <b>20</b>, such that the sensor <b>40</b> does not transmit communications via the communication link <b>140</b>. This type of communication for the sensor <b>40</b> is shown in phantom lines in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0093" num="0092">One or more sensors <b>40</b> in the system <b>100</b>&#x2032; of <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be operable to communicate by transmitting and receiving communications via at least one communication link <b>170</b> established directly with the remote device <b>20</b>. In this way, the sensor <b>40</b> may directly communicate with the remote device <b>20</b>. The at least one communication link <b>170</b> may include communications according to more than one protocol (e.g., BTLE and UWB).</p><p id="p-0094" num="0093">The one or more sensors <b>40</b> of the system <b>100</b>&#x2032; in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be operable to a) sniff communications with respect to the communication link <b>140</b> between the remote device <b>20</b> and the object device <b>50</b>, or b) directly communicate with the remote device <b>20</b> via the at least one communication link <b>170</b>. The communication capabilities of the one or more sensors <b>40</b> in the illustrated embodiment is identified in the figure and by a letter designation U for UWB and B or BTLE. For example, the sensor <b>40</b>U is an ultra-wideband anchor responsive to UWB signals; sensor <b>40</b>U+B is responsive to both UWB and BTLE communications; and sensor <b>40</b>B is a BTLE anchor.</p><p id="p-0095" num="0094">It is to be understood that an object <b>10</b>, such as a vehicle, may include more sensors <b>40</b> than shown in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>4</b></figref>. Depending on the implementation, some number of sensors <b>40</b> may be integrated in a vehicle. For instance, <b>3</b> to <b>10</b> sensors <b>40</b> with both UWB and BTLE capabilities may be provided.</p><p id="p-0096" num="0095">In one embodiment, UWB, similar to BTLE, is a standardized communication protocol (see IEEE 802.15.4a/z). One way in which UWB may differ from BTLE is with respect to ranging applications. UWB may involve transmitting short duration pulses that allow for time-of-flight functions to be used to determine the range from the remote device <b>20</b> to one or more sensors <b>40</b>U, <b>40</b>U+B (e.g., anchors). Then, in one embodiment, the object device <b>50</b> may implement a lateration function and/or a multilateration function to determine localization with respect to the remote device <b>20</b> (e.g., the location of the remote device <b>20</b> relative to the object <b>10</b>). Lateration and/or multilateration may involve processing a set of ranges from the remote device <b>20</b> to each sensor <b>40</b> to output a position estimate of the remote device <b>20</b> relative to the object <b>10</b>). The remote device <b>20</b> and the UWB-enabled sensors <b>40</b>U, <b>4</b>OUB may transmit and receive packets of data back-and-forth, enabling a time-of-flight determination with respect to such communications.</p><p id="p-0097" num="0096">The system <b>100</b> in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>4</b></figref> may include at least two different communication links for determining localization. For instance, the communication link <b>140</b> may utilize BTLE-based localization, and the communication link <b>170</b> may utilize UWB-based localization. In the illustrated embodiment, the communication link <b>170</b> is designated with respect to each of the sensors <b>40</b>U, <b>40</b>U+B; however, it is to be understood that each of these communication links <b>170</b> may not be the same. For instance, each of the communication links <b>170</b> may be separate (e.g., a separate channel or band).</p><p id="p-0098" num="0097">Utilizing multiple communication links based on multiple types of communication methodologies for localization may provide a number of benefits.</p><p id="p-0099" num="0098">For instance, in a configuration in which both BTLE and UWB information are obtained, this information can be combined to enhance and stabilize a localization estimate. The BTLE and UWB channels used in the localization may involve different frequencies, and the signal characteristics to be exploited for ranging are different (RSSI for BTLE and time-of-flight for UWB).</p><p id="p-0100" num="0099">RSSI ranging calibration may be augmented or supplemented with time-of-flight from UWB communications. This augmentation or supplemental use of time-of-flight may be conducted in real-time by the system <b>100</b>, <b>100</b>&#x2032;, or conducted in a manner to adapt a model that uses sensed information not based on UWB communications (e.g., only sensed information with respect to BTLE communications).</p><p id="p-0101" num="0100">For instance, one embodiment according to the present disclosure may be directed toward calibrating out variance of RSSI or range calculations. BTLE+UWB capable remote devices <b>20</b> may be tested to build up a map of BTLE communication characteristics, UWB communication characteristics, and ranging or localization data. A BTLE-only remote device <b>20</b> may be operable to process such maps but without UWB communications characteristics to refine RSSI-only range estimates. For instance, a locator <b>210</b>, described in further detail herein, may be based on both BTLE+UWB communication characteristics; however, in practice, the locator <b>210</b> may generate location information based on BTLE communication characteristics without the UWB communication characteristics. Alternatively, the locator <b>210</b> may be based on BTLE communication characteristics, and may be operable in practice to generate location information based on both UWB and BTLE communication characteristics. It is to be understood that BTLE or UWB, or both, may be replaced with another type of communication protocol.</p><p id="p-0102" num="0101">The remote device <b>20</b>, in one embodiment, can establish a communication link <b>170</b> that may be direct with one or more of the sensors <b>40</b>U, <b>40</b>U+B, and the one or more signal characteristics (e.g., time-of-flight) may be determined based on this direct communication link <b>170</b>.</p><p id="p-0103" num="0102">As described herein, one or more signal characteristics, such as signal strength, time of arrival, time of flight, and angle of arrival, may be analyzed to determine location information about the remote device <b>20</b> relative to the object <b>10</b>, an aspect of the object <b>10</b>, or the object device <b>50</b>, or a combination thereof. For instance, time difference of arrival or the angle of arrival, or both, among the sensors <b>40</b> and the object device <b>50</b> may be processed to determine a relative position of the remote device <b>20</b>. The positions of the one or more antenna arrays <b>30</b> relative to the object device <b>50</b> may be known so that the relative position of the remote device <b>20</b> can be translated to an absolute position with respect to the antenna arrays <b>30</b> and the object device <b>50</b>.</p><p id="p-0104" num="0103">Additional or alternative types of signal characteristics may be obtained to facilitate determining position according to one or more algorithms, including a distance function, trilateration function, a triangulation function, a lateration function, a multilateration function, a fingerprinting function, a differential function, a time of flight function, a time of arrival function, a time difference of arrival function, an angle of departure function, a geometric function, or any combination thereof.</p><p id="p-0105" num="0104">II. System Device Overview</p><p id="p-0106" num="0105">In the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the object device <b>50</b> may include a control system or controller <b>58</b> configured to control operation of the object device <b>50</b> in accordance with the one or more functions and algorithms discussed herein, or aspects thereof. The system components, such as the remote device <b>20</b> or the sensor <b>40</b>, or both, may similarly include a controller <b>58</b>.</p><p id="p-0107" num="0106">The controller <b>58</b> may include electrical circuitry and components to carry out the functions and algorithms described herein. Generally speaking, the controller <b>58</b> may include one or more microcontrollers, microprocessors, and/or other programmable electronics that are programmed to carry out the functions described herein. The controller <b>58</b> may additionally or alternatively include other electronic components that are programmed to carry out the functions described herein, or that support the microcontrollers, microprocessors, and/or other electronics. The other electronic components include, but are not limited to, one or more field programmable gate arrays (FPGAs), systems on a chip, volatile or nonvolatile memory, discrete circuitry, integrated circuits, application specific integrated circuits (ASICs) and/or other hardware, software, or firmware. Such components can be physically configured in any suitable manner, such as by mounting them to one or more circuit boards, or arranging them in other manners, whether combined into a single unit or distributed across multiple units. Such components may be physically distributed in different positions in the object device <b>50</b>, or they may reside in a common location within the object device <b>50</b>. When physically distributed, the components may communicate using any suitable serial or parallel communication protocol, such as, but not limited to, CAN, LIN, Vehicle Area Network (VAN), FireWire, I2C, RS-232, RS-485, and Universal Serial Bus (USB).</p><p id="p-0108" num="0107">As described herein, the terms locator, module, model, and generator designate parts of the controller <b>58</b>. For instance, a model or locator in one embodiment is described as having one or more core functions and one or more parameters that affect output of the one or more core functions. Aspects of the model or locator may be stored in memory of the controller <b>58</b>, and may also form part of the controller configuration such that the model is part of the controller <b>58</b> that is configured to operate to receive and translate one or more inputs and to output one or more outputs. Likewise, a module or a generator are parts of the controller <b>58</b> such that the controller <b>58</b> is configured to receive an input described in conjunction with a module or generator and provide an output corresponding to an algorithm associated with the module or generator.</p><p id="p-0109" num="0108">The controller <b>58</b> of the object device <b>50</b> in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>2</b></figref> may include one or more processors <b>51</b> that execute one or more applications <b>57</b> (software and/or includes firmware), one or more memory units <b>52</b> (e.g., RAM and/or ROM), and one or more communication interfaces <b>53</b>, amongst other electronic hardware. The object device <b>50</b> may or may not have an operating system <b>56</b> that controls access to lower-level devices/electronics via a communication interface <b>53</b>. The object device <b>50</b> may or may not have hardware-based cryptography units <b>55</b>&#x2014;in their absence, cryptographic functions may be performed in software. The object device <b>50</b> may or may not have (or have access to) secure memory units <b>54</b> (e.g., a secure element or a hardware security module (HSM)). Optional components and communication paths are shown in phantom lines in the illustrated embodiment.</p><p id="p-0110" num="0109">The controller <b>58</b> in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>2</b></figref> is not dependent upon the presence of a secure memory unit <b>54</b> in any component. In the optional absence of a secure memory unit <b>54</b>, data that may otherwise be stored in the secure memory unit <b>54</b> (e.g., private and/or secret keys) may be encrypted at rest. Both software-based and hardware-based mitigations may be utilized to substantially prevent access to such data, as well as substantially prevent or detect, or both, overall system component compromise. Examples of such mitigation features include implementing physical obstructions or shields, disabling JTAG and other ports, hardening software interfaces to eliminate attack vectors, using trusted execution environments (e.g., hardware or software, or both), and detecting operating system root access or compromise.</p><p id="p-0111" num="0110">For purposes of disclosure, being secure is generally considered being confidential (encrypted), authenticated, and integrity-verified. It should be understood, however, that the present disclosure is not so limited, and that the term &#x201c;secure&#x201d; may be a subset of these aspects or may include additional aspects related to data security.</p><p id="p-0112" num="0111">The communication interface <b>53</b> may provide any type of communication link, including any of the types of communication links described herein, including wired or wireless. The communication interface <b>53</b> may facilitate external or internal, or both, communications. For instance, the communication interface <b>53</b> may be coupled to or incorporate the antenna array <b>30</b>. The antenna array <b>30</b> may include one or more antennas configured to facilitate wireless communications, including BTLE communications and UWB communications.</p><p id="p-0113" num="0112">As another example, the communication interface <b>53</b> may provide a wireless communication link with another system component in the form of the remote device <b>20</b>, such as wireless communications according to the WiFi standard, BLTE, or UWB, or any combination thereof. In another example, the communication interface <b>53</b> may be configured to communicate with another device disposed on a vehicle (e.g., an object controller of the vehicle) via a wired link such as a CAN-based wired network that facilitates communication between a plurality of devices. The communication interface <b>53</b> in one embodiment may include a display and/or input interface for communicating information to and/or receiving information from the user <b>60</b>.</p><p id="p-0114" num="0113">In one embodiment, the object device <b>50</b> may be configured to communicate with one or more auxiliary devices of a type different from the remote device <b>20</b> or the sensor <b>40</b>. In other words, the auxiliary device may be configured differently from the object device <b>50</b>&#x2014;e.g., the auxiliary device may not include a processor <b>51</b>, and instead, may include at least one direct connection and/or a communication interface for transmission or receipt, or both, of information with the object device <b>50</b>. For instance, the auxiliary device may be a solenoid that accepts an input from the object device <b>50</b>, or the auxiliary device may be a sensor (e.g., a proximity sensor) that provides analog and/or digital feedback to the object device <b>50</b>.</p><p id="p-0115" num="0114">III. System for Determining Sensor Location</p><p id="p-0116" num="0115">As described herein, the system <b>100</b> may include one or more sensors <b>40</b> disposed on an object <b>10</b>, such as a vehicle. The location of the one or more sensors <b>40</b> on the object <b>10</b> may vary from application to application, depending on a variety of factors such as location availability and effectiveness. The effectiveness (also described herein as performance) of a sensor <b>40</b> can be considered a qualitative aspect of the sensed information obtained by the sensor <b>40</b> in facilitating an accurate location determination. For instance, if the sensor <b>40</b> is disposed at a location that is heavily shielded from wireless communications, the effectiveness of the sensor <b>40</b> is likely to be low&#x2014;that is, any sensed information obtained by the sensor <b>40</b> is unlikely to be significantly indicative of a remote device <b>20</b> being at different locations relative to the object <b>10</b>. On the other hand, a sensor <b>40</b> disposed at a location that is substantially unshielded and provides line of sight to a remote device <b>20</b> is more likely to be effective, with sensed information obtained by the sensor <b>40</b> being more indicative of the remote device <b>20</b> being at different positions relative to the object <b>10</b>.</p><p id="p-0117" num="0116">There are many factors that affect the effectiveness of a sensor <b>40</b> at a particular location on the object <b>10</b>, some of which are inherent and unchangeable relative to the construction of the object <b>10</b> and others of which vary over time. As a result, the location choice for the one or more sensors <b>40</b> is often constrained at least by the construction of the object <b>10</b>. One embodiment of the present disclosure may facilitate determining, during a configuration stage, a location for a sensor <b>40</b> that is considered effective for purposes of determining location of a remote device <b>20</b> relative to the vehicle. The metric for considering the location to be effective may be relative to several candidate locations, with the candidate location or locations that provide greater effectiveness being selected for one or more locations of the one or more sensors <b>40</b> in practice after the configuration stage.</p><p id="p-0118" num="0117">Additional factors that affect the effectiveness of a sensor <b>40</b> at a particular location can include external factors, such as the manner in which a user <b>60</b> is carrying the remote device <b>20</b> and reflectivity of the surrounding environment (which can change as the object <b>50</b> moves from one environment to another).</p><p id="p-0119" num="0118">A system for determining performance indicia or effectiveness for a plurality of candidate locations for sensors <b>40</b> is shown in the illustrated embodiment of <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>6</b></figref> and generally designated <b>300</b>. For purposes of disclosure, the sensors <b>40</b> in <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>6</b></figref> are identifiable as circles with line types indicative of a location of a respective sensor being outside or inside, and under test. The system <b>300</b> includes one or more aspects of the system <b>100</b>, <b>100</b>&#x2032;, including a sensor <b>40</b>, an object device <b>50</b>, and a remote device <b>20</b>. The system <b>300</b> may include a control system <b>310</b> in communication with one more aspects of the system <b>100</b> to collect sensor information obtained by one or more sensors <b>40</b> disposed on the object <b>10</b>. The system <b>300</b> may include a movable body <b>320</b> coupled to the remote device <b>20</b> and controllable by the control system <b>310</b> to move the remote device <b>20</b> to a variety of positions relative to the object <b>10</b>.</p><p id="p-0120" num="0119">The system <b>300</b> in the illustrated embodiment of <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>6</b></figref> includes a movable body <b>320</b> in the form of a terrestrial robot capable of receiving commands to move the remote device <b>20</b> to particular locations relative to the object <b>10</b> (e.g., a vehicle). The movable body <b>320</b> may be capable of moving the remote device <b>20</b> to a position in three-dimensional space and optionally at one or more angular orientations. In an alternative embodiment, the movable body <b>320</b> may be configured without a terrestrial system, such as the movable body described in U.S. Nonprovisional patent application Ser. No. 16/713,363 to Eric J. Smith et al., entitled SYSTEM AND METHOD OF CALIBRATION FOR ESTABLISHING REAL-TIME LOCATION, filed Dec. 13, 2019&#x2014;the disclosure of which is hereby incorporated by reference in its entirety. The control system <b>310</b> may be configured to automatically direct a path of the remote device <b>20</b> in accordance with a predefined path. The predefined path may correspond to a plurality of points in three-dimensional space that are spaced apart. The points may be spaced apart equally. Alternatively, the points may be spaced as a function of proximity to the object <b>10</b> (e.g., the closer to the object <b>10</b>, the more closely spaced the points.) This way, truth information (e.g., a position and sensor information with respect to communications from the remote device <b>20</b>) may be obtained in a consistent manner for different types of objects <b>10</b> and different types of remote devices <b>20</b>. An example test path is a raster path that covers the area surrounding the object <b>10</b> to a distance of 20 m.</p><p id="p-0121" num="0120">At each test location of the test path, information from the system <b>100</b> may be collected as truth data. Additionally, a state of the system <b>100</b> or the object <b>10</b>, or both, may be varied at the test location. For instance, a configuration of the object <b>10</b>, such as whether a door of the object <b>10</b> is open or closed. The state information may form part of the truth data that facilitates testing of the system <b>100</b> and determining performance data for candidate locations of one or more sensors <b>40</b>. The test path may also be conducted in different environments for the object <b>10</b> (e.g., in an open area outdoors, within a two-stall garage with the door open, within a two-stall garage with the door closed).</p><p id="p-0122" num="0121">The data for the test location and the truth data may be correlated in a number of ways, such as by time or by actual knowledge of the test parameters at the time the true data is obtained.</p><p id="p-0123" num="0122">In one embodiment, the test path of the remote device <b>20</b> may be dynamic, based on feedback from a training algorithm. For instance, if the training algorithm determines that a particular location or area is more indicative of performance for a sensor <b>40</b>, the control system <b>310</b> of the system <b>300</b> may position the remote device <b>20</b> at a plurality of more closely spaced positions near this location or within the area of interest in an effort to enhance performance data for this region with a greater number of associated samples of truth data.</p><p id="p-0124" num="0123">Additionally, the control system <b>310</b> may be configured to direct the system <b>300</b> to change or set an angular orientation of the remote device <b>20</b>. The system <b>300</b>, for instance, may include a plurality of motors (e.g., stepper motors) disposed proximal (or remote) to the remote device <b>20</b> and operable to change an angular orientation of the remote device <b>20</b>. The angular orientation may be defined in accordance with Euler angles for roll (&#x3c6;), pitch (&#x3b8;), and yaw (&#x3c8;). Alternatively, the angular orientation may be defined according to a normalized quaternion. The Euler angles or the quaternion may be determined relative to a reference coordinate frame (e.g., North, East, Down (NED) convention). By changing the angular orientation of the remote device <b>20</b> at a position, multiple samples of truth information may be obtained at that position. This way, performance data for a candidate location of a sensor <b>40</b> can be obtained for a variety of circumstances that may occur in use, such as various types of orientations that the user <b>60</b> carries the remote device <b>20</b>, thereby enhancing the degree of confidence for the performance data.</p><p id="p-0125" num="0124">In one embodiment, as described herein, the movable body <b>320</b> may be configured to carry a test object in addition to the remote device <b>20</b>. The test object may be configured to affect communication between the remote device <b>20</b> and the system <b>100</b> in a manner similar to circumstances likely to be encountered in use. For instance, the test object may be a bag of liquid (e.g., water) that imitates to a large extent the effect of a user's body on communications with the remote device <b>20</b>. The bag of liquid may have an effect on communications that is similar to the user placing the remote device <b>20</b> in their back pocket, with their body being disposed between the object <b>10</b> and the remote device <b>20</b>.</p><p id="p-0126" num="0125">The control system <b>310</b> of the system <b>300</b> may be configured similar to a system component described herein, including, for instance, one or more processors <b>51</b>, one or more memory units <b>52</b>, and one or more communication interfaces <b>53</b>. The control system <b>310</b> may include a communication interface <b>53</b> configured to communicate with the movable body <b>320</b>, and optionally the remote device <b>20</b>. Communication between the control system <b>310</b> and the remote device <b>20</b> may be optional primarily because, in one embodiment of obtaining truth data, the remote device <b>20</b> may be left to operate independent of the control system <b>310</b>, similar to how the remote device <b>20</b> would operate in use in one embodiment without being aware of a user's intent to move the remote device <b>20</b> from one area to another.</p><p id="p-0127" num="0126">In the illustrated embodiment, an object interface of the control system <b>310</b> may be configured to communicate with an object device <b>50</b> of the object <b>10</b> to obtain information pertaining to one or more sensed characteristics of communication received from one or more sensors <b>40</b> and the remote device <b>20</b>. For instance, the object device <b>50</b> may be configurable in a test mode in which the object device <b>50</b> communicates raw sensor information obtained with respect to communications transmitted from the remote device <b>20</b>, such as raw sensor information conveyed to the object device <b>50</b> by a sensor <b>40</b> disposed at a candidate location.</p><p id="p-0128" num="0127">For instance, as discussed herein, the object device <b>50</b> may be disposed on the object <b>10</b> and communicatively coupled to one or more sensors <b>40</b>. The object device <b>50</b> and the one or more sensors <b>40</b> may be operable to sense or measure one or more signal characteristics of the communications transmitted from the remote device <b>20</b>. The one or more sensors <b>40</b> may be provided connection parameters to enable the one or more sensors <b>40</b> to sniff communications transmitted from the remote device <b>20</b> to the object device <b>50</b>. This way, the one or more sensors <b>40</b> may measure one or more signal characteristics of the communications transmitted from the remote device <b>20</b> and correlate these one or more measured signal characteristics with a time of measurement. The object device <b>50</b> may also measure one or more signal characteristics of communications transmitted from the remote device <b>20</b>.</p><p id="p-0129" num="0128">To provide an example, the object device <b>50</b> and the one or more sensors <b>40</b> may measure a signal strength of communications transmitted from the remote device <b>20</b>. Because the object device <b>50</b> and the one or more sensors <b>40</b> may be disposed at different candidate locations on the object <b>10</b>, these signal strength measurements may differ as a function of the different candidate locations. The object device <b>50</b> may transmit the measurements along with a timestamp for the measurements to the control system <b>310</b> for generation of truth data used to facilitate generating performance data for each candidate location of a sensor <b>40</b>. The truth data in one embodiment may be based on a signal characteristic, such as time of flight, obtained with respect to UWB communications. Time of flight may be indicative of distance of the remote device <b>20</b> relative to one or more of the sensors <b>40</b>. The UWB communications, and associated time of flight characteristic, may be established directly with one or more of the sensors <b>40</b> or the object device <b>50</b>, or any combination thereof. In one embodiment, a signal characteristic obtained with respect to UWB communications may form part of the truth data that is processed along with a true location or true position of the remote device <b>20</b> relative to the object device <b>50</b>, or the UWB-based signal characteristic may be provided as an indicator of an actual position of the remote device <b>20</b> relative to the object <b>10</b> for comparison against other sensed characteristics in generating performance data for a candidate location.</p><p id="p-0130" num="0129">The control system <b>310</b> in the illustrated embodiment may include a position controller capable of transmitting a command to the movable body <b>320</b> to travel to a spatial coordinate in X, Y, Z Cartesian notation relative to an origin of the test area.</p><p id="p-0131" num="0130">With information pertaining to one or more sensed characteristics of communication for each test position and each candidate location of a sensor <b>40</b>, the control system <b>310</b> may develop a set of truth data of the candidate locations in connection with the object <b>10</b>. This truth data may be stored in memory associated with the control system <b>310</b> and utilized to generate a performance metric for each candidate location.</p><p id="p-0132" num="0131">A method in accordance with one embodiment of the present disclosure involves obtaining test samples and truth information with respect to a remote device <b>20</b> and a plurality of candidate locations for sensors <b>40</b> of the system <b>100</b>. Each of the sensors <b>40</b> may measure one or more signal characteristics of communications between the object device <b>50</b> and the remote device <b>20</b> to form a plurality of test samples. Additionally, the method may involve obtaining truth information for each test sample. The truth information may include an actual location of the remote device <b>20</b> relative to the object <b>10</b> or other information, or a combination thereof. The actual location of the remote device <b>20</b> may be known by the control system <b>310</b>, and changed by the control system <b>310</b> in accordance with a test path.</p><p id="p-0133" num="0132">The determination of one or more specific values (i.e., RSSI offsets, variability indicators, etc.) or samples for the remote device <b>20</b> may be conducted in a repeatable, controlled manner via the system <b>300</b>. This may facilitate obtaining performance data for each candidate location of the sensors <b>40</b>.</p><p id="p-0134" num="0133">The method may vary from application to application (e.g., for objects being vehicles vs. a building)&#x2014;however, the method involves obtaining samples of the one or more signal characteristics under a variety of conditions, including, for example, different positions and orientations with respect to the object <b>10</b> or various placements of the remote device <b>20</b>. In one embodiment, coverage of possible conditions may be determined based on use scenarios and whether a use scenario affects the one or more signal characteristics in a meaningful way different from other use scenarios that are tested. As an example, a use scenario in which the remote device <b>20</b> is placed in a first type of handbag may be substantially the same as the use scenario in which the remote device <b>20</b> is placed in a second type of handbag, which is provided for testing in the method. As a result, the use scenario with the first type of handbag may not be tested.</p><p id="p-0135" num="0134">In one embodiment, the method may be adapted to test all or substantially all use scenarios identified as being of interest. It should be understood that the present disclosure is not limited to testing all or substantially all use scenarios&#x2014;a subset of use scenarios may be tested for generating performance data for candidate locations of the sensors <b>40</b>. In the case where the object <b>10</b> is a vehicle, the test procedure may be provided to cover a reasonable number of positions in all or substantially all zones, with the remote device <b>20</b> in all orientations and placements (hand, front pocket, back pocket, backpack, purse, etc.).</p><p id="p-0136" num="0135">At each test location, and under each condition, the remote device <b>20</b> may be held in place for a period of time such as 10 to 30 seconds. During this time, the system <b>100</b> may be configured to obtain a plurality of samples with respect to the one or more signal characteristics described herein. For instance, the object device <b>50</b> or the sensor <b>40</b>, or both, may sense one or more characteristics of communications with the remote device <b>20</b> under each condition. Example characteristics include signal strength (RSSI), time of flight, and angle of arrival.</p><p id="p-0137" num="0136">It should be noted that the test environment or the conditions set may vary depending on the application. A test procedure that captures substantially all of the conditions identified above may be considered comprehensive for a particular type of object <b>10</b> and remote device <b>20</b>. It should be noted that one or more of the identified conditions may be dropped from the conditions set or performed in alternate test procedures or alternative embodiments. The conditions identified for the method or the test procedure may be selected to capture the performance of the system in a reasonable number of use cases or conditions. Additionally, a method may be used to collect data (as described herein). The collected data may or may not be combined or stored in aggregate, although doing so may facilitate correlation of the collected data among the plurality of test conditions for the remote device <b>20</b> and the object <b>10</b>. The collected data may be provided to a training module of the control system <b>310</b> in accordance with one embodiment.</p><p id="p-0138" num="0137">The example conditions outlined above are generally static conditions where the remote device <b>20</b> is positioned and held still for a period of time. It should be noted that the present disclosure is not so limited. Additionally, or alternatively, the conditions used in the method may be functional tests in which circumstances may be dynamic. Examples of such functional tests include approaches, departures, and zone transitions, or combinations thereof.</p><p id="p-0139" num="0138">In the illustrated embodiment of <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>6</b></figref>, the system <b>300</b> may be configured to enable evaluation of candidate locations for one or more sensors <b>40</b> in conjunction with a remote device <b>20</b>. The system <b>300</b> may enable capture of location performance for a sensor <b>40</b> that is operable for facilitating determining location via UWB communications. The system <b>300</b> may facilitate comparison of performance characterizations of candidate locations in a variety of locations relative to the object <b>10</b> (e.g., a vehicle), such as in a front driver side wheel well or a variety of positions as outlined in the illustrated embodiment of <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>6</b></figref>. The system <b>300</b> may provide reproducible performance evaluations in conjunction with candidate locations for the one or more sensors <b>40</b> and the remote device <b>20</b>. As described herein, the remote device <b>20</b> may vary from application to application, including from user to user (e.g., one user may have a remote device <b>20</b> in the form of an iPhone whereas another user may have a remote device <b>20</b> in the form of a Samsung Galaxy). The system <b>300</b> may facilitate obtaining repeatable results in evaluation for candidate locations for a variety of remote devices <b>20</b>.</p><p id="p-0140" num="0139">As described herein in conjunction with the system <b>300</b>, candidate locations for one or more sensors <b>40</b> may be provided in a variety of locations relative to the object <b>10</b>. In the illustrated embodiment, <b>22</b> candidate locations are provided and scored based on analysis of data obtained from sensors <b>40</b> disposed at each of the candidate locations and determined with respect to multiple zones in a target area relative to the object <b>10</b> (e.g., for 15 zones in a driver-side area of a vehicle). The analysis may include a score for each candidate location or a group of candidate locations. The score may vary depending on data and performance metrics obtained with respect to data from the plurality of sensors <b>40</b> in one embodiment, the score for a group of candidate locations may be based on a combined 1) range error, and 2) variability in range error and likelihood that range errors would contribute to misclassifying a zone in which the remote device <b>20</b> is located.</p><p id="p-0141" num="0140">Data obtained in one embodiment is indicative of the following candidate locations as having high-performing scores: 1) high-end front center of wheel well (#3), 2) low and back of driver side doors (#6, #7), 3) front headliners (#10, #18), and 4) middle and front center of wheel well (#12). In this arrangement, a remote device <b>20</b> having a UWB communication interface (e.g., a UWB initiator capable of transmitting communications) is mounted to the movable body <b>320</b> at a height of 1 m. The movable body <b>320</b> may be moved within a target area of 3&#xd7;5 m of the object <b>10</b> (e.g., a 3&#xd7;5 m area proximal to a driver-side of a vehicle). The movable body <b>320</b> may traverse the target area in a grid -like manner, moving in steps of approximately 0.25 m with a dwell time at each location of approximately 60 seconds. The target area may be traverse in a variety of ways and is not limited to a grid-like traversal. For instance, the movable body <b>320</b> may move to multiple positions within the target area in a radial manner that fans out from a reference point of the object <b>10</b> (e.g., a driver-side door handle), with the movable body <b>320</b> having a dwell time at each location of approximately 60 seconds. Because the target area in this example relates to a reference point of the object, or a reference region thereof, the data collected with respect to movement of the movable body <b>320</b> in the remote device <b>20</b> may facilitate generation of performance data for top-performing or high-performing candidate locations of the one or more sensors <b>40</b> proximal to the reference point or region of the object <b>10</b>.</p><p id="p-0142" num="0141">Data can be obtained with respect to UWB communications with the remote device <b>20</b> and may be conducted for each sensor <b>40</b> at each candidate location, and this data may be analyzed in accordance with one or more embodiments described herein to yield a score for one or more sensors <b>40</b>, or a group of sensors <b>40</b>, or a combination thereof. It is to be understood that the type of communication between the remote device <b>20</b> in each sensor may vary from application, and is not limited to UWB communications. For instance, data analysis may be conducted based on BTLE communications with the remote device <b>20</b>. It is further to be understood that the analysis and scoring described herein may be based on communications of more than one type, such as both UWB and BTLE communications.</p><p id="p-0143" num="0142">In one embodiment, the position of the remote device <b>20</b> may be varied in the target area as described herein. Additionally, or alternatively, the environment or state, or both, of the remote device <b>20</b> may be varied at position. Variance in the environment or state of the remote device <b>20</b> may be conducted at each position of the remote device <b>20</b> in the target area. Alternatively, variance may be achieved by obtaining data with respect to each position of the remote device in the target area under one set of conditions, and at a later stage, obtaining data with respect to each position of the remote device in the target area under another set of conditions.</p><p id="p-0144" num="0143">To provide an example, data may be collected with respect to the remote device <b>20</b> and one or more sensors <b>40</b> via movement of the movable body <b>320</b> within a target area. The remote device <b>20</b> in this example may be carried by the movable body <b>320</b> at a predetermined height and moved about the object <b>10</b>. In a first data collection path, the movable body <b>320</b> may move the remote device <b>20</b> to a plurality of positions within the target area, with the path between the remote device <b>20</b> and the object being substantially free of obstructions. After traversing the target area in a manner described herein, an obstruction may be disposed between the object <b>10</b> in the remote device <b>20</b>, and data may then be collected with respect a second data collection path that is similar to the first data collection path. The obstruction may be carried by the movable body <b>320</b> such that the obstruction is substantially present at all test locations along the data collection path. The first and second data collection paths in this example may be a radial, fanning out arrangement of test positions&#x2014;however, it is to be understood that the first and second data collection path may be different depending on the application.</p><p id="p-0145" num="0144">Data collected with respect to different sets of conditions (e.g., an obstruction and an obstruction-free data set) may be scored to determine performance for each of the candidate locations, or a group of candidate locations, of the plurality of sensors <b>40</b>. By determining performance data under multiple sets of conditions, robustness of the performance data for the candidate locations can be enhanced. In one embodiment, a range error between two sets of conditions may be determined to capture both increase delay and increase variability in range measurements for candidate locations. As described herein, in obtaining test data for one embodiment of the present disclosure under multiple conditions, high-performing sensor locations for a vehicle include a lower driver-side door (#6, #7, #5), middle and front center of the wheel well (#12), and high-end front center of wheel well (#3).</p><p id="p-0146" num="0145">A. Candidate Locations</p><p id="p-0147" num="0146">The candidate locations for a plurality of sensors <b>40</b> may vary depending on the configuration of the object <b>10</b>. For instance, candidate locations may be selected based on the construction of the object <b>10</b> and available mounting locations for the sensor <b>40</b>. There may be conditions on placement of a sensor <b>40</b> that affect selection of a candidate location, such as a condition that the sensor <b>40</b> be substantially inconspicuous or hidden from view. A full set of candidate locations for an object <b>10</b> in the form of a vehicle is depicted in the illustrated by <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref>. As can be seen, candidate locations may be disposed within aspects of the vehicle such as a vehicle cabin, a wheel well, or a door. A sensor <b>40</b> may be disposed at each of the candidate locations in conjunction with obtaining data for evaluating performance of each candidate location, as described herein.</p><p id="p-0148" num="0147">In one embodiment, evaluation of candidate locations via obtaining data for each sensor <b>40</b> at each candidate location may involve activating some but not all of the sensors <b>40</b>. For example, as depicted in the illustrated embodiment of <figref idref="DRAWINGS">FIGS. <b>7</b> and <b>8</b></figref>, different sets of candidate locations may be tested, such that <figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts a first set of candidate locations to be evaluated and <figref idref="DRAWINGS">FIG. <b>8</b></figref> shows a second set of candidate locations to be evaluated. The different sets may be mutually exclusive or intersecting with respect to candidate locations. In the illustrated embodiment of <figref idref="DRAWINGS">FIGS. <b>7</b> and <b>8</b></figref>, the different sets of candidate locations are determined based on the second set of candidate locations including a driver side, central locations, and passenger side locations of a vehicle with the first of candidate locations primarily focusing on a driver side of the vehicle.</p><p id="p-0149" num="0148">B. Data Collection Path</p><p id="p-0150" num="0149">The system <b>300</b> may be configured to obtain data for evaluating a plurality of candidate locations in conjunction with a target area or zone <b>330</b>, as described herein. The target area or zone <b>330</b> may vary depending on the application, including a reference point or reference region of the object <b>10</b>. For instance, the system <b>100</b> may be configured to determine a location of a remote device <b>20</b> relative to the reference point or reference region because a user is likely to approach or be proximate to the reference point or reference region. The zone <b>330</b> for evaluating the plurality of candidate locations may be determined based on the likely approach or position of the user relative to the reference point or reference region of the object <b>10</b>.</p><p id="p-0151" num="0150">In the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the target area or zone <b>330</b> is proximate to a driver' s-side region of a vehicle, and is rectangular in shape and approximately 5 m&#xd7;3 m in size. It is to be understood that the target area may vary from this shape and may vary in size.</p><p id="p-0152" num="0151">The data collection path <b>340</b> depicted in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>9</b></figref> is a raster-type arrangement with the movable body <b>320</b> starting a corner location of the target area <b>330</b> and traversing back-and-forth toward a side opposite a side of the corner location. The step size between each test location in the dwell time at each test location may vary along the data collection path <b>340</b>, or the step size and dwell time may be substantially constant along the data collection path <b>340</b>.</p><p id="p-0153" num="0152">Additional examples of target areas or zones <b>330</b> are shown in the illustrated embodiments of <figref idref="DRAWINGS">FIG. <b>10</b></figref> and respectively labeled A-O. The target areas or zones <b>330</b> are based on regions of interest relative to the vehicle, including a likely location of a user carrying the remote device <b>20</b> and a likely approach vector for the user carrying the remote device <b>20</b>. For instance, target areas <b>330</b> labeled respectively A-O relate to the vehicle as follows:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0153">A) a 0.5 m area proximal to a front handle (e.g., a handle of a driver side door);</li>        <li id="ul0002-0002" num="0154">B) a 1 m area proximal to the front handle;</li>        <li id="ul0002-0003" num="0155">C) a 2 m area proximal to the front handle;</li>        <li id="ul0002-0004" num="0156">D) a 0.5 m area proximal to a rear handle (e.g., a handle of a driver side passenger door);</li>        <li id="ul0002-0005" num="0157">E) a 1 m area proximal to the rear handle;</li>        <li id="ul0002-0006" num="0158">F) a 2 m area proximal to the rear handle;</li>        <li id="ul0002-0007" num="0159">G) a 0.5 m area central to a driver side the vehicle;</li>        <li id="ul0002-0008" num="0160">H) a 1 area central to the driver side of the vehicle;</li>        <li id="ul0002-0009" num="0161">I) a 2 m area central to the driver side of the vehicle;</li>        <li id="ul0002-0010" num="0162">J) a 1 m area corresponding to the driver side of the vehicle;</li>        <li id="ul0002-0011" num="0163">K) a 2 m area corresponding to the driver side;</li>        <li id="ul0002-0012" num="0164">L) a rear approach area of the vehicle;</li>        <li id="ul0002-0013" num="0165">M) a front approach area of the vehicle;</li>        <li id="ul0002-0014" num="0166">N) a central approach area of the vehicle; and</li>        <li id="ul0002-0015" num="0167">O) a driver side approach area of the vehicle.</li>    </ul>    </li></ul></p><p id="p-0154" num="0168">Data may be collected and candidate locations for a plurality of sensors <b>40</b> may be evaluated with respect to a data collection path aligned with the target area or zone <b>330</b>. Such performance data may be obtained for multiple types of target areas or zones <b>330</b> as depicted for example in <figref idref="DRAWINGS">FIGS. <b>10</b>A-O</figref>, and used to evaluate separately or collectively candidate locations for multiple zones <b>330</b>.</p><p id="p-0155" num="0169">The movable body <b>320</b> may traverse through a zone <b>330</b> in alternative ways, such as a fanned out pattern depicted in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>11</b></figref>, with the movable body <b>320</b> represented by person and configured to carry the remote device <b>20</b> along with an obstruction (e.g., a bag of water) operable to simulate a user carrying the remote device <b>20</b> in a back pocket. The movable body <b>320</b> may carry the remote device <b>20</b> to multiple positions, designated by a &#x201c;+&#x201d; in the illustrated embodiment, and as described herein the movable body <b>320</b> remain at each location for a period of time (e.g., a 62 s dwell time). In the illustrated embodiment the positions are arranged to fan out from a driver-side door handle, such that test point locations are approximately parallel to the door handle (+/&#x2212;90&#xb0;, normal to the door handle (0&#xb0;) and diagonal to the door handle (+/&#x2212;45&#xb0;). The test point locations along these angles relative to the door handle may be approximately 0.5 m, 1.0 m, 1.5 m, 2.0 m, and 3.0 m.</p><p id="p-0156" num="0170">The movable body <b>320</b> may traverse the target path or data collection path <b>340</b> as described herein. Truth data with respect to each data collection location of the zone <b>330</b> may be obtained for analysis and determining performance data as described herein. The truth data may include location data for the zone <b>330</b> determined by the control system <b>310</b>, such that the controller <b>310</b> can correlate the location data with sensor data obtained from the plurality of sensors <b>40</b> of the candidate locations.</p><p id="p-0157" num="0171">The location data obtained as part of the truth data for the control system <b>310</b> may be based on commands provided to the movable body <b>320</b> or information received from the movable body <b>320</b>, or both. Location data for the movable body <b>320</b> can be determined via dead reckoning by inertial measurement (which may be output from an inertial measurement unit (IMU) of the movable body <b>320</b>). However, there is a possibility that dead reckoning may yield inaccurate location data. Such inaccuracy may be caused by factors such as wheel slippage and IMU errors that cause drift in dead reckoning. In other words, the position array depicted in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>11</b></figref> may not be uniform or regular by using dead reckoning control for moving the movable body <b>320</b> from each position along the data collection path <b>340</b>.</p><p id="p-0158" num="0172">In one embodiment, inaccuracies in location data for the movable body <b>320</b> due to drift may be offset or corrected by correlating information obtained from the movable body <b>320</b> or commands provided to the movable body <b>320</b>, or both, with stability of sensor characteristics obtained with respect to communications with one or more of the sensors <b>40</b>. As depicted in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>12</b></figref>, at each of the identified locations of the zone <b>330</b>, the movable body <b>320</b> may dwell for a period of time. During this time, signal characteristics of communications may remain stable, such as UWB communications. This stability period may facilitate determining an offset for potential drift.</p><p id="p-0159" num="0173">Additionally, or alternatively, drift may be offset or corrected by obtaining information from one or more other sensors disposed on the movable body <b>320</b>, such as LIDAR and a depth camera. An extended Kalman filter (EKF) and/or simultaneous localization and mapping (SLAM) may be implemented in conjunction with such information to determine a location of the movable body <b>320</b> with respect to the vehicle.</p><p id="p-0160" num="0174">Additionally, or alternative to using the stability period as a basis for determining an offset for potential drift, the stability period of communications may also facilitate synchronization of data between the movable body <b>320</b> and information obtained from the one or more sensors <b>40</b>.</p><p id="p-0161" num="0175">C. Data Collection</p><p id="p-0162" num="0176">As described herein in conjunction with one embodiment, the system <b>300</b> may be configured to collect or obtain data from one or more sensors <b>40</b> with respect to communications with a remote device <b>20</b> carried by a movable body <b>320</b>. The data may include one or more signal characteristics with respect to such communications, including for instance, signal strength (e.g., RSSI), time-of-arrival (TOA), time-of-flight (TOF), angle-of-arrival (AOA), and time-difference-of-arrival (TDOA). The one or more signal characteristics may be determined with respect to communications received by each of the one or more sensors <b>40</b>. The communications may be direct between each of the one or more sensors <b>40</b> and the remote device <b>20</b>. Additionally, or alternatively, the communications may be between the remote device <b>20</b> and a designated device, such as a master device (e.g., object device <b>50</b>) or a sensor <b>40</b>. The other of the sensors <b>40</b> may be configured to sniff or detect communications between the remote device and the designated device, and generate one or more signal characteristics with respect to such sniffed or detected communications. Sniffing may be achieved in a variety of ways including, for example, in accordance with one or more embodiments described in U.S. Pat. No. 9,794,753, issued Oct. 17, 2017, entitled SYSTEM AND METHOD FOR ESTABLISHING REAL-TIME LOCATION, to Stitt et al.&#x2014;the disclosure of which is hereby incorporated by reference in its entirety.</p><p id="p-0163" num="0177">The one or more sensors <b>40</b> may transfer the one or more signal characteristics determined with respect to communications to controller <b>310</b>, via the object device <b>50</b> or direct to the controller <b>310</b>.</p><p id="p-0164" num="0178">The one or more signal characteristics may be analyzed to determine one or more metrics associated with the one or more metrics may be based on signal characteristics obtained from multiple sensors <b>40</b>, or signal characteristics obtained from a single sensor <b>40</b>. In one embodiment, the one or more metrics may include a computed range based on the one or more signal characteristics, missed detections, probability of non-line of sight. Additionally, or alternatively, the one or more metrics may include derived metrics, such as range errors.</p><p id="p-0165" num="0179">The one or more metrics may be mapped onto a grid corresponding to the zone <b>330</b> to facilitate visualization. The mapping may be provided as the form of a heat plot and/or a contour plot. For instance, coarse mapping based on the one or more metrics may be used to generate a contour plot <b>332</b> depicted in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>13</b></figref> for a measured range associated with a sensor <b>40</b> located in the grill of the vehicle.</p><p id="p-0166" num="0180">A heat plot with more fine contours relative to the contour plot <b>332</b>, based on the same measured range associated with the sensor <b>40</b> located in the grill of the vehicle, is designated <b>334</b> in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>13</b></figref>.</p><p id="p-0167" num="0181">In other words, the metrics can be from a coarse mapped heat plot (e.g., contour plot <b>332</b>) and can be interpolated to a finer, regularly space grid, such as the one depicted in the heat map <b>334</b>. The mappings may be provided on a regularly space grid for visualization purposes. Although the heat maps <b>332</b>, <b>334</b> are provided in conjunction with a measured range, it is to be understood that alternative or additional metrics may be depicted, including mean, range, RMS range error, standard deviation of range, missed detections, and likelihood of a line of sight measurement. Likelihood of a line of sight measurement may be based on data directly provided by each anchor such as provided by decawave records or measurements or may be derived from other types of measurements provided by each anchor depending upon the implementation. Example areas in which a percentage of measurements for the system recorded a 0% non-line of sight estimate correspond to the zones <b>330</b> depicted in the illustrated embodiment of <figref idref="DRAWINGS">FIGS. <b>10</b>A-O</figref>.</p><p id="p-0168" num="0182">D. Metrics</p><p id="p-0169" num="0183">As described herein, the system <b>300</b> may determine one or more metrics based on one or more signal characteristics obtained from each of the sensors <b>40</b> disposed at a candidate location. The metrics may be analyzed to determine performance of a sensor at a candidate location, or performance of a group of sensors <b>40</b> at multiple candidate locations. The one or more metrics may include assessments of: system accuracy and precision; coverage and resolution; impact of environmental phenomenology (natural and man-made), including attenuation due to through-material propagation or complete obscuration; and effects of random errors in the system such as errors caused by thermal noise, signal interference, and reflection. The system <b>300</b> may assess candidate location performance based on metrics that account for: the magnitude and impact of various types of errors; the effect of errors on system performance (for both localization and zone classification); and effects of error mitigation strategies on system performance.</p><p id="p-0170" num="0184">In the illustrated embodiments of <figref idref="DRAWINGS">FIGS. <b>14</b>-<b>16</b></figref>, an ensemble of range measurements, r<sub>n </sub>is shown in connection with communications from a remote device <b>20</b> that are detected by a sensor <b>40</b>. The remote device <b>20</b> may be disposed within a zone <b>330</b>. The communications may be direct between the remote device <b>20</b> and the sensor <b>40</b>, or alternatively, the communications may be transmitted from the remote device <b>20</b> to another device (e.g., an object device <b>50</b>) and the sensor <b>40</b> may be operable to sense one or more characteristics of such communications. Forty-five samples are depicted in the illustrated embodiment in conjunction with a distance determination based on one or more signal characteristics obtained by the sensor <b>40</b>. It is to be understood that more or fewer samples may be obtained, and that additional or different types of samples may be determined, depending on the configuration.</p><p id="p-0171" num="0185">A detectability metric in accordance with one embodiment is determined in conjunction with the analysis shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. The detectability metric may facilitate determining a performance indication for a candidate location of a sensor <b>40</b> for a zone classification system. In other words, the detectability metric may be indicative of whether the sensor output is helpful in determining whether the remote device <b>20</b> is disposed within a zone <b>330</b>. The detectability metric, in one embodiment, is the probability that range measurements, r<sub>n </sub>, for a remote device <b>20</b> at a location g<sub>n </sub>within the zone <b>330</b> will corroborate an assertion that the remote device <b>20</b> is in that zone <b>330</b>. The probability may be determined based on the truth information obtained from the movable body <b>320</b>, which may enable projection of ranges onto the coordinate system along with a downrange line running through the sensor <b>40</b> and the remote device location g<sub>n</sub>. The ensemble of range measurements r<sub>n </sub>at g<sub>n </sub>may enable analysis to model the range, such as the histogram depicted in the illustrated embodiment and the probability distribution thereof. The detectability of a zone for given range measurements is considered a probabilistic metric based upon the relative positions of a sensor <b>40</b>, the remote device <b>20</b>, and the zone <b>330</b> under test. The detectability metric may aid in quantifying how errors in range measurements affect zone classification. The distribution of range measurements determined from experimental data for a given sensor/remote device pair provide statistics to model detectability in a zone <b>330</b>.</p><p id="p-0172" num="0186">A method of determining the detectability metric is shown in further detail in the illustrated embodiments of <figref idref="DRAWINGS">FIGS. <b>16</b> and <b>17</b></figref>. The method is designated <b>1000</b> and may include obtaining input parameters, including an area of the zone <b>330</b> under test, ground truth positions g according to a 3-space coordinate system, r_g as an ensemble of range measurements at each position g, a candidate location a for the sensor <b>40</b> within the 3-space coordinate system, and t as a parameter for a linear array for parametric definition of a line. Step <b>1010</b>. For each position g, several parameters are calculated to facilitate generating a detectability metric. Step <b>1020</b>. The mean and standard deviation for the ensemble of range measurements may be calculated. Steps <b>1040</b>, <b>1050</b>. A downrange value based on the location vectors of the sensor <b>40</b> and the remote device <b>20</b> may be determined, and maximum and minimum values for the same may be determined. Steps <b>1050</b>, <b>1060</b>, <b>1070</b>. The detectability metric for the position g and sensor location a may be determined for each position g in accordance with the formula shown. The formula may vary from application to application and is not limited to the depicted form.</p><p id="p-0173" num="0187">In the illustrated embodiment of <figref idref="DRAWINGS">FIGS. <b>18</b>-<b>21</b></figref>, it is noted that, some geometries of the sensor <b>40</b> and the remote device <b>20</b> in a zone <b>330</b> are more tolerant to range errors than other geometries. The detectability metric may quantify this tolerance. For instance, consider ranging with the sensor <b>40</b> and a remote device <b>20</b> placed at two ground truth points, g<b>1</b> and g<b>2</b>, where the set of range measurements at each point have the same distribution of range delay and variability. The likelihood that a downrange measurement at g<b>1</b> will be consistent with a range located within the zone <b>330</b> is much higher than that of a downrange measurement at g<b>2</b>.</p><p id="p-0174" num="0188">The detectability throughout this zone <b>330</b> can be averaged to determine a value for detectability for each sensor <b>40</b>, remote device <b>20</b>, zone <b>330</b> combination, depicted separately in <figref idref="DRAWINGS">FIGS. <b>19</b> and <b>20</b></figref>. These scores can be rolled up into a single score for the entire driver-side area, as depicted in <figref idref="DRAWINGS">FIG. <b>21</b></figref>, which due to overlapping areas in the zone <b>330</b>, weights locations in the area (driver-side door handle) higher than other less operationally significant locations.</p><p id="p-0175" num="0189">In one embodiment, a method may be provided for determining a root-mean-square error (RMSE) metric as depicted in the illustrated embodiments of <figref idref="DRAWINGS">FIGS. <b>22</b>, <b>23</b>, and <b>24</b></figref> and generally designated <b>1500</b>. The RMSE may be used to quantify the difference between actual range and observe set of range data reported between a candidate position for a sensor <b>40</b> and the remote device <b>20</b>. The RMSE may be defined as the square root of the mean of quadratic difference between the measured ranges in the actual range. RMSE may be a useful measure of system performance as well, as a metric often uses a cost function to be minimized when building a detection system for zone classification or localization.</p><p id="p-0176" num="0190">The method <b>1500</b> may involve obtaining input parameters, including the zone <b>330</b> under test, ground truth information for N positions in the zone <b>330</b>, r_g as an ensemble of T range measurements at each position g in the zone <b>330</b>, and a candidate location of the sensor <b>40</b>. The parameters may be fed to through a function to yield RMSE, which may be performed in accordance with the formula depicted in <figref idref="DRAWINGS">FIG. <b>24</b></figref>. Steps <b>1510</b>, <b>1520</b>. It is to be understood that the formula may vary from application to application.</p><p id="p-0177" num="0191">The RMSE for each zone <b>330</b> can be computed, or a set of zones can be used to compute a single, overall RMSE. For instance, for the candidate location of the sensor <b>40</b> in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>22</b></figref>, an overall RMSE of <b>349</b> has been calculated in one embodiment of the present disclosure. As an indicator of coverage, RMS can be computed per point, per zone, or even across many zones.</p><p id="p-0178" num="0192">In one embodiment, a metric for determining performance may be determined based on RMSE. RMSE analysis yields that the Gaussian distribution of errors at each point in a zone <b>330</b> change from point-to-point within the zone <b>330</b>, creating a multi-modal distribution over the entire zone <b>330</b>. Statistics for Gaussian models (mean and standard deviation) may fail to accurately capture this variation and can lead to incorrect assumptions about the ranging performance.</p><p id="p-0179" num="0193">In one embodiment to capture the change and variability of ranging for a candidate location under test, the full width, half maximum (FWHM) of RMSE over the ground truth test points over a zone may be calculated. FWHM for RMSE may be the extent in range for which the RMSE occurs at least half as often as the most prevalent RMSE. Larger FWHM indicates that the ranging system has recorded range measurements that vary over a wider extent of ranges. A histogram of RMSE showing a non-Gaussian distribution is depicted in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>25</b></figref> in conjunction with the zone <b>330</b>. The Mode is 51.7 mm, and the mean is 177 mm for the distribution with a standard deviation of 118 (59-295) mm. The FWHM determined for this distribution is 7.48 (48-55.4) mm.</p><p id="p-0180" num="0194">FWHM may be determined in accordance with one embodiment by the method <b>1600</b>, which is depicted in <figref idref="DRAWINGS">FIG. <b>26</b></figref>. The method <b>1600</b> may include obtaining input parameters including RMSE for the zone <b>330</b> under test. Step <b>1610</b>. The RMSE for the zone <b>330</b> may be translated to a histogram [f,x] (e.g., a distribution), and analyzed for mode as x(f_max). Steps <b>1620</b>, <b>1630</b>. A half max upper and half max lower parameter may be determined based on the mode and the minimum and maximum X values. Step <b>1640</b>, <b>1650</b>. The FWHM metric may be determined as the difference between the half max upper in half max lower parameters. Step <b>1660</b>. The FWHM can be visualized in accordance with the histogram/distribution depicted in <figref idref="DRAWINGS">FIG. <b>27</b></figref>.</p><p id="p-0181" num="0195">The FWHM metric can be computed for each zone <b>330</b> being tested, as depicted in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>28</b></figref> for the identified zones. Additionally, or alternatively, the FWHM metric can be computed for a set of zones to compute a single, overall FWHM, which would be <b>146</b> for the data obtained in conjunction with the zones <b>330</b> under test in <figref idref="DRAWINGS">FIG. <b>28</b></figref>.</p><p id="p-0182" num="0196">It is noted that, as discussed herein, an obstruction can be carried by the movable body <b>320</b> in conjunction with the remote device <b>20</b>. As an example, the obstruction may be provided to emulate a &#x201c;back pocket&#x201d; scenario and its effect on performance. Alternatively, the movable body <b>320</b> may be a human person that carries the remote device <b>20</b> in their back pocket, and reports ground truth information to the control system <b>310</b>. The effect of an obstruction can be determined via one or more metrics, including a delta RMSE metric. This metric is determined in conjunction with the candidate locations depicted in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>29</b></figref>, where a person has carried the remote device <b>20</b> in their back pocket as an obstruction test. A comparison of the RMSE distributions for back pocket arrangements (e.g., an obstruction) and line of sight arrangements. The delta RMSE may be determined as the difference between these RMSE distributions, or the difference between RMSE_clear (root-mean-square-error for all range measurements in the clear where the remote device <b>20</b> is carried by the movable body <b>320</b>) and RMSE_back_pocket (root-mean-square error for all range measurements where the initiator is in a person's back pocket or emulated as such).</p><p id="p-0183" num="0197">In one embodiment, to characterize how much a human body attenuates the UWB signal, a comparison may be made between the range measurements of where the remote device <b>20</b> is in a person's back pocket and range measurements where the remote device is on a stand (e.g., the movable body <b>320</b>). The change in RMSE or delta RMSE may capture both increased delay and increased variability in the range measurements.</p><p id="p-0184" num="0198">An alternative obstruction procedure may involve use of a dummy that emulates a back pocket obstruction. A comparison of the results for no obstruction, a human carrying the remote device <b>20</b>, and a dummy system that emulates the back pocket scenario are shown in <figref idref="DRAWINGS">FIG. <b>30</b></figref>. The dummy system may involve the movable body <b>320</b> carrying the remote device <b>20</b> in conjunction with an obstruction, such as a bag of 1.2 L 96% water solution 50 g poly vinyl alcohol and 4 g sodium borate (&#x201c;slime&#x201d;). This type of dummy obstruction, as compared to a human body, and a no obstruction test, along the test paths shown in <figref idref="DRAWINGS">FIG. <b>30</b></figref>, yields comparable results in range delay and variability. The delay and spread shown in the distributions of range measurements indicates that more energy is directed through the dummy obstruction than a human body for candidate positions <b>7</b> and <b>16</b>. For candidate position <b>12</b>, the delay and spread in range measurements indicate a reasonable match between the dummy obstruction and the human body and non-obstructed configurations. It is noted that differences may relate to the dummy construction, and that changing the construction of the dummy may yield further aligned results, such as by adding a pocket to the bag for holding shape and position of the remote device <b>20</b>.</p><p id="p-0185" num="0199">It is to be understood that the present disclosure is not limited to the specific metrics described herein. Additional or alternative metrics may be generated. Examples of alternative metrics include mean range (mm), median range (mm), standard deviation of range measurements (mm), missed detection (%), likelihood of non-line-of-sight measurement (%), mean range error (mm), standard deviations of range error (mm), and detectability per zone (%).</p><p id="p-0186" num="0200">The likelihood of non-line-of-sight measurement may be computed as the number of measurements where the likelihood of non-line-of-sight metric equals 100% divided by the total number of measurements. In other words, this metric may be computed as the number of range measurements with a recorded non-line-of-sight (NLOS) value of 100 during an interval per number of total range measurements for a sensor <b>40</b> during an interval times <b>100</b>.</p><p id="p-0187" num="0201">Missed detections may be determined as the number of missing range measurements from a sensor <b>40</b> during an interval per number of total range measurements for the sensor <b>40</b> during an interval times <b>100</b>.</p><p id="p-0188" num="0202">Mean range error may be determined as the absolute value of the average difference between a measured range value and the ground truth range for an ensemble of range measurements.</p><p id="p-0189" num="0203">Standard deviation of range error may be determined as the standard deviation of difference between a measured range value and the ground truth range for an ensemble of range measurements.</p><p id="p-0190" num="0204">E. Evaluating Performance Metric</p><p id="p-0191" num="0205">The system <b>300</b> in one embodiment may be configured to generate one or more performance metrics for candidate locations, or groups of candidate locations, for the one or more sensors <b>40</b> on the object <b>10</b> and with respect to one or more zones <b>330</b>. The performance metrics may include, but are not limited, to one or more of the following: detectability; RMSE; FWHM; and delta RMSE.</p><p id="p-0192" num="0206">In the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>31</b></figref>, the detectability metric for a plurality of sensors <b>40</b> at candidate locations labeled <b>1</b>-<b>22</b> is shown in conjunction with each zone <b>330</b> identified and described in connection with <figref idref="DRAWINGS">FIGS. <b>10</b>A-O</figref>. <figref idref="DRAWINGS">FIGS. <b>32</b> and <b>33</b></figref> show the RMSE and FWHM metrics for the same candidate locations and zones <b>330</b>. As can be seen, in one embodiment, the top performing candidate locations for each metric can be determined. For instance, the top 5 performing candidate locations identified by the detectability metric are candidate locations <b>3</b>, <b>6</b>, <b>16</b>, <b>7</b>, and <b>12</b>. The top 5 performing candidate locations for the RMSE metric are candidate locations <b>3</b>, <b>6</b>, <b>7</b>, <b>10</b>, and <b>18</b>, and the top 5 performing candidate locations for the FWHM metric are candidate locations <b>7</b>, <b>10</b>, <b>3</b>, <b>18</b>, and <b>6</b>.</p><p id="p-0193" num="0207">A performance metric obtained with respect to a data collection with an obstruction can be analyzed in a manner similar to <figref idref="DRAWINGS">FIGS. <b>31</b>-<b>33</b></figref> for each candidate location and for each zone <b>330</b> under test. For instance, in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>34</b></figref>, delta RMSE is shown in conjunction with 1) the test paths at 90 deg., 45 deg., 0 deg., &#x2212;45 deg., and &#x2212;90 deg. relative to the driver side door hand and 2) candidate locations (labeled <b>3</b>, <b>5</b>-<b>8</b>, <b>10</b>, <b>12</b>, <b>15</b>, <b>17</b>, and <b>18</b>) for a plurality of sensors <b>40</b>.</p><p id="p-0194" num="0208">As depicted in the illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>35</b></figref>, the results for plurality of metrics for each candidate location of a sensor <b>40</b> relative to the zones <b>330</b> under test (e.g., data collection paths) can be processed to yield a composite score for each candidate location. The composite score may be based on an average of results across zones for detectability, RMSE, FWHM, and averaged across remote device test points for delta RMSE obstruction (e.g., RMSE back pocket). The top performing candidate locations, or group of candidate locations, may be identified for use in a real-time environment for determining location without the ground truth data.</p><p id="p-0195" num="0209">The composite score for each candidate location may be determined in a variety of ways. In one embodiment, the composite score may be determined according to the following formula (also shown in <figref idref="DRAWINGS">FIG. <b>36</b></figref>):</p><p id="p-0196" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <mrow>   <mrow>    <mi>Driver</mi>    <mo>'</mo>   </mrow>   <mo>&#x2062;</mo>   <mi>s</mi>   <mo>&#x2062;</mo>   <mtext>   </mtext>   <mi>Side</mi>   <mo>&#x2062;</mo>   <mtext>   </mtext>   <mi>Area</mi>   <mo>&#x2062;</mo>   <mtext>   </mtext>   <mi>Score</mi>  </mrow>  <mo>=</mo>  <mrow>   <mi>detectability</mi>   <mtext>   </mtext>   <mo>&#x2a2f;</mo>   <mtext>   </mtext>   <mfrac>    <mn>1</mn>    <mi>RMSE</mi>   </mfrac>   <mtext>   </mtext>   <mo>&#x2a2f;</mo>   <mfrac>    <mn>1</mn>    <mrow>     <mi>FWHM</mi>     <mo>&#x2062;</mo>     <mtext>   </mtext>     <mi>RMSE</mi>    </mrow>   </mfrac>  </mrow> </mrow></math></maths><maths id="MATH-US-00001-2" num="00001.2"><math overflow="scroll"> <mrow>  <mrow>   <mi>Obstruction</mi>   <mo>&#x2062;</mo>   <mtext>   </mtext>   <mrow>    <mo>(</mo>    <mi>backpocket</mi>    <mo>)</mo>   </mrow>   <mo>&#x2062;</mo>   <mtext>   </mtext>   <mi>score</mi>  </mrow>  <mo>=</mo>  <mfrac>   <mn>1</mn>   <mrow>    <mrow>     <mi>&#x394;</mi>     <mo>&#x2062;</mo>     <mi>RMSE</mi>    </mrow>    <mo>,</mo>    <mi>backpocket</mi>   </mrow>  </mfrac> </mrow></math></maths><maths id="MATH-US-00001-3" num="00001.3"><math overflow="scroll"> <mrow>  <mrow>   <mi>Overall</mi>   <mo>&#x2062;</mo>   <mtext>   </mtext>   <mi>Score</mi>  </mrow>  <mo>=</mo>  <mrow>   <mrow>    <mi>Driver</mi>    <mo>'</mo>   </mrow>   <mo>&#x2062;</mo>   <mi>s</mi>   <mo>&#x2062;</mo>   <mtext>   </mtext>   <mi>Side</mi>   <mo>&#x2062;</mo>   <mtext>   </mtext>   <mi>Area</mi>   <mo>&#x2062;</mo>   <mtext>   </mtext>   <mrow>    <mi>Score</mi>    <mtext>   </mtext>    <mo>&#x2a2f;</mo>    <mtext>   </mtext>    <mi>Obstruction</mi>   </mrow>   <mo>&#x2062;</mo>   <mtext>   </mtext>   <mi>Score</mi>  </mrow> </mrow></math></maths></p><p id="p-0197" num="0210">Based a composite score from this formula for each candidate location, for the driver's side area, higher performing candidate locations can be identified. In the illustrated embodiment, the candidate locations with the better scores are 1) the lower, back corner of the driver's side door (<b>7</b>, <b>6</b>); 2) high, front center of the wheel well (<b>3</b>) and middle and front center of the wheel well (<b>12</b>); 3) lower, front corner of the front driver's side door (<b>5</b>); and <b>4</b>) headline above driver's seat near the door (<b>10</b>).</p><p id="p-0198" num="0211">For the driver, the driver side zones performance metrics, detectability, RMSE, and FWHM RMSE are determined, and aggregated over 15 overlapping zones (e.g., <figref idref="DRAWINGS">FIGS. <b>10</b>A-O</figref>) in the driver side area. Scores can be weighted to areas with most overlap across zones. As described in <figref idref="DRAWINGS">FIG. <b>36</b></figref>, delta RMSE may be determined for an obstruction condition, and the obstruction score can be used in conjunction with the driver side zones score to yield a composite score for each candidate location of the sensor <b>4</b>.</p><p id="p-0199" num="0212">Directional terms, such as &#x201c;vertical,&#x201d; &#x201c;horizontal,&#x201d; &#x201c;top,&#x201d; &#x201c;bottom,&#x201d; &#x201c;upper,&#x201d; &#x201c;lower,&#x201d; &#x201c;inner,&#x201d; &#x201c;inwardly,&#x201d; &#x201c;outer&#x201d; and &#x201c;outwardly,&#x201d; are used to assist in describing the invention based on the orientation of the embodiments shown in the illustrations. The use of directional terms should not be interpreted to limit the invention to any specific orientation(s).</p><p id="p-0200" num="0213">The above description is that of current embodiments of the invention. Various alterations and changes can be made without departing from the spirit and broader aspects of the invention as defined in the appended claims, which are to be interpreted in accordance with the principles of patent law including the doctrine of equivalents. This disclosure is presented for illustrative purposes and should not be interpreted as an exhaustive description of all embodiments of the invention or to limit the scope of the claims to the specific elements illustrated or described in connection with these embodiments. For example, and without limitation, any individual element(s) of the described invention may be replaced by alternative elements that provide substantially similar functionality or otherwise provide adequate operation. This includes, for example, presently known alternative elements, such as those that might be currently known to one skilled in the art, and alternative elements that may be developed in the future, such as those that one skilled in the art might, upon development, recognize as an alternative. Further, the disclosed embodiments include a plurality of features that are described in concert and that might cooperatively provide a collection of benefits. The present invention is not limited to only those embodiments that include all of these features or that provide all of the stated benefits, except to the extent otherwise expressly set forth in the issued claims. Any reference to claim elements in the singular, for example, using the articles &#x201c;a,&#x201d; &#x201c;an,&#x201d; &#x201c;the&#x201d; or &#x201c;said,&#x201d; is not to be construed as limiting the element to the singular. Any reference to claim elements as &#x201c;at least one of X, Y and Z&#x201d; is meant to include any one of X, Y or Z individually, and any combination of X, Y and Z, for example, X, Y, Z; X, Y; X, Z; and Y, Z.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001 MATH-US-00001-2 MATH-US-00001-3" nb-file="US20230007441A1-20230105-M00001.NB"><img id="EMI-M00001" he="16.93mm" wi="76.20mm" file="US20230007441A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>The embodiments of the invention in which an exclusive property or privilege is claimed are defined as follows:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system for obtaining location data for a portable device relative to an object, the system comprising:<claim-text>an object device disposed in a fixed position relative to the object, the object device having an antenna configured to communicate wireles sly with the portable device via a communication link;</claim-text><claim-text>a control system configured to obtain one or more samples pertaining a time of flight of communications between the portable device and the object device, the control system configured to obtain a first set of the one or more samples with respect to the portable device being at a first position, the control system configured to obtain a second set of the one or more samples with respect to the portable device being at a second position;</claim-text><claim-text>a movable body operably coupled to the portable device, the movable body being configured to position the portable device in accordance with a position directive communicated from the control system; and</claim-text><claim-text>the control system configured to direct movement of the movable body to change a position of the portable device from the first position to the second position.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the control system is configured to obtain sensor characteristic data for the first and second positions, wherein the control system is configured to generate a composite score for the object device based on the sensor characteristic data.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref> wherein the composite score is indicative of a performance of a sensor position for a UWB sensor on the object.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref> comprising first and second sensor devices disposed on the object at respective first and second candidate locations, wherein the first sensor device is the object device.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system as claimed in <claim-ref idref="CLM-00004">claim 4</claim-ref> wherein the control system is configured to calculate a first composite score for the first sensor device and a second composite score for the second sensor device.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system as claimed in <claim-ref idref="CLM-00005">claim 5</claim-ref> wherein the control system is configured to identify a relative ranking of the first and second candidate locations based on the first and second composite scores.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system as claimed in <claim-ref idref="CLM-00006">claim 6</claim-ref> wherein the relative ranking is indicative of a position providing greater accuracy relative to another position in determining a location of the portable device relative to the object, wherein the location of the portable device is determined based on communications with the portable device according to a UWB communication protocol.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The system as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref> wherein the composite score is based on an RMSE metric and a FWHM metric of the RMSE metric, wherein the RMSE metric and the FWHM metric are based on range measurements, wherein the range measurements are determined based on communications with the portable device and based on sensor characteristic data obtained for each of the first and second sensors.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system as claimed in <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the composite score is based on a detectability metric.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A system for determining a location of a portable device relative to an object, the system comprising:<claim-text>a movable body operably coupled to the portable device, the movable body being configured to position the portable device in accordance with a position directive;</claim-text><claim-text>a control system configured to obtain first samples pertaining to a time of flight of communications between the portable device and a first sensor at a first position, the control system configured to obtain second samples pertaining to a time of flight of communications between the portable device and a second sensor at the first position;</claim-text><claim-text>the control system configured to obtain third samples pertaining to a time of flight of communications between the portable device and the first sensor at a second position, the control system configured to obtain fourth samples pertaining to a time of flight of communications between the portable device and the second sensor at the second position; and</claim-text><claim-text>wherein the control system is configured to communicate the position directive to the movable body to change a position of the portable device from the first position to the second position.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref> wherein the control system is configured to rank a performance of the first and second sensors at the respective first and second candidate locations.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref> wherein:<claim-text>the control system is operable to determine a first metric for the first sensor based on the first and third samples and to determine a second metric for the second sensor based on the second and fourth samples; and</claim-text><claim-text>the control system is operable to rank the performance of the first and second sensors based on the first and second metrics.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref> wherein the control system is operable to determine a performance score for the first and second sensors with respect to first and second zones, wherein the control system is configured to generate composite scores for the first and second sensors respectively based on the performance score for the first and second zones.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref> wherein the communications are UWB communications.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref> wherein first and second sensor devices are disposed on the object at respective first and second candidate locations.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the first sensor device includes the control system.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the control system is configured to calculate a first composite score for the first sensor device and a second composite score for the second sensor device.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The system of <claim-ref idref="CLM-00017">claim 17</claim-ref> wherein the control system is configured to identify a relative ranking of the first and second candidate locations based on the first and second composite scores.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00018">claim 18</claim-ref> wherein the relative ranking is indicative of a position providing greater accuracy relative to another position in determining a location of the portable device relative to the object.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref> wherein the location of the portable device is determined based on communications with the portable device according to a UWB communication protocol.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005262A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005262</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17779435</doc-number><date>20201125</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>20</main-group><subgroup>20</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>63</class><subclass>F</subclass><main-group>13</main-group><subgroup>28</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>19</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>20</main-group><subgroup>20</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20140902</date></cpc-version-indicator><section>A</section><class>63</class><subclass>F</subclass><main-group>13</main-group><subgroup>28</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>011</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>19</main-group><subgroup>006</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEM AND METHOD FOR DYNAMIC SYNCHRONIZATION BETWEEN REAL AND VIRTUAL ENVIRONMENTS</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>62939737</doc-number><date>20191125</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only"><addressbook><last-name>MELCHNER</last-name><first-name>Alon</first-name><address><city>Rosh Haayin</city><country>IL</country></address></addressbook><residence><country>IL</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MELCHNER</last-name><first-name>Alon</first-name><address><city>Rosh Haayin</city><country>IL</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/IL2020/051210</doc-number><date>20201125</date></document-id><us-371c12-date><date>20220524</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The invention relates to a mixed reality system for dynamic synchronization between real and virtual environments, allowing a virtual stimulus superimposed on or near a real object in a real world location to create a physical reaction in the real world, as if the virtual stimulus were real. The system comprises reactive piece(s) and a mechanism for tracking the reactive piece(s), a stimulizing mechanism for translating user motions into virtual stimuli, and a virtuality-reality synchronizer to compute appropriate reaction parameters of reactive piece(s) to a virtual stimulus, as if the stimulus were really applied to the physical piece. Each reactive piece has a reaction mechanism, e.g. a moving or vibrating component, actuated by a signal comprising the reaction parameters. When the reaction mechanism is actuated it can, for example, destabilize the object in a predetermined manner. Destabilization can be varied to reflect the power or effectiveness of the virtual stimulus.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="117.43mm" wi="158.75mm" file="US20230005262A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="208.45mm" wi="120.65mm" orientation="landscape" file="US20230005262A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="227.67mm" wi="160.87mm" orientation="landscape" file="US20230005262A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="233.17mm" wi="162.31mm" file="US20230005262A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="133.69mm" wi="156.21mm" file="US20230005262A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="232.07mm" wi="180.34mm" file="US20230005262A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="222.93mm" wi="170.35mm" file="US20230005262A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD OF THE INVENTION</heading><p id="p-0002" num="0001">The invention is in the field of mixed reality, and in particular relates to a system for synchronizing physical and simulated realities and enabling physical objects to react to virtual visual stimuli.</p><heading id="h-0002" level="1">BACKGROUND TO THE INVENTION</heading><p id="p-0003" num="0002">Augmented reality games are layers of virtual worlds that are superimposed on the real environment, sometimes acting as layers to real environment objects such as toys, engineering devices, furniture, etc.</p><p id="p-0004" num="0003">Mixed reality (MR) is the merging of real and virtual worlds to produce new environments and visualizations, where physical and digital objects co-exist and interact in real time. Mixed reality does not exclusively take place in either the physical or virtual world, but is a hybrid of reality and virtual reality, encompassing a spectrum of real and virtual elements.</p><p id="p-0005" num="0004">For example, different applications have been created with Lego&#xae; blocks that enable virtual layers to be connected or follow the physical toys or pieces, these layers appear &#x201c;floating&#x201d; near the physical pieces, without affecting them.</p><p id="p-0006" num="0005">Among existing games in the virtuality-reality spectrum, an augmented reality (AR) game, SpecTrek, projects ghosts at various locations on a Google map in either a predetermined search radius or a user-defined search radius. To play, the user must walk to ghosts within their range. The user can scan and find out what kind of ghost is nearby as well as how far the ghost is from their current position. If the user is unable to reach a ghost, a horn may be blown which makes all nearby ghosts flee and possibly stop within reach of another accessible location. The user catches ghosts by scanning the ghosts with their cameras.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0007" num="0006">The present invention relates to a mixed reality system for dynamic synchronization between real and virtual environments, allowing a virtual stimulus superimposed on or near a real object in a real world location to create a physical reaction in the real world, as if the virtual stimulus were real. The system comprises reactive piece(s) and a mechanism for tracking the reactive piece(s), a stimulizing mechanism for translating user motions into virtual stimuli, and a virtuality-reality synchronizer to compute appropriate reaction parameters of reactive piece(s) to a virtual stimulus, as if the stimulus were really applied to the physical piece. Each reactive piece has a reaction mechanism, for example a moving or vibrating component, which may be actuated by a signal comprising the reaction parameters. When the reaction mechanism is actuated it can, for example, destabilize the object in a predetermined manner. The destabilization can be varied in a manner to reflect the power or effectiveness of the virtual stimulus.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an MR gaming system, according to some embodiments of the invention.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a reaction mechanism of reactive pieces in an MR gaming system, according to some embodiments of the invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0010" num="0009">&#x201c;Virtual physics,&#x201d; as used in this disclosure, refers to the computer simulation of interactions and/or reactions of virtual objects.</p><p id="p-0011" num="0010">&#x201c;Virtuality-to-reality synchronization&#x201d; refers to the computational modeling of virtual stimuli and reactions of physical objects to the virtual stimuli, and how to implement the reactions in reaction mechanisms integrated into the physical objects.</p><p id="p-0012" num="0011">&#x201c;Reality-to-virtuality synchronization&#x201d; refers to updating the computational model to account for the physical stimulus.</p><p id="p-0013" num="0012">&#x201c;Prompt&#x201d; refers to action(s) by a user that cause(s), in whole or in part, a system of the invention to initiate a virtual stimulus and implement one or more particular physical reactions of one or more physical objects to the virtual stimulus as if it were real.</p><p id="p-0014" num="0013">The present disclosure relates to a mixed reality gaming system. It is appreciated that the principles disclosed herein can be applied to other mixed reality applications, including education, training, physical therapy, occupational therapy, remote surgery, industrial use, theme parks, smart cities, advertisements and interactive shopping, among others.</p><p id="p-0015" num="0014">Reference is now made to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, showing a mixed reality gaming system, according to some embodiments of the invention.</p><p id="p-0016" num="0015">Mixed reality gaming system <b>100</b> comprises reactive pieces <b>105</b>, each with a reaction mechanism configured to cause a physical reaction of the reactive piece <b>105</b>. The physical reaction can be toppling or tilting of reactive piece <b>105</b>, as further described herein. The reaction mechanism may be part of a base <b>200</b>, further described herein, of reactive piece <b>105</b>. Reactive pieces <b>105</b> may be stationary or may be moving on a real operative surface <b>125</b>.</p><p id="p-0017" num="0016">Mixed reality gaming system <b>100</b> further comprises a tracking mechanism <b>110</b> that tracks physical parameters of reactive pieces <b>105</b>. Such physical parameters may describe a physical position, a physical orientation, identifying features, and/or physical motion of reactive pieces <b>105</b> on operative surface <b>125</b>. Detection mechanism <b>110</b> can be a part of a user device (with a specialized application installed), as shown. Alternatively, or additionally, detection mechanism can be an external apparatus. Tracking mechanism <b>110</b> may store fixed initial positions of reactive pieces, such as reactive bowling pins in an MR bowling game, further described herein.</p><p id="p-0018" num="0017">Tracking mechanism <b>110</b> can comprise a camera and processor of a user device, as shown, equipped with a specialized application. A user scans the camera through the reactive pieces <b>105</b>. Alternatively, tracking mechanism <b>110</b> with similar functionality can be embedded in MR smart glasses. The scan can acquire images of QR codes on the pieces <b>105</b> or images of the pieces <b>105</b> themselves. The processor employs a computer vision algorithm to associates the images with identifiers of the pieces <b>105</b>; the processor may implement the association in cooperation a pieces control unit <b>115</b>, further described herein. The processor then computes their position; for example, using a computer vision methodology such as AR and/or SLAM technology.</p><p id="p-0019" num="0018">Tracking mechanism <b>110</b> may, alternatively or in addition, comprise a wireless triangulation system.</p><p id="p-0020" num="0019">Tracking mechanism <b>110</b> may, alternatively or in addition, comprise one or more touch-sensitive surfaces (e.g., mats) disposed on the operative surface <b>125</b>. Locations of the pieces <b>105</b> can be determined by where the touch-sensitive surface is depressed. Additionally, each reactive pieces <b>105</b> can have a unique footprint, each footprint shape associated a unique identifier of the piece <b>105</b>. If the pieces are moving, the touch-sensitive surface(s) continue to track locations of the reactive pieces <b>105</b>.</p><p id="p-0021" num="0020">System <b>100</b> further comprises a stimulizing mechanism <b>120</b>, in communicative connection with tracking mechanism <b>110</b> and/or reactive pieces <b>105</b>. Stimulizing mechanism <b>120</b> detects one or more motions of one or more users. For example, the user motion detected by stimulizing mechanism <b>120</b> can be the pulling a trigger while aiming tracking mechanism <b>110</b> at one of reactive pieces <b>105</b>. Stimulizing mechanism <b>120</b> then computes parameters of one or more virtual stimuli of one or more reactive pieces <b>105</b>, caused by the user motion(s). For example, stimulizing mechanism <b>120</b> may compute visual and/or acoustic virtual stimuli of a gun triggered by the user, in the aiming direction of tracking mechanism <b>110</b>, such as direction, velocity, power, virtual bullet location on a reactive target <b>105</b> etc. of the virtual gunshot.</p><p id="p-0022" num="0021">In some embodiments, stimulizing mechanism <b>120</b> detects limbs of a user; for example, throwing motions of the arms or kicking motions of the legs, captured by a video camera, for example. Stimulizing mechanism <b>120</b> may then implement a computer-vision algorithm to compute stimulus parameters as a function of the user motions, such as an initial velocity and direction of a virtual ball or dart, for example.</p><p id="p-0023" num="0022">Stimulizing mechanism <b>120</b> can comprise a user motion detector and a processor of a user device, as shown, equipped with a specialized application. The user motion detector could be a gyro, a compass, a tilt-sensor, a camera, or any combination thereof. Alternatively, stimulizing mechanism <b>120</b> with similar functionality can comprise MR smart glasses and an MR gun, for example.</p><p id="p-0024" num="0023">System <b>100</b> further comprises a mixed-reality output mechanism <b>122</b>. MR output mechanism <b>122</b> receives the virtual stimulus parameters and conveys to the user a superposition of the virtual stimulus over a reactive piece <b>105</b>. The MR output mechanism <b>122</b> may, for example, display the visual effects of a gunshot over an image of reactive piece <b>105</b>. MR output mechanism may comprise an output screen of a user device, or smart glasses. MR output mechanism may comprise a speaker (e.g., of the user device), for example blaring the sound of the virtual gunfire.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>1</b>B</figref> shows some of the effects that may appear in MR output mechanism <b>122</b>, such as a virtual explosion <b>130</b>, a virtual AR force field <b>135</b>, and a virtual AR health bar <b>140</b> (showing the &#x201c;health&#x201d; of a reactive piece <b>105</b> during a &#x201c;battle&#x201d;). In some embodiments, MR output mechanism <b>122</b> may be further equipped to give a reaction to the user, such as a recoil &#x201c;kick.&#x201d;</p><p id="p-0026" num="0025">System <b>100</b> further comprises a virtuality-reality (V-R) synchronizer <b>123</b>. V-R synchronizer <b>123</b> comprises a processor that receives the virtual stimulus parameters and computes physical reaction parameters of a physical reactive piece <b>105</b> to the virtual stimulus, as if the virtual stimulus takes place in the real physical world. The reaction parameters are computed according to how the virtually stimulated reactive piece <b>105</b> should react to the stimulus. V-R synchronizer <b>123</b> then sends the reaction parameters to the reaction mechanism of the virtually stimulated reactive piece <b>105</b>. The reaction mechanism implements the reaction parameters. The reaction can be for the virtually shot reactive piece to fall, to kneel (e.g., if a virtual shot missed), to run, and the like. Upon effecting the reaction, V-R synchronizer <b>123</b> may re-formulate a model of the MR environment, based on the new reality in the physical world, and use the re-formulated model in future computation of reaction parameters.</p><p id="p-0027" num="0026">In some embodiments, system <b>100</b> further comprises a pieces control unit (PCU) <b>115</b>, in communicative connection with a user device&#x2014;comprising tracking mechanism <b>110</b>, stimulizing mechanism <b>120</b>, and MR output mechanism&#x2014;and reactive pieces <b>105</b>. PCU <b>115</b> implements functions of virtual-reality synchronizer <b>123</b> (in whole or in part), thereby alleviating the user device of computational effort required to compute physical reaction parameters from virtual stimulus parameters. PCU <b>115</b> may also track the statuses (e.g., AR health) of reactive pieces <b>105</b>, and report these to one or more user devices, so that in a multi-user embodiment of system <b>100</b>, all user devices can be updated of the piece statuses.</p><p id="p-0028" num="0027">Reference is now also made to <figref idref="DRAWINGS">FIG. <b>2</b>A-<b>2</b>C</figref>, showing side views and a top view of a reaction mechanism of a reactive piece, according to some embodiments of the invention. The reaction mechanism, in these embodiments, is a magnetic dome base <b>200</b>, on which a reactive piece is attached.</p><p id="p-0029" num="0028">Magnetic dome base <b>200</b> comprises a dome <b>205</b> with an internal bowl, a metal ball <b>210</b> disposed to roll in the internal bowl, and a plurality of controllable magnets <b>215</b>.</p><p id="p-0030" num="0029">The V-R synchronizer <b>123</b> sends reaction parameters to the reaction mechanism <b>200</b>. The reaction parameters comprise selective activation of controllable magnets <b>215</b> (according to a direction which the V-R synchronizer <b>123</b> computed from the stimulus parameters). The magnetic fields thereby created cause the metal ball <b>210</b> to roll on the internal bowl in the specified direction, which in turn causes the magnetic dome base <b>200</b> to tilt, as shown in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>. The tilting base causes the reactive piece <b>105</b> to tilt or topple.</p><p id="p-0031" num="0030">In some embodiments, the strengths of magnetic fields generated by controllable magnets <b>215</b> are adjustable. PCU magnetic reaction parameters include an adjustment for the strength and/or rate of change of the magnetic field produced by each controllable magnet <b>215</b>. The extent and/or speed of the tilt/toppling is thereby adjustable, in accordance with the stimulus parameters received from the prompting mechanism <b>120</b>.</p><p id="p-0032" num="0031">In some embodiments, magnetic dome base <b>200</b> comprises at least four magnets, as shown in <figref idref="DRAWINGS">FIG. <b>2</b>C</figref>. Each pair of opposing magnets can control the magnitude, intensity, and/or rate of change of magnetic fields in an x and y direction, thereby enabling a tilting or toppling reaction along a horizontal axis selectable over 360&#xb0;. In some alternative embodiments, shown in <figref idref="DRAWINGS">FIG. <b>2</b>D</figref>, magnetic dome base <b>250</b> may be in the shape of a polygon. A polygonal magnetic dome base <b>250</b> can restrict the direction of tilt/tipple to directions normal to one of the sides of the polygon.</p><p id="p-0033" num="0032">It is understood that the reaction mechanism described herein is one example. The means of causing a reaction, such as making something fall in a particular direction, can be implemented, alternatively or in addition, in a variety of mechanical method(s) known in the art.</p><p id="p-0034" num="0033">Communication with PCU <b>115</b> can be by any one or more suitable wireless standards. For example, communication with detection mechanism <b>110</b> can be Bluetooth and communication with reactive pieces <b>105</b> can be by 2.4 GHz RF.</p><p id="p-0035" num="0034">Reference is now made to <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, showing a block diagram of a mixed reality gaming system <b>300</b>, according to some embodiments of the invention.</p><p id="p-0036" num="0035">A communication link <b>310</b> between a user device <b>310</b> and PCU <b>115</b> can employ a protocol suitable short distance wireless communication, preferably Bluetooth. Communication link <b>320</b> between PCU <b>115</b> and reactive pieces <b>105</b> (the bases thereof are shown) can also employ a protocol suitable short distance wireless communication, preferably Zigbee or 2.4 GHz RF.</p><p id="p-0037" num="0036">Alternative embodiments of the invention can be a bowling game system in which bowling pins are located on or connected to a physical base unit that activates their falling mechanism when a virtual bowling ball hits them. The system computes how the bowling pins should fall according to the direction, energy and other physical effects a real ball would have created. After movement, if the camera will be aiming the direction of the virtual ball's movement, it is possible to see the virtual ball moving toward the real physical pins and hits them and causes them to physically react as the system computed.</p><p id="p-0038" num="0037">Other embodiments include other real world games like a real soccer ball with a real kick action, bowling and rolling action of the ball with the real hand, and darts with virtual throwing action by real hand, then converted to a virtual action. Movements of real legs or arms recognized by computer vision may represent the movement or power generated to the ball or darts. which in turn initiates the real reaction as taught herein.</p><p id="p-0039" num="0038">The user device may be a mobile device that includes a gyro and/or other movement and momentum detections devices to define the use of the mobile device and its movement, then convert (by computation) the real movement to the movement of a virtual ball, dart, etc. in the direction and with the power computed from the movement of the mobile device.</p><p id="p-0040" num="0039">Reference is now made to <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, showing a block diagram of a mixed reality gaming system <b>300</b>, according to some embodiments of the invention. User device <b>360</b> stores locations of reactive pieces <b>355</b> and computes stimulus parameters when a prompting mechanism of user device is triggered. User device <b>360</b> transmits the stimulus parameters to a Bluetooth receiver <b>365</b> of PCU <b>115</b>. PCU may be powered by a battery <b>375</b>. A processor board <b>365</b> (e.g., Arduino) of PCU computes reaction parameters as a function of the stimulus parameters. An RF transmitter <b>370</b> of PCU <b>115</b> sends the reaction parameters to an RF receiver <b>380</b> of reactive piece <b>355</b>. Reactive piece <b>355</b> may comprise a processor board <b>385</b> (which can also be an Arduino board) in order to convert the reaction parameters a format needed to drive reaction mechanism <b>390</b>. Reaction mechanism <b>390</b> can be, for example, a vibration motor, a magnetic dome base (e.g., as further described herein), and/or a magnetic weight mechanism.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A mixed reality system for dynamic synchronization between real and virtual environments <b>100</b>, comprising<claim-text>a. one or more reactive pieces <b>105</b>, each comprising a reaction mechanism configured to cause a physical reaction of the reactive piece <b>105</b>;</claim-text><claim-text>b. a tracking mechanism <b>110</b>, configured to track one or more physical parameters of said reactive pieces <b>105</b>, said physical parameters comprising at least a location of a said reactive piece <b>105</b>;</claim-text><claim-text>c. a stimulizing mechanism <b>120</b>, configured to detect one or more motions of a user and compute parameters of a virtual stimulus near said location as a function of said user motions;</claim-text><claim-text>d. a mixed-reality output mechanism <b>122</b>, configured receive said virtual stimulus parameters and convey to the user a superimposition of said virtual stimulus over said reactive piece;</claim-text><claim-text>e. a virtuality-reality synchronizer <b>123</b>, configured to receive said virtual stimulus and compute physical reaction parameters of said reactive piece, as a function of said virtual stimulus and said reactive-piece physical parameters;</claim-text></claim-text><claim-text>wherein said reaction mechanism is configured to receive said physical reaction parameters and to implement said reaction of said reactive piece in accordance with said reaction parameters.</claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a pieces control unit (PCU) <b>115</b>, in communicative connection with said stimulizing mechanism <b>120</b> and said reactive pieces <b>105</b>, comprising said virtuality-reality synchronizer <b>123</b>.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein said PCU is further configured to track physical statuses of said reactive pieces and report said physical statuses to a plurality of user devices comprising said tracking mechanism <b>110</b>, said stimulizing mechanism <b>120</b>, and said MR output mechanism.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein communication of said PCU to said reactive pieces is by Bluetooth and to said stimulizing mechanism is by Zigbee or 2.4 GHz RF.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein said tracking mechanism comprises a user device with a camera and processor, said system further configured for<claim-text>a. said camera to be scanned by a user, thereby acquiring images associated with said reactive pieces;</claim-text><claim-text>b. said PCU to receive said images and associate each image with an identifier;</claim-text><claim-text>c. said processor to receive said identifiers;</claim-text><claim-text>d. said processor to compute positions of said reactive pieces;</claim-text><claim-text>e. said processor to associate said identifiers with said positions.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said tracking mechanism employs AR and/or SLAM technology to compute said positions.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said racking mechanism comprises a wireless triangulation system.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said tracking mechanism recognizes a sound unique to each particular said reactive piece, wherein said sounds are either humanly audible or heard by said tracking mechanism only.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said tracking mechanism comprises detection by a said reactive piece of a sound unique to said piece, said sound generated by a user device, each said reactive piece recognizing its own unique sound, wherein said sounds are either humanly audible or heard by said reactive pieces only.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said racking mechanism comprises one or more touch sensitive surfaces disposed on said operative surface, said system further configured for<claim-text>a. a user device to receive positions of said reactive pieces from said touch sensitive surface;</claim-text><claim-text>b. said reactive pieces each possessing a unique footprint associated with one of said identifiers;</claim-text><claim-text>c. said footprints sensed by said touch sensitive surface; and</claim-text><claim-text>d. tracking locations of said reactive pieces.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said reaction mechanism comprises a magnetic dome base <b>200</b>, comprising:<claim-text>a. a dome <b>205</b> with an internal bowl;</claim-text><claim-text>b. a metal ball <b>210</b>, disposed to roll in said internal bowl; and</claim-text><claim-text>c. a plurality of controllable magnets <b>215</b>;</claim-text></claim-text><claim-text>wherein said virtuality-reality synchronizer is configured to activate controllable magnets, causing said metal ball to roll in said internal bowl thereby tiling or toppling said reactive piece.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the strengths of the magnetic fields of said controllable magnets is adjustable, and said reaction parameters comprise an adjustment of the magnitude and/or rate of change of the magnetic fields, thereby affecting the extent and/or speed of said tiling or toppling.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, whereby said reaction mechanism comprises at least four magnets, enabling said tiling or toppling along a horizontal axis selectable over 360&#xb0;.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein said stimulus parameters include position and direction of said prompting mechanism, location and orientation of a said reactive piece virtually hit by said virtual projectile.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said stimulizing mechanism<claim-text>a. comprises a gyro to detect user motion</claim-text><claim-text>b. is configured for imparting said stimulus parameters with energy, power, and/or direction.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A method for dynamic synchronization between real and virtual environments, comprising steps of<claim-text>a. acquiring the system of <claim-ref idref="CLM-00001">claim 1</claim-ref> <b>405</b>;</claim-text><claim-text>b. tracking physical parameters of one or more reactive pieces <b>410</b>;</claim-text><claim-text>c. detecting one or more motions of a user <b>415</b>;</claim-text><claim-text>d. computing parameters of a virtual stimulus, as a function of said user motions <b>420</b>;</claim-text><claim-text>e. conveying a superposition of said virtual stimulus, according to said virtual stimulus parameters, over one or more of said reactive pieces <b>425</b>;</claim-text><claim-text>f. computing parameters of a physical reaction of one or more of said reactive pieces, as a function of said virtual stimulus parameters and said reactive-piece physical parameters <b>430</b>;</claim-text></claim-text><claim-text>wherein said method further comprises steps of sending said physical reaction parameters to one or more of said reaction mechanisms <b>435</b> and implementing said physical reaction in accordance with said reaction parameters <b>440</b>.</claim-text></claim></claims></us-patent-application>
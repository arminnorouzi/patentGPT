<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004783A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004783</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17765319</doc-number><date>20201005</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>19203894.1</doc-number><date>20191017</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>0454</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>088</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">EVALUATION FRAMEWORK FOR TIME SERIES DATA</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Siemens Aktiengesellschaft</orgname><address><city>M&#xfc;nchen</city><country>DE</country></address></addressbook><residence><country>DE</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Arnout</last-name><first-name>Hiba</first-name><address><city>M&#xfc;nchen</city><country>DE</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Bronner</last-name><first-name>Johanna</first-name><address><city>M&#xfc;nchen</city><country>DE</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Runkler</last-name><first-name>Thomas</first-name><address><city>M&#xfc;nchen</city><country>DE</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Kehrer</last-name><first-name>Johannes</first-name><address><city>M&#xfc;nchen</city><country>DE</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/EP2020/077805</doc-number><date>20201005</date></document-id><us-371c12-date><date>20220330</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An evaluation framework for a generated dataset of a data generation algorithm such as a generative adversarial network is provided. The generated dataset includes a plurality of iterations of multiple instances of generated time series of data points. The evaluation framework provides multiple views. A first view includes at least one distance measure. The at least one distance measure is between the multiple instances of the generated time series and multiple instances of a reference time series, as a function of the plurality of iterations.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="101.68mm" wi="156.55mm" file="US20230004783A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="164.59mm" wi="90.51mm" file="US20230004783A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="111.25mm" wi="158.58mm" file="US20230004783A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="234.61mm" wi="154.86mm" orientation="landscape" file="US20230004783A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="227.25mm" wi="105.75mm" file="US20230004783A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="261.11mm" wi="169.25mm" orientation="landscape" file="US20230004783A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="258.06mm" wi="169.25mm" orientation="landscape" file="US20230004783A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="104.82mm" wi="93.81mm" file="US20230004783A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims priority to PCT Application No. PCT/EP2020/077805, having a filing date of Oct. 5, 2020, which claims priority to EP Application No. 19203894.1, having a filing date of Oct. 17, 2019, the entire contents both of which are hereby incorporated by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD OF TECHNOLOGY</heading><p id="p-0003" num="0002">The following relates to configuring a data generation algorithm, such as a generative adversarial network, that is configurated to generate a training dataset comprising a training time series of data points. The following specifically relates to an evaluation framework of generated time series of data points provided by the data generation algorithm</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Time-dependent information arises in many fields ranging from meteorology, medicine to stock markets. The analysis of such time series of data points is a central goal in visual analytics, statistics, or machine learning (ML) and many related approaches exist. See Aigner, W.; Miksch, S.; Muller, W.; Schumann, H.; and Tominski, C. 2008. Visual methods for analyzing time-oriented data. IEEE Transactions on Visualization and Computer Graphics 14(1):47-60. Also see Aigner, W.; Miksch, S.; Schumann, H.; and Tominski, C. 2011. Visualization of Time-Oriented Data. Springer Pub-lishing Company, Incorporated, first edition. For example, a machine learning algorithm can detect features in the time series and classify the features. Thereby, it would be possible to detect malfunctioning of machines, implement predictive maintenance, detect wear-out of machines, detect abnormal system states of a machine, etc. Various such use cases are conceivable.</p><p id="p-0005" num="0004">A machine-learning (ML) algorithm is trained based on training data. It is necessary to accurately train the ML algorithm, based on a sufficient amount of training data, as well as a balanced training dataset (i.e., each feature class is equally well represented).</p><p id="p-0006" num="0005">In reality, ML experts often face situations where these criteria are not satisfied. For example, when commissioning a new machine, a cold-start problem may occur: here, because the machine is only about to commence operation, a measurement dataset provided by the machine is not yet available for training. Transfer learning&#x2014;i.e., relying on measurement datasets from further machines, e.g., of the same type&#x2014;is not always in appropriate solution: in particular, feature classes can even vary significantly between different machines of the same type.</p><p id="p-0007" num="0006">To mitigate such problems, generating new data, i.e., generating a new training dataset, can provide a possible solution. The training dataset can be generated based on a comparable limited amount of information, i.e., a small measurement dataset of a measurement. The training dataset may not only include generated data, but also measurement data.</p><p id="p-0008" num="0007">This has pushed researchers to deeply investigate new methods for data generation. In this context, Generative Adversarial Networks (GANs)&#x2014;see Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley, D.; Ozair, S.; Courville, A.; and Bengio, Y. 2014. Generative adversarial nets. In Ghahramani, Z.; Welling, M.; Cortes, C.; Lawrence, N. D.; and Weinberger, K. Q., eds., <i>Advances in Neural Information Processing Sys</i>-<i>tems</i>27. Curran Associates, Inc. 2672-2680.&#x2014;show an outstanding performance in generating training datasets. GANs implement a data generation algorithm to provide generated training datasets (sometimes also referred to as artificial training datasets).</p><p id="p-0009" num="0008">However, to trust an ML algorithm which was trained on a generated training dataset, it is typically desirable to assess how realistic the generated training dataset is; in other words, the performance of the data generation algorithm should be evaluated.</p><p id="p-0010" num="0009">Most efforts and best results have been shown for image generation, where the quality of the generated training dataset can be easily assessed with the human eye. This is because the human brain is capable to intuitively detect abnormalities in visualized 2-D images.</p><p id="p-0011" num="0010">However, while human-understandable 2D images can be evaluated by an experienced ML expert, this becomes more difficult for technical data, in particular, technical time series of data points. For example, it is often difficult for a human to detect abnormalities in a time series of data points indicating a pressure distribution in a turbine or an electrocardiogram of a patient, or other medical or industrial or generally technical data. Such time series in many cases cannot be interpreted intuitively.</p><p id="p-0012" num="0011">On the other hand, it has been shown that, in principle, data generation algorithms are also available for generating time series of data points. See C Esteban, S L Hyland, G. R. 2017. Real-valued (medical) time series generation with recurrent conditional gans. In <i>arXiv preprint arXiv: </i>1706.02633.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0013" num="0012">Accordingly, an aspect relates to advanced techniques of generating datasets including time series of data points. In particular, a need exists for advanced techniques of configuring a data generation algorithm to generate the time-series training datasets. As the generated dataset is used as training dataset to train a ML algorithm, there is a need to assess how realistic the generated training dataset is related to available real datasets.</p><p id="p-0014" num="0013">The techniques described herein generally solve this problem by providing an evaluation framework for assessing the quality of generated training datasets including time series of data points.</p><p id="p-0015" num="0014">The evaluation framework can include a workflow for visual analytics (VA) of the generated time series of data points obtained from a data generation algorithm. Such workflow provides human-machine interaction to guide an user in the evaluation of training datasets and enabling the user to select the appropriate configuration of the data generation algorithm. The workflow makes real and generated time series of data points comparable by combining VA with algorithmic methods. Thereby, the techniques enable the user to trust the GAN configuration.</p><p id="p-0016" num="0015">The evaluation framework can generally include one or more views. The various views can have a different level of abstraction or dimensionality reduction. For example, a first view (labeled iteration view, hereinafter) can include one or more plots that show, as a function the iteration, at least one distance measure between the generated time series of data points and the reference time series of data points.</p><p id="p-0017" num="0016">As a general rule, different iterations correspond to different configurations of the GANs. For example, different configurations can correspond to different parameter values of parameters of the configuration.</p><p id="p-0018" num="0017">Thus, the iteration view corresponds to an overview visualization at a high level of abstraction that helps the user to identify interesting iterations of the GAN generation process.</p><p id="p-0019" num="0018">A second view (labeled instance view, hereinafter) can include, for a selected one of the iterations or for multiple selected iterations of the plurality of iterations, a plot of multiple instances of the generated time series of data points using the configuration at that iteration.</p><p id="p-0020" num="0019">As a general rule, the various instances can correspond to the outputs of the data generation algorithm at the respective configuration of the respective iteration, using different seed values (e.g., different instantiation noise).</p><p id="p-0021" num="0020">The instance view, hence, enables a detailed comparison where the time series are visualized in a compact manner, at lower level of abstraction/higher level of detail.</p><p id="p-0022" num="0021">As a general rule, the instances of the time series may be ordered using, e.g., Principal Components Analysis (PCA), to facilitate comparison by juxtaposition.</p><p id="p-0023" num="0022">A method of configuring a data generation algorithm for generating a generated dataset. The generated dataset includes a time series of data points. The method includes obtaining multiple instances of a reference time series of data points. The method also includes iteratively adjusting a configuration of the data generation algorithm, based on the multiple instances of the reference time series. The method also includes executing the data generation algorithm with the respectively adjusted configuration, to thereby obtain a plurality of iterations of multiple instances of a generated time series of data points. The method further includes outputting, to a human-machine-interface, a first view of at least one distance measure. The at least one distance measure is between the multiple instances of the reference time series and the multiple instances of the generated time series. The first view provides the at least one distance measure as a function of the plurality of iterations. The method further includes obtaining, from the human-machine-interface, a user input indicative of a selected iteration of the plurality of iterations.</p><p id="p-0024" num="0023">Further the at least one distance measure comprises a first distance measure which is based on nearest-neighbor distances of each of the multiple instances of the generated time series to the multiple instances of the reference time series.</p><p id="p-0025" num="0024">It is also possible that the at least one distance measure comprises a second distance measure which is based on nearest-neighbor distances of each of the multiple instances of the reference time series to the multiple instances of the generated time series.</p><p id="p-0026" num="0025">The first view may comprise a first plot of the first distance measure and may further comprise a second plot of the second distance measure. The first plot and the second plot may have a common axis associated with the plurality of iterations.</p><p id="p-0027" num="0026">The first plot and the second plot of the first view may include 2-D heatmap plots for the first distance measure and the second distance measure as a function of the plurality of iterations and a function of the multiple iterations.</p><p id="p-0028" num="0027">The at least one distance measure may comprise a first distance measure indicative of a similarity between time-domain shapes of the data points of the generated time series with respect to the reference time series.</p><p id="p-0029" num="0028">The at least one distance measure may comprise a second distance measure indicative of a variation strength of time-domain shapes of the data points of the generated time series with respect to the reference time series.</p><p id="p-0030" num="0029">It is possible that the first view comprises at least one plot showing the at least one distance measure for each one of the multiple instances of the reference time series and/or the generated time series.</p><p id="p-0031" num="0030">The method may further include: outputting, to the human-machine-interface, a second view comprising an amplitude or phase of the multiple instances of the generated time series for the selected iteration of the plurality of iterations.</p><p id="p-0032" num="0031">The second view may comprise a first plot in which the amplitude or phase of the multiple instances of the reference time series is shown. The second view may comprise a second plot in which the amplitude or phase of the multiple instances of the generated time series is shown for the selected iteration of the plurality of iterations. The first plot and the second plot may share a common axis for the multiple instances.</p><p id="p-0033" num="0032">The plot of the second view may comprise 2-D heatmaps for the amplitude or phase of the selected iteration of the plurality of iterations of the generated time series and of the reference time series, as a function of the multiple iterations and as a function of time.</p><p id="p-0034" num="0033">The method may further comprise: obtaining, from the human-machine-interface, a further user input indicative of a selected instance of the multiple instances of the selected iteration of the plurality of iterations, and outputting, to the human-machine-interface, a third view indicative of the amplitude or phase of the selected instance of the multiple instances of the selected iteration of the plurality of iterations, as a function of time.</p><p id="p-0035" num="0034">The third view may comprise at least one line plot of the amplitude or phase of the selected instance of the multiple instances of the selected iteration of the plurality of iterations. The line plot may comprise a statistical reference of the amplitude or phase of the multiple instances of the reference time series.</p><p id="p-0036" num="0035">The method may further comprise: sorting at least one of the multiple instances of the reference time series or the generated time series.</p><p id="p-0037" num="0036">It is possible that said sorting is based on at least one of a further user input, the at least one distance measure, or a principle component analysis of the data points of each one of the multiple instances of the at least one of the reference time series or the generated time series.</p><p id="p-0038" num="0037">The method may further comprise, based on the user input, configuring at least one of the data generation algorithm or a training process of the data generation algorithm.</p><p id="p-0039" num="0038">The method may further comprise: based on the user input, adjusting a parameter space sampling scheme of the configuration of the data generation algorithm during a training process of the data generation algorithm.</p><p id="p-0040" num="0039">It is possible that the generated dataset is for training a machine-learning algorithm. The method may further comprise: executing the data generation algorithm based on the user input, to thereby obtain the generated dataset, and training the machine-learning algorithm using the generated dataset.</p><p id="p-0041" num="0040">The method may further comprise: using the trained machine-learning algorithm to recognize features in sensor data.</p><p id="p-0042" num="0041">It is possible that the data generation algorithm comprises a generative adversarial network comprising a generator and a discriminator.</p><p id="p-0043" num="0042">A computer program or a computer-program product (non-transitory computer readable storage medium having instructions, which when executed by a processor, perform actions) or a computer-readable storage medium includes program code. The program code can be executed by at least one processor. Executing the program code causes the at least one processor to perform a method of configuring a data generation algorithm for generating a generated dataset for a machine-learning algorithm. The generated dataset includes a time series of data points. The method includes obtaining multiple instances of a reference time series of data points. The method also includes iteratively adjusting a configuration of the data generation algorithm, based on the multiple instances of the reference time series. The method also includes executing the data generation algorithm with the respectively adjusted configuration, to thereby obtain a plurality of iterations of multiple instances of a generated time series of data points. The method further includes outputting, to a human-machine-interface, a first view of at least one distance measure. The at least one distance measure is between the multiple instances of the reference time series and the multiple instances of the generated time series. The first view provides the at least one distance measure as a function of the plurality of iterations. The method further includes obtaining, from the human-machine-interface, a user input indicative of a selected iteration of the plurality of iterations.</p><p id="p-0044" num="0043">A device includes program code. The program code can be executed by at least one processor. Executing the program code causes the at least one processor to perform a method of configuring a data generation algorithm for generating a generated dataset for a machine-learning algorithm. The generated dataset includes a generated time series of data points. The method includes obtaining multiple instances of a reference time series of data points. The method also includes iteratively adjusting a configuration of the data generation algorithm, based on the multiple instances of the reference time series. The method also includes executing the data generation algorithm with the respectively adjusted configuration, to thereby obtain a plurality of iterations of multiple instances of a generated time series of data points. The method further includes outputting, to a human-machine-interface, a first view of at least one distance measure. The at least one distance measure is between the multiple instances of the reference time series and the multiple instances of the generated time series. The first view provides the at least one distance measure as a function of the plurality of iterations. The method further includes obtaining, from the human-machine-interface, a user input indicative of a selected iteration of the plurality of iterations. Furtheron the at least one distance measure comprises a first distance measure which is based on nearest-neighbor distances of each of the multiple instances of the generated time series to the multiple instances of the reference time series.</p><p id="p-0045" num="0044">It is to be understood that the features mentioned above and those yet to be explained below may be used not only in the respective combinations indicated, but also in other combinations or in isolation without departing from the scope of embodiments of the invention.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION</heading><p id="p-0046" num="0045">Some of the embodiments will be described in detail, with reference to the following figures, wherein like designations denote like members, wherein:</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a flowchart of a method according to various examples;</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>2</b></figref> schematically illustrates a workflow including an evaluation framework according to various examples;</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>3</b></figref> schematically illustrates a GAN according to various examples;</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of a method according to various examples;</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>5</b></figref> schematically illustrates multiple views of an evaluation framework according to various examples;</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>6</b></figref> schematically illustrates multiple views of an evaluation framework according to various examples; and</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>7</b></figref> schematically illustrates a device according to various examples.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0054" num="0053">Some examples of the present disclosure generally provide for a plurality of circuits or other electrical devices. All references to the circuits and other electrical devices and the functionality provided by each are not intended to be limited to encompassing only what is illustrated and described herein. While particular labels may be assigned to the various circuits or other electrical devices disclosed, such labels are not intended to limit the scope of operation for the circuits and the other electrical devices. Such circuits and other electrical devices may be combined with each other and/or separated in any manner based on the particular type of electrical implementation that is desired. It is recognized that any circuit or other electrical device disclosed herein may include any number of microcontrollers, a graphics processor unit (GPU), integrated circuits, memory devices (e.g., FLASH, random access memory (RAM), read only memory (ROM), electrically programmable read only memory (EPROM), electrically erasable programmable read only memory (EEPROM), or other suitable variants thereof), and software which co-act with one another to perform operation(s) disclosed herein. In addition, any one or more of the electrical devices may be configured to execute a program code that is embodied in a non-transitory computer readable medium programmed to perform any number of the functions as disclosed.</p><p id="p-0055" num="0054">In the following, embodiments of the invention will be described in detail with reference to the accompanying drawings. It is to be understood that the following description of embodiments is not to be taken in a limiting sense. The scope of embodiments of the invention is not intended to be limited by the embodiments described hereinafter or by the drawings, which are taken to be illustrative only.</p><p id="p-0056" num="0055">The drawings are to be regarded as being schematic representations and elements illustrated in the drawings are not necessarily shown to scale. Rather, the various elements are represented such that their function and general purpose become apparent to a person skilled in the art. Any connection or coupling between functional blocks, devices, components, or other physical or functional units shown in the drawings or described herein may also be implemented by an indirect connection or coupling. A coupling between components may also be established over a wireless connection. Functional blocks may be implemented in hardware, firmware, software, or a combination thereof.</p><p id="p-0057" num="0056">Hereinafter, techniques are described that facilitate finding an appropriate configuration for a data generation algorithm.</p><p id="p-0058" num="0057">The techniques can be used to assess a result of a data generation algorithm training process; alternatively or additionally, the techniques can be used during the data generation algorithm training process, and it is possible to configure the data generation algorithm training process based on the techniques described herein to thereby find the appropriate configuration.</p><p id="p-0059" num="0058">The data generation algorithm can generate a generated dataset. The data generation algorithm may do so based on a reference dataset that can include measurement data. In the various examples described herein, the datasets include multiple instances of a time series of data points. I.e., time-resolved data is considered.</p><p id="p-0060" num="0059">As a general rule, various options are available for using the generated dataset. In one example, the generated dataset implements a training dataset for training an ML algorithm. Another example would relate to the generated dataset implementing a test dataset. The test dataset can be used to test, e.g., functionality of an integrated circuit. Hereinafter, various examples are described with respect to the generated dataset implementing a training dataset, for sake of simplicity. The training dataset is for training an ML algorithm. However, similar techniques can be readily applied for different purposes of the generated dataset.</p><p id="p-0061" num="0060">As a general rule, various options exist for implementing the data generation algorithm. An example implementation is a GAN including a generator and a discriminator. Hereinafter, for sake of simplicity, various examples will be described in connection with configuring the GAN; however, respective techniques may be readily applied to other kinds and types of data generation algorithms. There are different types of GANs available, e.g., CGAN, InfoGAN, etc. An alternative implementation may use a Variational Autoencoder (VAE).</p><p id="p-0062" num="0061">As a general rule, configuring GAN can include determining a configuration of the generator of the GAN and/or of the discriminator of the GAN. For example, one or more parameter values of parameters of the configuration of the GAN can be set. For example, it would be possible to set hyperparameter values of hyperparameters of the configuration of the GAN. Example hyperparameters include: type of noise; number of layers of the generator; number of layers of the discriminator; hyperparameters of the generator; hyperparameters of the discriminator; etc.</p><p id="p-0063" num="0062">As a general rule, there can be various objectives that influence whether the configuration of the GAN is appropriate. For example, an appropriate configuration may be a configuration that enables to generate a training dataset including multiple instances of a time series of data points for accurately training an ML algorithm. In such a scenario, the generated time series should mimic reference time series of a reference dataset (e.g., real measurement data, etc.) accurately.</p><p id="p-0064" num="0063">Various techniques are based on the finding that generated time series of data points typically mimic reference time series of data points if, at least, two criteria are fulfilled: (i) A time-domain shape of the data points of the generated time series should be exhibiting a strong similarity with the time-domain shape of the reference time series. I.e., the time-domain evolution of amplitude and/or phase of the data points should be similar for the generated time series and the reference time series. (ii) A variation strength of the time-domain shapes of the data points of the generated time series should be approximately equal to the variation strength of the time-domain shapes of the data points of the reference time series. This is to avoid a problem sometimes referred to as &#x201c;mode collapse&#x201d;: here, multiple feature classes included in the reference dataset may not be appropriately reflected in the generated dataset obtained from the GAN. For instance, a given one of the different feature classes may be overrepresented. Then, the variation strength of the time-domain shapes of the data points of the multiple instances of the generated time series may be smaller than the variation strength of the time-domain shapes of the data points of the multiple instances of the reference time series. This is because not all required time-domain shapes are included in the generated dataset.</p><p id="p-0065" num="0064">The techniques described herein can be generally used to evaluate the performance of a GAN or a training process of the GAN. Various techniques described herein provide an evaluation framework that enable to accurately assess whether the multiple instances of the generated time series of data points appropriately mimics the multiple instances of the reference time series of data points, e.g., taking into account the above-identified criteria (i) and (ii). The techniques described herein facilitate a fast and reliable evaluation by a user. In the techniques described herein it is typically not required that the user has specific domain knowledge of the particular use case/information content included in the time series of data points. Rather, the evaluation framework facilitates an analysis of the generated dataset based on statistical figures of merits and, as such, is widely applicable across various use cases.</p><p id="p-0066" num="0065">The techniques can find application in various use cases. In particular, the information content of the datasets can vary. For instance, the datasets could include time series of medical measurement data points such as electrocardiograms, blood-flow data, etc; another example includes speech measurement data points, e.g., voice recordings; another example includes industry measurement data points such as flow measurements in turbines or windparks or engines, data points of an acceleration or position sensor, e.g., of trains, subways, airplanes, temperature data points, e.g., for electrical power transmission equipment, pressure data points, e.g., for subsea equipment, and so forth. As will be appreciated, as a general rule, the datasets can capture a time-domain dynamics of a physical or technical or physiological process.</p><p id="p-0067" num="0066">As a general rule, the GAN training process can have a plurality of iterations. For each iteration of the plurality of iterations, the parameter values of parameters of a configuration of the GAN are varied. Then, based on multiple instances of a reference time series of data points, the GAN can be executed with the respectively adjusted configuration. Per iteration, the GAN outputs multiple instances of the time series of data points. As a result of the GAN training process, a plurality of iterations of multiple instances of a generated time series of data points can be obtained. Thus, there are, firstly, multiple iterations, and, secondly, each iteration has multiple instances of the time series of data points. For example, different instances of the reference time series can be associated with different seed values for the operation of the GAN, e.g., noise having a random contribution that is provided as an input to the generator. It has been found that it is difficult to evaluate such a large amount of data.</p><p id="p-0068" num="0067">The techniques described herein help to achieve the following goals:</p><p id="p-0069" num="0068">Goal 1: Find iterations of the GAN training process where an appropriate behavior is achieved, i.e., the iterations showing a sufficient quality of the multiple instances of the generated time series. For example, this enables to check if the number of iterations of the training process is sufficient, or whether a higher number of iterations is needed.</p><p id="p-0070" num="0069">Goal 2: Compare the performance of different GAN configurations&#x2014;e.g., having different configurations for the generator and/or the discriminator, or having different hyperparameter values&#x2014;and support the user in the decision making process to either trust or reject a given configuration. Hence, the user should be able to identify which GAN configuration is appropriate for the task.</p><p id="p-0071" num="0070">Goal 3: Present an adequate workflow to visually evaluate the quality of the multiple instances generated time series of data points, for the plurality of iterations. I.e., detect if the multiple instances of the generated time series are noisy or show a different behavior compared to the multiple instances of the reference time series. Users should be able to decide whether the multiple instances of the generated time series of data points generated by the GAN are realistic.</p><p id="p-0072" num="0071">Goal 4: Detect common GAN training problems such as non-convergence or mode collapse. Mode collapse describes a scenario in which the generator collapses to one mode (i.e., one feature class) and is not able to produce diverse samples. The techniques described herein offer the possibility to identify mode collapse. Once the mode collapse is detected, the user can use existing techniques to improve the performance of the considered GAN model, e.g., Salimans, T.; Goodfellow, I.; Zaremba, W.; Cheung, V.; Radford, A.; Chen, X.; and Chen, X. 2016. Improved techniques for training gans. In Lee, D. D.; Sugiyama, M.; Luxburg, U. V.; Guyon, I.; and Garnett, R., eds., <i>Advances in Neural Information Processing Systems </i>29. Curran Associates, Inc. 2234-2242.</p><p id="p-0073" num="0072">According to examples, this is achieved by outputting, to a human-machine-interface (HMI), one or more views. Each view can include one or more plots.</p><p id="p-0074" num="0073">A first view includes at least one distance measure between the multiple instances of the reference time series and the multiple instances of the generated time series, as a function of the plurality of iterations of the training process.</p><p id="p-0075" num="0074">For instance, heatmap plots could be used in which color/contrast is used to encode the value of the distance measure; thereby, the distance measure can be shown for each instance. Another option would be a line plot that encodes a distance measure averaged or otherwise condensed across the instances.</p><p id="p-0076" num="0075">By using the first view that illustrates the at least one distance measure as a function of the plurality of iterations, a high-level overview of the performance of the GAN can be provided.</p><p id="p-0077" num="0076">Then, it is possible to obtain, from the HMI, a user input indicative of a selected iteration of the plurality of iterations. Based on this user input, a further view can be configured.</p><p id="p-0078" num="0077">The evaluation framework is not limited to the first view. In particular, as part of a continued interaction between the user and the HMI, one or more further views can be activated.</p><p id="p-0079" num="0078">For instance, a second view can include amplitude and/or phase as a function of the multiple instances of a selected one of the plurality of iterations.</p><p id="p-0080" num="0079">The selected one of the plurality of iterations can be obtained from a user input that is made based on the first view.</p><p id="p-0081" num="0080">By using the second view that illustrates the multiple instances of the time series of data points for a selected iteration (i.e., does not show details with respect to the non-selected iterations), a closer inspection of the time-domain shapes of the data points of the generated time series can be made.</p><p id="p-0082" num="0081">The evaluation framework could include a third view that illustrates the amplitude and/or phase of a selected instance of a selected iteration, as a function of time. For example, the third view can include a respective line plot of the amplitude or phase. Again, the selected instance may be determined based on a user input indicative thereof that is made based on the second view.</p><p id="p-0083" num="0082">As will be appreciated from the above, multiple views can be provided, wherein the multiple views correspond to different levels of abstraction. For example, the first view can provide a general overview of the behavior of the training process, while the second and third views can provide a higher level of detail.</p><p id="p-0084" num="0083">As will be further appreciated from the above, the user can navigate through the multiple views by selecting iterations or selecting instances of interest. Such continued user-machine-interaction can make the large amount of data processable and accessible for evaluation.</p><p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a flowchart of a method according to various examples.</p><p id="p-0086" num="0085">At box <b>1001</b>, a training process of a GAN is executed. The training process can include a plurality of iterations. For each iteration of the plurality of iterations, the GAN is executed with a respective configuration. In other words, the configuration of the GAN is iteratively adjusted, e.g., a configuration of the generator and/or a configuration of the discriminator of the GAN.</p><p id="p-0087" num="0086">In particular, parameter values of the parameters of the generator and/or the discriminator can be altered. For example, backpropagation can be used, along with gradient descent, to sample the parameter space of the parameter values of the generator and the discriminator. For example, weights of the respective neural networks may be adjusted as parameter values.</p><p id="p-0088" num="0087">The execution of the GAN is based on multiple instances of a reference time series of data points, also obtained as part of box <b>1001</b>. For example, the reference time series of data points can be obtained from a measurement.</p><p id="p-0089" num="0088">Thereby, a generated dataset including, for each of the plurality of iterations, multiple instances of a generated time series of data points is obtained, at box <b>1002</b>. The generated dataset is a candidate for a training dataset of a ML algorithm</p><p id="p-0090" num="0089">At box <b>1003</b>, an evaluation of the performance of the GAN is performed. Box <b>1003</b> includes outputting, to an HMI, one or more views of an evaluation framework. The performance of the GAN is evaluation in view of the training process. In other words, the performance of the GAN can be evaluated for the different configurations associated with the plurality of iterations of the training process.</p><p id="p-0091" num="0090">The first view includes at least one distance measure between the multiple instances of the reference time series and the multiple instances of the generated time series, as a function of the plurality of iterations.</p><p id="p-0092" num="0091">Based on the first view, it is then possible to obtain a user input indicative of a selected iteration of the plurality of iterations.</p><p id="p-0093" num="0092">Based on such user input, it is then possible, at box <b>1004</b>, to configure the GAN and/or the training process of the generative adversarial network.</p><p id="p-0094" num="0093">As a general rule, there are various options available for implementing such configuration. For instance, the configuration of the GAN associated with the selected iteration of the plurality of iterations can be used to then determine a training dataset. Alternatively or additionally, it would be possible to adjust the configuration of the GAN, by appropriately configuring the training process of the GAN. In such case, it would be possible that box <b>1001</b>-box <b>1003</b> are re-executed, using the adjusted configuration of the training process. For instance, a parameter space sampling scheme of the configuration of the GAN during the training process can be adjusted based on the user input (e.g., deviating from gradient descent). Thereby, an appropriate configuration can be quickly found, because the parameter space of available configurations is efficiently sampled, towards an optimum. Yet another option would be associated with adjusting a hyperparameter value of a hyperparameter of the GAN, e.g., a number of layers of the discriminator and/or the generator, a type of noise considered, etc.</p><p id="p-0095" num="0094">Then, at box <b>1005</b>, the GAN can be executed, in accordance with the configuration of box <b>1004</b>, i.e., based on the user input. Thereby, the training dataset is obtained and, at box <b>1005</b>, the ML algorithm can be trained based on the training dataset.</p><p id="p-0096" num="0095">Then, at box <b>1006</b>, it is possible to recognize features based on the respectively trained ML algorithm. The features can be recognized in sensor data, e.g., from a machine, a medical equipment, surveillance equipment, etc.</p><p id="p-0097" num="0096">Based on the techniques described herein, it is possible to accurately train the ML algorithm such that the features can be accurately recognized in the sensor data.</p><p id="p-0098" num="0097">As will be appreciated from the above, box <b>1003</b> provides an evaluation framework for the performance of the GAN. Details with respect to the evaluation framework and a workflow associated there with are described next in connection with <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0099" num="0098"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic illustration of a workflow facilitating and evaluation of the performance of a GAN. The workflow includes the execution of an evaluation framework <b>104</b>.</p><p id="p-0100" num="0099">At <b>1011</b>, a reference dataset is obtained; i.e., multiple instances of a reference time series <b>101</b> are obtained. The multiple instances of the reference time series <b>101</b> are provided as an input to a GAN <b>102</b>.</p><p id="p-0101" num="0100">At <b>1012</b>, the training process of the GAN is executed (cf. <figref idref="DRAWINGS">FIG. <b>1</b></figref>: box <b>1001</b>). Accordingly, the GAN <b>102</b> outputs a plurality of iterations, each iteration including multiple instances of a generated times series <b>103</b> of data points.</p><p id="p-0102" num="0101">An evaluation framework <b>104</b> enables the evaluation of the performance of the GAN <b>102</b>. For this, the plurality of iterations of the multiple instances of the generated time series <b>103</b> are provided to the evaluation framework <b>104</b> at <b>1013</b>. At <b>1017</b>, the multiple instances of the reference time series are provided to the evaluation framework.</p><p id="p-0103" num="0102">The evaluation framework <b>104</b> provides, at <b>1014</b>, one or more views to a user <b>105</b>; and obtains, at <b>1015</b>, one or more user inputs from the user <b>105</b>.</p><p id="p-0104" num="0103">The user <b>105</b> may interact with the evaluation framework to get further insight about the data and their properties. After a rigorous exploration of the data, he or she can decide to terminate the training process if the desired behavior is achieved; a respective configuration of the GAN can be selected. Otherwise, he or she can adjust the configuration of the GAN. The configuration of the GAN <b>102</b> is adjusted or set based on a feedback, provided by the evaluation framework at <b>1016</b>.</p><p id="p-0105" num="0104">An example implementation of the workflow of <figref idref="DRAWINGS">FIG. <b>2</b></figref> is given next: The user <b>105</b> starts the process by executing the GAN <b>102</b>, to generate a plurality of iterations, each iteration including multiple instances of the generated time series <b>103</b>. The evaluation framework <b>104</b> is then used to check whether the GAN configuration and the generated time series fulfill the desired requirements, e.g., at least for one of the plurality of iterations. If this is the case, the user <b>105</b> has succeeded to generate realistic time series and can stop the configuration process. The training dataset can be generated using the respective configuration. Otherwise he or she can re-execute the GAN <b>102</b> with a different configuration&#x2014;e.g., adjusted parameter values or hyperparameter values&#x2014;and repeat the investigations using the evaluation framework <b>104</b>. It should be noted that an online evaluation is possible, i.e. the evaluation framework <b>104</b> can be used during the training process, e.g., by configuring the training process. As the training process can take up to several days, such approach may help to save valuable time by making sure during the training process that the variation of the parameter values of the configuration of the GAN <b>102</b> is going in the right direction or restart the training process if an unexpected behavior is detected.</p><p id="p-0106" num="0105"><figref idref="DRAWINGS">FIG. <b>3</b></figref> schematically illustrates aspects with respect to the GAN <b>102</b>. The GAN <b>102</b> includes the generator <b>121</b> and the discriminator <b>122</b>. The discriminator obtains, as an input, the multiple instances of the reference time series <b>101</b>. The generator <b>121</b> obtains, as an input, noise <b>109</b>. The generator <b>121</b> outputs the multiple instances of the generated time series <b>103</b> of data points. These are compared, at the discriminator <b>122</b> to the multiple instances of the reference time series <b>101</b>. The output of the discriminator <b>122</b> is an indication <b>123</b> whether the generated time series <b>103</b> can be distinguished from the reference time series <b>101</b>.</p><p id="p-0107" num="0106">A GAN can be briefly described as a minimax game between two neural networks, i.e., the generator and the discriminator. The discriminator is typically a binary classifier that tries to maximize its log-likelihood to learn to perfectly distinguish between the real and the generated data. At the same time, the generator is typically trying to minimize the log-probability of the generated samples that are recognized as false. The configuration of the generator <b>121</b> and the discriminator <b>122</b> is accordingly adjusted in accordance with the respective losses across the plurality of iterations.</p><p id="p-0108" num="0107">A challenge is to decide if the data produced by generator <b>121</b> sufficiently represent the original reference dataset. Much efforts are made by researchers to discover suitable metrics to evaluate the performance of GAN and can substitute a human judge. The discriminator <b>122</b> and generator <b>121</b> losses, for example, cannot be considered as a measure of GAN performance and this ML approach lacks an objective function that defines an appropriate end of iteration with suitable data quality. Various evaluation methods have been described in Theis, L.; van den Oord, A.; and Bethge, M. 2016. A note on the evaluation of generative models. In <i>International Conference on Learning Representations</i>, such as Parzen window or Maximum Mean Discrepancy (MMD). As proven in id., the use of these methods has various disadvantages. Other methods i.e. inception score are designed only for images and cannot be easily applied to datasets including time series of data points. Therefore, the quality of the generated data must be visually assessed by a human judge, see C Esteban, S L Hyland, G. R. 2017. Real-valued (medical) time series generation with recurrent conditional GANs. In <i>arXiv preprint arXiv: </i>1706.02633.</p><p id="p-0109" num="0108"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of a method according to various examples. The method of <figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example implementation of the execution of the evaluation framework <b>104</b>, i.e., an example implementation of box <b>1003</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0110" num="0109"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a method including continued interaction between a user and the machine in order to evaluate the quality of multiple instances of a generated time series.</p><p id="p-0111" num="0110">The evaluation framework <b>104</b> provides multiple views. Based on the multiple views, user inputs are received. Based on the user inputs, it is possible to navigate between the multiple views. Furthermore, based on the user inputs, it is possible to configure the GAN <b>102</b> and/or a training process of the GAN <b>102</b>.</p><p id="p-0112" num="0111">At box <b>1021</b>, a first view is output. The first view can be labeled iteration view. The first view includes one or more plots that indicate at least one distance measure between multiple instances of the reference time series <b>101</b> in multiple instances of the generated time series <b>103</b>, as a function of the iteration. For example, different plots can illustrate different distance measures. The multiple plots can share an axis associated with the plurality of iterations.</p><p id="p-0113" num="0112">At box <b>1022</b>, a user input is received that is indicative of a selected iteration of the plurality of iterations, based on the first view.</p><p id="p-0114" num="0113">Then, at box <b>1023</b>, a second view is output. The second view may be labeled instance view. Here, the one or more plots of the second view include at least an amplitude or phase of the multiple instances of the generated time series <b>103</b> for the selected iteration of box <b>1022</b>, e.g., as a function of time. Alternatively or additionally, the instance view can include the multiple instances of the reference time series <b>101</b>.</p><p id="p-0115" num="0114">Then, it is possible to obtain, at box <b>1024</b>, a further user input that is indicative of a selected instance, based on the second view.</p><p id="p-0116" num="0115">At box <b>1025</b>, it is then possible to output a third view&#x2014;e.g., labeled selected sample view&#x2014;that is indicative of the data points of the selected instance of the generated time series (for the selected iteration of the plurality iterations), as indicated by the further user input of box <b>1024</b>. The third view may include a line plot of the amplitude or phase of the selected instance, as a function of time.</p><p id="p-0117" num="0116">At box <b>1026</b>, it is then checked whether a further user input is received. The user may navigate back-and-forth between the views, as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, by means of the further user input.</p><p id="p-0118" num="0117">Otherwise, at box <b>1027</b>, the GAN <b>102</b> and/or the respective training process is configured, based on the previous user inputs.</p><p id="p-0119" num="0118">Next, in connection with <figref idref="DRAWINGS">FIG. <b>5</b></figref> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, details with respect to the various views are explained.</p><p id="p-0120" num="0119"><figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref> schematically illustrate plots of multiple views provided by the evaluation framework <b>104</b> (cf. <figref idref="DRAWINGS">FIG. <b>2</b></figref>).</p><p id="p-0121" num="0120"><figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref> correspond to each other, but the illustrated data is different; this is because a different configuration of GANs is used in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref>, as will be explained in further detail below.</p><p id="p-0122" num="0121"><figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrate a first view <b>391</b> (upper part in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref>), the iteration view. The iteration view <b>391</b> that includes two plots <b>301</b>, <b>302</b>. The two plots <b>301</b>, <b>302</b> share a common axis <b>312</b> that is associated with the plurality of iterations.</p><p id="p-0123" num="0122">The iteration view <b>391</b> shows at least one distance measure as a function of the iteration.</p><p id="p-0124" num="0123">The iteration view <b>391</b> gives the user a general impression about the behavior of GAN as a function of the iterations of the training process.</p><p id="p-0125" num="0124">The user can interactively select interesting iterations in the first view <b>391</b> and get more insights about the selected iterations in further views <b>392</b>, <b>393</b>. This will permit the user to identify the iteration with the best behavior.</p><p id="p-0126" num="0125">A second view <b>392</b> (middle part of <figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref>), the instance view, comprises two plots <b>321</b>, <b>322</b> (note that the plot <b>322</b> is provided multiple times). The plots <b>321</b>, <b>322</b> share an axis <b>311</b> that is associated with the multiple instances. The plots <b>321</b>, <b>322</b>, <b>331</b>, <b>332</b> is provided</p><p id="p-0127" num="0126">A third view <b>393</b> (lower part and right side of <figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref>)&#x2014;the selected sample view&#x2014;includes multiple plots <b>333</b>-<b>334</b> to further investigate time series at particular iterations and instances selected by the user. The multiple plots <b>333</b>-<b>334</b> share a common axis <b>313</b> that is associated with time.</p><p id="p-0128" num="0127">The plots <b>321</b>-<b>322</b> of the instance view <b>392</b> display the data points of all instances of the time series (plot <b>321</b>: reference time series; plot <b>322</b>: generated time series) at a certain iteration, respectively (in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the plot <b>322</b> is respectively shown for iterations 40, 198, 382, 614, 769, 899, and 978, respectively; as illustrated by the arrows; these iterations are also highlighted in the plots <b>301</b>, <b>302</b> of the iteration view <b>391</b>).</p><p id="p-0129" num="0128">A 2-D heatmap is used for the plots <b>321</b>, <b>322</b>. The 2-D heatmap encodes, as contrast or color, the amplitude of the data points as a function of instance along axis <b>311</b> and as a function of time along axis <b>313</b>.</p><p id="p-0130" num="0129">Note that two 2-D heatmaps are shown with a shared axis <b>311</b> for instance and with a shared axis <b>313</b> for time. This makes it possible to compare the generated time series <b>103</b> vis-&#xe0;-vis the reference time series <b>101</b>. The plots <b>321</b>, <b>322</b> of the instance view <b>392</b> allow investigation and exploration of the multiple instances of the generated time series <b>103</b> at a certain iteration and compares them to the multiple instances of the reference time series <b>101</b>.</p><p id="p-0131" num="0130">The plots <b>331</b>-<b>332</b> illustrate a time-dependent distribution of the amplitude and/or phase data points for a respective iteration. The plots <b>331</b>-<b>332</b> are sometimes labeled time-histogram views, as the show the variation of the data points for a given iteration. As can be seen from <figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the amplitude and/or phase of the data points spreads out; this is consistent with the assumption that different feature classes are represented by the multiple instances.</p><p id="p-0132" num="0131">The instance view <b>392</b> is used to depict the data points across multiple instances of the time series for a given iteration and enable a detailed and rigorous exploration of the generated time series and their properties. Each 2-D heatmap represents all the data of a specific iteration where each row corresponds to a specific instance of the time series. This visualization permits the user to compare a high number of time series in an efficient manner.</p><p id="p-0133" num="0132">The user can investigate different iterations at the same time, as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref> (multiple plots <b>322</b>, <b>332</b> are included in the view <b>392</b>).</p><p id="p-0134" num="0133">The time series of a given instance selected in the instance view <b>392</b> can then be visualized as line plots <b>333</b>-<b>334</b> of the selected sample view <b>393</b>. The line plots <b>333</b>-<b>334</b> show the time-domain evolution of the amplitude and/or phase of the data points of a given instance of a reference time series and/or a generated time series; and optionally a statistical reference (e.g., a median or average or a percentile taken across all time series of a kind). In plot <b>333</b>, the amplitude and/or phase are illustrated for the instances highlighted in the plots <b>322</b> using a square bracket (light full line; bold full line; dotted line). The plots <b>333</b> and <b>334</b> of the selected sample view <b>393</b> also include a statistical reference of the amplitude of phase of the multiple instances of the reference time series <b>101</b> (e.g., percentiles; dashed areas). The plot <b>334</b> shows a difference between the data points of a given instance of the generated time series and this statistical reference. A rigorous investigation of some selected time series is made possible with the selected sample view <b>393</b>. To give the user some insights about the reference time series, the plot <b>333</b> depicts the median of the instances of the reference time series and the amount of data falling in the 68th, 95th and 99.7th percentile. The user may add further instances of the reference or generated time series at different iterations, to compare them. The plot <b>334</b> highlights the element-wise difference between the selected instance of the generated time series and the median across all instances of the reference time series.</p><p id="p-0135" num="0134">As will be appreciated, the views <b>391</b> and <b>392</b> include the axis <b>311</b> that shows properties as a function of the instance. As a general rule, it would be possible that the multiple instances of the reference time series <b>101</b> and/or of the generated time series <b>103</b> are sorted. The sorting can arrange the sequence of instances along the axis <b>311</b>. To make both the reference and generated time series comparable, the same sorting is generally applied to the generated time series and the reference time series.</p><p id="p-0136" num="0135">As a general rule, various sorting criteria are conceivable. For example, sorting can be based on the PCA, or on a user input, or on the at least one distance measure of the iteration view <b>391</b>. For instance the sorting could be executed prior to box <b>1021</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0137" num="0136">As a general rule, the sorting based on PCA can be applied to the multiple instances of the reference time series, to transform the data points of each reference time series into uncorrelated components. The multiple instances of the reference time series are then sorted based on the first/primary principal component. For example, the PCA could be trained based on the reference time series of the reference dataset and the applied to the generated time series of the training dataset.</p><p id="p-0138" num="0137">Next, further details with respect to the iteration view <b>391</b> will be explained. Here, to get further insights about the properties of the data, a measure of similarity and a dimensionality reduction technique are used.</p><p id="p-0139" num="0138">As a general rule, the least one distance measure can use various underlying distance metrics, e.g., Euclidean Distance (ED) or Dynamic Time Warping (DTW). As a general rule, the user may select a metric for the distance measure. For example, the user may select either ED or DTW. The metric could also be predefined.</p><p id="p-0140" num="0139">As a further general rule, a nearest-neighbor distance can be determined. I.e., it is possible to determine, for a given instance of the generated time series the closest instance of the reference time series (using the respective distance metric)&#x2014;or vice versa; this minimum distance is then the nearest-neighbor distance.</p><p id="p-0141" num="0140">In the concrete example of <figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the plot <b>301</b> corresponds to a first distance measure and the plot <b>302</b> corresponds to a second distance measure. The first distance measure of the plot <b>301</b> is the Incoming Nearest Neighbor Distances (INND); and the second distance measure of the plot <b>302</b> is the Outgoing Nearest Neighbor Distances (ONND). In the example of plots <b>301</b>, <b>302</b> the INND and ONND are also resolved for each one of the multiple instances along axis <b>311</b>, but this is generally optional. The order of the instances is determined based on sorting, e.g., using the PCA.</p><p id="p-0142" num="0141">The plot <b>301</b> illustrates, for each instance of the generated time series, the minimum value of the distance metric to any instance of the reference time series (i.e., the nearest-neighbor distance to the multiple instances of the reference time series), as INNDs. The nearest-neighbor distances are defined within each iteration of the plurality of iterations.</p><p id="p-0143" num="0142">The plot <b>302</b> illustrates, for each instance of the reference time series <b>101</b>, the nearest-neighbor distance to the multiple instances of the generated time series <b>103</b>, as ONNDs. The calculation of the ONNDs is also illustrated by the pseudo-code of table 1 below</p><p id="p-0144" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="217pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 1</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>Pseudo-code for calculation of ONNDs of various</entry></row><row><entry>instances of the reference time series.</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="217pt" align="left"/><tbody valign="top"><row><entry>-Load all instances of the reference time series</entry></row><row><entry>-Select a given iteration</entry></row><row><entry>-Load all instances of the generated time series for the selected given</entry></row><row><entry>iteration</entry></row><row><entry>-For each instance of the reference time series</entry></row><row><entry>&#x2003;-For each instance of the generated time series</entry></row><row><entry>&#x2003;&#x2003;-Determine distance between current reference time series and current</entry></row><row><entry>&#x2003;&#x2003;generated time series</entry></row><row><entry>&#x2003;-Next Instance of the generated time series</entry></row><row><entry>&#x2003;-ONND of the current instance of the reference time series is the</entry></row><row><entry>&#x2003;minimum across all determined distances</entry></row><row><entry>-Next instance of the reference time series</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0145" num="0143">The 2-D heatmap plots <b>301</b>, <b>302</b> illustrate INNDs and ONNDs as a function of instances along the axis <b>311</b> and as a function of iterations along the axis <b>312</b>. The intensity of the color of each pixel of the 2-D heatmap plots highlights the value of the INNDs or ONNDs, respective. In the illustrated example, a dark pixel represents a high distance value, while a brighter pixel denotes a lower distance value.</p><p id="p-0146" num="0144">INNDs and ONNDs give an overview about the overall performance of GAN over the iterations and allow for different types of investigations:</p><p id="p-0147" num="0145">Firstly, are the generated time series <b>103</b> becoming more realistic with the iterations, i.e., do the INNDs/ONNDs become smaller as a function of the iterations along the axis <b>312</b>?</p><p id="p-0148" num="0146">Secondly, are INNDs/ONNDs reaching a stable behavior and indicating nearly constant values, as a function of the iterations along the axis <b>312</b>?</p><p id="p-0149" num="0147">Thirdly, is the variation/variation strength of the time-domain shapes of the instances of the reference time series representative for the variation strength of the variation strength of the time-domain shapes of the generated time series <b>103</b>? This is indicated by the ONNDs of the plot <b>302</b>. The ONNDs thus is indicative of whether all instances of reference time series are equally well represented by the instances of the generated time series, or whether the instances of the generated time series correspond to a limited number of instances of the reference time series. The INNDs, on the other hand are indicative of a similarity between the time-domain shapes of the data points of the generated time series with respect to the reference time series.</p><p id="p-0150" num="0148">Next, an example use case is discussed in concrete terms. This is an example only, but helps to understand the underlying motivation and details of the approach. The use case illustrates that the evaluation framework <b>104</b> enables an exploration of the behavior of the GAN over the iterations and an investigation of the similarity between the reference and generated time series. Hence, the presented human-centered approach gives the opportunity to build a relationship of trust between the user and the AI algorithm.</p><p id="p-0151" num="0149">Here, a user tested the proposed method on a GAN model (Mogren, O. 2016. C-rnn-gan: A continuous recurrent neural network with adversarial training. In Constructive MLML Workshop (CIVIL) at NIPS 2016, 1) to generate data based on the reference data set (Goldberger, A. L.; Amaral, L. A. N.; Glass, L.; Hausdorff, J. M.; Ivanov, P. C.; Mark, R. G.; Mietus, J. E.; Moody, G. B.; Peng, C.-K.; and Stanley, H. E. 2000 (June 13). PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation 101(23):e215-e220. Circulation Electronic Pages: http://circ.ahajournals.org/content/101/23/e215.full PMID:1085218; doi:10.1161/01.CIR.101.23.e215). The considered reference dataset consists of 7 long-term Electrocardiogram (ECG) for a period of 14 to 22 hours each. It contains two classes depicting the normal and abnormal behavior. To reduce the training time, only 30 time points from the reference time series are considered. The user used one class in his experiments. The performance of GAN is evaluated for two different parameter configurations, namely GAN type 1 and GAN type 2. The corresponding results are depicted in <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref>, respectively.</p><p id="p-0152" num="0150">The GAN Iteration Views <b>391</b> depicts the INNDs and ONNDs depending on the iterations and instances. The first iterations for both scenarios are characterized by high INND and ONND (dark pixels in the heatmap plots <b>301</b>, <b>302</b> of the iteration view <b>391</b>). As the number of iterations increases, an improvement in terms of INND can be seen. Hence, the generated data are progressively reaching similar values to the original data and the performance of the GAN is increasing with a growing number of iterations. However, the INNDs for GAN type 1 sharply increase at some iterations, e.g., between iteration 600 and 900. GAN type 2 is showing a more stable behavior. In fact, after approximately 300 iterations, the INNDs are almost constant. ONNDs in plot <b>302</b> of the iteration view <b>391</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref> show that the ONNDs at the top and bottom of the sorted iterations are still high (red circles in <figref idref="DRAWINGS">FIG. <b>5</b></figref>). As the instances of the reference time series are sorted with PCA, the expert concludes that the reference time series with an important shift are characterized by a high ONND. Hence, the multiple instances of the generated time series <b>103</b> produced by the first GAN are similar to a specific type of the multiple instances of the reference time series <b>101</b>, namely the instances that are sorted in the middle (i.e., similar to the respective one or more feature classes). The expert hypothesizes that GAN model type 1 was not able to reproduce the shift present in the real data and is collapsing to one mode (mode collapse); not all feature classes of the multiple instances of the reference time series are reproduced. In contrast to GAN type 1, ONNDs illustrated in plot <b>302</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref> depict a low ONND for all instances of the reference time-series. ONNDs helped the user to verify that the instances of the generated time series are diverse (i.e., show an appropriate variation strength) and do not correspond to a specific feature class, but to almost all real ones.</p><p id="p-0153" num="0151">Afterwards, the user selects some interesting iterations in the iteration view <b>391</b> and continues his investigation in the instance view <b>392</b>. For both scenarios, the user selected an iteration at the beginning of the training process, certain iterations with low INNDs in the middle of the training process, few iterations characterized by high INND and ONND in GAN type 1 and 2, and some iterations showing a stable behavior within the last hundred iterations of the training process.</p><p id="p-0154" num="0152">At the early iterations of the training process, the time-dependent distribution of data points of the generated time series was completely different from the time-dependent distribution of the data points of the reference time series <b>101</b>. An improvement in the performance is noticeable after approximately 200 iterations. In general, the time-dependent distribution and the quality of the generated time series are becoming more realistic over the iterations. An enhancement in the results is observed between the iterations 382, 614 and 899 for GAN type 1 (<figref idref="DRAWINGS">FIG. <b>5</b></figref>) and the iterations 386 and 669 for GAN type 2 (<figref idref="DRAWINGS">FIG. <b>6</b></figref>).</p><p id="p-0155" num="0153">To inspect the behavior of GAN type 1 rigorously, the user selected some instances of the generated time series at different iterations. In the selected sample view <b>393</b>, he noticed that at iteration 764 the data points of the generated time series exhibit a strange peak and at iteration 40 noise is generated. Hence, the evaluation framework <b>104</b> helped the user to detect if the data are noisy or have a different behavior from the real data.</p><p id="p-0156" num="0154">Accordingly, both GAN types were not able to generate realistic time series in the first iterations of the training process at all; the performance increased for subsequent iterations of the training process. However, the data quality can decrease drastically and suddenly, after only a single iteration, i.e. iterations 769 and 480 in the GAN type 1 scenario of <figref idref="DRAWINGS">FIG. <b>5</b></figref> and in the GAN type 2 scenario of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, respectively. The user confirms that this is an expected behavior with neural networks because their performance is not monotonic.</p><p id="p-0157" num="0155">An analysis of the last hundred iterations of the training process allows the user to find an iteration with the best result; this facilitates configuring the GAN accordingly. This corresponds to iteration 978 for GAN type 1 in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and iteration 926 for GAN type 2 in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. In both cases, the generated time series are smooth and realistic. However, the 2-D histogram plots <b>322</b> of the instance view <b>392</b> for GAN type 1 in <figref idref="DRAWINGS">FIG. <b>5</b></figref> is still different from the respective plot <b>321</b> of the instances of the reference time series. For the time-histogram plots <b>331</b>, <b>332</b> also differ from each other. Moreover, ONND of plot <b>302</b> for GAN type 1 demonstrates that the samples are not as diverse as in the instances of the reference time series. A rigorous investigation of these time series in the selected sample view <b>393</b>, e.g., plot <b>333</b>, shows that all the generated data are falling in the 68th percentile (a statistical reference) of the instances of the reference time series and are too close to the median i.e. their variation strength is low. This confirms the earlier hypothesis of the user when he observed the iteration view <b>391</b>. Thus, the user was able to easily detect the mode collapse phenomenon, one of the hardest training problems for GAN. In order to avoid this problem, the user used in GAN type 2 a normal distributed noise instead of the uniformly distributed noise and applied a technique introduced in Salimans, T.; Goodfellow, I.; Zaremba, W.; Cheung, V.; Radford, A.; Chen, X.; and Chen, X. 2016. Improved techniques for training gans. In Lee, D. D.; Sugiyama, M.; Luxburg, U. V.; Guyon, I.; and Garnett, R., eds., Advances in Neural Information Processing Systems 29. Curran Associates, Inc. 2234-2242, namely mini-batch discrimination. As a general rule, various options are available to configure the GAN appropriately; i.e., not just those two mentioned above. In contrast to GAN type 1, GAN type 2 is re-producing the distribution of the instances of the reference time series much better: the ONND of plot <b>302</b> shows smaller values across all instances along axis <b>311</b> (the plot <b>302</b> has more white pixels for <figref idref="DRAWINGS">FIG. <b>6</b></figref> than for <figref idref="DRAWINGS">FIG. <b>5</b></figref>). Also, the time-histogram plots <b>332</b> resemble the time-histogram plots <b>331</b> at least for some iterations.</p><p id="p-0158" num="0156">For even further exploration, the user selected different instances time series from the instance view <b>392</b> and visualized them in the selected sample view <b>393</b>. The generated data prove that GAN type 2 is reproducing the shift present in the time-domain shapes of the data points of the instances of the reference time series. The variation strength is higher. Differences to statistical median exist.</p><p id="p-0159" num="0157">As a last step, our expert used the view <b>393</b> to directly compare the time-domain shape of the data points of a given instance of the generated time-series to the time-domain shape of the data points of a given instance of the reference time series. This is illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> for plots <b>333</b> and <b>334</b>. The behavior of the data points of the generated time series is similar to the behavior of the data points of the reference data.</p><p id="p-0160" num="0158">Hence, the second GAN type 2 presents a more realistic behavior and was able at iteration 926 to generate time series that are rare in the real dataset. The user concludes that GAN type 2 is achieving the desired behavior. Hence, the proposed evaluation framework helped the users to find a trustworthy GAN configuration with a set of parameters producing the best results.</p><p id="p-0161" num="0159"><figref idref="DRAWINGS">FIG. <b>7</b></figref> schematically illustrates a device <b>701</b>. The device <b>701</b> includes a processor <b>701</b> and a memory <b>702</b>. The processor <b>701</b> can load program code from the memory <b>702</b>. The processor <b>701</b> can execute the program code. This causes the processor <b>701</b> to perform techniques as described herein, e.g.: obtaining a reference dataset, e.g., via a data interface <b>703</b>; performing a training process of a GAN; configuring a GAN based on user input; executing an evaluation framework; outputting views to a user via an HMI <b>704</b>; receiving user input via the HMI <b>704</b>; outputting a training dataset obtained from executing the GAN, e.g., via the data interface <b>703</b>; etc. The processor <b>701</b> could execute the methods of <figref idref="DRAWINGS">FIG. <b>1</b></figref> or <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0162" num="0160">Summarizing, above techniques pertaining to a visual approach to evaluate and optimize GANs generating time series data have been described. The proposed evaluation framework is based on at least one visualization techniques, namely a distance measure across multiple iterations, as well as a view for one or more selected iteration including all instances. The distance measure is used in a sophisticated manner to compute the INNDs and ONNDs. The evaluation framework supports users in the evaluation process. Experts can detect that a configuration of a GAN generates samples which are not diverse. Also, it is possible to verify that a mapping between the generated and the real data is clear, i.e. the generated samples should correspond to an easily recognizable class. Other developments are planned to allow for increased transparency and deeper understanding of the GAN algorithm such as: additional views that highlight the decision making process of the discriminator and an efficient comparison between data generated from different GAN configurations.</p><p id="p-0163" num="0161">For illustration, above, various examples have been described in which the data generation algorithm is implemented by a GAN. Other kinds and types of data generation algorithms are conceivable.</p><p id="p-0164" num="0162">For further illustration, various examples have been described for a scenario in which the data generation algorithm generates a generated dataset that implements a training dataset for training an ML algorithm. Similar techniques as described above can be readily applied for other purposes of the generated dataset, e.g., for a test dataset, etc.</p><p id="p-0165" num="0163">Although the present invention has been disclosed in the form of preferred embodiments and variations thereon, it will be understood that numerous additional modifications and variations could be made thereto without departing from the scope of the invention.</p><p id="p-0166" num="0164">For the sake of clarity, it is to be understood that the use of &#x201c;a&#x201d; or &#x201c;an&#x201d; throughout this application does not exclude a plurality, and &#x201c;comprising&#x201d; does not exclude other steps or elements.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of configuring a data generation algorithm for generating a generated dataset of technical data, the generated dataset implements a training dataset for training a machine learning algorithm, the generated dataset comprising a generated time series of data points, the method comprising:<claim-text>obtaining multiple instances of a reference time series of data points;</claim-text><claim-text>based on the multiple instances of the reference time series: iteratively adjusting a configuration of the data generation algorithm and executing the data generation algorithm with the respectively adjusted configuration, to thereby obtain a plurality of iterations of multiple instances of a generated time series of data points;</claim-text><claim-text>outputting, to a human-machine-interface, a first view of at least one distance measure between the multiple instances of the reference time series and the multiple instances of the generated time series as a function of the plurality of iterations; and</claim-text><claim-text>obtaining, from the human-machine-interface, a user input indicative of a selected iteration of the plurality of iterations;</claim-text><claim-text>wherein the at least one distance measure comprises a first distance measure which is based on nearest-neighbor distances of each of the multiple instances of the generated time series to the multiple instances of the reference time series.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one distance measure comprises a second distance measure which is based on nearest-neighbor distances of each of the multiple instances of the reference time series to the multiple instances of the generated time series.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first view comprises a first plot of the first distance measure and further comprises a second plot of the second distance measure, and the first plot and the second plot have a common axis associated with the plurality of iterations.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the first plot and the second plot of the first view include 2-D heatmap plots for the first distance measure and the second distance measure as a function of the plurality of iterations and a function of the multiple iterations.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one distance measure comprises a first distance measure indicative of a similarity between time-domain shapes of the data points of the generated time series with respect to the reference time series.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one distance measure comprises a second distance measure indicative of a variation strength of time-domain shapes of the data points of the generated time series with respect to the reference time series.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first view comprises at least one plot showing the at least one distance measure for each one of the multiple instances of the reference time series and/or the generated time series.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>outputting, to the human-machine-interface, a second view comprising an amplitude or phase of the multiple instances of the generated time series for the selected iteration of the plurality of iterations.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein:<claim-text>the second view comprises a first plot in which the amplitude or phase of the multiple instances of the reference time series is shown,</claim-text><claim-text>the second view comprises a second plot in which the amplitude or phase of the multiple instances of the generated time series is shown for the selected iteration of the plurality of iterations, and</claim-text><claim-text>the first plot and the second plot share a common axis for the multiple instances.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the plot of the second view comprises 2-D heatmaps for the amplitude or phase of the selected iteration of the plurality of iterations of the generated time series and of the reference time series, as a function of the multiple iterations and as a function of time.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising:<claim-text>obtaining, from the human-machine-interface, a further user input indicative of a selected instance of the multiple instances of the selected iteration of the plurality of iterations; and</claim-text><claim-text>outputting, to the human-machine-interface, a third view indicative of the amplitude or phase of the selected instance of the multiple instances of the selected iteration of the plurality of iterations, as a function of time.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>sorting at least one of the multiple instances of the reference time series or the generated time series.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>based on the user input, configuring at least one of the data generation algorithm or a training process of the data generation algorithm.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A device comprising a control circuitry configured to:<claim-text>obtain multiple instances of a reference time series of data points;</claim-text><claim-text>based on the multiple instances of the reference time series: iteratively adjust a configuration of the data generation algorithm and executing the data generation algorithm with the respectively adjusted configuration, to thereby obtain a plurality of iterations of multiple instances of a generated time series of data points;</claim-text><claim-text>output, to a human-machine-interface, a first view of at least one distance measure between the multiple instances of the reference time series and the multiple instances of the generated time series as a function of the plurality of iterations; and</claim-text><claim-text>obtain, from the human-machine-interface, a user input indicative of a selected iteration of the plurality of iterations;</claim-text><claim-text>wherein the at least one distance measure comprises a first distance measure which is based on nearest-neighbor distances of each of the multiple instances of the generated time series to the multiple instances of the reference time series.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004791A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004791</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17364444</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">COMPRESSED MATRIX REPRESENTATIONS OF NEURAL NETWORK ARCHITECTURES BASED ON SYNAPTIC CONNECTIVITY</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>X Development LLC</orgname><address><city>Mountain View</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Feng</last-name><first-name>Yu</first-name><address><city>Dublin</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Nguyen</last-name><first-name>Lam Thanh</first-name><address><city>Mountain View</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for implementing brain emulation neural networks using compressed matrix representations. One of the methods includes obtaining a network input; and processing the network input using a neural network to generate a network output, comprising: processing the network input using an input subnetwork of the neural network to generate an embedding of the network input; and processing the embedding of the network input using a brain emulation subnetwork of the neural network, wherein the brain emulation subnetwork has a brain emulation neural network architecture that represents synaptic connectivity between a plurality of biological neurons in a brain of a biological organism, the processing comprising: obtaining a compressed matrix representation of a sparse matrix of brain emulation parameters; and applying the compressed matrix representation to the embedding of the network input to generate a brain emulation subnetwork output.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="137.75mm" wi="158.75mm" file="US20230004791A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="212.60mm" wi="177.29mm" orientation="landscape" file="US20230004791A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="242.06mm" wi="158.07mm" file="US20230004791A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="196.17mm" wi="114.22mm" file="US20230004791A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="232.33mm" wi="127.85mm" file="US20230004791A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="245.62mm" wi="153.42mm" file="US20230004791A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="233.85mm" wi="150.37mm" file="US20230004791A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="188.64mm" wi="134.37mm" file="US20230004791A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="210.57mm" wi="134.87mm" file="US20230004791A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="193.63mm" wi="133.69mm" file="US20230004791A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="168.23mm" wi="133.77mm" file="US20230004791A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="224.37mm" wi="129.12mm" file="US20230004791A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="137.92mm" wi="160.27mm" file="US20230004791A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">This specification relates to processing data using machine learning models.</p><p id="p-0003" num="0002">Machine learning models receive an input and generate an output, e.g., a predicted output, based on the received input. Some machine learning models are parametric models and generate the output based on the received input and on values of the parameters of the model.</p><p id="p-0004" num="0003">Some machine learning models are deep models that employ multiple layers of computational units to generate an output for a received input. For example, a deep neural network is a deep machine learning model that includes an output layer and one or more hidden layers that each apply a non-linear transformation to a received input to generate an output.</p><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0005" num="0004">This specification describes systems implemented as computer programs on one or more computers in one or more locations for implementing neural networks that include one or more brain emulation neural network layers whose parameters have been determined according to the synaptic connectivity between neurons in the brain of a biological organism, e.g., a fly.</p><p id="p-0006" num="0005">For example, the parameters of a brain emulation neural network layer can be determined using a synaptic connectivity graph. A synaptic connectivity graph refers to a graph representing the structure of synaptic connections between neurons in the brain of a biological organism, e.g., a fly. For example, the synaptic connectivity graph can be generated by processing a synaptic resolution image of the brain of a biological organism.</p><p id="p-0007" num="0006">For convenience, throughout this specification, an artificial neural network layer whose parameters have been determined using synaptic connectivity is called a &#x201c;brain emulation&#x201d; neural network layer. An artificial neural network having at least one brain emulation neural network layer is called a &#x201c;brain emulation&#x201d; neural network. Identifying an artificial neural network as a &#x201c;brain emulation&#x201d; neural network is intended only to conveniently distinguish such neural networks from other neural networks (e.g., with hand-engineered architectures), and should not be interpreted as limiting the nature of the operations that can be performed by the neural network or otherwise implicitly characterizing the neural network.</p><p id="p-0008" num="0007">The architecture of a brain emulation neural network layer of a brain emulation neural network can be represented using a weight matrix that includes the parameters of the brain emulation neural network layer. When the brain emulation neural network processes a network input, the brain emulation neural network layer is configured to process a layer input generated from the network input by multiplying the weight matrix against the layer input to generate a layer output.</p><p id="p-0009" num="0008">The weight matrix of a brain emulation neural network layer can have a high sparsity; that is, a high proportion of the elements of the weight matrix can have a value of zero. In these cases, the weight matrix can be represented using a compressed matrix representation.</p><p id="p-0010" num="0009">In this specification, a compressed matrix representation of a matrix is any representation of the matrix that leverages the sparsity of the matrix to reduce the number of bits required to represent the matrix. For example, a compressed matrix representation can explicitly identify only a proper subset of the elements of the matrix, and not explicitly identify the other elements of the matrix. In some implementations, the elements of the sparse matrix that are not explicitly identified in the compressed matrix representation all have value zero, and some or all of the elements of the sparse matrix that are explicitly identified in the compressed matrix representation have respective non-zero values. In some implementations, the compressed matrix representation only explicitly identifies the elements of the matrix that have a non-zero value. In some other implementations, the compressed matrix representation explicitly identifies the elements of the matrix that have a non-zero value, while also explicitly identifying a proper subset of the elements of the matrix that have a value of zero. As a particular example, during training of a neural network that includes a weight matrix of parameters represented using a compressed matrix representation, some of the parameters of the weight matrix that are explicitly identified in the compressed matrix representation may temporarily have values of zero, e.g., if a parameter update causes the parameter to change from a non-zero value to a value of zero. Specific examples are described in more detail below.</p><p id="p-0011" num="0010">For example, the compressed matrix representation can be a compressed list (often called &#x201c;COO&#x201d;) representation, a compressed sparse row (CSR) representation, or a compressed sparse column (CSC) representation.</p><p id="p-0012" num="0011">The weight matrix of a brain emulation neural network layer can be stored using a compressed matrix representation, applied using a compressed matrix representation, or both.</p><p id="p-0013" num="0012">This specification also describes systems for training a neural network that includes one or more such brain emulation neural network layers, including updating the values of the parameters that are represented used the compressed matrix representation.</p><p id="p-0014" num="0013">Particular embodiments of the subject matter described in this specification can be implemented so as to realize one or more of the following advantages.</p><p id="p-0015" num="0014">The systems described in this specification can train and implement a brain emulation neural network using a compressed matrix representation. As described in this specification, brain emulation neural networks can achieve a higher performance (e.g., in terms of prediction accuracy), than other neural networks of an equivalent size (e.g., in terms of number of parameters). Put another way, brain emulation neural networks that have a relatively small size (e.g., 100 or 1000 parameters) can achieve comparable performance with other neural networks that are much larger (e.g., thousands or millions of parameters). Therefore, using techniques described in this specification, a system can implement a highly efficient, low-latency, and low-power-consuming neural network. That is, a system that implements a brain emulation neural network can reduce the use of computational resources, e.g., memory and computational power, relative to systems that implement other neural networks.</p><p id="p-0016" num="0015">Leveraging compressed matrix representations can further improve the efficiency of a system configured to execute a brain emulation neural network. In some implementations, brain emulation neural networks can have a very high sparsity, representing the fact that most pairs of neurons in the brain of a biological organism do not share a synaptic connection. Thus, brain emulation neural networks in particular can enjoy significant efficiency improvements from compressed matrix representations. The reduced size of the compressed matrix representation of a weight matrix of a brain emulation neural network layer improves the memory efficiency, computational efficiency, and time efficiency of processing layer inputs using the brain emulation neural network layer. Furthermore, this improved efficiency can further reduce the amount of power necessary for the system to execute the brain emulation neural network.</p><p id="p-0017" num="0016">These efficiency gains can be especially important in low-resource or low-memory environments, e.g., on mobile devices or other edge devices. Additionally, these efficiency gains can be especially important in situations in which the brain emulation neural network is continuously processing network inputs, e.g., in an application that continuously processes input audio data to determine whether a &#x201c;wakeup&#x201d; phrase has been spoken by a user.</p><p id="p-0018" num="0017">The systems described in this specification can implement a brain emulation neural network having an architecture specified by a synaptic connectivity graph derived from a synaptic resolution image of the brain of a biological organism. The brains of biological organisms may be adapted by evolutionary pressures to be effective at solving certain tasks, e.g., classifying objects or generating robust object representations, and brain emulation neural networks can share this capacity to effectively solve tasks. In particular, compared to other neural networks, e.g., with manually specified neural network architectures, brain emulation neural networks can require less training data, fewer training iterations, or both, to effectively solve certain tasks.</p><p id="p-0019" num="0018">The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>1</b></figref> and <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrate example neural network computing systems.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example weight matrix of a brain emulation neural network layer determined using synaptic connectivity.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> illustrates an example of generating a brain emulation neural network based on a synaptic resolution image of the brain of a biological organism.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> shows an example data flow for generating a synaptic connectivity graph and a brain emulation neural network based on the brain of a biological organism.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows an example architecture mapping system.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an example graph and an example sub-graph.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flow diagram of an example process for implementing a brain emulation neural network layer using a compressed matrix representation.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flow diagram of an example process for generating a brain emulation neural network.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flow diagram of an example process for determining an artificial neural network architecture corresponding to a sub-graph of a synaptic connectivity graph.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>10</b></figref> shows an example optimization system.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram of an example computer system.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0031" num="0030">Like reference numbers and designations in the various drawings indicate like elements.</p><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>1</b></figref> and <figref idref="DRAWINGS">FIG. <b>2</b></figref> show two examples of neural network computing systems for implementing neural networks that include at least one brain emulation neural network layers.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an example neural network computing system <b>100</b>. The neural network computing system <b>100</b> is an example of a system implemented as computer programs on one or more computers in one or more locations in which the systems, components, and techniques described below are implemented.</p><p id="p-0034" num="0033">The neural network computing system <b>100</b> includes a brain emulation neural network <b>102</b>. The brain emulation neural network <b>102</b> includes one or more brain emulation neural network layers (e.g., the brain emulation neural network layer <b>108</b>). Optionally, the brain emulation neural network <b>102</b> can also include one or more other neural network layers, e.g., one or more feed-forward neural network layers, recurrent neural network layers, convolutional neural network layers, or any other appropriate type of neural network layer.</p><p id="p-0035" num="0034">The brain emulation neural network <b>102</b> is configured to process a network input to generate a network output for a particular machine learning task. The network input for the brain emulation neural network <b>102</b> can be any kind of digital data input, and the network output for the brain emulation neural network <b>102</b> can be any kind of score, classification, or regression output based on the input. That is, the brain emulation neural network <b>102</b> can be configured for any appropriate machine learning tasks; example tasks are discussed below.</p><p id="p-0036" num="0035">The brain emulation neural network layer <b>108</b> includes multiple brain emulation parameters, and is configured to process a brain emulation layer input <b>110</b>, generated from the network input of the brain emulation neural network <b>102</b>, and to generate a brain emulation layer output <b>112</b>, which can be processed by subsequent neural network layers in the brain emulation neural network <b>102</b>. In general, the brain emulation layer input <b>110</b> can be the network input to the brain emulation neural network <b>102</b> (i.e., if the brain emulation neural network layer <b>108</b> is the first layer in the brain emulation neural network <b>102</b>) or the output of another layer of the brain emulation neural network <b>102</b>. Similarly, the brain emulation layer output <b>112</b> can be the network output of the brain emulation neural network <b>102</b> (i.e., if the brain emulation neural network layer <b>108</b> is the final layer in the brain emulation neural network <b>102</b>). The brain emulation layer input <b>110</b> and the brain emulation layer output <b>112</b> may be represented in any appropriate numerical format, for example, as vectors or as matrices.</p><p id="p-0037" num="0036">The brain emulation neural network layer <b>108</b> can have a brain emulation architecture that is based on a synaptic connectivity graph representing synaptic connectivity between neurons in the brain of a biological organism. An example process for determining a network architecture using a synaptic connectivity graph is described below with respect to <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>. In some implementations, the architecture of the brain emulation neural network layer <b>108</b> can be specified by the synaptic connectivity between neurons of a particular type in the brain, e.g., neurons from the visual system or the olfactory system. This process is described in more detail below with reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0038" num="0037">In particular, the architecture of the brain emulation neural network layer <b>108</b> can be represented by a weight matrix that the brain emulation neural network layer <b>108</b> applies to the brain emulation layer input <b>110</b> to generate the brain emulation layer output <b>112</b>. Each element of the weight matrix can be a respective brain emulation parameter of the brain emulation neural network layer <b>108</b>. As a particular example, the brain emulation layer input <b>110</b> can be an N&#xd7;1 vector of elements, the weight matrix of the brain emulation neural network layer <b>108</b> can be an M&#xd7;N matrix of elements, and the brain emulation layer output <b>112</b> can be an M&#xd7;1 vector of elements.</p><p id="p-0039" num="0038">Each brain emulation parameter of the weight matrix can correspond to a pair of neurons in the brain of the biological organism, where the value of the brain emulation parameter characterizes a strength of a neuronal connection between the pair of neurons. In other words, each row and column of the weight matrix can correspond to a respective neuron in the brain of the biological organism, and the value of each brain emulation parameter can characterize a strength of a neuronal connection between (i) the neuron corresponding to the row of the brain emulation parameter and (ii) the neuron corresponding to the column of the brain emulation parameter.</p><p id="p-0040" num="0039">In particular, the weight matrix can be an M&#xd7;N matrix, where each of the M rows corresponds to a neuron in a first set of neurons and each of the N columns corresponds to a neuron in a second set of neurons in the brain of the biological organism. The first set of neurons and the second set of neurons can be overlapping (i.e., one or more neurons in the brain of the biological organism is in both sets) or disjoint (i.e., there does not exist a neuron in the brain of the biological organism that is in both sets). As a particular example, the first set and the second set can be the same. That is, the weight matrix can be an N&#xd7;N matrix where the same neurons in the brain of the biological organism are represented by both the rows and the columns of the weight matrix. The process of generating the weight matrix is described in more detail below.</p><p id="p-0041" num="0040">Because many pairs of neurons in the brain of the biological organism may not share a synaptic connection at all, many brain emulation parameters of the weight matrix of the brain emulation neural network layer may have values of zero. In other words, the sparsity of the weight matrix may be high. In this specification, the sparsity of a matrix is a measure of the number or proportion of zero elements in the matrix. In this specification, a matrix may be referred to as a &#x201c;sparse matrix&#x201d; if the sparsity of the matrix satisfies a certain threshold. For example, in some implementations the weight matrix of a brain emulation neural network layer has a sparsity of 50% (i.e., where 50% of the brain emulation parameters of the weight matrix have a value of zero), 60%, 70%, 80%, 90%, 95%, or 99%.</p><p id="p-0042" num="0041">Therefore, the neural network computing system <b>100</b> can store a compressed matrix representation <b>122</b> of the weight matrix of the brain emulation neural network layer <b>108</b>. As described above, the compressed matrix representation <b>122</b> has a smaller memory footprint than the weight matrix when represented fully (i.e., as an array with all zero values represented) because only a proper subset of the brain emulation parameters of the weight matrix are explicitly identified (i.e., represented) by the compressed matrix representation.</p><p id="p-0043" num="0042">As described above, in some implementations, the compressed matrix representation <b>122</b> only explicitly identifies the brain emulation parameters that have a non-zero value. That is, the compressed matrix representation <b>122</b> does not explicitly represent the brain emulation parameters that have values of zero.</p><p id="p-0044" num="0043">In some other implementations, the compressed matrix representation <b>122</b> explicitly identifies both (i) each brain emulation parameter that has a non-zero value, and (ii) a proper subset of the brain emulation parameters that have a value of zero. For example, as described in more detail below, during training of the neural network <b>102</b>, the compressed matrix representation may temporarily explicitly represent brain emulation parameters that have values of zero, e.g., if a parameter update causes the parameter to change from a non-zero value to a value of zero. As another example, the compressed matrix representation <b>122</b> may represent brain emulation parameters that have values of zero during an evolutionary process of updating the compressed matrix representation. Example evolutionary processes are discussed in more detail below with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0045" num="0044">In this specification, a brain emulation parameter of a weight matrix that is explicitly identified by a compressed matrix representation of the weight matrix is called a &#x201c;represented&#x201d; brain emulation parameter. In this specification, a brain emulation parameter of a weight matrix that is not explicitly identified by a compressed matrix representation of the weight matrix is called an &#x201c;unrepresented&#x201d; brain emulation parameter.</p><p id="p-0046" num="0045">For example, the compressed matrix representation <b>122</b> can include data identifying, for each represented brain emulation parameter, the value of the represented brain emulation parameter and the position of the represented brain emulation parameter in the weight matrix. The &#x201c;position&#x201d; of a brain emulation parameter in the weight matrix can be represented, e.g., by the row and column index of the brain emulation parameter in the weight matrix, e.g., as a tuple (i,j) where i represents the row index and j represents the column index.</p><p id="p-0047" num="0046">A parameter data store <b>120</b> of the neural network computing system <b>100</b> can store the compressed matrix representation <b>122</b> of the weight matrix of the brain emulation neural network layer <b>108</b>. When the brain emulation neural network <b>102</b> is processing a network input, the brain emulation neural network layer <b>108</b> can obtain the compressed matrix representation <b>122</b> of the weight matrix from the parameter data store <b>120</b> to generate the brain emulation layer output <b>112</b>.</p><p id="p-0048" num="0047">In some implementations, the brain emulation neural network layer <b>108</b> processes the compressed matrix representation <b>122</b> of the weight matrix to re-generate the full representation of the weight matrix, i.e., a representation in which all brain emulation parameters, including the unrepresented brain emulation parameters of the compressed matrix representation <b>122</b>, are represented.</p><p id="p-0049" num="0048">In some other implementations, the neural network computing system <b>100</b> uses a compressed matrix representation that is configured for efficient matrix multiplication. Thus, the brain emulation neural network layer <b>108</b> does not need to &#x201c;decompress&#x201d; the compressed matrix representation <b>122</b>, but rather can apply the compressed matrix representation directly to the brain emulation layer input <b>110</b>.</p><p id="p-0050" num="0049">For example, the compressed matrix representation of a matrix can be configured to perform a matrix multiplication between the matrix and another tensor such that the unrepresented elements of the matrix are not explicitly multiplied against any values of the other tensor (as, in implementations in which the unrepresented elements all have value zero, the result of the multiplication is certain to also be zero). That is, a system executing a matrix multiplication using a compressed matrix representation of a matrix does not perform scalar multiplications of the unrepresented elements of the matrix.</p><p id="p-0051" num="0050">For example, the compressed matrix representation <b>112</b> can be a COO matrix representation, where each represented brain emulation parameter is represented by a tuple that include the row of the parameter, the column of the parameter, and the value of the parameter. The COO matrix representation is highly efficient when used to execute matrix multiplications, and is supported by many machine learning computer-language libraries, e.g., TensorFlow.</p><p id="p-0052" num="0051">In some implementations, the computational efficiency of executing a matrix multiplication using the compressed matrix representation <b>122</b> scales linearly or approximately linearly with the sparsity of the weight matrix of the brain emulation neural network layer <b>108</b>. That is, if the weight matrix has a sparsity of 70%, then the neural network computing system can execute the matrix multiplication to generate the brain emulation layer output <b>112</b> using 70% fewer computations.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an example neural network computing system <b>200</b>. The neural network computing system <b>200</b> is an example of a system implemented as computer programs on one or more computers in one or more locations in which the systems, components, and techniques described below are implemented.</p><p id="p-0054" num="0053">The neural network computing system <b>200</b> includes a neural network <b>202</b> that has (at least) three subnetworks: (i) a first trained subnetwork <b>204</b> (ii) a brain emulation subnetwork <b>208</b>, and (iii) a second trained subnetwork <b>212</b>. The neural network <b>202</b> is configured to process a network input <b>201</b> to generate a network output <b>214</b>.</p><p id="p-0055" num="0054">The first trained subnetwork <b>204</b> is configured to process the network input <b>201</b> in accordance with a set of model parameters <b>222</b> of the first trained subnetwork <b>204</b> to generate a first subnetwork output <b>206</b>. The brain emulation subnetwork <b>208</b> is configured to process the first subnetwork output <b>206</b> in accordance with a set of model parameters <b>224</b> of the brain emulation subnetwork <b>208</b> to generate a brain emulation subnetwork output <b>210</b>. The second trained subnetwork <b>212</b> is configured to process the brain emulation subnetwork output <b>210</b> in accordance with a set of model parameters <b>226</b> of the second trained subnetwork <b>212</b> to generate the network output <b>214</b>.</p><p id="p-0056" num="0055">The brain emulation subnetwork includes one or more brain emulation neural network layers whose respective architectures are represented by a weight matrix that is represented as a compressed matrix representation. For example, the brain emulation subnetwork <b>208</b> can be configured similarly to the brain emulation neural network <b>102</b> described above with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0057" num="0056">Although the neural network <b>202</b> depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref> includes one trained subnetwork <b>204</b> before the brain emulation subnetwork <b>208</b> and one trained subnetwork <b>212</b> after the brain emulation subnetwork <b>208</b>, in general the neural network <b>202</b> can include any number of trained subnetworks before and/or after the brain emulation subnetwork <b>208</b>. In some implementations, the first trained subnetwork <b>204</b> and/or the second trained subnetwork <b>212</b> can include only one or a few neural network layers (e.g., a single fully-connected layer) that processes the respective subnetwork input to generate the respective subnetwork output.</p><p id="p-0058" num="0057">In implementations where there are zero trained subnetworks before the brain emulation subnetwork <b>208</b>, the brain emulation subnetwork <b>208</b> can receive the network input <b>201</b> directly as input. In implementations where there are zero trained subnetworks after the brain emulation subnetwork <b>208</b>, the brain emulation subnetwork output <b>210</b> can be the network output <b>214</b>.</p><p id="p-0059" num="0058">Although the neural network <b>202</b> depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref> includes a single brain emulation subnetwork <b>208</b>, in general the neural network <b>202</b> can include multiple brain emulation subnetwork <b>208</b>. In some implementations, each brain emulation subnetwork <b>208</b> has the same set of model parameters <b>224</b>; in some other implementations, each brain emulation subnetwork <b>208</b> has a different set of model parameters <b>224</b>. In some implementations, each brain emulation subnetwork <b>208</b> has the same network architecture; in some other implementations, each brain emulation subnetwork <b>208</b> has a different network architecture.</p><p id="p-0060" num="0059">In some implementations, the neural network <b>202</b> is a recurrent neural network. In these implementations, the network input <b>201</b> includes a sequence of input elements. The first trained subnetwork <b>204</b> can process, at each of multiple time steps corresponding to respective input elements in the sequence, the input element to generate a respective first subnetwork output <b>206</b>. At each time step, the brain emulation subnetwork <b>208</b> can process the first subnetwork output <b>206</b> to generate a respective brain emulation subnetwork output <b>210</b>. At each time step, the second trained subnetwork <b>212</b> can process the brain emulation subnetwork output <b>210</b> to generate an output element corresponding to the input element.</p><p id="p-0061" num="0060">At each time step, the neural network <b>202</b> can maintain a hidden state <b>220</b>. That is, at each time step, the neural network <b>202</b> updates its hidden state <b>220</b>; then, at the subsequent time step in the sequence of time steps, the neural network <b>202</b> receives as input (i) the input element of the network input <b>201</b> corresponding to the subsequent time step and (ii) the current hidden state <b>220</b>.</p><p id="p-0062" num="0061">In some implementations in which the neural network <b>202</b> is a recurrent neural network (e.g., in the example depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>), the first trained subnetwork <b>204</b> receives both i) the input element of the sequence of the network input <b>201</b> and ii) the hidden state <b>220</b>. For example, the recurrent neural network <b>202</b> can combine the input element and the hidden state <b>220</b> (e.g., through concatenation, addition, multiplication, or an exponential function) to generate a combined input, and then process the combined input using the first trained subnetwork <b>204</b>.</p><p id="p-0063" num="0062">In some implementations in which the neural network <b>202</b> is a recurrent neural network, the brain emulation subnetwork <b>208</b> receives as input the hidden state <b>220</b> and the first subnetwork output <b>206</b>. For example, the neural network <b>202</b> can combine the first subnetwork output <b>206</b> and the hidden state <b>220</b> (e.g., through concatenation, addition, multiplication, or an exponential function) to generate a combined input, and then process the combined input using the brain emulation subnetwork <b>208</b>.</p><p id="p-0064" num="0063">In some implementations in which the neural network <b>202</b> is a recurrent neural network, the second trained subnetwork <b>212</b> receives as input the hidden state <b>220</b> and the brain emulation subnetwork output <b>210</b>. For example, the neural network <b>202</b> can combine the brain emulation subnetwork output <b>210</b> and the hidden state <b>220</b> (e.g., through concatenation, addition, multiplication, or an exponential function) to generate a combined input, and then process the combined input using the second trained subnetwork <b>212</b>.</p><p id="p-0065" num="0064">In some implementations in which the neural network <b>202</b> is a recurrent neural network, the updated hidden state <b>220</b> generated at a time step is the same as the output element generated at the time step. In some other implementations, the hidden state <b>220</b> is an intermediate output of the neural network <b>202</b>. An intermediate output refers to an output generated by a hidden artificial neuron or a hidden neural network layer of the neural network <b>202</b>, i.e., an artificial neuron or neural network layer that is not included in the input layer or the output layer of the neural network <b>202</b>. For example, the hidden state <b>220</b> can be the brain emulation subnetwork output <b>210</b>. In some other implementations, the hidden state <b>220</b> is a combination of the output element and one or more intermediate outputs of the neural network <b>202</b>. For example, the hidden state <b>220</b> can be computed using the output element and the brain emulation subnetwork output <b>210</b>, e.g., by combining the two outputs and applying an activation function.</p><p id="p-0066" num="0065">In some implementations in which the neural network <b>202</b> is a recurrent neural network, after each input element in the network input <b>201</b> has been processed by the recurrent neural network <b>202</b> to generate respective output elements, the recurrent neural network <b>202</b> can generate a network output <b>214</b> corresponding to the network input <b>201</b>. In some such implementations, the network output <b>214</b> is the sequence of generated output elements. In some other implementations, the network output <b>214</b> is a subset of the generated output elements, e.g., the final output element corresponding to the final input element in the sequence of input elements of the network input <b>201</b>. In some other implementations, the recurrent neural network <b>202</b> further processes the sequence of generated output elements to generate the network output <b>214</b>. For example, the network output <b>214</b> can be the mean of the generated output elements.</p><p id="p-0067" num="0066">In some implementations, the brain emulation subnetwork <b>208</b> itself has a recurrent neural network architecture. That is, the brain emulation subnetwork <b>208</b> can process the first subnetwork output <b>206</b> multiple times at respective sub-time steps (referred to as sub-time steps to differentiate from the time steps of the neural network <b>202</b> in implementations where the neural network <b>202</b> is a recurrent neural network).</p><p id="p-0068" num="0067">For example, the architecture of the brain emulation subnetwork <b>208</b> can include a sequence of components (e.g., brain emulation neural network layers or groups of brain emulation neural network layers) such that the architecture includes a connection from each component in the sequence to the next component, and the first and last components of the sequence are identical. In one example, two brain emulation neural network layers that are each directly connected to one another (i.e., where the first layer provides its output the second layer, and the second layer provides its output to the first layer) would form a recurrent loop. A recurrent brain emulation subnetwork <b>208</b> can process the first subnetwork output <b>206</b> over multiple sub-time steps to generate a respective brain emulation subnetwork output <b>210</b> at each sub-time step. In particular, at each sub-time step, the brain emulation subnetwork <b>208</b> can process: (i) the first subnetwork output <b>206</b> (or a component of the first subnetwork output <b>206</b>), and (ii) any outputs generated by the brain emulation subnetwork <b>208</b> at the preceding sub-time step, to generate the brain emulation subnetwork output <b>210</b> for the sub-time step. The neural network <b>202</b> can provide the brain emulation subnetwork output <b>210</b> generated by the brain emulation subnetwork <b>208</b> at the final sub-time step as the input to the second trained subnetwork <b>212</b>. The number of sub-time steps over which the brain emulation subnetwork <b>208</b> processes a network input can be a predetermined hyper-parameter of the neural network computing system <b>200</b>.</p><p id="p-0069" num="0068">In some implementations, in addition to processing the brain emulation subnetwork output <b>210</b> generated by the output layer of the brain emulation subnetwork <b>208</b>, the second trained subnetwork <b>212</b> can additionally process one or more intermediate outputs of the brain emulation subnetwork <b>208</b>.</p><p id="p-0070" num="0069">The neural network computing system <b>200</b> includes a training engine <b>216</b> that is configured to train the neural network <b>202</b>.</p><p id="p-0071" num="0070">In some implementations, the model parameters <b>224</b> for the brain emulation subnetwork <b>208</b> are untrained. Instead, the model parameters <b>224</b> of the brain emulation subnetwork <b>208</b> can be determined before the training of the trained subnetworks <b>204</b> and <b>212</b> based on the weight values of the edges in the synaptic connectivity graph. Optionally, the weight values of the edges in the synaptic connectivity graph can be transformed (e.g., by additive random noise) prior to being used for specifying model parameters <b>224</b> of the brain emulation subnetwork <b>208</b>. This procedure enables the neural network <b>202</b> to take advantage of the information from the synaptic connectivity graph encoded into the brain emulation subnetwork <b>208</b> in performing prediction tasks.</p><p id="p-0072" num="0071">Therefore, rather than training the entire neural network <b>202</b> from end-to-end, the training engine <b>216</b> can train only the model parameters <b>222</b> of the first trained subnetwork <b>204</b> and the model parameters <b>226</b> of the second trained subnetwork <b>212</b>, while leaving the model parameters <b>224</b> of the brain emulation subnetwork <b>208</b> fixed during training.</p><p id="p-0073" num="0072">The training engine <b>216</b> can train the neural network <b>202</b> on a set of training data over multiple training iterations. The training data can include a set of training examples, where each training example specifies: (i) a training network input, and (ii) a target network output that should be generated by the neural network <b>202</b> by processing the training network input.</p><p id="p-0074" num="0073">At each training iteration, the training engine <b>216</b> can sample a batch of training examples from the training data, and process the training inputs specified by the training examples using the neural network <b>202</b> to generate corresponding network outputs <b>214</b>. In particular, for each training input, the neural network <b>202</b> processes the training input using the current model parameter values <b>222</b> of the first trained subnetwork <b>204</b> to generate a first subnetwork output <b>206</b>. The neural network <b>202</b> processes the first subnetwork output <b>206</b> in accordance with the static model parameter values <b>224</b> of the brain emulation subnetwork <b>208</b> to generate a brain emulation subnetwork output <b>210</b>. The neural network <b>202</b> then processes the brain emulation subnetwork output <b>210</b> using the current model parameter values <b>226</b> of the second trained subnetwork <b>212</b> to generate the network output <b>214</b> corresponding to the training input.</p><p id="p-0075" num="0074">The training engine <b>216</b> adjusts the model parameters values <b>222</b> of the first trained subnetwork <b>204</b> and the model parameter values <b>226</b> of the second trained subnetwork <b>212</b> to optimize an objective function that measures a similarity between: (i) the network outputs <b>214</b> generated by the neural network <b>202</b>, and (ii) the target network outputs specified by the training examples. The objective function can be, e.g., a cross-entropy objective function, a squared-error objective function, or any other appropriate objective function.</p><p id="p-0076" num="0075">To optimize the objective function, the training engine <b>216</b> can determine gradients of the objective function with respect to the model parameters <b>222</b> of the first trained subnetwork <b>204</b> and the model parameters <b>226</b> of the second trained subnetwork <b>212</b>, e.g., using backpropagation techniques. The training engine <b>216</b> can then use the gradients to adjust the model parameter values <b>222</b> and <b>226</b>, e.g., using any appropriate gradient descent optimization technique, e.g., an RMSprop or Adam gradient descent optimization technique.</p><p id="p-0077" num="0076">The training engine <b>216</b> can use any of a variety of regularization techniques during training of the neural network <b>202</b>. For example, the training engine <b>216</b> can use a dropout regularization technique, such that certain artificial neurons of the neural network <b>202</b> are &#x201c;dropped out&#x201d; (e.g., by having their output set to zero) with a non-zero probability p&#x3e;0 each time the neural network <b>202</b> processes a network input. Using the dropout regularization technique can improve the performance of the trained neural network <b>202</b>, e.g., by reducing the likelihood of over-fitting. As another example, the training engine <b>216</b> can regularize the training of the neural network <b>202</b> by including a &#x201c;penalty&#x201d; term in the objective function that measures the magnitude of the model parameter values <b>222</b> and <b>226</b> of the trained subnetworks <b>204</b> and <b>212</b>. The penalty term can be, e.g., an L<sub>1 </sub>or L<sub>2 </sub>norm of the model parameter values <b>222</b> of the first trained subnetwork <b>204</b> and/or the model parameter values <b>226</b> of the second trained subnetwork <b>212</b>. In some other implementations, the model parameters <b>224</b> for the brain emulation subnetwork <b>208</b> are trained. That is, after initial values for the model parameters <b>224</b> of the brain emulation subnetwork <b>208</b> have been determined based on the weight values of the edges in the synaptic connectivity graph, the training engine <b>216</b> can update the weights of the model parameters, as described above with reference to the parameters <b>222</b> and <b>226</b> of the trained subnetworks, e.g., using backpropagation and stochastic gradient descent.</p><p id="p-0078" num="0077">Because the weight matrices of the brain emulation neural network layers of the brain emulation subnetwork <b>208</b> using the compressed matrix representation, the training engine <b>216</b> can efficiently update the represented brain emulation parameters of the weight matrices while keeping the unrepresented brain emulation parameters of the weight matrices constant, i.e., at zero. That is, if the weight matrices were represented fully and the training engine <b>216</b> executed backpropagation and gradient descent across all the values of the weight matrices, unrepresented brain emulation parameters having value zero would likely be updated to non-zero values. Because the weight matrices represent synaptic connectivity between neurons in the brain of a biological organism, updating a unrepresented, zero-value brain emulation parameter to have a non-zero value corresponds to incorrectly representing synaptic connectivity between the pair of neurons represented by the brain emulation parameter, when no such synaptic connectivity was measured in the brain of the biological organism. Thus, in some implementations in which fidelity to the measured synaptic connectivity is important, representing the weight matrices using the compressed matrix representation allows the training engine <b>216</b> to efficiently update the weight matrices of the brain emulation subnetwork <b>208</b> without inserting representations of new and incorrect synaptic connections.</p><p id="p-0079" num="0078">In some implementations, the training engine <b>216</b> does update which brain emulation parameters of the weight matrices are represented and which brain emulation parameters are unrepresented. That is, during training of the neural network <b>202</b>, the training engine <b>216</b> can update the compressed matrix representations of the weight matrices such that brain emulation parameters are added to the compressed matrix representations (e.g., corresponding to changing a zero-value brain emulation parameter to a non-zero brain emulation parameter) and some brain emulation parameters are removed from the compressed matrix representation (e.g., corresponding to changing a non-zero brain emulation parameter to a zero-value brain emulation parameter).</p><p id="p-0080" num="0079">In particular, for one or more weight matrices of respective brain emulation neural network layers, the training engine <b>216</b> can execute an artificial evolutionary procedure whereby, over multiple training stages, the training engine <b>216</b> iteratively removes the brain emulation parameters representing the weakest synaptic connections in the brain of the biological organism from the compressed matrix representation of the weight matrix. The training engine <b>216</b> can also add new brain emulation parameters to the compressed matrix representation of the weight matrix, where the new brain emulation parameters represent &#x201c;new&#x201d; synaptic connections in the brain of the biological organism (i.e., synaptic connections that were not measured in the brain of the biological organism).</p><p id="p-0081" num="0080">This procedure is referred to as &#x201c;evolutionary&#x201d; because it simulates, across the multiple training stages, the removal of &#x201c;weak&#x201d; brain emulation parameters (e.g., brain emulation parameters with the lowest value or magnitude) and the addition of new brain emulation parameters that may improve the performance of the neural network <b>202</b>. Performing the evolutionary procedure can further reduce the amount of training data and the number of training iterations required to train the neural network <b>202</b> to achieve an acceptable level of performance, e.g., as measured by prediction accuracy.</p><p id="p-0082" num="0081">For example, at each of one or more training stages during the training of the neural network <b>202</b> and for each of one or more weight matrices of the brain emulation subnetwork <b>208</b>, the training engine <b>216</b> can stochastically sample (i.e., select) represented brain emulation parameters of the compressed matrix representation of the weight matrix, and remove the sampled represented brain emulation parameters from the compressed matrix representation.</p><p id="p-0083" num="0082">As a particular example, the training engine <b>216</b> can sample each represented brain emulation parameter with a uniform likelihood. That is, each represented brain emulation parameter can have the same likelihood of being selected, regardless of the value of the parameter of the position of the parameter within the compressed matrix representation. As another particular example, the training engine <b>216</b> can determine the N represented brain emulation parameters that have the lowest respective magnitudes, N&#x3e;1, and sample the N represented brain emulation parameters uniformly. For instance, N can be a predetermined integer, or N can be a predetermined fraction of the total number of represented brain emulation parameters in the compressed matrix representation.</p><p id="p-0084" num="0083">As another particular example, the training engine <b>216</b> can sample each represented brain emulation parameter with a likelihood that is inversely proportional with the magnitude of its value. That is, represented brain emulation parameters with lower magnitudes can be more likely to be selected than represented brain emulation parameters with higher magnitudes.</p><p id="p-0085" num="0084">In some such implementations, the training engine <b>216</b> can determine the likelihood of sampling each represented brain emulation parameter to be equal to the softmax of the negated magnitude of the represented brain emulation parameter. That is, the training engine <b>216</b> can compute:</p><p id="p-0086" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <msub>   <mi>p</mi>   <mi>i</mi>  </msub>  <mo>=</mo>  <mfrac>   <msup>    <mi>e</mi>    <mrow>     <mo>-</mo>     <mrow>      <semantics definitionURL="">       <mo>&#x2758;</mo>       <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>      </semantics>      <msub>       <mi>x</mi>       <mi>i</mi>      </msub>      <semantics definitionURL="">       <mo>&#x2758;</mo>       <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>      </semantics>     </mrow>    </mrow>   </msup>   <mrow>    <msub>     <mi>&#x3a3;</mi>     <mi>j</mi>    </msub>    <mo>&#x2062;</mo>    <msup>     <mi>e</mi>     <mrow>      <mo>-</mo>      <mrow>       <semantics definitionURL="">        <mo>&#x2758;</mo>        <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>       </semantics>       <msub>        <mi>x</mi>        <mi>j</mi>       </msub>       <semantics definitionURL="">        <mo>&#x2758;</mo>        <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>       </semantics>      </mrow>     </mrow>    </msup>   </mrow>  </mfrac> </mrow></math></maths></p><p id="p-0087" num="0085">where x<sub>i </sub>is the value of the i<sup>th </sup>represented brain emulation parameter and p<sub>i </sub>is the likelihood with which the i<sup>th </sup>represented brain emulation parameter is sampled by the training engine <b>216</b>.</p><p id="p-0088" num="0086">In some other such implementations, the training engine <b>216</b> can determine the likelihood of sampling each represented brain emulation parameter to be equal to the softmax of the inverse magnitude of the represented brain emulation parameter. That is, the training engine <b>216</b> can compute:</p><p id="p-0089" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mrow>  <msub>   <mi>p</mi>   <mi>i</mi>  </msub>  <mo>=</mo>  <mfrac>   <msup>    <mi>e</mi>    <mrow>     <mn>1</mn>     <mo>/</mo>     <mrow>      <semantics definitionURL="">       <mo>&#x2758;</mo>       <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>      </semantics>      <msub>       <mi>x</mi>       <mi>i</mi>      </msub>      <semantics definitionURL="">       <mo>&#x2758;</mo>       <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>      </semantics>     </mrow>    </mrow>   </msup>   <mrow>    <msub>     <mi>&#x3a3;</mi>     <mi>j</mi>    </msub>    <mo>&#x2062;</mo>    <msup>     <mi>e</mi>     <mrow>      <mn>1</mn>      <mo>/</mo>      <mrow>       <semantics definitionURL="">        <mo>&#x2758;</mo>        <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>       </semantics>       <msub>        <mi>x</mi>        <mi>j</mi>       </msub>       <semantics definitionURL="">        <mo>&#x2758;</mo>        <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>       </semantics>      </mrow>     </mrow>    </msup>   </mrow>  </mfrac> </mrow></math></maths></p><p id="p-0090" num="0087">In some other such implementations, the training engine <b>216</b> can determine the N represented brain emulation parameters that have the lowest respective magnitudes, N&#x3e;1, and sample the N represented brain emulation parameters according to either of the softmax equations described above.</p><p id="p-0091" num="0088">As another particular example, the training engine <b>216</b> can sample each represented brain emulation parameter with a likelihood that is inversely proportional to the rank of the represented brain emulation parameter in a ranking of the represented brain emulation parameters of the weight matrix. That is, represented brain emulation parameters with lower ranks in the ranking of the magnitudes can be more likely to be selected than represented brain parameters with higher ranks in the ranking of the magnitudes. In some such implementations, the training engine <b>216</b> can determine the N represented brain emulation parameters that have the lowest respective ranks in the ranking of the magnitudes, N&#x3e;1, and sample the N represented brain emulation parameters according to their respective ranks.</p><p id="p-0092" num="0089">As another example, the training engine <b>216</b> can execute a two-step process for stochastically sampling the represented brain emulation parameters of the compressed matrix representation. In the first step of the two-step process, the training engine <b>216</b> can generate a set of candidate represented brain emulation parameters by sampling the represented brain emulation parameters according to a ranking of their magnitudes. In the second step of the two-step process, the training engine <b>216</b> can sample from the set of represented brain emulation parameters according to their magnitudes (e.g., using a softmax function as described above). The training engine <b>216</b> can then remove the candidate represented brain emulation parameters samples in the second step from the compressed matrix representation.</p><p id="p-0093" num="0090">In some implementations, the training engine <b>216</b> removes the same number of represented brain emulation parameters at each training stage. In some other implementations, the training engine <b>216</b> can sample a different number of represented brain emulation parameters at each training stage.</p><p id="p-0094" num="0091">Instead of or in addition to removing represented brain emulation parameters from the compressed matrix representation, the training engine <b>216</b> can add &#x201c;new&#x201d; represented brain emulation parameters to the compressed matrix representation at each of one or more training stages. For example, training engine <b>216</b> can randomly sample one or more unrepresented brain emulation parameters of the compressed matrix representation, generate values for the sampled unrepresented brain emulation parameters, and insert the sampled unrepresented brain emulation parameters, having the respective generated values, into the compressed matrix representation as newly-represented brain emulation parameters.</p><p id="p-0095" num="0092">For example, the training engine <b>216</b> can sample a respective value for each new represented brain emulation parameter from a predefined distribution, e.g., a uniform distribution between 0 and 1 or a Normal distribution with mean 0.</p><p id="p-0096" num="0093">As another example, the training engine <b>216</b> can determine the initial value of the new represented brain emulation parameters to be 0. As described above, in some cases, a brain emulation parameter can have a value of zero and still be explicitly represented in the compressed matrix representation. So, the training engine <b>216</b> can explicitly add a representation of the previously-unrepresented brain emulation parameters to the compressed matrix representation, and set their values to be zero. Then, during training of the neural network <b>202</b>, the value of these new non-zero brain emulation parameters can be updated to have non-zero values, e.g., using stochastic gradient descent.</p><p id="p-0097" num="0094">In some implementations, the training engine <b>216</b> samples the same number of unrepresented brain emulation parameters as the number of represented value brain emulation parameters sampled as described above. That is, the compressed matrix representation can include the same number of represented brain emulation parameters before and after the training stage. In some other implementations, the training engine <b>216</b> samples a different number of represented and unrepresented brain emulation parameters during a given training stage, such that the number of represented brain emulation parameters in the compressed matrix representation changes.</p><p id="p-0098" num="0095">In some implementations, the training engine <b>216</b> can sample new represented brain emulation parameters to add to the compressed matrix representation such that the sampled new represented brain emulation parameters are biologically plausible. That is, the training engine <b>216</b> can ensure that each new represented brain emulation parameter represents a pair of neurons that could plausibly share a synaptic connection in the brain of the biological organism. For example, the training engine <b>216</b> can sample represented brain emulation parameters corresponding to pairs of neurons in the same region of the brain of the biological organism.</p><p id="p-0099" num="0096">The neural network <b>202</b> can be configured to perform any appropriate task. A few examples follow.</p><p id="p-0100" num="0097">In one example, the neural network <b>202</b> can be configured to process network inputs <b>201</b> that represent sequences of audio data. For example, each input element in the network input <b>201</b> can be a raw audio sample or an input generated from a raw audio sample (e.g., a spectrogram), and the neural network <b>202</b> can process the sequence of input elements to generate network outputs <b>214</b> representing predicted text samples that correspond to the audio samples. That is, the neural network <b>202</b> can be a &#x201c;speech-to-text&#x201d; neural network. As another example, each input element can be a raw audio sample or an input generated from a raw audio sample, and the neural network <b>202</b> can generate a predicted class of the audio samples, e.g., a predicted identification of a speaker corresponding to the audio samples. As a particular example, the predicted class of the audio sample can represent a prediction of whether the input audio example is a verbalization of a predefined work or phrase, e.g., a &#x201c;wakeup&#x201d; phrase of a mobile device. In some implementations, one or more weight matrices of the brain emulation subnetwork <b>208</b> can be generated from a subgraph of the synaptic connectivity graph corresponding to an audio region of the brain, i.e., a region of the brain that processes auditory information (e.g., the auditory cortex).</p><p id="p-0101" num="0098">In another example, the neural network <b>202</b> can be configured to process network inputs <b>201</b> that represent sequences of text data. For example, each input element in the network input <b>201</b> can be a text sample (e.g., a character, phoneme, or word) or an embedding of a text sample, and the neural network <b>202</b> can process the sequence of input elements to generate network outputs <b>214</b> representing predicted audio samples that correspond to the text samples. That is, the neural network <b>202</b> can be a &#x201c;text-to-speech&#x201d; neural network. As another example, each input element can be an input text sample or an embedding of an input text sample, and the neural network <b>202</b> can generate a network output <b>214</b> representing a sequence of output text samples corresponding to the sequences of input text samples. As a particular example, the output text samples can represent the same text as the input text samples in a different language (i.e., the neural network <b>202</b> can be a machine translation neural network). As another particular example, the output text samples can represent an answer to a question posed by the input text samples (i.e., the neural network <b>202</b> can be a question-answering neural network). As another example, the input text samples can represent two texts (e.g., as separated by a delimiter token), and the neural network <b>202</b> can generate a network output representing a predicted similarity between the two texts. In some implementations, one or more weight matrices of the brain emulation subnetwork <b>208</b> can be generated from a subgraph of the synaptic connectivity graph corresponding to a speech region of the brain, i.e., a region of the brain that is linked to speech production (e.g., Broca's area).</p><p id="p-0102" num="0099">In another example, the neural network <b>202</b> can be configured to process network inputs <b>201</b> representing one or more images, e.g., sequences of video frames. For example, each input element in the network input <b>201</b> can be a video frame or an embedding of a video frame, and the neural network <b>202</b> can process the sequence of input elements to generate a network output <b>214</b> representing a prediction about the video represented by the sequence of video frames. As a particular example, the neural network <b>202</b> can be configured to track a particular object in each of the frames of the video, i.e., to generate a network output <b>214</b> that includes a sequences of output elements, where each output elements represents a predicted location within a respective video frames of the particular object. In some implementations, the brain emulation subnetwork <b>208</b> can be generated from a subgraph of the synaptic connectivity graph corresponding to a visual region of the brain, i.e., a region of the brain that processes visual information (e.g., the visual cortex).</p><p id="p-0103" num="0100">In another example, the neural network <b>202</b> can be configured to process a network input <b>201</b> representing a respective current state of an environment at each of one or more time points, and to generate a network output <b>214</b> representing action selection outputs that can be used to select actions to be performed at respective time points by an agent interacting with the environment. For example, each action selection output can specify a respective score for each action in a set of possible actions that can be performed by the agent, and the agent can select the action to be performed by sampling an action in accordance with the action scores. In one example, the agent can be a mechanical agent interacting with a real-world environment to perform a navigation task (e.g., reaching a goal location in the environment), and the actions performed by the agent cause the agent to navigate through the environment.</p><p id="p-0104" num="0101">In this specification, an embedding is an ordered collection of numeric values that represents an input in a particular embedding space. For example, an embedding can be a vector of floating point or other numeric values that has a fixed dimensionality.</p><p id="p-0105" num="0102">After training, the neural network <b>202</b> can be directly applied to perform prediction tasks. For example, the neural network <b>202</b> can be deployed onto a user device. In some implementations, the neural network <b>202</b> can be deployed directly into resource-constrained environments (e.g., mobile devices). Neural networks <b>202</b> that include brain emulation subnetworks <b>208</b> can generally perform at a high level, e.g., in terms of prediction accuracy, even with very few model parameters compared to other neural networks. For example, neural networks <b>202</b> as described in this specification that have, e.g., 100 or 1000 model parameters can achieve comparable performance to other neural networks that have millions of model parameters. Thus, the neural network <b>202</b> can be implemented efficiently and with low latency on user devices.</p><p id="p-0106" num="0103">In some implementations, after the neural network <b>202</b> has been deployed onto a user device, some of the parameters of the neural network <b>202</b> can be further trained, i.e., &#x201c;fine-tuned,&#x201d; using new training example obtained by the user device. For example, some of the parameters can be fine-tuned using training example corresponding to the specific user of the user device, so that the neural network <b>202</b> can achieve a higher accuracy for inputs provided by the specific user. As a particular example, the model parameters <b>222</b> of the first trained subnetwork <b>204</b> and/or the model parameters <b>226</b> of the second trained subnetwork <b>212</b> can be fine-tuned on the user device using new training examples while the model parameters <b>224</b> of the brain emulation subnetwork <b>208</b> are held static, as described above.</p><p id="p-0107" num="0104"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example weight matrix <b>302</b> of a brain emulation neural network layer determined using synaptic connectivity</p><p id="p-0108" num="0105">As described in more detail below with reference to <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>, a system (e.g., the graphing system <b>412</b> depicted in <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>), can generate a synaptic connectivity graph that represents the synaptic connectivity between neurons in the brain of the biological organism. The synaptic connectivity graph can be represented using an adjacency matrix <b>301</b>, all of which or a portion of which can be used as the weight matrix <b>302</b> of the brain emulation neural network layer.</p><p id="p-0109" num="0106">As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the adjacency matrix <b>301</b> includes n<sup>2 </sup>elements, where n is the number of neurons drawn from the brain of the biological organism. For example, the adjacency matrix <b>301</b> can include hundreds, thousands, tens of thousands, hundreds of thousands, millions, tens of millions, or hundreds of millions of elements.</p><p id="p-0110" num="0107">Each element of the adjacency matrix <b>301</b> represents the synaptic connectivity between a respective pair of neurons in the set of n neurons. That is, each element c<sub>i,j </sub>identifies the synaptic connection between neuron i and neuron j. As described in more detail below, in some implementations, each of the elements c<sub>i,j </sub>are either zero (representing that there is no synaptic connection between the corresponding neurons) or one (representing that there is a synaptic connection between the corresponding neurons), while in some other implementations, each element c<sub>i,j </sub>is a scalar value representing the strength of the synaptic connection between the corresponding neurons.</p><p id="p-0111" num="0108">As described above with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, each row of the adjacency matrix <b>301</b> can represent a respective neuron in a first set of neurons of the brain of the biological organism, and each column of the adjacency matrix <b>301</b> can represent a respective neuron in a second set of neurons of the brain of the biological organism. Generally, the first set and the second set can be overlapping or disjoint. As a particular example, the first set and the second set can be the same.</p><p id="p-0112" num="0109">In some implementations (e.g., in implementations in which the synaptic connectivity graph is undirected), the adjacency matrix <b>301</b> is symmetric (i.e., each element c<sub>i,j </sub>is the same as element while in some other implementations (e.g., in implementations in which the synaptic connectivity graph is directed), the adjacency matrix <b>301</b> is not symmetric (i.e., there may exist elements c<sub>i,j </sub>and c<sub>j,i </sub>such that c<sub>i,j</sub>&#x2260;c<sub>j,i</sub>).</p><p id="p-0113" num="0110">Although the above description refers to neurons in the brain of the biological organism, generally the elements of the adjacency matrix can correspond to pairs of any appropriate component of the brain of the biological organism. For example, each element can correspond to a pair of voxels in a voxel grid of the brain of the biological organism. As another example, each element can correspond to a pair of sub-neurons of the brain of the biological organism. As another example, each element can correspond to a pair of sets of multiple neurons of the brain of the biological organism.</p><p id="p-0114" num="0111">As described in more detail below with reference to <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>, an architecture mapping system (e.g., the architecture mapping system <b>420</b> depicted in <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>) can generate the weight matrix <b>302</b> from the adjacency matrix <b>301</b>. Generally, the elements of the weight matrix <b>302</b> (i.e., the brain emulation parameters of the brain emulation neural network layer) are a subset of the elements of the adjacency matrix <b>301</b>. For example, as depicted in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the weight matrix <b>302</b> includes the elements of the adjacency matrix <b>301</b> representing neuronal connections between the neurons represented by the first three rows and first three columns of the adjacency matrix <b>301</b>. For example, the weight matrix <b>302</b> can represent only neurons of a particular type in the brain of the biological organism. Identifying neurons of a particular type is discussed in more detail below with reference to <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0115" num="0112">For convenience, the weight matrix <b>302</b> is illustrated as including only nine brain emulation parameters; generally, weight matrices of brain emulation neural network layers can have significantly more brain emulation parameters, e.g., hundreds, thousands, or millions of brain emulation parameters. Although the weight matrix <b>302</b> is depicted as square in <figref idref="DRAWINGS">FIG. <b>3</b></figref> (i.e., the same number of columns and rows), generally the weight matrix <b>302</b> can have any appropriate dimensionality.</p><p id="p-0116" num="0113">The weight matrix can be a sparse matrix, i.e., can include more than a threshold number or proportion of zero-value brain emulation parameters. The weight matrix can thus be represented using a compressed matrix representation, as described above.</p><p id="p-0117" num="0114">In some implementations, the weight matrix <b>302</b> represents the entire synaptic connectivity graph. That is, the weight matrix <b>302</b> can include a respective row and column for each node of the synaptic connectivity graph. Because the weight matrix <b>302</b> will be represented using the compressed matrix representation when applied by the brain emulation neural network layer, representing the entire synaptic connectivity graph is significantly more feasible and efficient than if the weight matrix <b>302</b> were represented fully. Thus, in memory-constrained or computationally-constrained environments, leveraging the compressed matrix representation can allow systems to represent the full brain of the biological organism in implementations in which doing so would otherwise be prohibitive.</p><p id="p-0118" num="0115"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> illustrates an example of generating an artificial (i.e., computer implemented) brain emulation neural network <b>409</b> based on a synaptic resolution image <b>405</b> of the brain <b>403</b> of a biological organism <b>401</b>, e.g., a fly. The synaptic resolution image <b>405</b> can be processed to generate a synaptic connectivity graph <b>407</b>, e.g., where each node of the graph <b>407</b> corresponds to a neuron in the brain <b>403</b>, and two nodes in the graph <b>407</b> are connected if the corresponding neurons in the brain <b>403</b> share a synaptic connection. The structure of the graph <b>407</b> can be used to specify the architecture of the brain emulation neural network <b>409</b>. For example, each node of the graph <b>407</b> can mapped to an artificial neuron, a neural network layer, or a group of neural network layers in the brain emulation neural network <b>409</b>. Further, each edge of the graph <b>407</b> can be mapped to a connection between artificial neurons, layers, or groups of layers in the brain emulation neural network <b>409</b>. The brain <b>403</b> of the biological organism <b>401</b> can be adapted by evolutionary pressures to be effective at solving certain tasks, e.g., classifying objects or generating robust object representations, and the brain emulation neural network <b>409</b> can share this capacity to effectively solve tasks.</p><p id="p-0119" num="0116"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> shows an example data flow <b>400</b> for generating a synaptic connectivity graph <b>402</b> and a brain emulation neural network <b>404</b> based on the brain <b>406</b> of a biological organism.</p><p id="p-0120" num="0117">As used throughout this document, a brain may refer to any amount of nervous tissue from a nervous system of a biological organism, and nervous tissue may refer to any tissue that includes neurons (i.e., nerve cells). The biological organism can be, e.g., a worm, a fly, a mouse, a cat, or a human.</p><p id="p-0121" num="0118">An imaging system <b>408</b> can be used to generate a synaptic resolution image <b>410</b> of the brain <b>406</b>. An image of the brain <b>406</b> may be referred to as having synaptic resolution if it has a spatial resolution that is sufficiently high to enable the identification of at least some synapses in the brain <b>406</b>. Put another way, an image of the brain <b>406</b> may be referred to as having synaptic resolution if it depicts the brain <b>406</b> at a magnification level that is sufficiently high to enable the identification of at least some synapses in the brain <b>406</b>. The image <b>410</b> can be a volumetric image, i.e., that characterizes a three-dimensional representation of the brain <b>406</b>. The image <b>410</b> can be represented in any appropriate format, e.g., as a three-dimensional array of numerical values.</p><p id="p-0122" num="0119">The imaging system <b>408</b> can be any appropriate system capable of generating synaptic resolution images, e.g., an electron microscopy system. The imaging system <b>408</b> can process &#x201c;thin sections&#x201d; from the brain <b>406</b> (i.e., thin slices of the brain attached to slides) to generate output images that each have a field of view corresponding to a proper subset of a thin section. The imaging system <b>408</b> can generate a complete image of each thin section by stitching together the images corresponding to different fields of view of the thin section using any appropriate image stitching technique. The imaging system <b>408</b> can generate the volumetric image <b>410</b> of the brain by registering and stacking the images of each thin section. Registering two images refers to applying transformation operations (e.g., translation or rotation operations) to one or both of the images to align them. Example techniques for generating a synaptic resolution image of a brain are described with reference to: Z. Zheng, et al., &#x201c;A complete electron microscopy volume of the brain of adult <i>Drosophila melanogaster</i>,&#x201d; Cell 174, 730-743 (2018).</p><p id="p-0123" num="0120">A graphing system <b>412</b> is configured to process the synaptic resolution image <b>410</b> to generate the synaptic connectivity graph <b>402</b>. The synaptic connectivity graph <b>402</b> specifies a set of nodes and a set of edges, such that each edge connects two nodes. To generate the graph <b>402</b>, the graphing system <b>412</b> identifies each neuron in the image <b>410</b> as a respective node in the graph, and identifies each synaptic connection between a pair of neurons in the image <b>410</b> as an edge between the corresponding pair of nodes in the graph.</p><p id="p-0124" num="0121">The graphing system <b>412</b> can identify the neurons and the synapses depicted in the image <b>410</b> using any of a variety of techniques. For example, the graphing system <b>412</b> can process the image <b>410</b> to identify the positions of the neurons depicted in the image <b>410</b>, and determine whether a synapse connects two neurons based on the proximity of the neurons (as will be described in more detail below). In this example, the graphing system <b>412</b> can process an input including: (i) the image, (ii) features derived from the image, or (iii) both, using a machine learning model that is trained using supervised learning techniques to identify neurons in images. The machine learning model can be, e.g., a convolutional neural network model or a random forest model. The output of the machine learning model can include a neuron probability map that specifies a respective probability that each voxel in the image is included in a neuron. The graphing system <b>412</b> can identify contiguous clusters of voxels in the neuron probability map as being neurons.</p><p id="p-0125" num="0122">Optionally, prior to identifying the neurons from the neuron probability map, the graphing system <b>412</b> can apply one or more filtering operations to the neuron probability map, e.g., with a Gaussian filtering kernel. Filtering the neuron probability map can reduce the amount of &#x201c;noise&#x201d; in the neuron probability map, e.g., where only a single voxel in a region is associated with a high likelihood of being a neuron.</p><p id="p-0126" num="0123">The machine learning model used by the graphing system <b>412</b> to generate the neuron probability map can be trained using supervised learning training techniques on a set of training data. The training data can include a set of training examples, where each training example specifies: (i) a training input that can be processed by the machine learning model, and (ii) a target output that should be generated by the machine learning model by processing the training input. For example, the training input can be a synaptic resolution image of a brain, and the target output can be a &#x201c;label map&#x201d; that specifies a label for each voxel of the image indicating whether the voxel is included in a neuron. The target outputs of the training examples can be generated by manual annotation, e.g., where a person manually specifies which voxels of a training input are included in neurons.</p><p id="p-0127" num="0124">Example techniques for identifying the positions of neurons depicted in the image <b>410</b> using neural networks (in particular, flood-filling neural networks) are described with reference to: P. H. Li et al.: &#x201c;Automated Reconstruction of a Serial-Section EM Drosophila Brain with Flood-Filling Networks and Local Realignment,&#x201d; bioRxiv doi:10.1101/605634 (2019).</p><p id="p-0128" num="0125">The graphing system <b>412</b> can identify the synapses connecting the neurons in the image <b>410</b> based on the proximity of the neurons. For example, the graphing system <b>412</b> can determine that a first neuron is connected by a synapse to a second neuron based on the area of overlap between: (i) a tolerance region in the image around the first neuron, and (ii) a tolerance region in the image around the second neuron. That is, the graphing system <b>412</b> can determine whether the first neuron and the second neuron are connected based on the number of spatial locations (e.g., voxels) that are included in both: (i) the tolerance region around the first neuron, and (ii) the tolerance region around the second neuron. For example, the graphing system <b>412</b> can determine that two neurons are connected if the overlap between the tolerance regions around the respective neurons includes at least a predefined number of spatial locations (e.g., one spatial location). A &#x201c;tolerance region&#x201d; around a neuron refers to a contiguous region of the image that includes the neuron. For example, the tolerance region around a neuron can be specified as the set of spatial locations in the image that are either: (i) in the interior of the neuron, or (ii) within a predefined distance of the interior of the neuron.</p><p id="p-0129" num="0126">The graphing system <b>412</b> can further identify a weight value associated with each edge in the graph <b>402</b>. For example, the graphing system <b>412</b> can identify a weight for an edge connecting two nodes in the graph <b>402</b> based on the area of overlap between the tolerance regions around the respective neurons corresponding to the nodes in the image <b>410</b> (e.g., based on a proximity of the respective neurons). The area of overlap can be measured, e.g., as the number of voxels in the image <b>410</b> that are contained in the overlap of the respective tolerance regions around the neurons. The weight for an edge connecting two nodes in the graph <b>402</b> may be understood as characterizing the (approximate) strength of the connection between the corresponding neurons in the brain (e.g., the amount of information flow through the synapse connecting the two neurons).</p><p id="p-0130" num="0127">In addition to identifying synapses in the image <b>410</b>, the graphing system <b>412</b> can further determine the direction of each synapse using any appropriate technique. The &#x201c;direction&#x201d; of a synapse between two neurons refers to the direction of information flow between the two neurons, e.g., if a first neuron uses a synapse to transmit signals to a second neuron, then the direction of the synapse would point from the first neuron to the second neuron. Example techniques for determining the directions of synapses connecting pairs of neurons are described with reference to: C. Seguin, A. Razi, and A. Zalesky: &#x201c;Inferring neural signaling directionality from undirected structure connectomes,&#x201d; Nature Communications 10, 4289 (2019), doi:10.1038/s41467-019-12201-w.</p><p id="p-0131" num="0128">In implementations where the graphing system <b>412</b> determines the directions of the synapses in the image <b>410</b>, the graphing system <b>412</b> can associate each edge in the graph <b>402</b> with the direction of the corresponding synapse. That is, the graph <b>402</b> can be a directed graph. In some other implementations, the graph <b>402</b> can be an undirected graph, i.e., where the edges in the graph are not associated with a direction.</p><p id="p-0132" num="0129">The graph <b>402</b> can be represented in any of a variety of ways. For example, the graph <b>402</b> can be represented as a two-dimensional array of numerical values with a number of rows and columns equal to the number of nodes in the graph. The component of the array at position (i,j) can have value 1 if the graph includes an edge pointing from node i to node j, and value 0 otherwise. In implementations where the graphing system <b>412</b> determines a weight value for each edge in the graph <b>402</b>, the weight values can be similarly represented as a two-dimensional array of numerical values. More specifically, if the graph includes an edge connecting node i to node j, the component of the array at position (i,j) can have a value given by the corresponding edge weight, and otherwise the component of the array at position (i,j) can have value 0.</p><p id="p-0133" num="0130">An architecture mapping system <b>420</b> can process the synaptic connectivity graph <b>402</b> to determine the architecture of the brain emulation neural network <b>404</b>. For example, the architecture mapping system <b>420</b> can map each node in the graph <b>402</b> to: (i) an artificial neuron, (ii) a neural network layer, or (iii) a group of neural network layers, in the architecture of the brain emulation neural network <b>404</b>. The architecture mapping system <b>420</b> can further map each edge of the graph <b>402</b> to a connection in the brain emulation neural network <b>404</b>, e.g., such that a first artificial neuron that is connected to a second artificial neuron is configured to provide its output to the second artificial neuron. In some implementations, the architecture mapping system <b>420</b> can apply one or more transformation operations to the graph <b>402</b> before mapping the nodes and edges of the graph <b>402</b> to corresponding components in the architecture of the brain emulation neural network <b>404</b>, as will be described in more detail below. An example architecture mapping system is described in more detail below with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0134" num="0131">The brain emulation neural network <b>404</b> can be provided to a training system <b>414</b> that trains the brain emulation neural network using machine learning techniques, i.e., generates an update to the respective values of one or more parameters of the brain emulation neural network.</p><p id="p-0135" num="0132">In some implementations, the training system <b>414</b> is a supervised training system that is configured to train the brain emulation neural network <b>404</b> using a set of training data. The training data can include multiple training examples, where each training example specifies: (i) a training input, and (ii) a corresponding target output that should be generated by the brain emulation neural network <b>404</b> by processing the training input. In one example, the direct training system <b>414</b> can train the brain emulation neural network <b>404</b> over multiple training iterations using a gradient descent optimization technique, e.g., stochastic gradient descent. In this example, at each training iteration, the direct training system <b>414</b> can sample a &#x201c;batch&#x201d; (set) of one or more training examples from the training data, and process the training inputs specified by the training examples to generate corresponding network outputs. The direct training system <b>414</b> can evaluate an objective function that measures a similarity between: (i) the target outputs specified by the training examples, and (ii) the network outputs generated by the brain emulation neural network, e.g., a cross-entropy or squared-error objective function. The direct training system <b>414</b> can determine gradients of the objective function, e.g., using backpropagation techniques, and update the parameter values of the brain emulation neural network <b>404</b> using the gradients, e.g., using any appropriate gradient descent optimization algorithm, e.g., RMSprop or Adam.</p><p id="p-0136" num="0133">In some other implementations, the training system <b>414</b> is an adversarial training system that is configured to train the brain emulation neural network <b>404</b> in an adversarial fashion. For example, the training system <b>414</b> can include a discriminator neural network that is configured to process network outputs generated by the brain emulation neural network <b>404</b> to generate a prediction of whether the network outputs are &#x201c;real&#x201d; outputs (i.e., outputs that were not generated by the brain emulation neural network, e.g., outputs that represent data that was captured from the real world) or &#x201c;synthetic&#x201d; outputs (i.e., outputs generated by the brain emulation neural network <b>404</b>). The training system can then determine an update to the parameters of the brain emulation neural network in order to increase an error in the prediction of the discriminator neural network; that is, the goal of the brain emulation neural network is to generate synthetic outputs that are realistic enough that the discriminator neural network predicts them to be real outputs. In some implementations, concurrently with training the brain emulation neural network <b>404</b>, the training system <b>414</b> generates updates to the parameters of the discriminator neural network.</p><p id="p-0137" num="0134">In some other implementations, the training system <b>414</b> is a distillation training system that is configured to use the brain emulation neural network <b>404</b> to facilitate training of a &#x201c;student&#x201d; neural network having a less complex architecture than the brain emulation neural network <b>404</b>. The complexity of a neural network architecture can be measured, e.g., by the number of parameters required to specify the operations performed by the neural network. The training system <b>414</b> can train the student neural network to match the outputs generated by the brain emulation neural network. After training, the student neural network can inherit the capacity of the brain emulation neural network <b>404</b> to effectively solve certain tasks, while consuming fewer computational resources (e.g., memory and computing power) than the brain emulation neural network <b>404</b>. Typically, the training system <b>414</b> does not update the parameters of the brain emulation neural network <b>404</b> while training the student neural network. That is, in these implementations, the training system <b>414</b> is configured to train the student neural network instead of the brain emulation neural network <b>404</b>.</p><p id="p-0138" num="0135">As a particular example, the training system <b>414</b> can be a distillation training system that trains the student neural network in an adversarial manner. For example, the training system <b>414</b> can include a discriminator neural network that is configured to process network outputs that were generated either by the brain emulation neural network <b>404</b> or the student neural network, and to generate a prediction of whether the network outputs where generated by the brain emulation neural network <b>404</b> or the student neural network. The training system can then determine an update to the parameters of the student neural network in order to increase an error in the prediction of the discriminator neural network; that is, the goal of the student neural network is to generate network outputs that resemble network outputs generated by the brain emulation neural network <b>402</b> so that the discriminator neural network predicts that they were generated by the brain emulation neural network <b>404</b>.</p><p id="p-0139" num="0136">In some implementations, the brain emulation neural network <b>404</b> is a subnetwork of a neural network that includes one or more other neural network layers, e.g., one or more other subnetworks.</p><p id="p-0140" num="0137">For example, the brain emulation neural network <b>404</b> can be a subnetwork of a &#x201c;reservoir computing&#x201d; neural network. The reservoir computing neural network can include i) the brain emulation neural network, which includes untrained parameters, and ii) one or more other subnetworks that include trained parameters. For example, the reservoir computing neural network can be configured to process a network input using the brain emulation neural network <b>404</b> to generate an alternative representation of the network input, and process the alternative representation of the network input using a &#x201c;prediction&#x201d; subnetwork to generate a network output.</p><p id="p-0141" num="0138">During training of the reservoir computing neural network, the parameter values of the one or more other subnetworks (e.g., the prediction subnetwork) are trained, but the parameter values of the brain emulation neural network <b>404</b> are static, i.e., are not trained. Instead of being trained, the parameter values of the brain emulation neural network <b>404</b> can be determined from the weight values of the edges of the synaptic connectivity graph, as will be described in more detail below. The reservoir computing neural network facilitates application of the brain emulation neural network to machine learning tasks by obviating the need to train the parameter values of the brain emulation neural network <b>404</b>.</p><p id="p-0142" num="0139">After the training system <b>414</b> has completed training the brain emulation neural network <b>404</b> (or a neural network that includes the brain emulation neural network as a subnetwork, or a student neural network trained using the brain emulation neural network), the brain emulation neural network <b>404</b> can be deployed by a deployment system <b>422</b>. That is, the operations of the brain emulation neural network <b>404</b> can be implemented on a device or a system of devices for performing inference, i.e., receiving network inputs and processing the network inputs to generate network outputs. In some implementations, the brain emulation neural network <b>404</b> can be deployed onto a cloud system, i.e., a distributed computing system having multiple computing nodes, e.g., hundreds or thousands of computing nodes, in one or more locations. In some other implementations, the brain emulation neural network <b>404</b> can be deployed onto a user device.</p><p id="p-0143" num="0140">For example, the brain emulation neural network <b>404</b> (or a neural network that includes the brain emulation neural network as a subnetwork, or a student neural network that has been trained using the brain emulation neural network) can be deployed as a recurrent neural network that is configured to process a sequence of network inputs, as described above.</p><p id="p-0144" num="0141"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows an example architecture mapping system <b>500</b>. The architecture mapping system <b>500</b> is an example of a system implemented as computer programs on one or more computers in one or more locations in which the systems, components, and techniques described below are implemented.</p><p id="p-0145" num="0142">The architecture mapping system <b>500</b> is configured to process a synaptic connectivity graph <b>501</b> (e.g., the synaptic connectivity graph <b>402</b> depicted in <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>) to determine a corresponding neural network architecture <b>502</b> of a brain emulation neural network <b>516</b> (e.g., the brain emulation neural network <b>404</b> depicted in <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>). The architecture mapping system <b>500</b> can determine the architecture <b>502</b> using one or more of: a transformation engine <b>504</b>, a feature generation engine <b>506</b>, a node classification engine <b>508</b>, and a nucleus classification engine <b>518</b>, which will each be described in more detail next.</p><p id="p-0146" num="0143">The transformation engine <b>504</b> can be configured to apply one or more transformation operations to the synaptic connectivity graph <b>501</b> that alter the connectivity of the graph <b>501</b>, i.e., by adding or removing edges from the graph. A few examples of transformation operations follow.</p><p id="p-0147" num="0144">In one example, to apply a transformation operation to the graph <b>501</b>, the transformation engine <b>504</b> can randomly sample a set of node pairs from the graph (i.e., where each node pair specifies a first node and a second node). For example, the transformation engine can sample a predefined number of node pairs in accordance with a uniform probability distribution over the set of possible node pairs. For each sampled node pair, the transformation engine <b>504</b> can modify the connectivity between the two nodes in the node pair with a predefined probability (e.g., 0.1%). In one example, the transformation engine <b>504</b> can connect the nodes by an edge (i.e., if they are not already connected by an edge) with the predefined probability. In another example, the transformation engine <b>504</b> can reverse the direction of any edge connecting the two nodes with the predefined probability. In another example, the transformation engine <b>504</b> can invert the connectivity between the two nodes with the predefined probability, i.e., by adding an edge between the nodes if they are not already connected, and by removing the edge between the nodes if they are already connected.</p><p id="p-0148" num="0145">In another example, the transformation engine <b>504</b> can apply a convolutional filter to a representation of the graph <b>501</b> as a two-dimensional array of numerical values. As described above, the graph <b>501</b> can be represented as a two-dimensional array of numerical values where the component of the array at position (i,j) can have value 1 if the graph includes an edge pointing from node i to node j, and value 0 otherwise. The convolutional filter can have any appropriate kernel, e.g., a spherical kernel or a Gaussian kernel. After applying the convolutional filter, the transformation engine <b>504</b> can quantize the values in the array representing the graph, e.g., by rounding each value in the array to 0 or 1, to cause the array to unambiguously specify the connectivity of the graph. Applying a convolutional filter to the representation of the graph <b>501</b> can have the effect of regularizing the graph, e.g., by smoothing the values in the array representing the graph to reduce the likelihood of a component in the array having a different value than many of its neighbors.</p><p id="p-0149" num="0146">In some cases, the graph <b>501</b> can include some inaccuracies in representing the synaptic connectivity in the biological brain. For example, the graph can include nodes that are not connected by an edge despite the corresponding neurons in the brain being connected by a synapse, or &#x201c;spurious&#x201d; edges that connect nodes in the graph despite the corresponding neurons in the brain not being connected by a synapse. Inaccuracies in the graph can result, e.g., from imaging artifacts or ambiguities in the synaptic resolution image of the brain that is processed to generate the graph. Regularizing the graph, e.g., by applying a convolutional filter to the representation of the graph, can increase the accuracy with which the graph represents the synaptic connectivity in the brain, e.g., by removing spurious edges.</p><p id="p-0150" num="0147">The architecture mapping system <b>500</b> can use the feature generation engine <b>506</b> and the node classification engine <b>508</b> to determine predicted &#x201c;types&#x201d; <b>510</b> of the neurons corresponding to the nodes in the graph <b>501</b>. The type of a neuron can characterize any appropriate aspect of the neuron. In one example, the type of a neuron can characterize the function performed by the neuron in the brain, e.g., a visual function by processing visual data, an olfactory function by processing odor data, or a memory function by retaining information. After identifying the types of the neurons corresponding to the nodes in the graph <b>501</b>, the architecture mapping system <b>500</b> can identify a sub-graph <b>512</b> of the overall graph <b>501</b> based on the neuron types, and determine the neural network architecture <b>502</b> based on the sub-graph <b>512</b>. The feature generation engine <b>506</b> and the node classification engine <b>508</b> are described in more detail next.</p><p id="p-0151" num="0148">The feature generation engine <b>506</b> can be configured to process the graph <b>501</b> (potentially after it has been modified by the transformation engine <b>504</b>) to generate one or more respective node features <b>514</b> corresponding to each node of the graph <b>501</b>. The node features corresponding to a node can characterize the topology (i.e., connectivity) of the graph relative to the node. In one example, the feature generation engine <b>506</b> can generate a node degree feature for each node in the graph <b>501</b>, where the node degree feature for a given node specifies the number of other nodes that are connected to the given node by an edge. In another example, the feature generation engine <b>506</b> can generate a path length feature for each node in the graph <b>501</b>, where the path length feature for a node specifies the length of the longest path in the graph starting from the node. A path in the graph may refer to a sequence of nodes in the graph, such that each node in the path is connected by an edge to the next node in the path. The length of a path in the graph may refer to the number of nodes in the path. In another example, the feature generation engine <b>506</b> can generate a neighborhood size feature for each node in the graph <b>501</b>, where the neighborhood size feature for a given node specifies the number of other nodes that are connected to the node by a path of length at most N. In this example, N can be a positive integer value. In another example, the feature generation engine <b>506</b> can generate an information flow feature for each node in the graph <b>501</b>. The information flow feature for a given node can specify the fraction of the edges connected to the given node that are outgoing edges, i.e., the fraction of edges connected to the given node that point from the given node to a different node.</p><p id="p-0152" num="0149">In some implementations, the feature generation engine <b>506</b> can generate one or more node features that do not directly characterize the topology of the graph relative to the nodes. In one example, the feature generation engine <b>506</b> can generate a spatial position feature for each node in the graph <b>501</b>, where the spatial position feature for a given node specifies the spatial position in the brain of the neuron corresponding to the node, e.g., in a Cartesian coordinate system of the synaptic resolution image of the brain. In another example, the feature generation engine <b>506</b> can generate a feature for each node in the graph <b>501</b> indicating whether the corresponding neuron is excitatory or inhibitory. In another example, the feature generation engine <b>506</b> can generate a feature for each node in the graph <b>501</b> that identifies the neuropil region associated with the neuron corresponding to the node.</p><p id="p-0153" num="0150">In some cases, the feature generation engine <b>506</b> can use weights associated with the edges in the graph in determining the node features <b>514</b>. As described above, a weight value for an edge connecting two nodes can be determined, e.g., based on the area of any overlap between tolerance regions around the neurons corresponding to the nodes. In one example, the feature generation engine <b>506</b> can determine the node degree feature for a given node as a sum of the weights corresponding to the edges that connect the given node to other nodes in the graph. In another example, the feature generation engine <b>506</b> can determine the path length feature for a given node as a sum of the edge weights along the longest path in the graph starting from the node.</p><p id="p-0154" num="0151">The node classification engine <b>508</b> can be configured to process the node features <b>514</b> to identify a predicted neuron type <b>510</b> corresponding to certain nodes of the graph <b>501</b>. In one example, the node classification engine <b>508</b> can process the node features <b>514</b> to identify a proper subset of the nodes in the graph <b>501</b> with the highest values of the path length feature. For example, the node classification engine <b>508</b> can identify the nodes with a path length feature value greater than the 90th percentile (or any other appropriate percentile) of the path length feature values of all the nodes in the graph. The node classification engine <b>508</b> can then associate the identified nodes having the highest values of the path length feature with the predicted neuron type of &#x201c;primary sensory neuron.&#x201d; In another example, the node classification engine <b>508</b> can process the node features <b>514</b> to identify a proper subset of the nodes in the graph <b>501</b> with the highest values of the information flow feature, i.e., indicating that many of the edges connected to the node are outgoing edges. The node classification engine <b>508</b> can then associate the identified nodes having the highest values of the information flow feature with the predicted neuron type of &#x201c;sensory neuron.&#x201d; In another example, the node classification engine <b>508</b> can process the node features <b>514</b> to identify a proper subset of the nodes in the graph <b>501</b> with the lowest values of the information flow feature, i.e., indicating that many of the edges connected to the node are incoming edges (i.e., edges that point towards the node). The node classification engine <b>508</b> can then associate the identified nodes having the lowest values of the information flow feature with the predicted neuron type of &#x201c;associative neuron.&#x201d;</p><p id="p-0155" num="0152">The architecture mapping system <b>500</b> can identify a sub-graph <b>512</b> of the overall graph <b>501</b> based on the predicted neuron types <b>510</b> corresponding to the nodes of the graph <b>501</b>. A &#x201c;sub-graph&#x201d; may refer to a graph specified by: (i) a proper subset of the nodes of the graph <b>501</b>, and (ii) a proper subset of the edges of the graph <b>501</b>. <figref idref="DRAWINGS">FIG. <b>6</b></figref> provides an illustration of an example sub-graph of an overall graph. In one example, the architecture mapping system <b>500</b> can select: (i) each node in the graph <b>501</b> corresponding to particular neuron type, and (ii) each edge in the graph <b>501</b> that connects nodes in the graph corresponding to the particular neuron type, for inclusion in the sub-graph <b>512</b>. The neuron type selected for inclusion in the sub-graph can be, e.g., visual neurons, olfactory neurons, memory neurons, or any other appropriate type of neuron. In some cases, the architecture mapping system <b>500</b> can select multiple neuron types for inclusion in the sub-graph <b>512</b>, e.g., both visual neurons and olfactory neurons.</p><p id="p-0156" num="0153">The type of neuron selected for inclusion in the sub-graph <b>512</b> can be determined based on the task which the brain emulation neural network <b>516</b> will be configured to perform. In one example, the brain emulation neural network <b>516</b> can be configured to perform an image processing task, and neurons that are predicted to perform visual functions (i.e., by processing visual data) can be selected for inclusion in the sub-graph <b>512</b>. In another example, the brain emulation neural network <b>516</b> can be configured to perform an odor processing task, and neurons that are predicted to perform odor processing functions (i.e., by processing odor data) can be selected for inclusion in the sub-graph <b>512</b>. In another example, the brain emulation neural network <b>516</b> can be configured to perform an audio processing task, and neurons that are predicted to perform audio processing (i.e., by processing audio data) can be selected for inclusion in the sub-graph <b>512</b>.</p><p id="p-0157" num="0154">If the edges of the graph <b>501</b> are associated with weight values (as described above), then each edge of the sub-graph <b>512</b> can be associated with the weight value of the corresponding edge in the graph <b>501</b>. The sub-graph <b>512</b> can be represented, e.g., as a two-dimensional array of numerical values, as described with reference to the graph <b>501</b>.</p><p id="p-0158" num="0155">Determining the architecture <b>502</b> of the brain emulation neural network <b>516</b> based on the sub-graph <b>512</b> rather than the overall graph <b>501</b> can result in the architecture <b>502</b> having a reduced complexity, e.g., because the sub-graph <b>512</b> has fewer nodes, fewer edges, or both than the graph <b>501</b>. Reducing the complexity of the architecture <b>502</b> can reduce consumption of computational resources (e.g., memory and computing power) by the brain emulation neural network <b>516</b>, e.g., enabling the brain emulation neural network <b>516</b> to be deployed in resource-constrained environments, e.g., mobile devices. Reducing the complexity of the architecture <b>502</b> can also facilitate training of the brain emulation neural network <b>516</b>, e.g., by reducing the amount of training data required to train the brain emulation neural network <b>516</b> to achieve an threshold level of performance (e.g., prediction accuracy).</p><p id="p-0159" num="0156">In some cases, the architecture mapping system <b>500</b> can further reduce the complexity of the architecture <b>502</b> using a nucleus classification engine <b>518</b>. In particular, the architecture mapping system <b>500</b> can process the sub-graph <b>512</b> using the nucleus classification engine <b>518</b> prior to determining the architecture <b>502</b>. The nucleus classification engine <b>518</b> can be configured to process a representation of the sub-graph <b>512</b> as a two-dimensional array of numerical values (as described above) to identify one or more &#x201c;clusters&#x201d; in the array.</p><p id="p-0160" num="0157">A cluster in the array representing the sub-graph <b>512</b> may refer to a contiguous region of the array such that at least a threshold fraction of the components in the region have a value indicating that an edge exists between the pair of nodes corresponding to the component. In one example, the component of the array in position (i,j) can have value 1 if an edge exists from node i to node j, and value 0 otherwise. In this example, the nucleus classification engine <b>518</b> can identify contiguous regions of the array such that at least a threshold fraction of the components in the region have the value 1. The nucleus classification engine <b>518</b> can identify clusters in the array representing the sub-graph <b>512</b> by processing the array using a blob detection algorithm, e.g., by convolving the array with a Gaussian kernel and then applying the Laplacian operator to the array. After applying the Laplacian operator, the nucleus classification engine <b>518</b> can identify each component of the array having a value that satisfies a predefined threshold as being included in a cluster.</p><p id="p-0161" num="0158">Each of the clusters identified in the array representing the sub-graph <b>512</b> can correspond to edges connecting a &#x201c;nucleus&#x201d; (i.e., group) of related neurons in brain, e.g., a thalamic nucleus, a vestibular nucleus, a dentate nucleus, or a fastigial nucleus. After the nucleus classification engine <b>518</b> identifies the clusters in the array representing the sub-graph <b>512</b>, the architecture mapping system <b>500</b> can select one or more of the clusters for inclusion in the sub-graph <b>512</b>. The architecture mapping system <b>500</b> can select the clusters for inclusion in the sub-graph <b>512</b> based on respective features associated with each of the clusters. The features associated with a cluster can include, e.g., the number of edges (i.e., components of the array) in the cluster, the average of the node features corresponding to each node that is connected by an edge in the cluster, or both. In one example, the architecture mapping system <b>500</b> can select a predefined number of largest clusters (i.e., that include the greatest number of edges) for inclusion in the sub-graph <b>512</b>.</p><p id="p-0162" num="0159">The architecture mapping system <b>500</b> can reduce the sub-graph <b>512</b> by removing any edge in the sub-graph <b>512</b> that is not included in one of the selected clusters, and then map the reduced sub-graph <b>512</b> to a corresponding neural network architecture, as will be described in more detail below. Reducing the sub-graph <b>512</b> by restricting it to include only edges that are included in selected clusters can further reduce the complexity of the architecture <b>502</b>, thereby reducing computational resource consumption by the brain emulation neural network <b>516</b> and facilitating training of the brain emulation neural network <b>516</b>.</p><p id="p-0163" num="0160">The architecture mapping system <b>500</b> can determine the architecture <b>502</b> of the brain emulation neural network <b>516</b> from the sub-graph <b>512</b> in any of a variety of ways. For example, the architecture mapping system <b>500</b> can map each node in the sub-graph <b>512</b> to a corresponding: (i) artificial neuron, (ii) artificial neural network layer, or (iii) group of artificial neural network layers in the architecture <b>502</b>, as will be described in more detail next.</p><p id="p-0164" num="0161">In one example, the neural network architecture <b>502</b> can include: (i) a respective artificial neuron corresponding to each node in the sub-graph <b>512</b>, and (ii) a respective connection corresponding to each edge in the sub-graph <b>512</b>. In this example, the sub-graph <b>512</b> can be a directed graph, and an edge that points from a first node to a second node in the sub-graph <b>512</b> can specify a connection pointing from a corresponding first artificial neuron to a corresponding second artificial neuron in the architecture <b>502</b>. The connection pointing from the first artificial neuron to the second artificial neuron can indicate that the output of the first artificial neuron should be provided as an input to the second artificial neuron. Each connection in the architecture can be associated with a weight value, e.g., that is specified by the weight value associated with the corresponding edge in the sub-graph. An artificial neuron may refer to a component of the architecture <b>502</b> that is configured to receive one or more inputs (e.g., from one or more other artificial neurons), and to process the inputs to generate an output. The inputs to an artificial neuron and the output generated by the artificial neuron can be represented as scalar numerical values. In one example, a given artificial neuron can generate an output b as:</p><p id="p-0165" num="0000"><maths id="MATH-US-00003" num="00003"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mi>b</mi>     <mo>=</mo>     <mrow>      <mi>&#x3c3;</mi>      <mo>&#x2061;</mo>      <mo>(</mo>      <mrow>       <munderover>        <mo>&#x2211;</mo>        <mrow>         <mi>i</mi>         <mo>=</mo>         <mn>1</mn>        </mrow>        <mi>n</mi>       </munderover>       <mrow>        <msub>         <mi>w</mi>         <mi>i</mi>        </msub>        <mo>&#xb7;</mo>        <msub>         <mi>a</mi>         <mi>i</mi>        </msub>       </mrow>      </mrow>      <mo>)</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>1</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0166" num="0162">where &#x3c3;(&#xb7;) is a non-linear &#x201c;activation&#x201d; function (e.g., a sigmoid function or an arctangent function), {a<sub>i</sub>}<sub>i=1</sub><sup>n </sup>are the inputs provided to the given artificial neuron, and {w<sub>i</sub>}<sub>i=1</sub><sup>n </sup>are the weight values associated with the connections between the given artificial neuron and each of the other artificial neurons that provide an input to the given artificial neuron.</p><p id="p-0167" num="0163">In another example, the sub-graph <b>512</b> can be an undirected graph, and the architecture mapping system <b>500</b> can map an edge that connects a first node to a second node in the sub-graph <b>512</b> to two connections between a corresponding first artificial neuron and a corresponding second artificial neuron in the architecture. In particular, the architecture mapping system <b>500</b> can map the edge to: (i) a first connection pointing from the first artificial neuron to the second artificial neuron, and (ii) a second connection pointing from the second artificial neuron to the first artificial neuron.</p><p id="p-0168" num="0164">In another example, the sub-graph <b>512</b> can be an undirected graph, and the architecture mapping system can map an edge that connects a first node to a second node in the sub-graph <b>512</b> to one connection between a corresponding first artificial neuron and a corresponding second artificial neuron in the architecture. The architecture mapping system <b>500</b> can determine the direction of the connection between the first artificial neuron and the second artificial neuron, e.g., by randomly sampling the direction in accordance with a probability distribution over the set of two possible directions.</p><p id="p-0169" num="0165">In some cases, the edges in the sub-graph <b>512</b> is not be associated with weight values, and the weight values corresponding to the connections in the architecture <b>502</b> can be determined randomly. For example, the weight value corresponding to each connection in the architecture <b>502</b> can be randomly sampled from a predetermined probability distribution, e.g., a standard Normal (N(0,1)) probability distribution.</p><p id="p-0170" num="0166">In another example, the neural network architecture <b>502</b> can include: (i) a respective artificial neural network layer corresponding to each node in the sub-graph <b>512</b>, and (ii) a respective connection corresponding to each edge in the sub-graph <b>512</b>. In this example, a connection pointing from a first layer to a second layer can indicate that the output of the first layer should be provided as an input to the second layer. An artificial neural network layer may refer to a collection of artificial neurons, and the inputs to a layer and the output generated by the layer can be represented as ordered collections of numerical values (e.g., tensors of numerical values). In one example, the architecture <b>502</b> can include a respective convolutional neural network layer corresponding to each node in the sub-graph <b>512</b>, and each given convolutional layer can generate an output d as:</p><p id="p-0171" num="0000"><maths id="MATH-US-00004" num="00004"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mi>d</mi>     <mo>=</mo>     <mrow>      <mi>&#x3c3;</mi>      <mo>&#x2061;</mo>      <mo>(</mo>      <mrow>       <msub>        <mi>h</mi>        <mi>&#x3b8;</mi>       </msub>       <mo>(</mo>       <mrow>        <munderover>         <mo>&#x2211;</mo>         <mrow>          <mi>i</mi>          <mo>=</mo>          <mn>1</mn>         </mrow>         <mi>n</mi>        </munderover>        <mrow>         <msub>          <mi>w</mi>          <mi>i</mi>         </msub>         <mo>&#xb7;</mo>         <msub>          <mi>c</mi>          <mi>i</mi>         </msub>        </mrow>       </mrow>       <mo>)</mo>      </mrow>      <mo>)</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>2</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0172" num="0167">where each c<sub>i</sub>(i=1, . . . , n) is a tensor (e.g., a two- or three- dimensional array) of numerical values provided as an input to the layer, each w<sub>i</sub>(i=1, . . . , n) is a weight value associated with the connection between the given layer and each of the other layers that provide an input to the given layer (where the weight value for each edge can be specified by the weight value associated with the corresponding edge in the sub-graph), h<sub>&#x3b8;</sub>(&#xb7;) represents the operation of applying one or more convolutional kernels to an input to generate a corresponding output, and &#x3c3;(&#xb7;) is a non-linear activation function that is applied element-wise to each component of its input. In this example, each convolutional kernel can be represented as an array of numerical values, e.g., where each component of the array is randomly sampled from a predetermined probability distribution, e.g., a standard Normal probability distribution.</p><p id="p-0173" num="0168">In another example, the architecture mapping system <b>500</b> can determine that the neural network architecture includes: (i) a respective group of artificial neural network layers corresponding to each node in the sub-graph <b>512</b>, and (ii) a respective connection corresponding to each edge in the sub-graph <b>512</b>. The layers in a group of artificial neural network layers corresponding to a node in the sub-graph <b>512</b> can be connected, e.g., as a linear sequence of layers, or in any other appropriate manner.</p><p id="p-0174" num="0169">The neural network architecture <b>502</b> can include one or more artificial neurons that are identified as &#x201c;input&#x201d; artificial neurons and one or more artificial neurons that are identified as &#x201c;output&#x201d; artificial neurons. An input artificial neuron may refer to an artificial neuron that is configured to receive an input from a source that is external to the brain emulation neural network <b>516</b>. An output artificial neural neuron may refer to an artificial neuron that generates an output which is considered part of the overall output generated by the brain emulation neural network <b>516</b>.</p><p id="p-0175" num="0170">Various operations performed by the described architecture mapping system <b>500</b> are optional or can be implemented in a different order. For example, the architecture mapping system <b>500</b> can refrain from applying transformation operations to the graph <b>501</b> using the transformation engine <b>504</b>, and refrain from extracting a sub-graph <b>512</b> from the graph <b>501</b> using the feature generation engine <b>506</b>, the node classification engine <b>508</b>, and the nucleus classification engine <b>518</b>. In this example, the architecture mapping system <b>500</b> can directly map the graph <b>501</b> to the neural network architecture <b>502</b>, e.g., by mapping each node in the graph to an artificial neuron and mapping each edge in the graph to a connection in the architecture, as described above.</p><p id="p-0176" num="0171"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an example graph <b>600</b> and an example sub-graph <b>602</b>. Each node in the graph <b>600</b> is represented by a circle (e.g., <b>604</b> and <b>606</b>), and each edge in the graph <b>600</b> is represented by a line (e.g., <b>608</b> and <b>610</b>). In this illustration, the graph <b>600</b> can be considered a simplified representation of a synaptic connectivity graph (an actual synaptic connectivity graph can have far more nodes and edges than are depicted in <figref idref="DRAWINGS">FIG. <b>6</b></figref>). A sub-graph <b>602</b> can be identified in the graph <b>600</b>, where the sub-graph <b>602</b> includes a proper subset of the nodes and edges of the graph <b>600</b>. In this example, the nodes included in the sub-graph <b>602</b> are hatched (e.g., <b>606</b>) and the edges included in sub-graph <b>602</b> are dashed (e.g., <b>610</b>). The nodes included in the sub-graph <b>602</b> can correspond to neurons of a particular type, e.g., neurons having a particular function, e.g., olfactory neurons, visual neurons, or memory neurons. The architecture of the brain emulation neural network can be specified by the structure of the entire graph <b>600</b>, or by the structure of a sub-graph <b>602</b>, as described above.</p><p id="p-0177" num="0172"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flow diagram of an example process <b>700</b> for implementing a brain emulation subnetwork using a compressed matrix representation. For convenience, the process <b>700</b> will be described as being performed by a system of one or more computers located in one or more locations. For example, a neural network computing system, e.g., the neural network computing system <b>100</b> depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, appropriately programmed in accordance with this specification, can perform the process <b>700</b>.</p><p id="p-0178" num="0173">The brain emulation subnetwork is a component of a neural network that is configured to process a network input to generate a network output.</p><p id="p-0179" num="0174">The system process the network input using an input subnetwork of the neural network to generate an embedding of the network input (step <b>702</b>). For example, the input subnetwork can be a trained subnetwork, e.g., the first trained subnetwork <b>204</b> depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. As another example, the output subnetwork can be another brain emulation subnetwork.</p><p id="p-0180" num="0175">The system processing the embedding of the network input using the brain emulation subnetwork to generate a brain emulation subnetwork output (step <b>704</b>). The brain emulation subnetwork include brain emulation parameters that each correspond to a respective synaptic connection between a respective pair of biological neurons in the brain of a biological organism. Values for the brain emulation parameters can be specified by synaptic connectivity between the biological neurons in the brain of the biological organism.</p><p id="p-0181" num="0176">To generate the brain emulation subnetwork output, the system can obtain a compressed matrix representation of a sparse matrix that includes the brain emulation parameters. The sparse matrix represents the architecture of the brain emulation subnetwork. The system can then apply the compressed matrix representation to the embedding of the network input to generate the brain emulation subnetwork output.</p><p id="p-0182" num="0177">The system processes the brain emulation subnetwork output using an output subnetwork of the neural network to generate the network output (step <b>706</b>). For example, the output subnetwork can be a trained subnetwork, e.g., the second trained subnetwork <b>212</b> depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. As another example, the output subnetwork can be another brain emulation subnetwork.</p><p id="p-0183" num="0178"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flow diagram of an example process <b>800</b> for generating a brain emulation neural network. For convenience, the process <b>800</b> will be described as being performed by a system of one or more computers located in one or more locations.</p><p id="p-0184" num="0179">The system obtains a synaptic resolution image of at least a portion of a brain of a biological organism (<b>802</b>).</p><p id="p-0185" num="0180">The system processes the image to identify: (i) neurons in the brain, and (ii) synaptic connections between the neurons in the brain (<b>804</b>).</p><p id="p-0186" num="0181">The system generates data defining a graph representing synaptic connectivity between the neurons in the brain (<b>806</b>). The graph includes a set of nodes and a set of edges, where each edge connects a pair of nodes. The system identifies each neuron in the brain as a respective node in the graph, and each synaptic connection between a pair of neurons in the brain as an edge between a corresponding pair of nodes in the graph.</p><p id="p-0187" num="0182">The system determines an artificial neural network architecture corresponding to the graph representing the synaptic connectivity between the neurons in the brain (<b>808</b>).</p><p id="p-0188" num="0183">The system processes a network input using an artificial neural network having the artificial neural network architecture to generate a network output (<b>810</b>).</p><p id="p-0189" num="0184"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flow diagram of an example process <b>900</b> for determining an artificial neural network architecture corresponding to a sub-graph of a synaptic connectivity graph. For convenience, the process <b>900</b> will be described as being performed by a system of one or more computers located in one or more locations. For example, an architecture mapping system, e.g., the architecture mapping system <b>500</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, appropriately programmed in accordance with this specification, can perform the process <b>900</b>.</p><p id="p-0190" num="0185">The system obtains data defining a graph representing synaptic connectivity between neurons in a brain of a biological organism (<b>902</b>). The graph includes a set of nodes and edges, where each edge connects a pair of nodes. Each node corresponds to a respective neuron in the brain of the biological organism, and each edge connecting a pair of nodes in the graph corresponds to a synaptic connection between a pair of neurons in the brain of the biological organism.</p><p id="p-0191" num="0186">The system determines, for each node in the graph, a respective set of one or more node features characterizing a structure of the graph relative to the node (<b>904</b>).</p><p id="p-0192" num="0187">The system identifies a sub-graph of the graph (<b>906</b>). In particular, the system selects a proper subset of the nodes in the graph for inclusion in the sub-graph based on the node features of the nodes in the graph.</p><p id="p-0193" num="0188">The system determines an artificial neural network architecture corresponding to the sub-graph of the graph (<b>908</b>).</p><p id="p-0194" num="0189"><figref idref="DRAWINGS">FIG. <b>10</b></figref> shows an example optimization system <b>1000</b>. The optimization system <b>1000</b> is an example of a system implemented as computer programs on one or more computers in one or more locations in which the systems, components, and techniques described below are implemented.</p><p id="p-0195" num="0190">The optimization system <b>1000</b> is configured to generate candidate graphs <b>1003</b> using a graph generation engine <b>1002</b>. The graph generation engine <b>1002</b> is configured to process a synaptic connectivity graph <b>1001</b> in accordance with a set of graph generation parameters <b>1012</b> to generate an output graph <b>1004</b> that is added to the set of candidate graphs <b>1003</b>. The optimization system <b>1000</b> iteratively optimizes the parameters <b>1012</b> of the graph generation engine <b>1002</b> using an optimization engine <b>1010</b> to increase the performance measures <b>1008</b> of the output graphs <b>1004</b> generated by the graph generation engine <b>1002</b>, as will be described in more detail below.</p><p id="p-0196" num="0191">The parameters <b>1012</b> of the graph generation engine <b>1002</b> specify transformation operations that are applied to the synaptic connectivity graph <b>1001</b> to generate an output graph <b>1004</b>. The graph generation engine <b>1002</b> may generate the output graph <b>1004</b> by applying transformation operations to a representation of the synaptic connectivity graph <b>1001</b> as a two-dimensional array of numerical values. As described above, a graph may be represented as a two-dimensional array of numerical values with a number of rows and columns equal to the number of nodes in the graph. The component of the array at position (i,j) may have value 1 if the graph includes an edge pointing from node i to node j, and value 0 otherwise.</p><p id="p-0197" num="0192">In one example, as part of generating an output graph <b>1004</b>, the graph generation engine <b>1002</b> may apply a convolutional filtering operation specified by a filtering kernel to the array representing the synaptic connectivity graph <b>1001</b>. In this example, the graph generation parameters <b>1012</b> may specify the components of a matrix defining the filtering kernel.</p><p id="p-0198" num="0193">In another example, as part of generating an output graph <b>1004</b>, the graph generation engine <b>1002</b> may apply a &#x201c;shifting&#x201d; operation to the array representing the synaptic connectivity graph <b>1001</b>, e.g., such that each the value in each component of the array is translated &#x201c;left&#x201d;, &#x201c;right&#x201d;, &#x201c;up&#x201d;, or &#x201c;down&#x201d;. Components that are shifted outside the bounds of the array may be wrapped around the opposite side of the array. In this example, the graph generation parameters <b>1012</b> may specify the direction and magnitude of the shifting operation.</p><p id="p-0199" num="0194">In another example, as part of generating an output graph, the graph generation engine may apply a cropping operation to the adjacency matrix representing the synaptic connectivity graph, where the cropping operation replaces the adjacency matrix representing the synaptic connectivity graph with an adjacency matrix representing a sub-graph of the synaptic connectivity graph. Generally, a &#x201c;sub-graph&#x201d; may refer to a graph specified by: (i) a proper subset of the nodes of the synaptic connectivity graph, and (ii) a proper subset of the edges of the synaptic connectivity graph. The cropping operation may specify a sub-graph of synaptic connectivity graph, e.g., by specifying a proper subset of the rows and a proper subset of the columns of the adjacency matrix representing the synaptic connectivity graph that define a sub-matrix of the adjacency matrix. The sub-graph may include: (i) each edge specified by the sub-matrix, and (ii) each node that is connected by an edge specified by the sub-matrix.</p><p id="p-0200" num="0195">At each of multiple iterations, the graph generation engine <b>1002</b> processes the synaptic connectivity graph <b>1001</b> in accordance with the current values of the graph generation parameters <b>1012</b> to generate an output graph <b>1004</b> which may then be added to the set of candidate graphs <b>1003</b>. The optimization system <b>1000</b> determines a performance measure <b>1008</b> of the output graph <b>1004</b> using an evaluation engine <b>1006</b>, and then provides the performance measure <b>1008</b> of the output graph <b>1004</b> to the optimization engine <b>1010</b>.</p><p id="p-0201" num="0196">In some implementations, each edge of the synaptic connectivity graph may be associated with a weight value that is determined from the synaptic resolution image of the brain, as described above. Each candidate graph may inherit the weight values associated with the edges of the synaptic connectivity graph. For example, each edge in the candidate graph that corresponds to an edge in the synaptic connectivity graph may be associated with the same weight value as the corresponding edge in the synaptic connectivity graph. Edges in the candidate graph that do not correspond to edges in the synaptic connectivity graph may be associated with default or randomly initialized weight values.</p><p id="p-0202" num="0197">The performance measure for a candidate graph characterizes the performance of a neural network that includes a brain emulation neural network layer having an architecture specified by the candidate graph at performing a machine learning task. More specifically, to determine the performance measure of a candidate graph, the evaluation system <b>1006</b> can map the candidate graph to a corresponding brain emulation neural network layer, e.g., using the architecture mapping system <b>420</b> described with reference to <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>, e.g., by mapping each node in the candidate graph to an artificial neuron in the brain emulation neural network layer, each edge in the candidate graph to a connection between a corresponding pair of artificial neurons in the brain emulation neural network layer, and the weight value associated with each edge in the candidate graph to a parameter value associated with the corresponding connection in the brain emulation neural network layer.</p><p id="p-0203" num="0198">The evaluation engine may measure the performance of a neural network that includes a brain emulation neural network layer having an architecture specified by the candidate graph (e.g., the neural network <b>102</b> described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>), e.g., by training the neural network on a set of training data, and then evaluating the performance of the trained neural network on a set of validation data. Both the training data and the validation data may include training examples, where each training example specifies: (i) a network input, and (ii) a target output, i.e., that should be generated by processing the network input. In determining the performance measure of a neural network, the evaluation engine trains the neural network on the training data, but reserves the validation data for evaluating the performance of the trained neural network (i.e., by not training the neural network on the validation data). The evaluation engine may evaluate the performance of the trained neural network on the validation data, e.g., by using an objective function to measure an error between: (i) the target outputs specified by the validation data, and (ii) the predicted outputs generated by the trained neural network. The objective function may be, e.g., a squared-error objective function, or any other appropriate objective function.</p><p id="p-0204" num="0199">The optimization engine <b>1010</b> is configured to process the performance measures <b>1008</b> of the output graphs <b>1004</b> to determine adjustments to the current values of the graph generation parameters to encourage the generation of output graphs with higher performance measures. Prior to the first iteration, the values of the graph generation parameters <b>1012</b> may be set to default values or randomly initialized. The optimization engine <b>1010</b> may use any appropriate optimization technique, e.g., a &#x201c;black-box&#x201d; optimization technique that does not rely on computing gradients of the transformation operations applied by the graph generation engine <b>1002</b>. Examples of black-box optimization techniques which may be implemented by the optimization engine <b>1010</b> are described with reference to: Golovin, D., Solnik, B., Moitra, S., Kochanski, G., Karro, J., &#x26; Sculley, D.: &#x201c;Google vizier: A service for black-box optimization,&#x201d; In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1487-1495 (2017).</p><p id="p-0205" num="0200">After the final iteration, the optimization system <b>1000</b> may identify a best-performing candidate graph based on the performance measures. For example, the optimization system may identify the best-performing graph as the candidate graph with the highest performance measure. After identifying the best-performing graph, the optimization system may provide the brain emulation neural network layer specified by the best-performing graph for use as part of a neural network, e.g., the neural network <b>102</b> described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0206" num="0201"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram of an example computer system <b>1100</b> that can be used to perform operations described previously. The system <b>1100</b> includes a processor <b>1110</b>, a memory <b>1120</b>, a storage device <b>1130</b>, and an input/output device <b>1140</b>. Each of the components <b>1110</b>, <b>1120</b>, <b>1130</b>, and <b>1140</b> can be interconnected, for example, using a system bus <b>1150</b>. The processor <b>1110</b> is capable of processing instructions for execution within the system <b>1100</b>. In one implementation, the processor <b>1110</b> is a single-threaded processor. In another implementation, the processor <b>1110</b> is a multi-threaded processor. The processor <b>1110</b> is capable of processing instructions stored in the memory <b>1120</b> or on the storage device <b>1130</b>.</p><p id="p-0207" num="0202">The memory <b>1120</b> stores information within the system <b>1100</b>. In one implementation, the memory <b>1120</b> is a computer-readable medium. In one implementation, the memory <b>1120</b> is a volatile memory unit. In another implementation, the memory <b>1120</b> is a non-volatile memory unit.</p><p id="p-0208" num="0203">The storage device <b>1130</b> is capable of providing mass storage for the system <b>1100</b>. In one implementation, the storage device <b>1130</b> is a computer-readable medium. In various different implementations, the storage device <b>1130</b> can include, for example, a hard disk device, an optical disk device, a storage device that is shared over a network by multiple computing devices (for example, a cloud storage device), or some other large capacity storage device.</p><p id="p-0209" num="0204">The input/output device <b>1140</b> provides input/output operations for the system <b>1100</b>. In one implementation, the input/output device <b>1140</b> can include one or more network interface devices, for example, an Ethernet card, a serial communication device, for example, and RS-232 port, and/or a wireless interface device, for example, and 802.11 card. In another implementation, the input/output device <b>1140</b> can include driver devices configured to receive input data and send output data to other input/output devices, for example, keyboard, printer and display devices <b>1160</b>. Other implementations, however, can also be used, such as mobile computing devices, mobile communication devices, and set-top box television client devices.</p><p id="p-0210" num="0205">Although an example processing system has been described in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, implementations of the subject matter and the functional operations described in this specification can be implemented in other types of digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.</p><p id="p-0211" num="0206">Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly-embodied computer software or firmware, in computer hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a tangible non-transitory storage medium for execution by, or to control the operation of, data processing apparatus. The computer storage medium can be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them. Alternatively or in addition, the program instructions can be encoded on an artificially-generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus.</p><p id="p-0212" num="0207">The term &#x201c;data processing apparatus&#x201d; refers to data processing hardware and encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can also be, or further include, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can optionally include, in addition to hardware, code that creates an execution environment for computer programs, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.</p><p id="p-0213" num="0208">A computer program which may also be referred to or described as a program, software, a software application, an app, a module, a software module, a script, or code) can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data, e.g., one or more scripts stored in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files, e.g., files that store one or more modules, sub-programs, or portions of code. A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a data communication network.</p><p id="p-0214" num="0209">For a system of one or more computers to be configured to perform particular operations or actions means that the system has installed on it software, firmware, hardware, or a combination of them that in operation cause the system to perform the operations or actions. For one or more computer programs to be configured to perform particular operations or actions means that the one or more programs include instructions that, when executed by data processing apparatus, cause the apparatus to perform the operations or actions.</p><p id="p-0215" num="0210">As used in this specification, an &#x201c;engine,&#x201d; or &#x201c;software engine,&#x201d; refers to a software implemented input/output system that provides an output that is different from the input. An engine can be an encoded block of functionality, such as a library, a platform, a software development kit (&#x201c;SDK&#x201d;), or an object. Each engine can be implemented on any appropriate type of computing device, e.g., servers, mobile phones, tablet computers, notebook computers, music players, e-book readers, laptop or desktop computers, PDAs, smart phones, or other stationary or portable devices, that includes one or more processors and computer readable media. Additionally, two or more of the engines may be implemented on the same computing device, or on different computing devices.</p><p id="p-0216" num="0211">The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by special purpose logic circuitry, e.g., an FPGA or an ASIC, or by a combination of special purpose logic circuitry and one or more programmed computers.</p><p id="p-0217" num="0212">Computers suitable for the execution of a computer program can be based on general or special purpose microprocessors or both, or any other kind of central processing unit. Generally, a central processing unit will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a central processing unit for performing or executing instructions and one or more memory devices for storing instructions and data. The central processing unit and the memory can be supplemented by, or incorporated in, special purpose logic circuitry. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Moreover, a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device, e.g., a universal serial bus (USB) flash drive, to name just a few.</p><p id="p-0218" num="0213">Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.</p><p id="p-0219" num="0214">To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and pointing device, e.g, a mouse, trackball, or a presence sensitive display or other surface by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. In addition, a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; for example, by sending web pages to a web browser on a user's device in response to requests received from the web browser. Also, a computer can interact with a user by sending text messages or other forms of message to a personal device, e.g., a smartphone, running a messaging application, and receiving responsive messages from the user in return.</p><p id="p-0220" num="0215">Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface, a web browser, or an app through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (LAN) and a wide area network (WAN), e.g., the Internet.</p><p id="p-0221" num="0216">The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, a server transmits data, e.g., an HTML page, to a user device, e.g., for purposes of displaying data to and receiving user input from a user interacting with the device, which acts as a client. Data generated at the user device, e.g., a result of the user interaction, can be received at the server from the device.</p><p id="p-0222" num="0217">In addition to the embodiments described above, the following embodiments are also innovative:</p><p id="p-0223" num="0218">Embodiment 1 is a method comprising:</p><p id="p-0224" num="0219">obtaining a network input; and</p><p id="p-0225" num="0220">processing the network input using a neural network to generate a network output, comprising:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0221">processing the network input using an input subnetwork of the neural network to generate an embedding of the network input;</li>        <li id="ul0002-0002" num="0222">processing the embedding of the network input using a brain emulation subnetwork of the neural network, wherein the brain emulation subnetwork has a brain emulation neural network architecture that represents synaptic connectivity between a plurality of biological neurons in a brain of a biological organism, the processing comprising:        <ul id="ul0003" list-style="none">            <li id="ul0003-0001" num="0223">obtaining a compressed matrix representation of a sparse matrix of brain emulation parameters representing synaptic connectivity between the plurality of biological neurons in the brain of the biological organism; and</li>            <li id="ul0003-0002" num="0224">applying the compressed matrix representation to the embedding of the network input to generate a brain emulation subnetwork output; and</li>        </ul>        </li>        <li id="ul0002-0003" num="0225">processing the brain emulation subnetwork output using an output subnetwork of the neural network to generate the network output.</li>    </ul>    </li></ul></p><p id="p-0226" num="0226">Embodiment 2 is the method of embodiment 1, wherein the compressed matrix representation identifies only a proper subset of the brain emulation parameters of the sparse matrix.</p><p id="p-0227" num="0227">Embodiment 3 is the method of embodiment 2, wherein the compressed matrix representation identifies only brain emulation parameters in the sparse matrix that have non-zero values, and excludes brain emulation parameters in the sparse matrix having value zero.</p><p id="p-0228" num="0228">Embodiment 4 is the method of any one of embodiments 2 or 3, wherein the compressed matrix representation identifies: (i) all brain emulation parameters in the sparse matrix that have non-zero values, and (ii) a proper subset of brain emulation parameters in the sparse matrix having value zero.</p><p id="p-0229" num="0229">Embodiment 5 is the method of any one of embodiments 1-4, wherein the compressed matrix representation comprises data defining: (i) a respective value, and (ii) a respective position in the sparse matrix, of each brain emulation parameter that is identified in the compressed matrix representation.</p><p id="p-0230" num="0230">Embodiment 6 is the method of any one of embodiments 1-5, wherein the sparse matrix comprises at least 100 million brain emulation parameters.</p><p id="p-0231" num="0231">Embodiment 7 is the method of any one of embodiments 1-6, wherein at least 90% of brain emulation parameters in the sparse matrix have value zero.</p><p id="p-0232" num="0232">Embodiment 8 is the method of any one of embodiments 1-7, wherein the sparse matrix representing synaptic connectivity between the plurality of biological neurons is a two-dimensional matrix of brain emulation parameters arranged into a plurality of rows and a plurality of columns,</p><p id="p-0233" num="0233">wherein each row and each column of the sparse matrix correspond to a respective biological neuron from the plurality of biological neurons, and</p><p id="p-0234" num="0234">wherein each brain emulation parameter of the sparse matrix corresponds to a respective pair of biological neurons in the brain of the biological organism, the pair comprising: (i) the biological neuron corresponding to a row of the brain emulation parameter in the sparse matrix, and (ii) the biological neuron corresponding to a column of the brain emulation parameter in the sparse matrix.</p><p id="p-0235" num="0235">Embodiment 9 is the method of embodiment 8, wherein each brain emulation parameter of the sparse matrix has a respective value that characterizes synaptic connectivity in the brain of the biological organism between the respective pair of biological neurons corresponding to the brain emulation parameter.</p><p id="p-0236" num="0236">Embodiment 10 is the method of embodiment 9, wherein each brain emulation parameter of the sparse matrix that corresponds to a respective pair of biological neurons that are not connected by a synaptic connection in the brain of the biological organism has value zero.</p><p id="p-0237" num="0237">Embodiment 11 is the method of any one of embodiments 9 or 10, wherein each brain emulation parameter of the sparse matrix that corresponds to a respective pair of biological neurons that are connected by a synaptic connection in the brain of the biological organism has a respective non-zero value that is based on a proximity of the pair of biological neurons in the brain of the biological organism.</p><p id="p-0238" num="0238">Embodiment 12 is the method of any one of embodiments 1-11, wherein applying the compressed matrix representation to the embedding of the network input to generate the brain emulation subnetwork output comprises:</p><p id="p-0239" num="0239">determining the brain emulation subnetwork output to be a result of a matrix multiplication of: (i) the sparse matrix represented by the compressed matrix representation, and (ii) the embedding of the network input, without performing any scalar multiplications by brain emulation parameters of the sparse matrix that are not identified in the compressed matrix representation.</p><p id="p-0240" num="0240">Embodiment 13 is the method of any one of embodiments 1-12, further comprising training a plurality of neural network parameters of the neural network to optimize an objective function, the training comprising, at each of a plurality of training iterations:</p><p id="p-0241" num="0241">processing one or more network inputs using the neural network, in accordance with current values of the plurality of neural network parameters, to generate corresponding network outputs;</p><p id="p-0242" num="0242">determining gradients, with respect to the neural network parameters, of an objective function that depends on the network outputs; and</p><p id="p-0243" num="0243">updating the current values of the neural network parameters using the gradients.</p><p id="p-0244" num="0244">Embodiment 14 is the method of embodiment 13, wherein updating the current values of the neural network parameters using the gradients comprises updating current values of the brain emulation parameters of the sparse matrix,</p><p id="p-0245" num="0245">wherein updating the current values of the brain emulation parameters of the sparse matrix only modifies brain emulation parameters that are identified in the compressed matrix representation without modifying brain emulation parameters that are not identified in the compressed matrix representation.</p><p id="p-0246" num="0246">Embodiment 15 is the method of any one of embodiments 13 or 14, wherein the training further comprises, at each of a plurality of training iterations:</p><p id="p-0247" num="0247">removing one or more brain emulation parameters from the compressed matrix representation of the sparse matrix; and</p><p id="p-0248" num="0248">adding one or more new brain emulation parameters to the compressed matrix representation of the sparse matrix.</p><p id="p-0249" num="0249">Embodiment 16 is the method of embodiment 15, wherein removing one or more brain emulation parameters from the compressed matrix representation of the sparse matrix comprises one or more of:</p><p id="p-0250" num="0250">for each brain emulation parameter in the compressed matrix representation, randomly selecting the brain emulation parameter for removal with a likelihood that is inversely proportional with a magnitude of the value of the brain emulation parameter;</p><p id="p-0251" num="0251">for each brain emulation parameter in the compressed matrix representation, randomly selecting the brain emulation parameter for removal with a likelihood that is inversely proportional with a rank of the magnitude of the value of the brain emulation parameter in a ranking of the magnitudes of the values of the brain emulation parameters; or</p><p id="p-0252" num="0252">performing a multi-stage process comprising:<ul id="ul0004" list-style="none">    <li id="ul0004-0001" num="0000">    <ul id="ul0005" list-style="none">        <li id="ul0005-0001" num="0253">a first stage comprising generating a set of candidate brain emulation parameters by randomly sampling the candidate brain emulation parameters according to a ranking of the magnitudes of the values of the brain emulation parameters; and</li>        <li id="ul0005-0002" num="0254">a second stage comprising randomly selecting brain emulations parameters from the set of candidate brain emulation parameters for removal according to the magnitudes of the values of the candidate brain emulation parameters.</li>    </ul>    </li></ul></p><p id="p-0253" num="0255">Embodiment 17 is the method of any one of embodiments 15 or 16, wherein adding one or more new brain emulation parameters to the compressed matrix representation of the sparse matrix comprises:</p><p id="p-0254" num="0256">randomly selecting one or more brain emulation parameters that are not identified in the compressed matrix representation; and</p><p id="p-0255" num="0257">for each randomly selected brain emulation parameter, adding the randomly selected brain emulation parameter to the compressed matrix representation, and assigning an initial value of zero to the randomly selected brain emulation parameter.</p><p id="p-0256" num="0258">Embodiment 18 is the method of any one of embodiments 1-17, wherein the sparse matrix of brain emulation parameters representing synaptic connectivity between the plurality of biological neurons in the brain of the biological organism is determined from a synaptic resolution image of at least a portion of the brain of the biological organism, the determining comprising:</p><p id="p-0257" num="0259">processing the synaptic resolution image to identify: (i) the plurality of biological neurons, and (ii) a plurality of synaptic connections between pairs of biological neurons; and</p><p id="p-0258" num="0260">determining a respective value for each brain emulation parameter in the sparse matrix, comprising:<ul id="ul0006" list-style="none">    <li id="ul0006-0001" num="0000">    <ul id="ul0007" list-style="none">        <li id="ul0007-0001" num="0261">setting a value of each brain emulation parameter that corresponds to a pair of biological neurons in the brain that are not connected by a synapse to zero; and</li>        <li id="ul0007-0002" num="0262">setting a value of each brain emulation parameter that corresponds to a pair of biological neurons in the brain that are connected by a synapse based on a proximity of the pair of biological neurons in the brain.</li>    </ul>    </li></ul></p><p id="p-0259" num="0263">Embodiment 19 is a system comprising: one or more computers and one or more storage devices storing instructions that are operable, when executed by the one or more computers, to cause the one or more computers to perform the method of any one of embodiments 1 to 18.</p><p id="p-0260" num="0264">Embodiment 20 is one or more non-transitory computer storage media encoded with a computer program, the program comprising instructions that are operable, when executed by data processing apparatus, to cause the data processing apparatus to perform the method of any one of embodiments 1 to 18.</p><p id="p-0261" num="0265">While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or on the scope of what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially be claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.</p><p id="p-0262" num="0266">Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Moreover, the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.</p><p id="p-0263" num="0267">Particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In certain some cases, multitasking and parallel processing may be advantageous.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230004791A1-20230105-M00001.NB"><img id="EMI-M00001" he="7.79mm" wi="76.20mm" file="US20230004791A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230004791A1-20230105-M00002.NB"><img id="EMI-M00002" he="8.13mm" wi="76.20mm" file="US20230004791A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00003" nb-file="US20230004791A1-20230105-M00003.NB"><img id="EMI-M00003" he="7.79mm" wi="76.20mm" file="US20230004791A1-20230105-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00004" nb-file="US20230004791A1-20230105-M00004.NB"><img id="EMI-M00004" he="7.79mm" wi="76.20mm" file="US20230004791A1-20230105-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method comprising:<claim-text>obtaining a network input; and</claim-text><claim-text>processing the network input using a neural network to generate a network output, comprising:<claim-text>processing the network input using an input subnetwork of the neural network to generate an embedding of the network input;</claim-text><claim-text>processing the embedding of the network input using a brain emulation subnetwork of the neural network, wherein the brain emulation subnetwork has a brain emulation neural network architecture that represents synaptic connectivity between a plurality of biological neurons in a brain of a biological organism, the processing comprising:<claim-text>obtaining a compressed matrix representation of a sparse matrix of brain emulation parameters representing synaptic connectivity between the plurality of biological neurons in the brain of the biological organism; and</claim-text><claim-text>applying the compressed matrix representation to the embedding of the network input to generate a brain emulation subnetwork output; and</claim-text></claim-text><claim-text>processing the brain emulation subnetwork output using an output subnetwork of the neural network to generate the network output.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the compressed matrix representation identifies only a proper subset of the brain emulation parameters of the sparse matrix.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the compressed matrix representation identifies only brain emulation parameters in the sparse matrix that have non-zero values, and excludes brain emulation parameters in the sparse matrix having value zero.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the compressed matrix representation identifies: (i) all brain emulation parameters in the sparse matrix that have non-zero values, and (ii) a proper subset of brain emulation parameters in the sparse matrix having value zero.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the compressed matrix representation comprises data defining: (i) a respective value, and (ii) a respective position in the sparse matrix, of each brain emulation parameter that is identified in the compressed matrix representation.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sparse matrix comprises at least 100 million brain emulation parameters.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least 90% of brain emulation parameters in the sparse matrix have value zero.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sparse matrix representing synaptic connectivity between the plurality of biological neurons is a two-dimensional matrix of brain emulation parameters arranged into a plurality of rows and a plurality of columns,<claim-text>wherein each row and each column of the sparse matrix correspond to a respective biological neuron from the plurality of biological neurons, and</claim-text><claim-text>wherein each brain emulation parameter of the sparse matrix corresponds to a respective pair of biological neurons in the brain of the biological organism, the pair comprising: (i) the biological neuron corresponding to a row of the brain emulation parameter in the sparse matrix, and (ii) the biological neuron corresponding to a column of the brain emulation parameter in the sparse matrix.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein each brain emulation parameter of the sparse matrix has a respective value that characterizes synaptic connectivity in the brain of the biological organism between the respective pair of biological neurons corresponding to the brain emulation parameter.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein each brain emulation parameter of the sparse matrix that corresponds to a respective pair of biological neurons that are not connected by a synaptic connection in the brain of the biological organism has value zero.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein each brain emulation parameter of the sparse matrix that corresponds to a respective pair of biological neurons that are connected by a synaptic connection in the brain of the biological organism has a respective non-zero value that is based on a proximity of the pair of biological neurons in the brain of the biological organism.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein applying the compressed matrix representation to the embedding of the network input to generate the brain emulation subnetwork output comprises:<claim-text>determining the brain emulation subnetwork output to be a result of a matrix multiplication of: (i) the sparse matrix represented by the compressed matrix representation, and (ii) the embedding of the network input, without performing any scalar multiplications by brain emulation parameters of the sparse matrix that are not identified in the compressed matrix representation.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising training a plurality of neural network parameters of the neural network to optimize an objective function, the training comprising, at each of a plurality of training iterations:<claim-text>processing one or more network inputs using the neural network, in accordance with current values of the plurality of neural network parameters, to generate corresponding network outputs;</claim-text><claim-text>determining gradients, with respect to the neural network parameters, of an objective function that depends on the network outputs; and</claim-text><claim-text>updating the current values of the neural network parameters using the gradients.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein updating the current values of the neural network parameters using the gradients comprises updating current values of the brain emulation parameters of the sparse matrix,<claim-text>wherein updating the current values of the brain emulation parameters of the sparse matrix only modifies brain emulation parameters that are identified in the compressed matrix representation without modifying brain emulation parameters that are not identified in the compressed matrix representation.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the training further comprises, at each of a plurality of training iterations:<claim-text>removing one or more brain emulation parameters from the compressed matrix representation of the sparse matrix; and</claim-text><claim-text>adding one or more new brain emulation parameters to the compressed matrix representation of the sparse matrix.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein removing one or more brain emulation parameters from the compressed matrix representation of the sparse matrix comprises one or more of:<claim-text>for each brain emulation parameter in the compressed matrix representation, randomly selecting the brain emulation parameter for removal with a likelihood that is inversely proportional with a magnitude of the value of the brain emulation parameter;</claim-text><claim-text>for each brain emulation parameter in the compressed matrix representation, randomly selecting the brain emulation parameter for removal with a likelihood that is inversely proportional with a rank of the magnitude of the value of the brain emulation parameter in a ranking of the magnitudes of the values of the brain emulation parameters; or</claim-text><claim-text>performing a multi-stage process comprising:<claim-text>a first stage comprising generating a set of candidate brain emulation parameters by randomly sampling the candidate brain emulation parameters according to a ranking of the magnitudes of the values of the brain emulation parameters; and</claim-text><claim-text>a second stage comprising randomly selecting brain emulations parameters from the set of candidate brain emulation parameters for removal according to the magnitudes of the values of the candidate brain emulation parameters.</claim-text></claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein adding one or more new brain emulation parameters to the compressed matrix representation of the sparse matrix comprises:<claim-text>randomly selecting one or more brain emulation parameters that are not identified in the compressed matrix representation; and</claim-text><claim-text>for each randomly selected brain emulation parameter, adding the randomly selected brain emulation parameter to the compressed matrix representation, and assigning an initial value of zero to the randomly selected brain emulation parameter.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sparse matrix of brain emulation parameters representing synaptic connectivity between the plurality of biological neurons in the brain of the biological organism is determined from a synaptic resolution image of at least a portion of the brain of the biological organism, the determining comprising:<claim-text>processing the synaptic resolution image to identify: (i) the plurality of biological neurons, and (ii) a plurality of synaptic connections between pairs of biological neurons; and</claim-text><claim-text>determining a respective value for each brain emulation parameter in the sparse matrix, comprising:<claim-text>setting a value of each brain emulation parameter that corresponds to a pair of biological neurons in the brain that are not connected by a synapse to zero; and</claim-text><claim-text>setting a value of each brain emulation parameter that corresponds to a pair of biological neurons in the brain that are connected by a synapse based on a proximity of the pair of biological neurons in the brain.</claim-text></claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A system comprising one or more computers and one or more storage devices storing instructions that are operable, when executed by the one or more computers, to cause the one or more computers to perform operations comprising:<claim-text>obtaining a network input; and</claim-text><claim-text>processing the network input using a neural network to generate a network output, comprising:<claim-text>processing the network input using an input subnetwork of the neural network to generate an embedding of the network input;</claim-text><claim-text>processing the embedding of the network input using a brain emulation subnetwork having a brain emulation neural network architecture that is based on synaptic connectivity between a plurality of biological neurons in a brain of a biological organism, comprising:<claim-text>obtaining a compressed matrix representation of a sparse matrix of brain emulation parameters representing synaptic connectivity between the plurality of biological neurons in the brain of the biological organism; and</claim-text><claim-text>applying the compressed matrix representation to the embedding of the network input to generate a brain emulation subnetwork output; and</claim-text></claim-text><claim-text>processing the brain emulation subnetwork output using an output subnetwork of the neural network to generate the network output.</claim-text></claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. One or more non-transitory storage media storing instructions that when executed by one or more computers cause the one or more computers to perform operations comprising:<claim-text>obtaining a network input; and</claim-text><claim-text>processing the network input using a neural network to generate a network output, comprising:<claim-text>processing the network input using an input subnetwork of the neural network to generate an embedding of the network input;</claim-text><claim-text>processing the embedding of the network input using a brain emulation subnetwork having a brain emulation neural network architecture that is based on synaptic connectivity between a plurality of biological neurons in a brain of a biological organism, comprising:<claim-text>obtaining a compressed matrix representation of a sparse matrix of brain emulation parameters representing synaptic connectivity between the plurality of biological neurons in the brain of the biological organism; and</claim-text><claim-text>applying the compressed matrix representation to the embedding of the network input to generate a brain emulation subnetwork output; and</claim-text></claim-text><claim-text>processing the brain emulation subnetwork output using an output subnetwork of the neural network to generate the network output.</claim-text></claim-text></claim-text></claim></claims></us-patent-application>
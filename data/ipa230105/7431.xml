<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007432A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007432</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17939114</doc-number><date>20220907</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-174083</doc-number><date>20201015</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>S</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>S</subclass><main-group>3</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>10</class><subclass>L</subclass><main-group>19</main-group><subgroup>008</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>S</subclass><main-group>7</main-group><subgroup>304</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>S</subclass><main-group>3</main-group><subgroup>008</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>L</subclass><main-group>19</main-group><subgroup>008</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>S</subclass><main-group>2400</main-group><subgroup>15</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>S</subclass><main-group>2400</main-group><subgroup>11</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>S</subclass><main-group>2400</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>S</subclass><main-group>2420</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">ACOUSTIC REPRODUCTION METHOD, ACOUSTIC REPRODUCTION DEVICE, AND RECORDING MEDIUM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/009919</doc-number><date>20210311</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17939114</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>62990018</doc-number><date>20200316</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Panasonic Intellectual Property Corporation of America</orgname><address><city>Torrance</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>ENOMOTO</last-name><first-name>Seigo</first-name><address><city>Kyoto</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>ISHIKAWA</last-name><first-name>Tomokazu</first-name><address><city>Osaka</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An acoustic reproduction method includes: localizing a first sound image at a first position in a target space in which a user is present; and localizing, at a second position in the target space, a second sound image that represents an anchor sound for indicating a reference position.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="82.30mm" wi="145.46mm" file="US20230007432A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="122.51mm" wi="147.49mm" file="US20230007432A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="174.24mm" wi="87.21mm" file="US20230007432A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="158.16mm" wi="145.20mm" file="US20230007432A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="186.35mm" wi="115.23mm" file="US20230007432A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="166.37mm" wi="145.29mm" file="US20230007432A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="123.27mm" wi="109.56mm" file="US20230007432A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This is a continuation application of PCT International Application No. PCT/JP2021/009919 filed on Mar. 11, 2021, designating the United States of America, which is based on and claims priority of Japanese Patent Application No. 2020-174083 filed on Oct. 15, 2020 and U.S. Provisional Patent Application No. 62/990,018 filed on Mar. 16, 2020. The entire disclosures of the above-identified applications, including the specifications, drawings and claims are incorporated herein by reference in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">The present disclosure relates to an acoustic reproduction method, an acoustic reproduction device, and a recording medium.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Techniques relating to acoustic reproduction for causing a user to perceive stereophonic sounds by presenting sound images at desired positions within a three-dimensional space have been conventionally known (for example, see Patent Literature (PTL) 1 and Non Patent Literature (NPL) 1).</p><heading id="h-0004" level="1">CITATION LIST</heading><heading id="h-0005" level="1">Patent Literature</heading><p id="p-0005" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0004">PTL 1: Japanese Unexamined Patent Application Publication No. 2017-92732</li></ul></p><heading id="h-0006" level="1">Non Patent Literature</heading><p id="p-0006" num="0000"><ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0005">NPL 1: Itoh, K., Yonezawa, Y., &#x26; Kido, K. (1986) Transmission of image information through auditory sensation using control of sound lateralization: Improvement of display efficiency by addition of marker tone. The Journal of the Acoustical Society of Japan, 42(9), 708-715.</li></ul></p><heading id="h-0007" level="1">SUMMARY</heading><heading id="h-0008" level="1">Technical Problem</heading><p id="p-0007" num="0006">The present disclosure aims to provide an acoustic reproduction method, an acoustic reproduction device, and a recording medium which improve presentation of a sound image.</p><heading id="h-0009" level="1">Solution to Problem</heading><p id="p-0008" num="0007">An acoustic reproduction method according to one aspect of the present disclosure includes: localizing a first sound image at a first position in a target space in which a user is present; and localizing a second sound image at a second position in the target space, the second sound image representing an anchor sound for indicating a reference position.</p><p id="p-0009" num="0008">A recording medium according to one aspect of the present disclosure is a non-transitory computer-readable recording medium for use in a computer, the recording medium having a computer program recorded thereon for causing the computer to execute the above-described acoustic reproduction method.</p><p id="p-0010" num="0009">An acoustic reproduction device according to one aspect of the present disclosure includes: a decoder that decodes an encoded sound signal, the encoded sound signal causing a user to perceive a first sound image; a first localizer that localizes, according to the encoded sound signal that has been decoded, the first sound image at a first position in a target space in which the user is present; and a second localizer that localizes a second sound image at a second position in the target space, the second sound image representing an anchor sound for indicating a reference position.</p><p id="p-0011" num="0010">Note that these general or specific aspects may be realized by a system, a method, an integrated circuit, a computer program, or a non-transitory computer-readable recording medium such as a compact disc read only memory (CD-ROM), or by any optional combination of systems, methods, integrated circuits, computer programs, and recording media.</p><heading id="h-0010" level="1">Advantageous Effects</heading><p id="p-0012" num="0011">An acoustic reproduction method, a recording medium, and an acoustic reproduction device according to the present disclosure are capable of improving presentation of a sound image.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0011" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0013" num="0012">These and other advantages and features will become apparent from the following description thereof taken in conjunction with the accompanying Drawings, by way of non-limiting examples of embodiments disclosed herein.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating an example of a configuration of an acoustic reproduction device according to Embodiment 1.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> is a diagram schematically illustrating a target space of the acoustic reproduction device according to Embodiment 1.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> is a flowchart illustrating one example of an acoustic reproduction method employed by the acoustic reproduction device according to Embodiment 1.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating an example of a configuration of an acoustic reproduction device according to Embodiment 2.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is a flowchart illustrating one example of an acoustic reproduction method employed by the acoustic reproduction device according to Embodiment 2.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> is a flowchart illustrating an example of processing for adaptably determining a second position in the acoustic reproduction device according to Embodiment 2.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram illustrating a variation of the acoustic reproduction device according to Embodiment 2.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram illustrating an example of a hardware configuration of the acoustic reproduction device according to Embodiments 1 and 2.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0012" level="1">DESCRIPTION OF EMBODIMENTS</heading><heading id="h-0013" level="2">(Underlying Knowledge Forming Basis of the Present Disclosure)</heading><p id="p-0022" num="0021">In relation to the conventional techniques disclosed in the Background Art section, the inventors have found the following problems.</p><p id="p-0023" num="0022">PTL 1 proposes an auditory supporting system capable of assisting an auditory sense of a user by reproducing a three-dimensional sound environment observed in a target space for the user. The auditory supporting system disclosed by PTL 1 synthesizes a sound signal for reproducing a sound in each ear of the user from separation sound signals, using a head-related transfer function from the position of a sound source to each ear of the user according to the position of the sound source and an orientation of the face in the target space. The auditory supporting system further corrects a sound volume for each of frequency bands according to characteristics of hardness of hearing. With this, the auditory supporting system can realize agreeable auditory support, and can optionally control necessary sounds and unnecessary sounds for a user by separating individual sounds in an environment.</p><p id="p-0024" num="0023">However, PTL 1 poses the following problems. Although PTL 1 controls frequency characteristics, PTL 1 only uses a head-related transfer function for sound localization. For this reason, it is difficult for a user to accurately perceive the position of a sound image in the height direction. In other words, compared to the left-right direction with respect to the head or the ears of a user, the problem of difficulty in accurately perceiving a sound image in the up-down direction, namely, the height direction, remains unsolved.</p><p id="p-0025" num="0024">NPL 1 proposes, as one method of assisting visual impairment, a technique of transmitting an image including text via the auditory sense. The sound image display device according to NPL 1 associates positions of synthesized sounds with positions of pixels, temporally changes the associations, and scans the associations as point sound images to produce a display image in a space perceivable by both ears. The sound image display device according to NPL 1 further adds, within a display surface, a point sound image (called as a marker sound) that is an indicator of a position that does not merge with a sound image of a display point, and clarifies the relative positional relationship with the display point to enhance localization accuracy of the display point using the auditory sense. White noise that favorably produces an additional effect is used for the marker sound, and the marker sound is set at the central position in the left-right direction.</p><p id="p-0026" num="0025">However, NPL 1 poses the following problems. Since a marker sound is noise to a point sound image as a display point, the disclosure of NPL 1 reduces the quality of acoustics when used for virtual reality (VR), augmented reality (AR), mixed reality (MR), and the like, and interferes with the sense of immersion that a user experience.</p><p id="p-0027" num="0026">In view of the above, the present disclosure provides an acoustic reproduction method, an acoustic reproduction device, and a recording medium which improve presentation of a sound image.</p><p id="p-0028" num="0027">For this reason, an acoustic reproduction method according to one aspect of the present disclosure includes: localizing a first sound image at a first position in a target space in which a user is present; and localizing a second sound image at a second position in the target space. The second sound image represents an anchor sound for indicating a reference position.</p><p id="p-0029" num="0028">With this, presentation of a sound image of a first sound can be improved. Specifically, the first sound image is made perceivable according to a relative positional relationship between the first sound image and a second sound image as an anchor sound. Therefore, it is possible to accurately present the sound image of the first sound, even when the first sound image is positioned in the height direction.</p><p id="p-0030" num="0029">For example, in the localizing of the second sound image, the acoustic reproduction method may use some of ambient sounds or some of reproduced sounds in the target space as a sound source of the anchor sound.</p><p id="p-0031" num="0030">With this, since some of ambient sounds or some of reproduced sounds in a space are used as the sound source of an anchor sound, a reduction in the quality of acoustics can be prevented. For example, it is possible to prevent the anchor sound from interfering with the sense of immersion that a user experience.</p><p id="p-0032" num="0031">For example, the acoustic reproduction method may further include obtaining, using a microphone, ambient sounds arriving at the user from a direction of the second position in the target space. In the localizing of the second sound image, the ambient sounds obtained may be used as a sound source of the anchor sound.</p><p id="p-0033" num="0032">With this, since some of ambient sounds or some of reproduced sounds in a space are used as the sound source of an anchor sound, a reduction in the quality of acoustics can be prevented. For example, it is possible to prevent the anchor sound from interfering with the sense of immersion that a user experience.</p><p id="p-0034" num="0033">For example, the acoustic reproduction method may further include: obtaining, using a microphone, ambient sounds arriving at the user in the target space; selectively obtaining, from among the ambient sounds obtained, a sound that satisfies a predetermined condition; and determining a position in a direction of the sound selectively obtained to be the second position.</p><p id="p-0035" num="0034">With this, a degree of freedom in selecting a sound as the sound source of an anchor sound is enhanced, and thus the second position can be adaptably set.</p><p id="p-0036" num="0035">For example, the predetermined condition may relate to at least one of an arrival direction of a sound, duration of a sound, intensity of a sound, a frequency of a sound, and a type of a sound.</p><p id="p-0037" num="0036">With this, an appropriate sound can be selected as the sound source of an anchor sound.</p><p id="p-0038" num="0037">For example, as a condition indicating an arrival direction of a sound, the predetermined condition may include an angular range indicating a direction (i) not including a vertical direction with respect to the user, and (ii) including a forward direction and a horizontal direction with respect to the user.</p><p id="p-0039" num="0038">With this, as an anchor sound, a sound in a direction in which sounds are comparatively accurately perceived, namely, a direction closer to the horizontal direction can be selected.</p><p id="p-0040" num="0039">For example, as a condition indicating intensity of a sound, the predetermined condition may include a predetermined intensity range.</p><p id="p-0041" num="0040">With this, as an anchor sound, a sound having appropriate intensity can be selected.</p><p id="p-0042" num="0041">For example, as a condition indicating a frequency of a sound, the predetermined condition may include a particular frequency range.</p><p id="p-0043" num="0042">With this, as an anchor sound, a sound with an appropriate frequency which is readily perceived can be selected.</p><p id="p-0044" num="0043">For example, as a condition indicating a type of a sound, the predetermined condition may include a human voice or a special sound.</p><p id="p-0045" num="0044">With this, as an anchor sound, an appropriate sound can be selected.</p><p id="p-0046" num="0045">For example, the localizing of the second sound image may include adjusting intensity of the anchor sound according to intensity of a first sound source.</p><p id="p-0047" num="0046">With this, the volume of an anchor sound can be adjusted according to a relative relationship with the first sound source.</p><p id="p-0048" num="0047">For example, an elevation angle or a depression angle of the second position with respect to the user may be smaller than a predetermined angle.</p><p id="p-0049" num="0048">With this, as an anchor sound, a sound in a direction in which sounds are comparatively accurately perceived, namely, a direction closer to the horizontal direction can be selected.</p><p id="p-0050" num="0049">In addition, a recording medium according to one aspect of the present disclosure is a non-transitory computer-readable recording medium for use in a computer. The recording medium has a computer program recorded thereon for causing the computer to execute the above-described acoustic reproduction method.</p><p id="p-0051" num="0050">With this, presentation of a sound image of a first sound can be improved. Specifically, a first sound image is made perceivable according to a relative positional relationship between the first sound image and a second sound image as an anchor sound. Therefore, it is possible to accurately present the sound image of the first sound, even when the first sound image is positioned in the height direction.</p><p id="p-0052" num="0051">Moreover, an acoustic reproduction device according to one aspect of the present disclosure includes: a decoder that decodes an encoded sound signal that causes a user to perceive a first sound image; a first localizer that localizes, according to the encoded sound signal that has been decoded, the first sound image at a first position in a target space in which the user is present; and a second localizer that localizes, at a second position in the target space, a second sound image that represents an anchor sound for indicating a reference position.</p><p id="p-0053" num="0052">With this, presentation of a sound image of a first sound can be improved. Specifically, a first sound image is made perceivable according to a relative positional relationship between the first sound image and a second sound image as an anchor sound. Therefore, it is possible to accurately present the sound image of the first sound, even when the first sound image is positioned in the height direction.</p><p id="p-0054" num="0053">Note that these general or specific aspects may be realized by a system, a method, an integrated circuit, a computer program, or a non-transitory computer-readable recording medium such as a CD-ROM, or by any optional combination of systems, methods, integrated circuits, computer programs, or recording media.</p><p id="p-0055" num="0054">Hereinafter, embodiments will be described in detail with reference to the drawings.</p><p id="p-0056" num="0055">Note that the embodiments below each describe a general or specific example. The numerical values, shapes, materials, structural elements, the arrangement and connection of the structural elements, steps, orders of the steps etc. illustrated in the following embodiments are mere examples, and are not intended to limit the present disclosure.</p><heading id="h-0014" level="1">Embodiment 1</heading><heading id="h-0015" level="1">DEFINITION OF TERMS</heading><p id="p-0057" num="0056">First, the following provides definitions of technical terms that appear in the present disclosure.</p><p id="p-0058" num="0057">An &#x201c;encoded sound signal&#x201d; includes a sound object that causes a user to perceive a sound image. The encoded sound signal may be a signal that adheres to, for example, the MPEG-H Audio standard. This sound signal includes a plurality of audio channels, and a sound object indicating a first sound image. The plurality of audio channels include, at the maximum, 64 or 128 audio channels, for example.</p><p id="p-0059" num="0058">A &#x201c;sound object&#x201d; is data indicating a virtual sound image to be perceived by a user. Hereinafter, the sound object includes a sound of a first sound image and a first position indicating a position of the first sound image. Note that the term &#x201c;sound&#x201d; in a sound signal, a sound object, etc. does not exclusively connote a voice. The term applies to any audible sound.</p><p id="p-0060" num="0059">&#x201c;Localization of a sound image&#x201d; refers to an act of causing a user to perceive a sound image at a virtual position in a target space in which the user is present by convolving each of a head-related transfer function (HRTF) for the left ear and an HRTF for the right ear with a sound signal.</p><p id="p-0061" num="0060">A &#x201c;binaural signal&#x201d; is a signal obtained by convolving each of an HRTF for the left ear and an HRTF for the right ear with a sound signal that is the sound source of a sound image.</p><p id="p-0062" num="0061">A &#x201c;target space&#x201d; is a virtual three-dimensional space or a real three-dimensional space in which a user is present. The target space is a three-dimensional space, such as VR, AR, MR, in which a user perceives sounds.</p><p id="p-0063" num="0062">An &#x201c;anchor sound&#x201d; is a sound arriving from a sound image provided for causing a user to perceive a reference position in a target space. Hereinafter, a sound image that emits an anchor sound will be called a second sound image. Since the second sound image as an anchor sound makes a first sound image perceivable according to a relative positional relationship, the second sound image causes a user to more accurately perceive the position of a first sound image even when the first sound image is at a position in the height direction.</p><heading id="h-0016" level="2">[Configuration]</heading><p id="p-0064" num="0063">Next, a configuration of acoustic reproduction device <b>100</b> according to Embodiment 1 will be described. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating an example of a configuration of acoustic reproduction device <b>100</b> according to Embodiment 1. <figref idref="DRAWINGS">FIG. <b>2</b>A</figref> is a diagram schematically illustrating target space <b>200</b> of acoustic reproduction device <b>100</b> according to Embodiment 1. In <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, the Z axis direction denotes the front direction toward which user <b>99</b> is facing, the Y axis direction denotes the upward direction, and the X axis direction denotes the right direction.</p><p id="p-0065" num="0064">In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, acoustic reproduction device <b>100</b> includes decoder <b>101</b>, first localizer <b>102</b>, second localizer <b>103</b>, position estimator <b>104</b>, anchor direction estimator <b>105</b>, anchor sound producer <b>106</b>, mixer <b>107</b>, and headset <b>110</b>. Headset <b>110</b> includes pair of headphones <b>111</b>, head sensor <b>112</b>, and microphone <b>113</b>. Note that, in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the head of user <b>99</b> is schematically illustrated inside a frame surrounding headset <b>110</b>.</p><p id="p-0066" num="0065">Decoder <b>101</b> decodes an encoded sound signal. The encoded sound signal may be a signal that adheres to, for example, the MPEG-H Audio standard.</p><p id="p-0067" num="0066">First localizer <b>102</b> localizes a first sound image at a first position in a target space in which user <b>99</b> is present, according to the position of a sound object included in the decoded sound signal, the relative position of user <b>99</b>, and the direction of the head. From first localizer <b>102</b>, a first binaural signal that causes the first sound image to localize at the first position is output. <figref idref="DRAWINGS">FIG. <b>2</b>A</figref> schematically illustrates a situation in which first sound image <b>201</b> is localized in target space <b>200</b> in which user <b>99</b> is present. First sound image <b>201</b> is set at an optional position in target space <b>200</b> according to the sound object. It is difficult for user <b>99</b> to accurately perceive a position when first sound image <b>201</b> is localized in the up-down direction (i.e., the direction along the Y axis) with respect to user <b>99</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, compared to the case where first sound image <b>201</b> is localized in the horizontal direction (i.e., the direction along the X axis and the Z axis). Particularly for the case where an HRTF is not specific to a user or the case where headphones characteristics are not appropriately corrected, user <b>99</b> cannot accurately perceive the position of the first sound image.</p><p id="p-0068" num="0067">Second localizer <b>103</b> localizes, at a second position in the target space, a second sound image representing an anchor sound for indicating a reference position. From second localizer <b>103</b>, a second binaural signal that causes the second sound image to localize at the second position is output. In this case, second localizer <b>103</b> controls the volume and the frequency band of a second sound source such that the volume and the frequency band are appropriate for a first sound source and other reproduced sounds. For example, frequency characteristics of the second sound source may be controlled such that the crests and troughs of the frequency characteristics become smaller and flatter, or a signal may be controlled such that higher frequencies of the signal are emphasized. <figref idref="DRAWINGS">FIG. <b>2</b>A</figref> schematically illustrates a situation in which second sound image <b>202</b> is localized in target space <b>200</b> in which user <b>99</b> is present. The second position may be a predetermined fixed position, or may be a position adaptably determined based on ambient sounds or reproduced sounds. The second position may be a predetermined position in front of the face of a user in the initial state, namely, a predetermined position in the Z axis direction, or may be a predetermined position in a range from the front of the face of user <b>99</b> to the right side as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, for example. Second sound image <b>202</b> is localized in, for example, a direction close to the horizontal direction, namely, a direction from the horizontal direction to a direction within a predetermined angular range. Accordingly, an anchor sound is comparatively accurately perceived by user <b>99</b>. Since the anchor sound makes the first sound image perceivable according to the relative positional relationship, user <b>99</b> can more accurately perceive the position of the first sound image even when the first sound image is at a position in the height direction. Note that localization of the first sound image and the second sound image may be simultaneously performed or need not be simultaneously performed. When the localization is not simultaneously performed, a shorter time interval between the first sound image localization and the second sound image localization allows a user to more accurately perceive the sound images.</p><p id="p-0069" num="0068">Position estimator <b>104</b> obtains orientation information output from head sensor <b>112</b>, and estimates a direction of the head of user <b>99</b>, namely, a direction toward which the face is facing.</p><p id="p-0070" num="0069">In response to a movement made by user <b>99</b>, anchor direction estimator <b>105</b> estimates a new anchor direction, namely, the direction of a new second position, according to the direction estimated by position estimator <b>104</b>. The estimated direction of the second position is notified to anchor sound producer <b>106</b>.</p><p id="p-0071" num="0070">Note that the anchor direction may be a fixed direction in reference to a target space, or may be a fixed direction determined depending on an environment.</p><p id="p-0072" num="0071">Anchor sound producer <b>106</b> selectively obtains a sound arriving from the new anchor sound direction estimated by anchor direction estimator <b>105</b> from among ambient sounds picked up from every direction by microphone <b>113</b>. Furthermore, using the selectively obtained sound as the sound source of an anchor sound, anchor sound producer <b>106</b> adjusts the intensity, namely, the volume and frequency characteristics of the selectively obtained sound to produce an appropriate anchor sound. The intensity and frequency characteristics of the anchor sound may be adjusted depending on the sound of the first sound image.</p><p id="p-0073" num="0072">Mixer <b>107</b> mixes a first binaural signal output from first localizer <b>102</b> and a second binaural signal output from second localizer <b>103</b> together. A sound signal obtained by mixing the two binaural signals includes a left ear signal specific to the left ear and a right ear signal specific to the right ear, and is output to pair of headphones <b>111</b>.</p><p id="p-0074" num="0073">Pair of headphones <b>111</b> includes a left ear speaker and a right ear speaker. The left ear speaker converts the left ear signal into a sound, and the right ear speaker converts the right ear signal into a sound. Pair of headphones <b>111</b> may be a type of earphones inserted into the external ears.</p><p id="p-0075" num="0074">Head sensor <b>112</b> detects a direction toward which the head of user <b>99</b> is directed, namely, a direction toward which the face is facing, and outputs the direction as orientation information. Head sensor <b>112</b> may be a sensor that detects information on six degrees of freedom (6DOF) of the head of user <b>99</b>. Head sensor <b>112</b> may be an inertial measurement unit (IMU), an accelerometer, a gyroscope, or a magnetometric sensor, or a combination thereof.</p><p id="p-0076" num="0075">Microphone <b>113</b> picks up ambient sounds arriving at user <b>99</b> in the target space, and converts these ambient sounds into an electrical signal. Microphone <b>113</b> consists of, for example, a left microphone and a right microphone. The left microphone may be provided in the vicinity of the left ear speaker, and the right microphone may be provided in the vicinity of the right ear speaker. Note that microphone <b>113</b> may be a microphone having directionality which is capable of optionally designating a direction in which sounds are picked up, or may consist of three microphones. Moreover, microphone <b>113</b> may pick up sounds reproduced in pair of headphones <b>111</b>, instead of or in addition to ambient sounds, and convert these sounds into an electrical signal. When the second sound image is localized, second localizer <b>103</b> may use, as the sound source of an anchor sound, some of reproduced sounds instead of ambient sounds that arrive at a user from the direction of the second position in the target space.</p><p id="p-0077" num="0076">Note that headset <b>110</b> may be a unit separated from the main unit of acoustic reproduction device <b>100</b>, or may be integrated with the main unit of acoustic reproduction device <b>100</b>. When headset <b>110</b> is integrated with the main unit of acoustic reproduction device <b>100</b>, headset <b>110</b> and acoustic reproduction device <b>100</b> may be wirelessly connected with each other.</p><heading id="h-0017" level="2">[Operation]</heading><p id="p-0078" num="0077">Next, general operations performed by acoustic reproduction device <b>100</b> according to Embodiment 1 will be described.</p><p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> is a flowchart illustrating one example of an acoustic reproduction method employed by acoustic reproduction device <b>100</b> according to Embodiment 1. Firstly, as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, acoustic reproduction device <b>100</b> decodes an encoded sound signal that causes a user to perceive a first sound image (S<b>21</b>). Next, acoustic reproduction device <b>100</b> localizes the first sound image at a first position within a target space in which the user is present, according to the encoded sound signal that has been decoded (S<b>22</b>). Specifically, acoustic reproduction device <b>100</b> generates a first binaural signal by convolving each of an HRTF for the left ear and an HRTF for the right ear with the sound signal of the first sound image. Furthermore, acoustic reproduction device <b>100</b> localizes, at a second position in the target space, a second sound image representing an anchor sound for indicating a reference position (S<b>23</b>). Specifically, acoustic reproduction device <b>100</b> generates a second binaural signal by convolving each of an HRTF for the left ear and an HRTF for the right ear with a sound signal of an anchor sound represented by the second sound image. Acoustic reproduction device <b>100</b> repeatedly performs step S<b>21</b> through step S<b>23</b> at regular intervals. Alternatively, acoustic reproduction device <b>100</b> may repeatedly perform step S<b>22</b> and step S<b>23</b> at regular intervals while continuing decoding of a sound signal as a bitstream (S<b>21</b>).</p><p id="p-0080" num="0079">Reproduction of a first binaural signal for localization of a first sound image and a second binaural signal for localization of a second sound image via pair of headphones <b>111</b> allows user <b>99</b> to perceive the first sound image and the second sound image. In this case, user <b>99</b> perceives the first sound image according to the relative positional relationship using an anchor sound from the second sound image as a reference. Accordingly, user <b>99</b> can more accurately perceive the position of the first sound image even when the first sound image is at a position in the height direction.</p><p id="p-0081" num="0080">Note that as the sound source of an anchor sound to be emitted from the second sound image, sounds among ambient sounds arriving at user <b>99</b> which arrive from some direction or sounds among reproduced sounds which arrive from some direction can be used; however, the sound source of an anchor sound is not limited to the foregoing sounds. The sound source of an anchor sound may be predetermined sounds that are not out of tune with ambient sounds or reproduced sounds.</p><heading id="h-0018" level="1">Embodiment 2</heading><p id="p-0082" num="0081">Next, acoustic reproduction device <b>100</b> according to Embodiment 2 will be described.</p><p id="p-0083" num="0082">In Embodiment 2, sounds among ambient sounds arriving at a user in a target space from some direction are used as the sound source of an anchor sound. For example, acoustic reproduction device <b>100</b> obtains, using a microphone, ambient sounds arriving at the user in the target space, selectively obtains a sound that satisfies a predetermined condition from the obtained ambient sounds, and uses the selectively obtained sound as the sound source of the anchor sound in the step of localizing a second sound image. With this, a user can more accurately perceive the position of a first sound image according to the relative positional relationship with the anchor sound. In addition, since the anchor sound is a sound among the ambient sounds, the user hardly feels strange when they hear the anchor sound. As described above, it is readily possible to prevent an anchor sound from interfering with the sense of immersion that a user experience.</p><heading id="h-0019" level="2">[Configuration]</heading><p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating an example of a configuration of an acoustic reproduction device according to Embodiment 2. Compared to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, acoustic reproduction device <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> is different in that acoustic reproduction device <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> (i) further includes ambient sound obtainer <b>301</b>, directionality controller <b>302</b>, first direction obtainer <b>303</b>, anchor direction estimator <b>304</b>, and first volume obtainer <b>305</b>, and (ii) includes anchor sound producer <b>106</b><i>a </i>instead of anchor sound producer <b>106</b>. Hereinafter, different points will be mainly described.</p><p id="p-0085" num="0084">Ambient sound obtainer <b>301</b> obtains ambient sounds picked up by microphone <b>113</b>. Microphone <b>113</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> not only picks up ambient sounds in every direction, but also has directionality according to which sounds are picked up under control of directionality controller <b>302</b>. Here, ambient sound obtainer <b>301</b> is to obtain, using microphone <b>113</b>, ambient sounds in a direction in which a second sound image is to be localized.</p><p id="p-0086" num="0085">Directionality controller <b>302</b> controls directionality of microphone <b>113</b> according to which sounds are picked up. Specifically, directionality controller <b>302</b> controls microphone <b>113</b> such that microphone <b>113</b> has directionality in a new anchor direction estimated by anchor direction estimator <b>304</b>. Consequently, sounds picked up by microphone <b>113</b> are ambient sounds arriving from the new anchor direction, namely, the direction of a new second position, which is estimated in response to a movement made by user <b>99</b>.</p><p id="p-0087" num="0086">First direction obtainer <b>303</b> obtains the direction of a first sound image and the first position from a sound object decoded by decoder <b>101</b>.</p><p id="p-0088" num="0087">In response to a movement made by user <b>99</b>, anchor direction estimator <b>304</b> estimates a new anchor direction, namely, the direction of a new second position, based on a direction toward which the face of user <b>99</b> is facing which is estimated by position estimator <b>104</b> and the direction of the first sound image which is obtained by first direction obtainer <b>303</b>.</p><p id="p-0089" num="0088">First volume obtainer <b>305</b> obtains first volume that is volume of the first sound image from the sound object decoded by decoder <b>101</b>.</p><p id="p-0090" num="0089">Anchor sound producer <b>106</b><i>a </i>produces an anchor sound using, as the sound source, ambient sounds obtained by ambient sound obtainer <b>301</b>.</p><heading id="h-0020" level="2">[Operation]</heading><p id="p-0091" num="0090">Next, operations performed by acoustic reproduction device <b>100</b> according to Embodiment 2 will be described.</p><p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is a flowchart illustrating one example of an acoustic reproduction method employed by acoustic reproduction device <b>100</b> according to Embodiment 2. Compared to <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, <figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is different in that the acoustic reproduction method illustrated in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref> further includes step S<b>43</b> through step S<b>45</b>. Hereinafter, different points will be mainly described.</p><p id="p-0093" num="0092">Acoustic reproduction device <b>100</b> detects the orientation of the face of user <b>99</b> (S<b>43</b>), after the first sound image is localized in step S<b>22</b>. Detection of the orientation of the face is performed by head sensor <b>112</b> and position estimator <b>104</b>.</p><p id="p-0094" num="0093">Furthermore, acoustic reproduction device <b>100</b> estimates an anchor direction from the detected orientation of the face (S<b>44</b>). Estimation of the anchor direction is performed by anchor direction estimator <b>304</b>. Specifically, anchor direction estimator <b>304</b> estimates a new anchor direction, namely, the direction of a new second position when the head of user <b>99</b> moves. When the head of user <b>99</b> does not move, acoustic reproduction device <b>100</b> estimates a direction same as the current anchor direction as a new anchor direction.</p><p id="p-0095" num="0094">Next, acoustic reproduction device <b>100</b> produces an anchor sound using ambient sounds arriving from the estimated anchor direction as the sound source (S<b>45</b>). Obtainment of the ambient sounds arriving from the estimated anchor direction is performed by directionality controller <b>302</b>, microphone <b>113</b>, and ambient sound obtainer <b>301</b>. Production of the anchor sound using the ambient sounds as the sound source is performed by anchor sound producer <b>106</b><i>a. </i></p><p id="p-0096" num="0095">Thereafter, acoustic reproduction device <b>100</b> localizes a second sound image representing the anchor sound at the second position in the estimated anchor direction (S<b>23</b>).</p><p id="p-0097" num="0096">According to <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>, acoustic reproduction device <b>100</b> can track a movement of the head of user <b>99</b> and localize the second sound image.</p><p id="p-0098" num="0097">Note that a second position at which a second sound image is localized may be predetermined, but may be adaptably determined based on ambient sounds. Next, processing for adaptably determining a second position based on ambient sounds will be exemplified.</p><p id="p-0099" num="0098"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> is a flowchart illustrating an example of processing for adaptably determining a second position in the acoustic reproduction device according to Embodiment 2. Acoustic reproduction device <b>100</b> performs the processes illustrated in <figref idref="DRAWINGS">FIG. <b>4</b>B</figref> before the processes illustrated in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref> are performed, for example. Furthermore, acoustic reproduction device <b>100</b> repeatedly perform the processes illustrated in <figref idref="DRAWINGS">FIG. <b>4</b>B</figref> in parallel with the processes illustrated in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>. As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>, acoustic reproduction device <b>100</b> obtains, using a microphone, ambient sounds arriving at user <b>99</b> in a target space (S<b>46</b>). The ambient sounds to be obtained in this case are ambient sounds obtained from every direction or from the entire perimeter of an angular range including the horizontal direction. Furthermore, acoustic reproduction device <b>100</b> searches for a direction that satisfies a predetermined condition from the obtained ambient sounds (S<b>47</b>). For example, acoustic reproduction device <b>100</b> selectively obtains a sound that satisfies a predetermined condition from among the obtained ambient sounds, and determines an arrival direction of the sound to be a direction that satisfies the predetermined condition. Furthermore, acoustic reproduction device <b>100</b> determines the second position such that the second position is present in a direction obtained as a result of the searching (S<b>48</b>).</p><p id="p-0100" num="0099">Here, a predetermined condition will be described. A predetermined condition relates to at least one of an arrival direction of a sound, duration of the sound, intensity of the sound, a frequency of the sound, and a type of the sound.</p><p id="p-0101" num="0100">For example, as a condition indicating the arrival direction of a sound, the predetermined condition includes an angular range indicating a direction (i) not including the vertical direction with respect to a user, and (ii) including the forward direction and the horizontal direction with respect to the user. With this, a sound in a direction in which sounds are comparatively accurately perceived, namely, a direction closer to the horizontal direction, can be selected as an anchor sound.</p><p id="p-0102" num="0101">Moreover, as a condition indicating the intensity of a sound, the predetermined condition may include a predetermined intensity range. With this, a sound having appropriate intensity can be selected as an anchor sound.</p><p id="p-0103" num="0102">Furthermore, as a condition indicating the frequency of a sound, the predetermined condition may include a particular frequency range. With this, a sound with an appropriate frequency which is readily perceived can be selected as an anchor sound.</p><p id="p-0104" num="0103">In addition, as a condition indicating the type of a sound, the predetermined condition may include a human voice or a special sound. With this, an appropriate sound can be selected as an anchor sound.</p><p id="p-0105" num="0104">Furthermore, as a condition indicating the duration of a sound, the predetermined condition may include continuation of at least a predetermined time period or an interruption of at least a predetermined period. With this, an appropriate sound having distinctive temporal characteristics can be selected as an anchor sound. Satisfaction of a predetermined condition by the sound source of an anchor sound can produce an appropriate anchor sound that would not make user <b>99</b> feel strange.</p><p id="p-0106" num="0105">According to <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>, the second position at which the second sound image is localized can be adaptably determined according to ambient sounds. Moreover, as the sound source of an anchor sound, sounds among ambient sounds which arrive from some direction can be used.</p><p id="p-0107" num="0106">Note that acoustic reproduction device <b>100</b> according to each embodiment may include a head mounted display (HMD) instead of headset <b>110</b>. In this case, the HMD is to include a display, in addition to pair of headphones <b>111</b>, head sensor <b>112</b>, and microphone <b>113</b>. Moreover, the main unit of the HMD may be provided with acoustic reproduction device <b>100</b>.</p><p id="p-0108" num="0107">In addition, the acoustic reproduction device according to Embodiment 2 which is illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may be modified as follows. <figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram illustrating a variation of acoustic reproduction device <b>100</b> according to Embodiment 2. In this variation, a configuration that uses reproduced sounds instead of ambient sounds is exemplified. Compared to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, acoustic reproduction device <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> is different in that acoustic reproduction device <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> includes reproduced sound obtainer <b>401</b> instead of ambient sound obtainer <b>301</b>.</p><p id="p-0109" num="0108">Reproduced sound obtainer <b>401</b> obtains a reproduced sounds decoded by decoder <b>101</b>. Anchor sound producer <b>106</b><i>a </i>produces an anchor sound using, as the sound source, the reproduced sounds obtained by reproduced sound obtainer <b>401</b>. For example, acoustic reproduction device <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> reproduces a sound signal including audio channels different from audio channels of a first sound source, selectively obtains a sound that satisfies a predetermined condition from among the reproduced sounds included in the reproduced sound signal, and uses the selectively obtained sound as the sound source of an anchor sound. With this, a user can more accurately perceive the position of a first sound image according to a relative positional relationship with the anchor sound. In addition, since the anchor sound is a sound among the reproduced sounds, the user hardly feels strange when they hear the anchor sound. As described above, it is readily possible to prevent an anchor sound from interfering with the sense of immersion that a user experience.</p><heading id="h-0021" level="1">OTHER EMBODIMENTS</heading><p id="p-0110" num="0109">Hereinbefore, the acoustic reproduction devices and the acoustic reproduction methods according to aspects of the present disclosure have been described based on the embodiments, yet the present disclosure is not limited to these embodiments. For example, the present disclosure may include, as embodiments of the present disclosure, different embodiments realized by (i) optionally combining the structural elements described in the specification, and (ii) excluding some of the structural elements described in the specification. Moreover, the present disclosure also includes variations achieved by applying various modifications conceivable to those skilled in the art to each of the embodiments etc. without departing from the essence of the present disclosure, or in other words, without departing from the meaning of wording recited in the claims.</p><p id="p-0111" num="0110">The following may also be included within a range of one or more aspects of the present disclosure.</p><p id="p-0112" num="0111">(1) Some of the structural elements included in the above-described acoustic reproduction devices may be realized as a computer system including a microprocessor, read-only memory (ROM), random-access memory (RAM), a hard disk unit, a display unit, a keyboard, a mouse, etc. The RAM or the hard disk unit stores a computer program. The microprocessor fulfills its function by operating according to the computer program. Here, the computer program includes a combination of a plurality of instruction codes each indicating an instruction to the computer for fulfilling a predetermined function.</p><p id="p-0113" num="0112">Acoustic reproduction device <b>100</b> as described above may have a hardware configuration as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, for example. Acoustic reproduction device <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> includes input/output (I/O) unit <b>11</b>, display controller <b>12</b>, memory <b>13</b>, processor <b>14</b>, pair of headphones <b>111</b>, head sensor <b>112</b>, microphone <b>113</b>, and display <b>114</b>. Some of the structural elements included in acoustic reproduction device <b>100</b> according to Embodiments 1 through 2 fulfill its function by processor <b>14</b> executing a program stored in memory <b>13</b>. The hardware configuration illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> may be a head-mounted display (HMD), a combination of headset <b>110</b> and a tablet-type terminal, a combination of headset <b>110</b> and a smartphone, or a combination of headset <b>110</b> and an information processing device (e.g., a personal computer (PC) or a television), for example.</p><p id="p-0114" num="0113">(2) Some of the structural elements included in the above-described acoustic reproduction devices and acoustic reproduction methods may be configured from a single system large-scale integration (LSI) circuit. The system LSI circuit is a super-multifunction LSI circuit manufactured with a plurality of components integrated on a single chip. Specifically, the system LSI circuit is a computer system including a microprocessor, ROM, and RAM, for example. The RAM stores a computer program. The system LSI circuit fulfills its function as a result of the microprocessor operating according to the computer program.</p><p id="p-0115" num="0114">(3) Some of structural elements included in the above-described acoustic reproduction devices may be configured from an IC card detachable from devices or a stand-alone module. The IC card or the module is a computer system configured from a microprocessor, ROM, and RAM, for example. The IC card or the module may include the above-described super-multifunction LSI circuit. The IC card or the module fulfills its function as a result of the microprocessor operating according to a computer program. The IC card or the module may be tamper-proof.</p><p id="p-0116" num="0115">(4) Moreover, some of structural elements included in the above-described acoustic reproduction devices may be realized as the computer program or the digital signal recorded on a computer-readable recording medium, such as a flexible disk, hard disk, CD-ROM, magneto-optical disk (MO), DVD, DVD-ROM, DVD-RAM, Blu-ray Disc (BD, registered trademark), and semiconductor memory. In addition, some of structural elements included in the above-described acoustic reproduction devices may be digital signals recorded on these recording media.</p><p id="p-0117" num="0116">Some of structural elements included in the above-described acoustic reproduction devices may be realized by transmitting the computer program or the digital signal via an electric communication line, a wireless or wired line, a network epitomized by the Internet, data broadcasting, etc.</p><p id="p-0118" num="0117">(5) The present disclosure may be realized as the methods described above. The present disclosure may also be realized as a computer program realizing such methods using a computer, or as a digital signal of the computer program.</p><p id="p-0119" num="0118">(6) Moreover, the present disclosure may be a computer system including a microprocessor and memory. The memory may store the computer program, and the microprocessor may operate according to the computer program.</p><p id="p-0120" num="0119">(7) In addition, another independent computer system may execute the program or the digital signal by receiving a transmitted recording medium on which the program or the digital signal is recorded, or by receiving the program or the digital signal transmitted via the network.</p><p id="p-0121" num="0120">(8) The present disclosure may be realized by combining the above-described embodiments and variations.</p><p id="p-0122" num="0121">It should be noted that, in the above-described embodiments, each of the structural elements may be configured as a dedicated hardware product or may be realized by a microprocessor executing a software program suitable for the structural element. Each element may be realized as a result of a program execution unit, such as a central processing unit (CPU), processor or the like, loading and executing a software program stored in a storage medium such as a hard disk or a semiconductor memory.</p><p id="p-0123" num="0122">In addition, the present disclosure is not limited to the above-described embodiments. The scope of the one or more aspects of the present disclosure may encompass embodiments as a result of making, to the embodiments, various modifications that may be conceived by those skilled in the art and combining structural elements in different embodiments, as long as the resultant embodiments do not depart from the scope of the present disclosure.</p><heading id="h-0022" level="1">INDUSTRIAL APPLICABILITY</heading><p id="p-0124" num="0123">The present disclosure is applicable to an acoustic reproduction device and an acoustic reproduction method. For example, the present disclosure is applicable to a stereophonic reproduction device.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An acoustic reproduction method comprising:<claim-text>localizing a first sound image at a first position in a target space in which a user is present; and</claim-text><claim-text>localizing a second sound image at a second position in the target space, the second sound image representing an anchor sound for indicating a reference position.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The acoustic reproduction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>in the localizing of the second sound image, some of ambient sounds or some of reproduced sounds in the target space are used as a sound source of the anchor sound.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The acoustic reproduction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>obtaining, using a microphone, ambient sounds arriving at the user from a direction of the second position in the target space, wherein</claim-text><claim-text>in the localizing of the second sound image, the ambient sounds obtained are used as a sound source of the anchor sound.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The acoustic reproduction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>obtaining, using a microphone, ambient sounds arriving at the user in the target space;</claim-text><claim-text>selectively obtaining, from among the ambient sounds obtained, a sound that satisfies a predetermined condition; and</claim-text><claim-text>determining a position in a direction of the sound selectively obtained to be the second position.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The acoustic reproduction method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein<claim-text>the predetermined condition relates to at least one of an arrival direction of a sound, duration of a sound, intensity of a sound, a frequency of a sound, and a type of a sound.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The acoustic reproduction method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein<claim-text>as a condition indicating an arrival direction of a sound, the predetermined condition includes an angular range indicating a direction (i) not including a vertical direction with respect to the user, and (ii) including a forward direction and a horizontal direction with respect to the user.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The acoustic reproduction method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein<claim-text>as a condition indicating intensity of a sound, the predetermined condition includes a predetermined intensity range.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The acoustic reproduction method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein<claim-text>as a condition indicating a frequency of a sound, the predetermined condition includes a predetermined frequency range.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The acoustic reproduction method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein<claim-text>as a condition indicating a type of a sound, the predetermined condition includes a human voice or a special sound.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The acoustic reproduction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the localizing of the second sound image includes adjusting intensity of the anchor sound according to intensity of a first sound source.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The acoustic reproduction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>an elevation angle or a depression angle of the second position with respect to the user is smaller than a predetermined angle.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A non-transitory computer-readable recording medium for use in a computer, the recording medium having a computer program recorded thereon for causing the computer to execute the acoustic reproduction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. An acoustic reproduction device comprising:<claim-text>a decoder that decodes an encoded sound signal, the encoded sound signal causing a user to perceive a first sound image;</claim-text><claim-text>a first localizer that localizes, according to the encoded sound signal that has been decoded, the first sound image at a first position in a target space in which the user is present; and</claim-text><claim-text>a second localizer that localizes a second sound image at a second position in the target space, the second sound image representing an anchor sound for indicating a reference position.</claim-text></claim-text></claim></claims></us-patent-application>
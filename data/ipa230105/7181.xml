<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007182A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007182</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17834924</doc-number><date>20220607</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>TW</country><doc-number>110138713</doc-number><date>20211019</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>232</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23296</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><invention-title id="d2e61">IMAGE CONTROLLER, IMAGE PROCESSING SYSTEM AND IMAGE CORRECTING METHOD</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63217770</doc-number><date>20210702</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>GENESYS LOGIC, INC.</orgname><address><city>New Taipei City</city><country>TW</country></address></addressbook><residence><country>TW</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Hu</last-name><first-name>Shi-Ming</first-name><address><city>New Taipei City</city><country>TW</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Chao</last-name><first-name>Hsueh-Te</first-name><address><city>New Taipei City</city><country>TW</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>GENESYS LOGIC, INC.</orgname><role>03</role><address><city>New Taipei City</city><country>TW</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An image controller, an image processing system, and an image correcting method are provided. A first controller obtains a first image from an image capturing apparatus. The first controller converts the first image into a second image according to a converting operation. The converting operation includes deformation correction, and the deformation correction is used to correct deformation of one or more target objects in the first image. A second controller detects the target object in the second image to generate a detected result. The first controller corrects the converting operation according to the detected result. A visual experience may thus be improved in this way.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="150.96mm" wi="86.19mm" file="US20230007182A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="167.05mm" wi="88.22mm" file="US20230007182A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="107.02mm" wi="111.51mm" file="US20230007182A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="207.52mm" wi="150.54mm" file="US20230007182A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="219.63mm" wi="149.78mm" file="US20230007182A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="217.59mm" wi="149.78mm" file="US20230007182A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="222.76mm" wi="150.37mm" file="US20230007182A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="127.85mm" wi="152.23mm" file="US20230007182A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="221.23mm" wi="153.33mm" file="US20230007182A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="217.25mm" wi="133.60mm" file="US20230007182A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="194.73mm" wi="86.78mm" file="US20230007182A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="206.67mm" wi="119.30mm" file="US20230007182A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="201.59mm" wi="115.65mm" file="US20230007182A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="220.90mm" wi="144.70mm" file="US20230007182A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="194.06mm" wi="144.70mm" file="US20230007182A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="124.29mm" wi="136.48mm" file="US20230007182A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="195.50mm" wi="141.39mm" file="US20230007182A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This application claims the priority benefit of U.S. provisional application Ser. No. 63/217,770, filed on Jul. 2, 2021 and Taiwan application Ser. No. 110138713, filed on Oct. 19, 2021. The entirety of each of the above-mentioned patent applications is hereby incorporated by reference herein and made a part of this specification.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Technical Field</heading><p id="p-0003" num="0002">The disclosure relates to an image processing technology, and in particular, to an image controller, an image processing system, and an image correcting method.</p><heading id="h-0004" level="1">Description of Related Art</heading><p id="p-0004" num="0003">In the related art, although a camera equipped with a wide-angle lens or a fisheye lens may be used to capture an image with a wide field of view (FoV), the edges of the image may be curved and an unnatural appearance may be provided. Distortion of a wide-angle or fisheye image may make its content difficult to recognize, and may cause discomfort to the user's eyes.</p><p id="p-0005" num="0004">Moreover, such cameras are usually installed in products such as rear-view mirrors, IP cameras, surveillance systems, IoT cameras, and machine vision-related products. In some application scenarios, the object in the image is the target that the viewer would like to track. However, there may be more than one object in the image and the object may move, but such products generally cannot provide a suitable image in response to the movement or the number of objects.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0006" num="0005">In view of the above, the embodiments of the disclosure provide an image controller, an image processing system, and an image correcting method through which a distorted image may be easily and effectively corrected, and recognition of a specific tracking target in the image may be improved.</p><p id="p-0007" num="0006">An embodiment of the disclosure provides an image correcting method including (but not limited to) the following steps. A first image from an image capturing apparatus is obtained. The first image is converted into a second image according to a converting operation. The converting operation includes deformation correction, and the deformation correction is used to correct deformation of one or more target objects in the first image. The target object in the second image is detected to generate a detected result. The converting operation is corrected according to the detected result.</p><p id="p-0008" num="0007">An embodiment of the disclosure further provides an image processing system including (but not limited to) an image capturing apparatus, a first controller, and a second controller. The image capturing apparatus includes a lens and an image sensor. A first image may be captured through the lens and the image sensor. The first controller is coupled to the image capturing apparatus and is configured to convert the first image into a second image according to a converting operation. The converting operation includes distortion correction. The distortion correction is used to correct deformation of one or more target objects in the first image. The second controller is coupled to the first controller and is configured to detect the target objects in the second image to generate a detected result. The first controller if further configured to correct the converting operation according to the detected result.</p><p id="p-0009" num="0008">An embodiment of the disclosure further provides an image controller including (but not limited to) a memory and a processor. The memory is configured to store a program code. The processor is coupled to the memory. The processor is configured to load and execute the program code to obtain a first image, convert the first image into a second image according to a converting operation, detect one or more target objects in the second image to generate a detected result, and correct the converting operation according to the detected result. The converting operation includes deformation correction, and the deformation correction is used to correct deformation of one or more target objects in the first image.</p><p id="p-0010" num="0009">To sum up, in the image controller, the image processing system, and the image correcting method provided by the embodiments of the disclosure, the converting operation of the first controller is mainly corrected according to the detected result of the second controller for the target object. In this way, the distortion may be corrected and the target object may be highlighted in the second image.</p><p id="p-0011" num="0010">To make the aforementioned more comprehensible, several embodiments accompanied with drawings are described in detail as follows.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0012" num="0011">The accompanying drawings are included to provide a further understanding of the disclosure, and are incorporated in and constitute a part of this specification. The drawings illustrate exemplary embodiments of the disclosure and, together with the description, serve to explain the principles of the disclosure.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block view of devices in an image processing system according to an embodiment of the disclosure.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flow chart of an image correcting method according to an embodiment of the disclosure.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> is a schematic picture of dewarping according to an embodiment of the disclosure.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>3</b>B</figref> is a schematic picture of field of view (FoV) adjustment according to an embodiment of the disclosure.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>3</b>C</figref> is a schematic picture of zoom adjustment according to an embodiment of the disclosure.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>3</b>D</figref> is a schematic picture of shifting according to an embodiment of the disclosure.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>3</b>E</figref> is a schematic picture of upper and lower FoV adjustment according to an embodiment of the disclosure.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>3</b>F</figref> is a schematic picture of left and right FoV adjustment according to an embodiment of the disclosure.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>3</b>G</figref> is a schematic picture of plane FoV adjustment according to an embodiment of the disclosure.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>3</b>H</figref> is a schematic view of arrangement of an image capturing apparatus and captured images according to an embodiment of the disclosure.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>3</b>I</figref> is a schematic view of the arrangement of the image capturing apparatus and the captured images according to an embodiment of the disclosure.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>3</b>J</figref> is a schematic view of the arrangement of the image capturing apparatus and the captured images according to an embodiment of the disclosure.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic picture of an expanded fisheye image according to an embodiment of the disclosure.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic picture of a target layout according to an embodiment of the disclosure.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic picture of target layouts in a plurality of modes according to an embodiment of the disclosure.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> is a schematic picture of a target layout in a mode according to an embodiment of the disclosure.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> is a schematic picture of a target layout in a mode according to an embodiment of the disclosure.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>7</b>C</figref> is a schematic picture of a target layout in a mode according to an embodiment of the disclosure.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic diagram of coordinate system conversion in a mode according to an embodiment of the disclosure.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a schematic picture of a second image under a FoV according to an embodiment of the disclosure.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a schematic picture of a second image under a rotated FoV according to an embodiment of the disclosure.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a schematic picture of corrected second images according to an embodiment of the disclosure.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>12</b>A</figref> is a schematic picture of a second image of a conference scenario according to an embodiment of the disclosure.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>12</b>B</figref> is a schematic picture of a second image of the conference scenario according to another embodiment of the disclosure.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>12</b>C</figref> is a schematic picture of a corrected second image according to another embodiment of the disclosure.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a schematic picture of a multi-target window image according to an embodiment of the disclosure.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>14</b>A</figref> is a schematic picture of a second image of a multi-target window image according to an embodiment of the disclosure.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>14</b>B</figref> is a schematic picture of a corrected second image according to an embodiment of the disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DESCRIPTION OF THE EMBODIMENTS</heading><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block view of devices in an image processing system <b>1</b> according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the image processing system <b>1</b> includes (but not limited to) an image capturing apparatus <b>10</b>, a first controller <b>30</b>, and a second controller <b>50</b>.</p><p id="p-0042" num="0041">The image capturing apparatus <b>10</b> may be a camera, a video camera, a monitor, or an apparatus featuring similar functions. The image capturing apparatus <b>10</b> may include (but not limited to) a lens <b>11</b> and an image sensor <b>15</b> (e.g., a charge coupled device (CCD) or a complementary metal-oxide-semiconductor (CMOS), etc.). In an embodiment, an image may be captured through the lens <b>11</b> and the image sensor <b>15</b>. For instance, light may be imaged on the image sensor <b>15</b> through the lens <b>11</b>.</p><p id="p-0043" num="0042">In some embodiments, specifications of the image capturing apparatus <b>10</b> (e.g., imaging aperture, magnification, focal length, imaging viewing angle, size of the image sensor <b>15</b>, etc.) and a number thereof may be adjusted according to actual needs. For instance, the lens <b>11</b> is a fisheye or wide-angle lens and generates a fisheye image or a wide-angle image accordingly.</p><p id="p-0044" num="0043">The first controller <b>30</b> may be coupled to the image capturing apparatus <b>10</b> through a camera interface, I2C, and/or other transmission interfaces. The first controller <b>30</b> includes (but not limited to) a memory <b>31</b> and a processor <b>35</b>. The memory <b>31</b> may be a fixed or movable random access memory (RAM) in any form, a read only memory (ROM), a flash memory, a hard disk drive (HDD), a solid-state drive (SSD), or other similar devices. In an embodiment, the memory <b>31</b> is used to store a program code, a software module, a configuration, data, or a file. The processor <b>35</b> may be an image processor, a graphic processing unit (GPU), or a programmable microprocessor for general or special use, a digital signal processor (DSP), a programmable controller, a field programmable gate array (FPGA), an application-specific integrated circuit (ASIC), other similar devices, or a combination of the foregoing devices. In an embodiment, the processor <b>35</b> is configured to execute all or part of the operations of the first controller <b>30</b> and may load and execute various program codes, software modules, files, and data stored in the memory <b>31</b>.</p><p id="p-0045" num="0044">The second controller <b>50</b> may be coupled to the first controller <b>30</b> through a camera interface (e.g., mobile industry processor interface (MIPI)), I2C, USB, and/or other transmission interfaces. The second controller <b>50</b> includes (but not limited to) a memory <b>51</b> and a processor <b>55</b>. Implementation and functions of the memory <b>51</b> may be found with reference to the description of the memory <b>31</b>, which is not to be repeated herein. Implementation and functions of the processor <b>55</b> may be found with reference to the description of the processor <b>35</b>, which is not to be repeated herein. In an embodiment, the processor <b>55</b> is configured to execute all or part of the operations of the second controller <b>50</b> and may load and execute various program codes, software modules, files, and data stored in the memory <b>51</b>.</p><p id="p-0046" num="0045">In an embodiment, the image capturing apparatus <b>10</b>, the first controller <b>30</b>, and the second controller <b>50</b> may be integrated into an independent apparatus. For instance, the image processing system <b>1</b> is a camera system, where the first controller <b>30</b> may be a fisheye controller, a wide-angle lens controller, or other image-related controllers, and the second controller <b>50</b> is a microcontroller or an SoC. In another embodiment, the image capturing apparatus <b>10</b> and the first controller <b>30</b> may be integrated into a module, and the second controller <b>50</b> is, for example, a computer system (e.g., a desktop computer, a notebook computer, a server, a smartphone, or a tablet computer) or a part thereof. In still another embodiment, the first controller <b>30</b> and the second controller <b>50</b> may be integrated into an image controller or an appropriate controller module and may be coupled to the image capturing apparatus <b>10</b>.</p><p id="p-0047" num="0046">In the following paragraphs, a method provided by the embodiments of the disclosure is described together with the various apparatuses, devices, and modules in the image processing system <b>1</b>. The steps of the method may be adjusted according to actual implementation and are not limited by the disclosure.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flow chart of an image correcting method according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the first controller <b>30</b> obtains a first image from the image capturing apparatus <b>10</b> (step S<b>210</b>). To be specific, the first image is an image captured by the image capturing apparatus <b>10</b> or other external image capturing apparatuses on one or more target objects. In an embodiment, the target object is, for example, a human body. In some embodiments, the first image may also be for the upper body (e.g., the waist, shoulders, or above the chest) of a human. In other embodiments, the target object may also be various types of organisms or non-living organisms. The first controller <b>30</b> may obtain the first image captured by the image capturing apparatus <b>10</b> via the camera interface and/or I2C.</p><p id="p-0049" num="0048">The first controller <b>30</b> may convert the first image into a second image according to a converting operation (step S<b>230</b>). To be specific, in an embodiment, the converting operation comprises distortion correction. The distortion correction is used to correct deformation of one or more target objects in the first image. In another embodiment, the converting operation includes position adjustment. The position adjustment is used to correct a position or positions of one or more target objects in the first image. In still another embodiment, the converting operation includes distortion correction and position adjustment. That is, appearance and/or a position of the target object in the first image may be different from that of the same target object in the second image.</p><p id="p-0050" num="0049">For instance, <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> illustrates schematic pictures of dewarping according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, in this embodiment, the distortion correction is, for example, dewarping processing, and a first image FIM1 is, for example, an image obtained through a fisheye lens, and the image is, for example, a warped image. The first controller <b>30</b> may perform a converting operation, such as dewarping and unfolding, on the first image FIM1 to generate a second image SIM1, so that the second image SIM1 is closer to the real image. In this way, a target object image with a better ratio or a normal ratio may be generated.</p><p id="p-0051" num="0050">In some application scenarios, in order to adapt to a size (e.g., resolution of 1920&#xd7;1080 or 480&#xd7;272) or a ratio (e.g., 16:9 or 4:3) of a display apparatus, an imaging field of view (FoV) of the image may be adjusted. <figref idref="DRAWINGS">FIG. <b>3</b>B</figref> is a schematic picture of FoV adjustment according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, in this embodiment, the position adjustment included in the converting operation is, for example, FoV adjustment, and an imaging FoV of the lens <b>11</b> of the image capturing apparatus <b>10</b> is, for example, 180 degrees. Herein, the first controller <b>30</b> of this embodiment may, for example, change or adjust the imaging FoV of the first image FIM1 to become a FoV of FOV<b>1</b> (e.g., 140 degrees) (i.e., the converting operation) to generate a second image SIM2. Alternatively, the first controller <b>30</b> may change the imaging FoV of the first image FIM1 to become a FoV of FOV<b>2</b> (e.g., 110 degrees) (i.e., the converting operation) to generate a second image SIM3. In this way, the imaging FoV may be directed towards the target object at a specific position in front of the lens <b>11</b>.</p><p id="p-0052" num="0051">In some application scenarios, the image processing application is required to perform image zooming. For example, if the image is insufficient for image recognition, the image needs to be zoomed in. Besides, zooming in the image may cause the imaging FoV to be relatively narrowed. If an original size image is intended for viewing, the imaging FoV may be restored by zooming out the image. <figref idref="DRAWINGS">FIG. <b>3</b>C</figref> is a schematic picture of zoom adjustment according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>3</b>C</figref>, in this embodiment, the converting operation may further include zooming adjustment. In this embodiment, the first image FIM1 may be zoomed in (i.e., the converting operation) according to a zoom magnification SR<b>1</b> (e.g., 120%) to generate a second image SIMS. Alternatively, in this embodiment, the first image FIM1 may be zoomed out (i.e., the converting operation) according to a zoom magnification SR<b>2</b> (e.g., 80%) to generate a second image SIM6. In this way, the target object may be zoomed in or zoomed out.</p><p id="p-0053" num="0052">In some application scenarios, after the image is zoomed in, an area beyond a visible range in the image may be browsed by shifting. <figref idref="DRAWINGS">FIG. <b>3</b>D</figref> is a schematic picture of shifting according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>3</b>D</figref>, in this embodiment, the position adjustment included in the converting operation is, for example, image shifting, and the dotted-line boxes in the drawing represent the visible range of the first image, and the solid-line boxes represent the visible range of the second image. The first controller <b>30</b> may, for example, notify the image capturing apparatus <b>10</b> that the first image FIM1 may be shifted (i.e., the converting operation) according to a direction SH<b>1</b> (towards the upper right) to generate a second image SIM7. The first controller <b>30</b> may, for example, notify the image capturing apparatus <b>10</b> that the first image FIM1 may be shifted (i.e., the converting operation) according to a direction SH<b>2</b> (towards the lower left) to generate a second image SIM8. In this way, the position of the target object in the image may be changed.</p><p id="p-0054" num="0053">In some application scenarios, when an image of interest is located above or below the image capturing apparatus <b>10</b>, an angle may be adjusted through upper and lower FoV adjustment (or referred to as tilting adjustment) to obtain an improved imaging FoV. For instance, when the image capturing apparatus <b>10</b> is integrated into an electronic doorbell and is mounted on a wall, a height of the image capturing apparatus <b>10</b> may be higher or lower than a person's standing height, so that the imaging FoV may be changed through upper and lower FoV adjustment. <figref idref="DRAWINGS">FIG. <b>3</b>E</figref> is a schematic picture of upper and lower FoV adjustment according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>3</b>E</figref>, in this embodiment, the position adjustment included in the converting operation is, for example, upper and lower FoV adjustment. The image capturing apparatus <b>10</b> is installed upright and faces a y axis. The first controller <b>30</b> may, for example, notify the image capturing apparatus <b>10</b> that the FoV of the first image FIM1 in TI<b>1</b> may be adjusted upwards according to an axis x (i.e., the converting operation) to generate a second image SIM9. Alternatively, the first controller <b>30</b> may, for example, notify the image capturing apparatus <b>10</b> that the FoV of the first image FIM1 in TI<b>2</b> may be adjusted downwards according to the axis x (i.e., the converting operation) to generate a second image SIM10. In this way, the position of the target object in the image may be changed.</p><p id="p-0055" num="0054">In some application scenarios, when the image of interest is located to the left or right of the image capturing apparatus <b>10</b>, an angle may be adjusted through left and right FoV adjustment (or referred to as panning adjustment) to obtain an improved imaging FoV. For instance, when the image capturing apparatus <b>10</b> is integrated into an electronic doorbell and is mounted on a wall, the lens <b>11</b> may not face a visitor directly, so that the imaging FoV may be adjusted to face the visitor through panning adjustment. <figref idref="DRAWINGS">FIG. <b>3</b>F</figref> is a schematic picture of left and right FoV adjustment according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>3</b>F</figref>, the position adjustment included in the converting operation is, for example, left and right FoV adjustment (or referred to as panning adjustment). The image capturing apparatus <b>10</b> is installed upright and faces the y axis. The first controller <b>30</b> may, for example, notify the image capturing apparatus <b>10</b> that the FoV of the first image FIM1 in PA<b>1</b> may be adjusted to the right according to an axis z (i.e., the converting operation) to generate a second image SIM11. Alternatively, the first controller <b>30</b> may, for example, notify the image capturing apparatus <b>10</b> that the FoV of the first image FIM1 in PA<b>2</b> may be adjusted to the left according to the axis z (i.e., the converting operation) to generate a second image SIM12. In this way, the position of the target object in the image may be changed.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>3</b>G</figref> is a schematic picture of plane FoV adjustment according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>3</b>G</figref>, the position adjustment included in the converting operation is, for example, plane FoV adjustment (or referred to as rotating). The image capturing apparatus <b>10</b> is laid flat and faces the y axis. The first controller <b>30</b> may, for example, notify the image capturing apparatus <b>10</b> that the FoV of the first image FIM1 in RO<b>1</b> may be rotated clockwise according to the axis y (i.e., the converting operation) to generate a second image SIM13. Alternatively, the first controller <b>30</b> may, for example, notify the image capturing apparatus <b>10</b> that the FoV of the first image FIM1 in RO<b>2</b> may be rotated counterclockwise according to the axis y (i.e., the converting operation) to generate a second image SIM14. In this way, the position of the target object in the image may be changed.</p><p id="p-0057" num="0056">Regarding the application scenario of plane FoV adjustment, <figref idref="DRAWINGS">FIG. <b>3</b>H</figref> is a schematic view of arrangement of the image capturing apparatus <b>10</b> and captured images according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>3</b>H</figref>, the image capturing apparatus <b>10</b> is placed in a horizontal position. It is assumed that the lens <b>11</b> is a fisheye lens, light passes through the lens <b>11</b> and is projected on the image sensor <b>13</b> to generate a fisheye image IMe. According to application needs, the first controller <b>30</b> may, for example, notify the image capturing apparatus <b>10</b> to capture only an outer ring image IMo corresponding to an outer ring of the lens <b>11</b>.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>3</b>I</figref> is a schematic view of the arrangement of the image capturing apparatus <b>10</b> and the captured images according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>3</b>I</figref>, as shown in the upper half of the drawing, it is assumed that the image capturing apparatus <b>10</b> is placed among the <figref idref="DRAWINGS">figures P<b>1</b></figref>, P<b>2</b>, P<b>3</b>, and P<b>4</b> in a horizontal manner. If only the outer ring of the lens <b>11</b> is captured and is divided into two halves, outer ring images IMo1 and IMo2 may be generated. The outer ring image IMo1 captures the <figref idref="DRAWINGS">figures P<b>1</b></figref> and P<b>2</b>, and the outer ring image IMo2 captures the <figref idref="DRAWINGS">figures P<b>3</b></figref> and P<b>4</b>.</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>3</b>J</figref> is a schematic view of the arrangement of the image capturing apparatus <b>10</b> and the captured images according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>3</b>J</figref>, it is assumed that the first controller <b>30</b> performs plane FoV adjustment on the outer ring images IMo1 and IMo2 according to the direction of the arrow as shown in the left drawing. The <figref idref="DRAWINGS">figures P<b>1</b></figref> to P<b>4</b> with light-colored lines shown in the drawing represent their original positions, and the <figref idref="DRAWINGS">figures P<b>1</b></figref> to P<b>4</b> with dark-colored lines represent their positions after plane FoV adjustment is performed. The <figref idref="DRAWINGS">figures P<b>1</b></figref> and P<b>2</b> captured by the outer ring image IMo1 are shifted to the left, and the <figref idref="DRAWINGS">figures P<b>3</b></figref> and P<b>4</b> captured by the outer ring image IMo2 are shifted to the right.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic picture of an expanded fisheye image according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, it is assumed that a first image FIM2 is a fisheye image, and figures in the image are deformed. A second image SIM15 is an image corrected by the first controller <b>30</b>, and proportions of the figures in the image are normal.</p><p id="p-0061" num="0060">In an embodiment, the converting operation further includes a target layout (or referred to as a window layout or a multi-way split window). The second image includes a plurality of windows, for example. In addition, it is assumed that the second image includes one or more target objects. For instance, a first target, a second target, a third target, and/or a fourth target are included. The target layout is used to adjust a target window (i.e., one of those windows) of the first target among these target objects in the second image. In this embodiment, the second image may be divided into a plurality of windows, the image after the deformation correction is cropped, and a cropped portion of the image is arranged in a specific window. In a preferred embodiment, an application is adopted to divide the second image into a plurality of windows in this embodiment.</p><p id="p-0062" num="0061">For instance, <figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic picture of a target layout according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, after the first controller <b>30</b> performs deformation correction on the first image FIM2 in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the zoomed and/or cropped images are arranged in different windows, for example, in TW<b>1</b> and TW<b>2</b>. The images arranged in different windows TW<b>1</b> and TW<b>2</b> are, for example, images of people participating in a conference or images of participants who are specifically screened. The images of the participants who are specifically screened are, for example, the participants who speak in the conference.</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic picture of target layouts in a plurality of modes M<b>1</b> to M<b>15</b> according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, these plurality of modes M<b>1</b> to M<b>15</b> may include one window TW<b>1</b>, two windows TW<b>1</b> and TW<b>2</b>, three windows TW<b>1</b> to TW<b>3</b>, four windows TW<b>1</b> to TW<b>4</b>, five windows TW<b>1</b> to TW<b>5</b>, or six windows TW<b>1</b> to TW<b>6</b>. The dividing line in each mode M<b>2</b> to M<b>15</b> is the window range. TW<b>1</b> to TW<b>6</b> are configured to represent serial number of different windows. Furthermore, even though numbers of windows are the same in different targets, positions, sizes, and/or shapes of the windows may be different. For instance, the window TW<b>1</b> in the mode M<b>6</b> is larger than the window TW<b>1</b> in the mode <b>2</b>.</p><p id="p-0064" num="0063">It should be noted that, the numbers, sizes, and shapes of the windows may be further changed, which are not limited in the embodiments of the disclosure. In addition, the symbols &#x201c;TW<b>1</b>&#x201d;, &#x201c;TW<b>2</b>&#x201d;, &#x201c;TW<b>3</b>&#x201d;, &#x201c;TW<b>4</b>&#x201d;, &#x201c;TW<b>5</b>&#x201d;, and &#x201c;TW<b>6</b>&#x201d; are only used as serial numbers.</p><p id="p-0065" num="0064">Three modes are given below as examples.</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> is a schematic picture of a target layout in a mode according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, <figref idref="DRAWINGS">FIG. <b>6</b></figref>, and <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, assuming that the first controller <b>30</b> selects the mode M<b>1</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the first image FIM2 in <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be converted into a second image SIM16 in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, where the second image SIM16 in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> is, for example, a single-window mode.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> is a schematic picture of a target layout in a mode according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, <figref idref="DRAWINGS">FIG. <b>6</b></figref>, and <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, assuming that the first controller <b>30</b> selects the mode M<b>5</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the first image FIM2 in <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be converted into a second image SIM17 in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>. The second image SIM17 in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> is, for example, a two-way split window. The window TW<b>1</b> is for the <figref idref="DRAWINGS">figure P<b>3</b></figref>, and the window TW<b>2</b> is for the four <figref idref="DRAWINGS">figures P<b>1</b></figref>, P<b>2</b>, P<b>3</b>, and P<b>4</b>.</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. <b>7</b>C</figref> is a schematic picture of a target layout in a mode according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, <figref idref="DRAWINGS">FIG. <b>6</b></figref>, and <figref idref="DRAWINGS">FIG. <b>7</b>C</figref>, assuming that the first controller <b>30</b> selects the mode M<b>11</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the first image FIM2 in <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be converted into a second image SIM18 in <figref idref="DRAWINGS">FIG. <b>7</b>C</figref>. The second image SIM18 is, for example, a three-way split window. The window TW<b>1</b> is for the four <figref idref="DRAWINGS">figures P<b>1</b></figref>, P<b>2</b>, P<b>3</b>, and P<b>4</b>, the window TW<b>2</b> is for the <figref idref="DRAWINGS">figure P<b>3</b></figref>, and the window TW<b>3</b> is for the <figref idref="DRAWINGS">figure P<b>2</b></figref>.</p><p id="p-0069" num="0068">With reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref> again, the second controller <b>50</b> of this embodiment may detect one or more target objects in the second image to generate a detected result (step S<b>250</b>). To be specific, the second controller <b>50</b> may obtain the second image converted by the first controller <b>30</b> via the USB and/or I2C interface.</p><p id="p-0070" num="0069">In an embodiment, the second controller <b>50</b> may perform object detection on the second image. The object detection is to determine a bounding box or a representative point (pinot) (which may be located on the outline, center, or any position on the target object) corresponding to the target object (an object of, for example, a human, an animal, a non-living body, or its part) in the second image, and then to identify the type of the target object (e.g., human, male or female, dog or cat, table or chair, etc.). The detected result includes the bounding box (or the representative point) of the target object and/or the type of the target. The object detection described in the disclosure may also be to determine a region of interest (ROI) or a bounding rectangle corresponding to the target object in the second image, which is not limited herein.</p><p id="p-0071" num="0070">In an embodiment, the second controller <b>50</b> may be applied to, for example, a neural network based algorithm (e.g., YOLO, region based convolutional neural network (R-CNN), or fast R-CNN (fast CNN)) or a feature matching based algorithm (e.g., histogram of oriented gradient (HOG), Harr, or speeded up robust feature (SURF)) to achieve object detection.</p><p id="p-0072" num="0071">It should be noted that the algorithm used for object detection is not particularly limited in the embodiments of the disclosure. Besides, in some embodiments, the second controller <b>50</b> may specify a specific type of target object.</p><p id="p-0073" num="0072">In an embodiment, the second controller <b>50</b> determines the position of the target object in the second image. That is, the detected result includes the position of the target object. For instance, whether the target object is in the middle of the second image. For another instance, whether the target object appears in the second image. In some embodiments, the second controller <b>50</b> may define a reference axis (e.g., a horizontal axis or a vertical axis) in the second image and determines an angle of the object relative to the reference axis in the second image.</p><p id="p-0074" num="0073">In an embodiment, the second controller <b>50</b> may also determine whether the target object in the second image is moving. That is, the detected result includes the motion of the target object. For instance, the second controller <b>50</b> may determine the relationship and change of the positions or postures of the same target object in the frames of the front and rear images in the consecutive second images through object tracking. The consecutive second images represent those consecutive image frames of a video or video stream. The object tracking is to determine the correlation of, for example, the positions, movement, directions, and other motions of the same target object in adjacent second images (the position may be determined by a bounding box or a representative point), and then to locate the moving target object. In an embodiment, the second controller <b>50</b> may implement object tracking by applying, for example, optical flow, simple online and realtime tracking (SORT), deep SORT, a joint detection and embedding (JDE) model, or other tracking algorithms. It should be noted that the algorithm used for object tracking is not particularly limited in the embodiments of the disclosure.</p><p id="p-0075" num="0074">As described above, in a preferred embodiment, the second controller <b>50</b> may determine the relationship and change of the positions or postures of the same target object in the frames of the front and rear images in the consecutive second images through object tracking. Preferably, in the second image detected by the second controller <b>50</b>, when the detected result generated by the target object is that the target object in the second image does not move, the converting operation of dewarping and expanding may be performed only for the target object at the corresponding position of the bounding box, the ROI, or the bounding rectangle in this embodiment, so that the target object in the bounding box, for example, has a better ratio or a normal ratio of the target object image. In other words, when the detected result is that a position of the at least one target object in the second image is not changed, a converting operation such as dewarping and expanding may not be required for the entire image in this embodiment, and the deformation of the range corresponding to the position in the first image is required to be corrected only, and the efficiency of image processing is thereby improved.</p><p id="p-0076" num="0075">On the other hand, in the frames (or bounding boxes) of the front and rear images in the consecutive second images, when the positions or postures of the same object change, the detected result generated by the second controller <b>50</b> detecting the target object in the second image is the movement of the target object in the second image. In this embodiment, the converting operation is corrected based on the detected result, so that the entire image undergoes a converting operation such as dewarping and expanding, and the target object is then detected again.</p><p id="p-0077" num="0076">In an embodiment, the second controller <b>50</b> determines the integrity of the target object in the second image. That is, the detected result includes the integrity of the target object. For instance, the second controller <b>50</b> may identify key points (e.g., eyes, nose, or mouth) of the target object in the second image and confirm whether the parts corresponding to these key points are complete or the number is correct.</p><p id="p-0078" num="0077">It should be noted that, in some embodiments, the first controller <b>30</b> also detects one or more target objects in the second image to generate the detected result. For instance, the first controller <b>30</b> performs object detection, object tracking, or integrity detection on the second image, and the same or similar contents may be found with reference to the abovementioned description and is not repeated herein.</p><p id="p-0079" num="0078">The first controller <b>30</b> may correct the converting operation according to the detected result (step S<b>270</b>). To be specific, the target object and/or the image capturing apparatus <b>10</b> may change positions. If the converting operation remains unchanged, the position of the target object in the second image may not be centered or a portion of the target object may be cropped and become incomplete, the viewing experience is thereby affected. In an embodiment, the second controller <b>50</b> may return the detected result to the first controller <b>30</b> and determines whether the converting operation needs to be adjusted accordingly.</p><p id="p-0080" num="0079">In an embodiment, the position of the target object in the detected result is in a bounding box format. The bounding box format includes the coordinates of the horizontal axis and vertical axis of the bounding box in the second image and the size (e.g., width and height) of the second image.</p><p id="p-0081" num="0080">In another embodiment, the position of the target object in the detected result is in a representative point format. The representative point format includes the coordinates of the horizontal axis and the vertical axis of the representative point in the second image and the zoom magnification.</p><p id="p-0082" num="0081">In an embodiment, the coordinate systems defined by the first controller <b>30</b> and the second controller <b>50</b> for the second image may be different. <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic diagram of coordinate system conversion in a mode according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the second controller <b>50</b> positions pixels in the second image using a coordinate system CS<b>1</b> such as image coordinates. In the coordinate system CS<b>1</b>, the upper left corner is an origin. The first controller <b>30</b> positions the pixels in the second image in a coordinate system CS<b>2</b> (e.g., polar coordinate system). In the coordinate system CS<b>2</b>, the center point is the origin. In other preferred embodiments, either the first controller <b>30</b> or the second controller <b>50</b> may position the pixels in the second image in an appropriate coordinate system, which is not limited herein.</p><p id="p-0083" num="0082">If the detected result includes the target position of the fourth target among the targets in the second image, the first controller <b>30</b> or the second controller <b>50</b> may convert the coordinates (x<sub>o</sub>,y<sub>o</sub>) of the target position of the fourth target from the coordinate system CS<b>1</b> to the coordinates (x<sub>t</sub>,y<sub>t</sub>)) of the coordinate system CS<b>2</b>, and the conversion formula is as follows:</p><p id="p-0084" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>x</i><sub>t</sub><i>=x</i><sub>o</sub><i>&#x2212;w/</i>2&#x2003;&#x2003;(1) and<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0085" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>y</i><sub>t</sub><i>=y</i><sub>o</sub><i>&#x2212;h/</i>2&#x2003;&#x2003;(2),<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0086" num="0000">where x<sub>o </sub>is the coordinate of the fourth target on the horizontal axis in the coordinate system CS<b>1</b>, x<sub>t </sub>is the coordinate of the fourth target on the horizontal axis in the coordinate system CS<b>2</b>, y<sub>o </sub>is the coordinate of the fourth object on the vertical axis in the coordinate system CS<b>1</b>, y<sub>t </sub>is the coordinate of the fourth object on the vertical axis in the coordinate system CS<b>2</b>, w is the width of the second image, and h is the height of the second image.</p><p id="p-0087" num="0083">It should be noted that if the first controller <b>30</b> and the second controller <b>50</b> use the same coordinate system, the coordinate conversion may be ignored.</p><p id="p-0088" num="0084">It is worth noting that the target object may not be centered in the second image or the window of the second image. For instance, <figref idref="DRAWINGS">FIG. <b>9</b></figref> is a schematic picture of a second image SIM19 under an imaging FoV FOV<b>3</b> according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, it is assumed that a maximum FoV FOV<b>4</b> of the image capturing apparatus <b>10</b> is 180 degrees. That is, the first image includes a 180-degree field of view. Th FoV FOV<b>3</b> set by the converting operation is 140 degrees. It is assumed that an imaginary line extending directly forwards from the position of the image capturing apparatus <b>10</b> is the reference axis (i.e., the vertical center line of the imaging FoV FOV<b>3</b>). A target object T<b>1</b> is located directly in front of the image capturing apparatus <b>10</b>, that is, an offset angle relative to the reference axis is zero. Therefore, the target object T<b>1</b> is located in the middle of the second image SIM19.</p><p id="p-0089" num="0085"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a schematic picture of a second image SIM20 under a rotated FoV according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, different from <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the offset angle of the target object T<b>2</b> relative to the reference axis is 01 (e.g., 45 degrees). Therefore, the target object T<b>2</b> is located to the left of the second image SIM20.</p><p id="p-0090" num="0086">In an embodiment, the first controller <b>30</b> may center and align the target object according to the offset angle. The detected result includes the offset angle of the first target among these target objects relative to the reference axis in the second image. The reference axis is the horizontal or vertical center line of the original imaging FoV of the second image. The first controller <b>30</b> may set the converting operation to rotate the imaging FoV of the first image according to the offset angle to reduce the offset angle. For instance, the FoV rotation includes the upper and lower FoV adjustment shown in <figref idref="DRAWINGS">FIG. <b>3</b>E</figref>, the left and right FoV adjustment shown in <figref idref="DRAWINGS">FIG. <b>3</b>F</figref>, and the plane FoV adjustment shown in <figref idref="DRAWINGS">FIG. <b>3</b>G</figref>.</p><p id="p-0091" num="0087">In an embodiment, the first controller <b>30</b> may convert the coordinates of the second image according to the ratio of the imaging FoV of the first image to the length of the first image (e.g., its width or height) in the axial direction corresponding to the direction of rotating a first imaging FoV of the first image. If the coordinate system CS<b>2</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is used, the rotation of the imaging FoV in different axial directions are:</p><p id="p-0092" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Pan</i>(<i>x</i><sub>t</sub>)=<i>x</i><sub>t</sub>xfov<sub>H</sub><i>/w</i>&#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0093" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Tilt(<i>y</i><sub>t</sub>)=<i>y</i><sub>t</sub>xfov<sub>v</sub><i>/h</i>&#x2003;&#x2003;(4), and<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0094" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Rotate(<i>x</i><sub>t</sub>)=<i>x</i><sub>t</sub>xfov<sub>H</sub><i>/w</i>&#x2003;&#x2003;(5),<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0095" num="0000">where fov<sub>H </sub>is the imaging FoV of the second image in the horizontal direction, and fov<sub>v </sub>is the imaging FoV of the second image in the vertical direction. Pan( ) is a function for the upper and lower imaging FoV adjustment. For instance, the direction of left and right rotation corresponds to the x axis, so it is for the imaging FoV in the horizontal direction and the width of the second image. Tilt( ) is a function for the left and right imaging FoV adjustment. For instance, the direction of upper and lower rotation corresponds to the y axis, so it is for the imaging FoV in the vertical direction and the height of the second image. Tilt( ) is a function for the plane imaging FoV adjustment. As shown in <figref idref="DRAWINGS">FIG. <b>3</b>J</figref>, the outer ring images IMo1 and IMo2 respectively exhibit left-shift and right-shift effects, so it is for the imaging FoV in the horizontal direction and the width of the second image.</p><p id="p-0096" num="0088">In an embodiment, the detected result includes that the rotated imaging FoV of the second image exceeds the (maximum) FoV of the image capturing apparatus <b>10</b>. Taking <figref idref="DRAWINGS">FIG. <b>10</b></figref> as an example, after the imaging FoV FOV<b>4</b> of a second image SIM21 is rotated, the left boundary thereof exceeds the maximum imaging FoV FOV<b>3</b> of the image capturing apparatus <b>10</b>. Therefore, even if the target object T<b>2</b> is located in the middle of the second image SIM21, a black region is generated on the left side of the second image SIM21 because a visible image cannot be obtained.</p><p id="p-0097" num="0089">The first controller <b>30</b> may set a portion of the rotated imaging FoV of the second image (hereinafter referred to as the first imaging FoV) exceeding the imaging FoV of the image capturing apparatus <b>10</b> (hereinafter referred to as the second imaging FoV) to be limited to an edge of the second imaging FoV. For instance, if the coordinate system CS<b>2</b> in <figref idref="DRAWINGS">FIG. <b>8</b></figref> is used, the edge correction of the imaging FoV is as follows.</p><p id="p-0098" num="0000">If the coordinate x<sub>t2 </sub>of the horizontal axis of the rotated imaging FoV is between the left edge and the right edge of the second FoV, the coordinate x<sub>t2 </sub>does not change.<br/>If the coordinate x<sub>t2 </sub>of the horizontal axis of the rotated FoV is smaller than the coordinate of the left edge of the second FoV, the coordinate x<sub>t2 </sub>is corrected to the coordinate of the left edge of the second FoV.<br/>If the coordinate x<sub>t2 </sub>of the horizontal axis of the rotated FoV is greater than the coordinate of the right edge of the second FoV, the coordinate x<sub>t2 </sub>is corrected to the coordinate of the right edge of the second FoV.<br/>If the coordinate y<sub>t2 </sub>of the vertical axis of the rotated imaging FoV is between the upper edge and the lower edge of the second FoV, the coordinate y<sub>t2 </sub>does not change.<br/>If the coordinate y<sub>t2 </sub>of the vertical axis of the rotated FoV is smaller than the coordinate of the lower edge of the second FoV, the coordinate y<sub>t2 </sub>is corrected to the coordinate of the lower edge of the second FoV.<br/>If the coordinate y<sub>t2 </sub>of the vertical axis of the rotated FoV is greater than the coordinate of the upper edge of the second FoV, the coordinate y<sub>t2 </sub>is corrected to the coordinate of the upper edge of the second FoV.</p><p id="p-0099" num="0090">For instance, <figref idref="DRAWINGS">FIG. <b>11</b></figref> is a schematic picture of corrected second images SIM20 and SIM22 according to an embodiment of the disclosure. The difference between <figref idref="DRAWINGS">FIG. <b>11</b></figref> and <figref idref="DRAWINGS">FIG. <b>10</b></figref> is that the first FoV of the second image SIM22 is corrected, so the target object T<b>2</b> is close to the middle of the second image (e.g., an angle &#x3b8;2 is 20 degrees).</p><p id="p-0100" num="0091"><figref idref="DRAWINGS">FIG. <b>12</b>A</figref> is a schematic picture of a second image SIM23 of a conference scenario according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>12</b>A</figref>, in the application scenario of a conference mode, it is assumed that the lens <b>10</b> is a fisheye lens and may obtain the first image of 360 degrees, and images are stitched together in a manner of 180 degrees up and down. Since the targets T<b>3</b> and T<b>4</b> are located within the upper 180-degree FoV, and the targets T<b>5</b> and T<b>6</b> are located within the lower 180-degree FoV, the targets T<b>3</b> to T<b>6</b> are located at appropriate positions in the second image.</p><p id="p-0101" num="0092"><figref idref="DRAWINGS">FIG. <b>12</b>B</figref> is a schematic picture of a second image SIM24 of the conference scenario according to another embodiment of the disclosure. The difference between <figref idref="DRAWINGS">FIG. <b>12</b>B</figref> and <figref idref="DRAWINGS">FIG. <b>12</b>A</figref> is that the targets T<b>3</b> to T<b>6</b> of this embodiment are located at non-ideal positions or are in a moving state. Therefore, portions of the targets T<b>3</b> and T<b>5</b> in the second image SIM24 are cropped (i.e., incomplete).</p><p id="p-0102" num="0093"><figref idref="DRAWINGS">FIG. <b>12</b>C</figref> is a schematic picture of a corrected second image SIM25 according to another embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>12</b>C</figref>, if the detected result of the second controller <b>50</b> is the integrity of the target object, after determining the integrity of the target object, the first controller <b>30</b> may be triggered to rotate the imaging FoV (e.g., a rotation angle &#x3b8;3) of the first image. Therefore, compared to <figref idref="DRAWINGS">FIG. <b>12</b>B</figref>, the targets T<b>3</b> to T<b>6</b> may be completely presented in the second image SIM25.</p><p id="p-0103" num="0094">In an embodiment, the detected result includes a size ratio of the second target among the target object in the second image. In the image processing system provided by this embodiment, the converting operation may be set to change the zoom magnification of all or part of the second image according to the size ratio, so as to maintain the proportion of the second target object in the second image. Taking <figref idref="DRAWINGS">FIG. <b>6</b></figref> as an example, the size of the second target in the window TW<b>1</b> in the mode M<b>1</b> may be greater than the size of the second target in the window TW<b>1</b> in the mode M<b>15</b>, and the visual experience is improved in this way.</p><p id="p-0104" num="0095">In an embodiment, if the detected result is to position the second target with the bounding box, in the image processing system of this embodiment, the zoom magnification may be set to be a smallest one among the width ratio, the height ratio, and the maximum ratio. The size ratio includes the height ratio and the width ratio. The width ratio is the ratio of the width of the second image to the width of the bounding box of the second target, and the height ratio is the ratio of the height of the second image to the height of the bounding box.</p><p id="p-0105" num="0096">In another embodiment, if the detected result is to position the second target with the representative point, in the image processing system of this embodiment, the zoom magnification may be set to be a reference magnification. That is, the second target is directly zoomed in at the designated reference magnification.</p><p id="p-0106" num="0097">In an embodiment, the converting operation for target layout is provided. In the image processing system of this embodiment, the target window is determined according to the bounding box or the representative point in the original window. In the image processing system of this embodiment, the reference axis for evaluating the offset may be set as the central axis of the bounding box of the third target among the plurality of target objects or the extension line of the representative point, and the first FoV is rotated to align the third target with the object window. That is, the center of the FoV is directed towards the third target. The FoV in functions (3) to (4) may be replaced with the FoV for the target window. In addition, if the rotated FoV exceeds the bounding box, the first controller <b>30</b> may correct the FoV used for cropping the image and limits the exceeding portion of the FoV to the edge of the bounding box.</p><p id="p-0107" num="0098">In an embodiment, in the image processing system, the size ratio of the target window of the third target in the second image may be determined, and the converting operation may be set according to the size ratio to change the zoom magnification of the third target. For instance, in the image processing system, the zoom magnification may be set to be the smallest one among the second width ratio, the second height ratio, and the maximum ratio. The size ratio includes the second height ratio and the second width ratio. The second width ratio is the ratio of the width of the target window to the width of the bounding box of the third target, and the second height ratio is the ratio of the height of the target window to the height of the bounding box.</p><p id="p-0108" num="0099">For instance, <figref idref="DRAWINGS">FIG. <b>13</b></figref> is a schematic picture of a multi-target window image according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>13</b></figref>, taking the mode M<b>11</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref> as an example, the window TW<b>1</b> is the original window, and the windows TW<b>2</b> and TW<b>3</b> are the target windows. The original window is the image within a maximum FoV FOV<b>5</b> of the image capturing apparatus <b>10</b> or the predetermined FoV of the second image in the single-window mode. The other two target windows are the images in the FoV FOV<b>6</b> and the FoV FOV<b>7</b>. The second controller <b>50</b> obtains the bounding boxes BB<b>1</b> and BB<b>2</b> according to the detected results and respectively arranges the images in the two BB<b>1</b> and BB<b>2</b> in the windows TW<b>2</b> and TW<b>3</b>. Compared to the FoV FOV<b>5</b>, the FoV FOV<b>6</b> and the FoV FOV<b>7</b> are rotated and their left and right boundaries are the left and right boundaries of the bounding boxes BB<b>1</b> and BB<b>2</b>. Therefore, the face in each target window may be automatically centered, and the face in the target window may be automatically scaled to an appropriate size. Besides, if the human face in the target window moves, the human face may still be centered on the target window according to the detected result of the second controller <b>50</b> and the size of the human face may be maintained in this embodiment.</p><p id="p-0109" num="0100"><figref idref="DRAWINGS">FIG. <b>14</b>A</figref> is a schematic picture of a second image SIM27 of a multi-target window image according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>14</b>A</figref>, taking the mode M<b>4</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref> as an example, before the converting operation is not corrected, the faces of the target objects T<b>3</b> to T<b>6</b> in the second image SIM27 are all cut by the window, resulting in poor visual experience.</p><p id="p-0110" num="0101"><figref idref="DRAWINGS">FIG. <b>14</b>B</figref> is a schematic picture of a corrected second image SIM28 according to an embodiment of the disclosure. With reference to <figref idref="DRAWINGS">FIG. <b>14</b>B</figref>, the first controller <b>30</b> may obtain that the target objects T<b>3</b> to T<b>6</b> deviate from the center of the window according to the detected result and corrects the converting operation accordingly. Compared to <figref idref="DRAWINGS">FIG. <b>14</b>A</figref>, after the correcting and converting operation, the faces of the target objects T<b>3</b> to T<b>6</b> in the second image SIM28 are all centered on the target window, and the second image SIM28 presents a face of a suitable size, so that improved visual experience is provided. Besides, regardless of any position or movement of the target objects T<b>3</b> to T<b>6</b> in the conference room, the second image SIM28 may present an appropriate four-way split screen (i.e., the face remains centered and the size of the face is the same).</p><p id="p-0111" num="0102">In view of the foregoing, in the image controller, the image processing system, and the image correcting method provided by the embodiments of the disclosure, the converting operation related to deformation correction and/or target layout is corrected based on the detected result of the image recognition. Herein, in the embodiments of the disclosure, the FoV may be directed towards the target object, and the size of the target object in the image may also be changed. In this way, the target object may be automatically placed in the image or in the designated target window, the size of the target object in the image may be automatically adjusted, and improved visual experience is thereby provided. Even if the target object moves, the centering and size of the target object may still be maintained through the detected result and operation correction.</p><p id="p-0112" num="0103">It will be apparent to those skilled in the art that various modifications and variations can be made to the disclosed embodiments without departing from the scope or spirit of the disclosure. In view of the foregoing, it is intended that the disclosure covers modifications and variations provided that they fall within the scope of the following claims and their equivalents.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image correcting method, comprising:<claim-text>obtaining a first image;</claim-text><claim-text>converting the first image into a second image according to a converting operation, wherein the converting operation comprises at least one deformation correction, and the deformation correction is used to correct deformation of at least one target object in the first image;</claim-text><claim-text>detecting the at least one target object in the second image to generate a detected result; and</claim-text><claim-text>correcting the converting operation according to the detected result.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The image correcting method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising:<claim-text>obtaining, through a first controller, the first image from an image capturing apparatus;</claim-text><claim-text>converting, through the first controller, the first image into the second image according to the converting operation;</claim-text><claim-text>detecting, through a second controller, the at least one target object in the second image to generate the detected result; and</claim-text><claim-text>correcting, through the first controller, the converting operation according to the detected result.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The image correcting method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of correcting the converting operation according to the detected result further comprises:<claim-text>allowing the converting operation to further comprise position adjustment to adjust a position of the at least one target object in the second image.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The image correcting method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the detected result comprises an offset angle of a first target among the at least one target object relative to a reference axis in the second image, and the position adjustment further comprises:<claim-text>setting the converting operation to rotate a first imaging field of view (FoV) of the first image according to the offset angle to reduce the offset angle.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The image correcting method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the converting operation further comprises a target layout, the second image comprises a plurality of windows, the target layout is used to adjust a target window of the first target in the second image, the target window is one of the windows, and the step of setting the converting operation to rotate the first imaging field of view of the first image according to the offset angle to reduce the offset angle further comprises:<claim-text>rotating the first imaging field of view to align the first target with the target window.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The image correcting method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the detected result comprises that the rotated first imaging field of view exceeds a second imaging field of view of the image capturing apparatus, and the position adjustment further comprises:<claim-text>setting a portion of the rotated first imaging field of view exceeding the second imaging field of view to be limited to an edge of the second imaging field of view.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The image correcting method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the step of setting the converting operation to rotate the first imaging field of view of the first image according to the offset angle to reduce the offset angle further comprises:<claim-text>converting coordinates of the first image according to a ratio of the first imaging field of view to a length of the first image in an axial direction corresponding to a direction of rotating the first imaging field of view.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The image correcting method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the detected result comprises a size ratio of a second target among the at least one target object in the second image, and the converting operation is set to change a zoom magnification of the first image to the second image according to the size ratio.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The image correcting method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the step of setting the converting operation to change the zoom magnification of the first image to the second image according to the size ratio comprises:<claim-text>setting the zoom magnification to be a smallest one among a width ratio, a height ratio, and a maximum ratio, wherein the second target is positioned with a bounding box, the size ratio comprises the height ratio and the width ratio, the width ratio is a ratio of a width of the second image to a width of the bounding box of the second target, and the height ratio is a ratio of a height of the second image to a height of the bounding box.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The image correcting method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the step of setting the converting operation to change the zoom magnification of the first image to the second image according to the size ratio comprises:<claim-text>setting the zoom magnification as a reference magnification, wherein the second target is positioned with a representative point.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The image correcting method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the detected result comprises a size ratio of a third target among the at least one target object in a target window in the second image, the target window is one of the windows, and the step of correcting the converting operation according to the detected result comprises:<claim-text>setting the converting operation to change a zoom magnification of the third target according to the size ratio.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The image correcting method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the detected result comprises that a position of the at least one target object in the second image is not changed, and the distortion correction only corrects deformation of a range corresponding to the position in the first image.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The image correcting method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second controller positions pixels in the second image with a first coordinate system, the first controller positions the pixels in the second image with a second coordinate system, the detected result comprises a target position of a fourth target among the at least one target object in the second image, and the step of correcting the converting operation according to the detected result further comprises:<claim-text>converting coordinates of the target position from the first coordinate system to coordinates of the second coordinate system, wherein a center point is treated as an origin in the second coordinate system, and an upper left corner is treated as an origin in the first coordinate system.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. An image processing system, comprising:<claim-text>an image capturing apparatus, comprising a lens and an image sensor and configured to capture a first image through the lens and the image sensor;</claim-text><claim-text>a first controller, coupled to the image capturing apparatus and configured to convert the first image into a second image according to a converting operation, wherein the converting operation comprises deformation correction, and the deformation correction is used to correct deformation of at least one target object in the first image; and</claim-text><claim-text>a second controller, coupled to the first controller and configured to detect the at least one target object in the second image to generate a detected result, wherein the first controller is further configured to correct the converting operation according to the detected result.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The image processing system according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the correction of the converting operation performed by the first controller comprises:<claim-text>allowing the converting operation to further comprise position adjustment to adjust a position of the at least one target object in the second image;</claim-text><claim-text>wherein the detected result comprises an offset angle of a first target among the at least one target object relative to a reference axis in the second image, and the first controller is further configured for setting the converting operation to rotate a first imaging field of view of the first image according to the offset angle to reduce the offset angle;</claim-text><claim-text>wherein the detected result comprises that the rotated first imaging field of view exceeds a second imaging field of view of the image capturing apparatus, and the first controller is further configured for setting a portion of the rotated first imaging field of view exceeding the second imaging field of view to be limited to an edge of the second imaging field of view.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The image processing system according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the converting operation further comprises a target layout, the second image comprises a plurality of windows, the target layout is used to adjust a target window of the first target in the second image, the target window is one of the windows, and the first controller is further configured for:<claim-text>rotating the first imaging field of view to align the first target with the target window;</claim-text><claim-text>wherein the detected result comprises that a position of the at least one target object in the second image is not changed, and the distortion correction only corrects deformation of a range corresponding to the position in the first image.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The image processing system according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the first controller is further configured for:<claim-text>converting coordinates of the first image according to a ratio of the first imaging field of view to a length of the first image in an axial direction corresponding to a direction of rotating the first imaging field of view.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The image processing system according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the detected result comprises a size ratio of a second target among the at least one target object in the second image, and the converting operation is set to change a zoom magnification of the first image to the second image according to the size ratio;<claim-text>wherein the zoom magnification is set to be a smallest one among a width ratio, a height ratio, and a maximum ratio, the second target is positioned with a bounding box, the size ratio comprises the height ratio and the width ratio, the width ratio is a ratio of a width of the second image to a width of the bounding box of the second target, and the height ratio is a ratio of a height of the second image to a height of the bounding box;</claim-text><claim-text>wherein the zoom magnification is set as a reference magnification, and the second target is positioned with a representative point.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The image processing system according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the detected result comprises a size ratio of a third target among the at least one target object in a target window in the second image, the target window is one of the windows, and the first controller is further configured for:<claim-text>setting the converting operation to change a zoom magnification of the third target according to the size ratio.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The image processing system according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the second controller positions pixels in the second image with a first coordinate system, the first controller positions the pixels in the second image with a second coordinate system, the detected result comprises a target position of a fourth target among the at least one target object in the second image, and the first controller or the second controller is further configured for:<claim-text>converting coordinates of the target position from the first coordinate system to coordinates of the second coordinate system, wherein a center point is treated as an origin in the second coordinate system, and an upper left corner is treated as an origin in the first coordinate system.</claim-text></claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. An image controller, adapted to be coupled to an image capturing apparatus, wherein the image capturing apparatus comprises a lens and an image sensor, the image capturing apparatus captures a first image through the lens and the image sensor, and the image controller comprises:<claim-text>a memory, configured to store a program code; and</claim-text><claim-text>a processor, coupled to the memory, configured to load and execute the program code for:<claim-text>obtaining the first image,</claim-text><claim-text>converting the first image into a second image according to a converting operation, wherein the converting operation comprises distortion correction, and the distortion correction is used to correct deformation of at least one target object in the first image,</claim-text><claim-text>detecting the at least one target object in the second image to generate a detected result, and</claim-text><claim-text>correcting the converting operation according to the detected result.</claim-text></claim-text></claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The image controller according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the correction of the converting operation according to the detected result further comprises: allowing the converting operation to further comprise position adjustment to adjust a position of the at least one target object in the second image.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The image controller according to <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the detected result comprises an offset angle of a first target among the at least one target object relative to a reference axis in the second image, and the image controller sets the converting operation to rotate a first imaging field of view of the first image according to the offset angle to reduce the offset angle;<claim-text>wherein the detected result comprises that the rotated first imaging field of view exceeds a second imaging field of view of the image capturing apparatus, and the image controller is further configured for setting a portion of the rotated first imaging field of view exceeding the second imaging field of view to be limited to an edge of the second imaging field of view.</claim-text></claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. The image controller according to <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the converting operation further comprises a target layout, the second image comprises a plurality of windows, the target layout is used to adjust a target window of the first target in the second image, the target window is one of the windows, and the image controller is further configured for:<claim-text>rotating the first imaging field of view to align the first target with the target window,</claim-text><claim-text>wherein the detected result comprises a size ratio of a third target among the at least one target object in a target window in the second image, the target window is one of the windows, and the image controller is further configured for:</claim-text><claim-text>setting the converting operation to change a zoom magnification of the third target according to the size ratio.</claim-text></claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The image controller according to <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the image controller is further configured for: converting coordinates of the first image according to a ratio of the first imaging field of view to a length of the first image in an axial direction corresponding to a direction of rotating the first imaging field of view.</claim-text></claim></claims></us-patent-application>
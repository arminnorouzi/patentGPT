<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007060A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007060</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17832177</doc-number><date>20220603</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2021-111805</doc-number><date>20210705</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>403</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>1089</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>403</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>1</main-group><subgroup>00209</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>1089</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>2201</main-group><subgroup>0094</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>1</main-group><subgroup>00244</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">REMOTE CONFERENCE SYSTEM, OUTPUT IMAGE CONTROL METHOD, AND OUTPUT IMAGE CONTROL PROGRAM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only"><addressbook><orgname>KONICA MINOLTA, INC.</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MATSUURA</last-name><first-name>Tsumoru</first-name><address><city>Toyohashi-shi</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>KONICA MINOLTA, INC.</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">There is provided a remote conference system that remotely implements a conference using a plurality of operating devices respectively operated by a plurality of participants, and the remote conference system includes a hardware processor that: outputs a first image shared by the plurality of participants to cause the first image to be displayed on each of the plurality of operating devices; determines an output destination on a basis of a state of a requesting device operated by a requester among the plurality of operating devices; and outputs a second image different from the first image to cause the second image to be output from the output destination determined by the hardware processor in a state in which the first image is displayed on the requesting device.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="106.43mm" wi="158.75mm" file="US20230007060A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="213.95mm" wi="155.53mm" orientation="landscape" file="US20230007060A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="175.60mm" wi="108.80mm" orientation="landscape" file="US20230007060A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="248.41mm" wi="108.80mm" orientation="landscape" file="US20230007060A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="240.54mm" wi="159.43mm" orientation="landscape" file="US20230007060A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="189.06mm" wi="169.59mm" file="US20230007060A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="183.56mm" wi="168.49mm" file="US20230007060A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="242.65mm" wi="110.24mm" file="US20230007060A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="214.55mm" wi="110.15mm" file="US20230007060A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="211.67mm" wi="165.61mm" file="US20230007060A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="232.92mm" wi="119.21mm" file="US20230007060A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="250.02mm" wi="159.17mm" orientation="landscape" file="US20230007060A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="164.00mm" wi="164.68mm" file="US20230007060A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><p id="p-0002" num="0001">The entire disclosure of Japanese patent Application No. 2021-111805, filed on Jul. 5, 2021, is incorporated herein by reference in its entirety.</p><heading id="h-0001" level="1">BACKGROUND</heading><heading id="h-0002" level="1">Technological Field</heading><p id="p-0003" num="0002">The present invention relates to a remote conference system, an output image control method, and an output image control program, and more particularly, to a remote conference system that remotely implements a conference using a plurality of operating devices respectively operated by a plurality of participants, an output image control method executed in the remote conference system, and an output image control program that causes a computer to execute the output image control method.</p><heading id="h-0003" level="1">Description of the Related art</heading><p id="p-0004" num="0003">In recent years, a remote conference system has become widespread in which a plurality of participants located at distant places hold a conference via computers. In the remote conference system, in a case where one presenter among the participants of the conference makes a presentation, an image of a page used by the presenter to make the presentation is displayed on computers operated by all the participants. In this case, the participants may desire to refer to an image different from a page used by the presenter for presentation in addition to the page.</p><p id="p-0005" num="0004">In JP 9-101767 A, a terminal device is described that is connected via a network, the terminal device switching between a state in which a page selected by a participant from conference material is displayed and a synchronous state in which a page is displayed that is the same page as the conference material being viewed by another participant selected by the participant, for example, a presenter.</p><p id="p-0006" num="0005">However, according to the technique described in JP 9-101767 A, a page being viewed by the presenter and a page selected by the participant cannot be simultaneously displayed. In addition, to select a page to be displayed, it is necessary for the participant to perform selection from among thumbnails of a plurality of pages, and the selection is difficult. For this reason, there is a problem that it is difficult to display an appropriate page in accordance with progress of the conference.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0007" num="0006">One object of the present invention is to provide a remote conference system that improves convenience of participants of a conference.</p><p id="p-0008" num="0007">Another object of the present invention is to provide an output image control method that improves convenience of participants of a conference.</p><p id="p-0009" num="0008">Still another object of the present invention is to provide an output image control program that improves convenience of participants of a conference.</p><p id="p-0010" num="0009">To achieve at least one of the abovementioned objects, according to an aspect of the present invention, there is provided a remote conference system that remotely implements a conference using a plurality of operating devices respectively operated by a plurality of participants, and the remote conference system reflecting one aspect of the present invention comprises a hardware processor that: outputs a first image shared by the plurality of participants to cause the first image to be displayed on each of the plurality of operating devices; determines an output destination on a basis of a state of a requesting device operated by a requester among the plurality of operating devices; and outputs a second image different from the first image to cause the second image to be output from the output destination determined by the hardware processor in a state in which the first image is displayed on the requesting device.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0011" num="0010">The advantages and features provided by one or more embodiments of the invention will become more fully understood from the detailed description given hereinbelow and the appended drawings which are given by way of illustration only, and thus are not intended as a definition of the limits of the present invention:</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example of a system configuration of a remote conference system in one of embodiments of the present invention;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an example of a hardware configuration of a server;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating a hardware configuration of a PC;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating an example of functions of a CPU included in the server in the present embodiment;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating an example of a first association table;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram illustrating an example of a second association table;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating an example of a speaker table;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating an example of a display time table;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating an example of a request setting screen;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating an example of a display time setting screen;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram illustrating an example of a participant selection screen;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a first diagram illustrating an example of a display state;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a second diagram illustrating an example of the display state;</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram illustrating an example of an output state;</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart illustrating an example of a flow of output image control processing;</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a flowchart illustrating an example of a flow of request image determination processing; and</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flowchart illustrating an example of a flow of output destination determination processing.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION OF EMBODIMENTS</heading><p id="p-0029" num="0028">Hereinafter, one or more embodiments of the present invention will be described with reference to the drawings. However, the scope of the invention is not limited to the disclosed embodiments. In the following description, the same components are denoted by the same reference numerals. The names and functions thereof are also the same. Thus, detailed description thereof will not be repeated.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example of a system configuration of a remote conference system in one of embodiments of the present invention. Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a remote conference system <b>1</b> includes a server <b>200</b> and personal computers (hereinafter referred to as &#x201c;PCs&#x201d;) <b>100</b>-<b>1</b>, <b>100</b>-<b>2</b>, <b>100</b>-<b>3</b>, and <b>100</b>-<b>4</b> to <b>100</b>-N. Here, N is a positive integer, and is greater than or equal to five. The server <b>200</b> and the PCs <b>100</b>-<b>1</b> to <b>100</b>-N are connected to an Internet <b>5</b> and can communicate with each other.</p><p id="p-0031" num="0030">Each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N includes a camera, a microphone that collects voice, and a speaker that outputs sound. Each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N is a general computer, and has the same main hardware configuration and functions, and thus the PCs <b>100</b>-<b>1</b> to <b>100</b>-N are collectively referred to as a PC <b>100</b>, and the PC <b>100</b> will be described unless otherwise specified.</p><p id="p-0032" num="0031">Note that, instead of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, an information communication device such as a personal digital assistance (PDA) or a smartphone may be used as long as the device includes a camera, a microphone, a speaker, and a communication function.</p><p id="p-0033" num="0032">The PC <b>100</b>-<b>1</b> includes two display devices. The display device is a liquid crystal display device (LCD) or an organic electro-luminescence (EL) panel. The PC <b>100</b>-<b>2</b> and the PC <b>100</b>-<b>3</b> are connected to multi function peripherals (MFPs) <b>300</b>-<b>2</b> and <b>300</b>-<b>3</b>, respectively. The MFPs <b>300</b>-<b>2</b> and <b>300</b>-<b>3</b> each are an example of an image forming apparatus. Note that, instead of the MFPs <b>300</b>-<b>2</b> and <b>300</b>-<b>3</b>, an image forming apparatus such as a laser printer, an inkjet printer, or a facsimile machine may be used.</p><p id="p-0034" num="0033">A network to which the server <b>200</b> and the PCs <b>100</b>-<b>1</b> to <b>100</b>-N are connected is not limited to the Internet <b>5</b>, and may be another network as long as the server <b>200</b> and the PCs <b>100</b>-<b>1</b> to <b>100</b>-N can communicate with each other. As the network, for example, a local area network (LAN) or a wide area network (WAN) is used.</p><p id="p-0035" num="0034">In the remote conference system <b>1</b> in the present embodiment, a participant participates in a conference by operating any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. As an example, a description will be given of a case where a presenter is included among a plurality of participants in the remote conference system <b>1</b> in the present embodiment. The presenter explains to other participants by using conference material including a plurality of pages. For that, a page selected by the presenter among presentation materials is displayed on the PCs respectively operated by all other participants, and voice of the presenter is output from the PCs respectively operated by all the other participants. Here, as an example, a description will be given of a case where a participant who operates the PC <b>100</b>-N is the presenter.</p><p id="p-0036" num="0035">A program for participating in the conference is installed in each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, and each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N communicates with the server <b>200</b>, whereby the conference is held. The program installed in each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N may be a dedicated program for communicating with the server <b>200</b>, and in addition, in a case where the server <b>200</b> provides a web service, may be a general browser program.</p><p id="p-0037" num="0036">The server <b>200</b> executes a remote conference program, whereby a remote conference system is implemented. The server <b>200</b> communicates with the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, and transmits data received from each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N to each of the other PCs <b>100</b>-<b>1</b> to <b>100</b>-N.</p><p id="p-0038" num="0037">The data transmitted and received between each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N and the server <b>200</b> includes voice information indicating voice, video information indicating video, and application data. The data transmitted and received between each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N and the server <b>200</b> may be compressed data or uncompressed data.</p><p id="p-0039" num="0038">The server <b>200</b> manages data to be transmitted to each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. For example, the server <b>200</b> transmits voice data received from each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N to all of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. In addition, regarding the video information, the server <b>200</b> aggregates video data received from each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, and transmits the aggregated video data to each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N.</p><p id="p-0040" num="0039">The server <b>200</b> determines and transmits video and application data to be transmitted in response to a request from each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. Thus, images displayed on the respective PCs <b>100</b>-<b>1</b> to <b>100</b>-N may be the same or different. Note that, each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N may process and display the video information received from the server <b>200</b>. In this case, processing to process the video information by the server <b>200</b> becomes unnecessary, and thus a load on the server <b>200</b> is reduced.</p><p id="p-0041" num="0040">Note that, as an example, a description will be given of a case where the remote conference system <b>1</b> in the present embodiment includes the server <b>200</b>; however, the remote conference system <b>1</b> does not necessarily have to include the server <b>200</b>. In this case, each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N has functions of the server <b>200</b> described below.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an example of a hardware configuration of a server. Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the server <b>200</b> is a computer that performs arithmetic processing, and includes a central processing unit (CPU) <b>201</b> for controlling the entire server <b>200</b>, a read only memory (ROM) <b>202</b> that stores a program to be executed by the CPU <b>201</b>, a random access memory (RAM) <b>203</b> that is used as a work area of the CPU <b>201</b>, an HDD <b>204</b> that stores data in a nonvolatile manner, a communication unit <b>205</b> that connects the CPU <b>201</b> to the Internet <b>5</b>, a display unit <b>206</b> that displays an image, an operation unit <b>207</b> that accepts input of operation, and an external storage device <b>210</b>, each of which is connected to a bus <b>213</b>.</p><p id="p-0043" num="0042">The communication unit <b>205</b> is an interface for connecting the server <b>200</b> to the Internet <b>5</b>. The CPU <b>201</b> can therefore communicate with the PCs <b>100</b>-<b>1</b> to <b>100</b>-N connected to the Internet <b>5</b> via the communication unit <b>205</b>.</p><p id="p-0044" num="0043">A compact disk read only memory (CD-ROM) <b>211</b> is attached to the external storage device <b>210</b>. The CPU <b>201</b> controls the external storage device <b>210</b> to read data stored in the CD-ROM <b>211</b>.</p><p id="p-0045" num="0044">In the present embodiment, the CPU <b>201</b> executes a program stored in the ROM <b>202</b> or the HDD <b>204</b>. In addition, the CPU <b>201</b> may control the external storage device <b>210</b> to read a program to be executed by the CPU <b>201</b> from the CD-ROM <b>211</b>, and store the read program in the RAM <b>203</b> to execute the read program.</p><p id="p-0046" num="0045">Further, the CPU <b>201</b> downloads a program from a computer connected to the Internet <b>5</b> and stores the program in the HDD <b>204</b>. In a case where a computer connected to the Internet <b>5</b> writes a program to the HDD <b>204</b>, the program is stored in the HDD <b>204</b>. The CPU <b>201</b> may load the program stored in the HDD <b>204</b> into the RAM <b>203</b> and execute the program.</p><p id="p-0047" num="0046">Note that, a recording medium that stores the program to be executed by the CPU <b>201</b> is not limited to the CD-ROM <b>211</b>, but may be a medium such as a flexible disk, a cassette tape, an optical disk (Magnetic Optical Disc (MO)/Mini Disc (MD)/Digital Versatile Disc (DVD)), an IC card, an optical card, or semiconductor memories such as a mask ROM and an Erasable Programmable ROM (EPROM). The program referred to here includes not only a program that can be directly executed by the CPU <b>201</b>, but also a source program, a compressed program, an encrypted program, and the like.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating a hardware configuration of a PC. Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the PC <b>100</b> is a computer that performs arithmetic processing, and includes a CPU <b>101</b> for controlling the entire PC <b>100</b>, a ROM <b>102</b> that stores a program to be executed by the CPU <b>101</b>, a RAM <b>103</b> that is used as a work area of the CPU <b>101</b>, an HDD <b>104</b> that stores data in a nonvolatile manner, a communication unit <b>105</b> that connects the CPU <b>101</b> to the Internet <b>5</b>, a display unit <b>106</b> that displays an image, an operation unit <b>107</b> that accepts input of operation by a participant who is a user, a camera <b>108</b> that images the participant, a speaker <b>109</b> that outputs voice, a microphone <b>110</b> that collects voice of an operator, and an external storage device <b>111</b>, each of which is connected to a bus <b>112</b>.</p><p id="p-0049" num="0048">A CD-ROM <b>111</b>A is attached to the external storage device <b>111</b>. The CPU <b>101</b> controls the external storage device <b>111</b> to read data stored in the CD-ROM <b>111</b>A.</p><p id="p-0050" num="0049">A module in which at least two of the camera <b>108</b>, the speaker <b>109</b>, or the microphone <b>110</b> are integrated may be connected to the PC <b>100</b>. The module includes, for example, a headset in which the speaker <b>109</b> and the microphone <b>110</b> are integrated.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating an example of functions of a CPU included in the server in the present embodiment. The functions illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> are functions implemented by the CPU <b>201</b>, by execution of an output image control program stored in the ROM <b>202</b>, HDD <b>204</b>, or CD-ROM <b>211</b> by the CPU <b>201</b> included in the server <b>200</b>. Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the CPU <b>201</b> includes a participant information acquisition unit <b>251</b>, a conference material acquisition unit <b>253</b>, a first image control unit <b>255</b>, a request acceptance unit <b>257</b>, a conference state acquisition unit <b>259</b>, an image determination unit <b>261</b>, a device information acquisition unit <b>263</b>, an output destination determination unit <b>265</b>, and a second image control unit <b>267</b>.</p><p id="p-0052" num="0051">The participant information acquisition unit <b>251</b> acquires information regarding the participants who participate in the conference. The participants participate in the conference by operating any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. In a case where user IDs are input as identification information for identifying the participants when the participants participate in the conference, the user IDs of the participants are acquired from the respective PCs <b>100</b>-<b>1</b> to <b>100</b>-N. In a case where a user ID is received from any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, the participant information acquisition unit <b>251</b> associates the user ID with device identification information for identifying a device that has transmitted the user ID among the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. Specifically, the participant information acquisition unit <b>251</b> generates a participant record including the user ID and the device identification information, and stores a participant table including a plurality of participant records in the HDD <b>204</b>.</p><p id="p-0053" num="0052">The conference material acquisition unit <b>253</b> acquires data of materials to be used in the conference as presentation data. Specifically, in a case where the presentation data is received from a PC operated by a presenter among the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, the conference material acquisition unit <b>253</b> stores the presentation data in the HDD <b>204</b>. The presentation data is application data or image data. Here, the presentation data includes a plurality of pages.</p><p id="p-0054" num="0053">The first image control unit <b>255</b> transmits, as a first image, an image of a page selected by the presenter included in the presentation data (hereinafter referred to as &#x201c;presentation page&#x201d;) to each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. As a result, the first image is output by each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. Usually, the first image is displayed on display devices included in the respective PCs <b>100</b>-<b>1</b> to <b>100</b>-N. As a result, the first image is shared by all the participants. Specifically, the first image control unit <b>255</b> controls the communication unit <b>205</b> to transmit the first image to each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N in response to reception of an instruction to select a presentation page from the PC <b>100</b>-N operated by the presenter. The first image control unit <b>255</b> transmits the first image to each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N each time an instruction to select a presentation page is received from the PC <b>100</b>-N operated by the presenter. Thus, in response to switching of presentation pages by the presenter, an image of a presentation page after being switched by the presenter is displayed as the first image in each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. Note that the first image control unit <b>255</b> may transmit the presentation data to each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N in advance, and transmit a command to display the first image to each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N each time an instruction to select a presentation page is received from the PC <b>100</b>-N operated by the presenter.</p><p id="p-0055" num="0054">The conference state acquisition unit <b>259</b> acquires a conference state. The conference state includes presentation page state information and participant state information. The presentation page state information is information indicating a state in which the presentation page is displayed, and includes page identification information for identifying the presentation page and a time during which the presentation page is displayed. The participant state information is information indicating a state in which the participant is speaking, and includes participant identification information for identifying the participant and a time during which the participant is speaking.</p><p id="p-0056" num="0055">The conference state acquisition unit <b>259</b> determines, as a display start time, a time when the first image determined as the presentation page by the first image control unit <b>255</b> is transmitted, and determines, as a display end time, a time when the first image determined next as the presentation page by the first image control unit <b>255</b> is transmitted. Each time the presentation page is switched, the conference state acquisition unit <b>259</b> generates a page record in which a display start time at which display of the presentation page is started and a display end time at which display of the presentation page ends are associated with each other. The conference state acquisition unit <b>259</b> adds the page record to a presentation page table stored in the HDD <b>204</b>.</p><p id="p-0057" num="0056">The conference state acquisition unit <b>259</b> acquires voice information indicating voice of the participant from each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N operated by the plurality of participants. Each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N transmits, to the server <b>200</b>, voice information obtained by converting a voice collected by the microphone <b>110</b> into a digital signal, and video information obtained by converting a video obtained by imaging the face of the participant by the camera <b>108</b> into a digital signal. The conference state acquisition unit <b>259</b> stores the voice information and the video information received by the communication unit <b>205</b> from each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N in the HDD <b>204</b> in association with the participant. The voice information and the video information may be stored in association with the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, or may be stored in association with the participants who operate the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. The participant is authenticated and specified by the server <b>200</b> at a stage at which the participant logs in to the remote conference system by operating any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N.</p><p id="p-0058" num="0057">The conference state acquisition unit <b>259</b> specifies participant identification information of the participant on the basis of voice information received from any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, calculates a speech start time, a speech end time, and a speech time, and generates a voice record in which the participant identification information, the speech start time, the speech end time, and the speech time are associated with each other. The conference state acquisition unit <b>259</b> adds the voice record to a voice table stored in the HDD <b>204</b>.</p><p id="p-0059" num="0058">The request acceptance unit <b>257</b> accepts a request from any of the plurality of participants. The request here includes a request for displaying a second image different from the first image. The request acceptance unit <b>257</b> controls the communication unit <b>205</b> to accept the request of the participant in a case where a signal indicating the request of the participant is received from any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. The request acceptance unit <b>257</b> outputs a determination instruction to the image determination unit <b>261</b> and the output destination determination unit <b>265</b> in response to reception of a signal indicating the request of the participant by the communication unit <b>205</b>.</p><p id="p-0060" num="0059">The image determination unit <b>261</b> determines the second image in response to input of the determination instruction from the request acceptance unit <b>257</b>. The image determination unit <b>261</b> includes a related image determination unit <b>271</b> and a display history determination unit <b>273</b>. The related image determination unit <b>271</b> determines the second image from among images related to the first image. The related image determination unit <b>271</b> determines an image specified by a reserved word included in the first image as an image related to the first image. The reserved word is an instruction word that is a word indicating image identification information in combination with image identification information for identifying another image, or the image identification information itself. The instruction word is, for example, a verb such as &#x201c;refer&#x201d;, &#x201c;indicate&#x201d;, or &#x201c;represent&#x201d;. The image identification information includes a file name and a page number. In addition, the image identification information includes names such as a figure number, a table number, and a graph number attached to a figure, a table, a graph, and the like. Further, the image identification information may include a network address indicating a location in a network such as a uniform resource locator (URL).</p><p id="p-0061" num="0060">The related image determination unit <b>271</b> extracts a reserved word from the first image and determines an image specified by the reserved word as the second image. Specifically, in a case where an instruction word is extracted from the first image, the related image determination unit <b>271</b> specifies image identification information indicated by the instruction word, and determines an image of a page specified by the image identification information as the second image. For example, in a case where the first image includes a character string &#x201c;refer to the second page&#x201d;, the related image determination unit <b>271</b> extracts the instruction word &#x201c;refer&#x201d; from the first image, and determines &#x201c;the second page&#x201d; as image identification information specified by the instruction word. For example, in a case where the first image includes a character string &#x201c;<figref idref="DRAWINGS">FIG. <b>2</b></figref>&#x201d;, the related image determination unit <b>271</b> determines &#x201c;<figref idref="DRAWINGS">FIG. <b>2</b></figref>&#x201d; as image identification information from the first image. Here, a description will be given of a case where the image identification information identifies an image included in presentation data including the first image. In a case where the image identification information identifies an image included in data different from the presentation data, the related image determination unit <b>271</b> determines the second image with data stored in a predetermined range as a search target. For example, in a case where there is a plurality of pieces of presentation data, the related image determination unit <b>271</b> determines a folder storing the plurality of pieces of presentation data as the search target. In addition, the image identification information may be a network address such as a URL indicating a location on the Internet. The related image determination unit <b>271</b> determines an image of a web page specified by the URL as the second image.</p><p id="p-0062" num="0061">The related image determination unit <b>271</b> may create an association table at a stage at which presentation data is received. The related image determination unit <b>271</b> sequentially selects the presentation data as a processing target from the first page, and extracts a reserved word from the selected page. In a case where a reserved word is extracted, the related image determination unit <b>271</b> determines a page specified by the extracted reserved word. Then, the related image determination unit <b>271</b> generates an association record in which page identification information of the page as the processing target is associated with the page specified by the reserved word, and adds the association record to the association table stored in the HDD <b>204</b>.</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating an example of a first association table. The first association table is one of association tables, and includes an item of a reference source page and an item of a reference destination page. In the item of the reference source page, page identification information of a page as a processing target by the related image determination unit <b>271</b> is set, and in the item of the reference destination page, page identification information of a page specified by the reserved word by the related image determination unit <b>271</b> is set. For example, in the first record, the fifth page is set in the item of the reference source page, and the tenth page is set in the item of the reference destination page. This indicates that the tenth page is specified by a reserved word included in the fifth page, and the tenth page is associated with the fifth page.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram illustrating an example of a second association table. The second association table is one of the association tables, and includes an item of a reference source page, an item of a reference chart number, and an item of a chart number page. Page identification information of a page as a processing target by the related image determination unit <b>271</b> is set, image identification information is set in the item of the reference chart number, and page identification information of a page including an image specified by image identification information is set in the item of the chart number page. For example, in the first record, the second page is set in the item of the reference source page, &#x201c;<figref idref="DRAWINGS">FIG. <b>3</b></figref>&#x201d; is set in the item of the reference chart number, and the fifth page is set in the item of the chart number page. This indicates that the fifth page including image identification information &#x201c;<figref idref="DRAWINGS">FIG. <b>3</b></figref>&#x201d; that is a reserved word included in the second page is specified, and the fifth page is associated with the second page.</p><p id="p-0065" num="0064">Referring back to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the display history determination unit <b>273</b> determines the second image from among a plurality of images transmitted to the PCs <b>100</b>-<b>1</b> to <b>100</b>-N as the first images in the past by the first image control unit <b>255</b>. The plurality of images transmitted to the PCs <b>100</b>-<b>1</b> to <b>100</b>-N as the first images in the past by the first image control unit <b>255</b> is displayed on each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. Each of the plurality of images transmitted to the PCs <b>100</b>-<b>1</b> to <b>100</b>-N as the first images in the past by the first image control unit <b>255</b> is referred to as a displayed image. The display history determination unit <b>273</b> determines the second image from among a plurality of displayed images on the basis of a displayed time. For example, the display history determination unit <b>273</b> determines the displayed image having the longest displayed time as the second image. A time during which the plurality of displayed images is displayed is calculated with reference to the presentation page table stored in the HDD <b>204</b>.</p><p id="p-0066" num="0065">The display history determination unit <b>273</b> determines, as the second image, a displayed image displayed while a predetermined participant speaks from among the plurality of displayed images. For example, the display history determination unit <b>273</b> determines, as the second image, a displayed image displayed while a participant A is speaking. A time during which the participant A is speaking is calculated with reference to the voice table stored in the HDD <b>204</b>.</p><p id="p-0067" num="0066">The display history determination unit <b>273</b> may create a speaker table and a display time table while the conference progresses. The display history determination unit <b>273</b> generates a speaker record and a display time record each time a presentation page is displayed, and adds the speaker record and the display time record to the speaker table and the display time table stored in the HDD <b>204</b>, respectively.</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating an example of the speaker table. Referring to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the speaker table includes an item of a speaker and an item of a speech page. Page identification information for identifying the presentation page is set in the item of the speech page, and participant identification information of a participant who has spoken while the presentation page is displayed is set in the item of the speaker. For example, in the first record, &#x201c;SATO&#x201d; is set in the item of the speaker, and &#x201c;1&#x201d; is set in the item of the speech page. This indicates that a participant of the user identification information &#x201c;SATO&#x201d; has spoken while the first page is displayed as the presentation page.</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating an example of the display time table. Referring to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the display time table includes an item of a presentation page, an item of a start time, an item of an end time, and an item of a display time (seconds). Page identification information of the presentation page is set in the item of the presentation page, a time at which display of the presentation page is started is set in the item of the start time, a time at which display of the presentation page is ended is set in the item of the end time, and a time from the start time to the end time is set in the item of the display time (seconds). For example, in the first record, &#x201c;1&#x201d; is set in the item of the presentation page, &#x201c;10:00:00&#x201d; is set in the item of the start time, &#x201c;10:00:20&#x201d; is set in the item of the end time, and &#x201c;20&#x201d; is set in the item of the display time (second). This indicates that the first page has been displayed as the presentation page for 20 seconds from 10:10:00 to 10:10:20.</p><p id="p-0070" num="0069">The request accepted by the request acceptance unit <b>257</b> may include related page designation, time designation for displaying an image with a long display time, and speech page designation including user identification information for identifying a predetermined user. In this case, designation by the user can be included in the request accepted by the request acceptance unit <b>257</b>. The designation by the user includes related page designation for displaying a related image, time designation for displaying an image with a long display time, and speech page designation for designating a predetermined user. The request acceptance unit <b>257</b> outputs a determination instruction including designation by the user to the image determination unit <b>261</b>. For example, in a case where the determination instruction includes related page designation for displaying a related image, the related image determination unit <b>271</b> determines the second image. In a case where the determination instruction includes time designation for displaying an image with a long display time, the display history determination unit <b>273</b> determines the second image on the basis of the display time. In addition, in a case where the determination instruction includes speech page designation including user identification information for identifying a predetermined user, the display history determination unit <b>273</b> determines the second image displayed while the user is speaking.</p><p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating an example of a request setting screen. The request setting screen is displayed by input of a request instruction to the PCs <b>100</b>-<b>1</b> to <b>100</b>-N operated by the plurality of participants participating in the conference. <figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a state in which the request setting screen is displayed to be superimposed on a part of the first image in a state in which the first image is displayed. The request setting screen includes four selection menus. In a case where an option representing characters of &#x201c;related page&#x201d; is selected by a participant, a signal indicating a request including related page designation is transmitted to the server <b>200</b>. In a case where the signal indicating the request including the related page designation is received from any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, the request acceptance unit <b>257</b> outputs a determination instruction including the related page designation to the image determination unit <b>261</b>.</p><p id="p-0072" num="0071">In a case where an option representing characters of &#x201c;required time page&#x201d; is selected by a participant, a signal indicating a request including time designation is transmitted to the server <b>200</b>. In a case where the signal indicating the request including the time designation is received from any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, the request acceptance unit <b>257</b> outputs a determination instruction including the time designation to the image determination unit <b>261</b>. In this case, a displayed time may be settable in the time designation.</p><p id="p-0073" num="0072">In a case where an option representing characters of &#x201c;speech page&#x201d; is selected by a participant, a participant list is displayed, and when any of the participants is selected by the participant, a signal indicating a request including speech page designation is transmitted to the server <b>200</b>. The participant list includes participant identification information of all the participants of the conference or all the participants who have spoken. The speech page designation includes participant identification information of a speaker selected by the participant. In a case where the signal indicating the request including the speech page designation is received from any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, the request acceptance unit <b>257</b> outputs a determination instruction including the speech page designation to the image determination unit <b>261</b>.</p><p id="p-0074" num="0073">In a case where an option representing characters of &#x201c;another page&#x201d; is selected by a participant, an area for designating a page is displayed, and when a page is designated by the participant, a signal indicating a request including page identification information of the designated page is transmitted to the server <b>200</b>. In a case where the signal indicating the request including the page identification information is received from any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, the request acceptance unit <b>257</b> outputs a determination instruction including the page identification information to the image determination unit <b>261</b>. The image determination unit <b>261</b> determines an image of a page specified by the page identification information as the second image.</p><p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating an example of a display time setting screen. Referring to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the display time setting screen includes a plurality of display times, here, selection menus for 10 minutes, 8 minutes, 3 minutes, and 1 minute. In a case where an option for 10 minutes is selected, a page with a displayed time of greater than or equal to 10 minutes is determined as the second image; in a case where an option for 8 minutes is selected, a page with a displayed time of greater than or equal to 8 minutes and less than 10 minutes is determined as the second image; in a case where an option for 3 minutes is selected, a page with a displayed time of greater than or equal to 3 minutes and less than 8 minutes is determined as the second image; and in a case where an option for 1 minute is selected, a page with a displayed time of greater than or equal to 1 minute is determined as the second image.</p><p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram illustrating an example of a participant selection screen. Referring to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the participant selection screen includes participant identification information &#x201c;SATO&#x201d;, &#x201c;SUZUKI&#x201d;, &#x201c;TANAKA&#x201d;, and &#x201c;YAMADA&#x201d; displayed in a selectable state.</p><p id="p-0077" num="0076">Referring back to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the device information acquisition unit <b>263</b> acquires device information of each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. The device information includes the number of display devices and whether or not an image forming apparatus is connected. Here, the PC <b>100</b>-<b>1</b> is connected to two display devices, and the other PCs <b>100</b>-<b>2</b> to <b>100</b>-N are connected to one display device. In addition, the PCs <b>100</b>-<b>2</b> and <b>100</b>-<b>3</b> are connected to the MFPs <b>300</b>-<b>2</b> and <b>300</b>-<b>3</b>, respectively, and the other PCs <b>100</b>-<b>1</b>, and <b>100</b>-<b>4</b> to <b>100</b>-N are not connected to the image forming apparatus.</p><p id="p-0078" num="0077">The output destination determination unit <b>265</b> determines an output destination of the second image from among the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. The output destination determination unit <b>265</b> determines, as the output destination, a requesting device that has transmitted the request accepted by the request acceptance unit <b>257</b>. Here, a case where the PC <b>100</b>-<b>1</b> serves as the requesting device will be described as an example. Further, the output destination determination unit <b>265</b> determines the output destination on the basis of the device information of the requesting device. The device information of the PC <b>100</b>-<b>1</b>, which is the requesting device, acquired by the device information acquisition unit <b>263</b> indicates that two display devices are included. In this case, the output destination determination unit <b>265</b> determines, as the output destination, a second display device different from a first display device on which the first image is displayed among the two display devices. Note that, in a case where any of the PCs <b>100</b>-<b>2</b> and <b>100</b>-<b>3</b>, for example, the PC <b>100</b>-<b>2</b> is determined as the output destination, the device information of the PC <b>100</b>-<b>2</b> indicates that the MFP <b>300</b>-<b>2</b> is connected. In this case, the output destination determination unit <b>265</b> determines the MFP <b>300</b>-<b>2</b> as the output destination.</p><p id="p-0079" num="0078">The second image control unit <b>267</b> outputs the second image determined by the image determination unit <b>261</b> to the output destination determined by the output destination determination unit <b>265</b>. Specifically, the second image control unit <b>267</b> transmits the second image to the requesting device and causes the second image to be output from the output destination. For example, the second image control unit <b>267</b> controls the communication unit <b>205</b> to output an output instruction to the requesting device. The output instruction includes the second image and an output method for the second image. In a case where the second image control unit <b>267</b> outputs the output instruction to the PC <b>100</b>-<b>1</b>, the output method is a command to cause the second display device to perform display. In a case where the second image control unit <b>267</b> outputs the output instruction to any of the PCs <b>100</b>-<b>2</b> and <b>100</b>-<b>3</b>, the output method is a command to cause the MFPs <b>300</b>-<b>2</b> and <b>300</b>-<b>3</b> to perform image formation.</p><p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a first diagram illustrating an example of a display state. <figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates a display state of each of the PCs <b>100</b>-<b>4</b> to <b>100</b>-N. Each of the PCs <b>100</b>-<b>4</b> to <b>100</b>-N includes one display device. For this reason, a window including a first image <b>401</b> and a window including a second image <b>403</b> are displayed side by side on one display device.</p><p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a second diagram illustrating an example of the display state. <figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates a display state of PC <b>100</b>-<b>1</b>. The PC <b>100</b>-<b>1</b> includes two display devices. For this reason, the window including the first image <b>401</b> is displayed on one display device, and the window including the second image <b>403</b> is displayed on a display device different from the one display device on which the first image <b>401</b> is displayed.</p><p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram illustrating an example of an output state. <figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates an output state of each of the PCs <b>100</b>-<b>2</b> and <b>100</b>-<b>3</b>. The PC <b>100</b>-<b>2</b> includes one display device and the MFP <b>300</b>-<b>2</b>, and the PC <b>100</b>-<b>3</b> includes one display device and the MFP <b>300</b>-<b>3</b>. For this reason, the window including the first image <b>401</b> is displayed on one display device, the second image <b>403</b> is output to each of the MFPs <b>300</b>-<b>2</b> and <b>300</b>-<b>3</b>, and an image of the second image is formed on a recording medium.</p><p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart illustrating an example of a flow of output image control processing. The output image control processing is processing executed by the CPU <b>201</b>, by execution of an output image control program stored in the ROM <b>202</b>, HDD <b>204</b>, or CD-ROM <b>211</b> by the CPU <b>201</b> included in the server <b>200</b>. Referring to <figref idref="DRAWINGS">FIG. <b>15</b></figref>, the CPU <b>201</b> included in the server <b>200</b> acquires participant information (step S<b>01</b>), and advances the processing to step S<b>02</b>. The CPU <b>201</b> acquires information regarding the participants participating in the conference. In a case where the communication unit <b>205</b> receives a user ID transmitted from any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, a participant record is generated that includes the user ID and device identification information of a device that has transmitted the user ID among the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, and added to the participant table stored in the HDD <b>204</b>.</p><p id="p-0084" num="0083">In step S<b>02</b>, the conference material is acquired, and the processing proceeds to step S<b>03</b>. In a case where the communication unit <b>205</b> receives presentation data from any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, the presentation data is acquired. In a case where a presenter is determined among the plurality of participants and the presenter inputs an instruction to transmit presentation data to a PC operated among the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, the presentation data is transmitted from the PC. The presentation data received by the communication unit <b>205</b> is stored in the HDD <b>204</b>. Here, a case where presentation data includes a plurality of pages will be described as an example.</p><p id="p-0085" num="0084">In step S<b>03</b>, it is determined whether or not the first image has been determined. If the first image has been determined, the processing proceeds to step S<b>04</b>, otherwise the processing returns to step S<b>03</b>. In a case where a presentation page included in the presentation data is selected by the presenter, the image of the presentation page is determined as the first image. In step S<b>04</b>, the first image is transmitted to all the participants, and the processing proceeds to step S<b>05</b>. At this stage, the first image is displayed on each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N.</p><p id="p-0086" num="0085">In step S<b>05</b>, it is determined whether or not a request has been accepted. In a case where the communication unit <b>205</b> receives a request from any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, it is determined that the request has been accepted. The request here includes displaying the second image different from the first image. In a case where the communication unit <b>205</b> receives a signal indicating a request of a participant from any of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, the request is accepted. If the request has been accepted, the processing proceeds to step S<b>06</b>, otherwise the processing returns to step S<b>03</b>.</p><p id="p-0087" num="0086">In step S<b>06</b>, request image determination processing is executed, and the processing proceeds to step S<b>07</b>. Although details of the request image determination processing will be described later, the request image determination processing is processing of determining the second image for which output is requested by any of the participants. When the request image determination processing is executed, the second image is determined.</p><p id="p-0088" num="0087">In step S<b>07</b>, device information is acquired, and the processing proceeds to step S<b>08</b>. From a requesting device that has transmitted the signal indicating the request of the participant among the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, device information of the device is acquired. When the communication unit <b>205</b> is controlled to request the requesting device to transmit the device information and the communication unit <b>205</b> receives the device information from the requesting device, the device information is acquired.</p><p id="p-0089" num="0088">In step S<b>08</b>, output destination determination processing is executed, and the processing proceeds to step S<b>09</b>. Although details of the output destination determination processing will be described later, the output destination determination processing is processing of determining a method by which the second image is output.</p><p id="p-0090" num="0089">In step S<b>09</b>, an output instruction is transmitted to the requesting device, and the processing proceeds to step S<b>10</b>. The output instruction is transmitted from the communication unit <b>205</b> to the requesting device. The output instruction includes the second image and a command indicating a method of outputting the second image. In step S<b>10</b>, it is determined whether or not the conference has ended. If the conference has ended, the processing ends, otherwise the processing returns to step S<b>03</b>.</p><p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a flowchart illustrating an example of a flow of the request image determination processing. The request image determination processing is processing executed in step S<b>06</b> of the output image control processing. Referring to <figref idref="DRAWINGS">FIG. <b>16</b></figref>, it is determined whether or not the request indicates related page designation (step S<b>21</b>). If the request indicates the related page designation, the processing proceeds to step S<b>22</b>, otherwise the processing proceeds to step S<b>23</b>.</p><p id="p-0092" num="0091">In step S<b>22</b>, an image related to the first image is determined as the second image, and the processing returns to the output image control processing. An image specified by a reserved word included in the first image is determined as an image related to the first image. The reserved word is an instruction word or image identification information itself. The instruction word is, for example, a verb such as &#x201c;refer&#x201d;, &#x201c;indicate&#x201d;, or &#x201c;represent&#x201d;. The image identification information includes a file name and a page number. In addition, the image identification information includes names such as a figure number, a table number, and a graph number attached to a figure, a table, a graph, and the like, and a network address indicating a location in a network. Specifically, the reserved word is extracted from the first image, and the image specified by the reserved word is determined as the second image.</p><p id="p-0093" num="0092">In step S<b>23</b>, it is determined whether or not the request indicates speech page designation. If the request indicates the speech page designation, the processing proceeds to step S<b>24</b>, otherwise the processing proceeds to step S<b>25</b>. In step S<b>24</b>, a displayed image displayed while a designated user is speaking is determined as the second image, and the processing returns to the output image control processing. The displayed image is an image transmitted to and displayed on the PCs <b>100</b>-<b>1</b> to <b>100</b>-N as the first image. The designated user is a participant identified by user identification information included in the speech page designation indicated in the request. With reference to the voice table stored in the HDD <b>204</b>, a time during which the designated user is speaking is specified, and with reference to the presentation page table stored in the HDD <b>204</b>, a time during which a presented image is displayed is specified. Then, the displayed image displayed while the designated user is speaking is specified.</p><p id="p-0094" num="0093">In step S<b>25</b>, it is determined whether or not the request indicates time designation. If the request indicates the time designation, the processing proceeds to step S<b>26</b>, otherwise the processing proceeds to step S<b>27</b>. In step S<b>26</b>, a displayed image displayed for a designated time is determined as the second image, and the processing returns to the output image control processing. With reference to the presentation page table stored in the HDD <b>204</b>, a time during which the presented image is displayed is specified.</p><p id="p-0095" num="0094">In step S<b>27</b>, a designated page is determined as the second image, and the processing returns to the output image control processing. An image of the designated page specified by the page identification information included in the request among the plurality of pages included in the presentation data is determined as the second image.</p><p id="p-0096" num="0095"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flowchart illustrating an example of a flow of the output destination determination processing. The output destination determination processing is processing executed in step S<b>08</b> of the output image control processing. Referring to <figref idref="DRAWINGS">FIG. <b>17</b></figref>, the device information of the requesting device is determined (step S<b>31</b>), and the processing proceeds to step S<b>32</b>. The device information of each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N is acquired in step S<b>07</b> of the output image control processing. The device information of the requesting device among the PCs <b>100</b>-<b>1</b> to <b>100</b>-N is determined.</p><p id="p-0097" num="0096">In step S<b>32</b>, it is determined whether or not the requesting device includes a plurality of display devices. If the requesting device includes the plurality of display devices, the processing proceeds to step S<b>33</b>, otherwise the processing proceeds to step S<b>35</b>. In step S<b>33</b>, the first display device on which the first image is displayed is specified, and the processing proceeds to step S<b>34</b>. The first display device is specified by an inquiry to the requesting device about the display device on which the first image is displayed. In step S<b>34</b>, the second display device is determined as the output destination, and the processing returns to the output image control processing. The second display device is a display device different from the first display device among the plurality of display devices included in the requesting device.</p><p id="p-0098" num="0097">In step S<b>35</b>, it is determined whether or not the requesting device is connected to the image forming apparatus. If the requesting device is connected to the image forming apparatus, the processing proceeds to step S<b>36</b>, otherwise the processing returns to the output image control processing. In step S<b>36</b>, the image forming apparatus is determined as the output destination, and the processing returns to the output image control processing.</p><p id="p-0099" num="0098">Note that, although the first display device is specified in step S<b>33</b> and the second display device is determined as the output destination in step S<b>34</b>, a display device on which the first image is not displayed may be determined as the output destination. In this case, the requesting device is determined as the output destination, and a command indicating that the display device on which the first image is not displayed is the output destination is set to be transmitted to the requesting device.</p><p id="p-0100" num="0099">&#x3c;First Modification&#x3e;</p><p id="p-0101" num="0100">In the remote conference system <b>1</b> in the above-described embodiment, the CPU <b>201</b> included in the server <b>200</b> includes the image determination unit <b>261</b> and the output destination determination unit <b>265</b>. In the remote conference system <b>1</b> in a first modification, the CPU <b>201</b> included in the server <b>200</b> includes any one of the image determination unit <b>261</b> or the output destination determination unit <b>265</b>.</p><p id="p-0102" num="0101">In a case where the CPU <b>201</b> included in the server <b>200</b> includes the image determination unit <b>261</b> but does not include the output destination determination unit <b>265</b>, further, the device information acquisition unit <b>263</b> is not included. In this case, the server <b>200</b> transmits the second image determined by the image determination unit <b>261</b> to the requesting device.</p><p id="p-0103" num="0102">In a case where the CPU <b>201</b> included in the server <b>200</b> includes the output destination determination unit <b>265</b>, the image determination unit <b>261</b> is not included. In this case, the server <b>200</b> transmits, to the requesting device, the second image designated by the participant who operates the requesting device.</p><p id="p-0104" num="0103">As described above, the remote conference system <b>1</b> in the present embodiment remotely implements the conference by using the PCs <b>100</b>-<b>1</b> to <b>100</b>-N respectively operated by the plurality of participants. The server <b>200</b> outputs the first image so that the first image shared by the plurality of participants is displayed on each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, determines the output destination on the basis of the state of the requesting device operated by the requester among the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, and outputs the second image so that the second image different from the first image is output from the output destination determined in a state in which the first image is displayed on the requesting device. For this reason, the first image shared by the plurality of participants is displayed on each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, and the second image is output in the state in which the first image is displayed on the requesting device operated by the requester. For this reason, the first image and the second image are output to the requesting device. In addition, since the second image is output from the output destination determined on the basis of the state of the requesting device, the requester can view the first image and the second image.</p><p id="p-0105" num="0104">In addition, in the remote conference system <b>1</b>, for example, in a case where the PC <b>100</b>-<b>1</b> is the requesting device, the server <b>200</b> determines, as the output destination, the second display device different from the first display device on which the first image is displayed. For this reason, the participant who operates the PC <b>100</b>-<b>1</b> can simultaneously view the first image displayed on the first display device and the second image displayed on the second display device.</p><p id="p-0106" num="0105">In the remote conference system <b>1</b>, for example, in a case where the PC <b>100</b>-<b>2</b> is the requesting device, the server <b>200</b> determines the MFP <b>300</b>-<b>2</b> connected to the PC <b>100</b>-<b>2</b> as the output destination. For this reason, the participant who operates the PC <b>100</b>-<b>2</b> can simultaneously view the first image displayed on the display device and the second image formed on a sheet.</p><p id="p-0107" num="0106">In addition, in the remote conference system <b>1</b> in the present embodiment, the server <b>200</b> outputs the first image so that the first image shared by the plurality of participants is displayed on each of the PCs <b>100</b>-<b>1</b> to <b>100</b>-N, determines the second image on the basis of the state of the conference, and outputs the second image so that the second image is output by the requesting device in the state in which the first image is displayed on the requesting device operated by the requester among the PCs <b>100</b>-<b>1</b> to <b>100</b>-N. For this reason, the first image and the second image determined on the basis of the state of the conference are output to the requesting device. Thus, convenience of the participants of the conference is improved.</p><p id="p-0108" num="0107">In addition, the server <b>200</b> determines the second image from among the images related to the first image. For this reason, it is possible to output the second image necessary for understanding the content of the first image.</p><p id="p-0109" num="0108">In addition, the server <b>200</b> determines the image specified by the reserved word included in the first image as the second image. For this reason, it becomes easy to specify the first image from the second image.</p><p id="p-0110" num="0109">In addition, the server <b>200</b> determines the second image from among a plurality of images displayed as the first image in the past. For this reason, it becomes possible to view the first image currently shared and the image displayed in the past, so that the two images can be compared with each other.</p><p id="p-0111" num="0110">In addition, the server <b>200</b> determines the second image from among the plurality of images displayed as the first images on the basis of the time during which the images have been displayed as the first images. For this reason, since the second image is determined from the displayed time, it becomes easy to narrow down the second image from the plurality of images. In addition, it becomes possible to view the first image currently shared and the image displayed in the past, so that the two images can be compared with each other.</p><p id="p-0112" num="0111">In addition, the server <b>200</b> determines, as the second image, the image displayed as the first image while the predetermined participant speaks among the plurality of images displayed as the first image in the past. For this reason, since the second image is determined from a situation in which the participant has spoken, the second image can be easily determined from the plurality of images. In addition, the participant can view the first image and the image related to the predetermined participant.</p><p id="p-0113" num="0112">In addition, the server <b>200</b> determines the output destination on the basis of the state of the requesting device, and outputs the second image so that the second image is output from the determined output destination. Since the second image is output from the output destination determined on the basis of the state of the requesting device, the second image can be easily determined. In addition, the participant can view the first image and the image related to the predetermined participant.</p><p id="p-0114" num="0113">Although embodiments of the present invention have been described and illustrated in detail, the disclosed embodiments are made for purposes of illustration and example only in all respects and not limitation. The scope of the present invention should be interpreted by terms of the appended claims, and it is intended that meanings equivalent to the claims and all modifications within the scope are included.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A remote conference system that remotely implements a conference using a plurality of operating devices respectively operated by a plurality of participants, the remote conference system comprising a hardware processor that:<claim-text>outputs a first image shared by the plurality of participants to cause the first image to be displayed on each of the plurality of operating devices;</claim-text><claim-text>determines an output destination on a basis of a state of a requesting device operated by a requester among the plurality of operating devices; and</claim-text><claim-text>outputs a second image different from the first image to cause the second image to be output from the output destination determined by the hardware processor in a state in which the first image is displayed on the requesting device.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The remote conference system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein in a case where the requesting device includes a plurality of display devices, the hardware processor determines, as the output destination, a second display device different from a first display device on which the first image is displayed among the plurality of display devices.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The remote conference system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein in a case where the requesting device is connected to an image forming apparatus, the hardware processor determines the image forming apparatus as the output destination.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. A remote conference system that remotely implements a conference using a plurality of operating devices respectively operated by a plurality of participants, the remote conference system comprising a hardware processor that:<claim-text>outputs a first image shared by the plurality of participants to cause the first image to be displayed on each of the plurality of operating devices;</claim-text><claim-text>determines a second image on a basis of a state of the conference; and</claim-text><claim-text>outputs the second image to cause the second image to be output by a requesting device operated by a requester among the plurality of operating devices in a state in which the first image is displayed on the requesting device.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The remote conference system according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the hardware processor determines the second image from among images related to the first image.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The remote conference system according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the hardware processor determines an image specified by a reserved word included in the first image as the second image.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The remote conference system according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the hardware processor determines the second image from among a plurality of images displayed as the first image in a past.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The remote conference system according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the hardware processor determines the second image on a basis of a time during which each of the plurality of images is displayed as the first image in the past.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The remote conference system according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the hardware processor determines, as the second image, an image displayed as the first image while a predetermined participant speaks among the plurality of images displayed as the first image in the past.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The remote conference system according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein<claim-text>the hardware processor determines an output destination on a basis of a state of the requesting device, and</claim-text><claim-text>the hardware processor outputs the second image to cause the second image to be output from the output destination determined by the hardware processor.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The remote conference system according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein in a case where the requesting device includes a plurality of display devices, the hardware processor determines, as the output destination, a second display device different from a first display device on which the first image is displayed among the plurality of display devices.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The remote conference system according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein in a case where the requesting device is connected to an image forming apparatus, the hardware processor determines the image forming apparatus as the output destination.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. An output image control method executed in a remote conference system that remotely implements a conference using a plurality of operating devices respectively operated by a plurality of participants, the output image control method comprising:<claim-text>outputting a first image shared by the plurality of participants to cause the first image to be displayed on each of the plurality of operating devices;</claim-text><claim-text>determining an output destination on a basis of a state of a requesting device operated by a requester among the plurality of operating devices; and</claim-text><claim-text>outputting a second image different from the first image to cause the second image to be output from the output destination determined by the determining in a state in which the first image is displayed on the requesting device.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. An output image control method executed in a remote conference system that remotely implements a conference using a plurality of operating devices respectively operated by a plurality of participants, the output image control method comprising:<claim-text>outputting a first image shared by the plurality of participants to cause the first image to be displayed on each of the plurality of operating devices;</claim-text><claim-text>determining a second image on a basis of a state of the conference; and</claim-text><claim-text>outputting the second image to cause the second image to be output by a requesting device operated by a requester among the plurality of operating devices in a state in which the first image is displayed on the requesting device.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A non-transitory recording medium storing an output image control program executed by a computer that controls a remote conference system that remotely implements a conference using a plurality of operating devices respectively operated by a plurality of participants, the output image control program causing the computer to execute:<claim-text>outputting a first image shared by the plurality of participants to cause the first image to be displayed on each of the plurality of operating devices;</claim-text><claim-text>determining an output destination on a basis of a state of a requesting device operated by a requester among the plurality of operating devices; and</claim-text><claim-text>outputting a second image different from the first image to cause the second image to be output from the output destination determined by the determining in a state in which the first image is displayed on the requesting device.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A non-transitory recording medium storing an output image control program executed by a computer that controls a remote conference system that remotely implements a conference using a plurality of operating devices respectively operated by a plurality of participants, the output image control program causing the computer to execute:<claim-text>outputting a first image shared by the plurality of participants to cause the first image to be displayed on each of the plurality of operating devices;</claim-text><claim-text>determining a second image on a basis of a state of the conference; and</claim-text><claim-text>outputting the second image to cause the second image to be output by a requesting device operated by a requester among the plurality of operating devices in a state in which the first image is displayed on the requesting device.</claim-text></claim-text></claim></claims></us-patent-application>
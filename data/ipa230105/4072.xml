<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004073A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004073</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17517026</doc-number><date>20211102</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>IN</country><doc-number>202141029497</doc-number><date>20210630</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>03</class><subclass>B</subclass><main-group>17</main-group><subgroup>56</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>232</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>03</class><subclass>B</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>03</class><subclass>B</subclass><main-group>17</main-group><subgroup>12</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>03</class><subclass>B</subclass><main-group>17</main-group><subgroup>561</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180801</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23218</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180801</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23299</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>03</class><subclass>B</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>03</class><subclass>B</subclass><main-group>17</main-group><subgroup>12</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">AUTOMATED IMAGE CAPTURING APPARATUS AND SYSTEM THEREOF</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>Infosys Limited</orgname><address><city>Bangalore</city><country>IN</country></address></addressbook><residence><country>IN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>ASADULLAH</last-name><first-name>ALLAHBAKSH MOHAMMEDALI</first-name><address><city>Hubli</city><country>IN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Tarafdar</last-name><first-name>Mohammed Rafee</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Modak</last-name><first-name>Trijeet Kumar</first-name><address><city>Chinsurah</city><country>IN</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Pande</last-name><first-name>Anant Yash</first-name><address><city>Dhanbad</city><country>IN</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Behera</last-name><first-name>Anupam</first-name><address><city>Berhampur</city><country>IN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A system and apparatus for automated image capturing, comprising a microcontroller, an image capturing device operatively coupled to the pair of guiding apparatus using a first electric rotary actuator, a rotary plate operatively mounted on a second electric rotary actuator. The pair of guiding apparatus and the first electric rotary actuator is actuated to cause change in position of the image capturing device relative to an object positioned on the rotary plate and second electric rotary actuator is actuated causing change in angle of orientation of the object positioned on the rotary plate. By varying lighting conditions and for different background images, plurality of images of object are captured using the image capturing device by actuating electro-mechanical components of the apparatus.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="216.15mm" wi="142.66mm" file="US20230004073A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="226.82mm" wi="144.70mm" file="US20230004073A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="195.92mm" wi="159.34mm" orientation="landscape" file="US20230004073A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="180.85mm" wi="143.59mm" file="US20230004073A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="181.53mm" wi="125.73mm" orientation="landscape" file="US20230004073A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="182.29mm" wi="150.88mm" orientation="landscape" file="US20230004073A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><p id="p-0002" num="0001">This application claims the benefit of Indian Patent Application Serial No. 202141029497 filed Jun. 30, 2021, which is hereby incorporated by reference in its entirety.</p><heading id="h-0001" level="1">FIELD</heading><p id="p-0003" num="0002">The present technique relates to automated image capturing apparatus. More specifically, the technique relates to automated image capturing techniques and apparatus to generate image data set for training machine learning models.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Machine learning and deep-learning training in the field of image recognition requires large volume of image data. Generating high quality datasets of target objects is a time-consuming effort. The present technology involves a large amount of human effort and time to collect the data for any object to train and identify the object through means of machines (Deep Learning). For example, for an Autonomous Retail store several images of an item are captured using a camera with human effort in different orientations, backgrounds, lighting conditions, occlusions etc. Based on this image data set, the system is trained to detect the item/object so that a seamless, cashier-less experience is provided. In case of Generative Adversarial Networks (GAN), the images generated are fake and sometimes they are of very low quality. This does not generate images for all scenarios and often results in more effort as GAN is still evolving. In cases where the training data need to be generated in the challenging physical condition, it is difficult for human to operate. Some of the existing technologies such as data augmentation techniques generate multiple variants of the image by modifying/transforming existing images to generate more and multiple variants of image dataset either my inducing noise or by altering pixels etc.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0005" num="0004">As mentioned in the background, one of the solutions is to automate the process of capturing images of desired objects in varying lighting conditions and from different orientations in a short span of time to speed up the data collection process along with capturing plurality of images for multiple combinations of camera position, object position, lighting condition etc. in an automated manner in very short span of time.</p><p id="p-0006" num="0005">Disclosed are a system, apparatus and method for automated image capturing by central computing system which is configured to control the position and operation of the camera, the orientation of the object and lighting of the environment.</p><p id="p-0007" num="0006">In one aspect, a system for automated image capturing is disclosed. The system comprises components such as, but not limited to a microcontroller, a pair of guiding apparatus, an image capturing device operatively coupled to the pair of guiding apparatus using a first electric rotary actuator, a rotary plate operatively mounted on a second electric rotary actuator, at least one processor and at least one memory unit. The at least one processor is configured to actuate at least one of the pair of guiding apparatus and the first electric rotary actuator, through the microcontroller, to cause change in position of the image capturing device relative to an object positioned on the rotary plate and capture one or more images of the object positioned on the rotary plate. The one or more images are captured by the image capturing device for plurality of combinations of angle of orientation of object and position of the image capturing device. The at least one processor may also be configured to actuate the second electric rotary actuator through the microcontroller, causing change in angle of orientation of the object positioned on the rotary plate. The second electric rotary actuator is positioned at a predetermined distance from a position of the pair of guiding apparatus.</p><p id="p-0008" num="0007">The system comprises another guiding apparatus actuated through the microcontroller, which comprises an occlusion object positioned between the rotary plate and the pair of guiding apparatus. The at least one processor is configured to display at least one background image through a display device. The above mentioned components are controlled by the at least one processor centrally through the microcontroller to capture one or more images of the object positioned on the rotary plate with plurality of combinations of position of the image capturing device, angle of orientation of the object, position of the occlusion object and the background image displayed on the display device positioned behind the object.</p><p id="p-0009" num="0008">In another aspect, an apparatus for automated image capture is disclosed. The apparatus comprises one or more operatively coupled components such as, but not limited to a microcontroller, a first guiding apparatus, a second guiding apparatus, a third guiding apparatus, an image capturing device, a rotary plate and at least one processor. The second guiding apparatus is operatively coupled to the first guiding apparatus wherein the second guiding apparatus is mounted at an angle on the first guiding apparatus. The image capturing device is operatively coupled to the second guiding apparatus using a first electric rotary actuator. The rotary plate is operatively mounted on a second electric rotary actuator positioned at a predetermined distance from the first guiding apparatus. The third guiding apparatus comprising an occlusion object is positioned between the first guiding apparatus and the second electric rotary actuator.</p><p id="p-0010" num="0009">The at least one processor is configured to send one or more instructions to the microcontroller which causes microcontroller to actuate the either or combination of, the first guiding apparatus, the second guiding apparatus, the third guiding apparatus, the first electric rotary actuator and the second electric rotary actuator. By sending instructions to the microcontroller, the at least one processor is configured to capture one or more images of an object positioned on the rotary plate, with or without occlusion object for plurality lighting conditions and plurality of background images displayed using a display unit.</p><p id="p-0011" num="0010">In yet another aspect, a computer implemented method for automated image capture is disclosed. A processor may be configured to send one or more instructions to a microcontroller causing the microcontroller to perform one or more steps, comprising positioning the object, positioning the image capturing device and capturing one or more images of the object. The processor may send one or more instructions to the microcontroller which causes positioning an object at an angle of orientation by actuating an electric rotary actuator associated with a rotary plate. The processor may send one or more instructions to the microcontroller to actuate a guiding apparatus and an electric rotary actuator associated with image capturing device to position the image capturing device to point at the object. The processor may send one or more instructions to image capturing device to capture one or more images of the object. The method further comprising, positioning an occlusion object between the object and the image capturing device using a guiding apparatus. The one or more images are capture for plurality of combinations of angle of orientation of the object and position of the image capturing device.</p><p id="p-0012" num="0011">The system, apparatus and/or method disclosed herein may be implemented in any means for achieving various aspects, and may be executed in a form of a machine-readable medium embodying a set of instructions that, when executed by a machine, cause the machine to perform any of the operations disclosed herein. Other features will be apparent from the accompanying drawings and from the detailed description that follows.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0013" num="0012">Example embodiments are illustrated by way of example and not limitation in the figures of the accompanying drawings, in which like references indicate similar elements and in which:</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagrammatic representation of a data processing system capable of processing a set of instructions to perform any one or more of the methodologies herein, according to one or more embodiments.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagrammatic representation of exemplary assembly of various components of automated image capturing apparatus, according to one or more embodiments.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> is a diagrammatic representation of front view perspective of the image capturing device and electric rotary actuator associated with the image capturing device, according to one or more embodiments.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> is a diagrammatic representation of a perspective view of a guiding apparatus comprising occlusion object and electric rotary actuator comprising object of which image to be captured, according to one or more embodiments.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>2</b>C</figref> is an architecture diagram illustrating various components of the system for automated image capturing, according to one or more embodiments.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a process flow diagram illustrating a computer implemented method for automated image capturing, according to one or more embodiments.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagrammatic representation of position of various components of the image capturing apparatus, according to one or more embodiments.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is a diagrammatic representation of determining angle for the image capturing device, according to one or more embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0022" num="0021">Other features of the present embodiments will be apparent from the accompanying drawings and from the detailed description that follows.</p><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0023" num="0022">One of the exemplary objectives of examples of this technology is to overcome the technical problem mentioned in the background section through a system, apparatus and method for automated image capturing by central computing system which is configured to control the position and operation of the camera, the orientation of the object and lighting of the environment, which automates and speed up the data collection process with more accuracy.</p><p id="p-0024" num="0023">In one or more embodiments, a system, apparatus and/or a method for automated image capturing is disclosed. The system comprising components such as, but not limited to a microcontroller, a pair of guiding apparatus, an image capturing device operatively coupled to the pair of guiding apparatus using a first electric rotary actuator, a rotary plate operatively mounted on a second electric rotary actuator, at least one processor and at least one memory unit. The at least one processor may be configured to actuate at least one of the pair of guiding apparatus and the first electric rotary actuator, through the microcontroller, to cause change in position of the image capturing device relative to an object positioned on the rotary plate and capture one or more images of the object positioned on the rotary plate. The one or more images may be captured by the image capturing device for plurality of combinations of angle of orientation of object and position of the image capturing device. The at least one processor may also be configured to actuate the second electric rotary actuator through the microcontroller, causing change in angle of orientation of the object positioned on the rotary plate. The second electric rotary actuator may be positioned at a predetermined distance from a position of the pair of guiding apparatus.</p><p id="p-0025" num="0024">The system further comprises another guiding apparatus actuated through the microcontroller, which comprises an occlusion object positioned between the rotary plate and the pair of guiding apparatus. The at least one processor is configured to display at least one background image through a display device. The above mentioned components are controlled by the at least one processor centrally through the microcontroller capture to one or more images of the object positioned on the rotary plate with plurality of combinations of position of the image capturing device, angle of orientation of the object, position of the occlusion object and the background image displayed on the display device positioned behind the object.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagrammatic representation of a machine and/or data processing device capable of processing a set of instructions to perform any one or more of the methodologies herein, according to one embodiment. The machine and/or the data processing device in the example form, comprises a computer system <b>100</b> within which a set of instructions, for causing the machine to perform any one or more of the methodologies discussed herein, may be executed. In various embodiments, the machine operates as a standalone device and/or may be connected (e.g., networked) to other machines.</p><p id="p-0027" num="0026">A machine may be a personal computer (PC), laptop or an embedded system and/or any machine capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that machine. Further, while only a single machine is illustrated, the term &#x201c;machine&#x201d; shall also be taken to include any collection of machines that individually and/or jointly execute a set (or multiple sets) of instructions to perform any one and/or more of the methodologies discussed herein.</p><p id="p-0028" num="0027">The example computer system <b>100</b> includes a processor <b>102</b> (e.g., a central processing unit (CPU) a graphics processing unit (GPU) and/or both), a main memory <b>104</b> and a static memory <b>106</b>, which communicate with each other via a bus <b>108</b>. The computer system <b>100</b> may further include a video display unit <b>110</b> (e.g., a liquid crystal displays (LCD) and/or a cathode ray tube (CRT)). The computer system <b>100</b> also includes an alphanumeric input device <b>112</b> (e.g., a keyboard), a cursor control device <b>114</b> (e.g., a mouse), a disk drive unit <b>116</b>, a signal generation device <b>118</b> (e.g., a speaker), a network interface <b>120</b> and a microcontroller <b>128</b>.</p><p id="p-0029" num="0028">The disk drive unit <b>116</b> includes a machine-readable medium <b>122</b> on which is stored one or more sets of instructions <b>124</b> (e.g., software) embodying any one or more of the methodologies and/or functions described herein. The instructions <b>124</b> may also reside, completely and/or at least partially, within the main memory <b>104</b>, within the static memory <b>106</b> and/or within the processor <b>102</b> during execution thereof by the computer system <b>100</b>, the main memory <b>104</b> and the processor <b>102</b> also constituting machine-readable media.</p><p id="p-0030" num="0029">The instructions <b>124</b> may further be transmitted and/or received over a network <b>126</b> via the network interface <b>120</b>. While the machine-readable medium <b>122</b> is shown in an example embodiment to be a single medium, the term &#x201c;machine-readable medium&#x201d; should be taken to include a single medium and/or multiple media (e.g., a centralized and/or distributed database, and/or associated caches and servers) that store the one or more sets of instructions. The term &#x201c;machine-readable medium&#x201d; shall also be taken to include any medium that is capable of storing, encoding and/or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the various embodiments. The term &#x201c;machine-readable medium&#x201d; shall accordingly be taken to include, but not be limited to, solid-state memories, optical media and magnetic media.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagrammatic representation of exemplary assembly of various components of automated image capturing apparatus, according to one or more embodiments. In one or more embodiments, the automated image capturing apparatus <b>200</b> comprises one or more components, but not limited to, a first guiding apparatus <b>202</b>, a second guiding apparatus <b>204</b>, a third guiding apparatus <b>210</b>, a first electric rotary actuator <b>206</b>, an image capturing device <b>208</b>, an occlusion object <b>212</b>, an object <b>214</b> (also referred as &#x2018;target object&#x2019;) of which plurality of images to be captured and a rotary plate <b>216</b>.</p><p id="p-0032" num="0031">In one or more embodiments the first guiding apparatus <b>202</b> may be an electro-mechanical linear guide which provides linear motion by re-circulating rolling elements between a profiled rail and a bearing block <b>202</b>B, wherein the linear motion is achieved using a stepper motor <b>202</b>A which is actuated by sending one or more instructions through the microcontroller <b>128</b> by the processor <b>102</b>. The second guiding apparatus <b>204</b> may be an electro-mechanical linear guide mechanically and operatively coupled to the first guiding apparatus <b>202</b> wherein the second guiding apparatus <b>204</b> is mounted on the bearing block <b>202</b>B of the first guiding apparatus <b>202</b> at an angle which is measured along the axis of movement of the bearing block <b>202</b>B of the first guiding apparatus <b>202</b>. The second actuating apparatus <b>204</b> comprises a stepper motor <b>204</b>A and bearing block <b>204</b>B wherein the bearing block <b>204</b>B moves along profiled rail of the second actuating apparatus <b>204</b>, wherein the movement is achieved by actuating the stepper motor <b>204</b>A by sending one or more instructions to the stepper motor <b>204</b>A through the microcontroller <b>128</b> by the processor <b>102</b>. The angle at which the second guiding apparatus <b>204</b> mounted on the first guiding apparatus <b>202</b> may be adjusted to any degree between 45&#xb0; to 60&#xb0;, based on preferred view angle of the target object.</p><p id="p-0033" num="0032">The image capturing device <b>208</b> may be operatively coupled to the bearing block <b>204</b>B of the second guiding apparatus <b>204</b> using the first electric rotary actuator <b>206</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>. Referring to <figref idref="DRAWINGS">FIG. <b>2</b>A</figref> which is a diagrammatic representation of front view perspective of the image capturing device <b>208</b> and the first electric rotary actuator <b>206</b> associated with the image capturing device <b>208</b>, according to one or more embodiments. The image capturing device <b>208</b> may be operatively coupled to first electric rotary actuator <b>206</b> which is in turn physically coupled to the bearing block <b>204</b>B of the second guiding apparatus <b>204</b>. The bearing block <b>204</b>B of the second guiding apparatus <b>204</b> may be equipped with a lighting component <b>218</b>, which is a light source operated by sending one or more instructions from the microcontroller <b>128</b>.</p><p id="p-0034" num="0033">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a rotary plate <b>216</b> may be positioned at a predetermined distance from the first guiding apparatus <b>202</b>. Further, a third guiding apparatus <b>210</b> may be positioned between the first guiding apparatus <b>202</b> and the rotary plate <b>216</b>. The third guiding apparatus <b>210</b> comprises a stepper motor <b>210</b>A and a bearing block <b>210</b>B wherein the movement of the bearing block <b>210</b>B is achieved by actuating the stepper motor <b>210</b>A by sending one or more instructions through the microcontroller <b>128</b> by the processor <b>102</b>. An occlusion object <b>212</b> may be physically positioned (mounted) on the bearing block <b>210</b>B of the third guiding apparatus <b>210</b>. The object <b>214</b> may be positioned on the rotary plate <b>216</b>.</p><p id="p-0035" num="0034">Referring to <figref idref="DRAWINGS">FIG. <b>2</b>B</figref> which is a diagrammatic representation of a perspective view of the third guiding apparatus <b>210</b> comprising occlusion object <b>212</b> and a second electric rotary actuator <b>220</b> comprising a rotary plate <b>216</b> on which object <b>212</b> of which image to be captured is placed, according to one or more embodiments. The assembly of various components of the image capturing apparatus <b>200</b> is described in subsequent paragraphs.</p><p id="p-0036" num="0035">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, as mentioned in previous paragraphs, the second guiding apparatus <b>204</b> is mounted on the bearing block <b>202</b>B of the first guiding apparatus <b>202</b> at an angle which is measured along the axis of movement of the bearing block <b>202</b>B of the first guiding apparatus <b>202</b>. For the reference purpose, the direction is which the profiled rail of the first guiding apparatus <b>202</b> is present may be considered as &#x2018;x&#x2019; axis. The bearing block <b>202</b>B of the first guiding apparatus <b>202</b> may be configured to move along the profiled rail in a first direction and a direction opposite to the first direction which may result in movement of the second guiding apparatus <b>204</b> mounted on the bearing block <b>202</b>B of the first guiding apparatus <b>202</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, the electric rotary actuator <b>206</b> may be physically coupled to the bearing block <b>204</b>B of the second guiding apparatus <b>204</b>. The image capturing device <b>208</b> may be operatively coupled to the first electric rotary actuator <b>206</b>. Both the image capturing device <b>208</b> and the first electric rotary actuator <b>206</b> may be configured to move along the direction of the rails of the second guiding apparatus <b>204</b>, based on the instructions executed by the microcontroller <b>128</b>. The image capturing device <b>208</b> may be configured to rotate within the pre-defined range of angles along the axis perpendicular axis of the direction of movement of the bearing block <b>204</b>B of the second guiding apparatus <b>204</b>. The third guiding apparatus <b>210</b> may be positioned in front of the first guiding apparatus as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in a direction perpendicular to the direction of movement of bearing block <b>202</b>B of the first guiding apparatus <b>202</b>. An occlusion object <b>212</b> may be positioned on top of the bearing block <b>210</b>B of the third guiding apparatus <b>210</b>. A rotary plate <b>216</b> may be positioned adjacent to the third guiding apparatus <b>210</b> (as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>) wherein the object <b>214</b> may be positioned on top of the rotary plate <b>214</b>.</p><p id="p-0037" num="0036">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, the rotary plate <b>216</b> may be operatively mounted on the second electric rotary actuator <b>220</b> which is configured to receive one or more instructions from the microcontroller <b>128</b> for operation. The rotary plate <b>216</b> may be configured to move either in clockwise direction or anti-clockwise direction while capturing the image of object <b>214</b> positioned on the rotary plate <b>216</b>.</p><p id="p-0038" num="0037">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the third guiding apparatus <b>210</b> maybe positioned between the first guiding apparatus <b>202</b> and the rotary plate <b>216</b> comprising object <b>214</b>. The third guiding apparatus <b>210</b> may be positioned at a predetermined distance form the first guiding apparatus <b>202</b>. The rotary plate <b>216</b> may be positioned at a predetermine distance from the first guiding apparatus <b>202</b>. The predetermined distance may be calculated based on at least one of, but not limited to, focal length of the image capturing device <b>208</b> and/or the field of view value of the image capturing device <b>208</b> so that the images of the object <b>214</b> captured by the images capturing device <b>208</b> with or without the occlusion object <b>214</b> is always within the focal length range of the image capturing device <b>208</b>.</p><p id="p-0039" num="0038">In one or more embodiments, the first guiding apparatus <b>202</b>, the second guiding apparatus <b>204</b>, the third guiding apparatus <b>210</b>, the first electric rotary actuator <b>206</b>, the rotary plate <b>216</b> through the second electric rotary actuator <b>220</b>, and/or the lighting component <b>218</b> may be centrally controlled and actuated through microcontroller <b>128</b> by sending one or more instructions from the processor <b>102</b>. The image capturing apparatus <b>200</b> may also comprise a background display unit (also referred as background display device) positioned behind the object <b>214</b> or the rotary plate <b>216</b> (not illustrated in figures) configured to display plurality of background images while capturing images of the object <b>214</b>. Plurality of background images may be stored in a database and at least one image may be fetched from the database to be displayed as background images at the background display unit while capturing images of the object <b>214</b>.</p><p id="p-0040" num="0039">Based on the one or more instructions sent by the processor <b>102</b>, the microcontroller <b>128</b> may be configured to actuate the stepper motor <b>202</b>A of the first guiding apparatus <b>202</b> which causes the bearing block <b>202</b>B of the first guiding apparatus <b>202</b> to move in a first direction and in a direction opposite to the first direction along the axis of the railings of the first guiding apparatus <b>202</b>. For example, the first direction of movement may be the movement of the bearing block <b>202</b>B of the first guiding apparatus <b>202</b> towards the object <b>214</b> positioned in front of the image capturing device <b>208</b>. The direction opposite to the first direction of movement may be the movement of the bearing block <b>202</b>B of the first guiding apparatus <b>202</b> away from the object <b>214</b> positioned in front of the image capturing device <b>208</b>. For the reference purpose, the direction is which the profiled rail of the first guiding apparatus <b>202</b> is present may be considered as &#x2018;x&#x2019; axis.</p><p id="p-0041" num="0040">Based on the one or more instructions sent by the processor <b>102</b>, the microcontroller <b>128</b> may be configured to actuate the stepper motor <b>204</b>A of the second guiding apparatus <b>204</b> which causes the bearing block <b>204</b>B of the second guiding apparatus <b>204</b> to move in a second direction and a direction opposite to the second direction along the axis of the railings of the second guiding apparatus <b>204</b>. For example, the second direction of movement may be the movement of the bearing block <b>204</b>B of the second guiding apparatus <b>204</b> towards the first guiding apparatus <b>202</b>. The direction opposite to the second direction of movement may be the movement of the bearing block <b>204</b>B of the second guiding apparatus <b>204</b> away from the first guiding apparatus <b>202</b>. The actuation of the second guiding apparatus <b>204</b> may in turn cause the movement of first electric rotary actuator <b>206</b>, the image capturing device <b>208</b> and the lighting system <b>218</b>, along with the movement of the bearing block <b>204</b>B of the second guiding apparatus <b>204</b>. For the reference purpose, the direction is which the profiled rail of the second guiding apparatus <b>204</b> is present may be considered as &#x2018;z&#x2019; axis.</p><p id="p-0042" num="0041">Based on the one or more instructions sent by the processor <b>102</b>, the microcontroller <b>128</b> may be configured to actuate the stepper motor <b>210</b>A of the third guiding apparatus <b>210</b> which causes the bearing block <b>210</b>B of the third guiding apparatus <b>210</b> to move in a third direction and a direction opposite to the third direction along the axis of the railings of the third guiding apparatus <b>210</b>. For the reference purpose, the direction is which the profiled rail of the third guiding apparatus <b>210</b> is present may be considered as &#x2018;y&#x2019; axis. The actuation of the third guiding apparatus <b>210</b> may in turn cause the movement of occlusion object <b>212</b> positioned on the bearing block <b>210</b>B of the third guiding apparatus <b>210</b> which may cause either partial obstruction or complete obstruction to the view of object <b>214</b> from the image capturing device <b>208</b>, which helps in capturing images of the object <b>214</b> with obstacles/occlusion object to generate image data set for the machine learning models to train efficiently.</p><p id="p-0043" num="0042">Based on the one or more instructions sent by the processor <b>102</b>, the microcontroller <b>128</b> may be configured to actuate the first electric rotary actuator <b>206</b> which may cause angular movement of the image capturing device <b>208</b> along the axis of the second guiding apparatus <b>204</b> so that whatever may be the position of the image capturing device <b>208</b> along the axis of the second guiding apparatus <b>208</b>, the image capturing device <b>208</b> remains focusing on the object <b>216</b> all the time. Also, the actuation of the first electric rotary actuator <b>206</b> may cause the image capturing device <b>208</b> to capture one or more images of the object <b>214</b> from various angles. In an example embodiment, the first electric rotary actuator <b>206</b> may be a servo motor.</p><p id="p-0044" num="0043">Based on the one or more instructions sent by the processor <b>102</b>, the microcontroller <b>128</b> may be configured to actuate the second electric rotary actuator <b>220</b> which may cause the rotary plate <b>216</b> to rotate either in clockwise or anti-clockwise direction which may cause the object <b>214</b> mounted on the rotary plate <b>216</b> to rotate. In an example embodiment, the second electric rotary actuator <b>220</b> may be a servo motor.</p><p id="p-0045" num="0044">Based on the one or more instructions sent by the processor <b>102</b>, the microcontroller <b>128</b> may be configured perform at least one of, but not limited to, switch on/off the lighting system <b>218</b>, increase or decrease the brightness level of the lighting system <b>218</b>, and/or change the color of the lighting system <b>218</b>.</p><p id="p-0046" num="0045">The processor <b>102</b> may be configured to send one or more instructions to the microcontroller <b>128</b> which causes microcontroller <b>128</b> to actuate the either or combination of, the first guiding apparatus <b>202</b>, the second guiding apparatus <b>204</b>, the third guiding apparatus <b>210</b>, the first electric rotary actuator <b>208</b> and the second electric rotary actuator <b>220</b>. Such actuation may cause at least one or combination of&#x2014;movement of second guiding apparatus <b>204</b> along the first direction and/or direction opposite to the first direction, movement of the image capturing device <b>208</b> in a second direction and/or the direction opposite to the second direction, movement of the occlusion object <b>212</b> in a third direction and the direction opposite to the third direction, rotation of the rotary plate <b>216</b> either in a clockwise direction or an anti-clockwise direction and/or change in angle of orientation of the image capturing device <b>208</b> pointing at the object <b>214</b>. As the above-mentioned components are actuated, the processor <b>102</b> may simultaneously send one or more instructions to the image capturing device <b>208</b> to capture plurality of images of the object <b>214</b> with or without the obstacle(s) caused by occlusion object <b>212</b> and with or without the background images being displayed at the background display unit, positioned in front of the image capturing device <b>208</b> (behind the rotary plate <b>216</b>).</p><p id="p-0047" num="0046">In one or more embodiments, during the image capture, at least one or combination of components are stopped at a position and rest of the components are actuated to capture images from plurality of combinations of angle, distance, orientation of the object <b>214</b>, with or without occlusion object <b>212</b>, for various lighting condition through lighting system <b>218</b> for various combination of background images.</p><p id="p-0048" num="0047">In an example embodiment, consider the first guiding apparatus <b>202</b> is actuated causing the bearing block <b>202</b>B to be stopped at position &#x2018;A&#x2019; along the rails of the first guiding apparatus <b>202</b>, and image capturing device <b>208</b> is stopped at position &#x2018;B&#x2019; along the rails of the second guiding apparatus <b>204</b> and also the image capturing device <b>208</b> is positioned at an angle &#x2018;C&#x2019; by actuating first electric rotary actuator <b>206</b>, and the occlusion object is stopped at position &#x2018;D&#x2019; along the rails of the third guiding apparatus <b>210</b>, then the object <b>214</b> may be rotated for 360 degrees hence generating 360 or more images of the object <b>214</b> from all angles of rotation of rotary plate <b>216</b> at one particular position of image capturing device <b>208</b> for different lighting conditions and different background images. In another example embodiments, the object <b>214</b> may be stopped at one angle and at least one or combination of all other components are actuated to capture plurality of images of the object <b>214</b>. As the variables are in terms of positions of first guiding apparatus <b>202</b>, second guiding apparatus <b>204</b>, third guiding apparatus <b>210</b>, first electric rotary actuator <b>206</b>, second electric rotary actuator <b>220</b>, lighting conditions <b>218</b> and background display, numerous combinations of images can be captured in less time thereby providing automating image capturing process and eliminating human intervention. The steps to determine positions and angles are described in subsequent paragraphs of the present disclosure.</p><p id="p-0049" num="0048">In one or more embodiments, <figref idref="DRAWINGS">FIG. <b>2</b>C</figref> illustrates an architecture of a system for autonomous image capture, according to one or more embodiments. The system comprises one or more components such as, but not limited to, a computing system <b>222</b> comprising a processor <b>102</b>, an image capturing device <b>208</b>, a microcontroller <b>128</b>, a background display unit <b>224</b>, a lighting component <b>218</b>, a camera positioning system <b>224</b> and an object positioning system <b>226</b>. The computing system <b>222</b> may be communicatively coupled to image capturing device <b>208</b>, the microcontroller <b>128</b> and the background display unit <b>224</b>. The computing system <b>222</b> may be communicatively coupled to the lighting component <b>218</b>, the camera positioning system <b>224</b> and object positioning system <b>226</b> through the microcontroller <b>128</b>.</p><p id="p-0050" num="0049">In one or more embodiments, the computing system <b>222</b> may be a standard desktop, a single-board computer like Raspberry Pi or any such computing device comprising the processor <b>102</b> and capable of executing one or more instructions. The computing system <b>222</b> may execute one or more instructions that may calculate various states or actuation position of components that the system must achieve to capture and generate image dataset. In one or more embodiments, the image capturing device <b>208</b> may be communicatively coupled to the computing system <b>222</b> and may be configured to capture plurality of images by varying different parameters such as, but not limited to resolution, shutter speed, aperture etc. In one or more embodiments, the background display unit <b>224</b> may be communicatively coupled to the computing system <b>222</b> and may be configured to display background images while generating image dataset through image capturing device <b>208</b>. The background images and the metadata associated with the background images such as resolution, storage location information and information on type/format of the background images may be stored in a database associated with the computing system <b>222</b> and may be displayed using the background display unit <b>224</b>.</p><p id="p-0051" num="0050">In one or more embodiments, the microcontroller <b>128</b> may be operatively coupled to the computing system <b>222</b> either with a serial connection or Wi-Fi link and may be configured to communicate with computing system <b>222</b> and various other components of the system described in the present disclosure. The microcontroller <b>128</b> may be configured to send one or more instructions to components communicatively coupled to it, to achieve state or position based on one or more instructions received from the computing system <b>222</b> and return confirmation to the computing system <b>222</b> after execution of the instructed state or actuation position. The state here may refer to intended position of various components such as linear guides, electric rotary actuators, or the luminosity of color of the light component that the microcontroller is configured to achieve for image capture.</p><p id="p-0052" num="0051">In one or more embodiments, the lighting component <b>218</b> may comprise Light Emitting Diodes (LED) array that is operatively coupled to the microcontroller <b>128</b>. The required brightness and color is controlled by the microcontroller <b>128</b> which may receive the values for brightness of light and/or values for color of light from the computing system <b>222</b>. The lighting component <b>218</b> may be mounted along with the camera (to the bearing block <b>204</b>B of the second linear guide <b>204</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>) so that the lighting system may always point at the object positioned using the object positioning system <b>226</b>.</p><p id="p-0053" num="0052">In one or more embodiments, the camera positioning system <b>224</b> may comprise pair of guiding apparatus i.e. a guiding apparatus&#x2014;&#x2018;x&#x2019; axis <b>202</b> (also referred as an &#x2018;horizontal linear guide&#x2019; <b>202</b> or a proximity guide <b>202</b>), and a guiding apparatus &#x2018;z&#x2019; axis <b>204</b> (also referred as a &#x2018;vertical linear guide&#x2019; <b>204</b> or a perspective guide <b>204</b>), and a first electric rotary actuator <b>206</b> (also referred as a perspective tuner <b>206</b>). The object positioning system <b>226</b> may comprise guiding apparatus&#x2014;&#x2018;y&#x2019; axis <b>210</b> (also referred as an occlusion guide <b>210</b>) and a second electric rotary actuator <b>220</b> (an orientation tuner <b>220</b>). The proximity guide <b>202</b> and the perspective guide <b>204</b> may be coupled to each other wherein the perspective guide <b>204</b> may be mounted on the proximity guide <b>202</b> at a predetermined angle. The perspective tuner <b>206</b> may be coupled to the perspective guide <b>204</b> and the image capturing device <b>208</b> may be operatively coupled to the perspective tuner <b>206</b>. The proximity guide <b>202</b> may be actuated through a stepper motor <b>202</b>A, the perspective guide <b>204</b> may be actuated through a stepper motor <b>204</b>A. The perspective tuner <b>206</b> may be configured to actuate image capturing device <b>208</b>, which may be a servo motor. The angle of orientation the image capturing device <b>208</b> may be changed/controlled using the servo motor to make sure that the image capturing device <b>208</b> always keeps the subject/object within the focus area/frame during the image capture. The actuation position of the servo motor i.e., the angle of orientation of the image capturing device may be calculated based on the angle between the proximity guide <b>202</b> and perspective guide <b>204</b>, and the position of both the proximity guide <b>202</b> and perspective guide <b>204</b> with respect to rotary plate where the object is positioned.</p><p id="p-0054" num="0053">The object positioning system <b>226</b> may comprise a guiding apparatus&#x2014;&#x2018;y&#x2019; axis <b>210</b> (also referred as occlusion guide <b>210</b>) and the second electric rotary actuator <b>220</b> (also referred as orientation tuner <b>220</b>). The occlusion guide <b>210</b> may comprise an occlusion object wherein the occlusion object is mounted on the occlusion guide <b>210</b>. The orientation tuner <b>220</b> may comprise a rotary plate on top of which the object is positioned, and the rotary plate may be operatively coupled to the orientation tuner <b>220</b>. The lighting component <b>218</b> may be coupled to the perspective guide <b>204</b> and the background display unit <b>224</b> may be positioned behind the object. The assembly of the above-mentioned components are illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, <figref idref="DRAWINGS">FIG. <b>2</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>.</p><p id="p-0055" num="0054">The processor <b>102</b> may be configured to actuate either or combination of, the pair of guiding apparatus (the proximity guide <b>202</b> and the perspective guide <b>204</b>) and the perspective tuner <b>206</b>, through the microcontroller <b>128</b> to cause change in position of the image capturing device <b>208</b> relative to the object positioned on the rotary plate. The change in position of the image capturing device <b>208</b> may be because of actuation of at least one or combination of a proximity guide <b>202</b>, perspective guide <b>204</b>, and a perspective tuner <b>206</b>, wherein the actuation is caused by sending one or more instructions from the processor <b>102</b> through the microcontroller <b>128</b> to the components mentioned above.</p><p id="p-0056" num="0055">In one or more embodiments, the &#x2018;change in position&#x2019; may indicate the movement of the bearing block of the proximity guide <b>202</b> from one position to another position along the axis of railings of the proximity guide <b>202</b> which causes the movement of the perspective guide <b>204</b> as the perspective guide <b>204</b> is mounted on the proximity guide <b>202</b>. In one or more embodiments, the &#x2018;change in position&#x2019; may also indicate the movement of bearing block of the of perspective guide <b>204</b> from one position to another position along the axis of railing of the perspective guide <b>204</b> which causes the movement of the perspective tuner <b>206</b> along with the image capturing device <b>208</b> since the perspective tuner <b>206</b> along with the image capturing device <b>208</b> are mounted to the bearing block of the perspective guide <b>204</b>. In one or more embodiments, the &#x2018;change in position&#x2019; may also indicate movement of image capturing device <b>208</b> in terms of angular rotation as the image capturing device <b>208</b> operatively coupled to the perspective tuner <b>206</b>. The combination of above-mentioned &#x2018;change in position&#x2019; may collectively result in change in position of the image capturing device <b>208</b> relative to the object positioned on the rotary plate.</p><p id="p-0057" num="0056">In one or more embodiments, the processor <b>102</b> may be configured to actuate the orientation tuner <b>220</b> through the microcontroller <b>128</b> causing change in angle of orientation of the object positioned on the rotary plate. After the actuation, the processor <b>102</b> may be configured to send one or more instructions to the image capturing device <b>208</b> to capture plurality of images of the object positioned on the rotary plate. The one or more images are captured by the image capturing device <b>208</b> for plurality of combinations of angle of orientation of object, and the position and/or the angle of orientation of the image capturing device <b>208</b>. The orientation tuner <b>220</b> is positioned at a predetermined distance from a position of the pair of guiding apparatus <b>202</b>,<b>204</b>.</p><p id="p-0058" num="0057">The object positioning system <b>226</b> may comprise the guiding apparatus &#x2018;y&#x2019; axis <b>210</b> (also referred as the occlusion guide <b>210</b>) comprises occlusion object and may be actuated through the microcontroller <b>128</b> which causes the movement of the occlusion object positioned on the bearing block of the occlusion guide <b>210</b> along the railings of the occlusion guide <b>210</b>. The occlusion guide <b>210</b> may be positioned between the rotary plate and the pair of guiding apparatus <b>202</b>,<b>204</b>. The processor <b>102</b> may be configured to display at least one background image through a background display unit <b>224</b> (also referred as &#x2018;display device&#x2019;) which may be positioned in front of the image capturing device <b>208</b> and behind the object position system <b>226</b> or the object. The above mentioned components are controlled by the processor <b>102</b> centrally through the microcontroller <b>128</b> to capture one or more images of the object positioned on the rotary plate with plurality of combinations of position of the image capturing device <b>208</b>, angle of orientation of the object, position of the occlusion object and the background image displayed on the background display unit <b>224</b> positioned behind the object.</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a process flow diagram illustrating a computer implemented method for automated image capturing, according to one or more embodiments. A user input may be received at a central computing system to initiate the process of capturing images using automated image capturing apparatus, as in step <b>302</b>. After receiving input from the user, the central computing system comprising at least one processor may send one or more instructions to a micro controller causing the micro controller to position the object and actuate components of the image capturing apparatus.</p><p id="p-0060" num="0059">In one or more embodiments, the microcontroller may be configured to actuate guiding apparatus as, in step <b>304</b>. The guiding apparatus may comprise proximity guide, perspective guide and an occlusion guide. The proximity guide may be a linear guide that is horizontally positioned, as described in various embodiments of the present disclosure. The perspective guide may be a linear guide that is vertically positioned on top of the proximity guide at a predetermined angle. The occlusion guide may be a linear guide or a circular guide that is positioned between the proximity guide and a rotary plate (may also be visualized as between the object and the image capturing device using). The occlusion guide may comprise occlusion object as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>.</p><p id="p-0061" num="0060">In one or more embodiments, the microcontroller may be configured to actuate electric rotary actuators, as in step <b>306</b>. The electric rotary actuators may comprise a perspective tuner and an orientation tuner. The perspective tuner which is coupled to the perspective guide may be a servo motor operatively coupled to an image capturing device, with a range of angle of orientation/rotation of image capturing device with respect to horizontal plane, represented as A<sub>PT</sub>. The valid range of angles may be between 0 degree to 360 degrees, but in practical, the suitable range may be between 30 degrees and 120 degrees. The orientation tuner may be a servo motor with a range of angles represented as A<sub>OT</sub>, operatively coupled to a rotary plate on top of which the object may be placed. The microcontroller may instruct orientation tuner to rotate, further causing rotation of the rotary plate operatively coupled to the orientation tuner. The rotation of the rotary plate may cause change in angle of orientation of the object placed on top of the rotary plate at an angle of orientation A<sub>OT</sub>. The microcontroller may actuate the guiding apparatus (proximity guide and perspective guide) and an electric rotary actuator (perspective tuner) associated with image capturing device causing change in position/orientation of the image capturing device to point at the object.</p><p id="p-0062" num="0061">The combination of step <b>304</b> and <b>306</b> may cause the positioning of the object placed on the rotary plate of the orientation tuner at an angle A<sub>OT</sub>, positioning of perspective guide mounted on a proximity guide at a position/step S<sub>PR</sub>, positioning of the perspective tuner coupled to the perspective guide at a position S<sub>PE</sub>, positioning of the image capturing device at an angle A<sub>PT</sub>. Linear guides are actuated using a stepper motor attached to it. Values of target positions may be provided as input to the microcontroller wherein the timing signals that is to be sent to the driver may be determined automatically by the microcontroller of the stepper motor which in turn sends the voltage required for the stepper motor to achieve the required number of rotations. The rotations of the stepper motor are translated as linear movement on the linear guide.</p><p id="p-0063" num="0062">In an example embodiment, consider the linear guides have a slide range of 10 inches. The proximity guide may have a slide range between 0 inches (nearest to the target object) and 10 inches (farthest from the target object). The perspective guide may have a slide range between 0 inches (nearest to the floor or nearest to the proximity guide) and 10 inches (farthest from the floor or farthest from the proximity guide). The occlusion guide may have a slide range between 0 inches (towards far left from the view-point of image capturing device as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>) and 10 inches (towards to the far right from the view-point of image capturing device as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>). The perspective tuner may range between 0 degrees (where the camera would be pointing towards the foot of the perspective guide or the bearing block of the proximity guide) and 180 degrees (where the camera would be pointing towards the head of the perspective guide or the stepper motor of the perspective guide). The orientation tuner can rotate 360 degrees. The diameter of rotary plate operatively coupled to the orientation tuner should be chosen based on the degree of intended occlusion. A background image may be displayed using a display device that is positioned behind the object, as in step <b>308</b>. One or lighting condition of various luminosity may be created by the at least one processor to emulate different environment conditions, as in step <b>310</b>. Then the processor may be configured to send one or more instructions to image capturing device to capture plurality of images of the object for various positions of components mentioned in above paragraphs, as in step <b>312</b>. In an example embodiment, to capture a batch of images of a single object, the following configuration may be used. The step value for the proximity guide may be set to intervals of 1 inches and with starting position as 0 inches, subsequent positions become as 1 inches, 2 inches, 3 inches, 4 inches, 5 inches, 6 inches, 7 inches, 8 inches, 9 inches and 10 inches which results in 11 steps or 11 different positions (S<sub>PR</sub>) of the bearing block of the proximity guide. The step value for the perspective guide may be set to intervals of 2 inches and with the starting position as 1 inches, subsequent positions become as 3 inches, 5 inches, 7 inches and 9 inches which results in 5 steps or 5 different positions (S<sub>PE</sub>) of the bearing block of the perspective guide. The step value for the occlusion guide may be set to intervals of 2 inches and with the starting position as 0 inches, subsequent positions become 2 inches, 4 inches, 6 inches, 8 inches and 10 inches which results in 6 steps or 6 different positions (S<sub>OC</sub>) of the bearing block of the occlusion guide. The step value for the orientation tuner may be set to intervals of 5 degrees and with the starting position as 0 degrees, the resultant would be 72 steps or 72 different angular positions (A<sub>OT</sub>) of the orientation tuner. The lighting condition through the lighting component may be set to vary with different light intensities such as 500 lumens, 700 lumens, 1100 lumens and 1300 lumens resulting in 5 step values. At least 10 background images may be fetched from the database to be displayed at the display device which results in 10 step values. For each of the above-mentioned configurations plurality of images may be captured by the image capturing device. For example, one of the above-mentioned step values is fixed and rest of the step values are modified to capture images. Other way round, at least one value is varied by keeping all other step values fixed. In the present example embodiment, considering one image is captured for each of the varying step values, the resultant number of images would be equal to multiplication of all the step values.</p><p id="p-0064" num="0063">It is to be noted that the angle A<sub>PT </sub>of image capturing device i.e. the perspective tuner needs to be corrected for every movement of the bearing block of the perspective guide or any changes in the step values mentioned above, so that the object remains within the focus and field of view of the image capturing device all the time for all the varying step values. For each change in step value S<sub>PR </sub>of the proximity guide and step value S<sub>PE </sub>of the perspective guide, the value of A<sub>PT </sub>needs to be determined and the perspective tuner needs to be actuated accordingly. The method of determination is illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> and <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>. Let L<sub>PR </sub>be the distance between position of the bearing block of the of proximity guide and the end point of the proximity guide (the end point near the object), which also represents the length of range of motion of the bearing block of the proximity guide. Let L<sub>PE </sub>be the distance between position of the image capturing device and end point of the perspective guide which is mounted on the bearing block of the proximity guide, which also represents the length of range of motion of the perspective guide. The length range of motion of bearing block of occlusion guide be L<sub>OG </sub>and the distance between the proximity guide and outer edge of the rotary plate be L<sub>GAP </sub>as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. It is to be observed that the diameter of the rotary plate represented as L<sub>R </sub>is same as L<sub>OG </sub>and is positioned in such a way that the radius of the rotary plate is considered for calculation and object to be placed at the center of the rotary plate. As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>, the values are calculated as below:</p><p id="p-0065" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>p=h sin &#x3b8;<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0066" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>b=h cos&#x3b8;<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0067" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x3c9;=90&#x2212;&#x3b8;<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0068" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <mi>d</mi>  <mo>=</mo>  <mrow>   <msub>    <mi>L</mi>    <mi>PR</mi>   </msub>   <mo>+</mo>   <msub>    <mi>L</mi>    <mi>GAP</mi>   </msub>   <mo>+</mo>   <mrow>    <mfrac>     <mn>1</mn>     <mn>2</mn>    </mfrac>    <mo>&#x2062;</mo>    <msub>     <mi>L</mi>     <mi>R</mi>    </msub>   </mrow>   <mo>-</mo>   <mi>b</mi>  </mrow> </mrow></math></maths><maths id="MATH-US-00001-2" num="00001.2"><math overflow="scroll"> <mrow>  <mi>&#x3d5;</mi>  <mo>=</mo>  <mrow>   <msup>    <mi>tan</mi>    <mrow>     <mo>-</mo>     <mn>1</mn>    </mrow>   </msup>   <mo>&#x2062;</mo>   <mfrac>    <mi>d</mi>    <mi>p</mi>   </mfrac>  </mrow> </mrow></math></maths><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>A</i><sub>PT</sub>=&#x3c9;+&#x3d5;<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0069" num="0000">wherein,<br/>h is the value of L<sub>PE</sub>;<br/>p is the vertical distance between image capturing device and axis of the proximity guide;<br/>b is the distance between one end of the proximity guide and intersection point of p with the axis of the proximity guide, as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>;<br/>&#x3c9; is the angle made by the image capturing device with respect to p and h;<br/>d is the distance between the intersecting point of p with the axis of the proximity guide and the center of the rotary plate;<br/>&#x3b8; is the angle at which the perspective guide is mounted on the proximity guide; and<br/>&#x3d5; is the angle between p and the line representing distance between image capturing device and the center of the rotary plate, which is the focal length of the image capturing device; and<br/>A<sub>PT </sub>is the angle at which the image capturing device to be rotated using perspective tuner.</p><p id="p-0070" num="0064">Whenever the other step values are changed, the value of A<sub>PT </sub>is determined and the image capturing device is tuned to angle A<sub>PT </sub>so that image capturing device points at the object every time. After adjusting the image capturing device through the microcontroller, the processor may send one or more instructions to the image capturing device to capture plurality of images of the object, as in step <b>312</b> for plurality of combinations of angle of orientation of the object and position of the image capturing device.</p><p id="p-0071" num="0065">In an example embodiment, consider the below values: L<sub>PE</sub>=h=2.0; L<sub>PR</sub>=2.5; L<sub>GAP</sub>=1; L<sub>OG</sub>=2.5; &#x3b8;=60 degrees which is 1.0472 radians, then:</p><p id="p-0072" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>p=2.0 sin 1.0472=1.7321<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0073" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>b=2.0 cos 1.0472=1.0<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0074" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x3c9;=1.5708&#x2212;1.0472=0.5236<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0075" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mrow>  <mi>d</mi>  <mo>=</mo>  <mrow>   <mrow>    <msub>     <mi>L</mi>     <mi>PR</mi>    </msub>    <mo>+</mo>    <msub>     <mi>L</mi>     <mi>GAP</mi>    </msub>    <mo>+</mo>    <mrow>     <mfrac>      <mn>1</mn>      <mn>2</mn>     </mfrac>     <mo>&#x2062;</mo>     <msub>      <mi>L</mi>      <mi>R</mi>     </msub>    </mrow>    <mo>-</mo>    <mi>b</mi>   </mrow>   <mo>=</mo>   <mn>3.75</mn>  </mrow> </mrow></math></maths><maths id="MATH-US-00002-2" num="00002.2"><math overflow="scroll"> <mrow>  <mi>&#x3d5;</mi>  <mo>=</mo>  <mrow>   <mrow>    <msup>     <mi>tan</mi>     <mrow>      <mo>-</mo>      <mn>1</mn>     </mrow>    </msup>    <mo>&#x2062;</mo>    <mfrac>     <mi>d</mi>     <mi>p</mi>    </mfrac>   </mrow>   <mo>=</mo>   <mn>1.1381</mn>  </mrow> </mrow></math></maths><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>A</i><sub>PT</sub>&#x3c9;+&#x3d5;=1.6617<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0076" num="0066">The determined value of A<sub>PT </sub>will be in radians and when converted to degrees, the value of A<sub>PT </sub>will be 95.2087 degrees. The value of A<sub>PT </sub>may be provided as input to the microcontroller wherein the timing signals that is to be sent to the driver may be determined automatically which in turn sends the voltage required for the perspective tuner to achieve the required number of rotations achieve 95.2087 degrees angle for the image capturing device.</p><p id="p-0077" num="0067">In another example embodiment, consider the perspective guide is actuated and is bearing block of the perspective guide is made to move to another position, say L<sub>PE=h=</sub>2.5; and the rest of the values remains same, say L<sub>PR</sub>=2.5; L<sub>GAP</sub>=1; L<sub>OG</sub>=2.5; &#x3b8;=60 degrees which is 1.0472 radians, then:</p><p id="p-0078" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>p=2.5 sin 1.0472=2.1651<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0079" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>b=2.5 cos 1.0472=1.2500<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0080" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x3c9;=1.5708&#x2212;1.0472=0.5236<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0081" num="0000"><maths id="MATH-US-00003" num="00003"><math overflow="scroll"> <mrow>  <mi>d</mi>  <mo>=</mo>  <mrow>   <mrow>    <msub>     <mi>L</mi>     <mi>PR</mi>    </msub>    <mo>+</mo>    <msub>     <mi>L</mi>     <mi>GAP</mi>    </msub>    <mo>+</mo>    <mrow>     <mfrac>      <mn>1</mn>      <mn>2</mn>     </mfrac>     <mo>&#x2062;</mo>     <msub>      <mi>L</mi>      <mi>R</mi>     </msub>    </mrow>    <mo>-</mo>    <mi>b</mi>   </mrow>   <mo>=</mo>   <mn>3.5</mn>  </mrow> </mrow></math></maths><maths id="MATH-US-00003-2" num="00003.2"><math overflow="scroll"> <mrow>  <mi>&#x3d5;</mi>  <mo>=</mo>  <mrow>   <mrow>    <msup>     <mi>tan</mi>     <mrow>      <mo>-</mo>      <mn>1</mn>     </mrow>    </msup>    <mo>&#x2062;</mo>    <mfrac>     <mi>d</mi>     <mi>p</mi>    </mfrac>   </mrow>   <mo>=</mo>   <mn>1.0168</mn>  </mrow> </mrow></math></maths><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>A</i><sub>PT</sub>=&#x3c9;+&#x3d5;=1.5404<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0082" num="0068">The determined value of A<sub>PT </sub>will be in radians and when converted to degrees, the value of A<sub>PT </sub>will be 88.2595 degrees. The value of A<sub>PT </sub>may be provided as input to the microcontroller wherein the timing signals that is to be sent to the driver may be determined automatically which in turn sends the voltage required for the perspective tuner to achieve the required number of rotations achieve 88.2595 degrees angle for the image capturing device. It is to be observed that increase in value of h has resulted in reduction in angle which makes the image capturing device to point the object without losing the view. The captured images along with the metadata information such as Exchangeable Image file Format (EXIF) data of the captures images may be stored in database as in step <b>314</b>, which may further be used to train machine learning models such as, but not limited to image recognition models, object detection models. The captured images may be used train systems like assisted assorting of items, robot assisted shopping etc. The captures images can be used to train systems which recognizes items that customer has picked and adding to digital cart automatically.</p><p id="p-0083" num="0069">In an example embodiment, the object (product) of the interest may be soft drink can, and obstacle image may be a milk tetra pack. The background image may be a sample image which illustrated assorted products in a brick-and-mortar retail store The plurality of images are may be captured as described in various embodiments of the present disclosure and may be used to train object detection model which can be used in adding products to cart of user automatically when they pick the product/item from shelves such as robot assisted shopping in retail stores</p><p id="p-0084" num="0070">The apparatus and/system disclosed herein will reduce the time and effort spent in data generation and collection phase as the variations in lighting conditions, orientations and occlusions are automatically handled. The fully automated robotic process as described in the present technology can generate significantly large volumes of image data as compared their human counterparts and increases training efficiency as large number of appropriate images will be available in short time.</p><p id="p-0085" num="0071">The specification and drawings in the present disclosure are to be regarded in an illustrative rather than a restrictive sense.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001 MATH-US-00001-2" nb-file="US20230004073A1-20230105-M00001.NB"><img id="EMI-M00001" he="12.70mm" wi="76.20mm" file="US20230004073A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002 MATH-US-00002-2" nb-file="US20230004073A1-20230105-M00002.NB"><img id="EMI-M00002" he="12.70mm" wi="76.20mm" file="US20230004073A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00003 MATH-US-00003-2" nb-file="US20230004073A1-20230105-M00003.NB"><img id="EMI-M00003" he="12.70mm" wi="76.20mm" file="US20230004073A1-20230105-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system for automated image capture, comprising:<claim-text>a microcontroller;</claim-text><claim-text>a pair of guiding apparatus;</claim-text><claim-text>an image capturing device operatively coupled to the pair of guiding apparatus using a first electric rotary actuator;</claim-text><claim-text>a rotary plate operatively mounted on a second electric rotary actuator;</claim-text><claim-text>at least one processor; and</claim-text><claim-text>at least one memory unit operatively coupled to the at least one processor, having instructions stored thereon that, when executed by the at least one processor, causes the at least one processor to:<claim-text>actuate, the pair of guiding apparatus or the first electric rotary actuator to cause change in position of the image capturing device relative to an object positioned on the rotary plate; and</claim-text><claim-text>capture, one or more images of the object positioned on the rotary plate.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of clam <b>1</b>, when instructions executed by the at least one processor, further causes the at least one processor to:<claim-text>actuate, the second electric rotary actuator, causing change in angle of orientation of the object positioned on the rotary plate.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>another guiding apparatus, positioned between the rotary plate and the pair of guiding apparatus, comprising an occlusion object.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one processor is further configured to display at least one background image through a display device.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second electric rotary actuator is positioned at a predetermined distance from a position of the pair of guiding apparatus.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more images are captured by the image capturing device for plurality of combinations of angle of orientation of object and position of the image capturing device. <b>7</b> An apparatus for automated image capture, comprising:<claim-text>a microcontroller;</claim-text><claim-text>a first guiding apparatus;</claim-text><claim-text>a second guiding apparatus operatively coupled to the first guiding apparatus, wherein the second guiding apparatus is mounted at an angle on the first guiding apparatus;</claim-text><claim-text>an image capturing device operatively coupled to the second guiding apparatus using a first electric rotary actuator;</claim-text><claim-text>a rotary plate operatively mounted on a second electric rotary actuator positioned at a predetermined distance from the first guiding apparatus; and</claim-text><claim-text>at least one processor configured to capture one or more images of an object positioned on the rotary plate by sending one or more instructions to the microcontroller.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The apparatus of claim <b>7</b>, further comprising:<claim-text>a third guiding apparatus comprising an occlusion object is positioned between the first guiding apparatus and the second electric rotary actuator.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The apparatus of claim <b>7</b>, wherein, sending one or more instructions to the microcontroller causes the microcontroller to actuate at least one of the first guiding apparatus, the second guiding apparatus, the third guiding apparatus, the first electric rotary actuator or the second electric rotary actuator.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A computer implemented method for automated image capture, comprising:<claim-text>communicating, by a processor, one or more instructions to a microcontroller causing the microcontroller to perform steps comprising:</claim-text><claim-text>positioning, through the microcontroller, an object at an angle of orientation by actuating an electric rotary actuator associated with a rotary plate; and</claim-text><claim-text>actuating, through the microcontroller, a pair of guiding apparatus and an electric rotary actuator associated with image capturing device to position the image capturing device to point at the object; and</claim-text><claim-text>instructing, by the processor, the image capturing device to capture one or more images of the object.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The computer implemented method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising:<claim-text>positioning, through the microcontroller, an occlusion object between the object and the image capturing device using a guiding apparatus.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The computer implemented method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the one or more images are captured for plurality of combinations of angle of orientation of the object and position of the image capturing device.</claim-text></claim></claims></us-patent-application>
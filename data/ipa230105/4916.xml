<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004917A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004917</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17842477</doc-number><date>20220616</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>D</subclass><main-group>9</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>06398</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>D</subclass><main-group>9</main-group><subgroup>005</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>04847</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">Performance Management System and Method</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63217994</doc-number><date>20210702</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only"><addressbook><orgname>Rippleworx, Inc.</orgname><address><city>Huntsville</city><state>AL</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Sandritter</last-name><first-name>Timo</first-name><address><city>Huntsville</city><state>AL</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Hadley</last-name><first-name>Brian</first-name><address><city>Madison</city><state>AL</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Sandritter</last-name><first-name>Angela Michelle</first-name><address><city>Huntsville</city><state>AL</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>DeVine</last-name><first-name>Jason P.</first-name><address><city>Alpharetta</city><state>GA</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Bolan</last-name><first-name>Amanda</first-name><address><city>Frisco</city><state>CO</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Rippleworx, Inc.</orgname><role>02</role><address><city>Huntsville</city><state>AL</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Systems and methods identify and trigger actions to improve performance in a role in an organization. A server computer receives input data associated with a performance of a target entity in a role in an organization from a remote device. The server computer also receives, via input to a Graphical User Interface (GUI), a set of weights for a respective set of skills for the role. The server computer computes a metric based on the input data and the weights, the metric representing the performance in the role for the target entity. The server computer identifies an action likely to improve the metric and triggers the action.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="111.59mm" wi="158.75mm" file="US20230004917A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="199.73mm" wi="152.65mm" orientation="landscape" file="US20230004917A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="217.76mm" wi="147.83mm" file="US20230004917A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="241.13mm" wi="135.13mm" orientation="landscape" file="US20230004917A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="236.39mm" wi="113.96mm" orientation="landscape" file="US20230004917A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="233.93mm" wi="141.90mm" orientation="landscape" file="US20230004917A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="240.20mm" wi="139.36mm" orientation="landscape" file="US20230004917A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="198.63mm" wi="143.17mm" file="US20230004917A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="224.54mm" wi="147.91mm" orientation="landscape" file="US20230004917A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="224.54mm" wi="147.24mm" orientation="landscape" file="US20230004917A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="224.45mm" wi="147.15mm" orientation="landscape" file="US20230004917A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="227.75mm" wi="87.04mm" orientation="landscape" file="US20230004917A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="233.34mm" wi="154.26mm" orientation="landscape" file="US20230004917A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="237.24mm" wi="105.83mm" orientation="landscape" file="US20230004917A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="223.86mm" wi="143.76mm" orientation="landscape" file="US20230004917A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="237.24mm" wi="139.78mm" orientation="landscape" file="US20230004917A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="239.01mm" wi="156.97mm" orientation="landscape" file="US20230004917A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="212.68mm" wi="159.00mm" orientation="landscape" file="US20230004917A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="197.53mm" wi="158.16mm" orientation="landscape" file="US20230004917A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="235.80mm" wi="156.13mm" orientation="landscape" file="US20230004917A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCES TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims the benefit of priority under 35 U.S.C. &#xa7; 119 from U.S. Provisional Application No. 63/217,994, filed on Jul. 2, 2021, the disclosure of which is hereby incorporated by reference in its entirety for all purposes.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">It is increasingly popular to gather and analyze data associated with individuals. For example, devices that monitor physical states like steps taken and heart rate are widely used. Wearable devices may gather biometric information and perform simple computations based on the gathered biometric information. For example, wearable devices may compute an average number of steps taken per day, or convert a pulse rate to a heart rate. Other types of data that can be analyzed in connection with an individual include Web data, test results, and other performance data. With the proliferation of data collected about individuals, it becomes increasingly challenging to discern meaning from large amounts of data of disparate types.</p><heading id="h-0003" level="1">BRIEF SUMMARY</heading><p id="p-0004" num="0003">Systems and methods are described for triggering an action to improve performance in a role in an organization based on data gathered from one or more remote devices. A set of Graphical User Interfaces (GUIs) are provided to show dashboards and recommendations to improve the performance of the organization as a whole as well as individuals in the organization. GUIs can further be provided to accept user input to customize how performance is assessed, e.g., via user-configured weights, skills of interest in a particular role, and data sources used to assess the performance.</p><p id="p-0005" num="0004">In some embodiments, a computer-implemented method comprises receiving, by a server computer from a remote device, input data associated with a performance of a target entity in a role in an organization; receiving, by the server computer via input to a Graphical User Interface (GUI), a set of weights for a respective set of skills for the role; computing, by the server computer, a metric based on the input data and the weights, the metric representing the performance in the role for the target entity; identifying, by the server computer, an action likely to improve the metric; and triggering, by the server computer, the action.</p><p id="p-0006" num="0005">In some aspects, triggering the action comprises one or more of: modifying an entry on a calendar for the target entity to include an identified task to improve the performance; transmitting an electronic mail (email) message including the metric and at least a subset of the input data or a derivative thereof; displaying a second GUI including the metric and at least a subset of the input data or a derivative thereof; or transmitting a suggestion thereby causing the target entity to perform the action.</p><p id="p-0007" num="0006">In some aspects, the input data includes one or more of: biometric data received from a wearable device that collected the biometric data from the target entity; performance data received from a computing device that analyzed performance of the target entity; or survey or test data received from a user device that received responses from the target entity. In some aspects, the biometric data comprises one or more of heartrate data or blood oxygenation data.</p><p id="p-0008" num="0007">In some aspects, the method further comprises displaying the GUI, the GUI comprising one or more interactive elements for modifying the weights; receiving, via the one or more interactive elements, user input modifying the weights; and updating the weights based upon the user input.</p><p id="p-0009" num="0008">In some aspects, computing the metric comprises identifying, by the server computer, a first skill value for a first skill for a second entity; incrementing, by the server computer, the first skill value according to a predetermined margin to generate a first baseline value; identifying, by the server computer, a second skill value for the first skill for the target entity; and computing, by the server computer, a percentage of the first baseline value for the second skill value. In some aspects, computing the metric further comprises identifying, by the server computer, a third skill value for a second skill for a third entity; incrementing, by the server computer, the third skill value according to the predetermined margin to generate a second baseline value; identifying, by the server computer, a fourth skill value for the second skill for the target entity; computing, by the server computer, a percentage of the second baseline value for the fourth skill value; and computing, by the server computer, the metric based on the percentage of the first baseline value and the percentage of the second baseline value.</p><p id="p-0010" num="0009">In some aspects, the method further comprises displaying, via a third GUI, performance metrics for a plurality of entities including the target entity and an attribute for each entity of the plurality of entities, thereby causing a modification of the attribute for at least a subset of the plurality of entities. In some aspects, the method further comprises displaying, via a fourth GUI, an interactive element for configuring a source of the input data; and receiving, via the fourth GUI, user input configuring the source of the input data, wherein the input data is retrieved and stored by the server computer based on the configured source. In some aspects, at least a subset of the input data is retrieved from a he a Global Positioning System (GPS).</p><p id="p-0011" num="0010">In some embodiments, a computing system comprises a processor; and a non-transitory computer readable medium operatively coupled to the processor, the non-transitory computer readable medium comprising code executable by the processor for performing any of the above methods.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0012" num="0011">Illustrative aspects of the present disclosure are described in detail below with reference to the following drawing figures. It is intended that that embodiments and figures disclosed herein are to be considered illustrative rather than restrictive.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a schematic diagram of a system and method for analyzing and improving a performance metric for an entity according to some embodiments.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a block diagram of the server computer of <figref idref="DRAWINGS">FIG. <b>1</b></figref> according to some embodiments.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example of performance data.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example overview configuration process according to some embodiments.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>5</b>A</figref> illustrates an example user interface for receiving configuration data according to some embodiments.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>5</b>B</figref> illustrates another example user interface for receiving configuration data according to some embodiments.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates another example user interface for receiving configuration data according to some embodiments.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates another example user interface for receiving configuration data according to some embodiments.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates another example user interface for receiving configuration data according to some embodiments.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates another example user interface for receiving configuration data according to some embodiments.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates another example user interface for receiving configuration data according to some embodiments.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates an example user interface illustrating configured weights and skills, according to some embodiments.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates an overview process for evaluating and improving performance in a role according to some embodiments.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates an example user interface illustrating data ingestion according to some embodiments.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates another example user interface illustrating data ingestion according to some embodiments.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates an example user interface illustrating output information according to some embodiments.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>16</b>A</figref> illustrates another example user interface illustrating output information according to some embodiments.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>16</b>B</figref> illustrates another example user interface illustrating output information according to some embodiments.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>16</b>C</figref> illustrates another example user interface illustrating output information according to some embodiments.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>17</b></figref> illustrates another example user interface illustrating output information according to some embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0033" num="0032">Systems and methods are described for identifying and triggering actions for improving performance in a role in an organization based on data characterizing one or more entities in the role. For example, they system may analyze performance data for players on a sports team, in roles such as linebacker and quarterback, or analyze performance data for members of a police force, in roles such as patrol officer and detective. Data associated with one or more entities (e.g., individuals or groups in the organization) is retrieved. Biometric data may be gathered from a wearable device. User feedback may also be gathered from a user interface of a user device. The system may analyze multiple types of data from multiple remote sources to compute a metric indicating a performance level in a role in the organization. This metric is computed using user-configured weights, roles, skills and/or data sources. The system triggers an action according to the computed metric, which may include transmitting advised activities, turning on or off hardware devices, and displaying a user interface with suggested actions.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a schematic diagram <b>100</b> of a computing system and method for improving performance in a role based on data characterizing one or more entities in the role according to some embodiments. The computing system may include a target entity <b>102</b>, a wearable device <b>103</b>, a first user device <b>104</b>, a server computer <b>106</b>, and a second user device <b>108</b>. For simplicity of illustration, a limited number of components are shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. It is understood, however, that embodiments may include more than one of each component.</p><p id="p-0035" num="0034">The components in the computing system depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref> can be in operative communication with each other through any suitable communication channel or communications network. Suitable communications networks may be any one and/or the combination of the following: a direct interconnection; the Internet; a Local Area Network (LAN); a Metropolitan Area Network (MAN); an Operating Missions as Nodes on the Internet (OMNI); a secured custom connection; a Wide Area Network (WAN); a wireless network (e.g., employing protocols such as, but not limited to a Wireless Application Protocol (WAP), I-mode, and/or the like); and/or the like. Messages between the computers, networks, and devices may be transmitted using a secure communications protocols such as, but not limited to, File Transfer Protocol (FTP); HyperText Transfer Protocol (HTTP); Secure Hypertext Transfer Protocol (HTTPS), Secure Socket Layer (SSL), and/or the like.</p><p id="p-0036" num="0035">The server computer <b>106</b> retrieves data associated with a target entity <b>102</b> from one or more remote devices including the wearable device <b>103</b>, the first user device <b>104</b>, and the second user device <b>108</b>. The target entity <b>102</b> can be an individual (e.g., a person, such as a member of an organization such as a sports team, company or division thereof, military organization, etc.). Alternatively, a target entity <b>102</b> may be a group of individuals, such as a division of an organization. For example, the target entity <b>102</b> can be a group of people such as the defensive players on a soccer team, the cashiers at a grocery store, etc.</p><p id="p-0037" num="0036">The wearable device <b>103</b> may be a device wearable by a user (e.g., target entity <b>102</b>) and capable of obtaining data about the target entity <b>102</b>. The wearable device <b>103</b> may, for example, be a vest, watch, ring, hat, or the like. The wearable device <b>103</b> may include hardware for detecting the data about the target entity <b>102</b> such as a heart rate monitor, an oximetry sensor, a blood pressure detector, a Global Positioning System (GPS), and so forth. The data about the target entity <b>102</b> may include biometric information such as heartrate information, pulse information blood oxygen levels, and blood salinization levels. The data about the target entity <b>102</b> may include location information (e.g., as determined via GPS).</p><p id="p-0038" num="0037">The first user device <b>104</b> may be a device operable by a user (e.g., target entity <b>102</b>) and capable of executing applications. As examples, the first user device <b>104</b> may be a smartphone, a computer, a tablet, or the like. The first user device <b>104</b> may also include hardware and/or software configured to store data. The first user device <b>104</b> may also include hardware and/or software configured to receive data from the wearable device <b>103</b>. The first user device <b>104</b> may include hardware and/or software configured to transmit data to the server computer <b>106</b>. The first user device <b>104</b> may also be connected to the server computer <b>106</b> via a communication network. The first user device <b>104</b> may also include hardware and/or software capable of receiving user input. The first user device <b>104</b> may include a keyboard, touchscreen, microphone, and/or the like for receiving data from a user. The first user device <b>104</b> may also receive information about the target entity <b>102</b>, via direct user input (e.g., the user inputs an answer to a question via a user interface displayed by the first user device <b>104</b>) and/or by way of the wearable device <b>103</b> (e.g., via a wireless connection and a coupled application). In some implementations, the first user device <b>104</b> includes a GPS and/or biometric sensors as described above with respect to the wearable device <b>103</b>.</p><p id="p-0039" num="0038">The server computer <b>106</b> may include functionality to receive and analyze data received from the first user device <b>104</b> and/or the wearable device <b>103</b>. The server computer <b>106</b> may include a processor coupled to a memory, a network interface, and a computer-readable medium, as described in further detail below with respect to <figref idref="DRAWINGS">FIG. <b>2</b></figref>. In some embodiments, the server computer <b>106</b> is configured to gather data from the first user device <b>104</b> and/or wearable device <b>103</b>, and analyze this data to evaluate performance and identify and trigger actions.</p><p id="p-0040" num="0039">The second user device <b>108</b> may be a device operable by a user and capable of executing applications. In some embodiments, the user operating the second user device is different than the target entity <b>102</b> operating the first user device <b>104</b>. For example, the second user device <b>108</b> may be operated by someone in a supervisory role with respect to the user of the first user device <b>104</b>. As a specific example, target entity <b>102</b> may be an athlete, and the second user device <b>108</b> may be operated by a coach that supervises target entity <b>102</b> along with other athletes on a team. As another example, target entity <b>102</b> may be a pilot or soldier and the second user device <b>108</b> may be operated by a commander that supervises target entity <b>102</b> along with other pilots or soldiers in a division. The second user device <b>108</b> may otherwise be substantially similar to the first user device <b>104</b>.</p><p id="p-0041" num="0040">At step <b>1</b>, the server computer <b>106</b> receives configuration data from the second user device <b>108</b>. The configuration data can be used to establish what data to collect, and how to use and weight the data in making a performance assessment, as described herein. The configuration data can be configured by a user (e.g., an administrator, such as a coach, supervisor, doctor, etc.) via user interfaces such as those depicted in <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>10</b> and <b>13</b>-<b>14</b></figref>.</p><p id="p-0042" num="0041">At step <b>2</b>, the wearable device <b>103</b> collects data related to target entity <b>102</b>. For example, the wearable device <b>103</b> may detect a pulse of the target entity <b>102</b>, which may be converted to heartrate information. As another example, the wearable device <b>103</b> may detect blood oxygenation and/or blood salinity levels of target entity <b>102</b>. As another example, the wearable device <b>103</b> may detect location information associated with the target entity <b>102</b> (e.g., the GPS coordinates of the target entity <b>102</b> at one or more times). In some aspects, the wearable device <b>103</b> records a timestamp with each element of data, e.g., a set of coordinates with respective timestamps at which the coordinates were retrieved.</p><p id="p-0043" num="0042">In some embodiments, at step <b>3</b>, the wearable device <b>103</b> transmits the user data to the first user device <b>104</b>. The first user device <b>104</b> may, in turn, transmit the user data to the server computer <b>106</b> at step <b>5</b>. Alternatively, or additionally, the wearable device <b>103</b> may transmit the user data directly to the server computer <b>106</b>. The wearable device <b>103</b> and/or the first user device <b>104</b> may analyze the data. For example, the wearable device <b>103</b> may compute a heart rate based on a detected pulse. As another example, the first user device <b>104</b> may compute a distance traveled and/or speed based on a set of GPS coordinates collected over time. In some embodiments, aggregate statistics, such as an average, minimum, maximum, event count, etc., are computed from time series data on-board the wearable device or the first user device.</p><p id="p-0044" num="0043">At step <b>4</b>, the target entity <b>102</b> may input data to the first user device <b>104</b>. The target entity <b>102</b> may interact with the first user device <b>104</b> via one or more Graphical User Interfaces (GUIs). The target entity <b>102</b> may input subjective perceptions of the physical or mental state of the target entity <b>102</b>. As an example, the target entity <b>102</b> takes a quiz or survey and enters various answers via a GUI, which are then stored to the first user device <b>104</b>. As another example, the target entity <b>102</b> may input information about how well rested the user feels, how tired the user feels after an activity such as a workout or flying a plane, what the user has eaten that day, and so forth. In some examples, the target entity is an athlete, and the athlete inputs a numerical value representing a subjective perception of their physical exertion during an athletic session. The athlete may input, and the system may record, the subjective perception after the athletic session.</p><p id="p-0045" num="0044">At step <b>5</b>, the first user device <b>104</b> (and/or the wearable device <b>103</b>) transmits information to the server computer <b>106</b>. The server computer <b>106</b> may receive the information from the first user device <b>104</b> and/or the wearable device <b>103</b>. The information may be time series data, i.e., a set of data with corresponding time stamps that can be used to analyze patterns in the data over time. In some embodiments, the first user device <b>104</b> transmits a first data set and second data set&#x2014;e.g., two sets of time series data for different measurements. As an example, a first data set may be from the wearable device <b>103</b>, e.g., heartrate, pulse, oximetry, and so forth. A second data may be from the first user device <b>104</b>, e.g., information input by the user. Alternatively, or additionally, multiple data sets may be received from the wearable device <b>103</b> and/or the first user device <b>104</b>. For example, heartrate and oximetry information may be received from the first user device <b>104</b> originating from the wearable device <b>103</b>.</p><p id="p-0046" num="0045">Each data set may include a plurality of data points. The data points may represent a measurement at a particular time, and may be associated with a timestamp. Each data set may also include an identifier of the user and/or user device (e.g., a universally unique identifier (UUID), user name, first and/or last name, nickname, Internet Protocol (IP) address, and so forth).</p><p id="p-0047" num="0046">Alternatively, or additionally, the server computer <b>106</b> may receive performance data from a computing device that analyzed performance of the target entity. As specific examples, the performance data can be player statistics for a sports player (e.g., passing accuracy, shooting percentage, and so forth) or efficiency statistics for an office worker (e.g., time spent typing in documents or sending emails in a given day). In some implementations, the computing device applies one or more machine learning models to identify the performance data. For example, the computing device applies a machine learning model trained to identify and count each time a tennis player hits a ball in practice footage. The number of times hitting the ball is then compiled and sent to the server computer <b>106</b>. The machine learning model may, for example, be a neural network.</p><p id="p-0048" num="0047">As another example, the server computer <b>106</b> may receive user information from a computer operated by a doctor administrating tests to the target entity <b>102</b>. As another example, the server computer <b>106</b> may receive information from a vehicle operated by the target entity <b>102</b>. The information may relate to a status of the vehicle. For example, the target entity <b>102</b> may operate an airplane, and the airplane may transmit altitude information, speed information, GPS information, and so forth. As other examples, a vehicle (e.g., a car, truck, tank, or submarine operated by the user) may transmit vehicle information to the server computer <b>106</b>.</p><p id="p-0049" num="0048">At step <b>6</b>, the server computer <b>106</b> analyzes the data received from the wearable device <b>103</b> and/or first user device <b>104</b> according to the configuration data received from the second user device <b>108</b>. The server computer <b>106</b> may perform statistical operations on the received data such as sum, count, average, and standard deviation. The server computer <b>106</b> may correlate received data. For example, the server computer <b>106</b> correlates a first data set received from the wearable device <b>103</b> and a second data set received from the first user device <b>104</b> based on timestamps, user identifiers, and/or device identifiers. As a specific example, the server computer may correlate a heart rate and an oximetry level based on same or similar timestamps (e.g., within one second or ten seconds of one another). The data points in the first data set and the second data set may be correlated over time to analyze how the first data set and the second data set relate to one another (e.g., time series data).</p><p id="p-0050" num="0049">In some embodiments, at step <b>6</b>, the server computer <b>106</b> computes a metric based on the received data and the configuration data. The metric may represent how the target entity <b>102</b> is performing in a role. In some implementations, the metric represents how the target entity <b>102</b> is performing in comparison to other entities in that role. Techniques for computing the metric are described in further detail with respect to <figref idref="DRAWINGS">FIG. <b>12</b></figref>.</p><p id="p-0051" num="0050">At step <b>7</b>, the server computer <b>106</b> identifies and triggers an action based on the metric. For example, the server computer <b>106</b> transmits a message to the second user device <b>108</b> and/or the first user device <b>104</b>. The message may be in the form of a push notification, an email, a text message, and/or the like. For example, the server computer <b>106</b> transmits, to the first user device <b>104</b> and/or second user device, an electronic mail (email) message including the metric and at least a subset of the input data or a derivative thereof. As a specific example, the target entity is a baseball player, and the metric is 5 out of 10, indicating that the target entity's performance has room for improvement. The email includes the metric, as well as a derivative of a subset of the input data in the form of an average sprinting speed of the target entity, which is significantly lower than average.</p><p id="p-0052" num="0051">Alternatively, or additionally, the server computer updates a user interface displayed on the second user device <b>108</b> and/or the first user device <b>104</b>. The server computer <b>106</b> may cause display of information via a user interface. The server computer <b>106</b> may transmit instructions to the second user device <b>108</b> and/or the first user device <b>104</b>, thereby causing the second user device <b>108</b> and/or the first user device <b>104</b> to display a Graphical User Interface (GUI) including the metric and at least a subset of the input data or a derivative thereof via the first user device and/or second user device. As illustrated in <figref idref="DRAWINGS">FIGS. <b>15</b>-<b>17</b></figref>, the server computer may cause display of information indicating the metric, information involved in computing the metric, and/or suggested actions determined based upon the metric.</p><p id="p-0053" num="0052">In some implementations, the server computer <b>106</b> modifies an entry on a calendar for the target entity to include an identified task to improve the performance. For example, the target entity is a race car driver and the metric is low due to relatively poor historical performance when passing another car on the race track. The driver's schedule, in the form of a digital calendar, is updated to include additional passing practice. As another example, analysis of an athlete's performance and the athlete's subjective perceptions of how tired he feels results in a low metric due to the athlete being on the verge of an injury. The athlete's calendar is updated to include more rest and stretching. As another example, the target entity is a police officer and the metric is based on correlating schedules to mental wellbeing. The server computer <b>106</b> determines that the target entity is on third shift too long, leading to mental and physical problems. The calendar is updated to move the officer from the third shift to mitigate these effects.</p><p id="p-0054" num="0053">In some implementations, the server computer <b>106</b> transmits a suggestion, thereby causing the target entity to perform an action to improve the performance. For example, one or more of the above alerts can be transmitted, along with a suggestion such as going to a class, talking to a therapist, increasing a certain type of training, etc. The target entity follows the suggestion, and then further data is collected, the metric is recomputed, and the metric has increased, indicating an improvement in performance.</p><p id="p-0055" num="0054">In some implementations, the server computer <b>106</b> causes a modification to equipment. This may include activating or deactivating the equipment. For example, the target entity is a law enforcement officer and the metric indicates that the target entity is underperforming. The corresponding action is turning on a body camera worn by the target entity. The server computer may transmit a signal over a wireless network causing the equipment to be activated or deactivated. Alternatively, or additionally, the equipment is modified by changing the issued equipment&#x2014;e.g., a law enforcement officer is issued a body camera, a sports player is issued new shoes, and so forth.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a server computer <b>200</b> according to some aspects of the disclosure. The server computer <b>200</b> may, e.g., be the server computer <b>106</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The server computer <b>200</b> includes functionality to receive and analyze data received from the first user device <b>104</b>, second user device <b>108</b>, and/or the wearable device <b>103</b>. The server computer <b>200</b> includes a processor <b>202</b> coupled to a memory <b>204</b>, a network interface <b>206</b>, and a computer-readable medium <b>208</b>.</p><p id="p-0057" num="0056">The memory <b>204</b> can be used to store data and code. The memory <b>204</b> may be coupled to the processor <b>202</b> internally or externally (e.g., cloud based data storage), and may comprise any combination of volatile and/or non-volatile memory, such as RAM, DRAM, ROM, flash, or any other suitable memory device. The memory <b>204</b> may store user data collected in association with one or more users over time.</p><p id="p-0058" num="0057">The processor <b>202</b> may comprise one or more processors, application specific integrated circuits (ASICs), or field programmable gate arrays (FPGAs). The processors may include be single core or multicore processors. In some embodiments, processor <b>202</b> can include one or more special purpose co-processors such as graphics processors, digital signal processors (DSPs), or the like. In some embodiments, the processor <b>202</b> can be implemented using customized circuits, such as application specific integrated circuits (ASICs), or field programmable gate arrays (FPGAs).</p><p id="p-0059" num="0058">In some embodiments, the processor <b>202</b> can execute instructions stored in memory <b>204</b> or on computer-readable medium <b>208</b>. In various embodiments, the processor <b>202</b> can execute a variety of programs or code instructions and can maintain multiple concurrently executing programs or processes. At any given time, some or all of the program code to be executed can be resident in memory <b>204</b> and/or on computer-readable medium <b>208</b> including potentially on one or more storage devices. Through suitable programming, processor <b>202</b> can provide various functionalities described herein.</p><p id="p-0060" num="0059">The network interface <b>206</b> may include an interface that can allow the server computer <b>200</b> to communicate with external computers. The computer-readable medium <b>208</b> is a non-transitory computer-readable medium and may include software code stored as a series of instructions or commands. The computer-readable medium <b>208</b> may comprise code, executable by the processor, to implement methods as described herein.</p><p id="p-0061" num="0060">In some aspects, the computer-readable medium includes a data management module <b>210</b>, a configuration module <b>212</b>, a performance assessment module <b>214</b>, and a visualization module <b>216</b>.</p><p id="p-0062" num="0061">The data management module <b>210</b> includes code for importing, storing, and organizing data. In some embodiments, the data management module <b>210</b> is configured to retrieve data from one or more external devices (e.g., wearable devices, user computing devices, other server computers, etc.). The data management module <b>210</b> may further be configured to store the data in an organized fashion (e.g., in chronological order and/or in association with a user identifier or device identifier).</p><p id="p-0063" num="0062">The configuration module <b>212</b> includes functionality to identify and manage attributes configured by a user. The configuration module <b>212</b> may identify attributes to be configured by a user such as weights, categories, roles, and data sources, as described herein. The configuration module <b>212</b> may prepare interface elements for display to guide a user to provide configuration values (e.g., as shown in <figref idref="DRAWINGS">FIGS. <b>5</b>A-<b>10</b></figref>). The configuration module <b>212</b> may further apply the configuration values to customize the data structures and analytics based on user input.</p><p id="p-0064" num="0063">The performance assessment module <b>214</b> includes code configured to compute a metric indicative of a target entity's performance, and identify and trigger actions to perform the performance. The performance assessment module <b>214</b> may include code configured to retrieve data for an entity, apply user-configured attributes such as weights, and compute a performance metric indicative of the target entity's performance in a role based on the data and the user-configured attributes. The performance assessment module <b>214</b> may further include code configured to identify actions for improving the performance metric and the performance of the target entity in a role. For example, the performance assessment module may <b>214</b> include functionality for traversing a database that maps different skills or aspects of a role to different activities to be performed to identify actions that will improve different aspects of a role. As specific examples, an entity can take a typing class to improve typing or do batting practice to improve hitting.</p><p id="p-0065" num="0064">The visualization module <b>216</b> includes functionality to generate visualizations, which may include user interfaces illustrating the performance of entities in an organization. This can include coaches dashboards showing performance metrics for team members as shown in <figref idref="DRAWINGS">FIGS. <b>15</b> and <b>17</b></figref> and interfaces for guiding a user to engage in activities to improve performance, as shown in <figref idref="DRAWINGS">FIGS. <b>16</b>A, <b>16</b>B, and <b>16</b>C</figref>. The visualization module <b>216</b> may further include code configured to generate and cause display of interface views for configuring how and for what entities the performance metrics are computed, e.g., as illustrated in <figref idref="DRAWINGS">FIGS. <b>5</b>A-<b>11</b> and <b>13</b>-<b>14</b></figref>.</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example of performance data <b>300</b>. As noted above, performance data can come from a variety of sources and entities, which makes it difficult to discern meeting from these large amounts large amounts of data of disparate types. <figref idref="DRAWINGS">FIG. <b>3</b></figref> shows game metrics <b>302</b>, which include different data points gathered based on players' performance in a sports game. The data covers different roles <b>304</b> and dates <b>306</b>. This raw data is not instructive as to how each player is doing or how to improve the players' performance. The techniques described below can be used to discern meaning from such user performance data <b>300</b> and use it to trigger actions to improve the performance of entities in roles.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example configuration process <b>400</b> according to some embodiments. As noted above with respect to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in some embodiments, the system presents one or more user interfaces that prompt a user to provide input configuring to what extent different factors will affect the performance metric and/or ensuing action. The process <b>400</b> may include a user (e.g., an administrator such as a coach, employer, etc.) establishing configuration data including skills, roles, members, and weights. The configuration data may be received by a server computer <b>106</b> from a user device (e.g., second user device <b>108</b>) over a communication network.</p><p id="p-0068" num="0067">At step <b>402</b> a skills hierarchy is created. As shown in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, the system may present a user interface including different skills and skill categories. A skill is a particular activity to be monitored and/or improved, such as defending, distance, goal keeping, etc. A skill category is a category of skills, such as performance, preparation, etc. A skills hierarchy establishes categories, and potentially subcategories, and what skills fall in what category or subcategory. User input can be received to configure particular skills and corresponding skill categories. In some aspects, based on the received user input, the system stores a data structure nesting the skills within the skill categories.</p><p id="p-0069" num="0068">At step <b>404</b>, roles are created. As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the system may present a user interface including functionality to enter (e.g., by typing, selecting from a drop-down or other interface element, etc.) different skills and subskills. User input can be received to configure particular skills and corresponding subskills.</p><p id="p-0070" num="0069">At step <b>406</b>, members are assigned to roles. As shown in <figref idref="DRAWINGS">FIG. <b>5</b>B</figref>, the system may present a user interface including functionality to add or manage members for a given role. A role is a position in an organization. For example, in a soccer team, roles include goalkeeper, striker, and the like; in a business, roles may include secretary, accountant, and so forth. The user interface may include one or more text entry fields for accepting typed user input, a drop-down for facilitating user selection of one of several options, functionality to drag and drop a member to a different role, or other suitable interface elements. User input can be received to assign members (e.g., different entities, such as players on a team, employees at a workplace, etc.) to a particular role.</p><p id="p-0071" num="0070">At step <b>408</b>, skills are weighted to roles. For a given role, different skills may apply. For example, for an athlete, passing and kicking may be applicable skills. The system may prompt a user to configure weights that establish how much of an impact each skill has on an overall performance metric. As shown in <figref idref="DRAWINGS">FIGS. <b>7</b>-<b>9</b></figref>, the system may present user interface views including functionality to adjust these weights (e.g., by typing, selecting from a drop-down or other interface element, etc.) for skills and/or skill categories corresponding to a given role. User input can be received to adjust a weight for each skill, which will affect how much impact each of the skills has on determining a recommended course of action for entities for a particular skill category in a particular role.</p><p id="p-0072" num="0071">At step <b>410</b>, data is mapped to skills. Via a user interface, the system prompts a user to establish data sources for the respective skills. For example, depending on the skill and the resources available, appropriate data sources may include wearable biometric sensors, user input to a user device, video or image data, GPS data, and so forth. As shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the system can present a user interface that accepts user input configuring data sources and data fields for ingesting and storing input data for use in determining the scores and metrics described herein. The process <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> is used to accept and digest user input to configure different skills for roles, and weight how the skills are used to manage performance in the respective roles.</p><p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. <b>5</b>A</figref> illustrates an example user interface <b>450</b> for receiving configuration data according to some embodiments. The user interface <b>450</b> can be used to configure a skills hierarchy (e.g., as in step <b>402</b> of the process <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>). The user interface <b>450</b> enables managing skill categories, as indicated by the manage categories heading <b>401</b>. The user interface <b>450</b> includes selectable icons list <b>452</b>, for displaying the categories and skills in a list view, and tree view <b>454</b>, for displaying the categories and skills in a tree view <b>454</b>. In this example, the tree view <b>454</b> has been selected.</p><p id="p-0074" num="0073">The user interface <b>450</b> depicted in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> displays the skill categories performance <b>414</b> and preparation <b>416</b>. For a given category, a drop-down icon such as drop-down icon <b>415</b> is displayed. As shown in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, the drop-down icon <b>415</b> for performance <b>414</b> has been selected, revealing the current skills in the performance <b>414</b> category. The skills in the performance <b>414</b> category are defending <b>422</b>, distance <b>424</b>, goalkeeping <b>426</b>, participation <b>428</b>, passing <b>430</b>, possession <b>432</b>, and scoring <b>434</b>. These skills affect the success of one or more entities in the performance <b>414</b> skill category. The skill categories of performance <b>414</b> and preparation <b>416</b> both affect the success of one or more entities in a corresponding role (e.g., players on a soccer team).</p><p id="p-0075" num="0074">In some implementations, a user can manipulate the skills and skill categories displayed (e.g., by dragging and dropping, typing, etc.) to configure skills and skill categories for a given role. The user interface <b>450</b> includes an editing icon <b>456</b>. When a user interacts with the editing icon <b>456</b>, the user interface <b>450</b> can transition to a view for user modification of the skills and/or categories. A sorting icon <b>458</b> is provided for sorting the skills and/or categories (e.g., alphabetically, by recency of addition to the list, in order of their weights, etc.). The user interface <b>450</b> further includes an add button <b>460</b>, which, when selected via user interaction, transitions to a view for accepting user input to add skills and/or categories. In some implementations, the categories and skills are initially displayed based on defaults, which an be adjusted by the user. Alternatively, the categories and/or skills can be provided by a user from scratch.</p><p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. <b>5</b>B</figref> illustrates another example user interface <b>500</b> for receiving configuration data according to some embodiments. The user interface <b>500</b> can be used to configure roles (e.g., as in step <b>404</b> of the process <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>). The user interface <b>500</b> displays different roles in an organization. In this example, the roles are listed under a drop-down menu labeled name <b>510</b>. The roles in this example are administrator <b>512</b>, centerback <b>514</b>, goalkeeper <b>516</b>, midfielder <b>518</b>, striker <b>520</b>, user <b>522</b>, wingback <b>524</b>, and winger <b>526</b>, corresponding to different roles on a soccer team. Other examples or roles include positions within a company, such as secretary, banker, human resources representative, etc., or positions within a military organization, such as pilot, soldier, general, etc. The user interface <b>500</b> includes a column for description <b>530</b>, which can include information describing the different roles (blank and yet-to-be configured in this example). The user interface <b>500</b> includes a column for members <b>540</b>, which shows how many members are assigned to each role via respective numbers of members <b>542</b>. In some implementations, a user (e.g., an administrator) can configure what members are assigned to what roles, as well as add or edit descriptions. In some implementations, the numbers listed under members are linked to the user interface <b>600</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, which can be used to view and/or edit the members in a given role. The role may control what skills contribute to a metric for a given member. For example, athletic skills are key for centerback <b>514</b> and goalkeeper <b>516</b>, but less important for administrator <b>512</b>.</p><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates another example user interface <b>600</b> for receiving configuration data according to some embodiments. The user interface <b>600</b> can be used to assign members <b>604</b> to a role <b>602</b> (e.g., as in step <b>406</b> of the process <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>). The user interface <b>600</b> is role specific. For example, using an interface such as that depicted in <figref idref="DRAWINGS">FIG. <b>5</b>B</figref>, a particular role can be selected, and the user can drill down into what users are placed in that role <b>602</b>. In some implementations, the user interface <b>600</b> is a modal that is overlaid over another interface such as the user interface <b>500</b> of <figref idref="DRAWINGS">FIG. <b>5</b>B</figref>.</p><p id="p-0078" num="0077">In this example, the user interface <b>600</b> displays a list of members <b>604</b> currently assigned to the role <b>602</b> of centerback&#x2014;Pierce Sampson <b>610</b>, Erik Lee <b>614</b>, Hugo Alfero <b>612</b>, and Laurence Spooner <b>616</b>. User input can be received which the system uses to add or remove entities from the member list for a given role. The user interface <b>600</b> further includes a save button <b>622</b> for saving changes, a cancel button <b>620</b> for canceling changes, members <b>604</b> tab (selected in this example) for viewing or configuring members, and a basic info tab <b>624</b> for displaying additional information about a role.</p><p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates another example user interface <b>700</b> for receiving configuration data according to some embodiments. The user interface <b>700</b> can be used to weight skills and select skills for roles (e.g., as in step <b>408</b> of the process <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>). The user interface <b>700</b> displays a list of roles <b>702</b> on the left hand side&#x2014;centerback <b>704</b>, goalkeeper <b>706</b>, midfielder <b>708</b>, striker <b>710</b>, user <b>712</b>, wingback <b>714</b>, and winger <b>716</b>. A user can interact with the user interface <b>700</b> to select a role to configure or view. As shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, striker <b>710</b> has been selected and is shaded. The user interface <b>700</b> shows a list of available skills <b>720</b>, with a selectable check box for each available skill. For the selected role of striker <b>710</b>, the skill category of performance <b>718</b> is available and selected (as indicated by the checkmark). Next to the skill category of performance <b>718</b> is a configurable percentage box <b>719</b>. In this example, since performance <b>718</b> is the only skill category assigned to the striker <b>710</b> role, it accounts for 100% (e.g., for contributing to the metric determination as described herein).</p><p id="p-0080" num="0079">For the selected skill category of performance <b>718</b>, the right hand side lists the available skills <b>720</b>&#x2014;defending <b>722</b>, distance <b>724</b>, goal keeping <b>726</b>, participation <b>728</b>, passing <b>730</b>, possession <b>732</b>, and scoring <b>734</b>. A user can check one or more of the skills <b>720</b> for weighting (e.g., for contributing to the metric determination as described herein). As shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the skills of defending <b>722</b>, passing <b>730</b>, possession <b>732</b>, and scoring <b>734</b> have been selected using corresponding checkboxes. When a checkbox <b>735</b> is activated, a text field <b>740</b> for the corresponding skill <b>720</b> is activated, so that a user can enter or edit a percentage in the text field <b>740</b>. The remaining skills of distance <b>724</b>, goal keeping <b>726</b>, and participation <b>728</b> have not been selected and their weighting percentages are greyed-out and fixed to 0. The selected skills <b>720</b> are assigned default or user-configured weights&#x2014;defending has been set to 5%, passing has been set to 15%, possession has been set to 30%, and scoring has been set to 50%. A user can interact with the text fields <b>740</b> (e.g., by typing or using a drop-down menu) to change the weights. In some implementations, when one weight is changed, the other weights are automatically changed (e.g., by an equal amount) such that the weights of the selected skills add to 100% or another configured percentage for the overall skill. The user interface <b>700</b> also includes a box labeled &#x201c;check all&#x201d; <b>750</b>, which can be selected to include all available skills.</p><p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates another example user interface view <b>800</b> for receiving configuration data according to some embodiments. The user interface view <b>800</b> may correspond to another view of the user interface <b>700</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, when a different role <b>802</b> has been selected. Similarly to the user interface <b>700</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the user interface view <b>800</b> can be used to weight skills to roles (e.g., as in step <b>408</b> of the process <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>). In this case, the role of goalkeeper <b>806</b> has been selected from the roles <b>802</b> of centerback <b>804</b>, goalkeeper <b>806</b>, midfielder <b>810</b>, user <b>812</b>, wingback <b>814</b>, and winger <b>816</b>. As in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the listed skills <b>820</b> include defending <b>822</b>, distance <b>824</b>, goal keeping <b>826</b>, participation <b>828</b>, passing <b>830</b>, possession <b>832</b>, and scoring <b>834</b>. Based on the selected role of goalkeeper <b>836</b>, different skills have been selected that are more appropriate for a goalkeeper <b>836</b>, as indicated by the activated checkboxes <b>835</b>. In this case, goal keeping <b>826</b> and passing <b>830</b> are selected to contribute, and defending <b>822</b>, distance <b>824</b>, participation <b>828</b>, possession <b>832</b>, and scoring <b>834</b> are not selected to contribute. Similarly to the user interface <b>700</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, in the user interface view <b>800</b> of <figref idref="DRAWINGS">FIG. <b>8</b></figref>, each selected skill <b>820</b> includes a weight or percentage adding up to 100% total for the selected performance skill category, and the respective weights can be adjusted via text fields <b>840</b>.</p><p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates another example user interface view <b>900</b> for receiving configuration data according to some embodiments. The user interface view <b>900</b> may correspond to another view of the user interface <b>700</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, when a different role <b>902</b> has been selected. Similarly to the user interface <b>700</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the user interface view <b>900</b> can be used to weight skills to roles (e.g., as in step <b>408</b> of the process <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>). In this case, the role of centerback <b>904</b> has been selected, and the skills <b>920</b> selected (indicated by activated checkboxes <b>935</b>) are different. With centerback <b>904</b> selected, defending <b>922</b>, passing <b>930</b>, and possession <b>932</b> are selected to contribute to further analysis for users in the centerback <b>904</b> role <b>902</b>, and distance <b>924</b>, goal keeping <b>926</b>, participation <b>928</b>, and scoring <b>934</b> are not selected to contribute. Similarly to the user interface <b>700</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, in the user interface view <b>900</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, each selected skill <b>920</b> includes a weight or percentage adding up to 100% total for the selected performance skill category, and the respective weights can be adjusted via text fields <b>940</b>.</p><p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates another example user interface <b>1000</b> for receiving configuration data according to some embodiments. The user interface <b>1000</b> can be used to configure a data source. For example, for a given type of data, different data sources <b>1002</b> can be chosen, such as surveys <b>1004</b>, a particular wearable device, and so forth. The user interface <b>1000</b> is labeled Choose Data Source <b>1001</b> and includes drop-down menus labeled Data Source <b>1002</b>, Field Name <b>1006</b>, Time Range <b>1010</b>, and Aggregation <b>1014</b>. The Data Source <b>1002</b> drop-down menu can be used to select a data source (e.g., from a biometric device, survey, test, performance monitoring computing device, etc.). In this example, Surveys <b>1004</b> is the selected data source. Based on this configuration data (e.g., for a particular data field or skill), data will be retrieved from the selected data source. The Field Name <b>1006</b> drop-down menu can be used to select a name for the configured data field (e.g., fifth level <b>1008</b>, as shown). The Time Range <b>1010</b> drop-down menu can be used to select a time range (e.g., last 90 days <b>1012</b> as shown). Based on the configured time range, data will be retrieved for that time range. The Aggregation <b>1014</b> drop-down menu can be used to select an aggregation method for aggregating the data (e.g., averaging <b>1016</b>, as is shown). Based on the configured aggregation method, the retrieved data will be averaged (or added, the mean or median computed, etc.). The user interface <b>1000</b> further includes a cancel button <b>1018</b> for canceling any changes entered and an apply buttons <b>1020</b> for applying any changes entered.</p><p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates an example user interface <b>1100</b> illustrating configured weights and skills, according to some embodiments. This represents what skills will be used, and with what weights, for each role in an organization, in computing a metric as described herein. This user interface <b>1100</b> can be used to show the results of the user configurations applied via the process <b>400</b> and the user interfaces <b>450</b>-<b>1000</b> described above. The user interface <b>1100</b> displays a list of roles, labeled Role Name <b>1102</b> and including the roles of Centerback <b>1106</b>, Goalkeeper <b>1108</b>, Midfielder <b>1110</b>, Striker <b>1112</b>, Wingback <b>1114</b>, and Winger <b>1116</b>. For each role, different categories <b>1120</b> and data sources <b>1130</b> are shown. The user interface <b>1000</b> further displays a list of fields <b>1140</b>, which correspond to the skills selected for each respective role. For each field or skill is a bar graph <b>1150</b> showing the weight assigned for that skill for the given role&#x2014;e.g., 50% tackle success rate, 20% passing success rate, and 30% possession success rate for centerback, and so forth. Each field or role is also categorized, as shown with different, as explained by the Field legend <b>1160</b>.</p><p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates an overview process for evaluating and improving performance in a role according to some embodiments. The process <b>1200</b> may include ingesting data, analyzing that data, and using that data to identify and trigger actions to improve performance in a role. The process <b>1200</b> can be performed by the server computer <b>106</b> in cooperation with other devices in the computing system of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0086" num="0085">At step <b>1202</b>, the server computer receives input data from a remote device. The server computer can retrieve the data (e.g., over a communication network) from one or more remote devices, such as wearable devices, mobile devices, and/or computing devices. As described above with respect to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, data can be ingested by the system from one or more remote devices. For example, the server computer retrieves input data including one or more of: biometric data received from a monitoring device that collected the biometric data from a target entity, performance data received from a computing device that analyzed performance of the target entity, and/or survey or test data received from an entity device that received responses from the target entity.</p><p id="p-0087" num="0086">The input data is associated with a performance of the target entity in a role in an organization. For example, for an athlete, running speed and other athletic criteria may be relevant to their performance in their position on the sports team. For a role in a business, different skills may apply, such as typing speed and interpersonal and other skills. The relevant data, based on the role of the target entity in the organization, is retrieved from one or more remote computing devices.</p><p id="p-0088" num="0087">Various types of data can be gathered from various types of remote computing devices. As an example, the server computer retrieves, from a wearable device with one or more biometric sensors, biometric data such as heartrate data, blood oxygenation data, or the like (i.e., heartrate or pulse when performing the action of interest). As another example, the server computer retrieves at least a subset of the input data from a Global Positioning System (GPS). The server computer may retrieve GPS data from a user device or wearable device associated with the user. The server computer may then analyze position and time data to identify an average speed of the user over a time interval. As another example, the server computer retrieves, from a computing device associated with the target entity, answers to survey questions (e.g., &#x201c;How tired did you feel after running sprints today?&#x201d;, &#x201c;Do you find it difficult working in groups?&#x201d;, etc.). As another example, the data is gathered from an external computing device that performs machine learning-based analysis of video footage of each entity on the field.</p><p id="p-0089" num="0088">As described above, the different skills assessed, based on the role of the target entity, can be configured by a user and/or set to default values based on the role and organization at issue. For example, as described above with respect to <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>11</b></figref>, user input can be accepted via a GUI to configure what skills are assessed for what role (e.g., for the role of forward, passing and kicking can be set to user-configured and/or default skills for that role).</p><p id="p-0090" num="0089">In some embodiments, the server computer receives user input via a GUI (e.g., a first GUI) to establish a set of weights for the respective set of skills for the role. The computing system (e.g., a user device) displays the GUI, which includes one or more interactive elements (e.g., text entry fields, sliders, drop-down menus, etc.) for modifying the weights. The computing system receives user input modifying the weights via the one or more interactive elements, and updates the weights based on the user input. As an example, for the role of striker, defending, passing, possession, and scoring are skills of interest. As shown in <figref idref="DRAWINGS">FIGS. <b>7</b>-<b>9</b></figref>, a user can interact with the GUI to establish weights for each of these skills so that each weight contributes to a certain percentage of an overall performance metric. This allows the user to adjust the computations to tailor performance assessment and improvement to what is important in that role and that organization.</p><p id="p-0091" num="0090">In some embodiments, the data sources from which the data is retrieved are user-configured. In some aspects, the computing system displays, via a GUI (e.g., a fourth GUI), an interactive element (e.g., drop-down, text-entry field, etc.) for configuring a source of the input data and receives, via the GUI, user input configuring the source of the input data. For example, a user can interact with a GUI to establish that a particular wearable device (e.g., based on a unique identifier of the wearable device) should be used to gather speed and heartrate data for a particular target entity. As another example, user input establishes that how the user is feeling should be gathered from a particular application that gathers survey data from the target entity on their mobile device. A user can further interact with the GUI to establish a format in which the data is stored (e.g., string, integer, numeric, etc.) and where the data is stored (e.g., in a remote database or on a user device, in certain fields, etc.). An example user interface for configuring data sources is shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>. The input data is retrieved and stored by the server computer based on the configured source. The input data can further be stored in a particular manner based on user configuration via interfaces such as those depicted in <figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref>.</p><p id="p-0092" num="0091">At step <b>1204</b>, the system computes a metric. The metric represents how well a target entity is performing in a role, and can indicate the target entity's success in the organization as a whole. The metric may be indicative of courses of action for improvement. The metric is computed based on the data retrieved at step <b>1202</b>. In some embodiments, the metric is also based on the weights received via the GUI. For example, for the role of centerback on a soccer team, the configured skills and weights are defending (50%), passing (20%), and possession (30%). The system identifies defending data, passing data, and possession data. In some cases, the data is retrieved from a data store of the server computer, which periodically retrieves the data from remote devices at step <b>1202</b>. Alternatively, or additionally, some data may be retrieved directly from a remote device in real-time (e.g., from a biometric sensor to assess the current physical status of the target entity).</p><p id="p-0093" num="0092">The data is used to compute a metric, or representation of the entity's overall performance according to the selected skills and weights. In some examples, the metric is numeric, on some scale (e.g., 1-100, where 100 is best). As an example, the metric is given by:</p><p id="p-0094" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>0.5(DR+1/HRD)+0.2(PAR+1/HAR)+0.3(POT+1/POR),<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0095" num="0000">where DR is a percentage of successful defense actions, HRD is an average measured heart rate associated with the defense actions, PAR is a percentage of successful passing actions, HAR is an average measured heart rate associated with the passing actions, POT is a time of possession, and POR is an average measured heart rate associated with the possession actions, each term being weighted using the respective configured weight.</p><p id="p-0096" num="0093">In some implementations, computing the metric further includes analyzing the data based on how the data points for entities within a role or organization compare to one another. For example, the system computes the metric by analyzing different skills for a given role in turn for each of a set of entities assigned to that role. The server computer may identify a first skill value for a first skill for another entity in the role (e.g., a second entity different than the target entity). For example, the role is patrolling police officer and skills configured for the role include the skill categories of driving (including the skills of pit maneuvers, speed trials, etc.) and shooting (including the skills of target practice, gun safety, etc.). The server computer selects one of the skills (e.g., pit maneuvers) and identifies a score for the entity in pit maneuvers (e.g., an average score for a set of historical practice pit maneuvers for the entity). This may be repeated for each entity in the role (e.g., for all police officers in the role of patrolling officers an organization). In some implementations, the server computer generates a baseline value for the skill for the role. The baseline value may be set to the highest score for the skill, or a derivative thereof. For example, the server computer increments a first skill value equal to the highest score for the skill among entities in the role according to a predetermined margin to generate the baseline value. The predetermined margin may, for example, be 1% (e.g., the highest score for a basketball forward on a team is 83% shooting success, and a predetermined margin of 1% is added to establish a baseline value of 84% for the shooting skill). Upon determining the baseline value, the server computer compares the scores for other entities in the role to the baseline value. For example, the server computer identifies a skill value for the target entity, and other entities in the role (e.g., 75% shooting success, 39% shooting success, etc.). The server computer then computes a percentage of the baseline value for the skill for the other entities (e.g., for the target entity, the percentage of the baseline value for the shooting skill is (75/84)&#xd7;100=89%). This may be repeated for each target entity in the role.</p><p id="p-0097" num="0094">In some implementations, this process is repeated for each skill assigned to the role (e.g., for additional skills of speed trials, shooting, gun safety, etc., a respective baseline value is computed which is then compared to values for other entities in the role for that skill). For example, computing the metric further includes identifying a third skill value for a second skill for a third entity. The server computer moves on to another skill configured for the role, speed trials, for which a different entity in the role has a highest score of 95. This is incremented using the margin of 1% to arrive at a second baseline value of 96 for the speed trials skill. The server computer identifies a skill value for the speed trials skill (e.g., the second skill) for the target entity, and computes a percentage of the second baseline value for the skill value for the target entity. This can be repeated for each skill assigned to the role. In some implementations, if data is missing for a particular entity for a particular skill (e.g., if a striker has no data for tackle success rate), then the other skills are dynamically computed and reweighted to avoid counting this as a zero score. The server computer then computes the metric based on the percentage of the first baseline value and the percentage of the second baseline value. For example, the metric may be a weighted sum of the computed percentages, according to the user-configured weights for each of the skills. The scores can be recomputed and reweighted until every entity in the role is accounted for.</p><p id="p-0098" num="0095">At step <b>1206</b>, the server computer identifies an action likely to improve the metric. For example, the server computer may determine that the metric is below some threshold and perform further analysis to identify one or more skills in which the target entity is underperforming. As a specific example, if a player is underperforming in passing, scheduling passing practices may be identified as a corrective action, e.g., based on traversing a stored mapping of skills to actions. As another example, if an entity is showing signs of burnout, a more relaxed schedule may be identified as a corrective action.</p><p id="p-0099" num="0096">At step <b>1208</b>, the server computer triggers the action identified at step <b>1206</b>. Triggering the action may include performing the action directly and/or causing another device or entity to perform the action. For example, the server computer identifies signs of distress in a police officer and determines that the officer's body cam should be turned on. The server computer triggers the action by transmitting a signal to the body cam, causing the body cam to activate.</p><p id="p-0100" num="0097">Triggering the action in some examples includes modifying an entry on a calendar for the target entity to include an identified task to improve the performance. As an example, the identified action is to perform a particular training, and the server computer adds the training to the target entity's calendar. As another example, if it is found that the target entity has signs of burnout, then activities may be removed from the calendar, and/or therapy or meditation sessions are added to the calendar.</p><p id="p-0101" num="0098">As another example, triggering the action includes transmitting an electronic mail (email) message including the metric and at least a subset of the input data or a derivative thereof. As a specific example, the system sends the metric, along with average passing and running scores, to a coach. The coach can then adjust an athlete's training regime based on the information in the email.</p><p id="p-0102" num="0099">As another example, triggering the action includes displaying a GUI (e.g., a second GUI) including the metric and at least a subset of the input data or a derivative thereof. Example interfaces for presenting such results are illustrated in <figref idref="DRAWINGS">FIGS. <b>15</b>-<b>17</b></figref>. In some aspects, the computing system displays, via a GUI (e.g., a third GUI), performance metrics for a plurality of entities including the target entity and an attribute for each entity of the plurality of entities. The attribute can be some information about the target entity that is related to the metric, such as number of classes taken, hours worked per week, average running speed, and so forth. In some embodiments, the computing system displays an interface such as that shown in <figref idref="DRAWINGS">FIG. <b>17</b></figref>, showing attributes (e.g., minutes played as shown in <figref idref="DRAWINGS">FIG. <b>17</b></figref>) and metrics for a set of target entities. A user such as a coach can use such information to easily discern an appropriate intervention. For example, the server computer, by causing display of a user-friendly interface that shows the coach that a particular player with high scores and low playing time should play more, causes a modification of the attribute (in that the playing time is increased). Thus, the server computer, by displaying such an interface, causes a modification of the attribute for at least a subset of the plurality of entities.</p><p id="p-0103" num="0100">At step <b>1210</b>, the process returns to step <b>1202</b> and the metric is updated. The metric may, for example, be updated periodically. For example, new data is ingested daily, when new tests are taken, on a streaming basis, etc. The metric can be recomputed on a periodic basis so that the metric remains up-to-date. In some iterations, the action may not be triggered (e.g., if the target entity is performing well in all skills associated with their role).</p><p id="p-0104" num="0101">Advantageously, the techniques of <figref idref="DRAWINGS">FIG. <b>12</b></figref> distill data retrieved from one or more (often many) remote sources, which can be of many types. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, such data in raw form is not very instructive as to how each entity is performing in a role or what to do to improve the performance of the entity and the overall organization. Using user-configured weights and skills, the system is able to identify performance metrics and recommended skills suitable for specific organizations and roles. Moreover, the results can be summarized in user-friendly GUIs that show a user information about the performance of the organization as a whole as well as providing the ability to drill down and understand the performance of individuals. This can give the user insights on how to make adjustment to improve performance. Additionally, the system can take automatic action without the need for user intervention. For example, the system can turn on or off a body camera, change schedules in a calendar, make a doctor's appointment, and other automatic interventions. These techniques provide multiple improvements to the functioning of a system for managing data for organizations, by efficiently distilling meaning from disparate and complex data and identifying and triggering appropriate interactions, which would otherwise involve complex computer aided and/or manual processes to attempt to identify performance issues from complex data coming from various sources.</p><p id="p-0105" num="0102"><figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref> illustrate example user interface views <b>1300</b> and <b>1400</b> illustrating data ingestion according to some embodiments. The user interface views of <figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref> can be used to manage data ingestion (e.g., at step <b>1202</b> of the process <b>1200</b> of <figref idref="DRAWINGS">FIG. <b>12</b></figref>).</p><p id="p-0106" num="0103">Referring to the user interface view <b>1300</b> shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, data fields can be configured for the data retrieved and stored by the server computer. In the user interface view <b>1300</b>, a Field Definitions tab <b>1302</b> has been selected. When the Field Definitions tab <b>1302</b> is selected, interface elements for configuring different fields are displayed, as shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>. In order to facilitate customization of the data fields, text boxes for Name <b>1304</b> and Data Type <b>1306</b> are presented in the user interface view <b>1300</b>. In the example depicted in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the field names are Person <b>1310</b>, One Lap Time <b>1312</b>, Date <b>1314</b>, and Two Laps Time <b>1316</b>. For each of the named fields, a corresponding data type is configured&#x2014;User <b>1320</b> for Person <b>1310</b>, Number <b>1322</b> for One Lap Time <b>1312</b>, Date <b>1324</b> for Date <b>1314</b>, and Number <b>1326</b> for Two Laps Time <b>1316</b>. This can be used to control the options for user configuration of values for each field as well as how the data is stored by the system. These data types can be selected using drop-down menus, as illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>. The user interface view <b>1300</b> further includes checkboxes which can be used to configure user-selected Key Fields <b>1330</b>, Value Fact Dates <b>1332</b>, and Facets <b>1334</b>. The user interface view <b>1300</b> further includes a Delete Collection button <b>1340</b> for deleting the displayed field definitions and a Save button <b>1342</b> for saving the displayed field definition configurations. A Record Set tab <b>1350</b>, when selected via user interaction, transitions the user interface to the user interface view <b>1400</b> depicted in <figref idref="DRAWINGS">FIG. <b>14</b></figref>.</p><p id="p-0107" num="0104">Referring now to <figref idref="DRAWINGS">FIG. <b>14</b></figref>, corresponding data for each of the configured fields is shown for four athletes on a team (i.e., four entities in a role). The user interface view <b>1400</b> shows data for a set of entities, organized by the columns Person <b>1410</b>, One Lap Time <b>1420</b>, Date <b>1422</b>, and Two Laps Time <b>1424</b>. Under each column is a corresponding data element. For example, various One Lap Time <b>1420</b> values and Two Laps Time <b>1424</b> values are shown for each entity, with a date on which this data was collected. This data has been ingested from another computing device over a network and stored as structured data according to the configured fields. For a first entity, Gaz Paulson <b>1412</b>, One Lap Time <b>1420</b> and Two Laps Time <b>1424</b> values are shown for several different dates <b>1422</b>. For a second entity, Haze Dupuy <b>1414</b>, One Lap Time <b>1420</b> and Two Laps Time <b>1424</b> values are shown for a date <b>1422</b>. For a third entity, Vivek Herman <b>1416</b>, One Lap Time <b>1420</b> and Two Laps Time <b>1424</b> values are shown for two dates <b>1422</b>. For a fourth entity, Drew Bowman <b>1418</b>, One Lap Time <b>1420</b> and Two Laps Time <b>1424</b> values are shown for a date <b>1422</b>. This data shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref> can be ingested according to the configuration parameters established using the interface of <figref idref="DRAWINGS">FIG. <b>13</b></figref>. This structured data can then be used for computing the metrics for each of the entities as described herein. Using the user interface view <b>1400</b>, a user can interact with checkboxes <b>1434</b> to select an entry. Interaction with a Delete Selected button <b>1430</b> will cause that entry to be deleted, and interaction with a Save Changes button will cause the changes to be saved. Thus, the user interface view <b>1400</b> can be used to view or delete entries. For example, if a particular entry appears to be erroneous (e.g., the one lap time is zero), or otherwise should be removed, the user can use the user interface view <b>1400</b> to remove one or more entries.</p><p id="p-0108" num="0105"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates an example user interface <b>1500</b> illustrating output based on a computed metric according to some embodiments. The output may be displayed, for example, to an administrator (e.g., a coach) via the second user device <b>108</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The user interface <b>1500</b> shows information about a set of Users <b>1510</b> that are entities in a role, in particular, players on a sports team. The user interface <b>1500</b> displays a Coaches Dashboard <b>1502</b>, which includes a Score Leader Board section <b>1550</b> and a Score Breakdown section <b>1555</b>.</p><p id="p-0109" num="0106">The Score Leader Board section <b>1550</b> shows a list of players on the team under a User <b>1510</b> column, according to a role under a Role Name <b>1512</b> column, along with a Latest Score <b>1514</b> (e.g. a metric, which can be computed as described above with respect to step <b>1204</b> of <figref idref="DRAWINGS">FIG. <b>12</b></figref>). The Users <b>1510</b> are further assigned a Latest Ranking <b>1516</b> based on the metric. For example, as shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, a Latest Ranking <b>1516</b> of 1 is assigned to Users <b>1510</b> with the highest Latest Scores <b>1514</b>, and a Latest Ranking <b>1516</b> of 5 is assigned to Users <b>1510</b> with the lowest Latest Scores <b>1514</b>. A scale <b>1518</b> for the Latest Scores <b>1514</b> (e.g., with color coding) is also shown.</p><p id="p-0110" num="0107">The Score Breakdown section <b>1555</b> shows factors contributing to the respective scores. Entities are shown in the User <b>1510</b> column, sorted by respective Role Names <b>1512</b>. For each entity named in the User <b>1510</b> column, scores <b>1524</b> are shown, with bar chart and numeric formats to clearly show to the user how the scores compare for each entity and skill. Category Names <b>1520</b> are shown in one column, with skills in each category shown in a Field <b>1522</b> column. The appropriate Fields <b>1522</b> and Category Names <b>1520</b> vary depending on the Role Name <b>1512</b>. For example, example, the midfielders have metrics (i.e., the Latest Scores <b>1514</b> shown on the left) based on individual scores for tackle success rate, distance travelled, passing success rate, possession success rate, and shot success rate. A coach can use this information to identify key areas that need improvement and take an appropriate action such as scheduling additional training for a target entity, assign a target entity to a different role on the team, and so forth. The user interface <b>1500</b> includes drop-down menus <b>1530</b>, <b>1532</b>, and <b>1534</b> that a user can interact with to filter by User <b>1530</b>, Category Name <b>1532</b>, or Role Name <b>1534</b>. A scale <b>1536</b> for the scores <b>1524</b> (e.g., with color coding) is also shown.</p><p id="p-0111" num="0108"><figref idref="DRAWINGS">FIG. <b>16</b>A</figref>, <figref idref="DRAWINGS">FIG. <b>16</b>B</figref>, and <figref idref="DRAWINGS">FIG. <b>16</b>C</figref> illustrate additional example user interfaces <b>1602</b>, <b>1604</b>, and <b>1606</b>, respectively. The user interfaces <b>1602</b>, <b>1604</b>, and <b>1606</b> illustrate output based on a computed metric according to some embodiments.</p><p id="p-0112" num="0109">Referring to <figref idref="DRAWINGS">FIG. <b>16</b>A</figref>, the first user interface <b>1602</b> is displayed on a computing device <b>1610</b> (e.g., a desktop or laptop computer). The user interface <b>1602</b> shows a recommended intervention <b>1612</b>. Based on the ingested data, derivatives thereof, and/or computed metric, the system has determined that the target entity should improve their ability to handle stress <b>1614</b>. This recommended intervention <b>1612</b> is displayed, along with a training plan <b>1616</b> (understand the effects of stress and learn how to manage it), and e-courses <b>1618</b><i>a</i>, <b>1618</b><i>b </i>(an active coping and problem solving e-course <b>1618</b><i>a </i>and a shifting unhelpful behaviors e-course <b>1618</b><i>b</i>). The first user interface <b>1602</b> shows that the training plan has been completed, as indicated by the check box <b>1620</b>. The e-courses are associated with selectable interface elements for assigning the e-courses (assign buttons <b>1620</b><i>a</i>, <b>1620</b><i>b</i>). This first user interface <b>1602</b> can be displayed to an administrator (e.g., via second user device <b>108</b>) to manage tasks assigned to an entity in a role that has been identified as one that would benefit from improvement in a particular skill or set of skills.</p><p id="p-0113" num="0110">Referring to <figref idref="DRAWINGS">FIG. <b>16</b>B</figref>, the second user interface <b>1604</b> shows a training plan <b>1630</b>. A training plan <b>1630</b> may, for example, be displayed to a target entity that has been identified for an action to improve performance in one or more skills for a role. The second user interface <b>1604</b> shows the training plan <b>1630</b> &#x201c;understand the effects of stress and learn how to manage it,&#x201d; a progress bar <b>1632</b> indicating 100% progress, and trainings <b>1634</b> in the training plan <b>1630</b>. The trainings <b>1634</b> can be navigated through by swiping the screen. One of the trainings <b>1634</b> is shown, a video <b>1636</b> &#x201c;communicating effectively in the workplace,&#x201d; which can be played by interacting with the video embedded in the user interface <b>1604</b>. In some implementations, upon determining that the target entity should improve stress management, the system takes the action of presenting the user interface <b>1604</b> to the target entity, thereby causing the target entity to complete the training plan and improve their stress management skill level.</p><p id="p-0114" num="0111">Referring to <figref idref="DRAWINGS">FIG. <b>16</b>C</figref>, the third user interface <b>1606</b> shows a dashboard <b>1650</b>. The dashboard <b>1650</b> shows a scorecard <b>1652</b> for a target entity, Joseph M. <b>1654</b>, in the role of defender <b>1656</b>. The dashboard <b>1650</b> shows a scorecard <b>1652</b> indicating a metric <b>1660</b> computed indicating the target entity's performance in the role of defender&#x2014;55 is the metric <b>1660</b> computed for the target entity, and a goal metric value <b>1662</b> of 63 (e.g., a baseline metric corresponding to a highest performer in the role) and average metric value <b>1664</b> of 54. The dashboard <b>1650</b> also shows different skill categories for Joseph M. <b>1654</b> and corresponding scores&#x2014;80% for technical <b>1670</b>, 100% for tactical <b>1672</b>, 60% for physical <b>1674</b>, and 45% for physiological <b>1676</b>. The scores are also displayed in association with symbols&#x2014;a thumbs up <b>1680</b> indicating that the performance is on target (for technical and tactical which are above some threshold) or a caution sign <b>1682</b> indicating that the performance can use improvement (for physical and physiological which are scored below some threshold). The user interface <b>1606</b> further includes announcements <b>1690</b> (e.g., a practice update) and a to-do list <b>1692</b> (e.g., daily wellness survey and dribbling drill). The to-do list <b>1692</b> can include interventions that the system has identified as likely to improve the target entity's performance/performance metric. The dashboard <b>1650</b> can be presented to a target entity, causing the target entity to perform activities and improve their performance.</p><p id="p-0115" num="0112"><figref idref="DRAWINGS">FIG. <b>17</b></figref> illustrates another example user interface <b>1700</b> illustrating a coaches dashboard <b>1702</b> showing output based on a computed metric according to some embodiments. The output may be displayed, for example, to an administrator (e.g., a coach) via the second user device <b>108</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The user interface <b>1700</b> shows information about a set of entities in a role, in particular, players on a sports team. The user interface <b>1700</b> shows an impact vs. playing time <b>1704</b> for each player <b>1706</b>. A role <b>1708</b> is shown for each player <b>1706</b>.</p><p id="p-0116" num="0113">The user interface <b>1700</b> shows minutes played <b>1710</b> for each player <b>1706</b>, indicating the correlation between the minutes played <b>1710</b> and the computed metric for each player <b>1706</b>, as indicated by the ranked scores <b>1712</b> and raw scores <b>1714</b> for each player <b>1706</b>. This allows the administrator to drill down to see how each player is being utilized and reshuffle as appropriate. For example, a coach may see that one of the best players is spending a lot of time on the bench and take action to increase the playing time for that player. Alternatively, or additionally, the system can perform such actions automatically, e.g., by updating an electronic calendar or modifying a starting lineup in an electronic document. On hover <b>1720</b>, the user interface <b>1700</b> transitions to show additional information about a selected data element&#x2014;here, the hover <b>1720</b> is on the minutes played for Theun Leclerc, and a pop-up shows information for that player.</p><p id="p-0117" num="0114">It should be appreciated that the computing system for performance management may have one or more microprocessors/processing devices that can further be a component of the overall apparatuses. The control systems are generally proximate to their respective devices, in electronic communication (wired or wireless) and can also include a display interface and/or operational controls configured to be handled by a user to monitor the respective systems, to change configurations of the respective systems, and to operate, directly guide, or set programmed instructions for the respective systems, and sub-portions thereof. Such processing devices can be communicatively coupled to a non-volatile memory device via a bus. The non-volatile memory device may include any type of memory device that retains stored information when powered off. Non-limiting examples of the memory device include electrically erasable programmable read-only memory (&#x201c;ROM&#x201d;), flash memory, or any other type of non-volatile memory. In some aspects, at least some of the memory device can include a non-transitory medium or memory device from which the processing device can read instructions. A non-transitory computer-readable medium can include electronic, optical, magnetic, or other storage devices capable of providing the processing device with computer-readable instructions or other program code. Non-limiting examples of a non-transitory computer-readable medium include (but are not limited to) magnetic disk(s), memory chip(s), ROM, random-access memory (&#x201c;RAM&#x201d;), an ASIC, a configured processor, optical storage, and/or any other medium from which a computer processor can read instructions. The instructions may include processor-specific instructions generated by a compiler and/or an interpreter from code written in any suitable computer-programming language, including, for example, C, C++, C #, Java, Python, Perl, JavaScript, etc.</p><p id="p-0118" num="0115">While the above description describes various embodiments of the invention and the best mode contemplated, regardless of how detailed the above text, the invention can be practiced in many ways. Details of the system may vary considerably in its specific implementation, while still being encompassed by the present disclosure. As noted above, particular terminology used when describing certain features or aspects of the invention should not be taken to imply that the terminology is being redefined herein to be restricted to any specific characteristics, features, or aspects of the invention with which that terminology is associated. In general, the terms used in the following claims should not be construed to limit the invention to the specific examples disclosed in the specification, unless the above Detailed Description section explicitly defines such terms. Accordingly, the actual scope of the invention encompasses not only the disclosed examples, but also all equivalent ways of practicing or implementing the invention under the claims.</p><p id="p-0119" num="0116">The teachings of the invention provided herein can be applied to other systems, not necessarily the system described above. The elements and acts of the various examples described above can be combined to provide further implementations of the invention. Some alternative implementations of the invention may include not only additional elements to those implementations noted above, but also may include fewer elements. Further any specific numbers noted herein are only examples; alternative implementations may employ differing values or ranges, and can accommodate various increments and gradients of values within and at the boundaries of such ranges.</p><p id="p-0120" num="0117">References throughout the foregoing description to features, advantages, or similar language do not imply that all of the features and advantages that may be realized with the present technology should be or are in any single embodiment of the invention. Rather, language referring to the features and advantages is understood to mean that a specific feature, advantage, or characteristic described in connection with an embodiment is included in at least one embodiment of the present technology. Thus, discussion of the features and advantages, and similar language, throughout this specification may, but do not necessarily, refer to the same embodiment. Furthermore, the described features, advantages, and characteristics of the present technology may be combined in any suitable manner in one or more embodiments. One skilled in the relevant art will recognize that the present technology can be practiced without one or more of the specific features or advantages of a particular embodiment. In other instances, additional features and advantages may be recognized in certain embodiments that may not be present in all embodiments of the present technology.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer-implemented method comprising:<claim-text>receiving, by a server computer from a remote device, input data associated with a performance of a target entity in a role in an organization;</claim-text><claim-text>receiving, by the server computer via input to a Graphical User Interface (GUI), a set of weights for a respective set of skills for the role;</claim-text><claim-text>computing, by the server computer, a metric based on the input data and the weights, the metric representing the performance in the role for the target entity;</claim-text><claim-text>identifying, by the server computer, an action likely to improve the metric; and</claim-text><claim-text>triggering, by the server computer, the action.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein triggering the action comprises one or more of:<claim-text>modifying an entry on a calendar for the target entity to include an identified task to improve the metric;</claim-text><claim-text>transmitting an electronic mail (email) message including the metric and at least a subset of the input data or a derivative thereof;</claim-text><claim-text>displaying a second GUI including the metric and at least a subset of the input data or a derivative thereof; or</claim-text><claim-text>transmitting a suggestion thereby causing the target entity to perform the action.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the input data includes one or more of:<claim-text>biometric data received from a wearable device that collected the biometric data from the target entity;</claim-text><claim-text>performance data received from a computing device that analyzed performance of the target entity; or</claim-text><claim-text>survey or test data received from a user device that received responses from the target entity.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the biometric data comprises one or more of heartrate data or blood oxygenation data.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>displaying the GUI, the GUI comprising one or more interactive elements for modifying the weights;</claim-text><claim-text>receiving, via the one or more interactive elements, user input modifying the weights; and</claim-text><claim-text>updating the weights based upon the user input.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein computing the metric comprises:<claim-text>identifying, by the server computer, a first skill value for a first skill for a second entity;</claim-text><claim-text>incrementing, by the server computer, the first skill value according to a predetermined margin to generate a first baseline value;</claim-text><claim-text>identifying, by the server computer, a second skill value for the first skill for the target entity; and</claim-text><claim-text>computing, by the server computer, a percentage of the first baseline value for the second skill value.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein computing the metric further comprises:<claim-text>identifying, by the server computer, a third skill value for a second skill for a third entity;</claim-text><claim-text>incrementing, by the server computer, the third skill value according to the predetermined margin to generate a second baseline value;</claim-text><claim-text>identifying, by the server computer, a fourth skill value for the second skill for the target entity;</claim-text><claim-text>computing, by the server computer, a percentage of the second baseline value for the fourth skill value; and</claim-text><claim-text>computing, by the server computer, the metric based on the percentage of the first baseline value and the percentage of the second baseline value.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>displaying, via a third GUI, performance metrics for a plurality of entities including the target entity and an attribute for each entity of the plurality of entities,</claim-text><claim-text>thereby causing a modification of the attribute for at least a subset of the plurality of entities.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>displaying, via a fourth GUI, an interactive element for configuring a source of the input data; and</claim-text><claim-text>receiving, via the fourth GUI, user input configuring the source of the input data,</claim-text><claim-text>wherein the input data is retrieved and stored by the server computer based on the configured source.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least a subset of the input data is retrieved from a Global Positioning System (GPS).</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A computing system comprising:<claim-text>a processor; and</claim-text><claim-text>a non-transitory computer readable medium operatively coupled to the processor, the non-transitory computer readable medium comprising code executable by the processor for performing a method comprising:</claim-text><claim-text>receiving, by a server computer from a remote device, input data associated with a performance of a target entity in a role in an organization;</claim-text><claim-text>receiving, by the server computer via input to a Graphical User Interface (GUI), a set of weights for a respective set of skills for the role;</claim-text><claim-text>computing, by the server computer, a metric based on the input data and the weights, the metric representing the performance in the role for the target entity;</claim-text><claim-text>identifying, by the server computer, an action likely to improve the metric; and</claim-text><claim-text>triggering, by the server computer, the action.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The computing system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein triggering the action comprises one or more of:<claim-text>modifying an entry on a calendar for the target entity to include an identified task to improve the metric;</claim-text><claim-text>transmitting an electronic mail (email) message including the metric and at least a subset of the input data or a derivative thereof;</claim-text><claim-text>displaying a second GUI including the metric and at least a subset of the input data or a derivative thereof; or</claim-text><claim-text>transmitting a suggestion thereby causing the target entity to perform the action.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The computing system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the input data includes one or more of:<claim-text>biometric data received from a wearable device that collected the biometric data from the target entity;</claim-text><claim-text>performance data received from a computing device that analyzed performance of the target entity; or</claim-text><claim-text>survey or test data received from a user device that received responses from the target entity.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The computing system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the biometric data comprises one or more of heartrate data or blood oxygenation data.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The computing system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, the method further comprising:<claim-text>displaying the GUI, the GUI comprising one or more interactive elements for modifying the weights;</claim-text><claim-text>receiving, via the one or more interactive elements, user input modifying the weights; and</claim-text><claim-text>updating the weights based upon the user input.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The computing system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein computing the metric comprises:<claim-text>identifying, by the server computer, a first skill value for a first skill for a second entity;</claim-text><claim-text>incrementing, by the server computer, the first skill value according to a predetermined margin to generate a first baseline value;</claim-text><claim-text>identifying, by the server computer, a second skill value for the first skill for the target entity; and</claim-text><claim-text>computing, by the server computer, a percentage of the first baseline value for the second skill value.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The computing system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein computing the metric further comprises:<claim-text>identifying, by the server computer, a third skill value for a second skill for a third entity;</claim-text><claim-text>incrementing, by the server computer, the third skill value according to the predetermined margin to generate a second baseline value;</claim-text><claim-text>identifying, by the server computer, a fourth skill value for the second skill for the target entity;</claim-text><claim-text>computing, by the server computer, a percentage of the second baseline value for the fourth skill value; and</claim-text><claim-text>computing, by the server computer, the metric based on the percentage of the first baseline value and the percentage of the second baseline value.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The computing system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, the method further comprising:<claim-text>displaying, via a third GUI, performance metrics for a plurality of entities including the target entity and an attribute for each entity of the plurality of entities,</claim-text><claim-text>thereby causing a modification of the attribute for at least a subset of the plurality of entities.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The computing system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, the method further comprising:<claim-text>displaying, via a fourth GUI, an interactive element for configuring a source of the input data; and</claim-text><claim-text>receiving, via the fourth GUI, user input configuring the source of the input data,</claim-text><claim-text>wherein the input data is retrieved and stored by the server computer based on the configured source.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The computing system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising a Global Positioning System (GPS) from which at least a subset of the input data is retrieved.</claim-text></claim></claims></us-patent-application>
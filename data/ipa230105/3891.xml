<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003892A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003892</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17930979</doc-number><date>20220909</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-041095</doc-number><date>20200310</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>89</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>89</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><invention-title id="d2e61">OBJECT RECOGNITION DEVICE</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/008187</doc-number><date>20210303</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17930979</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>DENSO CORPORATION</orgname><address><city>Kariya-city</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>TAKAGI</last-name><first-name>Masanari</first-name><address><city>Kariya-city</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An object recognition device includes a recognition unit and an object determination unit. The object determination unit includes a detection unit, an estimation unit, and a pseudo-determination unit. The estimation unit assumes that a shielding object is a vehicle and estimates a length of a side surface of the shielding object based on the width of the shielding object. The pseudo-determination unit determines whether a candidate object is a pseudo-object by using the length of the side surface. The pseudo-determination unit determines that the candidate object is the pseudo-object, if it is determined that transmission waves radiated in a direction in which the candidate object is located are reflected from the side surface and if another object is recognized at a location apart from a reflection point in a reflection direction by the same distance as a distance from the reflection point to the candidate object.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="120.57mm" wi="131.32mm" file="US20230003892A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="136.40mm" wi="133.35mm" file="US20230003892A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="134.37mm" wi="95.17mm" file="US20230003892A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="209.38mm" wi="151.21mm" file="US20230003892A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="159.43mm" wi="113.79mm" file="US20230003892A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="194.23mm" wi="71.29mm" file="US20230003892A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="193.89mm" wi="72.05mm" file="US20230003892A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="193.89mm" wi="71.88mm" file="US20230003892A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">The present application is based on and claims the benefit of priority from earlier Japanese Patent Application No. 2020-41095 filed on Mar. 10, 2020, the description of which is incorporated herein by reference.</p><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Technical Field</heading><p id="p-0003" num="0002">The present disclosure relates to an object recognition device.</p><heading id="h-0004" level="1">Related Art</heading><p id="p-0004" num="0003">An object recognition device is known which recognizes an object based on reflected waves of radiated electromagnetic waves.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0005" num="0004">An aspect of the present disclosure provides an object recognition device, including: a recognition unit configured to radiate transmission waves in a plurality of radiation directions and receive reflected waves of the transmission waves to recognize objects; and an object determination unit configured to determine whether a candidate object, which is one of the objects recognized by the recognition unit, is a pseudo-object erroneously recognized due to the transmission waves reflected from a side surface of a shielding object, which is present on a near side of the candidate object.</p><p id="p-0006" num="0005">The object determination unit includes: a detection unit configured to detect a width of the shielding object; an estimation unit configured to assume that the shielding object is a vehicle and estimate a length of the side surface of the shielding object based on the width of the shielding object detected by the detection unit; and a pseudo-determination unit configured to determine whether the candidate object is the pseudo-object by using the length of the side surface of the shielding object estimated by the estimation unit.</p><p id="p-0007" num="0006">The pseudo-determination unit is configured to determine that the candidate object is the pseudo-object, if it is determined that the transmission waves radiated in a direction in which the candidate object is located are reflected from the side surface of the shielding object and if another object is recognized at a location apart from a reflection point in a reflection direction by the same distance as a distance from the reflection point to the candidate object.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0008" num="0007">In the accompanying drawings:</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating a configuration of a lidar device;</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flowchart of an object recognition process;</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart of side surface length setting processing of the object recognition process;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of pseudo-determination processing of the object recognition process;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic diagram illustrating an example in which an own vehicle and objects recognized by the object recognition process are viewed from above;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic diagram illustrating another example in which an own vehicle and objects recognized by the object recognition process are viewed from above; and</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a schematic diagram illustrating still another example in which an own vehicle and objects recognized by the object recognition process are viewed from above.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading><p id="p-0016" num="0015">An object recognition device is known which recognizes an object based on reflected waves of radiated electromagnetic waves.</p><p id="p-0017" num="0016">As disclosed in JP 2014-119285 A, this kind of object recognition device may erroneously recognize an object due to a multipath phenomenon. For example, when the radiated electromagnetic waves are reflected from a side surface of an object and are thereafter reflected from another object, and are then received as reflected waves, it is erroneously recognized that an object is present in the radiation direction of the electromagnetic waves in which the object is not present actually.</p><p id="p-0018" num="0017">To determine whether the recognized object is an object erroneously recognized due to a multipath phenomenon, a technique can be considered which is for determining whether electromagnetic waves radiated in the direction in which the object is located have been reflected from a side surface of a shielding object, which is present on the near side of the erroneously recognized object, and another object is present in the reflection direction. However, as a result of detailed studies by the inventor, a problem was found that since the length the side surface of the shielding object may not be appropriately detected due to, for example, a positional relationship between the shielding object and a vehicle in which the object recognition device is installed, the determination technique described above may not be able to appropriately determine whether the recognized object is an object erroneously recognized due to a multipath phenomenon.</p><p id="p-0019" num="0018">An aspect of the present disclosure provides an object recognition device that can determine whether a recognized object is an object erroneously recognized due to a multipath phenomenon even when a length of a side surface of a shielding object cannot be appropriately detected.</p><p id="p-0020" num="0019">Hereinafter, exemplary embodiments of the present disclosure will be described with reference to the drawings.</p><heading id="h-0008" level="1">1. Configuration</heading><p id="p-0021" num="0020">A lidar device <b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> radiates laser light (transmission waves) and receives reflected light (reflected waves) thereof to recognize an object. The lidar device <b>1</b> is, for example, installed in a vehicle and is used for recognizing various objects present around the vehicle. Hereinafter, the vehicle in which the lidar device <b>1</b> is installed is referred to as an own vehicle. Lidar is also written as LIDAR. LIDAR is an abbreviation for Light Detection and Ranging.</p><p id="p-0022" num="0021">As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the lidar device <b>1</b> includes a radiation unit <b>10</b>, a light-receiving unit <b>20</b>, and a control unit <b>30</b>.</p><p id="p-0023" num="0022">The radiation unit <b>10</b> radiates laser light to a predetermined radiation region based on an instruction from the control unit <b>30</b>. The radiation region extends ahead of the vehicle in a predetermined angular range in the horizontal direction and the perpendicular direction. The radiation unit <b>10</b> radiates laser light to a plurality of radiation divisions obtained by dividing the radiation region in the horizontal direction and the perpendicular direction to radiate the laser light to the whole of the radiation region.</p><p id="p-0024" num="0023">The light-receiving unit <b>20</b> receives the reflected light of the laser light radiated from the radiation unit <b>10</b>. The light-receiving unit <b>20</b> converts the received reflected light into an electrical signal and outputs the electrical signal to the control unit <b>30</b>.</p><p id="p-0025" num="0024">The control unit <b>30</b> is mainly configured by a well-known microcomputer including a CPU <b>31</b>, a RAM <b>32</b>, a ROM <b>33</b>, and a flash memory <b>34</b>. Functions of the control unit <b>30</b> are implemented by executing a program stored in a non-transitory tangible storage medium. In this example, the ROM <b>33</b> corresponds to the non-transitory tangible storage medium. Executing the program implements a method corresponding to the program. The control unit <b>30</b> may include one microcomputer or a plurality of microcomputers.</p><heading id="h-0009" level="1">2. Processing</heading><p id="p-0026" num="0025">Next, an object recognition process performed by the CPU <b>31</b> of the control unit <b>30</b> will be described with reference to a flowchart illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. On termination of scanning with laser light in one cycle, the CPU <b>31</b> starts the object recognition process. The termination of scanning with laser light in one cycle indicates that radiation of laser light by the radiation unit <b>10</b> to the whole of the radiation region is completed.</p><p id="p-0027" num="0026">First, in S<b>101</b>, the CPU <b>31</b> acquires reflection point information. The reflection point information includes information indicating a reflection point, which is a point from which laser light is reflected, for example, information indicating a direction of radiation of the laser light related to the reflection point and a distance from the lidar device <b>1</b> to the reflection point. In S<b>101</b>, the CPU <b>31</b> acquires reflection point information on all reflection points acquired by scanning with laser light in one cycle.</p><p id="p-0028" num="0027">Next, in S<b>102</b>, the CPU <b>31</b> performs clustering for all the reflection points based on the reflection point information acquired in S<b>101</b> to form a cluster point group, and recognizes the formed cluster point group as an object.</p><p id="p-0029" num="0028">Then, in S<b>103</b>, the CPU <b>31</b> determines whether the number of the objects recognized in S<b>102</b> is three or more. In S<b>103</b>, if determining that the number of the objects recognized in S<b>102</b> is not three or more, that is, if determining that the number of the recognized objects is two or less, the CPU <b>31</b> terminates the object recognition process.</p><p id="p-0030" num="0029">In contrast, in S<b>103</b>, if determining that the number of the objects recognized in S<b>102</b> is three or more, the CPU <b>31</b> proceeds to S<b>104</b> to perform side surface length setting processing. The side surface length setting processing sets, as described later in detail, a length of the side surface of each of the objects recognized in S<b>102</b>.</p><p id="p-0031" num="0030">Next, in S<b>105</b>, the CPU <b>31</b> performs pseudo-determination processing. The pseudo-determination processing determines, as described later in detail, whether each of the objects recognized in S<b>102</b> is a pseudo-object due to a multipath phenomenon. The pseudo-object due to a multipath phenomenon is an object erroneously recognized in S<b>102</b> due to laser light reflected from a side surface of another object present at a location nearer the lidar device <b>1</b>.</p><p id="p-0032" num="0031">On termination of S<b>105</b>, the CPU <b>31</b> terminates the object recognition process.</p><p id="p-0033" num="0032">Next, the side surface length setting processing of the object recognition process will be described with reference to a flowchart illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0034" num="0033">First, in S<b>201</b>, the CPU <b>31</b> performs processing from S<b>202</b> to S<b>208</b> described later for all the objects recognized in S<b>102</b> to determine whether a length of a side surface has been set. If determining that a length of a side surface has been set for all the objects in S<b>201</b>, the CPU <b>31</b> terminates the side surface length setting processing.</p><p id="p-0035" num="0034">In contrast, if determining that a length of a side surface is not set for all the objects in S<b>201</b>, that is, there is an object for which a length of a side surface is not set yet, the CPU <b>31</b> proceeds to S<b>202</b>.</p><p id="p-0036" num="0035">In S<b>202</b>, the CPU <b>31</b> selects, as a target object, one object for which a length of a side surface is not set yet, from among the plurality of objects recognized in S<b>102</b>. Then, the CPU <b>31</b> detects information regarding the width of the target object based on reflection points belonging to the cluster point group of the target object. Specifically, in the present embodiment, the CPU <b>31</b> detects the width of the target object as information regarding the width of the target object, that is, the length of the target object in the width direction. The CPU <b>31</b> may employ, as a detection value of the width of the target object, for example, the following values (a) to (c). (a) A width of the target object detected from a result of scanning in one cycle, a so-called instantaneous value. (b) An average value obtained by averaging the widths of the target object detected from respective results of scanning in a plurality of cycles. (c) The maximum value among widths of the target object detected from results of scanning in a plurality of cycles. In the present embodiment, the CPU <b>31</b> employs the average value in the above (b) as a detection value of the width of the target object.</p><p id="p-0037" num="0036">Next, in S<b>203</b>, the CPU <b>31</b> estimates the length of a side surface of the target object in a case in which the target object is assumed to be a vehicle, based on the width of the target object detected in S<b>202</b>.</p><p id="p-0038" num="0037">Specifically, the CPU <b>31</b> checks the width of the target object detected in S<b>202</b> against a table previously stored in the flash memory <b>34</b> to estimate the length of the side surface of the target object. The table previously stored in the flash memory <b>34</b> indicates a relationship between a vehicle width and a vehicle length. For each classified vehicle, a vehicle width and a vehicle length are defined. For example, a small-sized passenger vehicle has a vehicle width of approximately 1.4 m and a vehicle length of approximately 3.4 m. For example, a standard-sized passenger vehicle has a vehicle width of approximately 1.8 m and a vehicle length of approximately 4.8 m. For example, a truck has a vehicle width of approximately 2.5 m and a vehicle length of approximately 10 m. The flash memory <b>34</b> stores, for example, a table indicating a relationship between a vehicle width and a vehicle length, such that when the vehicle width is shorter than 1.5 m, the corresponding vehicle length is 3.4 m, when the vehicle width is 1.5 m or longer and shorter than 2.1 m, the corresponding vehicle length is 4.8 m, and when the vehicle width is 2.1 m or longer, the corresponding vehicle length is 10 m. The CPU <b>31</b> assumes that the target object is a vehicle and checks the table against the width of the target object detected in S<b>202</b> to estimate the length of the side surface of the target object corresponding to the vehicle length. Hereinafter, the length of the side surface of the target object estimated in S<b>203</b> is also referred to as an estimated length.</p><p id="p-0039" num="0038">Next, in S<b>204</b>, the CPU <b>31</b> detects information regarding the side surface of the target object based on reflection points belonging to the cluster point group of the target object. Specifically, in the present embodiment, the CPU <b>31</b> detects the length of the side surface of the target object as information regarding the side surface of the target object.</p><p id="p-0040" num="0039">Whether the length of the side surface of the target object can be appropriately detected depends on the positional relationship between the target object and the own vehicle or the like. For example, when the target object is located diagonally in front of the own vehicle, laser light is easily reflected from the side surface of the target object. Hence, the length of the side surface of the target object can be appropriately detected. In contrast, for example, when the target object is located directly in front of the own vehicle, laser light is rarely reflected from the side surface of the target object. Hence, the length of the side surface of the target object is difficult to appropriately detect. As described above, since there is a case in which the length of the side surface of the target object can be appropriately detected and a case in which the length of the side surface of the target object is difficult to appropriately detect, detection values of the length of the side surface of the target object may vary.</p><p id="p-0041" num="0040">Thus, in the present embodiment, the maximum value among the lengths of the side surface of the target object detected from respective results of scanning in a plurality of cycles is employed as a detection value of the length of the side surface of the target object. By employing the maximum value, pseudo-determination processing described later in detail is performed on condition that a multipath phenomenon is easily caused, whereby erroneous recognition of an object due to a multipath phenomenon is not easily overlooked. This is because although a multipath phenomenon is likely to occur when the radiated laser light is reflected from the side surface of the target object, it can be considered that as the side surface of the target object is longer, the side surface is more highly likely to reflect the radiated laser light. Hereinafter, the length of the side surface of the target object detected in S<b>204</b> is also referred to as a detected length.</p><p id="p-0042" num="0041">Next, in S<b>205</b>, the CPU <b>31</b> determines whether the detected length is longer than the estimated length.</p><p id="p-0043" num="0042">If determining that the detected length is longer than the estimated length in S<b>205</b>, the CPU <b>31</b> proceeds to S<b>206</b> and sets the detected length as a length of the side surface of the target object.</p><p id="p-0044" num="0043">In contrast, if determining that the detected length is not longer than the estimated length in S<b>205</b>, that is, the detected length is equal to or shorter than the estimated length, the CPU <b>31</b> proceeds to S<b>207</b> and sets the detected length as a length of the side surface of the target object.</p><p id="p-0045" num="0044">In S<b>208</b>, the CPU <b>31</b> estimates an orientation of the side surface of the target object. Specifically, in the present embodiment, the CPU <b>31</b> estimates, as an orientation of the side surface of the target object, a moving direction of the target object, that is, a traveling direction of the target object when the target object is assumed to be a vehicle. The moving direction of the target object is calculated from change with time of a location of the target object with respect to the own vehicle.</p><p id="p-0046" num="0045">On termination of S<b>208</b>, the CPU <b>31</b> returns the process to S<b>201</b>.</p><p id="p-0047" num="0046">Next, pseudo-determination processing of the object recognition process will be described with reference to a flowchart illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> and schematic diagrams illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> to <figref idref="DRAWINGS">FIG. <b>7</b></figref>. <figref idref="DRAWINGS">FIG. <b>5</b></figref> to <figref idref="DRAWINGS">FIG. <b>7</b></figref> are schematic diagrams illustrating examples of locations of the own vehicle and recognized three objects viewed from above when the objects are recognized in S<b>102</b>. In <figref idref="DRAWINGS">FIG. <b>5</b></figref> to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the own vehicle is denoted by vehicle V<b>1</b>, and the recognized three objects are respectively denoted by object T<b>1</b>, object T<b>2</b>, and object T<b>3</b>. Each of the objects is indicated by a solid-line rectangle</p><p id="p-0048" num="0047">The pseudo-determination processing determines whether the recognized object is a pseudo-object due to a multipath phenomenon. This determination is performed on a two-dimensional plane on which the own vehicle and the recognized object are projected when viewed from above.</p><p id="p-0049" num="0048">First, in S<b>301</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the CPU <b>31</b> performs processing of S<b>302</b> to S<b>304</b> described later for all the objects recognized in S<b>102</b> to determine whether the determination whether the recognized object is a pseudo-object due to a multipath phenomenon has been completed. If determining that, for all the recognized objects, the determination whether the recognized object is a pseudo-object has been completed in S<b>301</b>, the CPU <b>31</b> terminates the pseudo-determination processing.</p><p id="p-0050" num="0049">In contrast, if determining that, for all the recognized objects, the determination whether the recognized object is a pseudo-object has not been not completed in S<b>301</b>, that is, if determining that there is a recognized object for which the determination whether the recognized object is a pseudo-object is not yet completed, the CPU <b>31</b> proceeds to S<b>302</b>.</p><p id="p-0051" num="0050">In S<b>302</b>, the CPU <b>31</b> selects, as a candidate object, one object for which the determination whether the recognized object is a pseudo-object is not yet completed, among the plurality of objects recognized in S<b>102</b>. Then, the CPU <b>31</b> determines whether the laser light radiated in the direction, in which the candidate object is located, has been reflected from a side surface of another object.</p><p id="p-0052" num="0051">Specifically, the CPU <b>31</b> first determines whether another object is present between the candidate object and the own vehicle. In examples illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, for example, if object T<b>1</b> is selected as the candidate object, it is determined that object T<b>2</b> is present between vehicle V<b>1</b> and object T<b>1</b>. Hereinafter, another object determined to be present between the candidate object and the own vehicle is also referred to as a shielding object.</p><p id="p-0053" num="0052">If determining that a shielding object is present, the CPU <b>31</b> next determines, on a two-dimensional plane on which the own vehicle and the recognized object are projected when viewed from above, assuming that the shielding object has a rectangular shape having a side surface having a length set by the side surface length setting processing and an orientation estimated by the side surface length setting processing, whether the side surface on the own vehicle side of the shielding object intersects a straight line connecting the candidate object and the own vehicle. The straight line connecting the candidate object and the own vehicle is a straight line connecting one point of the candidate object and a reference point predetermined in the lidar device <b>1</b> installed in the own vehicle. In <figref idref="DRAWINGS">FIG. <b>5</b></figref> to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, point P<b>3</b> is one point of the object T<b>1</b>. Point P<b>1</b> is the reference point of the lidar device <b>1</b> installed in vehicle V<b>1</b>. Broken line Y connecting point P<b>1</b> and point P<b>3</b> corresponds to the above straight line. Arrow X in <figref idref="DRAWINGS">FIG. <b>5</b></figref> to <figref idref="DRAWINGS">FIG. <b>7</b></figref> indicates a traveling direction of object T<b>2</b>, and a solid-line rectangle is a shape assuming object T<b>2</b>.</p><p id="p-0054" num="0053">One point of the candidate object may be, for example, one of a plurality of reflection points belonging a cluster point group recognized as the candidate object, a center point of reflection points selected from among the plurality of reflection points, or a center point of all the reflection points. The CPU <b>31</b> may determine whether the straight line connecting the candidate object and the own vehicle intersects the side surface on the own vehicle side of the shielding object, based on one point of the candidate object, or whether straight lines connecting respective plurality of points of the candidate object and the own vehicle intersect the side surface on the own vehicle side of the shielding object. In the latter case, the CPU <b>31</b> may determine that the straight lines intersect the side surface on the own vehicle side of the shielding object, if at least one of the straight lines intersects the side surface on the own vehicle side of the shielding object, or if a predetermined number or more of the straight lines intersect the side surface on the own vehicle side of the shielding object. If determining that the straight line connecting the candidate object and the own vehicle intersects the side surface on the own vehicle side of the shielding object, the CPU <b>31</b> determines that the laser light radiated in the direction, in which the candidate object is located, has been reflected from the side surface of the shielding object. In the examples illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, since the side surface on the vehicle V<b>1</b> side of object T<b>2</b> intersects broken line Y at point P<b>2</b>, it is determined that the laser light radiated in the direction, in which object T<b>1</b> is located, has been reflected from the side surface of object T<b>2</b>.</p><p id="p-0055" num="0054">Returning back to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, in S<b>302</b>, if determining that the laser light radiated in the direction, in which the candidate object is located, has not been reflected from the side surface of the shielding object, the CPU <b>31</b> returns the process to S<b>301</b>.</p><p id="p-0056" num="0055">In contrast, in S<b>302</b>, if determining that the laser light radiated in the direction, in which the candidate object is located, has been reflected from the side surface of the shielding object, the CPU <b>31</b> proceeds to S<b>303</b>.</p><p id="p-0057" num="0056">In S<b>303</b>, the CPU <b>31</b> determines whether an object other than the shielding object is present at a real image position. The real image position is apart from a reflection position on the side surface of the shielding object in the reflection direction by the same distance as a distance from the reflection position to the candidate object. The reflection position on the side surface of the shielding object is a reflection position of laser light on the side surface of the shielding object determined, in S<b>302</b>, to reflect the laser light radiated in the direction in which the shielding object is located. In <figref idref="DRAWINGS">FIG. <b>5</b></figref> to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, point P<b>2</b> corresponds to the reflection position. The reflection direction is a direction in which the laser light reflected from the reflection position travels in a straight line.</p><p id="p-0058" num="0057">In <figref idref="DRAWINGS">FIG. <b>5</b></figref> to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the direction indicated by arrow Z corresponds to the reflection direction. Point P<b>4</b> corresponds to the real image position. That is, in <figref idref="DRAWINGS">FIG. <b>5</b></figref> to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the distance from point P<b>2</b> to point P<b>3</b> and the distance from point P<b>2</b> to point P<b>4</b> are equal. In S<b>303</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, for example, the CPU <b>31</b> may determine that an object related to a cluster point group is present at the real image position when at least one of reflection points belonging to the cluster point group is located within a predetermined radius centering on the real image position. In the examples illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, since object T<b>3</b> is present at point P<b>4</b>, it is determined that an object other than the shielding object is present at the real image position. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, since no object is present at point P<b>4</b>, it is determined that no object is present at the real image position.</p><p id="p-0059" num="0058">Returning back to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, in S<b>303</b>, if determining that no other object is present at the real image position, the CPU <b>31</b> returns the process to S<b>301</b>.</p><p id="p-0060" num="0059">In contrast, in S<b>303</b>, if determining that another object is present at the real image position, the CPU <b>31</b> proceeds to S<b>304</b>.</p><p id="p-0061" num="0060">In S<b>304</b>, the CPU <b>31</b> determines that the candidate object is a pseudo-object due to a multipath phenomenon and cancels the recognition for the candidate object. In the examples illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the recognition for object T<b>1</b> is canceled.</p><p id="p-0062" num="0061">On termination of S<b>304</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the CPU <b>31</b> returns the process to S<b>301</b>.</p><heading id="h-0010" level="1">3. Effects</heading><p id="p-0063" num="0062">According to the embodiment described above in detail, the following effects are provided.</p><p id="p-0064" num="0063">(3a) The lidar device <b>1</b> is configured to assume that a shielding object is a vehicle and estimate a length of a side surface of the shielding object based on the width of the shielding object. The lidar device <b>1</b> is configured to use the estimated length of the side surface of the shielding object to determine whether a candidate object is a pseudo-object. The lidar device <b>1</b> is configured to determine that the candidate object is a pseudo-object, if determining that laser light radiated in the direction, in which the candidate object is located, has been reflected from the side surface of the shielding object, and having recognized another object at a location apart from a reflection position in the reflection direction by the same distance as a distance from the reflection position to the candidate object.</p><p id="p-0065" num="0064">According to the configuration described above, even when the length of the side surface of the shielding object cannot be appropriately detected, it can be determined whether the recognized object is an object erroneously recognized due to a multipath phenomenon.</p><p id="p-0066" num="0065">(3b) The lidar device <b>1</b> is further configured to estimate an orientation of the side surface of the shielding object. The lidar device <b>1</b> is configured to use the estimated length and orientation of the side surface of the shielding object to determine whether the candidate object is a pseudo-object.</p><p id="p-0067" num="0066">According to the configuration described above, the reflection direction of laser light can be estimated more appropriately. Hence, it can be determined more appropriately whether the recognized object is an object erroneously recognized due to a multipath phenomenon.</p><p id="p-0068" num="0067">(3c) The lidar device <b>1</b> is further configured to estimate that the traveling direction of the shielding object is the orientation of the side surface of the target object. In addition, the lidar device <b>1</b> is configured to use the estimated length and orientation of the side surface of the shielding object to determine whether the candidate object is a pseudo-object.</p><p id="p-0069" num="0068">According to the configuration described above, the reflection direction of laser light can be estimated more appropriately. Hence, it can be determined more appropriately whether the recognized object is an object erroneously recognized due to a multipath phenomenon.</p><p id="p-0070" num="0069">(3d) The lidar device <b>1</b> is further configured to detect a length of the side surface of the shielding object. The lidar device <b>1</b> is configured to use any one of the detected length of the side surface of the shielding object and the estimated length of the side surface of the shielding object to determine whether the candidate object is a pseudo-object.</p><p id="p-0071" num="0070">According to the configuration described above, it can be more appropriately determined whether laser light radiated in the direction, in which the candidate object is located, has been reflected from a side surface of another object. Hence, it can be determined more appropriately whether the recognized object is an object erroneously recognized due to a multipath phenomenon.</p><heading id="h-0011" level="1">4. Other Embodiments</heading><p id="p-0072" num="0071">The present disclosure is not limited to the above embodiment and can be variously modified.</p><p id="p-0073" num="0072">(4a) In the above embodiment, in S<b>204</b> of the side surface length setting processing, the CPU <b>31</b> detects, as information regarding a side surface of a target object, a length of the side surface of the target object, based on reflection points belonging to a cluster point group of the target object. However, the CPU <b>31</b> may further detect a longitudinal direction of the side surface of the target object as information regarding the side surface of the target object. If detecting the longitudinal direction of the side surface of the target object as information regarding the side surface of the target object, in S<b>208</b> of the side surface length setting processing, the CPU <b>31</b> may estimate the longitudinal direction of the side surface of the detected target object as an orientation of the side surface of the target object. By employing the above estimation method, for example, even when the target object is a stationary body, specifically, even when the target object is a roadside object such as a side wall, the orientation of the side surface of the target object can be estimated.</p><p id="p-0074" num="0073">(4b) In the above embodiment, in S<b>202</b> of the side surface length setting processing, the CPU <b>31</b> detects a width of the target object as information regarding the width of the target object, based on reflection points belonging to the cluster point group of the target object. However, the CPU <b>31</b> may further detect a width direction of the target object as the information regarding the width of the target object. When a width direction of the target object is detected as the information regarding the width of the target object, in S<b>208</b> of the side surface length setting processing, the CPU <b>31</b> may estimate the direction perpendicular to the width direction of the detected target object as an orientation of the side surface of the target object. By employing the above estimation method, for example, even when the target object is a stationary body, the orientation of the side surface can be estimated. In addition, for example, even when a longitudinal direction of the side surface of the target object is difficult to appropriately detect for the same reason as that, as described above, when a length of the side surface of the target object is difficult to appropriately detect, the orientation of the side surface of the target object can be estimated.</p><p id="p-0075" num="0074">(4c) In the above embodiment, in S<b>204</b> of the side surface length setting processing, the CPU <b>31</b> employs, as a detection value of the length of the side surface of the target object, the maximum value among the lengths of the side surface of the target object detected from respective results of scanning in a plurality of cycles. However, the CPU <b>31</b> may employ, as a detection value of the length of the side surface of the target object, for example, the length of the side surface of the target object detected from a result of scanning in one cycle, a so-called instantaneous value. The CPU <b>31</b> may employ, as a detection value of the length of the side surface of the target object, for example, an average value obtained by averaging lengths of the side surface of the target object detected from respective results of scanning in a plurality of cycles.</p><p id="p-0076" num="0075">(4d) In the above embodiment, in S<b>205</b> to S<b>207</b> of the side surface length setting processing, the CPU <b>31</b> employs, as a set value of the length of the side surface of the target object, the longer one of the estimated length and the detected length. However, the CPU <b>31</b> may employ, as a set value of the length of the side surface of the target object, for example, the shorter length. By employing the shorter length, the recognized object can be prevented from being erroneously determined as a pseudo-object due to a multipath phenomenon.</p><p id="p-0077" num="0076">(4e) In the above embodiment, in the side surface length setting processing, the CPU <b>31</b> estimates a length and an orientation of the side surface of each of the recognized objects. In the side surface length setting processing, the CPU <b>31</b> may not estimate a length and an orientation of the side surface of all of the recognized objects. For example, the CPU <b>31</b> may estimate a length and an orientation of the side surface of only another object determined to be present between the candidate object and the own vehicle, that is, a shielding object.</p><p id="p-0078" num="0077">(4f) In the above embodiment, when the pseudo-determination processing is terminated, the CPU <b>31</b> terminates the object recognition process. However, for example, the CPU <b>31</b> may execute the pseudo-determination processing again by using the orientation of the side surface estimated by a different method. The CPU <b>31</b> may execute the pseudo-determination processing repeatedly, for example, three times or more. Specifically, for example, as the estimated orientation of the side surface of the shielding object, the CPU <b>31</b> may employ a moving direction of the shielding object for a first time, a longitudinal direction of the side surface of the shielding object for a second time, and a direction perpendicular to the width direction of the shielding object for a third time to repeatedly execute the pseudo-determination processing.</p><p id="p-0079" num="0078">In this case, in the pseudo-determination processing that has been executed multiple times, if determining that the recognized object is a pseudo-object due to a multipath phenomenon at least one time, the CPU <b>31</b> may determine that the object is a pseudo-object. By employing such a determination method, a pseudo-object due to a multipath phenomenon is difficult to overlook. In the pseudo-determination processing that has been executed multiple times, if determining that the same object is a pseudo-object due to a multipath phenomenon a predetermined number of times, for example, two or more times, the CPU <b>31</b> may determine that the object is a pseudo-object. By employing such a determination method, the recognized object can be prevented from being erroneously determined as a pseudo-object due to a multipath phenomenon.</p><p id="p-0080" num="0079">(4g) Functions of one component in the above embodiment may be decentralized to a plurality of components, or functions of a plurality of components may be integrated into one component. Furthermore, part of the configuration of the above embodiment may be omitted. Furthermore, at least part of the configuration of the above embodiment may be added to or replaced by another configuration of the above embodiment.</p><p id="p-0081" num="0080">In the above embodiment, S<b>101</b> to S<b>102</b> correspond to processing as a recognition unit, and S<b>104</b> to S<b>105</b> correspond to processing as an object determination unit.</p><p id="p-0082" num="0081">An aspect of the present disclosure provides an object recognition device, including: a recognition unit configured to radiate transmission waves in a plurality of radiation directions and receive reflected waves of the transmission waves to recognize objects; and an object determination unit configured to determine whether a candidate object, which is one of the objects recognized by the recognition unit, is a pseudo-object erroneously recognized due to the transmission waves reflected from a side surface of a shielding object, which is present on a near side of the candidate object.</p><p id="p-0083" num="0082">The object determination unit includes: a detection unit (<b>31</b>, S<b>104</b>, S<b>202</b>) configured to detect a width of the shielding object; an estimation unit (<b>31</b>, S<b>104</b>, S<b>203</b>) configured to assume that the shielding object is a vehicle and estimate a length of the side surface of the shielding object based on the width of the shielding object detected by the detection unit; and a pseudo-determination unit (<b>31</b>, S<b>105</b>, S<b>302</b>, S<b>303</b>, S<b>304</b>) configured to determine whether the candidate object is the pseudo-object by using the length of the side surface of the shielding object estimated by the estimation unit.</p><p id="p-0084" num="0083">The pseudo-determination unit is configured to determine that the candidate object is the pseudo-object, if it is determined that the transmission waves radiated in a direction in which the candidate object is located are reflected from the side surface of the shielding object and if another object is recognized at a location apart from a reflection point in a reflection direction by the same distance as a distance from the reflection point to the candidate object.</p><p id="p-0085" num="0084">According to the above configuration, it can be determined whether a recognized object is an object erroneously recognized due to a multipath phenomenon even when a length of a side surface of a shielding object cannot be appropriately detected.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An object recognition device, comprising:<claim-text>a recognition unit configured to radiate transmission waves in a plurality of radiation directions and receive reflected waves of the transmission waves to recognize objects; and</claim-text><claim-text>an object determination unit configured to determine whether a candidate object, which is one of the objects recognized by the recognition unit, is a pseudo-object erroneously recognized due to the transmission waves reflected from a side surface of a shielding object, which is present on a near side of the candidate object, wherein</claim-text><claim-text>the object determination unit includes:</claim-text><claim-text>a detection unit configured to detect a width of the shielding object;</claim-text><claim-text>an estimation unit configured to assume that the shielding object is a vehicle and estimate a length of the side surface of the shielding object based on the width of the shielding object detected by the detection unit; and</claim-text><claim-text>a pseudo-determination unit configured to determine whether the candidate object is the pseudo-object by using the length of the side surface of the shielding object estimated by the estimation unit, wherein</claim-text><claim-text>the pseudo-determination unit is configured to determine that the candidate object is the pseudo-object, if it is determined that the transmission waves radiated in a direction in which the candidate object is located are reflected from the side surface of the shielding object and if another object is recognized at a location apart from a reflection point in a reflection direction by the same distance as a distance from the reflection point to the candidate object.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The object recognition device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the estimation unit is further configured to estimate an orientation of the side surface of the shielding object, and</claim-text><claim-text>the pseudo-determination unit determines whether the candidate object is the pseudo-object by using the length and the orientation of the side surface of the shielding object estimated by the estimation unit.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The object recognition device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the estimation unit is further configured to estimate a moving direction of the shielding object to be an orientation of the side surface of the shielding object, and</claim-text><claim-text>the pseudo-determination unit determines whether the candidate object is the pseudo-object by using the length and the orientation of the side surface of the shielding object estimated by the estimation unit.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The object recognition device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the detection unit is further configured to detect a longitudinal direction of the side surface of the shielding object,</claim-text><claim-text>the estimation unit is further configured to estimate the longitudinal direction of the side surface of the shielding object detected by the detection unit to be an orientation of the side surface of the shielding object, and</claim-text><claim-text>the pseudo-determination unit determines whether the candidate object is the pseudo-object by using the length and the orientation of the side surface of the shielding object estimated by the estimation unit.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The object recognition device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the detection unit is further configured to detect a width direction of the shielding object,</claim-text><claim-text>the estimation unit is further configured to estimate a direction perpendicular to the width direction of the shielding object detected by the detection unit to be an orientation of the side surface of the shielding object, and</claim-text><claim-text>the pseudo-determination unit determines whether the candidate object is the pseudo-object by using the length and the orientation of the side surface of the shielding object estimated by the estimation unit.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The object recognition device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the detection unit is further configured to detect a length of the side surface of the shielding object,</claim-text><claim-text>the pseudo-determination unit determines whether the candidate object is the pseudo-object by using any one of the length of the side surface of the shielding object detected by the detection unit and the length of the side surface of the shielding object estimated by the estimation unit.</claim-text></claim-text></claim></claims></us-patent-application>
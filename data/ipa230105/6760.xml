<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230006761A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230006761</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17930873</doc-number><date>20220909</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>1</main-group><subgroup>004</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">METHOD FOR REDUCING FALSE DETECTION OF SUCCESSFUL DECODING OF CYCLIC REDUNDANCY CHECK CODES</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16867186</doc-number><date>20200505</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11451330</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17930873</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>VIAVI Solutions Inc.</orgname><address><city>Chandler</city><state>AZ</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>RAJAEI</last-name><first-name>Saman</first-name><address><city>London</city><country>GB</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>HUANG</last-name><first-name>Hongyuan</first-name><address><city>Letchworth Garden City</city><country>GB</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A network testing device may receive, from a base station, an encoded physical downlink control channel (PDCCH) payload and decode the encoded PDCCH payload to obtain candidate PDCCH payloads and to generate path metrics (PMs), wherein each PM of the PMs corresponds to one candidate PDCCH payload of the candidate PDCCH payloads. The network testing device may perform a cyclic redundancy check on each of the candidate PDCCH payloads to determine, from the PMs, a passing PM, and may determine, based on the PMs, a confidence value associated with the passing PM. The network testing device may discard, based on determining that the confidence value does not satisfy a threshold, the passing PM, or may output, based on determining that the confidence value satisfies the threshold, a candidate PDCCH payload corresponding to the passing PM. The network testing device may transmit, based on the candidate PDCCH payload, data to the base station.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="77.05mm" wi="158.75mm" file="US20230006761A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="199.73mm" wi="158.50mm" orientation="landscape" file="US20230006761A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="201.68mm" wi="158.50mm" orientation="landscape" file="US20230006761A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="210.06mm" wi="158.50mm" orientation="landscape" file="US20230006761A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="213.36mm" wi="156.80mm" orientation="landscape" file="US20230006761A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="209.13mm" wi="169.67mm" orientation="landscape" file="US20230006761A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="154.35mm" wi="158.50mm" orientation="landscape" file="US20230006761A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="198.46mm" wi="121.16mm" orientation="landscape" file="US20230006761A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="211.16mm" wi="159.17mm" file="US20230006761A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="212.60mm" wi="157.23mm" file="US20230006761A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="213.53mm" wi="156.04mm" file="US20230006761A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">RELATED APPLICATION</heading><p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 16/867,186, filed May 5, 2020 (now U.S. Pat. No. 11,451,330), which is incorporated herein by reference in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">A fifth generation (5G) telecommunications system may utilize a control channel (CCH) that includes one or more downlink physical channels, such as a physical downlink control channel (PDCCH). The PDCCH carries downlink control information (DCI), such as scheduling assignments, to user devices in an area of coverage of a base station associated with the 5G telecommunications system.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">According to some implementations, a method may include receiving, by a device and from a base station, an encoded physical downlink control channel (PDCCH) payload; decoding, by the device, the encoded PDCCH payload to obtain candidate PDCCH payloads and to generate path metrics (PMs), wherein each PM of the PMs corresponds to one candidate PDCCH payload of the candidate PDCCH payloads; performing, by the device, a cyclic redundancy check (CRC) on each of the candidate PDCCH payloads to determine, from the PMs, a passing PM; determining, by the device and based on the PMs, a confidence value associated with the passing PM; determining, by the device, whether the confidence value satisfies a threshold; discarding, by the device and based on determining that the confidence value does not satisfy the threshold, the passing PM; or outputting, by the device and based on determining that the confidence value does satisfy the threshold, a candidate PDCCH payload corresponding to the passing PM; and transmitting, by the device and based on the candidate PDCCH payload, data to the base station.</p><p id="p-0005" num="0004">According to some implementations, a device may include one or more memories and one or more processors. The one or more processors may be configured to: receive, from a base station, a polar encoded PDCCH payload; decode, using a successive cancellation list decoding algorithm, the polar encoded PDCCH payload to obtain candidate PDCCH payloads and to generate PMs, wherein each PM of the PMs corresponds to one candidate PDCCH payload of the candidate PDCCH payloads; perform a cyclic redundancy check on each of the candidate PDCCH payloads to determine, from the PMs, a passing PM; determine, based on the PMs, a confidence value associated with the passing PM; determine whether the confidence value satisfies a threshold; discard, based on determining that the confidence value does not satisfy the threshold, the passing PM; or output, based on determining that the confidence value does satisfy the threshold, a candidate PDCCH payload corresponding to the passing PM; and transmit, based on the candidate PDCCH payload, data to the base station.</p><p id="p-0006" num="0005">According to some implementations, a non-transitory computer-readable medium may store one or more instructions. The one or more instructions, when executed by one or more processors, may cause the one or more processors to: receive, from a base station, an encoded PDCCH payload; decode the encoded PDCCH payload to obtain candidate PDCCH payloads and to generate PMs, wherein each PM of the PMs corresponds to one candidate PDCCH payload of the candidate PDCCH payloads; perform a cyclic redundancy check on each of the candidate PDCCH payloads to obtain, from the PMs, a passing PM; determine, based on the PMs and using a machine learning model, a confidence value associated with the passing PM; determine whether the confidence value satisfies a threshold; discard, based on determining that the confidence value does not satisfy the threshold, the passing PM; or output, based on determining that the confidence value does satisfy the threshold, a candidate PDCCH payload corresponding to the passing PM; and transmit, based on the candidate PDCCH payload, data to the base station.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref> are diagrams of an example implementation described herein.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref> are diagrams of one or more example implementations described herein.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram of an example environment in which systems and/or methods described herein may be implemented.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram of example components of one or more devices of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIGS. <b>6</b>-<b>8</b></figref> are flowcharts of example processes relating to reducing false detection of successful decoding of cyclic redundancy check codes.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS</heading><p id="p-0012" num="0011">The following detailed description of example implementations refers to the accompanying drawings. The same reference numbers in different drawings may identify the same or similar elements.</p><p id="p-0013" num="0012">Often, when a user device receives an encoded physical downlink control channel (PDCCH) payload from a base station, the user device attempts to locate, in the encoded PDCCH payload, control information (e.g., downlink control information (DCI)) intended specifically for the user device to use to communicate with the base station. In some cases, to locate the control information, the user device uses a decoding process, such as a successive cancellation list (SCL) decoding algorithm, to generate and/or obtain candidate PDCCH payloads (e.g., where a candidate PDCCH payload may be associated with the control information) and respective path metrics (PMs). The user device performs a cyclic redundancy check (CRC) on the candidate PDCCH payloads to identify a PM that is error-free. The user device decodes, using the error-free PM, a candidate PDCCH payload corresponding to the error-free PM, and transmits, based on the candidate PDCCH payload, information to the base station.</p><p id="p-0014" num="0013">However, in many cases, the CRC may fail to identify errors in a PM and may incorrectly indicate that the PM is error-free, which is referred to as a CRC mis-detection. Additionally, or alternatively, the CRC may indicate that a PM is error-free when the PM is purely random, such as when the user device mistakenly identifies noise as an encoded PDCCH payload, which is referred to as a CRC false alarm. The user device then attempts to transmit information with the base station based on the PM including an error and/or the purely random PM, and the transmission fails.</p><p id="p-0015" num="0014">When the transmission fails, the user device obtains another encoded PDCCH payload and repeats the attempt. For a single user device, such as a mobile device, CRC mis-detections and CRC false alarms are often infrequent. However, for a network testing device (e.g., that tests one or more functionalities of a base station) that emulates multiple user devices (e.g., hundreds, thousands, or even millions of UEs), CRC mis-detections and CRC false alarms may be very frequent and may consume computing resources (e.g., processing resources, memory resources, power resources, communication resources, and/or the like), network resources, and/or financial resources by extending a length of time and a number of procedures required to perform network testing.</p><p id="p-0016" num="0015">Some implementations described herein provide a method that includes determining a confidence value associated with a passing PM (e.g., a PM that a CRC indicates is error-free). The confidence value may be determined by normalizing PM values of the PMs, averaging the normalized PM values, and determining a difference between a normalized PM value of the passing PM and the averaged normalized PM value. The method may include determining whether the confidence value satisfies a threshold. The method may include, if the confidence value does not satisfy the threshold, discarding the passing PM. The method may include, if the confidence value does satisfy the threshold, outputting a candidate PDCCH payload corresponding to the passing PM, and transmitting, based on the candidate PDCCH payload, data to a base station. In some implementations, the method may include using a machine learning model to determine the confidence value and/or the threshold. By determining whether the confidence value of the passing PM satisfies the threshold, the method may detect CRC mis-detections and/or CRC false alarms. In this way, the method may conserve computing resources (e.g., processing resources, memory resources, power resources, communication resources, and/or the like), network resources, and/or financial resources that would otherwise be consumed by CRC mis-detections and/or CRC false alarms extending a length of time and a number of procedures required to perform network testing.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref> are diagrams of one or more example implementations <b>100</b> described herein. As shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref>, example implementation(s) <b>100</b> may include a base station, a network testing device, and/or the like. The network testing device may be configured to test one or more functionalities of the base station. For example, the network device may be configured to emulate, simulate, and/or the like a plurality of user devices that connect to and communicate with the base station.</p><p id="p-0018" num="0017">As shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> and by reference number <b>110</b>, the network testing device may receive an encoded PDCCH payload from the base station. The encoded PDCCH payload may be a polar encoded PDCCH payload. As shown by reference number <b>120</b>, the network testing device may decode (e.g., using a decoding algorithm) the encoded PDCCH payload. In some implementations, the network testing device may decode, using an SCL decoding algorithm, the encoded PDCCH payload to obtain and/or generate a plurality of candidate PDCCH payloads and a plurality of PMs, wherein each PM is respectively associated with a candidate PDCCH payload of the plurality of candidate PDCCH payloads. A candidate PDCCH payload may be associated with downlink control information (e.g., DCI) for a set of user devices (e.g., control information for one or more user devices). A PM may be associated with a decoding path to decode a candidate PDCCH payload associated with the PM. The PM may have a PM value (e.g., that numerically indicates the decoding path to decode the candidate PDCCH path associated with the PM).</p><p id="p-0019" num="0018">As shown by reference number <b>130</b>, the network testing device may perform a CRC on the plurality of candidate PDCCH payloads (e.g., on one or more candidate PDCCH payloads of the plurality of candidate PDCCH payloads). For example, the network testing device may perform the CRC on each of the candidate PDCCH payloads to identify a passing PM (e.g., a PM associated with a candidate PDCCH payload that is error-free). Identification of the passing PM may indicate that the candidate PDCCH payload associated with the passing PM was successfully decoded from the coded PDCCH payload. In some implementations, the network testing device may determine, based on performing the CRC, that a particular PM is not a passing PM (e.g., that the particular PM is not error-free), which may indicate that the candidate PDCCH payload associated with the particular PM was not successfully decoded from the coded PDCCH payload. The network device may therefore discard the particular PM and/or the candidate PDCCH payload associated with the particular PM. In some implementations, the network testing device may perform the CRC on each of the candidate PDCCH payloads to identify a plurality of passing PMs (e.g., a first PM that is error-free, a second PM that is error-free, and/or the like).</p><p id="p-0020" num="0019">In some implementations, the network testing device may sequentially perform the CRC on the plurality of candidate PDCCH payloads to identify a passing PM. For example, the network testing device may perform the CRC on a first candidate PDCCH payload having a lowest PM value to determine whether the first PM is error-free. The network device may determine, based on determining that the first PM is error-free, that the first PM is a passing PM. Additionally, or alternatively, the network testing device may perform, based on determining that the first PM is not error-free, the CRC on a second candidate PDCCH payload having a second lowest PM value to determine whether the second PM is error-free. The network device may determine, based on determining that the second PM is error-free, that the second PM is a passing PM. Additionally, or alternatively, the network testing device may perform, based on determining that the second PM is not error-free, the CRC on a third candidate PDCCH payload having a third PM value to determine whether the third PM is error-free. The network testing device may continue to perform the CRC in a similar manner on the remaining candidate PDCCH payloads, in order of lowest PM value to highest PM value, until a passing PM is identified.</p><p id="p-0021" num="0020">As shown in <figref idref="DRAWINGS">FIG. <b>1</b>B</figref> and by reference number <b>140</b>, the network testing device may determine a confidence value associated with a passing PM. For example, the network testing device may normalize the respective PM values of the plurality of PMs to obtain a plurality of normalized PM values (e.g., a plurality of normalized values, where each normalized value is greater than 0 and less than or equal to 1). The network testing device may generate an average (e.g., a mathematical mean, a geometric mean, a harmonic mean, an interquartile mean, a truncated mean, and/or the like) of the plurality of normalized PM values to obtain an average normalized PM value. The network testing device may determine the confidence value associated with the passing PM based on the average normalized PM value. For example, the network testing device may determine a difference between a normalized PM value of the passing PM and the average normalized PM value to obtain the confidence value associated with the passing PM.</p><p id="p-0022" num="0021">In some implementations, the network testing device may determine the confidence value associated with the passing PM using a machine learning model. For example, the network testing device may process the respective PM values of the plurality of PMs using the machine learning model to determine the confidence value associated with the passing PM. In some implementations, a network testing device platform may train the machine learning model using historical data associated with respective PM values of a plurality of PMs, historical data indicating which of the PMs of the plurality of PMs are passing PMs, historical data indicating respective confidence values associated with passing PMs, and/or the like. Using the historical data as inputs to the machine learning model, the network testing device may identify one or more relationships between sets of PM values and a confidence value associated with a passing PM. The machine learning model may be trained and/or used in a similar manner to that described below with respect to <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>.</p><p id="p-0023" num="0022">Additionally, or alternatively, the network testing device may determine a confidence value associated with each PM of the plurality of PMs (e.g., in a similar manner as described above). In some implementations, the network testing device may determine the respective confidence values associated with the PMs while performing the CRC on the candidate PDCCH payloads.</p><p id="p-0024" num="0023">As shown by reference number <b>150</b>, the network testing device may determine whether a confidence value associated with a passing PM satisfies (e.g., is greater than or equal to) a threshold (e.g., a threshold associated with a reduction and/or prevention of CRC mis-detections and/or CRC false alarms). In some implementations, when the network testing device determines that the confidence value does not satisfy the threshold, the network testing device may discard the passing PM. Additionally, or alternatively, when the network testing device determines that the confidence value does satisfy the threshold, the network testing device may output a candidate PDCCH payload corresponding to the passing PM. For example, the network testing device may output the candidate PDCCH payload corresponding to the passing PM to allow the network testing device to modify functionality of one or more emulated, simulated, and/or the like user devices of the network testing device according to the control information included in the candidate PDCCH payload.</p><p id="p-0025" num="0024">In some implementations, when the network testing device determines that the confidence value does not satisfy the threshold, the network testing device may determine, after discarding the passing PM, a confidence value associated with another passing PM (e.g., in a similar manner as described herein). The network testing device may determine whether the confidence value associated with the other passing PM satisfies the threshold. In some implementations, when the network testing device determines that the confidence value associated with the other passing PM does not satisfy the threshold, the network testing device may discard the other passing PM. Additionally, or alternatively, when the network testing device determines that the confidence value associated with the other passing PM does satisfy the threshold, the network testing device may output a candidate PDCCH payload corresponding to the other passing PM.</p><p id="p-0026" num="0025">In some implementations, the network testing device may determine and/or set the threshold using an additional machine learning model. In some implementations, the network testing device platform may train the additional machine learning model using historical data associated with respective confidence values of a plurality of PMs, historical data indicating different thresholds, historical data indicating which PMs of the plurality of PMs are associated with CRC mis-detections and/or CRC false alarms, and/or the like. Using the historical data as inputs to the machine learning model, the network testing device may identify one or more relationships between thresholds and reductions in CRC mis-detections and/or CRC false alarms. The machine learning model may be trained and/or used in a similar manner to that described below with respect to <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>.</p><p id="p-0027" num="0026">As shown by reference number <b>160</b>, the network testing device may transmit, based on the candidate PDCCH payload corresponding to the passing PM, data to the base station. For example, the network testing device, after modifying functionality of the one or more emulated, simulated, and/or the like user devices of the network testing device according to the control information included in the candidate PDCCH payload corresponding to the passing PM, may cause at least one emulated, simulated, and/or the like user device to transmit data to the base station (e.g., to test one or more functionalities of the base station).</p><p id="p-0028" num="0027">In some implementations, the network testing device may perform one or more additional actions. For example, the network testing device may retrain the machine learning model and/or the additional machine learning model based on at least one of the plurality of PMs, information concerning the CRC on the plurality of candidate PDCCH payloads, the confidence value of the passing PM, the threshold, whether the confidence value satisfies the threshold, and/or the like. In this way, the network testing device may continually reduce a likelihood of CRC mis-detections and/or CRC false alarms.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>1</b>C</figref> illustrates an example flowchart that corresponds to the processing steps described herein in relation to <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>B</figref>. As shown by reference number <b>170</b>, the network testing device may receive a polar encoded PDCCH payload and may decode the polar encoded PDCCH payload using an SCL algorithm to generate a plurality of candidate PDCCH payloads and a plurality of PMs (e.g., as described herein in relation to <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> and reference numbers <b>110</b> and <b>120</b>). As shown by reference number <b>171</b>, the network testing device may perform a CRC on the plurality of candidate PDCCH payloads to identify a passing PM (e.g., as described herein in relation to <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> and reference number <b>130</b>). When a PM is not a passing PM, the network testing device may discard the output associated with the PM (e.g., discard the candidate PDCCH payload associated with the PM). As shown by reference number <b>172</b>, when the PM is a passing PM, the network testing device may normalize the PM values of the plurality of PMs and determine a confidence value associated with the passing PM (e.g., as described herein in relation to <figref idref="DRAWINGS">FIG. <b>1</b>B</figref> and reference number <b>140</b>). The network testing device may use a machine learning model to determine the confidence value. As shown by reference number <b>173</b>, the network testing device may determine whether the confidence value satisfies (e.g., is greater than or equal to) a threshold (e.g., as described herein in relation to <figref idref="DRAWINGS">FIG. <b>1</b>B</figref> and reference number <b>150</b>). When the confidence value satisfies the threshold, the network testing device may output the candidate PDCCH payload corresponding to the passing PM. Additionally, or alternatively, when the confidence value does not satisfy the threshold (e.g., the network testing device determines that a false detection of a passing PM has occurred), the network testing device may discard the output associated with the passing PM (e.g., discard the candidate PDCCH payload associated with the passing PM) and may start the process over again by receiving and decoding a new polar encoded PDCCH payload (e.g., as described herein in relation to reference number <b>170</b>).</p><p id="p-0030" num="0029">As indicated above, <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref> are provided as an example. Other examples may differ from what is described with regard to <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref>. The number and arrangement of devices shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref> are provided as an example. In practice, there may be additional devices, fewer devices, different devices, or differently arranged than those shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref>. Furthermore, two or more devices shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref> may be implemented within a single device, or a single device shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref> may be implemented as multiple, distributed devices. Additionally, or alternatively, a set of devices (e.g., one or more devices) shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref> may perform one or more functions described as being performed by another set of devices shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref>.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example <b>200</b> of training a machine learning model. The machine learning model training described herein may be performed using a machine learning system. The machine learning system may include a computing device, a server, a cloud computing environment, a network testing device, and/or the like.</p><p id="p-0032" num="0031">As shown by reference number <b>205</b>, a machine learning model may be trained using a set of observations. The set of observations may be obtained and/or input from historical data, such as data gathered during one or more processes described herein. For example, the set of observations may include data gathered from obtaining a passing PM and/or determining a confidence value associated with the passing PM, as described elsewhere herein. In some implementations, the machine learning system may receive the set of observations (e.g., as input) from another device, such as a base station.</p><p id="p-0033" num="0032">As shown by reference number <b>210</b>, a feature set may be derived from the set of observations. The feature set may include a set of variable types. A variable type may be referred to as a feature. A specific observation may include a set of variable values corresponding to the set of variable types. A set of variable values may be specific to an observation. In some cases, different observations may be associated with different sets of variable values, sometimes referred to as feature values. In some implementations, the machine learning system may determine variable values for a specific observation based on input received from the base station. For example, the machine learning system may identify a feature set (e.g., one or more features and/or corresponding feature values) from structured data input to the machine learning system, such as by extracting data from a particular column of a table, extracting data from a particular field of a form, extracting data from a particular field of a message, extracting data received in a structured data format, and/or the like. In some implementations, the machine learning system may determine features (e.g., variables types) for a feature set based on input received from the base station, such as by extracting or generating a name for a column, extracting or generating a name for a field of a form and/or a message, extracting or generating a name based on a structured data format, and/or the like. Additionally, or alternatively, the machine learning system may receive input from an operator to determine features and/or feature values. In some implementations, the machine learning system may perform natural language processing and/or another feature identification technique to extract features (e.g., variable types) and/or feature values (e.g., variable values) from text (e.g., unstructured data) input to the machine learning system, such as by identifying keywords and/or values associated with those keywords from the text.</p><p id="p-0034" num="0033">As an example, a feature set for a set of observations may include a first feature of a set of PMs, a second feature of respective PM values of the set of PMs, a third feature identifying passing PMs of the set of PMs, and so on. As shown, for a first observation, the first feature may include a set of PMs PM<sub>11 </sub>through PM<sub>1M</sub>, the second feature may include respective PM values of PMV<sub>11 </sub>through PMV<sub>1M</sub>, the third feature may identify PM<sub>13 </sub>as a passing PM, and so on. These features and feature values are provided as examples, and may differ in other examples. In some implementations, the machine learning system may pre-process and/or perform dimensionality reduction to reduce the feature set and/or combine features of the feature set to a minimum feature set. A machine learning model may be trained on the minimum feature set, thereby conserving resources of the machine learning system (e.g., processing resources, memory resources, and/or the like) used to train the machine learning model.</p><p id="p-0035" num="0034">As shown by reference number <b>215</b>, the set of observations may be associated with a target variable type. The target variable type may represent a variable having a numeric value (e.g., an integer value, a floating point value, and/or the like), may represent a variable having a numeric value that falls within a range of values or has some discrete possible values, may represent a variable that is selectable from one of multiple options (e.g., one of multiples classes, classifications, labels, and/or the like), may represent a variable having a Boolean value (e.g., 0 or 1, True or False, Yes or No), and/or the like. A target variable type may be associated with a target variable value, and a target variable value may be specific to an observation. In some cases, different observations may be associated with different target variable values.</p><p id="p-0036" num="0035">The target variable may represent a value that a machine learning model is being trained to predict, and the feature set may represent the variables that are input to a trained machine learning model to predict a value for the target variable. The set of observations may include target variable values so that the machine learning model can be trained to recognize patterns in the feature set that lead to a target variable value. A machine learning model that is trained to predict a target variable value may be referred to as a supervised learning model, a predictive model, and/or the like. When the target variable type is associated with continuous target variable values (e.g., a range of numbers and/or the like), the machine learning model may employ a regression technique. When the target variable type is associated with categorical target variable values (e.g., classes, labels, and/or the like), the machine learning model may employ a classification technique.</p><p id="p-0037" num="0036">In some implementations, the machine learning model may be trained on a set of observations that do not include a target variable (or that include a target variable, but the machine learning model is not being executed to predict the target variable). This may be referred to as an unsupervised learning model, an automated data analysis model, an automated signal extraction model, and/or the like. In this case, the machine learning model may learn patterns from the set of observations without labeling or supervision, and may provide output that indicates such patterns, such as by using clustering and/or association to identify related groups of items within the set of observations.</p><p id="p-0038" num="0037">As further shown, the machine learning system may partition the set of observations into a training set <b>220</b> that includes a first subset of observations, of the set of observations, and a test set <b>225</b> that includes a second subset of observations of the set of observations. The training set <b>220</b> may be used to train (e.g., fit, tune, and/or the like) the machine learning model, while the test set <b>225</b> may be used to evaluate a machine learning model that is trained using the training set <b>220</b>. For example, for supervised learning, the test set <b>225</b> may be used for initial model training using the first subset of observations, and the test set <b>225</b> may be used to test whether the trained model accurately predicts target variables in the second subset of observations. In some implementations, the machine learning system may partition the set of observations into the training set <b>220</b> and the test set <b>225</b> by including a first portion or a first percentage of the set of observations in the training set <b>220</b> (e.g., 75%, 80%, or 85%, among other examples) and including a second portion or a second percentage of the set of observations in the test set <b>225</b> (e.g., 25%, 20%, or 15%, among other examples). In some implementations, the machine learning system may randomly select observations to be included in the training set <b>220</b> and/or the test set <b>225</b>.</p><p id="p-0039" num="0038">As shown by reference number <b>230</b>, the machine learning system may train a machine learning model using the training set <b>220</b>. This training may include executing, by the machine learning system, a machine learning algorithm to determine a set of model parameters based on the training set <b>220</b>. In some implementations, the machine learning algorithm may include a regression algorithm (e.g., linear regression, logistic regression, and/or the like), which may include a regularized regression algorithm (e.g., Lasso regression, Ridge regression, Elastic-Net regression, and/or the like). Additionally, or alternatively, the machine learning algorithm may include a decision tree algorithm, which may include a tree ensemble algorithm (e.g., generated using bagging and/or boosting), a random forest algorithm, a boosted trees algorithm, and/or the like. A model parameter may include an attribute of a machine learning model that is learned from data input into the model (e.g., the training set <b>220</b>). For example, for a regression algorithm, a model parameter may include a regression coefficient (e.g., a weight). For a decision tree algorithm, a model parameter may include a decision tree split location, as an example.</p><p id="p-0040" num="0039">As shown by reference number <b>235</b>, the machine learning system may use one or more hyperparameter sets <b>240</b> to tune the machine learning model. A hyperparameter may include a structural parameter that controls execution of a machine learning algorithm by the machine learning system, such as a constraint applied to the machine learning algorithm. Unlike a model parameter, a hyperparameter is not learned from data input into the model. An example hyperparameter for a regularized regression algorithm includes a strength (e.g., a weight) of a penalty applied to a regression coefficient to mitigate overfitting of the machine learning model to the training set <b>220</b>. The penalty may be applied based on a size of a coefficient value (e.g., for Lasso regression, such as to penalize large coefficient values), may be applied based on a squared size of a coefficient value (e.g., for Ridge regression, such as to penalize large squared coefficient values), may be applied based on a ratio of the size and the squared size (e.g., for Elastic-Net regression), may be applied by setting one or more feature values to zero (e.g., for automatic feature selection), and/or the like. Example hyperparameters for a decision tree algorithm include a tree ensemble technique to be applied (e.g., bagging, boosting, a random forest algorithm, a boosted trees algorithm, and/or the like), a number of features to evaluate, a number of observations to use, a maximum depth of each decision tree (e.g., a number of branches permitted for the decision tree), a number of decision trees to include in a random forest algorithm, and/or the like.</p><p id="p-0041" num="0040">To train a machine learning model, the machine learning system may identify a set of machine learning algorithms to be trained (e.g., based on operator input that identifies the one or more machine learning algorithms, based on random selection of a set of machine learning algorithms, and/or the like), and may train the set of machine learning algorithms (e.g., independently for each machine learning algorithm in the set) using the training set <b>220</b>. The machine learning system may tune each machine learning algorithm using one or more hyperparameter sets <b>240</b> (e.g., based on operator input that identifies hyperparameter sets <b>240</b> to be used, based on randomly generating hyperparameter values, and/or the like). The machine learning system may train a particular machine learning model using a specific machine learning algorithm and a corresponding hyperparameter set <b>240</b>. In some implementations, the machine learning system may train multiple machine learning models to generate a set of model parameters for each machine learning model, where each machine learning model corresponds to a different combination of a machine learning algorithm and a hyperparameter set <b>240</b> for that machine learning algorithm.</p><p id="p-0042" num="0041">In some implementations, the machine learning system may perform cross-validation when training a machine learning model. Cross validation can be used to obtain a reliable estimate of machine learning model performance using only the training set <b>220</b>, and without using the test set <b>225</b>, such as by splitting the training set <b>220</b> into a number of groups (e.g., based on operator input that identifies the number of groups, based on randomly selecting a number of groups, and/or the like) and using those groups to estimate model performance. For example, using k-fold cross-validation, observations in the training set <b>220</b> may be split into k groups (e.g., in order or at random). For a training procedure, one group may be marked as a hold-out group, and the remaining groups may be marked as training groups. For the training procedure, the machine learning system may train a machine learning model on the training groups and then test the machine learning model on the hold-out group to generate a cross-validation score. The machine learning system may repeat this training procedure using different hold-out groups and different test groups to generate a cross-validation score for each training procedure. In some implementations, the machine learning system may independently train the machine learning model k times, with each individual group being used as a hold-out group once and being used as a training group k-1 times. The machine learning system may combine the cross-validation scores for each training procedure to generate an overall cross-validation score for the machine learning model. The overall cross-validation score may include, for example, an average cross-validation score (e.g., across all training procedures), a standard deviation across cross-validation scores, a standard error across cross-validation scores, and/or the like.</p><p id="p-0043" num="0042">In some implementations, the machine learning system may perform cross-validation when training a machine learning model by splitting the training set into a number of groups (e.g., based on operator input that identifies the number of groups, based on randomly selecting a number of groups, and/or the like). The machine learning system may perform multiple training procedures and may generate a cross-validation score for each training procedure. The machine learning system may generate an overall cross-validation score for each hyperparameter set <b>240</b> associated with a particular machine learning algorithm. The machine learning system may compare the overall cross-validation scores for different hyperparameter sets <b>240</b> associated with the particular machine learning algorithm, and may select the hyperparameter set <b>240</b> with the best (e.g., highest accuracy, lowest error, closest to a desired threshold, and/or the like) overall cross-validation score for training the machine learning model. The machine learning system may then train the machine learning model using the selected hyperparameter set <b>240</b>, without cross-validation (e.g., using all of data in the training set <b>220</b> without any hold-out groups), to generate a single machine learning model for a particular machine learning algorithm. The machine learning system may then test this machine learning model using the test set <b>225</b> to generate a performance score, such as a mean squared error (e.g., for regression), a mean absolute error (e.g., for regression), an area under receiver operating characteristic curve (e.g., for classification), and/or the like. If the machine learning model performs adequately (e.g., with a performance score that satisfies a threshold), then the machine learning system may store that machine learning model as a trained machine learning model <b>245</b> to be used to analyze new observations, as described below in connection with <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0044" num="0043">In some implementations, the machine learning system may perform cross-validation, as described above, for multiple machine learning algorithms (e.g., independently), such as a regularized regression algorithm, different types of regularized regression algorithms, a decision tree algorithm, different types of decision tree algorithms, and/or the like. Based on performing cross-validation for multiple machine learning algorithms, the machine learning system may generate multiple machine learning models, where each machine learning model has the best overall cross-validation score for a corresponding machine learning algorithm. The machine learning system may then train each machine learning model using the entire training set <b>220</b> (e.g., without cross-validation), and may test each machine learning model using the test set <b>225</b> to generate a corresponding performance score for each machine learning model. The machine learning model may compare the performance scores for each machine learning model, and may select the machine learning model with the best (e.g., highest accuracy, lowest error, closest to a desired threshold, and/or the like) performance score as the trained machine learning model <b>245</b>.</p><p id="p-0045" num="0044">As indicated above, <figref idref="DRAWINGS">FIG. <b>2</b></figref> is provided as an example. Other examples may differ from what is described in connection with <figref idref="DRAWINGS">FIG. <b>2</b></figref>. For example, the machine learning model may be trained using a different process than what is described in connection with <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Additionally, or alternatively, the machine learning model may employ a different machine learning algorithm than what is described in connection with <figref idref="DRAWINGS">FIG. <b>2</b></figref>, such as a Bayesian estimation algorithm, a k-nearest neighbor algorithm, an a priori algorithm, a k-means algorithm, a support vector machine algorithm, a neural network algorithm (e.g., a convolutional neural network algorithm), a deep learning algorithm, and/or the like.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example <b>300</b> of applying a trained machine learning model to a new observation. The new observation may be input to a machine learning system that stores a trained machine learning model <b>305</b>. In some implementations, the trained machine learning model <b>305</b> may be the trained machine learning model <b>245</b> described above in connection with <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The machine learning system may include a computing device, a server, a cloud computing environment, a network testing device, and/or the like.</p><p id="p-0047" num="0046">As shown by reference number <b>310</b>, the machine learning system may receive a new observation (or a set of new observations), and may input the new observation to the machine learning model <b>305</b>. As shown, the new observation may include a first feature of a set of PMs, a second feature of respective PM values of the set of PMs, a third feature identifying passing PMs of the set of PMs, and so on, as an example. The machine learning system may apply the trained machine learning model <b>305</b> to the new observation to generate an output (e.g., a result). The type of output may depend on the type of machine learning model and/or the type of machine learning task being performed. For example, the output may include a predicted (e.g., estimated) value of a target variable (e.g., a value within a continuous range of values, a discrete value, a label, a class, a classification, and/or the like), such as when supervised learning is employed. Additionally, or alternatively, the output may include information that identifies a cluster to which the new observation belongs, information that indicates a degree of similarity between the new observation and one or more prior observations (e.g., which may have previously been new observations input to the machine learning model and/or observations used to train the machine learning model), and/or the like, such as when unsupervised learning is employed.</p><p id="p-0048" num="0047">In some implementations, the trained machine learning model 305 may predict a value of 0.87, for example, for the target variable of a confidence value for the new observation, as shown by reference number <b>315</b>. Based on this prediction (e.g., based on the value having a particular label/classification, based on the value satisfying or failing to satisfy a threshold, and/or the like), the machine learning system may provide a recommendation, such as a recommendation to output a PDCCH payload corresponding to the passing PM or discard the passing PM. Additionally, or alternatively, the machine learning system may perform an automated action and/or may cause an automated action to be performed (e.g., by instructing another device to perform the automated action), such as automatically outputting the PDCCH payload corresponding to the passing PM or discarding the passing PM. In some implementations, the recommendation and/or the automated action may be based on the target variable value having a particular label (e.g., classification, categorization, and/or the like), may be based on whether the target variable value satisfies one or more thresholds (e.g., whether the target variable value is greater than a threshold, is less than a threshold, is equal to a threshold, falls within a range of threshold values, and/or the like), and/or the like.</p><p id="p-0049" num="0048">In some implementations, the trained machine learning model <b>305</b> may classify (e.g., cluster) the new observation in a particular cluster, as shown by reference number <b>320</b>. The observations within a cluster may have a threshold degree of similarity. Based on classifying the new observation in the particular cluster, the machine learning system may provide a recommendation, such as a recommendation to output a PDCCH payload corresponding to the passing PM or discard the passing PM. Additionally, or alternatively, the machine learning system may perform an automated action and/or may cause an automated action to be performed (e.g., by instructing another device to perform the automated action), such as automatically outputting the PDCCH payload corresponding to the passing PM or discarding the passing PM.</p><p id="p-0050" num="0049">In this way, the machine learning system may apply a rigorous and automated process to determining a confidence value associated with a passing PM. The machine learning system enables recognition and/or identification of tens, hundreds, thousands, or millions of features and/or feature values for tens, hundreds, thousands, or millions of observations, thereby increasing an accuracy and consistency of determining a confidence value associated with a passing PM, relative to requiring computing resources to be allocated for tens, hundreds, or thousands of operators to manually determine a confidence value associated with a passing PM using the features or feature values.</p><p id="p-0051" num="0050">As indicated above, <figref idref="DRAWINGS">FIG. <b>3</b></figref> is provided as an example. Other examples may differ from what is described in connection with <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram of an example environment <b>400</b> in which systems and/or methods described herein may be implemented. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, environment <b>400</b> may include a base station <b>410</b> and a network testing device <b>420</b>. Devices of environment <b>400</b> may interconnect via wired connections, wireless connections, or a combination of wired and wireless connections.</p><p id="p-0053" num="0052">Base station <b>410</b> includes one or more devices capable of transferring traffic, such as encoded PDCCH payloads and/or other traffic, destined for and/or received from network testing device <b>420</b>. In some implementations, base station <b>410</b> may include a next generation Node B (gNB) associated with a fifth generation (5G) network, an evolved Node B (eNB) associated with a long term evolution (LTE) network, and/or the like. Base station <b>410</b> may include a massive multiple-input multiple-output (MIMO) antenna system that utilizes time division duplexing (TDD). In some implementations, base station <b>410</b> may send traffic to and/or receive traffic from network testing device <b>420</b> via an air interface. Additionally, or alternatively, base station <b>410</b> may be connected to network testing device <b>420</b> via one or more RF cables (e.g., an antenna of base station <b>410</b> (e.g., an antenna of the massive MIMO antenna system) is connected to an antenna of network testing device <b>420</b>) and may send traffic to and/or receive traffic from network testing device <b>420</b> via the one or more RF cables.</p><p id="p-0054" num="0053">Network testing device <b>420</b> includes one or more devices capable of communicating traffic with base station <b>410</b>, such as to receive encoded PDCCH payloads from base station <b>410</b> and/or transmit data to base station <b>410</b>. For example, network testing device <b>420</b> may include a channel analyzer, a user device (e.g., a mobile phone (e.g., a smartphone or a radiotelephone), a laptop computer, a tablet computer, a gaming device, a wearable communication device (e.g., a smart wristwatch or a pair of smart eyeglasses), an Internet of things (IoT) device, or a similar type of device), a device to simulate a plurality of user devices, or a similar type of device. Network testing device <b>420</b> may include one or more antennas. In some implementations, network testing device <b>420</b> may send traffic to and/or receive traffic from base station <b>410</b> via an air interface. Additionally, or alternatively, network testing device <b>420</b> may be connected to base station <b>410</b> via one or more RF cables (e.g., an antenna of network testing device <b>420</b> may be connected to an antenna of base station <b>410</b>) and may send traffic to and/or receive traffic from base station <b>410</b> via the one or more RF cables.</p><p id="p-0055" num="0054">The number and arrangement of devices and networks shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> are provided as an example. In practice, there may be additional devices and/or networks, fewer devices and/or networks, different devices and/or networks, or differently arranged devices and/or networks than those shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. Furthermore, two or more devices shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be implemented within a single device, or a single device shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be implemented as multiple, distributed devices. Additionally, or alternatively, a set of devices (e.g., one or more devices) of environment <b>400</b> may perform one or more functions described as being performed by another set of devices of environment <b>400</b>.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram of example components of a device <b>500</b>. Device <b>500</b> may correspond to base station <b>410</b> and/or network testing device <b>420</b>. In some implementations, base station <b>410</b> and/or network testing device <b>420</b> may include one or more devices <b>500</b> and/or one or more components of device <b>500</b>. As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, device <b>500</b> may include a bus <b>510</b>, a processor <b>520</b>, a memory <b>530</b>, a storage component <b>540</b>, an input component <b>550</b>, an output component <b>560</b>, and a communication interface <b>570</b>.</p><p id="p-0057" num="0056">Bus <b>510</b> includes a component that permits communication among the components of device <b>500</b>. Processor <b>520</b> is implemented in hardware, firmware, or a combination of hardware and software. Processor <b>520</b> is a central processing unit (CPU), a graphics processing unit (GPU), an accelerated processing unit (APU), a microprocessor, a microcontroller, a digital signal processor (DSP), a field-programmable gate array (FPGA), an application-specific integrated circuit (ASIC), or another type of processing component. In some implementations, processor <b>520</b> includes one or more processors capable of being programmed to perform a function. Memory <b>530</b> includes a random access memory (RAM), a read only memory (ROM), and/or another type of dynamic or static storage device (e.g., a flash memory, a magnetic memory, and/or an optical memory) that stores information and/or instructions for use by processor <b>520</b>.</p><p id="p-0058" num="0057">Storage component <b>540</b> stores information and/or software related to the operation and use of device <b>500</b>. For example, storage component <b>540</b> may include a hard disk (e.g., a magnetic disk, an optical disk, a magneto-optic disk, and/or a solid state disk), a compact disc (CD), a digital versatile disc (DVD), a floppy disk, a cartridge, a magnetic tape, and/or another type of non-transitory computer-readable medium, along with a corresponding drive.</p><p id="p-0059" num="0058">Input component <b>550</b> includes a component that permits device <b>500</b> to receive information, such as via user input (e.g., a touch screen display, a keyboard, a keypad, a mouse, a button, a switch, and/or a microphone). Additionally, or alternatively, input component <b>550</b> may include a sensor for sensing information (e.g., a global positioning system (GPS) component, an accelerometer, a gyroscope, and/or an actuator). Output component <b>560</b> includes a component that provides output information from device <b>500</b> (e.g., a display, a speaker, and/or one or more LEDs).</p><p id="p-0060" num="0059">Communication interface <b>570</b> includes a transceiver-like component (e.g., a transceiver and/or a separate receiver and transmitter) that enables device <b>500</b> to communicate with other devices, such as via a wired connection, a wireless connection, or a combination of wired and wireless connections. Communication interface <b>570</b> may permit device <b>500</b> to receive information from another device and/or provide information to another device. For example, communication interface <b>570</b> may include an Ethernet interface, an optical interface, a coaxial interface, an infrared interface, an RF interface, a universal serial bus (USB) interface, a wireless local area interface, a cellular network interface, and/or the like.</p><p id="p-0061" num="0060">Device <b>500</b> may perform one or more processes described herein. Device <b>500</b> may perform these processes based on processor <b>520</b> executing software instructions stored by a non-transitory computer-readable medium, such as memory <b>530</b> and/or storage component <b>540</b>. A computer-readable medium is defined herein as a non-transitory memory device. A memory device includes memory space within a single physical storage device or memory space spread across multiple physical storage devices.</p><p id="p-0062" num="0061">Software instructions may be read into memory <b>530</b> and/or storage component <b>540</b> from another computer-readable medium or from another device via communication interface <b>570</b>. When executed, software instructions stored in memory <b>530</b> and/or storage component <b>540</b> may cause processor <b>520</b> to perform one or more processes described herein. Additionally, or alternatively, hardwired circuitry may be used in place of or in combination with software instructions to perform one or more processes described herein. Thus, implementations described herein are not limited to any specific combination of hardware circuitry and software.</p><p id="p-0063" num="0062">The number and arrangement of components shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> are provided as an example. In practice, device <b>500</b> may include additional components, fewer components, different components, or differently arranged components than those shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. Additionally, or alternatively, a set of components (e.g., one or more components) of device <b>500</b> may perform one or more functions described as being performed by another set of components of device <b>500</b>.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart of an example process <b>600</b> for reducing false detection of successful decoding of cyclic redundancy check codes. In some implementations, one or more process blocks of <figref idref="DRAWINGS">FIG. <b>6</b></figref> may be performed by a device (e.g., network testing device <b>420</b>). In some implementations, one or more process blocks of <figref idref="DRAWINGS">FIG. <b>6</b></figref> may be performed by another device or a group of devices separate from or including the device, such as another device (e.g., base station <b>410</b>), and/or the like.</p><p id="p-0065" num="0064">As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, process <b>600</b> may include receiving, from a base station, an encoded PDCCH payload (block <b>610</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may receive, from a base station, an encoded PDCCH payload, as described above.</p><p id="p-0066" num="0065">As further shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, process <b>600</b> may include decoding the encoded PDCCH payload to obtain candidate PDCCH payloads and to generate PMs, wherein each PM of the PMs corresponds to one candidate PDCCH payload of the candidate PDCCH payloads (block <b>620</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may decode the encoded PDCCH payload to obtain candidate PDCCH payloads and to generate PMs, as described above. In some implementations, each PM of the PMs corresponds to one candidate PDCCH payload of the candidate PDCCH payloads.</p><p id="p-0067" num="0066">As further shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, process <b>600</b> may include performing a cyclic redundancy check on each of the candidate PDCCH payloads to determine, from the PMs, a passing PM (block <b>630</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may perform a cyclic redundancy check on each of the candidate PDCCH payloads to determine, from the PMs, a passing PM, as described above.</p><p id="p-0068" num="0067">As further shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, process <b>600</b> may include determining, based on the PMs, a confidence value associated with the passing PM (block <b>640</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may determine, based on the PMs, a confidence value associated with the passing PM, as described above.</p><p id="p-0069" num="0068">As further shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, process <b>600</b> may include determining whether the confidence value satisfies a threshold (block <b>650</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may determine whether the confidence value satisfies a threshold, as described above.</p><p id="p-0070" num="0069">As further shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, process <b>600</b> may include discarding, based on determining that the confidence value does not satisfy the threshold, the passing PM (block <b>660</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may discard, based on determining that the confidence value does not satisfy the threshold, the passing PM, as described above.</p><p id="p-0071" num="0070">As further shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, process <b>600</b> may include outputting, based on determining that the confidence value does satisfy the threshold, a candidate PDCCH payload corresponding to the passing PM (block <b>670</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may output, based on determining that the confidence value does satisfy the threshold, a candidate PDCCH payload corresponding to the passing PM, as described above.</p><p id="p-0072" num="0071">As further shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, process <b>600</b> may include transmitting, based on the PDCCH payload, data to the base station (block <b>680</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may transmit, based on the candidate PDCCH payload, data to the base station, as described above.</p><p id="p-0073" num="0072">Process <b>600</b> may include additional implementations, such as any single implementation or any combination of implementations described below and/or in connection with one or more other processes described elsewhere herein.</p><p id="p-0074" num="0073">In a first implementation, each PM, of the PMs, has a PM value, and determining the confidence value associated with the passing PM comprises normalizing PM values of the PMs to obtain normalized PM values, averaging the normalized PM values to obtain an average normalized PM value, and determining a difference between a normalized PM value of the passing PM and the average normalized PM value, to obtain the confidence value associated with the passing PM.</p><p id="p-0075" num="0074">In a second implementation, alone or in combination with the first implementation, process <b>600</b> includes determining, based on the PMs , respective confidence values associated with each of the PMs.</p><p id="p-0076" num="0075">In a third implementation, alone or in combination with one or more of the first and second implementations, process <b>600</b> includes determining, based on the PMs and while performing the cyclic redundancy check on the candidate PDCCH payloads, respective confidence values associated with each of the PMs.</p><p id="p-0077" num="0076">In a fourth implementation, alone or in combination with one or more of the first through third implementations, the passing PM is a first passing PM and the confidence value is a first confidence value, wherein performing the cyclic redundancy check on the candidate PDCCH payloads comprises performing the cyclic redundancy check on the candidate PDCCH payloads to determine, from the PMs, the first passing PM and a second passing PM, and process <b>600</b> further comprises determining, after discarding the first passing PM and based on the PMs, a second confidence value associated with the second passing PM, and determining whether the second confidence value satisfies the threshold.</p><p id="p-0078" num="0077">In a fifth implementation, alone or in combination with one or more of the first through fourth implementations, each PM, of the PMs, has a PM value, and performing the cyclic redundancy check on the candidate PDCCH payloads comprises performing the cyclic redundancy check on a first candidate PDCCH payload having a lowest PM value to determine whether a first PM associated with the lowest PM value is error-free; performing, based on determining that the first PM is not error-free, the cyclic redundancy check on a second candidate PDCCH payload having a second lowest PM value to determine whether a second PM associated with the second lowest PM value is error-free; and obtaining, from the PMs and based on determining that the second PM is error-free, the passing PM, wherein the passing PM corresponds to the second PM.</p><p id="p-0079" num="0078">Although <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows example blocks of process <b>600</b>, in some implementations, process <b>600</b> may include additional blocks, fewer blocks, different blocks, or differently arranged blocks than those depicted in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. Additionally, or alternatively, two or more of the blocks of process <b>600</b> may be performed in parallel.</p><p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart of an example process <b>700</b> for reducing false detection of successful decoding of cyclic redundancy check codes. In some implementations, one or more process blocks of <figref idref="DRAWINGS">FIG. <b>7</b></figref> may be performed by a device (e.g., network testing device <b>420</b>). In some implementations, one or more process blocks of <figref idref="DRAWINGS">FIG. <b>7</b></figref> may be performed by another device or a group of devices separate from or including the device, such as another device (e.g., base station <b>410</b>), and/or the like.</p><p id="p-0081" num="0080">As shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, process <b>700</b> may include receiving, from a base station, a polar encoded PDCCH payload (block <b>710</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may receive, from a base station, a polar encoded PDCCH payload, as described above.</p><p id="p-0082" num="0081">As further shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, process <b>700</b> may include decoding, using a successive cancellation list decoding algorithm, the polar encoded PDCCH payload to obtain candidate PDCCH payloads and to generate PMs, wherein each PM of the PMs corresponds to one candidate PDCCH payload of the candidate PDCCH payloads (block <b>720</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may decode, using a successive cancellation list decoding algorithm, the polar encoded PDCCH payload to obtain candidate PDCCH payloads and to generate PMs, as described above. In some implementations, each PM of the PMs corresponds to one candidate PDCCH payload of the candidate PDCCH payloads.</p><p id="p-0083" num="0082">As further shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, process <b>700</b> may include performing a cyclic redundancy check on each of the candidate PDCCH payloads to determine, from the PMs, a passing PM (block <b>730</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may perform a cyclic redundancy check on each of the candidate PDCCH payloads to determine, from the PMs, a passing PM, as described above.</p><p id="p-0084" num="0083">As further shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, process <b>700</b> may include determining, based on the PMs, a confidence value associated with the passing PM (block <b>740</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may determine, based on the PMs, a confidence value associated with the passing PM, as described above.</p><p id="p-0085" num="0084">As further shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, process <b>700</b> may include determining whether the confidence value satisfies a threshold (block <b>750</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may determine whether the confidence value satisfies a threshold, as described above.</p><p id="p-0086" num="0085">As further shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, process <b>700</b> may include discarding, based on determining that the confidence value does not satisfy the threshold, the passing PM (block <b>760</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may discard, based on determining that the confidence value does not satisfy the threshold, the passing PM, as described above.</p><p id="p-0087" num="0086">As further shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, process <b>700</b> may include outputting, based on determining that the confidence value does satisfy the threshold, a candidate PDCCH payload corresponding to the passing PM (block <b>770</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may output, based on determining that the confidence value does satisfy the threshold, a candidate PDCCH payload corresponding to the passing PM, as described above.</p><p id="p-0088" num="0087">As further shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, process <b>700</b> may include transmitting, based on the candidate PDCCH payload, data to the base station (block <b>780</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may transmit, based on the candidate PDCCH payload, data to the base station, as described above.</p><p id="p-0089" num="0088">Process <b>700</b> may include additional implementations, such as any single implementation or any combination of implementations described below and/or in connection with one or more other processes described elsewhere herein.</p><p id="p-0090" num="0089">In a first implementation, each PM, of the PMs, has a PM value, and determining the confidence value associated with the passing PM comprises normalizing PM values of the PMs to obtain normalized PM values, averaging the normalized PM values to obtain an average normalized PM value, and determining a difference between a normalized PM value of the passing PM and the average normalized PM value, to obtain the confidence value associated with the passing PM.</p><p id="p-0091" num="0090">In a second implementation, alone or in combination with the first implementation, process <b>700</b> includes determining, based on the PMs, respective confidence values associated with each of the PMs.</p><p id="p-0092" num="0091">In a third implementation, alone or in combination with one or more of the first and second implementations, process <b>700</b> includes determining, based on the PMs and while performing the cyclic redundancy check on the candidate PDCCH payloads, respective confidence values associated with each of the PMs.</p><p id="p-0093" num="0092">In a fourth implementation, alone or in combination with one or more of the first through third implementations, the passing PM is a first passing PM and the confidence value is a first confidence value, wherein performing the cyclic redundancy check on the candidate PDCCH payloads comprises performing the cyclic redundancy check on the candidate PDCCH payloads to determine, from the PMs, the first passing PM and a second passing PM, and process <b>700</b> further includes determining, after discarding the first passing PM and based on the PMs, a second confidence value associated with the second passing PM, and determining whether the second confidence value satisfies the threshold.</p><p id="p-0094" num="0093">In a fifth implementation, alone or in combination with one or more of the first through fourth implementations, the device is a network testing device.</p><p id="p-0095" num="0094">Although <figref idref="DRAWINGS">FIG. <b>7</b></figref> shows example blocks of process <b>700</b>, in some implementations, process <b>700</b> may include additional blocks, fewer blocks, different blocks, or differently arranged blocks than those depicted in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. Additionally, or alternatively, two or more of the blocks of process <b>700</b> may be performed in parallel.</p><p id="p-0096" num="0095"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart of an example process <b>800</b> for reducing false detection of successful decoding of cyclic redundancy check codes. In some implementations, one or more process blocks of Fig. may be performed by a device (e.g., network testing device <b>420</b>). In some implementations, one or more process blocks of <figref idref="DRAWINGS">FIG. <b>8</b></figref> may be performed by another device or a group of devices separate from or including the device, such as another device (e.g., base station <b>410</b>), and/or the like.</p><p id="p-0097" num="0096">As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, process <b>800</b> may include receiving, from a base station, an encoded PDCCH payload (block <b>810</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may receive, from a base station, an encoded PDCCH payload, as described above.</p><p id="p-0098" num="0097">As further shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, process <b>800</b> may include decoding the encoded PDCCH payload to obtain candidate PDCCH payloads and to generate PMs, wherein each PM of the PMs corresponds to one candidate PDCCH payload of the candidate PDCCH payloads (block <b>820</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may decode the encoded PDCCH payload to obtain candidate PDCCH payloads and to generate PMs, as described above. In some implementations, each PM of the PMs corresponds to one candidate PDCCH payload of the candidate PDCCH payloads.</p><p id="p-0099" num="0098">As further shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, process <b>800</b> may include performing a cyclic redundancy check on each of the candidate PDCCH payloads to obtain, from the PMs, a passing PM (block <b>830</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may perform a cyclic redundancy check on each of the candidate PDCCH payloads to obtain, from the PMs, a passing PM, as described above.</p><p id="p-0100" num="0099">As further shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, process <b>800</b> may include determining, based on the PMs and using a machine learning model, a confidence value associated with the passing PM (block <b>840</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may determine, based on the PMs and using a machine learning model, a confidence value associated with the passing PM, as described above.</p><p id="p-0101" num="0100">As further shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, process <b>800</b> may include determining whether the confidence value satisfies a threshold (block <b>850</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may determine whether the confidence value satisfies a threshold, as described above.</p><p id="p-0102" num="0101">As further shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, process <b>800</b> may include discarding, based on determining that the confidence value does not satisfy the threshold, the passing PM (block <b>860</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may discard, based on determining that the confidence value does not satisfy the threshold, the passing PM, as described above.</p><p id="p-0103" num="0102">As further shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, process <b>800</b> may include outputting, based on determining that the confidence value does satisfy the threshold, a candidate PDCCH payload corresponding to the passing PM (block <b>870</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may output, based on determining that the confidence value does satisfy the threshold, a candidate PDCCH payload corresponding to the passing PM, as described above.</p><p id="p-0104" num="0103">As further shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, process <b>800</b> may include transmitting, based on the candidate PDCCH payload, data to the base station (block <b>880</b>). For example, the device (e.g., using processor <b>520</b>, memory <b>530</b>, storage component <b>540</b>, input component <b>550</b>, output component <b>560</b>, communication interface <b>570</b>, and/or the like) may transmit, based on the PDCCH payload, data to the base station, as described above.</p><p id="p-0105" num="0104">Process <b>800</b> may include additional implementations, such as any single implementation or any combination of implementations described below and/or in connection with one or more other processes described elsewhere herein.</p><p id="p-0106" num="0105">In a first implementation, each PM, of the PMs, has a PM value, and determining the confidence value associated with the passing PM includes normalizing PM values of the PMs to obtain normalized PM values, averaging the normalized PM values to obtain an average normalized PM value, and determining a difference between a normalized PM value of the passing PM and the average normalized PM value, to obtain the confidence value associated with the passing PM.</p><p id="p-0107" num="0106">In a second implementation, alone or in combination with the first implementation, process <b>800</b> includes retraining the machine learning model based on at least one of the PMs, the cyclic redundancy check on the candidate PDCCH payloads, the confidence value, the threshold, or whether the confidence value satisfies the threshold.</p><p id="p-0108" num="0107">In a third implementation, alone or in combination with one or more of the first and second implementations, the machine learning model is a first machine learning model, and process <b>800</b> includes determining the threshold using a second machine learning model.</p><p id="p-0109" num="0108">In a fourth implementation, alone or in combination with one or more of the first through third implementations, process <b>800</b> includes retraining the second machine learning model based on at least one of the PMs, the cyclic redundancy check on the candidate PDCCH payloads, the confidence value, the threshold, or whether the confidence value satisfies the threshold.</p><p id="p-0110" num="0109">In a fifth implementation, alone or in combination with one or more of the first through fourth implementations, process <b>800</b> includes determining, based on the PMs and while performing the cyclic redundancy check on the candidate PDCCH payloads, respective confidence values associated with each of the PMs.</p><p id="p-0111" num="0110">In a sixth implementation, alone or in combination with one or more of the first through fifth implementations, the passing PM is a first passing PM, the confidence value is a first confidence value, and performing the cyclic redundancy check on the candidate PDCCH payloads includes performing the cyclic redundancy check on the candidate PDCCH payloads to obtain, from the PMs, the first passing PM and a second passing PM, wherein process <b>800</b> further includes determining, after discarding the first passing PM and based on the PMs, a second confidence value associated with a second passing PM, and determining whether the second confidence value satisfies the threshold.</p><p id="p-0112" num="0111">In a seventh implementation, alone or in combination with one or more of the first through sixth implementations, each PM, of the PMs, has a PM value, and performing the cyclic redundancy check on the candidate PDCCH payloads includes performing the cyclic redundancy check on a first candidate PDCCH payload having a lowest PM value to determine whether the lowest PM is error-free; performing, based on determining that the lowest PM is not error-free, the cyclic redundancy check on a second candidate PDCCH payload having a second lowest PM value to determine whether the second lowest PM is error-free; and obtaining, from the PMs and based on determining that the second lowest PM is error-free, the passing PM, wherein the passing PM corresponds to the second lowest PM.</p><p id="p-0113" num="0112">Although <figref idref="DRAWINGS">FIG. <b>8</b></figref> shows example blocks of process <b>800</b>, in some implementations, process <b>800</b> may include additional blocks, fewer blocks, different blocks, or differently arranged blocks than those depicted in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. Additionally, or alternatively, two or more of the blocks of process <b>800</b> may be performed in parallel.</p><p id="p-0114" num="0113">The foregoing disclosure provides illustration and description, but is not intended to be exhaustive or to limit the implementations to the precise form disclosed. Modifications and variations may be made in light of the above disclosure or may be acquired from practice of the implementations.</p><p id="p-0115" num="0114">As used herein, the term &#x201c;component&#x201d; is intended to be broadly construed as hardware, firmware, or a combination of hardware and software.</p><p id="p-0116" num="0115">Some implementations are described herein in connection with thresholds. As used herein, satisfying a threshold may, depending on the context, refer to a value being greater than the threshold, more than the threshold, higher than the threshold, greater than or equal to the threshold, less than the threshold, fewer than the threshold, lower than the threshold, less than or equal to the threshold, equal to the threshold, etc., depending on the context.</p><p id="p-0117" num="0116">It will be apparent that systems and/or methods described herein may be implemented in different forms of hardware, firmware, and/or a combination of hardware and software. The actual specialized control hardware or software code used to implement these systems and/or methods is not limiting of the implementations. Thus, the operation and behavior of the systems and/or methods are described herein without reference to specific software code - it being understood that software and hardware can be used to implement the systems and/or methods based on the description herein.</p><p id="p-0118" num="0117">Even though particular combinations of features are recited in the claims and/or disclosed in the specification, these combinations are not intended to limit the disclosure of various implementations. In fact, many of these features may be combined in ways not specifically recited in the claims and/or disclosed in the specification. Although each dependent claim listed below may directly depend on only one claim, the disclosure of various implementations includes each dependent claim in combination with every other claim in the claim set.</p><p id="p-0119" num="0118">No element, act, or instruction used herein should be construed as critical or essential unless explicitly described as such. Also, as used herein, the articles &#x201c;a&#x201d; and &#x201c;an&#x201d; are intended to include one or more items, and may be used interchangeably with &#x201c;one or more.&#x201d; Further, as used herein, the article &#x201c;the&#x201d; is intended to include one or more items referenced in connection with the article &#x201c;the&#x201d; and may be used interchangeably with &#x201c;the one or more.&#x201d; Furthermore, as used herein, the term &#x201c;set&#x201d; is intended to include one or more items (e.g., related items, unrelated items, a combination of related and unrelated items, etc.), and may be used interchangeably with &#x201c;one or more.&#x201d; Where only one item is intended, the phrase &#x201c;only one&#x201d; or similar language is used. Also, as used herein, the terms &#x201c;has,&#x201d; &#x201c;have,&#x201d; &#x201c;having,&#x201d; or the like are intended to be open-ended terms. Further, the phrase &#x201c;based on&#x201d; is intended to mean &#x201c;based, at least in part, on&#x201d; unless explicitly stated otherwise. Also, as used herein, the term &#x201c;or&#x201d; is intended to be inclusive when used in a series and may be used interchangeably with &#x201c;and/or,&#x201d; unless explicitly stated otherwise (e.g., if used in combination with &#x201c;either&#x201d; or &#x201c;only one of&#x201d;).</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method, comprising:<claim-text>determining, by a device, a confidence value associated with a passing path metric (PM) based on processing the passing PM using a machine learning model trained on historical PM values;</claim-text><claim-text>determining, by the device, whether the confidence value satisfies a threshold;<claim-text>discarding, by the device and based on determining that the confidence value does not satisfy the threshold, the passing PM; or</claim-text><claim-text>outputting, by the device and based on determining that the confidence value does satisfy the threshold, a candidate physical downlink control channel (PDCCH) payload corresponding to the passing PM; and</claim-text></claim-text><claim-text>transmitting, by the device and based on the candidate PDCCH payload, data to a base station.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the confidence value comprises:<claim-text>determining the confidence value based on an average normalized PM value.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the machine learning model is trained based on historical confidence values.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the threshold is determined based on an additional machine learning model.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>determining another confidence value associated with another passing PM;</claim-text><claim-text>determining whether the other confidence value satisfies the threshold; and</claim-text><claim-text>discarding the other confidence value based on determining that the other confidence value does not satisfy the threshold.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>retraining the machine learning model based on the passing PM or the confidence value.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the passing PM is identified as the passing PM based on a cyclic redundancy check.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A device, comprising:<claim-text>one or more memories; and</claim-text><claim-text>one or more processors, coupled to the one or more memories, configured to:<claim-text>determine a confidence value associated with a passing path metric (PM) based on processing the passing PM using a machine learning model trained on historical PM values;</claim-text><claim-text>determine whether the confidence value satisfies a threshold;<claim-text>discard, based on determining that the confidence value does not satisfy the threshold, the passing PM; or</claim-text><claim-text>output, based on determining that the confidence value does satisfy the threshold, a candidate physical downlink control channel (PDCCH) payload corresponding to the passing PM; and</claim-text></claim-text><claim-text>transmit, based on the candidate PDCCH payload, data to a base station.</claim-text></claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the one or more processors, to determine the confidence value, are configured to:<claim-text>determine the confidence value based on an average normalized PM value.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the machine learning model is trained based on historical confidence values.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the threshold is determined based on an additional machine learning model.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the one or more processors are further configured to:<claim-text>determine another confidence value associated with another passing PM;</claim-text><claim-text>determine whether the other confidence value satisfies the threshold; and</claim-text><claim-text>discard the other confidence value based on determining that the other confidence value does not satisfy the threshold.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the one or more processors are further configured to:<claim-text>retrain the machine learning model based on the passing PM or the confidence value.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the passing PM is identified as the passing PM based on a cyclic redundancy check.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A non-transitory computer-readable medium storing a set of instructions, the set of instructions comprising:<claim-text>one or more instructions that, when executed by one or more processors of a device, cause the device to:<claim-text>determine a confidence value associated with a passing path metric (PM) based on processing the passing PM using a machine learning model trained on historical PM values;</claim-text><claim-text>determine whether the confidence value satisfies a threshold;<claim-text>discard, based on determining that the confidence value does not satisfy the threshold, the passing PM; or</claim-text><claim-text>output, based on determining that the confidence value does satisfy the threshold, a candidate physical downlink control channel (PDCCH) payload corresponding to the passing PM; and</claim-text></claim-text><claim-text>transmit, based on the candidate PDCCH payload, data to a base station.</claim-text></claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the one or more instructions, that cause the device to determine the confidence value, cause the device to:<claim-text>determine the confidence value based on an average normalized PM value.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the machine learning model is trained based on historical confidence values.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the threshold is determined based on an additional machine learning model.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the one or more instructions further cause the device to:<claim-text>determine another confidence value associated with another passing PM;</claim-text><claim-text>determine whether the other confidence value satisfies the threshold; and</claim-text><claim-text>discard the other confidence value based on determining that the other confidence value does not satisfy the threshold.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the one or more instructions further cause the device to:<claim-text>retrain the machine learning model based on the passing PM or the confidence value.</claim-text></claim-text></claim></claims></us-patent-application>
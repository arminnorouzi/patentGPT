<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003521A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003521</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17781323</doc-number><date>20201201</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2019-218034</doc-number><date>20191202</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>C</subclass><main-group>9</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>C</subclass><main-group>21</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>C</subclass><main-group>9</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>C</subclass><main-group>21</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>C</subclass><main-group>2009</main-group><subgroup>066</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>0969</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">INFORMATION PROCESSING DEVICE, CONTROL METHOD, PROGRAM AND STORAGE MEDIUM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>PIONEER CORPORATION</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KATO</last-name><first-name>Masahiro</first-name><address><city>Saitama</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/044665</doc-number><date>20201201</date></document-id><us-371c12-date><date>20220531</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The control unit <b>15</b> of the in-vehicle device <b>1</b> is configured to extract, from voxel data VD that is position information of an object for each of unit areas (voxels) into which a space is divided, the voxel data VD of plural voxels located at or around an own vehicle. Then, the control unit <b>15</b> is configured to calculate a normal vector of an approximate plane calculated based on the extracted voxel data VD of the plural voxels. Then, the control unit <b>15</b> is configured to calculate at least one of a pitch angle of the own vehicle or a roll angle of the own vehicle based on an orientation of the own vehicle and the normal vector.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="52.15mm" wi="154.35mm" file="US20230003521A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="156.13mm" wi="157.40mm" file="US20230003521A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="156.21mm" wi="164.59mm" file="US20230003521A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="191.43mm" wi="152.48mm" file="US20230003521A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="217.51mm" wi="153.33mm" orientation="landscape" file="US20230003521A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="181.36mm" wi="143.17mm" file="US20230003521A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="208.70mm" wi="139.02mm" file="US20230003521A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="207.43mm" wi="135.64mm" file="US20230003521A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="212.34mm" wi="158.24mm" file="US20230003521A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="231.06mm" wi="120.06mm" orientation="landscape" file="US20230003521A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="233.34mm" wi="175.51mm" file="US20230003521A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="246.30mm" wi="174.50mm" file="US20230003521A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="239.69mm" wi="171.37mm" file="US20230003521A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="247.73mm" wi="169.59mm" file="US20230003521A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="248.67mm" wi="164.00mm" file="US20230003521A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present invention relates to a technique for estimating the posture of a vehicle.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">Conventionally, there is known a technique for estimating the self-position of a vehicle by collating (matching) the shape data of a peripheral object measured by a measuring device such as a laser scanner with the map information in which the shape of the peripheral object is stored in advance. For example, Patent Literature 1 discloses an autonomous mobile system configured to determine whether a detected object situated in each voxel that is obtained by dividing the space by a predetermined rule is a stationary object or a moving body and to perform matching between map information and measurement data for voxels in which stationary objects are present. Further, Patent Literature 2 discloses a scan matching method for performing the own vehicle position estimation by matching (verification) between point cloud data outputted by lidar and voxel data which includes the mean vector and the covariance matrix of stationary object(s) for each voxel.</p><heading id="h-0003" level="1">PRIOR ART DOCUMENTS</heading><heading id="h-0004" level="1">Patent Literature</heading><p id="p-0004" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0003">Patent Literature 1: WO2013/076829</li>    <li id="ul0001-0002" num="0004">Patent Literature 2: WO2018/221453</li></ul></p><heading id="h-0005" level="1">SUMMARY</heading><heading id="h-0006" level="1">Problem to be Solved by the Invention</heading><p id="p-0005" num="0005">Generally, the vehicle is constrained on the road surface, and changes in the pitch angle, roll angle, and vertical direction of the vehicle are negligibly small, though there is some fluctuation by the suspension. Therefore, in the general self-position estimation of the vehicle by scan matching, the planar position and orientation of the vehicle are set as parameters to be estimated. On the other hand, when the vehicle is traveling on a slope (hill) having a large gradient or a road with a cross slope, simply by estimating the planar position and orientation of the vehicle, it is impossible to cope with changes in pitch angle and roll angle, which leads to incorrect association between voxels to be matched and the measurement data or no association therebetween. In contrast, in order to cope with the changes in pitch angle and/or roll angle, when the pitch angle and/or the roll angle is added as a part of the estimation parameters of self-position estimation, the calculation load increases due to an increase in the number of the estimated parameters, resulting in an issue that the self-position estimation to be done in the required time cycle does not stably terminate. Although there is a method for determining the pitch angle and roll angle of the vehicle from the data outputted by an IMU (Inertial Measurement Unit), there is also an issue that the pitch angle and the roll angle cannot be accurately calculated due to the sensitivity error and offset in a common IMU.</p><p id="p-0006" num="0006">The present invention has been made in order to solve the above issues, and it is an object of the present invention to provide an information processing device capable of suitably estimating the posture of the vehicle.</p><heading id="h-0007" level="1">Means for Solving the Problem</heading><p id="p-0007" num="0007">One invention is an information processing device including: an extraction unit configured to extract, from position information of an object for each of unit areas into which a space is divided, the position information of plural unit areas located at or around a moving body; a normal vector calculation unit configured to calculate a normal vector of an approximate plane calculated based on the extracted position information of the plural unit areas; and an angle calculation unit configured to calculate at least one of a pitch angle of the moving body or a roll angle of the moving body based on an orientation of the moving body and the normal vector.</p><p id="p-0008" num="0008">Another invention is a control method executed by an information processing device, the control method including: extracting, from position information of an object for each of unit areas into which a space is divided, the position information of plural unit areas located at or around a moving body; calculating a normal vector of an approximate plane calculated based on the extracted position information of the plural unit areas; and calculating at least one of a pitch angle of the moving body or a roll angle of the moving body based on an orientation of the moving body and the normal vector.</p><p id="p-0009" num="0009">Still another invention is a program executed by a computer, the program causing the computer to function as: an extraction unit configured to extract, from position information of an object for each of unit areas into which a space is divided, the position information of plural unit areas located at or around a moving body; a normal vector calculation unit configured to calculate a normal vector of an approximate plane calculated based on the extracted position information of the plural unit areas; and an angle calculation unit configured to calculate at least one of a pitch angle of the moving body or a roll angle of the moving body based on an orientation of the moving body and the normal vector.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0008" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic configuration diagram of a driving support system.</p><p id="p-0011" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram showing a functional configuration of an in-vehicle device.</p><p id="p-0012" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a state variable vector in two-dimensional orthogonal coordinates.</p><p id="p-0013" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example of a schematic data structure of voxel data.</p><p id="p-0014" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is an example of a functional block of a NDT matching unit.</p><p id="p-0015" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is a plane view showing the correspondence between the position of the vehicle and road surface voxels.</p><p id="p-0016" num="0016"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> is a side view of the vehicle which explicitly indicates the road surface mean vector.</p><p id="p-0017" num="0017"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is an x-y plane view showing the relation between the yaw angle and the traveling direction vector of the vehicle.</p><p id="p-0018" num="0018"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates the relation among the angle formed by the normal vector, the traveling direction vector, and the pitch angle of the vehicle.</p><p id="p-0019" num="0019"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is an x-y plane view showing the relation between the yaw angle and the lateral direction vector of the vehicle.</p><p id="p-0020" num="0020"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates the relation among the angle formed by the normal vector, the lateral direction vector, and the roll angle of the vehicle.</p><p id="p-0021" num="0021"><figref idref="DRAWINGS">FIG. <b>11</b>A</figref> is a side view of a road and the vehicle traveling on the flat road surface.</p><p id="p-0022" num="0022"><figref idref="DRAWINGS">FIG. <b>11</b>B</figref> is a side view of a road and the vehicle traveling on a road surface having a large gradient in the case of not performing the coordinate transformation of the point cloud data based on the pitch angle of the vehicle.</p><p id="p-0023" num="0023"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a side view of a road and the vehicle traveling on a road surface having a large gradient in the case of performing the coordinate transformation of the point cloud data based on the pitch angle of the vehicle.</p><p id="p-0024" num="0024"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is an example of a flowchart showing the procedure of the estimation process of the position and posture of the vehicle.</p><p id="p-0025" num="0025"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is an example of a flowchart showing the procedure of the vehicle height estimation process.</p><p id="p-0026" num="0026"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is an example of a flowchart showing the procedure of the estimation process of the roll angle and pitch angle of the vehicle.</p><p id="p-0027" num="0027"><figref idref="DRAWINGS">FIGS. <b>16</b>A to <b>16</b>E</figref> indicate the transition of the number of point cloud data, the number of associations, the association ratio, the evaluation value, and the pitch angle, respectively, in the case of estimating the pitch angle and performing the coordinate transformation of the point cloud data based on the estimated pitch angle.</p><p id="p-0028" num="0028"><figref idref="DRAWINGS">FIGS. <b>17</b>A to <b>17</b>E</figref> indicate the transition of the number of point cloud data, the number of associations, the association ratio, the evaluation value, and the pitch angle, respectively, in the case of not estimating the pitch angle.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0009" level="1">DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS</heading><p id="p-0029" num="0029">According to a preferred embodiment of the present invention, there is provided an information processing device including: an extraction unit configured to extract, from position information of an object for each of unit areas into which a space is divided, the position information of plural unit areas located at or around a moving body; a normal vector calculation unit configured to calculate a normal vector of an approximate plane calculated based on the extracted position information of the plural unit areas; and an angle calculation unit configured to calculate at least one of a pitch angle of the moving body or a roll angle of the moving body based on an orientation of the moving body and the normal vector.</p><p id="p-0030" num="0030">Generally, since a moving body travels on a road surface, there is a road surface in the vicinity of the moving body and it is inferred that the road surface is included in a plurality of unit areas at or around the moving body. Further, the moving body is constrained to the road surface, the pitch angle and the roll angle of the moving body depend on the inclination of the road surface. In view of the above, in this embodiment, the information processing device calculates a normal vector of a plane, which approximates the road surface, based on position information, which is presumed to be the position information of the road surface, of an object existing in plural unit areas. Thereby, the information processing device can suitably calculate at least one of the pitch angle or the roll angle of the moving body, based on the relation between the calculated normal vector and the orientation of the moving body.</p><p id="p-0031" num="0031">In one mode of the information processing device, the angle calculation unit calculates the pitch angle based on an inner product of the normal vector and a vector indicative of the orientation of a travelling direction of the moving body on a horizontal plane. According to this mode, the information processing device calculates the angle formed between the normal vector of the approximate plane and the traveling direction of the moving body on the horizontal plane, thereby to suitably determine the pitch angle of the moving body.</p><p id="p-0032" num="0032">In another mode of the information processing device, the angle calculation unit calculates the roll angle based on an inner product of the normal vector and a vector indicative of the orientation of a lateral direction of the moving body on a horizontal plane. According to this mode, the information processing device calculates the angle formed between the normal vector of the approximate plane and the lateral direction of the moving body on the horizontal plane, thereby to suitably determine the roll angle of the moving body.</p><p id="p-0033" num="0033">In still another mode of the information processing device, the information processing device further includes a position estimation unit configured to perform position estimation of the moving body through matching for each of the unit areas between the position information of the object and data obtained by a coordinate transformation of measurement data based on at least one of the pitch angle or the roll angle, the measurement data being outputted by a measurement unit mounted on the moving body. In this mode, the information processing device performs the position estimation of the moving body through matching (verification) between the position information of the object and the measurement data outputted by the measuring unit. At this time, the information processing device performs the coordinate transformation of the measurement data based on the calculated pitch angle or roll angle. Thereby, even when the variation in the pitch angle or the roll angle of the vehicle occurs by running on a hill or a road with a high cross slope, the information processing device can perform the matching while accurately associating the unit areas where a target object of measurement is actually present with the measurement data of the target object of measurement.</p><p id="p-0034" num="0034">In still another mode of the information processing device, the position information of the object for each of the unit areas includes information indicative of a mean vector of the position of the object for each of the unit areas, and the normal vector calculation unit calculates the normal vector based on the coordinates of the mean vector for each of the plural unit areas. According to this mode, based on the position information of the object in plural unit areas inferred to be the position information of a road surface on which the moving body is present, the information processing device can suitably calculate the normal vector of the plane approximating the road surface.</p><p id="p-0035" num="0035">In still another mode of the information processing device, the extracting unit extracts the position information corresponding to a first unit area overlapping with the position of the moving body and second unit areas adjacent to the first unit area, the first unit area and the second unit areas being selected from unit areas which have the position information of the object. According to this mode, the information processing device can suitably extract the position information of the object in plural unit areas inferred as the position information of the road surface.</p><p id="p-0036" num="0036">In still another mode of the information processing device, the information processing device further includes a height calculation unit configured to calculates a height of the moving body from a reference position based on the position information of the first unit area and information indicative of a height of the moving body from a road surface. The reference position herein indicates is a position in the absolute coordinate system to be a reference used in map data or the like, and for example, it indicates the position of the altitude 0 m. According to this mode, the information processing device can suitably calculate the height of the moving body from the reference position by using the position information of the object (road surface) in the first unit area in which the moving body is inferred to exist. In some embodiments, if the difference between the height from the reference position calculated based on the position information of the object in the first unit area and the information indicative of the height of the moving body from the road surface and the height from the reference position calculated at the preceding processing time is larger than a predetermined value, height calculation unit may determine the height from the reference position at the current processing time to be the height from the reference position calculated at the preceding processing time. Thereby, when an error occurs in the height of the calculated moving body due to existence of a grade-separated crossing or guard rail in the vicinity, it is possible to suitably suppress recognizing the erroneous height of moving body as the current height of moving body.</p><p id="p-0037" num="0037">In still another mode of the information processing device, the position information is position information of a stationary structure including a road surface, and the extracting unit extracts position information of the road surface included in the plural unit areas from map data including the position information of the object for each of the unit areas. According to this mode, the information processing device suitably extract the position information of the road surface in which the moving body is present from the map data and thereby suitably calculates the normal vector of the approximate plane necessary for calculating the pitch angle or roll angle.</p><p id="p-0038" num="0038">According to another preferred embodiment of the present invention, there is provided a control method executed by an information processing device, the control method including: extracting, from position information of an object for each of unit areas into which a space is divided, the position information of plural unit areas located at or around a moving body; calculating a normal vector of an approximate plane calculated based on the extracted position information of the plural unit areas; and calculating at least one of a pitch angle of the moving body or a roll angle of the moving body based on an orientation of the moving body and the normal vector. By executing the control method, the information processing device can suitably calculate at least one of the pitch angle or the roll angle of the moving body, based on the relation between the normal vector calculated based on position information of unit areas at or around the moving body and the orientation of the moving body.</p><p id="p-0039" num="0039">According to still another preferred embodiment of the present invention, there is provided a program executed by a computer, the program causing the computer to function as: an extraction unit configured to extract, from position information of an object for each of unit areas into which a space is divided, the position information of plural unit areas located at or around a moving body; a normal vector calculation unit configured to calculate a normal vector of an approximate plane calculated based on the extracted position information of the plural unit areas; and an angle calculation unit configured to calculate at least one of a pitch angle of the moving body or a roll angle of the moving body based on an orientation of the moving body and the normal vector. By executing the program, the computer can suitably calculate at least one of the pitch angle or the roll angle of the moving body, based on the relation between the normal vector calculated based on position information of unit areas at or around the moving body and the orientation of the moving body. In some embodiments, the program is stored in a storage medium.</p><heading id="h-0010" level="1">EMBODIMENTS</heading><p id="p-0040" num="0040">Hereinafter, preferred embodiments of the present invention are described below with reference to drawings. It is noted that a character with &#x201c;{circumflex over (&#x2003;)}&#x201d; or &#x201c;&#x2212;&#x201d; on its top is expressed in this specification as &#x201c;A<sup>{circumflex over (&#x2003;)}</sup>&#x201d; or &#x201c;A<sup>&#x2212;</sup>&#x201d; (where &#x201c;A&#x201d; is a character) for convenience.</p><heading id="h-0011" level="1">(1) Outline of Driving Support System</heading><p id="p-0041" num="0041"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic configuration of a driving support system according to the present embodiment. The driving support system includes an in-vehicle device <b>1</b> that moves with a vehicle that is a moving body, a lidar (Lidar: Light Detection and Ranging, or Laser Illuminated Detection And Ranging) <b>2</b>, a gyroscope sensor <b>3</b>, a vehicle velocity sensor <b>4</b>, and a GPS receiver <b>5</b>.</p><p id="p-0042" num="0042">The in-vehicle device <b>1</b> is electrically connected to the lidar <b>2</b>, the gyroscope sensor <b>3</b>, the vehicle velocity sensor <b>4</b>, and the GPS receiver <b>5</b>, and based on these outputs, estimates the position (also referred to as &#x201c;own vehicle position&#x201d;) of the vehicle equipped with the in-vehicle device <b>1</b>. Then, the in-vehicle device <b>1</b> performs autonomous driving control of the vehicle so as to travel along a route to the set destination based on the estimation result of the own vehicle position. The in-vehicle device <b>1</b> stores a map database (DB) <b>10</b> including voxel data &#x201c;VD&#x201d;. The voxel data VD is data in which position information and the like of a stationary structure are recorded for each voxel that is a minimum unit of a three-dimensional space in a cube (normalized grid) shape. The voxel data VD includes data which expresses, by normal distribution with respect to each voxel, measured point cloud data of stationary structures, and is used for scan matching using NDT (Normal Distributions Transform), as will be described later. Further, while estimating the planar position and the yaw angle of the vehicle by NDT scan matching, the in-vehicle device <b>1</b> estimates the height position of the vehicle and at least one of the pitch angle or the roll angle, based on the voxel data VD.</p><p id="p-0043" num="0043">The lidar <b>2</b> emits pulsed lasers for a predetermined angular range in the horizontal and vertical directions to thereby discretely measure the distance to an external object and then generates three-dimensional point cloud information indicating the position of the object. In this case, the lidar <b>2</b> includes: a radiation (emitting) unit for radiating (emitting) a laser beam while changing the irradiation (emitting) direction; a light receiving unit for receiving the reflected light (scattered light) which is the laser beam reflected by the object; and an output unit for outputting scan data based on the light receiving signal outputted by the light receiving unit. The scan data is generated based on the irradiation direction corresponding to the laser beam received by the light receiving unit and the response delay time of the laser beam specified based on the light receiving signal described above. In general, the closer the distance to the object is, the higher the accuracy of the lidar's distance measurement value becomes, and the farther the distance is, the lower the accuracy thereof becomes. The lidar <b>2</b>, the gyroscope sensor <b>3</b>, the vehicle velocity sensor <b>4</b>, the GPS receiver <b>5</b>, respectively, supply the output data to the in-vehicle device <b>1</b>. The in-vehicle device <b>1</b> is an example of an &#x201c;information processing device&#x201d; in the present invention, the lidar <b>2</b> is an example of a &#x201c;measurement unit&#x201d; in the present invention.</p><p id="p-0044" num="0044">Incidentally, the driving support system, in place of or in addition to having the gyroscope sensor <b>3</b>, may have an inertial measurement unit (IMU) for measuring the acceleration and angular velocity of the vehicle in the three-axis direction.</p><heading id="h-0012" level="1">(2) Configuration of In-Vehicle Device</heading><p id="p-0045" num="0045"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram showing a functional configuration of the in-vehicle device <b>1</b>. The in-vehicle device <b>1</b> mainly includes an interface <b>11</b>, a storage unit <b>12</b>, a communication unit <b>13</b>, an input unit <b>14</b>, a control unit <b>15</b>, and an information output unit <b>16</b>. Each of these elements is connected to each other via a bus line.</p><p id="p-0046" num="0046">The interface <b>11</b> acquires output data from sensors such as the lidar <b>2</b>, the gyroscope sensor <b>3</b>, the vehicle velocity sensor <b>4</b>, and the GPS receiver <b>5</b>, and supplies the output data to the control unit <b>15</b>. Further, the interface <b>11</b> supplies a signal relating to the driving control of the vehicle generated by the control unit <b>15</b> to the electronic control unit (ECU: Electronic Control Unit) of the vehicle.</p><p id="p-0047" num="0047">The storage unit <b>12</b> stores a program to be executed by the control unit <b>15</b>, and the information necessary for the control unit <b>15</b> to execute a predetermined process. In this example, the storage unit <b>12</b> stores the map DB <b>10</b> including the voxel data VD. The map DB <b>10</b> may be updated periodically. In this case, for example, the control unit <b>15</b> receives, via the communication unit <b>13</b>, from the server device which manages the map information, the partial map information relating to the area to which the own vehicle position belongs, and reflects it into the map DB <b>10</b>. Incidentally, the storage unit <b>12</b> may not store the map DB <b>10</b>. In this case, for example, the control unit <b>15</b> communicates, via the communication unit <b>13</b>, with a server device which stores the map data including the voxel data VD, and thereby acquires information necessary for the own vehicle position estimation processing or the like as necessary.</p><p id="p-0048" num="0048">Examples of the input unit <b>14</b> include a button, a touch panel, a remote controller, a voice input device, which are provided for the user to operate. The input unit <b>14</b> accepts an input for specifying a destination for the route search, an input for specifying ON or OFF of the autonomous driving operation, and the like. The information output unit <b>16</b> is, for example, a display or a speaker or the like for outputting information based on the control of the control unit <b>15</b>.</p><p id="p-0049" num="0049">The control unit <b>15</b> includes a CPU or the like for executing a program, and controls the entire in-vehicle device <b>1</b>. In this example, the control unit <b>15</b> includes a posture angle calculation unit <b>17</b> and an NDT matching unit <b>18</b>. The control unit <b>15</b> is an example of the &#x201c;extraction unit&#x201d;, the &#x201c;normal vector calculation unit&#x201d;, the &#x201c;angle calculation unit&#x201d;, the &#x201c;position estimation unit&#x201d;, the &#x201c;height calculation unit&#x201d;, and the &#x201c;computer&#x201d; that executes a program in the present invention.</p><p id="p-0050" num="0050">The posture angle calculation unit <b>17</b> refers to the voxel data VD and calculates at least one of the pitch angle or the roll angle of the vehicle. The NDT matching unit <b>18</b> estimate the own vehicle position by performing scan matching based on NDT (NDT scan matching) using point cloud data outputted from the lidar <b>2</b> and the voxel data VD corresponding to voxels to which the point cloud data belongs. In this example, as will be described later, in the NDT scan matching, the NDT matching unit <b>18</b> sets the planar position of the vehicle (i.e., the position on the horizontal plane specified by latitude and longitude) and the yaw angle (i.e., azimuth orientation) of the vehicle as estimation parameters.</p><heading id="h-0013" level="1">(3) Position Estimation Based on NDT Scan Matching</heading><p id="p-0051" num="0051"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram showing the own vehicle position to be estimated by the own vehicle position estimator <b>18</b> in two-dimensional orthogonal coordinates. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the own vehicle position on a plane defined in the two-dimensional orthogonal coordinates x-y is represented by the coordinates &#x201c;(x, y)&#x201d; and the orientation (yaw angle) &#x201c;&#x3c8;&#x201d; of the vehicle. Here, the yaw angle &#x3c8; is defined as the angle formed by the traveling direction of the vehicle and the x-axis. The coordinates (x, y) indicate, for example, an absolute position corresponding to the combination of latitude and longitude, or world coordinates indicating a position with respect to the predetermined origin. Then, the own vehicle position estimator <b>18</b> performs the own vehicle position estimation using these x, y, and w as estimation parameters. The estimation method of the pitch angle and roll angle of the vehicle will be described in detail in the section &#x201c;(4) Calculation of Posture Angles&#x201d;.</p><p id="p-0052" num="0052">Next, the voxel data VD to be used for NDT scan matching will be described. The voxel data VD includes data representing, by normal distribution, the measured point cloud data of stationary structure(s) in each voxel.</p><p id="p-0053" num="0053"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows an example of a schematic data structure of the voxel data VD. The voxel data VD includes information relating to parameters of the normal distribution for representing the point cloud in each voxel. According to the embodiment, as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the voxel data VD includes the voxel ID, the voxel coordinates, the mean vector, and the covariance matrix.</p><p id="p-0054" num="0054">The &#x201c;voxel coordinates&#x201d; herein indicates three-dimensional absolute coordinates of the reference position (such as central position) of each voxel. It is noted that a voxel is each of cubes (or grids) into which the space is divided in a reticular pattern, and the shape and the size thereof are preliminarily determined. Thus, it is possible to identify the space corresponding to each voxel by its voxel coordinates. It is also noted that the voxel coordinates may be used as the voxel ID.</p><p id="p-0055" num="0055">The &#x201c;mean vector&#x201d; and &#x201c;covariance matrix&#x201d; indicate the mean vector and the covariance matrix corresponding to parameters of the normal distribution which represents the point cloud in a voxel of interest, respectively. Here, the coordinates of a point &#x201c;i&#x201d; in a voxel &#x201c;n&#x201d; are defined as follows.</p><p id="p-0056" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>X</i><sub>n</sub>(<i>i</i>)=[<i>x</i><sub>n</sub>(<i>i</i>),<i>y</i><sub>n</sub>(<i>i</i>),<i>z</i><sub>n</sub>(<i>i</i>)]<sup>T </sup><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0057" num="0056">Besides, if &#x201c;N<sub>n</sub>&#x201d; denotes the number of point clouds in the voxel n, the mean vector &#x201c;&#x3bc;<sub>n</sub>&#x201d; and the covariance matrix &#x201c;V<sub>n</sub>&#x201d; in the voxel n are expressed by the following equations (1) and (2), respectively.</p><p id="p-0058" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msub>      <mi>&#x3bc;</mi>      <mi>n</mi>     </msub>     <mo>=</mo>     <mrow>      <mrow>       <mo>[</mo>       <mtable>        <mtr>         <mtd>          <msub>           <mover>            <mi>x</mi>            <mo>_</mo>           </mover>           <mi>n</mi>          </msub>         </mtd>        </mtr>        <mtr>         <mtd>          <msub>           <mover>            <mi>y</mi>            <mo>_</mo>           </mover>           <mi>n</mi>          </msub>         </mtd>        </mtr>        <mtr>         <mtd>          <msub>           <mover>            <mi>z</mi>            <mo>_</mo>           </mover>           <mi>n</mi>          </msub>         </mtd>        </mtr>       </mtable>       <mo>]</mo>      </mrow>      <mo>=</mo>      <mrow>       <mfrac>        <mn>1</mn>        <msub>         <mi>N</mi>         <mi>n</mi>        </msub>       </mfrac>       <mo>&#x2062;</mo>       <mrow>        <munderover>         <mo>&#x2211;</mo>         <mrow>          <mi>i</mi>          <mo>=</mo>          <mn>1</mn>         </mrow>         <msub>          <mi>N</mi>          <mi>n</mi>         </msub>        </munderover>        <mrow>         <msub>          <mi>X</mi>          <mi>n</mi>         </msub>         <mo>(</mo>         <mi>i</mi>         <mo>)</mo>        </mrow>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>1</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths><maths id="MATH-US-00001-2" num="00001.2"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msub>      <mi>V</mi>      <mi>n</mi>     </msub>     <mo>=</mo>     <mrow>      <mfrac>       <mn>1</mn>       <mrow>        <msub>         <mi>N</mi>         <mi>n</mi>        </msub>        <mo>-</mo>        <mn>1</mn>       </mrow>      </mfrac>      <mo>&#x2062;</mo>      <mrow>       <munderover>        <mo>&#x2211;</mo>        <mrow>         <mi>i</mi>         <mo>=</mo>         <mn>1</mn>        </mrow>        <msub>         <mi>N</mi>         <mi>n</mi>        </msub>       </munderover>       <mrow>        <mrow>         <mo>{</mo>         <mrow>          <mrow>           <msub>            <mi>X</mi>            <mi>n</mi>           </msub>           <mo>(</mo>           <mi>i</mi>           <mo>)</mo>          </mrow>          <mo>-</mo>          <msub>           <mi>&#x3bc;</mi>           <mi>n</mi>          </msub>         </mrow>         <mo>}</mo>        </mrow>        <mo>&#x2062;</mo>        <msup>         <mrow>          <mo>{</mo>          <mrow>           <mrow>            <msub>             <mi>X</mi>             <mi>n</mi>            </msub>            <mo>(</mo>            <mi>i</mi>            <mo>)</mo>           </mrow>           <mo>-</mo>           <msub>            <mi>&#x3bc;</mi>            <mi>n</mi>           </msub>          </mrow>          <mo>}</mo>         </mrow>         <mi>T</mi>        </msup>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>2</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0059" num="0057">Next, an outline of the NDT scan matching using voxel data VD will be described.</p><p id="p-0060" num="0058">In the NDT scan matching assuming a vehicle, the following estimation parameter P, which includes as its elements the movement amount on the road plane (hereinafter referred to as x-y coordinates) and the orientation of the vehicle, is estimated.</p><p id="p-0061" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>P</i>=[<i>t</i><sub>x</sub><i>,t</i><sub>y</sub><i>,t</i><sub>&#x3c8;</sub>]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0062" num="0059">Here, &#x201c;t<sub>x</sub>&#x201d; indicates the moving amount in the x-direction, &#x201c;t<sub>y</sub>&#x201d; indicates the moving amount in the y-direction, &#x201c;t<sub>&#x3c8;</sub>&#x201d; indicates the yaw angle.</p><p id="p-0063" num="0060">Here, the point cloud data obtained by the lidar <b>2</b> is associated with the voxels to be matched, and the coordinates of a point existing in the corresponding voxel n is expressed as follows.</p><p id="p-0064" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>X</i><sub>L</sub>=[<i>x</i><sub>n</sub>(<i>j</i>),<i>y</i><sub>n</sub>(<i>j</i>),<i>z</i><sub>n</sub>(<i>j</i>)]<sup>T </sup><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0065" num="0061">Then, the mean value &#x201c;L&#x2032;<sub>n</sub>&#x201d; of X<sub>L </sub>(j) in the voxel n is expressed by the following equation (3).</p><p id="p-0066" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msubsup>      <mi>L</mi>      <mi>n</mi>      <mo>&#x2032;</mo>     </msubsup>     <mo>=</mo>     <mrow>      <mrow>       <mo>[</mo>       <mtable>        <mtr>         <mtd>          <msubsup>           <mi>L</mi>           <mi>x</mi>           <mo>&#x2032;</mo>          </msubsup>         </mtd>        </mtr>        <mtr>         <mtd>          <msubsup>           <mi>L</mi>           <mi>y</mi>           <mo>&#x2032;</mo>          </msubsup>         </mtd>        </mtr>        <mtr>         <mtd>          <msubsup>           <mi>L</mi>           <mi>z</mi>           <mo>&#x2032;</mo>          </msubsup>         </mtd>        </mtr>       </mtable>       <mo>]</mo>      </mrow>      <mo>=</mo>      <mrow>       <mfrac>        <mn>1</mn>        <mi>N</mi>       </mfrac>       <mo>&#x2062;</mo>       <mrow>        <munderover>         <mo>&#x2211;</mo>         <msup>          <mrow>           <mi>j</mi>           <mo>=</mo>           <mn>1</mn>          </mrow>         </msup>         <mi>N</mi>        </munderover>        <mrow>         <msub>          <mi>X</mi>          <mi>L</mi>         </msub>         <mo>(</mo>         <mi>j</mi>         <mo>)</mo>        </mrow>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>3</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0067" num="0062">When the mean value L&#x2032; is coordinate-transformed using the above-described estimation parameter P, the coordinate &#x201c;L<sub>n</sub>&#x201d; after the transformation is expressed by the following equation (4).</p><p id="p-0068" num="0000"><maths id="MATH-US-00003" num="00003"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msub>      <mi>L</mi>      <mi>n</mi>     </msub>     <mo>=</mo>     <mrow>      <mrow>       <mo>[</mo>       <mtable>        <mtr>         <mtd>          <msub>           <mi>L</mi>           <mi>x</mi>          </msub>         </mtd>        </mtr>        <mtr>         <mtd>          <msub>           <mi>L</mi>           <mi>y</mi>          </msub>         </mtd>        </mtr>        <mtr>         <mtd>          <msub>           <mi>L</mi>           <mi>z</mi>          </msub>         </mtd>        </mtr>       </mtable>       <mo>]</mo>      </mrow>      <mo>=</mo>      <mrow>       <mrow>        <mrow>         <mo>[</mo>         <mtable>          <mtr>           <mtd>            <mrow>             <mi>cos</mi>             <mo>&#x2062;</mo>             <msub>              <mi>t</mi>              <mi>&#x3c8;</mi>             </msub>            </mrow>           </mtd>           <mtd>            <mrow>             <mrow>              <mo>-</mo>              <mi>sin</mi>             </mrow>             <mo>&#x2062;</mo>             <msub>              <mi>t</mi>              <mi>&#x3c8;</mi>             </msub>            </mrow>           </mtd>           <mtd>            <mn>0</mn>           </mtd>          </mtr>          <mtr>           <mtd>            <mrow>             <mi>sin</mi>             <mo>&#x2062;</mo>             <msub>              <mi>t</mi>              <mi>&#x3c8;</mi>             </msub>            </mrow>           </mtd>           <mtd>            <mrow>             <mi>cos</mi>             <mo>&#x2062;</mo>             <msub>              <mi>t</mi>              <mi>&#x3c8;</mi>             </msub>            </mrow>           </mtd>           <mtd>            <mn>0</mn>           </mtd>          </mtr>          <mtr>           <mtd>            <mn>0</mn>           </mtd>           <mtd>            <mn>0</mn>           </mtd>           <mtd>            <mn>1</mn>           </mtd>          </mtr>         </mtable>         <mo>]</mo>        </mrow>        <mo>[</mo>        <mtable>         <mtr>          <mtd>           <msubsup>            <mi>L</mi>            <mi>x</mi>            <mo>&#x2032;</mo>           </msubsup>          </mtd>         </mtr>         <mtr>          <mtd>           <msubsup>            <mi>L</mi>            <mi>y</mi>            <mo>&#x2032;</mo>           </msubsup>          </mtd>         </mtr>         <mtr>          <mtd>           <msubsup>            <mi>L</mi>            <mi>z</mi>            <mo>&#x2032;</mo>           </msubsup>          </mtd>         </mtr>        </mtable>        <mo>]</mo>       </mrow>       <mo>+</mo>       <mrow>        <mo>[</mo>        <mtable>         <mtr>          <mtd>           <msub>            <mi>t</mi>            <mi>x</mi>           </msub>          </mtd>         </mtr>         <mtr>          <mtd>           <msub>            <mi>t</mi>            <mi>y</mi>           </msub>          </mtd>         </mtr>         <mtr>          <mtd>           <mn>0</mn>          </mtd>         </mtr>        </mtable>        <mo>]</mo>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>4</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0069" num="0063">By using the point cloud data converted into data in the absolute coordinate system (also referred to as &#x201c;world coordinate system&#x201d;) which is the same coordinate system as the map DB <b>10</b>, and the mean vector &#x3bc;<sub>n </sub>and the covariance matrix V<sub>n </sub>included in the voxel data VD, the in-vehicle device <b>1</b> calculates an evaluation function value (also referred to as &#x201c;individual evaluation function value&#x201d;) &#x201c;E<sub>n</sub>&#x201d; for the voxel n. In this case, the in-vehicle device <b>1</b> calculates the individual evaluation function value E<sub>n </sub>for the voxel n based on the following equation (5).</p><p id="p-0070" num="0000"><maths id="MATH-US-00004" num="00004"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msub>      <mi>E</mi>      <mi>n</mi>     </msub>     <mo>=</mo>     <mrow>      <mi>exp</mi>      <mo>&#x2062;</mo>      <mrow>       <mo>{</mo>       <mrow>        <mrow>         <mo>-</mo>         <mfrac>          <mn>1</mn>          <mn>2</mn>         </mfrac>        </mrow>        <mo>&#x2062;</mo>        <msup>         <mrow>          <mo>(</mo>          <mrow>           <msub>            <mi>L</mi>            <mi>n</mi>           </msub>           <mo>-</mo>           <msub>            <mi>&#x3bc;</mi>            <mi>n</mi>           </msub>          </mrow>          <mo>)</mo>         </mrow>         <mi>T</mi>        </msup>        <mo>&#x2062;</mo>        <mrow>         <msubsup>          <mi>V</mi>          <mi>n</mi>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>         </msubsup>         <mo>(</mo>         <mrow>          <msub>           <mi>L</mi>           <mi>n</mi>          </msub>          <mo>-</mo>          <msub>           <mi>&#x3bc;</mi>           <mi>n</mi>          </msub>         </mrow>         <mo>)</mo>        </mrow>       </mrow>       <mo>}</mo>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>5</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0071" num="0064">Then, the in-vehicle device <b>1</b> calculates the total evaluation function value (also referred to as &#x201c;total evaluation function value E (k)&#x201d;) for all voxels to be matched as shown by the following equation (6).</p><p id="p-0072" num="0000"><maths id="MATH-US-00005" num="00005"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>E</mi>      <mo>&#x2061;</mo>      <mo>(</mo>      <mi>k</mi>      <mo>)</mo>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <munderover>        <mo>&#x2211;</mo>        <mrow>         <mi>n</mi>         <mo>=</mo>         <mn>1</mn>        </mrow>        <mi>M</mi>       </munderover>       <msub>        <mi>E</mi>        <mi>n</mi>       </msub>      </mrow>      <mo>=</mo>      <mrow>       <msub>        <mi>E</mi>        <mn>1</mn>       </msub>       <mo>+</mo>       <msub>        <mi>E</mi>        <mn>2</mn>       </msub>       <mo>+</mo>       <mo>&#x2026;</mo>       <mo>+</mo>       <msub>        <mi>E</mi>        <mi>M</mi>       </msub>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>6</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0073" num="0065">Thereafter, through an arbitrary root finding algorithm such as Newton method, the in-vehicle device <b>1</b> calculates the estimation parameter P at which the total evaluation function value E (k) is maximized. Then, by applying the estimation parameter P to the predicted vehicle position &#x201c;X<sup>&#x2212;</sup> (k)&#x201d; tentatively calculated by the dead reckoning, the in-vehicle device <b>1</b> calculates the accurately-estimated own vehicle position &#x201c;X<sup>{circumflex over (&#x2003;)}</sup>(k)&#x201d; using the following equation (7).</p><p id="p-0074" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>{circumflex over (x)}</i>(<i>k</i>)=<i><o ostyle="single">x</o></i>(<i>k</i>)+<i>P</i>&#x2003;&#x2003;(7)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0075" num="0066">Here, the state variable vector indicating the own vehicle position at the target reference time of calculation (i.e., the current processing time) &#x201c;k&#x201d; is denoted as &#x201c;X<sup>&#x2212;</sup> (k)&#x201d; or &#x201c;X<sup>{circumflex over (&#x2003;)}</sup>(k)&#x201d;.</p><p id="p-0076" num="0067"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is an example of a functional block of the NDT matching unit <b>18</b>. As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the own vehicle position estimator <b>18</b> includes a dead reckoning block <b>21</b>, a position prediction block <b>22</b>, a coordinate transformation block <b>23</b>, a point cloud data association block <b>24</b>, and a position correction block <b>25</b>.</p><p id="p-0077" num="0068">The dead reckoning block <b>21</b> uses the movement velocity and angular velocity of the vehicle based on the output of the gyroscope sensor <b>3</b>, the vehicle velocity sensor <b>4</b>, and the GPS receiver <b>5</b> and the like, to determine the movement distance and orientation change from the preceding processing time. The position prediction block <b>22</b> calculates the predicted vehicle position X<sup>&#x2212;</sup> (k) at the time k by adding the calculated movement distance and orientation change to the estimated own vehicle position X<sup>{circumflex over (&#x2003;)}</sup>(k&#x2212;1) at the time k&#x2212;1 calculated at the immediately preceding step.</p><p id="p-0078" num="0069">The coordinate transformation block <b>23</b> converts the point cloud data outputted from the lidar <b>2</b> into data in the world coordinate system that is the same coordinate system as the coordinate system adopted in the map DB <b>10</b>. In this case, the coordinate transformation block <b>23</b> performs the coordinate transformation of the point cloud data outputted by the lidar <b>2</b> at time k based on the predicted vehicle position (i.e., the planar position and the azimuth orientation of the vehicle) outputted by the position prediction block <b>22</b> at time k and the height and the posture angle (here at least one of the pitch angle or roll angle) of the vehicle outputted by the posture angle calculation unit <b>17</b> at time k. Details of this coordinate transformation will be described later.</p><p id="p-0079" num="0070">The point cloud data association block <b>24</b> associates the point cloud data with the voxels by performing the matching between the point cloud data in the world coordinate system outputted by the coordinate transformation block <b>23</b> and the voxel data VD represented by the same world coordinate system. The position correction block <b>25</b> calculates the individual evaluation function value according to the equation (5) for each voxel which is associated with the point cloud data, and calculates the estimation parameter P at which the total evaluation function value E (k) according to the equation (6) becomes the maximum. Then, the position correction block <b>25</b> calculates the estimated vehicle position X<sup>{circumflex over (&#x2003;)}</sup>(k) according to the equation (7) by applying the estimation parameter P obtained at time k to the predicted vehicle position X<sup>&#x2212;</sup> (k) outputted by the position prediction block <b>22</b>.</p><heading id="h-0014" level="1">(4) Calculation of Posture Angles</heading><p id="p-0080" num="0071">Next, a description will be given of a calculation method of the pitch angle and the roll angle that are the posture angles of the vehicle by the posture angle calculation unit <b>17</b> using the voxel data VD.</p><p id="p-0081" num="0072">(4-1) Calculation of Pitch Angle</p><p id="p-0082" num="0073">First, a description will be given of a calculation method of the pitch angle of the vehicle by the posture angle calculation unit <b>17</b>.</p><p id="p-0083" num="0074">The posture angle calculation unit <b>17</b> refers to the voxel data VD and searches voxels (also referred to as &#x201c;road surface voxels&#x201d;) corresponding to a road surface for a road surface voxel located at the own vehicle planar position x and y (i.e., (x<sup>&#x2212;</sup>, y<sup>&#x2212;</sup>) or (x<sup>{circumflex over (&#x2003;)}</sup>, y<sup>{circumflex over (&#x2003;)}</sup>)) predicted or estimated by the NDT matching unit <b>18</b>. Then, the posture angle calculation unit <b>17</b> acquires the voxel data VD corresponding to the &#x201c;n&#x201d; voxels which include the road surface voxel (also referred to as &#x201c;own vehicle position road surface voxel&#x201d;) located at the own vehicle planar position x, y and its peripheral road surface voxels. Herein, &#x201c;n&#x201d; is any integer larger than or equal to 3. The own vehicle position road surface voxel is an example of the &#x201c;first unit area&#x201d; in the present invention, and the n&#x2212;1 peripheral road surface voxels other than the own vehicle position road surface voxel are an example of the &#x201c;second unit areas&#x201d; in the present invention.</p><p id="p-0084" num="0075"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is a plane view showing the correspondence between the position of the vehicle and the road surface voxels. <figref idref="DRAWINGS">FIG. <b>6</b>A</figref> indicates the own vehicle position road surface voxel &#x201c;Vo<b>5</b>&#x201d; located at the vehicle planar position x, y (here (x<sup>{circumflex over (&#x2003;)}</sup>, y<sup>{circumflex over (&#x2003;)}</sup>)), and other road surface voxels &#x201c;Vol&#x201d; to &#x201c;Vo<b>4</b>&#x201d; and &#x201c;Vo<b>6</b>&#x201d; to &#x201c;Vo<b>9</b>&#x201d; positioned at front, rear, left and right of the own vehicle position road surface voxel Vo<b>5</b>. In this example, &#x201c;n=9&#x201d; is assumed, and the posture angle calculation unit <b>17</b> acquires the voxel data VD corresponding to the nine road surface voxels Vol to Vo<b>9</b> from the map DB <b>10</b>.</p><p id="p-0085" num="0076">Next, the posture angle calculation unit <b>17</b> calculates mean vectors (also referred to as a &#x201c;road surface mean vectors&#x201d;) in the world coordinate system of the road surface included in the n road surface voxels, based on the information indicative of the voxel coordinates and the mean vectors included in the voxel data VD corresponding to the n road surface voxels, respectively.</p><p id="p-0086" num="0077"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> is a side view of the vehicle that explicitly indicates a road surface mean vector for each road surface voxel. <figref idref="DRAWINGS">FIG. <b>6</b>B</figref> indicates the coordinate positions &#x201c;M<b>4</b>&#x201d; to &#x201c;M<b>6</b>&#x201d; of the road surface mean vectors corresponding to the road surface voxels Vo<b>4</b> to Vo<b>6</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, respectively. Since &#x201c;n=9&#x201d;, the posture angle calculation unit <b>17</b> calculates the road surface mean vectors corresponding to the nine road surface voxels Vol to Vo<b>9</b>, based on the voxel data VD corresponding to the nine road surface voxels Vol to Vo<b>9</b>, respectively.</p><p id="p-0087" num="0078">Next, the posture angle calculation unit <b>17</b> considers the road surface as a plane, and expresses the equation of the plane approximating the road surface by the following equation (8).</p><p id="p-0088" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>z=ax+by+c</i>&#x2003;&#x2003;(8)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0089" num="0079">Then, the posture angle calculation unit <b>17</b> substitutes the calculated n road surface mean vectors,</p><p id="p-0090" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>(<i>x</i><sub>1</sub><i>,y</i><sub>1</sub><i>,z</i><sub>1</sub>),(<i>x</i><sub>2</sub><i>,y</i><sub>2</sub><i>,z</i><sub>2</sub>), . . . ,(<i>x</i><sub>n</sub><i>,y</i><sub>n</sub><i>,z</i><sub>n</sub>),<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0091" num="0000">into the equation (8) and thereby acquires a simultaneous equation with n equations shown in the following equation (9).</p><p id="p-0092" num="0000"><maths id="MATH-US-00006" num="00006"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mo>{</mo>     <mtable>      <mtr>       <mtd>        <mrow>         <msub>          <mi>z</mi>          <mn>1</mn>         </msub>         <mo>=</mo>         <mrow>          <msub>           <mi>ax</mi>           <mn>1</mn>          </msub>          <mo>+</mo>          <msub>           <mi>by</mi>           <mn>1</mn>          </msub>          <mo>+</mo>          <mi>c</mi>         </mrow>        </mrow>       </mtd>      </mtr>      <mtr>       <mtd>        <mrow>         <msub>          <mi>z</mi>          <mn>2</mn>         </msub>         <mo>=</mo>         <mrow>          <msub>           <mi>ax</mi>           <mn>2</mn>          </msub>          <mo>+</mo>          <msub>           <mi>by</mi>           <mn>2</mn>          </msub>          <mo>+</mo>          <mi>c</mi>         </mrow>        </mrow>       </mtd>      </mtr>      <mtr>       <mtd>        <mo>&#x2026;</mo>       </mtd>      </mtr>      <mtr>       <mtd>        <mrow>         <msub>          <mi>z</mi>          <mi>n</mi>         </msub>         <mo>=</mo>         <mrow>          <msub>           <mi>ax</mi>           <mi>n</mi>          </msub>          <mo>+</mo>          <msub>           <mi>by</mi>           <mi>n</mi>          </msub>          <mo>+</mo>          <mi>c</mi>         </mrow>        </mrow>       </mtd>      </mtr>     </mtable>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>9</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0093" num="0080">Here, expressing the equations (9) by a matrix, the following equation (10) is obtained.</p><p id="p-0094" num="0000"><maths id="MATH-US-00007" num="00007"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mo>[</mo>     <mrow>      <mi>Number</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mn>10</mn>     </mrow>     <mo>]</mo>    </mrow>   </mtd>   <mtd>    <mi>&#xf3ba;</mi>   </mtd>  </mtr>  <mtr>   <mtd>    <mrow>     <mrow>      <mrow>       <mo>[</mo>       <mtable>        <mtr>         <mtd>          <msub>           <mi>x</mi>           <mn>1</mn>          </msub>         </mtd>         <mtd>          <msub>           <mi>y</mi>           <mn>1</mn>          </msub>         </mtd>         <mtd>          <mn>1</mn>         </mtd>        </mtr>        <mtr>         <mtd>          <msub>           <mi>x</mi>           <mn>2</mn>          </msub>         </mtd>         <mtd>          <msub>           <mi>x</mi>           <mn>2</mn>          </msub>         </mtd>         <mtd>          <mn>1</mn>         </mtd>        </mtr>        <mtr>         <mtd>          <mtext> </mtext>         </mtd>         <mtd>          <mo>&#x22ee;</mo>         </mtd>         <mtd>          <mtext> </mtext>         </mtd>        </mtr>        <mtr>         <mtd>          <msub>           <mi>x</mi>           <mi>n</mi>          </msub>         </mtd>         <mtd>          <msub>           <mi>y</mi>           <mi>n</mi>          </msub>         </mtd>         <mtd>          <mn>1</mn>         </mtd>        </mtr>       </mtable>       <mo>]</mo>      </mrow>      <mo>[</mo>      <mtable>       <mtr>        <mtd>         <mi>a</mi>        </mtd>       </mtr>       <mtr>        <mtd>         <mi>b</mi>        </mtd>       </mtr>       <mtr>        <mtd>         <mi>c</mi>        </mtd>       </mtr>      </mtable>      <mo>]</mo>     </mrow>     <mo>=</mo>     <mrow>      <mo>[</mo>      <mtable>       <mtr>        <mtd>         <msub>          <mi>z</mi>          <mn>1</mn>         </msub>        </mtd>       </mtr>       <mtr>        <mtd>         <msub>          <mi>z</mi>          <mn>2</mn>         </msub>        </mtd>       </mtr>       <mtr>        <mtd>         <mo>&#x22ee;</mo>        </mtd>       </mtr>       <mtr>        <mtd>         <msub>          <mi>z</mi>          <mi>n</mi>         </msub>        </mtd>       </mtr>      </mtable>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>10</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0095" num="0081">Here, when &#x201c;C&#x201d; denotes the n&#xd7;3 matrix on the left side, &#x201c;a&#x201d; denotes 3&#xd7;1 matrix (i.e., vector) on the left side, and &#x201c;b&#x201d; denotes n&#xd7;1 matrix (i.e., vector) on the right side, the equation (10) is converted into the following equation (11).</p><p id="p-0096" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Ca=b</i>(11)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0097" num="0082">Then, by modifying the equation (11), the following equation (12) is obtained as a normal equation.</p><p id="p-0098" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>C</i><sup>T</sup><i>Ca=C</i><sup>T</sup><i>b</i>&#x2003;&#x2003;(12)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0099" num="0083">Therefore, when n is 3 or more, the posture angle calculation unit <b>17</b> can calculate, by the least squares method according to the following equation (13), the coefficient vector &#x201c;a=[a, b, c] <sup>T</sup>&#x201d; of the plane equation shown in the equation (8).</p><p id="p-0100" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>a</i>=(<i>C</i><sup>T</sup><i>C</i>)<sup>&#x2212;1</sup><i>C</i><sup>T</sup><i>b</i>&#x2003;&#x2003;(13)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0101" num="0084">Further, when deforming the plane equation of the equation (8), the following equation (14) is obtained.</p><p id="p-0102" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x2212;<i>ax&#x2212;by +z&#x2212;c=</i>0&#x2003;&#x2003;(14)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0103" num="0085">Based on the equation (14), the normal vector &#x201c;Vn&#x201d; of the plane is expressed by the following equation (15).</p><p id="p-0104" num="0000"><maths id="MATH-US-00008" num="00008"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msub>      <mi>v</mi>      <mi>n</mi>     </msub>     <mo>=</mo>     <mrow>      <mo>[</mo>      <mtable>       <mtr>        <mtd>         <mrow>          <mo>-</mo>          <mi>a</mi>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mo>-</mo>          <mi>b</mi>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mn>1</mn>        </mtd>       </mtr>      </mtable>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>15</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0105" num="0086">The posture angle calculation unit <b>17</b> determines the orientation vector &#x201c;Vx&#x201d; of the vehicle on the x-y plane based on the yaw angle predicted or estimated by the NDT matching unit <b>18</b>. <figref idref="DRAWINGS">FIG. <b>7</b></figref> is a x-y plane view showing the relation between the yaw angle of the vehicle (here &#x3c8;<sup>{circumflex over (&#x2003;)}</sup>) and the traveling direction vector Vx. The z component of the traveling direction vector Vx is 0, and the x component and y component are proportional to the cosine and sine of the yaw angle of the vehicle, respectively. Thus, the traveling direction vector Vx is given by the following equation (16).</p><p id="p-0106" num="0000"><maths id="MATH-US-00009" num="00009"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msub>      <mi>v</mi>      <mi>X</mi>     </msub>     <mo>=</mo>     <mrow>      <mo>[</mo>      <mtable>       <mtr>        <mtd>         <mrow>          <mi>cos</mi>          <mo>&#x2062;</mo>          <mover>           <mi>&#x3c8;</mi>           <mo>^</mo>          </mover>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mi>sin</mi>          <mo>&#x2062;</mo>          <mover>           <mi>&#x3c8;</mi>           <mo>^</mo>          </mover>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mn>0</mn>        </mtd>       </mtr>      </mtable>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>16</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0107" num="0087">In this case, the angle &#x201c;&#x3b8;&#x2032;&#x201d; formed by the normal vector Vn and the traveling direction vector Vx is indicated by the following equation (17) which includes the inner product calculation of the normal vector Vn and the traveling direction vector Vx.</p><p id="p-0108" num="0000"><maths id="MATH-US-00010" num="00010"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>cos</mi>      <mo>&#x2062;</mo>      <msup>       <mi>&#x3b8;</mi>       <mo>&#x2032;</mo>      </msup>     </mrow>     <mo>=</mo>     <mrow>      <mfrac>       <mrow>        <msub>         <mi>v</mi>         <mi>n</mi>        </msub>        <mo>&#xb7;</mo>        <msub>         <mi>v</mi>         <mi>X</mi>        </msub>       </mrow>       <mrow>        <mrow>         <semantics definitionURL="">          <mo>&#x2758;</mo>          <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>         </semantics>         <msub>          <mi>v</mi>          <mi>n</mi>         </msub>         <semantics definitionURL="">          <mo>&#x2758;</mo>          <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>         </semantics>        </mrow>        <mo>&#x2062;</mo>        <mrow>         <semantics definitionURL="">          <mo>&#x2758;</mo>          <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>         </semantics>         <msub>          <mi>v</mi>          <mi>X</mi>         </msub>         <semantics definitionURL="">          <mo>&#x2758;</mo>          <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>         </semantics>        </mrow>       </mrow>      </mfrac>      <mo>=</mo>      <mrow>       <mfrac>        <mrow>         <mrow>          <mrow>           <mo>-</mo>           <mi>a</mi>          </mrow>          <mo>&#x2062;</mo>          <mi>cos</mi>          <mo>&#x2062;</mo>          <mover>           <mi>&#x3c8;</mi>           <mo>^</mo>          </mover>         </mrow>         <mo>-</mo>         <mrow>          <mi>b</mi>          <mo>&#x2062;</mo>          <mi>sin</mi>          <mo>&#x2062;</mo>          <mover>           <mi>&#x3c8;</mi>           <mo>^</mo>          </mover>         </mrow>        </mrow>        <mrow>         <msqrt>          <mrow>           <msup>            <mi>a</mi>            <mn>2</mn>           </msup>           <mo>+</mo>           <msup>            <mi>b</mi>            <mn>2</mn>           </msup>           <mo>+</mo>           <mn>1</mn>          </mrow>         </msqrt>         <mo>&#x2062;</mo>         <msqrt>          <mrow>           <mrow>            <msup>             <mi>cos</mi>             <mn>2</mn>            </msup>            <mo>&#x2062;</mo>            <mover>             <mi>&#x3c8;</mi>             <mo>^</mo>            </mover>           </mrow>           <mo>+</mo>           <mrow>            <msup>             <mi>sin</mi>             <mn>2</mn>            </msup>            <mo>&#x2062;</mo>            <mover>             <mi>&#x3c8;</mi>             <mo>^</mo>            </mover>           </mrow>          </mrow>         </msqrt>        </mrow>       </mfrac>       <mo>=</mo>       <mfrac>        <mrow>         <mrow>          <mrow>           <mo>-</mo>           <mi>a</mi>          </mrow>          <mo>&#x2062;</mo>          <mi>cos</mi>          <mo>&#x2062;</mo>          <mover>           <mi>&#x3c8;</mi>           <mo>^</mo>          </mover>         </mrow>         <mo>-</mo>         <mrow>          <mi>b</mi>          <mo>&#x2062;</mo>          <mi>sin</mi>          <mo>&#x2062;</mo>          <mover>           <mi>&#x3c8;</mi>           <mo>^</mo>          </mover>         </mrow>        </mrow>        <msqrt>         <mrow>          <msup>           <mi>a</mi>           <mn>2</mn>          </msup>          <mo>+</mo>          <msup>           <mi>b</mi>           <mn>2</mn>          </msup>          <mo>+</mo>          <mn>1</mn>         </mrow>        </msqrt>       </mfrac>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>17</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0109" num="0088">Then, the posture angle calculation unit <b>17</b>, based on the angle &#x3b8;&#x2032; formed by the normal vector Vn and the traveling direction vector Vx, calculates the pitch angle &#x201c;&#x3b8;&#x201d; of the vehicle.</p><p id="p-0110" num="0089"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows the relation between the pitch angle &#x3b8; of the vehicle and the angle &#x3b8;&#x2032; formed by the normal vector Vn and the traveling direction vector Vx. As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the angle &#x3b8;&#x2032; formed by the normal vector Vn and the traveling direction vector Vx is larger by 90 degrees (i.e., &#x3c0;/2) than the pitch angle &#x3b8; of the vehicle. Further, since the vehicle is constrained on the road surface, the inclination of the road surface in the traveling direction of the vehicle is equal to the pitch angle &#x3b8; of the vehicle. Therefore, the posture angle calculation unit <b>17</b> calculates the pitch angle &#x3b8; based on the following equation (18).</p><p id="p-0111" num="0000"><maths id="MATH-US-00011" num="00011"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mi>&#x3b8;</mi>     <mo>=</mo>     <mrow>      <mrow>       <msup>        <mi>&#x3b8;</mi>        <mo>&#x2032;</mo>       </msup>       <mo>-</mo>       <mfrac>        <mi>&#x3c0;</mi>        <mn>2</mn>       </mfrac>      </mrow>      <mo>=</mo>      <mrow>       <mrow>        <msup>         <mi>cos</mi>         <mrow>          <mo>-</mo>          <mn>1</mn>         </mrow>        </msup>        <mo>&#x2062;</mo>        <mfrac>         <mrow>          <mrow>           <mrow>            <mo>-</mo>            <mi>a</mi>           </mrow>           <mo>&#x2062;</mo>           <mi>cos</mi>           <mo>&#x2062;</mo>           <mover>            <mi>&#x3c8;</mi>            <mo>^</mo>           </mover>          </mrow>          <mo>-</mo>          <mrow>           <mi>b</mi>           <mo>&#x2062;</mo>           <mi>sin</mi>           <mo>&#x2062;</mo>           <mover>            <mi>&#x3c8;</mi>            <mo>^</mo>           </mover>          </mrow>         </mrow>         <msqrt>          <mrow>           <msup>            <mi>a</mi>            <mn>2</mn>           </msup>           <mo>+</mo>           <msup>            <mi>b</mi>            <mn>2</mn>           </msup>           <mo>+</mo>           <mn>1</mn>          </mrow>         </msqrt>        </mfrac>       </mrow>       <mo>-</mo>       <mfrac>        <mi>&#x3c0;</mi>        <mn>2</mn>       </mfrac>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>18</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0112" num="0090">In this way, the posture angle calculation unit <b>17</b> can suitably calculate the pitch angle of the vehicle based on: the coefficient vector of the plane equation calculated from the n road surface mean vectors based on the voxel data VD of the road surface voxels; and the yaw angle predicted or estimated by the NDT matching unit <b>18</b>.</p><p id="p-0113" num="0091">(4-2) Estimation of Roll Angle</p><p id="p-0114" num="0092">As with the calculation of the pitch angle, the posture angle calculation unit <b>17</b> calculates the normal vector V<sub>n </sub>shown in the equation (15) by using the n road surface mean vectors based on the voxel data VD.</p><p id="p-0115" num="0093">Further, the posture angle calculation unit <b>17</b> determines the lateral direction vector &#x201c;V<sub>Y</sub>&#x201d; of the vehicle on the x-y plane based on the yaw angle predicted or estimated by the NDT matching unit <b>18</b>. <figref idref="DRAWINGS">FIG. <b>9</b></figref> is an x-y plane view showing the relation between the yaw angle of the vehicle (here &#x3c8;<sup>{circumflex over (&#x2003;)}</sup>) and the lateral direction vector V<sub>Y</sub>. As shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the lateral direction vector V<sub>Y </sub>corresponds to a direction in which the yaw angle (here, referred to as &#x3c8;<sup>{circumflex over (&#x2003;)}</sup>) predicted or estimated by the NDT matching unit <b>18</b> is rotated by 90 degrees (&#x3c0;/2) along the x-y plane. Therefore, the lateral direction vector V<sub>Y </sub>is given by the following equation (19).</p><p id="p-0116" num="0000"><maths id="MATH-US-00012" num="00012"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msub>      <mi>v</mi>      <mi>Y</mi>     </msub>     <mo>=</mo>     <mrow>      <mrow>       <mrow>        <mo>[</mo>        <mtable>         <mtr>          <mtd>           <mrow>            <mi>cos</mi>            <mo>&#x2062;</mo>            <mfrac>             <mi>&#x3c0;</mi>             <mn>2</mn>            </mfrac>           </mrow>          </mtd>          <mtd>           <mrow>            <mrow>             <mo>-</mo>             <mi>sin</mi>            </mrow>            <mo>&#x2062;</mo>            <mfrac>             <mi>&#x3c0;</mi>             <mn>2</mn>            </mfrac>           </mrow>          </mtd>          <mtd>           <mn>0</mn>          </mtd>         </mtr>         <mtr>          <mtd>           <mrow>            <mi>sin</mi>            <mo>&#x2062;</mo>            <mfrac>             <mi>&#x3c0;</mi>             <mn>2</mn>            </mfrac>           </mrow>          </mtd>          <mtd>           <mrow>            <mi>cos</mi>            <mo>&#x2062;</mo>            <mfrac>             <mi>&#x3c0;</mi>             <mn>2</mn>            </mfrac>           </mrow>          </mtd>          <mtd>           <mn>0</mn>          </mtd>         </mtr>         <mtr>          <mtd>           <mn>0</mn>          </mtd>          <mtd>           <mn>0</mn>          </mtd>          <mtd>           <mn>1</mn>          </mtd>         </mtr>        </mtable>        <mo>]</mo>       </mrow>       <mo>&#x2062;</mo>       <msub>        <mi>v</mi>        <mi>X</mi>       </msub>      </mrow>      <mo>=</mo>      <mrow>       <mrow>        <mrow>         <mo>[</mo>         <mtable>          <mtr>           <mtd>            <mn>0</mn>           </mtd>           <mtd>            <mrow>             <mo>-</mo>             <mn>1</mn>            </mrow>           </mtd>           <mtd>            <mn>0</mn>           </mtd>          </mtr>          <mtr>           <mtd>            <mn>1</mn>           </mtd>           <mtd>            <mn>0</mn>           </mtd>           <mtd>            <mn>0</mn>           </mtd>          </mtr>          <mtr>           <mtd>            <mn>0</mn>           </mtd>           <mtd>            <mn>0</mn>           </mtd>           <mtd>            <mn>1</mn>           </mtd>          </mtr>         </mtable>         <mo>]</mo>        </mrow>        <mo>[</mo>        <mtable>         <mtr>          <mtd>           <mrow>            <mi>cos</mi>            <mo>&#x2062;</mo>            <mover>             <mi>&#x3c8;</mi>             <mo>^</mo>            </mover>           </mrow>          </mtd>         </mtr>         <mtr>          <mtd>           <mrow>            <mi>sin</mi>            <mo>&#x2062;</mo>            <mover>             <mi>&#x3c8;</mi>             <mo>^</mo>            </mover>           </mrow>          </mtd>         </mtr>         <mtr>          <mtd>           <mn>0</mn>          </mtd>         </mtr>        </mtable>        <mo>]</mo>       </mrow>       <mo>=</mo>       <mrow>        <mo>[</mo>        <mtable>         <mtr>          <mtd>           <mrow>            <mrow>             <mo>-</mo>             <mi>sin</mi>            </mrow>            <mo>&#x2062;</mo>            <mover>             <mi>&#x3c8;</mi>             <mo>^</mo>            </mover>           </mrow>          </mtd>         </mtr>         <mtr>          <mtd>           <mrow>            <mi>cos</mi>            <mo>&#x2062;</mo>            <mover>             <mi>&#x3c8;</mi>             <mo>^</mo>            </mover>           </mrow>          </mtd>         </mtr>         <mtr>          <mtd>           <mn>0</mn>          </mtd>         </mtr>        </mtable>        <mo>]</mo>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>19</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0117" num="0094">In this case, the angle &#x201c;&#x3c6;&#x2032;&#x201d; formed by the normal vector Vn and the lateral direction vector V<sub>Y </sub>is expressed by the following equation (20), which includes the inner product calculation of the normal vector Vn and the lateral direction vector V<sub>Y</sub>.</p><p id="p-0118" num="0000"><maths id="MATH-US-00013" num="00013"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>cos</mi>      <mo>&#x2062;</mo>      <msup>       <mi>&#x3d5;</mi>       <mo>&#x2032;</mo>      </msup>     </mrow>     <mo>=</mo>     <mrow>      <mfrac>       <mrow>        <msub>         <mi>v</mi>         <mi>n</mi>        </msub>        <mo>&#xb7;</mo>        <msub>         <mi>v</mi>         <mi>Y</mi>        </msub>       </mrow>       <mrow>        <mrow>         <semantics definitionURL="">          <mo>&#x2758;</mo>          <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>         </semantics>         <msub>          <mi>v</mi>          <mi>n</mi>         </msub>         <semantics definitionURL="">          <mo>&#x2758;</mo>          <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>         </semantics>        </mrow>        <mo>&#x2062;</mo>        <mrow>         <semantics definitionURL="">          <mo>&#x2758;</mo>          <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>         </semantics>         <msub>          <mi>v</mi>          <mi>Y</mi>         </msub>         <semantics definitionURL="">          <mo>&#x2758;</mo>          <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>         </semantics>        </mrow>       </mrow>      </mfrac>      <mo>=</mo>      <mrow>       <mfrac>        <mrow>         <mrow>          <mrow>           <mo>-</mo>           <mi>a</mi>          </mrow>          <mo>&#x2062;</mo>          <mi>cos</mi>          <mo>&#x2062;</mo>          <mover>           <mi>&#x3c8;</mi>           <mo>^</mo>          </mover>         </mrow>         <mo>-</mo>         <mrow>          <mi>b</mi>          <mo>&#x2062;</mo>          <mi>sin</mi>          <mo>&#x2062;</mo>          <mover>           <mi>&#x3c8;</mi>           <mo>^</mo>          </mover>         </mrow>        </mrow>        <mrow>         <msqrt>          <mrow>           <msup>            <mi>a</mi>            <mn>2</mn>           </msup>           <mo>+</mo>           <msup>            <mi>b</mi>            <mn>2</mn>           </msup>           <mo>+</mo>           <mn>1</mn>          </mrow>         </msqrt>         <mo>&#x2062;</mo>         <msqrt>          <mrow>           <mrow>            <msup>             <mi>cos</mi>             <mn>2</mn>            </msup>            <mo>&#x2062;</mo>            <mover>             <mi>&#x3c8;</mi>             <mo>^</mo>            </mover>           </mrow>           <mo>+</mo>           <mrow>            <msup>             <mi>sin</mi>             <mn>2</mn>            </msup>            <mo>&#x2062;</mo>            <mover>             <mi>&#x3c8;</mi>             <mo>^</mo>            </mover>           </mrow>          </mrow>         </msqrt>        </mrow>       </mfrac>       <mo>=</mo>       <mfrac>        <mrow>         <mrow>          <mrow>           <mo>-</mo>           <mi>a</mi>          </mrow>          <mo>&#x2062;</mo>          <mi>cos</mi>          <mo>&#x2062;</mo>          <mover>           <mi>&#x3c8;</mi>           <mo>^</mo>          </mover>         </mrow>         <mo>-</mo>         <mrow>          <mi>b</mi>          <mo>&#x2062;</mo>          <mi>sin</mi>          <mo>&#x2062;</mo>          <mover>           <mi>&#x3c8;</mi>           <mo>^</mo>          </mover>         </mrow>        </mrow>        <msqrt>         <mrow>          <msup>           <mi>a</mi>           <mn>2</mn>          </msup>          <mo>+</mo>          <msup>           <mi>b</mi>           <mn>2</mn>          </msup>          <mo>+</mo>          <mn>1</mn>         </mrow>        </msqrt>       </mfrac>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>20</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0119" num="0095">Then, the posture angle calculation unit <b>17</b> calculates, based on the angle &#x3c6;&#x2032; formed by the normal vector V<sub>n </sub>and the lateral direction vector V<sub>Y</sub>, the roll angle &#x201c;&#x3c6;&#x201d; of the vehicle.</p><p id="p-0120" num="0096"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates the relation between the roll angle &#x3c6; of the vehicle and the angle &#x3c6;&#x2032; formed by the normal vector Vn and the lateral direction vector V<sub>Y</sub>. As shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the angle &#x3c6;&#x2032; formed by the normal vector Vn and the lateral direction vector V<sub>Y </sub>is larger by 90 degrees (i.e., &#x3c0;/2) than the roll angle &#x3c6; of the vehicle. Further, since the vehicle is constrained on the road surface, the inclination of the road surface in the lateral direction of the vehicle is equal to the roll angle &#x3c6; of the vehicle. Therefore, the posture angle calculation unit <b>17</b> calculates the roll angle &#x3c6; based on the following equation (21).</p><p id="p-0121" num="0000"><maths id="MATH-US-00014" num="00014"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mi>&#x3d5;</mi>     <mo>=</mo>     <mrow>      <mrow>       <msup>        <mi>&#x3d5;</mi>        <mo>&#x2032;</mo>       </msup>       <mo>-</mo>       <mfrac>        <mi>&#x3c0;</mi>        <mn>2</mn>       </mfrac>      </mrow>      <mo>=</mo>      <mrow>       <mrow>        <msup>         <mi>cos</mi>         <mrow>          <mo>-</mo>          <mn>1</mn>         </mrow>        </msup>        <mo>&#x2062;</mo>        <mfrac>         <mrow>          <mrow>           <mi>a</mi>           <mo>&#x2062;</mo>           <mi>cos</mi>           <mo>&#x2062;</mo>           <mover>            <mi>&#x3c8;</mi>            <mo>^</mo>           </mover>          </mrow>          <mo>-</mo>          <mrow>           <mi>b</mi>           <mo>&#x2062;</mo>           <mi>sin</mi>           <mo>&#x2062;</mo>           <mover>            <mi>&#x3c8;</mi>            <mo>^</mo>           </mover>          </mrow>         </mrow>         <msqrt>          <mrow>           <msup>            <mi>a</mi>            <mn>2</mn>           </msup>           <mo>+</mo>           <msup>            <mi>b</mi>            <mn>2</mn>           </msup>           <mo>+</mo>           <mn>1</mn>          </mrow>         </msqrt>        </mfrac>       </mrow>       <mo>-</mo>       <mfrac>        <mi>&#x3c0;</mi>        <mn>2</mn>       </mfrac>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>21</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0122" num="0097">In this way, the posture angle calculation unit <b>17</b> can suitably calculate the roll angle of the vehicle based on: the coefficient vector of the plane equation calculated from n road surface mean vectors based on the voxel data VD; and the yaw angle predicted or estimated by the NDT matching unit <b>18</b>.</p><heading id="h-0015" level="1">(5) Coordinate Transformation of Point Cloud Data</heading><p id="p-0123" num="0098">Next, a description will be given of the coordinate transformation of the point cloud data based on the pitch angle calculated by the posture angle calculation unit <b>17</b>.</p><p id="p-0124" num="0099">The coordinate transformation block <b>23</b> of the NDT matching unit <b>18</b> generates, using the pitch angle &#x3b8; calculated by the posture angle calculation unit <b>17</b>, a rotation matrix &#x201c;Re&#x201d; shown in the following equation (22).</p><p id="p-0125" num="0000"><maths id="MATH-US-00015" num="00015"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msub>      <mi>R</mi>      <mi>&#x3b8;</mi>     </msub>     <mo>=</mo>     <mrow>      <mo>[</mo>      <mtable>       <mtr>        <mtd>         <mrow>          <mi>cos</mi>          <mo>&#x2062;</mo>          <mi>&#x3b8;</mi>         </mrow>        </mtd>        <mtd>         <mn>0</mn>        </mtd>        <mtd>         <mrow>          <mrow>           <mo>-</mo>           <mi>sin</mi>          </mrow>          <mo>&#x2062;</mo>          <mi>&#x3b8;</mi>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mn>0</mn>        </mtd>        <mtd>         <mn>1</mn>        </mtd>        <mtd>         <mn>0</mn>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mi>sin</mi>          <mo>&#x2062;</mo>          <mi>&#x3b8;</mi>         </mrow>        </mtd>        <mtd>         <mn>0</mn>        </mtd>        <mtd>         <mrow>          <mi>cos</mi>          <mo>&#x2062;</mo>          <mi>&#x3b8;</mi>         </mrow>        </mtd>       </mtr>      </mtable>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>22</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0126" num="0100">Here, when n pieces of three-dimensional data is detected by the lidar <b>2</b>, a matrix &#x201c;X<sub>L</sub>&#x201d; representing these n pieces of three-dimensional data is represented by the following equation (23).</p><p id="p-0127" num="0000"><maths id="MATH-US-00016" num="00016"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msub>      <mi>X</mi>      <mi>L</mi>     </msub>     <mo>=</mo>     <mrow>      <mo>[</mo>      <mtable>       <mtr>        <mtd>         <msub>          <mi>x</mi>          <mn>1</mn>         </msub>        </mtd>        <mtd>         <msub>          <mi>y</mi>          <mn>1</mn>         </msub>        </mtd>        <mtd>         <msub>          <mi>z</mi>          <mn>1</mn>         </msub>        </mtd>       </mtr>       <mtr>        <mtd>         <msub>          <mi>x</mi>          <mn>2</mn>         </msub>        </mtd>        <mtd>         <msub>          <mi>x</mi>          <mn>2</mn>         </msub>        </mtd>        <mtd>         <msub>          <mi>z</mi>          <mn>2</mn>         </msub>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mo>&#x22ee;</mo>          <mtext> </mtext>         </mrow>        </mtd>        <mtd>         <mo>&#x22ee;</mo>        </mtd>        <mtd>         <mrow>          <mo>&#x22ee;</mo>          <mtext> </mtext>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <msub>          <mi>x</mi>          <mi>n</mi>         </msub>        </mtd>        <mtd>         <msub>          <mi>y</mi>          <mi>n</mi>         </msub>        </mtd>        <mtd>         <msub>          <mi>z</mi>          <mi>n</mi>         </msub>        </mtd>       </mtr>      </mtable>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>23</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0128" num="0101">In this case, the coordinate transformation block <b>23</b> performs the coordinate transformation of the point cloud data with respect to the pitch angle &#x3b8; according to the following equation (24).</p><p id="p-0129" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>X&#x2032;</i><sub>L</sub>=(<i>R</i><sub>&#x3b8;</sub><i>X</i><sub>L</sub><sup>T</sup>)&#x2003;&#x2003;(24)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0130" num="0102">Then, the coordinate transformation block <b>23</b> adds the predicted or estimated three-dimensional own vehicle position (x, y, z) to the n pieces of the three-dimensional data corresponding to each row of X<sub>L</sub>&#x2032; in the equation (24). Thereby, the point cloud data in which the three-dimensional position x, y, z is also converted to the world coordinate system is generated. Then, the coordinate conversion block <b>23</b> supplies the point cloud data converted into the world coordinate system, to the point cloud data association block <b>24</b>.</p><p id="p-0131" num="0103">Next, a description will be given of the coordinate transformation in consideration of both the pitch angle &#x3b8; and the roll angle &#x3c6;. Using the rotation matrix R<sub>&#x3b8;</sub> based on the pitch angle &#x3b8; calculated by the posture angle calculation unit <b>17</b> and the rotation matrix &#x201c;R<sub>&#x3c6;</sub>&#x201d; based on the roll angle &#x3c6;, the coordinate transformation block <b>23</b> generates the rotation matrix &#x201c;R&#x201d; to be multiplied by the matrix X<sub>L </sub>indicating n pieces of the three-dimensional data outputted by the lidar <b>2</b>, according to the following equation (25).</p><p id="p-0132" num="0000"><maths id="MATH-US-00017" num="00017"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mi>R</mi>     <mo>=</mo>     <mrow>      <mrow>       <msub>        <mi>R</mi>        <mi>&#x3d5;</mi>       </msub>       <mo>&#x2062;</mo>       <msub>        <mi>R</mi>        <mi>&#x3b8;</mi>       </msub>      </mrow>      <mo>=</mo>      <mrow>       <mrow>        <mo>[</mo>        <mtable>         <mtr>          <mtd>           <mn>1</mn>          </mtd>          <mtd>           <mn>0</mn>          </mtd>          <mtd>           <mn>0</mn>          </mtd>         </mtr>         <mtr>          <mtd>           <mn>0</mn>          </mtd>          <mtd>           <mrow>            <mi>cos</mi>            <mo>&#x2062;</mo>            <mi>&#x3d5;</mi>           </mrow>          </mtd>          <mtd>           <mrow>            <mi>sin</mi>            <mo>&#x2062;</mo>            <mi>&#x3d5;</mi>           </mrow>          </mtd>         </mtr>         <mtr>          <mtd>           <mn>0</mn>          </mtd>          <mtd>           <mrow>            <mrow>             <mo>-</mo>             <mi>sin</mi>            </mrow>            <mo>&#x2062;</mo>            <mi>&#x3d5;</mi>           </mrow>          </mtd>          <mtd>           <mrow>            <mi>cos</mi>            <mo>&#x2062;</mo>            <mi>&#x3d5;</mi>           </mrow>          </mtd>         </mtr>        </mtable>        <mo>]</mo>       </mrow>       <mo>[</mo>       <mtable>        <mtr>         <mtd>          <mrow>           <mi>cos</mi>           <mo>&#x2062;</mo>           <mi>&#x3b8;</mi>          </mrow>         </mtd>         <mtd>          <mn>0</mn>         </mtd>         <mtd>          <mrow>           <mrow>            <mo>-</mo>            <mi>sin</mi>           </mrow>           <mo>&#x2062;</mo>           <mi>&#x3b8;</mi>          </mrow>         </mtd>        </mtr>        <mtr>         <mtd>          <mn>0</mn>         </mtd>         <mtd>          <mn>1</mn>         </mtd>         <mtd>          <mn>0</mn>         </mtd>        </mtr>        <mtr>         <mtd>          <mrow>           <mi>sin</mi>           <mo>&#x2062;</mo>           <mi>&#x3b8;</mi>          </mrow>         </mtd>         <mtd>          <mn>0</mn>         </mtd>         <mtd>          <mrow>           <mi>cos</mi>           <mo>&#x2062;</mo>           <mi>&#x3b8;</mi>          </mrow>         </mtd>        </mtr>       </mtable>       <mo>]</mo>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>25</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0133" num="0104">In this case, the position prediction block <b>22</b> performs the coordinate transformation of the point cloud data to the world coordinate system with respect to the pitch angle &#x3b8; and the roll angle &#x3c6;, according to the following equation (26).</p><p id="p-0134" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>X&#x2032;</i><sub>L</sub>=(<i>RX</i><sub>L</sub><sup>T</sup>)<sup>T</sup>&#x2003;&#x2003;(26)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0135" num="0105">Thereafter, the coordinate transformation block <b>23</b> performs the coordinate transformation of the point cloud data to the world coordinate system with respect to the yaw angle &#x3c8;, by multiplying X<sub>L</sub>&#x2032; in the equation (26) by the rotation matrix based on the yaw angle &#x3c8; in the same way. Further, the coordinate transformation block <b>23</b> performs the coordinate transformation to the world coordinate system with respect to the three-dimensional position by adding the predicted or estimated vehicle position (x, y, z) to the n pieces of the three-dimensional data corresponding to each row of X<sub>L</sub>&#x2032; after the coordinate transformation. Then, the coordinate conversion block <b>23</b> supplies the point cloud data association block <b>24</b> with the point cloud data converted into the world coordinate system through the above-described process.</p><p id="p-0136" num="0106">In some embodiments, the coordinate transformation block <b>23</b> converts the point cloud data indicating three-dimensional positions with reference to the lidar <b>2</b> to data in the vehicle coordinate system, wherein each of the three-dimensional positions is expressed by a combination of the distance measured by the lidar <b>2</b> and the scan angle. The vehicle coordinate system is the coordinate system of the vehicle whose axes are along the traveling direction and the lateral direction of the vehicle. In this case, based on the information of the installation position and installation angle of the lidar <b>2</b> to the vehicle, the coordinate transformation block <b>23</b> converts the point cloud data in the coordinate system with respect to the lidar <b>2</b> to data in the vehicle coordinate system and further converts the converted point cloud data in the vehicle coordinate system to data in the world coordinate system according to the above-mentioned approach. Examples of the process of converting the point cloud data outputted by a lidar installed in the vehicle to data in the vehicle coordinate system is disclosed in WO2019/188745.</p><p id="p-0137" num="0107">Further, the coordinate transformation block <b>23</b> may perform the coordinate transformation considering only the roll angle &#x3c6; instead of considering both the pitch angle &#x3b8; and the roll angle cp. In this case, the coordinate transformation block <b>23</b> may multiply the rotation matrix R<sub>&#x3c6;</sub> shown in the equation (25) by the matrix X<sub>L </sub>representing n pieces of the three-dimensional data outputted by the lidar <b>2</b>.</p><p id="p-0138" num="0108">Next, the effect of the above-described coordinate transformation will be supplementally described with reference to <figref idref="DRAWINGS">FIGS. <b>11</b>A, <b>11</b>B and <b>12</b></figref>.</p><p id="p-0139" num="0109"><figref idref="DRAWINGS">FIG. <b>11</b>A</figref> is a side view of a road and the vehicle running on a flat road surface. In this case, the vehicle height &#x201c;z&#x201d; from the reference position (e.g., the position where the altitude is 0) of the world coordinate system is the height obtained by adding the height (also referred to as &#x201c;vehicle reference position z<sub>0</sub>&#x201d;) of the vehicle from the road surface to the height of the road surface from the reference position of the world coordinate system. Then, the height &#x201c;z<sup>{circumflex over (&#x2003;)}</sup>+d&#x201d; obtained by adding the height &#x201c;d&#x201d; of a certain measurement point &#x201c;Ptag<b>1</b>&#x201d; measured by the lidar <b>2</b> from the vehicle to the vehicle height z<sup>{circumflex over (&#x2003;)}</sup> matches the actual height of the measurement point Ptag<b>1</b> in the world coordinate system. Therefore, in this case, in the associating process executed by the point cloud data association block <b>24</b>, the measurement point Ptag<b>1</b> is associated with the voxel &#x201c;V<b>1</b>&#x201d; where the measurement point Ptag<b>1</b> is actually included.</p><p id="p-0140" num="0110"><figref idref="DRAWINGS">FIG. <b>11</b>B</figref> is a side view of a road and the vehicle traveling on a large gradient road surface in the case of not performing the coordinate transformation of the point cloud data based on the pitch angle of the vehicle. In this case, since the pitch angle is generated in the vehicle by the road surface gradient, the point cloud data becomes upward. Therefore, the height, in the world coordinate system, of the measurement point &#x201c;Ptag<b>2</b>&#x201d; present at the position of the height d from the vehicle is not equal to &#x201c;z<sup>{circumflex over (&#x2003;)}</sup>+d&#x201d; obtained by adding the height d to the vehicle height z<sup>{circumflex over (&#x2003;)}</sup>. Consequently, in the associating process executed by the point cloud data association block <b>24</b>, the measurement point Ptag<b>2</b> is not associated with the voxel &#x201c;VT&#x201d; in which the measurement point Ptag<b>2</b> is actually present but mistakenly associated with the voxel &#x201c;V<b>2</b>&#x3b1;&#x201d; because its height in the world coordinate system is calculated as &#x201c;z<sup>{circumflex over (&#x2003;)}</sup>+d&#x201d;.</p><p id="p-0141" num="0111"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a side view of the road and the vehicle traveling on a large slope road surface in the case of performing the coordinate transformation of the point cloud data based on the pitch angle of the vehicle based on the present embodiment. In this case, through the rotation matrix based on the pitch angle determined by the calculation method according to the embodiment, the point cloud data outputted by the lidar <b>2</b> is converted to data in the world coordinate system in consideration of the pitch angle of the vehicle. Therefore, in this case, the height, in the world coordinate system, of the measurement point &#x201c;Ptag<b>3</b>&#x201d; present at the position of the height d from the vehicle is equal to &#x201c;z<sup>{circumflex over (&#x2003;)}</sup>+d&#x2033;. Therefore, in the associating process executed by the point cloud data association block <b>24</b>, the measurement point Ptag<b>3</b> is associated with the voxel V<b>3</b> (i.e., correct matching target) where the measurement point Ptag<b>3</b> is actually present and therefore the NDT scan matching is preferably performed.</p><p id="p-0142" num="0112">Even when traveling on a road where a cross slope such as a cant is present, the in-vehicle device <b>1</b> performs the coordinate transformation of the point cloud data based on the roll angle of the vehicle thereby to suitably associate each measurement point of the point cloud data outputted by the lidar <b>2</b> with the voxel that is a correct matching target.</p><heading id="h-0016" level="1">(6) Processing Flow</heading><p id="p-0143" num="0113">Next, a specific processing flow of the estimation process of the vehicle position and posture by NDT matching including the estimation of the pitch angle and the roll angle described above will be described with reference to flowcharts.</p><p id="p-0144" num="0114">(6-1) Outline of Vehicle Position and Posture Estimation Process</p><p id="p-0145" num="0115"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is an example of a flowchart showing the procedure of estimation processing of the vehicle position and posture. The posture angle calculation unit <b>17</b> and the NDT matching unit <b>18</b> of the in-vehicle device <b>1</b> repeatedly execute the processing of the flowchart shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref> at predetermined time intervals at which the estimation of the position and the posture of the vehicle should be performed. Symbols displayed on the right of each step in <figref idref="DRAWINGS">FIG. <b>13</b></figref> represent the elements calculated in each step.</p><p id="p-0146" num="0116">First, the dead reckoning block <b>21</b> of the NDT matching unit <b>18</b> determines the movement distance and the azimuth orientation change from the previous time using the movement velocity and the angular velocity calculated based on the output by the gyro sensor <b>3</b>, the vehicle velocity sensor <b>4</b>, and the GPS receiver <b>5</b>. Thereby, the position prediction block <b>22</b> of the NDT matching unit <b>18</b> calculates the predicted vehicle position x<sup>&#x2212;</sup>, y<sup>&#x2212;</sup>, &#x3c8;<sup>&#x2212;</sup> at the current processing time from the estimated vehicle position x<sup>{circumflex over (&#x2003;)}</sup>, y<sup>{circumflex over (&#x2003;)}</sup>, &#x3c8;<sup>{circumflex over (&#x2003;)}</sup> obtained at the preceding processing time (i.e., one processing time before the current processing time) (step S<b>11</b>).</p><p id="p-0147" num="0117">Next, the posture angle calculation unit <b>17</b> calculates the predicted vehicle height &#x201c;z<sup>&#x2212;</sup>&#x201d; by performing the estimation process of the vehicle height (e.g., the altitude where the vehicle is located) (step S<b>12</b>). This process will be described later with reference to <figref idref="DRAWINGS">FIG. <b>14</b></figref>. Furthermore, the posture angle calculation unit <b>17</b> calculates the predicted roll angle &#x201c;&#x3c6;<sup>&#x2212;</sup>&#x201d; and predicted pitch angle &#x201c;&#x3b8;<sup>&#x2212;</sup>&#x201d; by performing the vehicle roll angle/pitch angle estimation process (step S<b>13</b>). This process will be described later with reference to <figref idref="DRAWINGS">FIG. <b>15</b></figref>.</p><p id="p-0148" num="0118">Then, the coordinate conversion block <b>23</b> of the NDT matching unit <b>18</b> generates the rotation matrix R (see the equation (25)) based on the roll angle and pitch angle calculated at step S<b>13</b> (step S<b>14</b>). Then, the coordinate conversion block <b>23</b> converts the point cloud data into data in the world coordinate system (step S<b>15</b>). Thereafter, the NDT matching unit <b>18</b> (i.e., the point cloud data association block <b>24</b> and the position correction block <b>25</b>) performs NDT matching using the point cloud data and the voxel data VD after the coordinate transformation to thereby calculate the estimated vehicle position x<sup>{circumflex over (&#x2003;)}</sup>, y<sup>{circumflex over (&#x2003;)}</sup>, &#x3c8;<sup>{circumflex over (&#x2003;)}</sup> at the current processing time (step S<b>16</b>). Thereafter, the posture angle calculation unit <b>17</b> calculates the estimated vehicle height &#x201c;z&#x201d; by performing the same height estimation process of the vehicle as the process at step S<b>12</b> again using the calculated estimated vehicle position x<sup>{circumflex over (&#x2003;)}</sup>, y<sup>{circumflex over (&#x2003;)}</sup>, &#x3c8;<sup>{circumflex over (&#x2003;)}</sup> at the current processing time (step S<b>17</b>). This process will be described later with reference to <figref idref="DRAWINGS">FIG. <b>14</b></figref>. Furthermore, using the calculated estimated vehicle position x<sup>{circumflex over (&#x2003;)}</sup>, y<sup>{circumflex over (&#x2003;)}</sup>, &#x3c8;<sup>{circumflex over (&#x2003;)}</sup> and the estimated vehicle height z<sup>{circumflex over (&#x2003;)}</sup> at the current processing time, the posture angle calculation unit <b>17</b> calculates the estimated roll angle &#x201c;&#x3c6;<sup>{circumflex over (&#x2003;)}</sup>&#x201d; and the estimated pitch angle &#x201c;&#x3b8;<sup>{circumflex over (&#x2003;)}</sup>&#x201d; through the vehicle roll angle/pitch angle estimation process (step S<b>18</b>). This process will be described later with reference to <figref idref="DRAWINGS">FIG. <b>15</b></figref>.</p><p id="p-0149" num="0119">(6-2) Vehicle Height Estimation Processing</p><p id="p-0150" num="0120"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is an example of a flowchart showing the procedure of the vehicle height estimation process to be executed at step S<b>12</b> and step S<b>17</b> in <figref idref="DRAWINGS">FIG. <b>13</b></figref>. In the vehicle height estimation process, the posture angle calculation unit <b>17</b> determines the own vehicle position road surface voxel based on the predicted or estimated planar position of the vehicle, and determines the vehicle height to be a value obtained by adding the vehicle reference position z<sub>0 </sub>(the height of the vehicle from the road surface) to the z-coordinate of the mean vector of the own vehicle position road surface voxel. Further, the in-vehicle device <b>1</b> carries out labeling by setting the voxel index idz of the own vehicle position road surface voxel with low reliability to &#x201c;&#x2212;1&#x201d; so as not to use the own vehicle position road surface voxel with low reliability in the estimation process of the roll angle and pitch angle to be described later.</p><p id="p-0151" num="0121">First, the posture angle calculation unit <b>17</b> acquires the voxel index (idx, idy) of the voxel where the predicted vehicle position x<sup>&#x2212;</sup>, y<sup>&#x2212;</sup> or the estimated vehicle position x<sup>{circumflex over (&#x2003;)}</sup>, y<sup>{circumflex over (&#x2003;)}</sup> belongs, and searches for voxels having the voxel index (idx, idy) (step S<b>21</b>). Namely, the posture angle calculation unit <b>17</b> refers to the voxel data VD and searches the height direction of the voxels having the same planar position in the x-y plane with the predicted vehicle position x<sup>&#x2212;</sup>, y<sup>&#x2212;</sup> or the estimated vehicle position x<sup>{circumflex over (&#x2003;)}</sup>, y<sup>{circumflex over (&#x2003;)}</sup>. In case of processing at step S<b>12</b> in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the posture angle calculation unit <b>17</b> searches for voxels having the voxel index (idx, idy) of the voxel including the predicted vehicle position x<sup>&#x2212;</sup>, y<sup>&#x2212;</sup>. In case of processing at step S<b>17</b> in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the posture angle calculation unit <b>17</b> searches for voxels having the voxel index (idx, idy) of the voxel including the estimated vehicle position x<sup>{circumflex over (&#x2003;)}</sup>, y<sup>{circumflex over (&#x2003;)}</sup>.</p><p id="p-0152" num="0122">Next, the posture angle calculation unit <b>17</b> determines whether or not one or more voxels have been detected at step S<b>21</b> (step S<b>22</b>). If one or more voxels is not detected at step S<b>21</b> (step S<b>22</b>: No), the posture angle calculation unit <b>17</b> determines the predicted vehicle height z<sup>&#x2212;</sup> or the estimated vehicle height z<sup>{circumflex over (&#x2003;)}</sup> at the preceding processing time as the predicted vehicle height z<sup>&#x2212;</sup> or the estimated vehicle height z<sup>{circumflex over (&#x2003;)}</sup> to be obtained (step S<b>27</b>). Further, at step S<b>27</b>, the posture angle calculation unit <b>17</b> determines a temporary own vehicle position road surface voxel in which the voxel index idz <b>15</b> &#x201c;&#x2212;1&#x201d;.</p><p id="p-0153" num="0123">On the other hand, if one or more voxels are detected at step S<b>21</b> (step S<b>22</b>; Yes), the posture angle calculation unit <b>17</b> determines that the detected voxels are candidates of the own vehicle position road surface voxel. Then, the posture angle calculation unit <b>17</b> reads each z-coordinates of the candidates (i.e., z-coordinates of the mean vectors of the candidates) from the voxel data VD and adds the vehicle reference position z<sub>0 </sub>to the each z-coordinate (step S<b>23</b>). The vehicle reference position z<sub>0 </sub>is previously stored, for example, in the storage unit <b>12</b>.</p><p id="p-0154" num="0124">The posture angle calculation unit <b>17</b> selects, as the own vehicle position road surface voxel, a candidate of the own vehicle position road surface voxel whose value obtained by adding the vehicle reference position z<sub>0 </sub>to the z coordinate of the mean vector of the candidate becomes the value closest to the predicted vehicle height z<sup>&#x2212;</sup> or the estimated vehicle height z<sup>{circumflex over (&#x2003;)}</sup> at the preceding processing time (step S<b>24</b>).</p><p id="p-0155" num="0125">If the difference between the value obtained by adding the vehicle reference position z<sub>0 </sub>to the z-coordinate of the mean vector of the selected vehicle position road surface voxel and the predicted vehicle height z<sup>&#x2212;</sup> or the estimated vehicle height z<sup>{circumflex over (&#x2003;)}</sup> at the preceding processing time is equal to or less than a predetermined value (step S<b>25</b>; Yes), the posture angle calculation unit <b>17</b> executes the process at step S<b>26</b>. In this case, for example, the above-mentioned predetermined value is set to the upper limit of the fluctuation width of the height that can occur in the vehicle on a hill during the time interval from the preceding processing time to the current processing time.</p><p id="p-0156" num="0126">Then, the posture angle calculation unit <b>17</b> determines that the value obtained by adding the vehicle reference position z<sub>0 </sub>to the z-coordinate of the mean vector of the own vehicle position road surface voxel is the predicted vehicle height z<sup>&#x2212;</sup> or the estimated vehicle height z<sup>{circumflex over (&#x2003;)}</sup> to be obtained (step S<b>26</b>). In contrasts, if the above-described difference is larger than the predetermined value (Step S<b>25</b>; No), the posture angle calculation unit <b>17</b> determines that the predicted vehicle height z<sup>&#x2212;</sup> or the estimated vehicle height z<sup>{circumflex over (&#x2003;)}</sup> at the preceding processing time is the predicted vehicle height z<sup>&#x2212;</sup> or the estimated vehicle height z<sup>{circumflex over (&#x2003;)}</sup> to be obtained (step S<b>27</b>). Furthermore, at step S<b>27</b>, the posture angle calculation unit <b>17</b> sets the voxel index idz of the own vehicle position road surface voxel selected at step S<b>24</b> to &#x201c;&#x2212;1&#x201d;.</p><p id="p-0157" num="0127">(6-3) Roll Angle/Pitch Angle Estimation Process</p><p id="p-0158" num="0128"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is an example of a flowchart showing the procedure of the vehicle roll angle/pitch angle estimation process to be executed at step S<b>13</b> and step S<b>18</b> in <figref idref="DRAWINGS">FIG. <b>13</b></figref>. In <figref idref="DRAWINGS">FIG. <b>15</b></figref>, as an example, the in-vehicle device <b>1</b> estimates both the roll angle and the pitch angle of the vehicle, however, it may perform a process of estimating only one of the roll angle and the pitch angle of the vehicle.</p><p id="p-0159" num="0129">First, the posture angle calculation unit <b>17</b> refers to the voxel index (idx, idy, idz) of the own vehicle position road surface voxel determined by the vehicle height estimation process at step S<b>12</b> or step S<b>17</b> executed immediately before (step S<b>31</b>). Then, the posture angle calculation unit <b>17</b> determines whether or not the voxel index idz of the own vehicle position road surface voxel is set to &#x201c;&#x2212;1&#x201d; (step S<b>32</b>). If the voxel index idz of the own vehicle position road surface voxel is &#x201c;&#x2212;1&#x201d; (step S<b>32</b>; Yes), the posture angle calculation unit <b>17</b> determines that the reliability of the target vehicle position road surface voxel is low or the own vehicle position road surface voxel cannot be detected. Therefore, in this case, the posture angle calculation unit <b>17</b> sets the roll angle &#x3c6; (&#x3c6;<sup>&#x2212;</sup> or &#x3c6;<sup>{circumflex over (&#x2003;)}</sup>) or the pitch angle &#x3b8; (&#x3b8;<sup>&#x2212;</sup> or &#x3b8;<sup>{circumflex over (&#x2003;)}</sup>) at the current processing time to be obtained to the roll angle &#x3c6; (&#x3c6;<sup>&#x2212;</sup> or &#x3c6;<sup>{circumflex over (&#x2003;)}</sup>) or the pitch angle &#x3b8; (&#x3b8;<sup>&#x2212;</sup> or &#x3b8;<sup>{circumflex over (&#x2003;)}</sup>) calculated at the preceding processing time (step S<b>38</b>).</p><p id="p-0160" num="0130">On the other hand, if the voxel index idz of the own vehicle position road surface voxel is not &#x201c;&#x2212;1&#x201d; (step S<b>32</b>; No), the posture angle calculation unit <b>17</b> acquires the voxel data VD of the n voxels around the own vehicle position road surface voxel including the own vehicle position road surface voxel (step S<b>33</b>). For example, the posture angle calculation unit <b>17</b> determines that voxels whose at least one of the voxel index idx or voxel index idy is different from the index of the own vehicle position road surface voxel and whose voxel index idz is the same or one difference as or from the index of the own vehicle position road surface voxel correspond to the n voxels described above together with the own vehicle position road surface voxel.</p><p id="p-0161" num="0131">Then, the posture angle calculation unit <b>17</b> generates the matrix C and the vector b according to the equation (10) by reading the x, y, z coordinates of the mean vector included in the respective voxel data VD for the n voxels described above (step S<b>34</b>). Next, the posture angle calculation unit <b>17</b> calculates the coefficient vector a by the least squares method based on the equation (13), and specifies the normal vector Vn shown in the equation (15) (step S<b>35</b>). Then, using the yaw angle of the predicted or estimated vehicle (azimuth orientation) &#x3c8; (i.e., &#x3c8;<sup>&#x2212;</sup> or &#x3c8;<sup>{circumflex over (&#x2003;)}</sup>), the posture angle calculation unit <b>17</b> calculates the traveling direction vector V<sub>X </sub>shown in the equation (16) and the lateral direction vector V<sub>Y </sub>shown in the equation (19) (step S<b>36</b>). Thereafter, the posture angle calculation unit <b>17</b> calculates the inner product of the normal vector V<sub>n </sub>and the traveling direction vector Vx based on the equation (17) and calculates the inner product of the normal vector Vn and the lateral direction vector V<sub>Y </sub>based on the equation (20). Then, the posture angle calculation unit <b>17</b> calculates roll angle &#x3c6; (&#x3c6;<sup>&#x2212;</sup> or &#x3c6;<sup>{circumflex over (&#x2003;)}</sup>) and pitch angle &#x3b8; (&#x3b8;<sup>&#x2212;</sup> or &#x3b8;<sup>{circumflex over (&#x2003;)}</sup>) to be determined at the current processing time (step S<b>37</b>).</p><heading id="h-0017" level="1">(7) Experimental Example</heading><p id="p-0162" num="0132">The applicant ran a vehicle equipped with a lidar in the same manner as the configuration shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> on a road including a hill with a large inclination, and performed the own vehicle position estimation based on NDT scan matching to collect the necessary data. The maximum ranging distance of the lidar mounted on the vehicle was 25 meters, and the horizontal angle range for performing ranging was around 120 degrees.</p><p id="p-0163" num="0133"><figref idref="DRAWINGS">FIGS. <b>16</b>A to <b>16</b>E</figref> indicate the transition of the number of point cloud data, the number of associations, the association ratio, the evaluation value, and the pitch angle which were obtained on the above-mentioned road in the case of estimating the pitch angle and then performing the coordinate transformation of the point cloud data based on the estimated pitch angle. <figref idref="DRAWINGS">FIGS. <b>17</b>A to <b>17</b>E</figref> indicate the transition of the number of point cloud data, the number of associations, the association ratio, the evaluation value, and the pitch angle which were obtained on the above-mentioned road in the case of not estimating the pitch angle.</p><p id="p-0164" num="0134">Here, &#x201c;the number of point cloud data&#x201d; indicates the number of measurement points of the point cloud data obtained from the lidar for each processing time, &#x201c;the number of associations&#x201d; indicates the number of measurement points associated with voxels. Further, &#x201c;association ratio&#x201d; indicates the ratio of the number of associations to the number of point cloud data, and &#x201c;evaluation value&#x201d; indicates the total evaluation function value corresponding to the estimated parameter determined in the NDT scan matching. Further, &#x201c;pitch angle&#x201d; indicates the pitch angle of the vehicle estimated by the vehicle. Since the estimation of the pitch angle is not performed in the case of <figref idref="DRAWINGS">FIG. <b>17</b>A to <b>17</b>E</figref>, the pitch angle shown in <figref idref="DRAWINGS">FIG. <b>17</b>E</figref> is always 0 degrees. Further, the time period of the broken line arrow <b>58</b> in <figref idref="DRAWINGS">FIGS. <b>16</b>B to <b>16</b>E</figref> and the time period of the broken line arrow <b>59</b> in <figref idref="DRAWINGS">FIGS. <b>17</b>B to <b>17</b>E</figref> are the time period when the vehicle traveled on the road where the voxel data VD did not exist in the vicinity and therefore when the NDT scan matching had not been performed.</p><p id="p-0165" num="0135">In <figref idref="DRAWINGS">FIG. <b>16</b>E</figref>, in the time periods indicated by the broken line frame <b>60</b> and the broken line frame <b>61</b>, the absolute value of the pitch angle is temporarily increased, and they correspond to the period in which the vehicle was traveling on a hill. Even in such a running period of a hill, as shown in <figref idref="DRAWINGS">FIG. <b>16</b>C</figref>, the association ratio is equivalent to the association ratio in the running period of the other flat road since the decrease in the number of associations is suppressed by the coordinate transformation of the point cloud data considering the pitch angle.</p><p id="p-0166" num="0136">On the other hand, in the case of not performing the estimation of pitch angle and the coordinate transformation of the point cloud data based on the pitch angle, the association ratio corresponding to the time period when the vehicle was running on the above-described hill temporarily significantly decreases as shown in the broken line frame <b>70</b> and the broken line frame <b>71</b> in <figref idref="DRAWINGS">FIG. <b>17</b>C</figref>. When a decrease in the number of associations and the association ratio has occurred, the robustness of NDT scan matching deteriorates, and it is inferred that the reliability of the estimated vehicle position is low.</p><p id="p-0167" num="0137">Thus, according to this example, by performing the estimation of the pitch angle and the coordinate transformation of the point cloud data based on the pitch angle, it is possible to suitably suppress a decrease in the number of associations and the association ratio of the point cloud data even when running on a hill, thereby improving the robustness of the own vehicle position estimation based in the NDT scan matching. Similarly, by performing the estimation of the roll angle and the coordinate transformation of the point cloud data based on the roll angle, it is possible to suitably suppress the reduction of the number of associations and the association ratio of the point cloud data even when running on the road with a high cross slope, thereby improving robustness of the own vehicle position estimation based on the NDT scan matching.</p><p id="p-0168" num="0138">As described above, the control unit <b>15</b> of the in-vehicle device <b>1</b> according to the present embodiment is configured to extract, from voxel data VD that is position information of an object for each of unit areas (voxels) into which a space is divided, the voxel data VD of plural voxels located at or around an own vehicle. Then, the control unit <b>15</b> is configured to calculate a normal vector of an approximate plane calculated based on the extracted voxel data VD of the plural voxels. Then, the control unit <b>15</b> is configured to calculate at least one of a pitch angle of the own vehicle or a roll angle of the own vehicle based on an orientation of the own vehicle and the normal vector. According to this mode, the in-vehicle device <b>1</b> can calculate at least one of the pitch angle or the roll angle with high accuracy, based on the voxel data VD.</p><heading id="h-0018" level="1">(8) Modification</heading><p id="p-0169" num="0139">Hereinafter, a description will be given of a preferred modification to the embodiment described above. The following modifications may be applied to these embodiments in combination.</p><p id="p-0170" num="0140">(First Modification)</p><p id="p-0171" num="0141">In the flowchart in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the in-vehicle device <b>1</b> calculates the height of the vehicle (predicted vehicle height z<sup>&#x2212;</sup> or estimated vehicle height z<sup>{circumflex over (&#x2003;)}</sup>) by performing the height estimation process of the vehicle shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>. However, the calculation method of the height of the vehicle is not limited thereto.</p><p id="p-0172" num="0142">For example, the in-vehicle device <b>1</b> may further include the height of the vehicle in the estimation parameters in the in-vehicle position estimation based on the NDT scan matching. In this case, the in-vehicle device <b>1</b> performs the own vehicle position estimation in which the state variables of the own vehicle position are four variables (x, y, z, &#x3c8;) including not only the coordinates (x, y) and the yaw angle &#x3c8; shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> but also the coordinate of the z-axis perpendicular to the x-axis and y-axis. According to this mode, the in-vehicle device <b>1</b> can also suitably estimate the height of the vehicle.</p><p id="p-0173" num="0143">(Second Modification)</p><p id="p-0174" num="0144">The in-vehicle device <b>1</b> may estimate the pitch angle or the roll angle of the vehicle based on the embodiment even when not performing NDT scan matching.</p><p id="p-0175" num="0145">In this case, for example, in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the in-vehicle device <b>1</b> repeatedly executes the processes at step S<b>11</b> to step S<b>13</b> to repeatedly estimate at least one of the pitch angle or the roll angle of the vehicle based on the voxel data VD. Even in this case, the in-vehicle device <b>1</b> can use the estimated pitch angle or/and roll angle for various applications such as coordinate transformation of the output data of external sensor(s) such as the lidar <b>2</b> and hill (cant) detection processing.</p><p id="p-0176" num="0146">(Third Modification)</p><p id="p-0177" num="0147">The configuration of the driving support system shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is an example, and the configuration of the driving support system to which the present invention is applicable is not limited to the configuration shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. For example, the driving support system may have, instead of having an in-vehicle device <b>1</b>, the electronic control device of the vehicle executing the process to be executed by the posture angle calculation unit <b>17</b> and the NDT matching unit <b>18</b> of the in-vehicle device <b>1</b>. In this case, the map DB <b>10</b> is stored in, for example, a storage unit in the vehicle or a server device configured to perform data communication with the vehicle, and the electronic controller of the vehicle estimates, by referring to the map DB<b>10</b>, the roll angle and/or the pitch angle and the own vehicle position based on NDT scan matching.</p><p id="p-0178" num="0148">(Fourth Modification)</p><p id="p-0179" num="0149">The data structure of the voxel data VD is not limited to a data structure that includes a mean vector and a covariance matrix, as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. For example, the voxel data VD may include the point cloud data measured by the measurement maintenance vehicle to be used in calculating the mean vector and the covariance matrix as it is. In this case, for example, the in-vehicle device <b>1</b> refers to the voxel data VD and calculates the mean vector for each voxel to generate a matrix C shown in the equation (10).</p><p id="p-0180" num="0150">Further, not only NDT scan matching but also other scan matching such as ICP (Iterative Closest Point) may be applied to the embodiment. Even in this case, in the same way as in the embodiment, the in-vehicle device <b>1</b> calculates the posture angle (pitch angle or/and roll angle) based on the embodiment, and performs the own vehicle position estimation relating to the planar position and the azimuth orientation by any scan matching.</p><p id="p-0181" num="0151">While the present invention has been described with reference to the embodiments, the present invention is not limited to the above embodiments. Various changes that can be understood by those skilled in the art within the scope of the present invention can be made in the configuration and details of the present invention. In other words, it is needless to say that the present invention includes various modifications that could be made by a person skilled in the art according to the entire disclosure including the scope of the claims, and the technical philosophy. In addition, all patent and non-patent literatures mentioned in this specification are incorporated by reference in its entirety.</p><heading id="h-0019" level="1">DESCRIPTION OF REFERENCE NUMERALS</heading><p id="p-0182" num="0000"><ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0152"><b>1</b> In-vehicle device</li>    <li id="ul0002-0002" num="0153"><b>2</b> Lidar</li>    <li id="ul0002-0003" num="0154"><b>3</b> Gyroscope sensor</li>    <li id="ul0002-0004" num="0155"><b>4</b> Vehicle velocity sensor</li>    <li id="ul0002-0005" num="0156"><b>5</b> GPS receiver</li>    <li id="ul0002-0006" num="0157"><b>10</b> Map DB</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001 MATH-US-00001-2" nb-file="US20230003521A1-20230105-M00001.NB"><img id="EMI-M00001" he="18.71mm" wi="76.20mm" file="US20230003521A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230003521A1-20230105-M00002.NB"><img id="EMI-M00002" he="9.91mm" wi="76.20mm" file="US20230003521A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00003" nb-file="US20230003521A1-20230105-M00003.NB"><img id="EMI-M00003" he="9.91mm" wi="76.20mm" file="US20230003521A1-20230105-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00004" nb-file="US20230003521A1-20230105-M00004.NB"><img id="EMI-M00004" he="5.67mm" wi="76.20mm" file="US20230003521A1-20230105-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00005" nb-file="US20230003521A1-20230105-M00005.NB"><img id="EMI-M00005" he="8.13mm" wi="76.20mm" file="US20230003521A1-20230105-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00006" nb-file="US20230003521A1-20230105-M00006.NB"><img id="EMI-M00006" he="12.70mm" wi="76.20mm" file="US20230003521A1-20230105-M00006.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00007" nb-file="US20230003521A1-20230105-M00007.NB"><img id="EMI-M00007" he="15.16mm" wi="76.20mm" file="US20230003521A1-20230105-M00007.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00008" nb-file="US20230003521A1-20230105-M00008.NB"><img id="EMI-M00008" he="8.81mm" wi="76.20mm" file="US20230003521A1-20230105-M00008.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00009" nb-file="US20230003521A1-20230105-M00009.NB"><img id="EMI-M00009" he="10.58mm" wi="76.20mm" file="US20230003521A1-20230105-M00009.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00010" nb-file="US20230003521A1-20230105-M00010.NB"><img id="EMI-M00010" he="8.47mm" wi="76.20mm" file="US20230003521A1-20230105-M00010.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00011" nb-file="US20230003521A1-20230105-M00011.NB"><img id="EMI-M00011" he="7.79mm" wi="76.20mm" file="US20230003521A1-20230105-M00011.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00012" nb-file="US20230003521A1-20230105-M00012.NB"><img id="EMI-M00012" he="13.72mm" wi="76.20mm" file="US20230003521A1-20230105-M00012.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00013" nb-file="US20230003521A1-20230105-M00013.NB"><img id="EMI-M00013" he="8.47mm" wi="76.20mm" file="US20230003521A1-20230105-M00013.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00014" nb-file="US20230003521A1-20230105-M00014.NB"><img id="EMI-M00014" he="7.79mm" wi="76.20mm" file="US20230003521A1-20230105-M00014.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00015" nb-file="US20230003521A1-20230105-M00015.NB"><img id="EMI-M00015" he="8.81mm" wi="76.20mm" file="US20230003521A1-20230105-M00015.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00016" nb-file="US20230003521A1-20230105-M00016.NB"><img id="EMI-M00016" he="12.36mm" wi="76.20mm" file="US20230003521A1-20230105-M00016.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00017" nb-file="US20230003521A1-20230105-M00017.NB"><img id="EMI-M00017" he="8.81mm" wi="76.20mm" file="US20230003521A1-20230105-M00017.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An information processing device comprising:<claim-text>an extraction unit configured to extract, from position information of an object for each of unit areas into which a space is divided, the position information of plural unit areas located at or around a moving body;</claim-text><claim-text>a normal vector calculation unit configured to calculate a normal vector of an approximate plane calculated based on the extracted position information of the plural unit areas; and</claim-text><claim-text>an angle calculation unit configured to calculate at least one of a pitch angle of the moving body or a roll angle of the moving body based on an orientation of the moving body and the normal vector.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the angle calculation unit calculates the pitch angle based on an inner product of the normal vector and a vector indicative of the orientation of a travelling direction of the moving body on a horizontal plane.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the angle calculation unit calculates the roll angle based on an inner product of the normal vector and a vector indicative of the orientation of a lateral direction of the moving body on a horizontal plane.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising<claim-text>a position estimation unit configured to perform position estimation of the moving body through matching for each of the unit areas between the position information and data obtained by a coordinate transformation of measurement data based on at least one of the pitch angle or the roll angle, the measurement data being outputted by a measurement unit mounted on the moving body.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the position information of the object for each of the unit areas includes information indicative of a mean vector of the position of the object for each of the unit areas, and</claim-text><claim-text>wherein the normal vector calculation unit calculates the normal vector based on the coordinates of the mean vector for each of the plural unit areas.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the extracting unit extracts the position information corresponding to a first unit area overlapping with the position of the moving body and second unit areas adjacent to the first unit area, the first unit area and the second unit areas being selected from unit areas which have the position information of the object.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The information processing device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising<claim-text>a height calculation unit configured to calculates a height of the moving body from a reference position based on the position information of the first unit area and information indicative of a height of the moving body from a road surface.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the position information is position information of a stationary structure including a road surface, and</claim-text><claim-text>wherein the extracting unit extracts position information of the road surface included in the plural unit areas from map data including the position information of the object for each of the unit areas.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A control method executed by an information processing device, the control method comprising:<claim-text>extracting, from position information of an object for each of unit areas into which a space is divided, the position information of plural unit areas located at or around a moving body;</claim-text><claim-text>calculating a normal vector of an approximate plane calculated based on the extracted position information of the plural unit areas; and</claim-text><claim-text>calculating at least one of a pitch angle of the moving body or a roll angle of the moving body based on an orientation of the moving body and the normal vector.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A non-transitory computer readable medium including instructions executed by a computer, the instructions comprising:<claim-text>extracting, from position information of an object for each of unit areas into which a space is divided, the position information of plural unit areas located at or around a moving body;</claim-text><claim-text>calculating a normal vector of an approximate plane calculated based on the extracted position information of the plural unit areas; and</claim-text><claim-text>calculating at least one of a pitch angle of the moving body or a roll angle of the moving body based on an orientation of the moving body and the normal vector.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. (canceled)</claim-text></claim></claims></us-patent-application>
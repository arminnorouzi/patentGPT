<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003545A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003545</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17305121</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>C</subclass><main-group>21</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>62</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20200801</date></cpc-version-indicator><section>G</section><class>01</class><subclass>C</subclass><main-group>21</main-group><subgroup>3822</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>00798</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>6277</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">METHOD, APPARATUS AND COMPUTER PROGRAM PRODUCT FOR TUNNEL DETECTION FROM A POINT CLOUD</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>HERE GLOBAL B.V.</orgname><address><city>Eindhoven</city><country>NL</country></address></addressbook><residence><country>NL</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>ARMENOFF</last-name><first-name>Nicholas</first-name><address><city>Montgomery</city><state>IL</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Provided herein is a method, apparatus, and computer program product for identifying locations along a road segment as a tunnel based on point cloud data. Methods may include: receiving point cloud data representative of an environment of a trajectory along a road segment; generating, from the point cloud data, one or more two-dimensional images in one or more corresponding planes orthogonal to the trajectory; determining, for the one or more two-dimensional images, a probability as to whether a respective two-dimensional image is captured within a tunnel along the road segment; and classifying a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment satisfying a predetermined value.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="112.01mm" wi="158.75mm" file="US20230003545A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="179.49mm" wi="156.04mm" orientation="landscape" file="US20230003545A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="149.52mm" wi="156.97mm" orientation="landscape" file="US20230003545A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="188.04mm" wi="125.65mm" orientation="landscape" file="US20230003545A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="160.02mm" wi="175.51mm" orientation="landscape" file="US20230003545A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><p id="p-0002" num="0001">An example embodiment of the present invention relates generally to mapping and modeling a three dimensional environment, and more particularly, to using LiDAR data or equivalents thereof to accurately model an environment and to identify tunnels within point clouds.</p><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Map generation for two-dimensional and three-dimensional maps is a time consuming and data-intensive process, particularly when generating three-dimensional maps that are highly accurate. Identifying accurate locations within three-dimensional maps can be of critical importance when those maps are employed for route guidance and to facilitate autonomous and semi-autonomous vehicle control. For a three-dimensional map to be of a quality sufficient to facilitate autonomous and semi-autonomous vehicle control, the maps must include substantial detail and accurate location of boundaries and objects within the mapped region and for the road geometry.</p><p id="p-0004" num="0003">Road geometry modelling is very useful for three-dimensional map creation and 3D terrain identification along with feature and obstacle detection in environments, each of which may facilitate autonomous vehicle navigation along a prescribed path. Traditional methods for 3D modelling of road geometry and object or feature detection and correlation of features between images from different perspectives are resource intensive, often requiring significant amounts of human measurement and calculation. Such methods are thus time consuming and costly. Exacerbating this issue is the fact that many modern-day applications (e.g., 3D mapping, terrain identification, or the like) require manual or semi-automated analysis and labelling of large amounts of data, and therefore are not practical without quicker or less costly techniques.</p><p id="p-0005" num="0004">Some current methods rely upon feature detection from image data to perform road terrain detection or environment feature detection, but these methods have deficiencies. For instance, some systems designed for terrain and feature detection around a vehicle exist but may be unreliable. Further, the reliability of feature detection may not be known such that erroneous feature detection or lack of feature detection may adversely impact autonomous or semi-autonomous driving. Over-estimating the accuracy of feature detection may cause safety concerns as object locations may be improperly interpreted as accurate when they are actually inaccurate, while under-estimating accuracy may lead to inefficiencies through overly cautious behaviors. Further, map data reconstruction of an environment may be inaccurate if object identification does not properly establish the location of an object in three-dimensional space due to inaccuracy during the detection stage. Locating of objects in three-dimensional space from two-dimensional images is challenging and is generally resource intensive.</p><heading id="h-0002" level="1">BRIEF SUMMARY</heading><p id="p-0006" num="0005">A method, apparatus, and computer program product are therefore provided to map and model a three dimensional environment, and more particularly, to use LiDAR data or point cloud generating equivalents thereof to accurately model an environment and to identify tunnels within point clouds. Further, the ubiquity and relatively low-cost of sensors to gather data such as point cloud data may provide access to tremendous amounts of data that can be used in various ways to enhance location-based services, such as through the generation and analysis of three-dimensional models of an environment including the identification of features, such as tunnels as described herein. Embodiments may provide an apparatus including at least one processor and at least one non-transitory memory including computer program code instructions, the computer program code instructions configured to, when executed, cause the apparatus to at least: receive point cloud data representative of an environment from at least one sensor-equipped vehicle traveling on a trajectory along a road segment; generate, from the point cloud data, one or more two-dimensional images in one or more corresponding planes orthogonal to the trajectory; determine, for the one or more two-dimensional images, a probability as to whether a respective two-dimensional image is captured within a tunnel along the road segment; classify a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment satisfying a predetermined value; and update a map database of a road network including the road segment with the point along the road segment classified as a tunnel point.</p><p id="p-0007" num="0006">According to some embodiments, causing the apparatus to determine for the one or more two-dimensional images, a probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment includes causing the apparatus to: process the respective two-dimensional image as an input to a convolutional neural network; and generate, from the convolutional neural network, the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment. The apparatus of some embodiments is caused to classify a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a non-tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment failing to satisfy the predetermined value.</p><p id="p-0008" num="0007">According to some embodiments, the apparatus is further caused to identify a first tunnel point following a non-tunnel point in a direction of travel of the trajectory as a tunnel entrance point, where the tunnel entrance point represents the entrance of a tunnel along the road segment. According to some embodiments, the apparatus is further caused to identify a first non-tunnel point following a tunnel point in the direction of travel of the trajectory as a tunnel exit point, where the tunnel exit point represents an exit of the tunnel along the road segment. The apparatus of some embodiments is caused to update the map database of the road network to include the tunnel entrance point and the tunnel exit point. Causing the apparatus of some embodiments to update a map database of the road network including the road segment with the point along the road segment classified as a tunnel point includes causing the apparatus to update the map database of the road network with bounds of a tunnel entrance and exit.</p><p id="p-0009" num="0008">Embodiments provided herein include a computer program product having at least one non-transitory computer-readable storage medium having computer-executable program code instructions stored therein, the computer-executable program code instructions including program code instructions to: receive point cloud data representative of an environment from at least one sensor-equipped vehicle traveling on a trajectory along a road segment; generate, from the point cloud data, one or more two-dimensional images in one or more corresponding planes orthogonal to the trajectory; determine, for the one or more two-dimensional images, a probability as to whether a respective two-dimensional image is captured within a tunnel along the road segment; classify a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment satisfying a predetermined value; and update a map database of a road network including the road segment with the point along the road segment classified as a tunnel point.</p><p id="p-0010" num="0009">According to some embodiments, the program code instructions to determine, for the one or more two-dimensional images, a probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment includes program code instructions to: process the respective two-dimensional image as an input to a convolutional neural network; and generate, from the convolutional neural network, the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment. Embodiments may include program code instructions to: classify a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a non-tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment failing to satisfy the predetermined value.</p><p id="p-0011" num="0010">According to some embodiments, the computer program product further includes program code instructions to identify a first tunnel point following a non-tunnel point in a direction of travel of the trajectory as a tunnel entrance point, where the tunnel entrance point represents the entrance of a tunnel along the road. Embodiments optionally include program code instructions to identify a first non-tunnel point following a tunnel point in the direction of travel of the trajectory as a tunnel exit point, where the tunnel exit point represents an exit of the tunnel along the road segment. Embodiments optionally include program code instructions to update the map database of the road network to include the tunnel entrance point and the tunnel exit point. The program code instructions to update a map database of the road network including the road segment with the along the road segment classified as a tunnel point optionally includes program code instructions to update the map database of the road network with bounds of a tunnel entrance and exit.</p><p id="p-0012" num="0011">Embodiments provided herein include a method including: receiving point cloud data representative of an environment from at least one sensor-equipped vehicle traveling on a trajectory along a road segment; generating, from the point cloud data, one or more two-dimensional images in one or more corresponding planes orthogonal to the trajectory; determining, for the one or more two-dimensional images, a probability as to whether a respective two-dimensional image is captured within a tunnel along the road segment; classifying a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment satisfying a predetermined value; and updating a map database of a road network including the road segment with the point along the road segment classified as a tunnel point.</p><p id="p-0013" num="0012">According to an example embodiment, determining for the one or more two-dimensional images, a probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment includes: processing the respective two-dimensional image as an input to a convolutional neural network; and generating, from the convolutional neural network, the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment. Methods of some embodiments further include classifying a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a non-tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment failing to satisfy the predetermined value.</p><p id="p-0014" num="0013">According to some embodiments, methods include identifying a first tunnel point following a non-tunnel point in a direction of travel of the trajectory as a tunnel entrance point, where the tunnel entrance point represents the entrance of a tunnel along the road segment. Methods optionally include identifying a first non-tunnel point following a tunnel point in the direction of travel of the trajectory as an exit point, where the tunnel exit point represents an exit of the tunnel along the road segment. Methods optionally include updating the map database of the road network to include the tunnel entrance point and the tunnel exit point.</p><p id="p-0015" num="0014">Embodiments provided herein include an apparatus including: means for receiving point cloud data representative of an environment from at least one sensor-equipped vehicle traveling on a trajectory along a road segment; means for generating, from the point cloud data, one or more two-dimensional images in one or more corresponding planes orthogonal to the trajectory; means for determining, for the one or more two-dimensional images, a probability as to whether a respective two-dimensional image is captured within a tunnel along the road segment; means for classifying a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment satisfying a predetermined value; and means for updating a map database of a road network including the road segment with the point along the road segment classified as a tunnel point.</p><p id="p-0016" num="0015">According to an example embodiment, the means for determining for the one or more two-dimensional images, a probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment includes: means for processing the respective two-dimensional image as an input to a convolutional neural network; and means for generating, from the convolutional neural network, the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment. The apparatus of some embodiments further includes means for classifying a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a non-tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment failing to satisfy the predetermined value.</p><p id="p-0017" num="0016">According to some embodiments, the apparatus includes means for identifying a first tunnel point following a non-tunnel point in a direction of travel of the trajectory as a tunnel entrance point, where the tunnel entrance point represents the entrance of a tunnel along the road segment. The apparatus of example embodiments optionally includes means for identifying a first non-tunnel point following a tunnel point in the direction of travel of the trajectory as an exit point, where the tunnel exit point represents an exit of the tunnel along the road segment. Example apparatuses optionally include means for updating the map database of the road network to include the tunnel entrance point and the tunnel exit point.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0018" num="0017">Having thus described certain example embodiments of the present invention in general terms, reference will hereinafter be made to the accompanying drawings which are not necessarily drawn to scale, and wherein:</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of an apparatus according to an example embodiment of the present disclosure;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram of a system for using LiDAR data or equivalents thereof to accurately model an environment and to identify tunnels within point clouds according to an example embodiment of the present disclosure;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is an example embodiment of the process flow for classifying points along a trajectory in an environment as either being in a tunnel or not being in a tunnel according to an example embodiment of the present disclosure; and</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of a method for accurately modelling an environment and to identify tunnels within point clouds according to an example embodiment of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0023" num="0022">Some embodiments of the present invention will now be described more fully hereinafter with reference to the accompanying drawings, in which some, but not all, embodiments of the invention are shown. Indeed, various embodiments of the invention may be embodied in many different forms and should not be construed as limited to the embodiments set forth herein; rather, these embodiments are provided so that this disclosure will satisfy applicable legal requirements. Like reference numerals refer to like elements throughout. As used herein, the terms &#x201c;data,&#x201d; &#x201c;content,&#x201d; &#x201c;information,&#x201d; and similar terms may be used interchangeably to refer to data capable of being transmitted, received and/or stored in accordance with embodiments of the present invention. Thus, use of any such terms should not be taken to limit the spirit and scope of embodiments of the present invention.</p><p id="p-0024" num="0023">A method, apparatus and computer program product are provided in accordance with an example embodiment of the present disclosure for mapping and modeling a three dimensional environment, and more particularly, to using LiDAR data or equivalents thereof to accurately model an environment and to identify tunnels based on sensed point clouds. Embodiments described herein provide a system with techniques to reconstruct a three-dimensional point cloud model to identify and distinguish tunnels along a road segment to facilitate mapping and navigation, along with improved environmental awareness for autonomous or semi-autonomous vehicle control. The three-dimensional point cloud may be generated by, for example, a LIDAR (Light Distancing and Ranging) sensor that collects point information in a three-dimensional environment.</p><p id="p-0025" num="0024">While LIDAR is described herein according to example embodiments for generating a three-dimensional point cloud, a variety of techniques may be used to accomplish a similar three-dimensional point cloud. Light sensing, imagery (e.g., multi-view such as stereoscopic), acoustic sensing, or various other forms of surface detection techniques may be used for generating a three-dimensional point cloud. Thus, while LIDAR is described with regard to example embodiments, various embodiments may use techniques other than LIDAR.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram of an example apparatus configured for performing any of the operations described herein. Apparatus <b>20</b> is an example embodiment that may be embodied by or associated with any of a variety of computing devices that include or are otherwise associated with a device configured for gathering position/location and environment related information and/or for generating a three-dimensional map and/or model for use in a variety of applications. For example, the computing device may be a mobile terminal, such as a personal digital assistant (PDA), mobile telephone, smart phone, personal navigation device, smart watch, tablet computer, camera or any combination of the aforementioned and other types of voice and text communications systems. Optionally, the computing device may be a fixed computing device, such as a built-in vehicular navigation device, assisted driving device, or the like.</p><p id="p-0027" num="0026">Optionally, the apparatus may be embodied by or associated with a plurality of computing devices that are in communication with or otherwise networked with one another such that the various functions performed by the apparatus may be divided between the plurality of computing devices that operate in collaboration with one another.</p><p id="p-0028" num="0027">The apparatus <b>20</b> may be equipped with any number of sensors <b>21</b>, such as a global positioning system (GPS), LIDAR sensor (transmitter and receiver), local positioning sensor (e.g., odometer or wheel sensor), or any of a variety of sensors configured to establish location information and environment information around the sensor(s). Any of the sensors may be used to sense information regarding the movement, positioning, or orientation of the device and for determining features of the environment and layout of the surroundings at the location of the device as described herein according to example embodiments. In some example embodiments, such sensors may be implemented in a vehicle or other remote apparatus, and the information detected may be transmitted to the apparatus <b>20</b>, such as by near field communication (NFC) including, but not limited to, Bluetooth&#x2122; communication, or the like.</p><p id="p-0029" num="0028">The apparatus <b>20</b> may include, be associated with, or may otherwise be in communication with a communication interface <b>22</b>, processor <b>24</b>, a memory device <b>26</b> and a user interface <b>28</b>. In some embodiments, the processor (and/or co-processors or any other processing circuitry assisting or otherwise associated with the processor) may be in communication with the memory device via a bus for passing information among components of the apparatus. The memory device may be non-transitory and may include, for example, one or more volatile and/or non-volatile memories. In other words, for example, the memory device may be an electronic storage device (for example, a computer readable storage medium) comprising gates configured to store data (for example, bits) that may be retrievable by a machine (for example, a computing device like the processor). The memory device may be configured to store information, data, content, applications, instructions, or the like for enabling the apparatus to carry out various functions in accordance with an example embodiment of the present invention. For example, the memory device could be configured to buffer input data for processing by the processor. Additionally or alternatively, the memory device could be configured to store instructions for execution by the processor.</p><p id="p-0030" num="0029">The processor <b>24</b> may be embodied in a number of different ways. For example, the processor may be embodied as one or more of various hardware processing means such as a coprocessor, a microprocessor, a controller, a digital signal processor (DSP), a processing element with or without an accompanying DSP, or various other processing circuitry including integrated circuits such as, for example, an ASIC (application specific integrated circuit), an FPGA (field programmable gate array), a microcontroller unit (MCU), a hardware accelerator, a special-purpose computer chip, or the like. As such, in some embodiments, the processor may include one or more processing cores configured to perform independently. A multi-core processor may enable multiprocessing within a single physical package. Additionally or alternatively, the processor may include one or more processors configured in tandem via the bus to enable independent execution of instructions, pipelining and/or multithreading.</p><p id="p-0031" num="0030">In an example embodiment, the processor <b>24</b> may be configured to execute instructions stored in the memory device <b>26</b> or otherwise accessible to the processor. Alternatively or additionally, the processor may be configured to execute hard coded functionality. As such, whether configured by hardware or software methods, or by a combination thereof, the processor may represent an entity (for example, physically embodied in circuitry) capable of performing operations according to an embodiment of the present invention while configured accordingly. Thus, for example, when the processor is embodied as an ASIC, FPGA or the like, the processor may be specifically configured hardware for conducting the operations described herein. Alternatively, as another example, when the processor is embodied as an executor of software instructions, the instructions may specifically configure the processor to perform the algorithms and/or operations described herein when the instructions are executed. However, in some cases, the processor may be a processor of a specific device (for example, the computing device) configured to employ an embodiment of the present invention by further configuration of the processor by instructions for performing the algorithms and/or operations described herein. The processor may include, among other things, a clock, an arithmetic logic unit (ALU) and logic gates configured to support operation of the processor.</p><p id="p-0032" num="0031">The apparatus <b>20</b> of an example embodiment may also include or otherwise be in communication with a user interface <b>28</b>. The user interface may include a touch screen display, a speaker, physical buttons, and/or other input/output mechanisms. In an example embodiment, the processor <b>24</b> may comprise user interface circuitry configured to control at least some functions of one or more input/output mechanisms. The processor and/or user interface circuitry comprising the processor may be configured to control one or more functions of one or more input/output mechanisms through computer program instructions (for example, software and/or firmware) stored on a memory accessible to the processor (for example, memory device <b>24</b>, and/or the like). In this regard, the apparatus <b>20</b> may interpret sensed data as surfaces in the surroundings of the sensor and establish location based on other sensor data, such as GPS data, for example.</p><p id="p-0033" num="0032">The apparatus <b>20</b> of an example embodiment may also optionally include a communication interface <b>22</b> that may be any means such as a device or circuitry embodied in either hardware or a combination of hardware and software that is configured to receive and/or transmit data from/to other electronic devices in communication with the apparatus, such as by NFC, described above. Additionally or alternatively, the communication interface <b>22</b> may be configured to communicate over Global System for Mobile Communications (GSM), such as but not limited to Long Term Evolution (LTE). In this regard, the communication interface <b>22</b> may include, for example, an antenna (or multiple antennas) and supporting hardware and/or software for enabling communications with a wireless communication network. Additionally or alternatively, the communication interface <b>22</b> may include the circuitry for interacting with the antenna(s) to cause transmission of signals via the antenna(s) or to handle receipt of signals received via the antenna(s). In some environments, the communication interface <b>22</b> may alternatively or also support wired communication may alternatively support vehicle to vehicle or vehicle to infrastructure wireless links.</p><p id="p-0034" num="0033">According to certain embodiments, the apparatus <b>20</b> may support a mapping or navigation application so as to present maps or otherwise provide navigation or driver assistance. In order to support a mapping application, the computing device may include or otherwise be in communication with a geographic database, such as may be stored in memory <b>26</b>. For example, the geographic database includes node data records, road segment or link data records, point of interest (POI) data records, and other data records. More, fewer or different data records can be provided. In one embodiment, the other data records include cartographic data records, routing data, and maneuver data. One or more portions, components, areas, layers, features, text, and/or symbols of the POI or event data can be stored in, linked to, and/or associated with one or more of these data records. For example, one or more portions of the POI, event data, or recorded route information can be matched with respective map or geographic records via position or GPS data associations (such as using known or future map matching or geo-coding techniques), for example. Furthermore, other positioning technology may be used, such as electronic horizon sensors, radar, LIDAR, ultrasonic and/or infrared sensors.</p><p id="p-0035" num="0034">According to example embodiments, map service provider database may be used to provide driver assistance via a navigation system for route guidance, and/or to facilitate some level of autonomous driving (e.g., levels 2-5 of vehicle autonomy as defined by the Society of Automotive Engineers). <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a communication diagram of an example embodiment of a system for implementing example embodiments described herein using a navigation system and a map data service provider. The illustrated embodiment of <figref idref="DRAWINGS">FIG. <b>2</b></figref> includes a mobile device <b>104</b>, which may be, for example, the apparatus <b>20</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, such as a mobile phone, an in-vehicle navigation system, or the like, and a map data service provider or cloud service <b>108</b>. Each of the mobile device <b>104</b> and map data service provider <b>108</b> may be in communication with at least one of the other elements illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> via a network <b>112</b>, which may be any form of wireless or partially wireless network as will be described further below. Additional, different, or fewer components may be provided. For example, many mobile devices <b>104</b> may connect with the network <b>112</b>. The map data service provider <b>108</b> may be cloud-based services and/or may operate via a hosting server that receives, processes, and provides data to other elements of the system.</p><p id="p-0036" num="0035">The map data service provider may include a map database <b>110</b> that may include node data, road segment data or link data, point of interest (POI) data, traffic data or the like. The map database <b>110</b> may also include cartographic data, routing data, maneuvering data, and/or data regarding structures. According to some example embodiments, the road segment data records may be links or segments representing roads, streets, or paths, as may be used in calculating a route or recorded route information for determination of one or more personalized routes. The node data may be end points corresponding to the respective links or segments of road segment data. The road link data and the node data may represent a road network, such as used by vehicles, cars, trucks, buses, motorcycles, and/or other entities. Optionally, the map database <b>110</b> may contain path segment and node data records or other data that may represent pedestrian paths or areas in addition to or instead of the vehicle road record data, for example. The road/link segments and nodes can be associated with attributes, such as geographic coordinates, street names, address ranges, speed limits, turn restrictions at intersections, and other navigation related attributes, as well as POIs, such as fueling stations, hotels, restaurants, museums, stadiums, offices, auto repair shops, buildings, stores, parks, parking lots, parking structures (e.g., multi-level parking structures), etc. The map database <b>110</b> can include data about the POIs and their respective locations in the POI records. The map database <b>110</b> may include data about places, such as cities, towns, or other communities, and other geographic features such as bodies of water, mountain ranges, etc. Such place or feature data can be part of the POI data or can be associated with POIs or POI data records (such as a data point used for displaying or representing a position of a city). In addition, the map database <b>110</b> can include event data (e.g., traffic incidents, construction activities, scheduled events, unscheduled events, etc.) associated with the POI data records or other records of the map database <b>110</b>.</p><p id="p-0037" num="0036">The map database <b>110</b> may be maintained by a content provider e.g., the map data service provider and may be accessed, for example, by the content or service provider processing server <b>102</b>. By way of example, the map data service provider can collect geographic data and dynamic data to generate and enhance the map database <b>110</b> and dynamic data such as traffic-related data or location-based hazard warning data contained therein. There can be different ways used by the map developer to collect data. These ways can include obtaining data from other sources, such as municipalities or respective geographic authorities, such as via global information system databases. In addition, the map developer can employ field personnel to travel by vehicle along roads throughout the geographic region to observe features and/or record information about them, for example. Also, remote sensing, such as aerial or satellite photography and/or LiDAR, can be used to generate map geometries directly or through machine learning. However, the most ubiquitous form of data that may be available is vehicle data provided by vehicles, such as mobile device <b>104</b>, as they travel the roads throughout a region or among a network of roads. These vehicles or probes may be embodied by mobile device <b>104</b> and may provide data to the map data service provider in the form of traffic speed/congestion data, weather information, location, speed, direction, tunnel presence information etc.</p><p id="p-0038" num="0037">The map database <b>110</b> may be a master map database stored in a format that facilitates updates, maintenance, and development. For example, the master map database or data in the master map database can be in an Oracle spatial format or other spatial format, such as for development or production purposes. The Oracle spatial format or development/production database can be compiled into a delivery format, such as a geographic data files (GDF) format. The data in the production and/or delivery formats can be compiled or further compiled to form geographic database products or databases, which can be used in end user navigation devices or systems.</p><p id="p-0039" num="0038">For example, geographic data may be compiled (such as into a platform specification format (PSF) format) to organize and/or configure the data for performing navigation-related functions and/or services, such as route calculation, route guidance, map display, speed calculation, distance and travel time functions, and other functions, by a navigation device, such as by a vehicle represented by mobile device <b>104</b>, for example.</p><p id="p-0040" num="0039">As mentioned above, the map data service provider <b>108</b> map database <b>110</b> may be a master geographic database, but in alternate embodiments, a client side map database may represent a compiled navigation database that may be used in or with end user devices (e.g., mobile device <b>104</b>) to provide navigation and/or map-related functions. For example, the map database <b>110</b> may be used with the mobile device <b>104</b> to provide an end user with navigation features. In such a case, the map database <b>110</b> can be downloaded or stored on the end user device which can access the map database <b>110</b> through a wireless or wired connection, such as via a processing server <b>102</b> and/or the network <b>112</b>, for example.</p><p id="p-0041" num="0040">In one embodiment, as noted above, the end user device or mobile device <b>104</b> can be embodied by the apparatus <b>20</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> and can include a vehicle infotainment system, an in-dash navigation head unit, a personal navigation device, cellular telephone, or an Advanced Driver Assistance System (ADAS) which may facilitate automated driving features such as autonomous driving and/or parking. An end user can use the mobile device <b>104</b> for navigation and map functions such as guidance and map display, for example, and for determination of useful driver assistance information, according to some example embodiments.</p><p id="p-0042" num="0041">Example embodiments provided herein provide a method for mapping and modeling a three dimensional environment, and more particularly, to using LiDAR data or equivalents thereof to accurately model an environment and to identify tunnels within point clouds. Autonomous vehicles, in particular, need a resilient and relevant perception of the real-world environment around them to properly function in a dynamic environment. Autonomous vehicles need to understand the presence of objects and their locations to safely navigate as a human driver would. Further, human drivers, even when assisted by technology such as a level of autonomous control, require a detailed understanding of the environment in which they are driving, and can benefit from information regarding upcoming road features, hazards, and restrictions.</p><p id="p-0043" num="0042">The accurate mapping and modeling of tunnels and the inclusion of these tunnels in map data within a map database provides information to vehicles and their drivers that can impact how a vehicle is controlled. For example, understanding the location where a tunnel begins at a tunnel entrance and ends at a tunnel exit can provide a driver with an indication to remove sunglasses, turn on head lights, maintain their lane of travel, and to prepare for potentially narrower road boundaries (e.g., reduce speed, avoid traveling adjacent to a wide load, etc.). Tunnel information can also provide an indication for an autonomous or semi-autonomous vehicle to take actions such as turning on headlights, preparing sensors to adapt to a different light contrast, adjusting speed, adjusting following distance, and other controls that may improve safety. The accurate modeling and mapping of tunnels within a road network therefore benefits all vehicles traveling along the road network.</p><p id="p-0044" num="0043">Embodiments of the present disclosure use three-dimensional point cloud information to generate two-dimensional images or &#x201c;slices&#x201d; along a road segment and to determine a probability that individual two-dimensional images are captured within a tunnel. Determining the probability of these two-dimensional images being within a tunnel can provide data points along a trajectory as to where a tunnel begins and ends.</p><p id="p-0045" num="0044">An algorithm of example embodiments receives point cloud data representative of an environment from at least one sensor-equipped vehicle traveling on a trajectory along a road segment of a road network. A trajectory, as described herein, is a path of a vehicle as it travels within a road network. From the point cloud data, two-dimensional images are generated at regularly spaced points along the trajectory by projecting the point cloud points into a two-dimensional plane orthogonal to the trajectory and binning the point cloud points into pixels. These two-dimensional images represent slices of the environment taken along the trajectory at regularly spaced intervals.</p><p id="p-0046" num="0045">The two-dimensional images are each processed to classify the respective images according to whether they are within a tunnel or not. These images may be classified according to a classifier model, which can include a convolutional neural network operating on sequences of the images. The convolutional neural network can be trained from training data that has verified (e.g., human confirmed) tunnels or a lack of tunnels. The convolutional neural network may be augmented using different techniques. These augmentation techniques can include: random translation of two-dimensional image projection points along the trajectory; random small-angle rotation around and from the trajectory path direction; random translation of the two-dimensional images; random small-displacement perturbation of point cloud points (e.g., LiDAR points); and spatial warping either in the point cloud data or in the two-dimensional images. Synthetic point cloud data may also be generated for use in training the convolutional neural network.</p><p id="p-0047" num="0046">Regardless of the process used to determine whether a two-dimensional image is representative of a tunnel or not, the classification of a two-dimensional image as a tunnel is performed using a probability as to whether the image is representative of a tunnel. This probability can be represented as a number between zero and one, with a value of one representing a 100% likelihood that the two-dimensional image is within a tunnel, and a value of zero representing a 0% likelihood that the two-dimensional image is within a tunnel.</p><p id="p-0048" num="0047">Classification of each two-dimensional image from the point cloud data can then be used to generate a probability map, where points along the trajectory corresponding to the respective two-dimensional images are identified with a value representing the probability that the respective point along the trajectory is within a tunnel. This probability map is a one-dimensional map of points along the trajectory classified according to whether respective points are within a tunnel, and may be referred to as a &#x201c;tunnel likelihood map&#x201d;. Thresholding of the tunnel likelihood map or of individual points along the trajectory can yield which points are established to be within a tunnel. A predetermined value of the probability may be used to define whether a respective point is within a tunnel. This predetermined value may be a threshold probability, where the predetermined value may be established, such as by a machine learning model or based on a learned accuracy of the classification of probability that a two-dimensional image is within a tunnel.</p><p id="p-0049" num="0048">A map database is updated with the tunnel likelihood map to establish where tunnels exist along the road network. A tunnel entrance may be established based on points along the trajectory where there is a transition from a non-tunnel point (classified based on a probability of the respective two-dimensional image at that point corresponding to a tunnel being below the predefined value) to a tunnel point (classified based on a probability of the respective two-dimensional image at that point corresponding to a tunnel satisfying the predetermined value). A similar process can be followed to establish a tunnel exit. This information is used by the map database to define the tunnel entrance and the tunnel exit along the road segment(s) of the road network.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a diagram of the disclosed process of using LiDAR data or equivalents thereof to accurately model an environment and to identify tunnels within point clouds. As shown, point cloud data <b>202</b> is received at the trajectory labeling model <b>204</b> that includes the model and model parameters <b>206</b> for establishing how to process the input point cloud data. The trajectory labeling model <b>204</b> converts the point cloud data <b>202</b> into spaced two-dimensional slices/images in planes orthogonal to the trajectory. The model may be run on each two-dimensional image in order to establish a likelihood or probability that the image is in a tunnel. Once the probability is established for each two-dimensional image, a point corresponding to each two-dimensional image on the trajectory can be output together with the probability.</p><p id="p-0051" num="0050">The points representing the probability of a tunnel existing at the corresponding point along the trajectory can then be used as input to the tunnel observation identification model <b>210</b> together with imagery of the environment of the trajectory, which may be maintained, for example, in map database <b>110</b>. The tunnel observation identification model processes the input according to the clustering parameters, threshold parameters, model parameters, and the model itself as shown at <b>212</b>. The tunnel observation identification model processes the pixels representing the tunnel probability and employs the predetermined value (e.g., threshold parameters) to determine if a tunnel exists at the position represented by the point. Nearby points along the trajectory are clustered according to whether they represent a tunnel at the respective position or not. Tunnel entrances and exits may be identified from the tunnel observation identification model <b>210</b>. These entrances/exits may be paired to form a pair of endpoints for a respective tunnel that define the interval of the road segment(s) over which the tunnel exists. These pairs of endpoints may be output to the tunnel localization model <b>220</b>.</p><p id="p-0052" num="0051">The tunnel localization model <b>220</b> uses the pairs of endpoints for each tunnel as input together with top-down point cloud information. The trajectory can be projected onto the top-down point cloud, where bounds of a tunnel are refined, and the output of the tunnel localization model includes a single tunnel with refined bounds that becomes part of the map database for use with navigation and/or autonomous vehicle control.</p><p id="p-0053" num="0052">Embodiments described herein can further be used to create improved three-dimensional mapping contents directly from spatial point clouds such as LiDAR data without losing valuable information that may be lost during conversion between three-dimensional and two-dimensional representations. Accurate and concise maps are necessary for high definition three-dimensional precision maps to ensure proper functionality of some applications in the perspective of scalability. For example, autonomous vehicle control requires an accurate and concise map to safely navigate an environment. Methods described herein use point cloud data to accurately model an environment and to identify where tunnels begin and end. The identification of tunnels along a network of roads better enables improved reconstruction of an environment for better three-dimensional map creation and to use the environment information for autonomous vehicle control.</p><p id="p-0054" num="0053">Navigation of roadways through digital map data can be informed through map data from municipalities, probe data from vehicles traversing the roads, or known vehicles traversing roads to establish the physical location of the roads. This mapping enables relatively accurate mapping of roadways and facilitates navigation and autonomous driving application. However, for increased autonomous vehicle functionality, a higher degree of accuracy and reliability is needed for objects and road or environmental features found along roadways than conventionally provided by map data resources. While such map data resources may provide sufficient detail for certain applications, mapping and autonomous driving may require more detailed and accurate representations of physical structures and environments (e.g., tunnels) through which a vehicle is navigating.</p><p id="p-0055" num="0054">Three-dimensional point cloud reconstruction of a physical structures based on sensor data such as RGB-D or LiDAR sensors may provide raw measurement as described above for segmentation of the point cloud to establish two-dimensional images from which tunnel presence can be more readily identified. Example embodiments described herein provide a system to more readily discern tunnels along road segments and to identify entrances and exits of these tunnels. A system may include a mobile device, such as apparatus <b>20</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, which may be a sensing vehicle having three-dimensional LiDAR (or the like vision sensors), GPS, and/or INS (inertial navigation sensing) unit. The sensing vehicle may obtain the necessary point cloud data from an environment including sensed objects to generate the two-dimensional images in planes orthogonal to a trajectory of the vehicle as described above. The sensing vehicle may obtain sensor data as the vehicle traverses the environment to provide sensor data output which may be stored in, for example, memory <b>26</b>. The sensed data may be provided to a server, such as processing server <b>102</b> of map data service provider <b>108</b> for processing using the models detailed in <figref idref="DRAWINGS">FIG. <b>3</b></figref> above. Optionally, the sensed data may be processed by the sensing device (e.g., an apparatus as in <figref idref="DRAWINGS">FIG. <b>1</b></figref>) and determination of the presence of a tunnel may be generated in real-time as the apparatus encounters and passes through a tunnel.</p><p id="p-0056" num="0055">While mapping may be performed on sensed data from a single vehicle or mobile device <b>104</b>, embodiments may benefit from a plurality of vehicles or mobile devices <b>104</b> providing data regarding the same environment in order to minimize any data noise and to improve the accuracy of the identification of tunnel presences along road segments.</p><p id="p-0057" num="0056">The sensor platform may be a vehicle specifically configured for generating the necessary sensed data or may be crowd-sourced from a vehicle that has the same sensing capabilities that has collected data from the environment of a vehicle as it travels along a trajectory through a network or roads. Such a vehicle may include a three-dimensional LiDAR range sensor or image sensors configured to measure the surroundings of the vehicle, and a GPS/INS unit that allows for positioning to provide an augmented reference for the LiDAR point cloud data. The mobile device <b>104</b> or sensing vehicle may use GPS/INS for global positioning within a geographic region, while the three-dimensional LiDAR sensor or image sensor may collect the range or environment data surrounding the vehicle, colored by the reflectivity field, and may be synchronized with the GPS/INS data for fused LiDAR odometry.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrative of a method according to example embodiments of the present invention. It will be understood that each block of the flowcharts and combination of blocks in the flowcharts may be implemented by various means, such as hardware, firmware, processor, circuitry, and/or other communication devices associated with execution of software including one or more computer program instructions. For example, one or more of the procedures described above may be embodied by computer program instructions. In this regard, the computer program instructions which embody the procedures described above may be stored by a memory device <b>26</b> of an apparatus employing an embodiment of the present invention and executed by a processor <b>24</b> of the apparatus <b>20</b>. As will be appreciated, any such computer program instructions may be loaded onto a computer or other programmable apparatus (for example, hardware) to produce a machine, such that the resulting computer or other programmable apparatus implements the functions specified in the flowchart blocks. These computer program instructions may also be stored in a computer-readable memory that may direct a computer or other programmable apparatus to function in a particular manner, such that the instructions stored in the computer-readable memory produce an article of manufacture the execution of which implements the function specified in the flowchart blocks. The computer program instructions may also be loaded onto a computer or other programmable apparatus to cause a series of operations to be performed on the computer or other programmable apparatus to produce a computer-implemented process such that the instructions which execute on the computer or other programmable apparatus provide operations for implementing the functions specified in the flowchart blocks.</p><p id="p-0059" num="0058">Accordingly, blocks of the flowcharts support combinations of means for performing the specified functions and combinations of operations for performing the specified functions for performing the specified functions. It will also be understood that one or more blocks of the flowcharts, and combinations of blocks in the flowcharts, can be implemented by special purpose hardware-based computer systems which perform the specified functions, or combinations of special purpose hardware and computer instructions.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a method using LiDAR data or equivalents thereof to accurately model an environment and to identify tunnels within point clouds. As shown, point cloud data is received at <b>310</b> representative of an environment from at least one sensor-equipped vehicle traveling or having traveled along a road segment of the trajectory. The point cloud data may be in the form of LiDAR data gathered from LiDAR sensors on a vehicle, for example. At <b>320</b>, one or more two-dimensional images are generated from the point cloud data, where the one or more two-dimensional images are in one or more corresponding planes orthogonal to the trajectory. At <b>330</b>, a probability is determined for the one or more two-dimensional images as to whether a respective two-dimensional image is captured within a tunnel along the road segment. A point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images is classified as a tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment satisfying the predetermined value at <b>340</b>. A map database of a road network including the road segment, such as map database <b>110</b>, is updated at <b>350</b> with the point along the road segment being classified as a tunnel point.</p><p id="p-0061" num="0060">In an example embodiment, an apparatus for performing the method of <figref idref="DRAWINGS">FIG. <b>6</b></figref> above may comprise a processor (e.g., the processor <b>24</b>) configured to perform some or each of the operations (<b>310</b>-<b>350</b>) described above. The processor may, for example, be configured to perform the operations (<b>310</b>-<b>350</b>) by performing hardware implemented logical functions, executing stored instructions, or executing algorithms for performing each of the operations. Alternatively, the apparatus may comprise means for performing each of the operations described above. In this regard, according to an example embodiment, examples of means for performing operations <b>310</b>-<b>350</b> may comprise, for example, the processor <b>24</b> and/or a device or circuit for executing instructions or executing an algorithm for processing information as described above.</p><p id="p-0062" num="0061">Many modifications and other embodiments of the inventions set forth herein will come to mind to one skilled in the art to which these inventions pertain having the benefit of the teachings presented in the foregoing descriptions and the associated drawings. Therefore, it is to be understood that the inventions are not to be limited to the specific embodiments disclosed and that modifications and other embodiments are intended to be included within the scope of the appended claims. Moreover, although the foregoing descriptions and the associated drawings describe example embodiments in the context of certain example combinations of elements and/or functions, it should be appreciated that different combinations of elements and/or functions may be provided by alternative embodiments without departing from the scope of the appended claims. In this regard, for example, different combinations of elements and/or functions than those explicitly described above are also contemplated as may be set forth in some of the appended claims. Although specific terms are employed herein, they are used in a generic and descriptive sense only and not for purposes of limitation.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>That which is claimed:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An apparatus comprising at least one processor and at least one non-transitory memory including computer program code instructions, the computer program code instructions configured to, when executed, cause the apparatus to at least:<claim-text>receive point cloud data representative of an environment from at least one sensor-equipped vehicle traveling on a trajectory along a road segment;</claim-text><claim-text>generate, from the point cloud data, one or more two-dimensional images in one or more corresponding planes orthogonal to the trajectory;</claim-text><claim-text>determine, for the one or more two-dimensional images, a probability as to whether a respective two-dimensional image is captured within a tunnel along the road segment;</claim-text><claim-text>classify a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment satisfying a predetermined value; and</claim-text><claim-text>update a map database of a road network including the road segment with the point along the road segment classified as a tunnel point.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein causing the apparatus to determine for the one or more two-dimensional images, a probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment comprises causing the apparatus to:<claim-text>process the respective two-dimensional image as an input to a convolutional neural network; and</claim-text><claim-text>generate, from the convolutional neural network, the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the apparatus is further caused to:<claim-text>classify a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a non-tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment failing to satisfy the predetermined value.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The apparatus of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the apparatus is further caused to:<claim-text>identify a first tunnel point following a non-tunnel point in a direction of travel of the trajectory as a tunnel entrance point, wherein the tunnel entrance point represents the entrance of a tunnel along the road segment.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The apparatus of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the apparatus is further caused to:<claim-text>identify a first non-tunnel point following a tunnel point in the direction of travel of the trajectory as a tunnel exit point, where the tunnel exit point represents an exit of the tunnel along the road segment.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The apparatus of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the apparatus is further caused to:<claim-text>update the map database of the road network to include the tunnel entrance point and the tunnel exit point.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein causing the apparatus to update a map database of the road network including the road segment with the point along the road segment classified as a tunnel point comprises causing the apparatus to update the map database of the road network with bounds of a tunnel entrance and exit.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A computer program product comprising at least one non-transitory computer-readable storage medium having computer-executable program code instructions stored therein, the computer-executable program code instructions comprising program code instructions to:<claim-text>receive point cloud data representative of an environment from at least one sensor-equipped vehicle traveling on a trajectory along a road segment;</claim-text><claim-text>generate, from the point cloud data, one or more two-dimensional images in one or more corresponding planes orthogonal to the trajectory;</claim-text><claim-text>determine, for the one or more two-dimensional images, a probability as to whether a respective two-dimensional image is captured within a tunnel along the road segment;</claim-text><claim-text>classify a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment satisfying a predetermined value; and</claim-text><claim-text>update a map database of a road network including the road segment with the point along the road segment classified as a tunnel point.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the program code instructions to determine for the one or more two-dimensional images, a probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment comprise program code instructions to:<claim-text>process the respective two-dimensional image as an input to a convolutional neural network; and</claim-text><claim-text>generate, from the convolutional neural network, the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising program code instructions to:<claim-text>classify a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a non-tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment failing to satisfy the predetermined value.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The computer program product of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising program code instructions to:<claim-text>identify a first tunnel point following a non-tunnel point in a direction of travel of the trajectory as a tunnel entrance point, wherein the tunnel entrance point represents the entrance of a tunnel along the road segment.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The computer program product of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising program code instructions to:<claim-text>identify a first non-tunnel point following a tunnel point in the direction of travel of the trajectory as a tunnel exit point, where the tunnel exit point represents an exit of the tunnel along the road segment.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The computer program product of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising program code instructions to:<claim-text>update the map database of the road network to include the tunnel entrance point and the tunnel exit point.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the program code instructions to update a map database of the road network including the road segment with the point along the road segment classified as a tunnel point comprise program code instructions to update the map database of the road network with bounds of a tunnel entrance and exit.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A method comprising:<claim-text>receiving point cloud data representative of an environment from at least one sensor-equipped vehicle traveling on a trajectory along a road segment;</claim-text><claim-text>generating, from the point cloud data, one or more two-dimensional images in one or more corresponding planes orthogonal to the trajectory;</claim-text><claim-text>determining, for the one or more two-dimensional images, a probability as to whether a respective two-dimensional image is captured within a tunnel along the road segment;</claim-text><claim-text>classifying a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment satisfying a predetermined value; and</claim-text><claim-text>updating a map database of a road network including the road segment with the point along the road segment classified as a tunnel point.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein determining for the one or more two-dimensional images, a probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment comprises:<claim-text>processing the respective two-dimensional image as an input to a convolutional neural network; and</claim-text><claim-text>generating, from the convolutional neural network, the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising:<claim-text>classifying a point along the road segment at a position corresponding to a respective one of the one or more two-dimensional images as a non-tunnel point in response to the probability as to whether the respective two-dimensional image is captured within a tunnel along the road segment failing to satisfy the predetermined value.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising:<claim-text>identifying a first tunnel point following a non-tunnel point in a direction of travel of the trajectory as a tunnel entrance point, wherein the tunnel entrance point represents the entrance of a tunnel along the road segment.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further comprising:<claim-text>identifying a first non-tunnel point following a tunnel point in the direction of travel of the trajectory as a tunnel exit point, where the tunnel exit point represents an exit of the tunnel along the road segment.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising:<claim-text>updating the map database of the road network to include the tunnel entrance point and the tunnel exit point.</claim-text></claim-text></claim></claims></us-patent-application>
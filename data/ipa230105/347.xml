<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000348A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000348</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17852490</doc-number><date>20220629</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2021-111847</doc-number><date>20210705</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>3</main-group><subgroup>12</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>3</main-group><subgroup>14</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>3</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>5</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>90</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>3</main-group><subgroup>12</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>3</main-group><subgroup>14</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>3</main-group><subgroup>0058</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>5</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>90</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30041</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10024</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">NON-TRANSITORY COMPUTER-READABLE STORAGE MEDIUM AND OPHTHALMIC IMAGE PROCESSING APPARATUS</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>NIDEK CO., LTD.</orgname><address><city>Gamagori</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Kumagai</last-name><first-name>Yoshiki</first-name><address><city>Gamagori</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Shiba</last-name><first-name>Ryosuke</first-name><address><city>Gamagori</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>NIDEK CO., LTD.</orgname><role>03</role><address><city>Gamagori</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An ophthalmic image processing apparatus includes a processor. The processor acquires a first image as a color fundus image, and corrects a pixel value of at least any color component in the first image, based on color gamut information for specifying a predetermined color gamut to be applied to a color fundus image, to generate a color gamut-corrected image.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="85.43mm" wi="141.82mm" file="US20230000348A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="143.85mm" wi="109.14mm" orientation="landscape" file="US20230000348A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="115.99mm" wi="103.21mm" file="US20230000348A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="177.12mm" wi="137.84mm" file="US20230000348A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="221.40mm" wi="128.95mm" orientation="landscape" file="US20230000348A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="100.33mm" wi="140.29mm" file="US20230000348A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="95.59mm" wi="50.72mm" file="US20230000348A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="107.19mm" wi="80.26mm" file="US20230000348A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="217.17mm" wi="96.01mm" file="US20230000348A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="109.39mm" wi="127.85mm" file="US20230000348A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims priority from Japanese Patent Application No. 2021-111847 filed on Jul. 5, 2021, the entire subject-matter of which is incorporated herein by reference.</p><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present disclosure relates to a non-transitory computer-readable storage medium storing an ophthalmic image processing program for processing a fundus image of a subject eye, and an ophthalmic image processing apparatus.</p><heading id="h-0003" level="1">BACKGROUND ART</heading><p id="p-0004" num="0003">For a long time, in the field of ophthalmology, color fundus images (hereinafter, referred to as fundus photographs) captured by fundus cameras have been used in fundus examination.</p><p id="p-0005" num="0004">In recent years, devices with a high confocal feature compared with conventional fundus cameras have become widespread in ophthalmic facilities. Color fundus images captured by the devices are also utilized in fundus examination. In a color fundus image captured by a device having a high confocal function, for example, each part is depicted with a higher contrast, but a color tint is different from that of a fundus photograph.</p><p id="p-0006" num="0005">As a technique for bringing a color tint of a color fundus image captured by a device having a high confocal system closer to that of a fundus photograph, JP-A-2020-054479 discloses a technique in which a color tone of a color fundus image captured by a device having a high confocal system is corrected on the basis of a predetermined histogram target pattern for each color. According to this, in the device of the high confocal type, a color fundus image having a constant color tone is generated regardless of a wavelength of illumination light, an individual difference in a fundus shape, and an alignment state.</p><p id="p-0007" num="0006">However, due to a difference between an imaging method of a fundus camera and an imaging method different from that, even if a color tone of a fundus image acquired by a device employing the latter method is corrected by using the method in JP-A-2020-054479 described above, unnatural color development may occur in a part of the image when a fundus photograph is used as a reference. The color development can be a useful index for understanding a condition of a fundus, but may give a sense of discomfort to an examiner who is accustomed to fundus photographs.</p><heading id="h-0004" level="1">SUMMARY OF INVENTION</heading><p id="p-0008" num="0007">An object of the present disclosure is to provide a non-transitory computer-readable storage medium recording an ophthalmic image processing program capable of generating a color fundus image with less sense of discomfort to an examiner, and an ophthalmic image processing apparatus.</p><p id="p-0009" num="0008">A first aspect of the present disclosure is a non-transitory computer-readable storage medium storing an ophthalmic image processing program having instructions which, when the ophthalmic image processing program is executed by a processor of a computer, cause the computer to perform:</p><p id="p-0010" num="0009">a first image acquisition step of acquiring a first image as a color fundus image; and</p><p id="p-0011" num="0010">a color gamut-corrected image generation step of correcting a pixel value of at least any color component in the first image, based on color gamut information for specifying a predetermined color gamut to be applied to a color fundus image, to generate a color gamut-corrected image.</p><p id="p-0012" num="0011">A second aspect of the present disclosure is an ophthalmic image processing apparatus including a processor configured to:</p><p id="p-0013" num="0012">acquire a first image as a color fundus image; and</p><p id="p-0014" num="0013">correct a pixel value of at least any color component in the first image, based on color gamut information for specifying a predetermined color gamut to be applied to a color fundus image, to generate a color gamut-corrected image.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram showing a schematic configuration of a fundus imaging device according to an embodiment.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flowchart showing an ophthalmic image processing method according to the present embodiment.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram showing a GUI for color correction and a fundus image display layout.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram for describing a color tone correction method, and shows fundus images before and after correction in a case where a target pattern is used, and a histogram of each channel.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram for describing clipping as a color gamut correction method in an Example.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram showing a GUI for manually adjusting a target color gamut.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram showing an example of an adjusted target color gamut.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIGS. <b>8</b>A to <b>8</b>C</figref> are diagrams showing a case where a monochromatic fundus image is simultaneously displayed as an example of a display mode of a second image, and show the monochromatic fundus image displayed in combination with the second image.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram for describing an outline of color gamut correction in a modification example.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0024" num="0023">[Outline]</p><p id="p-0025" num="0024">Hereinafter, the present disclosure will be described on the basis of an embodiment. For convenience, in the following description, unless otherwise specified, the processing content of an ophthalmic image processing program according to the embodiment and an ophthalmic image processing method will be described as being executed by a computer. The computer may be an ophthalmic image processing apparatus including an ophthalmic imaging device, or may be an ophthalmic image processing apparatus separate from the ophthalmic imaging device.</p><p id="p-0026" num="0025">The ophthalmic image processing program of the present embodiment causes a computer to execute at least a first image acquisition step and a color gamut-corrected image generation step. In the first image acquisition step, a color fundus image is acquired as a first image. In the color gamut-corrected image generation step, a pixel value of at least any color component in the first image is corrected on the basis of color gamut information. As a result, a color gamut-corrected image is generated from the first image. The color gamut information is information for specifying a predetermined color gamut to be applied to a color fundus image. Therefore, in the color gamut-corrected image, a color tint of each tissue is expressed in a predetermined color gamut.</p><p id="p-0027" num="0026">A color gamut specified in the color gamut information in the present embodiment is different from a color reproduction gamut (color gamut) of each image output device. That is, the color gamut specified in the color gamut information is not derived from an image output device such as a display and a printer. Therefore, a color gamut-corrected image is expressed in a predetermined color gamut that is different from the original color gamut of the first image and the color gamut derived from an image output device such as a display and a printer.</p><p id="p-0028" num="0027">In the present embodiment, the color gamut information may be information for specifying a target hue section after correction (after color gamut conversion). More specifically, the color gamut information may be information for defining a target color gamut after correction (after color gamut conversion), information indicating a correspondence between color gamuts before and after correction, such as a mapping table, or other information. In the present embodiment, a pixel value of at least any color component in the first image is corrected such that a color exceeding from the target hue section in the first image is included in the target hue section, or a difference from the target hue section is reduced. As a result, in a color gamut-corrected image, unnatural colors can be appropriately reduced with respect to a target.</p><p id="p-0029" num="0028">The first image may be a color fundus image according to a first imaging method. The target hue section in the color gamut information may be appropriately determined. For example, a hue section of a color fundus image according to a second imaging method different from the first imaging method may be defined as a target color gamut. In this case, the target color gamut is defined in order to suppress a difference in hue between a color fundus image captured according to the second imaging method and the first image, and complete matching with a color gamut in the color fundus image captured according to the second imaging method is not necessarily required. A color gamut corresponding to the second imaging method may be determined on the basis of an average and a variance of hues of respective pixels in the color fundus image captured according to the second imaging method.</p><p id="p-0030" num="0029">The first imaging method may be a confocal method, and the second imaging method may be a non-confocal method. There are some differences between the confocal method and the non-confocal method as follows. For example, in the confocal method, unnecessary scattered light is suppressed from being guided to a light receiving element compared with the non-confocal method such as that of a fundus camera. Therefore, the first image is an image having excellent contrast. For example, in the confocal method, a light source having a narrow wavelength range (for example, a monochromatic light source) is used compared with a white light source such as a flash lamp widely used in a fundus camera. Since the fundus has different spectral reflection characteristics for each tissue (for example, for each layer), emphasized tissues may be different between color fundus images acquired according to the two imaging methods.</p><p id="p-0031" num="0030">In a case where an imaging optical system employs the confocal method, a color tone (balance of each color component) of the entire image of a fundus image may be different for each imaging operation depending on differences in imaging conditions such as alignment and focus. Therefore, even in a case where a specific subject eye is imaged, it is difficult to stabilize a color tone of the entire image in each imaging operation.</p><p id="p-0032" num="0031">On the other hand, in the present embodiment, regarding the first image, the first image may be acquired by converting a color fundus image (referred to as an original image) captured according to the confocal method through a process different from that in the color gamut-corrected image generation step. For example, the conversion may be performed manually or automatically.</p><p id="p-0033" num="0032">As a specific example, a pixel value of each color component in the original image may be corrected on the basis of a predetermined histogram target pattern for each color component. Consequently, regardless of a difference in imaging conditions, the first image becomes an image having a color tone defined by a predefined histogram target pattern for each color component. The target pattern may be, for example, a target pattern for coming closer to a color tint of a fundus photograph.</p><p id="p-0034" num="0033">However, even if the color tone of the first image is corrected in advance, a color tint of a part of the image may be different from a target color tint.</p><p id="p-0035" num="0034">For example, even if the color tone of the first image is corrected in advance to come closer to the color tint of the fundus photograph, the color development in a tissue having a different shape from the surroundings such as an optic nerve head or a lesion is different from that in the fundus photograph and thus tends to be unnatural. More specifically, a part of the tissue or the lesion may have a relatively small red component to be depicted green. It is considered that this phenomenon is caused by a difference between the confocal method and the non-confocal method, which is exemplified above or another factor.</p><p id="p-0036" num="0035">On the other hand, the first image acquired according to the confocal method is corrected on the basis of a color gamut corresponding to the color fundus image acquired according to the non-confocal method, and as a result, the occurrence of a location having an unnatural color tint is reduced compared with the color fundus image acquired according to the non-confocal method.</p><p id="p-0037" num="0036">In this case, it is preferable that a pixel value of at least the red component in the first image is corrected on the basis of the color gamut information. That is, since the red component is relatively small in a portion of the first image that is depicted green, the pixel value of the red component is corrected to a high luminance side, so that a tissue is depicted in a more natural color when the color fundus image according to the non-confocal method is used as a reference.</p><p id="p-0038" num="0037">In the present embodiment, a GUI for accepting a change operation for a color gamut specified by the color gamut information may be displayed. The color gamut information may be changeable on the basis of a change operation via the GUI. Consequently, an examiner can adjust the color gamut-corrected image to a desired color tint.</p><p id="p-0039" num="0038">In the present embodiment, the color gamut-corrected image and a color component image corresponding to the first image are output to an image output device such that the color component image which is a fundus image for each color component in the first image is displayed together with the color gamut-corrected image. Here, in the fundus image for each color component in the color gamut-corrected image, an image that does not originally exist may be drawn in a pixel of which a color component has been corrected as a result of color gamut correction. Therefore, upon displaying the color component image together with the color gamut-corrected image, an examiner can appropriately check the color component image by using a color component image of the first image can be used as the color component image.</p><p id="p-0040" num="0039">In the above embodiment, the color gamut information has been described as information indicating a color gamut corresponding to the second imaging method, but is not necessarily limited to this. For example, the color gamut information may be set on the basis of the first image. For example, if it is empirically clear that a natural color (that is, a color included in a desired hue section) is dominant in the first image, it is considered that a hue section is obtained on the basis of an average, a variance, or the like of hue of each pixel in the first image such that an unnatural color, which is a deviation value from the hue section, can be excluded. Therefore, it is considered that a color gamut-corrected image in which unnatural colors in the first image are reduced can be generated even if a color gamut is corrected by using the color gamut information based on the first image as described above.</p><heading id="h-0007" level="1">EXAMPLE</heading><p id="p-0041" num="0040">&#x3c;Overall Configuration&#x3e;</p><p id="p-0042" num="0041">A fundus imaging device <b>1</b> (hereinafter, abbreviated to &#x201c;the present device <b>1</b>&#x201d;) according to an embodiment includes at least imaging optical systems <b>10</b> and <b>20</b> and an image processor <b>80</b>. The present device <b>1</b> includes the image processor <b>80</b> to function as a computer that executes various types of image processing. The image processor <b>80</b> may also be shared by a processor that controls an operation of the entire device. The image processor <b>80</b> may be separate from a processor that controls an operation of the entire device. An ophthalmic image processing program may be stored in a memory accessible from a processor of the image processor <b>80</b>.</p><p id="p-0043" num="0042">As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the present device <b>1</b> is roughly divided into an optical unit <b>1</b><i>a </i>and a control unit <b>1</b><i>b</i>. The imaging optical systems <b>10</b> and <b>20</b> may be stored in the optical unit <b>1</b><i>a</i>, and the image processor <b>80</b> may be stored in the control unit <b>1</b><i>b</i>. The control unit <b>1</b><i>b </i>has various memories <b>72</b> in addition to a processor (CPU) <b>71</b>. The ophthalmic image processing program may be stored in the memory <b>72</b>. An operation unit <b>75</b> (user interface) may be connected to the control unit <b>1</b><i>b</i>. The operation unit <b>75</b> may be a pointing device such as a mouse and a touch panel, or may be another user interface. For example, a PC may be used as the control unit <b>1</b><i>b. </i></p><p id="p-0044" num="0043">The present device <b>1</b> may have a monitor <b>90</b>. For example, a captured fundus image is displayed on the monitor <b>90</b>. In addition, various GUIs may be displayed on the monitor <b>90</b>.</p><p id="p-0045" num="0044">&#x3c;Imaging Optical System&#x3e;</p><p id="p-0046" num="0045">The imaging optical systems <b>10</b> and <b>20</b> capture at least a color fundus image, which is a kind of fundus image. In the present embodiment, the fundus image is a front image of the fundus. In the color fundus image, each pixel has color information. The imaging optical systems <b>10</b> and <b>20</b> include an irradiation optical system <b>10</b> and a light receiving optical system <b>20</b> (refer to <figref idref="DRAWINGS">FIG. <b>1</b></figref>). The imaging optical systems <b>10</b> and <b>20</b> may capture a monochrome fundus image.</p><p id="p-0047" num="0046">The irradiation optical system <b>10</b> irradiates the fundus with a plurality of pieces of monochromatic light having different wavelengths. The light receiving optical system <b>20</b> has at least a light receiving element <b>25</b> that receives a plurality of pieces of monochromatic light reflected from the fundus. A signal from the light receiving element <b>25</b> is input to the image processor <b>80</b>, and as a result, a color fundus image is generated by the image processor <b>80</b>. In the light receiving optical system <b>20</b>, a plurality of light receiving elements <b>25</b> may be provided for each wavelength of monochromatic light. In this case, a plurality of pieces of monochromatic light reflected from the fundus having different wavelengths may be received simultaneously by the plurality of light receiving elements <b>25</b> by the plurality of pieces of light reflected from the fundus. A plurality of pieces of light reflected from the fundus having different wavelengths may be received by one light receiving element <b>25</b> in a time division manner (in other words, at different timings). As the light receiving element <b>25</b>, a point light receiving element, a one-dimensional imaging element (line sensor), a two-dimensional imaging element, or the like may be used. A sensor to be used is selected as appropriate according to an imaging method.</p><p id="p-0048" num="0047">The irradiation optical system <b>10</b> may have a light source <b>11</b> for each wavelength. For example, as the light source <b>11</b>, any one of various light sources such as a monochromatic LED and a laser light source may be used. Here, &#x201c;monochromatic light&#x201d; has a narrow meaning of light that cannot be decomposed into spectra, but is not necessarily limited to this in the present disclosure. The &#x201c;monochromatic light&#x201d; in the present disclosure may have a width of wavelength distribution to the extent that the light is handled as a specific color in the technical field of the fundus imaging device. However, the width of the wavelength distribution in monochromatic light is narrow enough to be clearly distinguishable from white light in the technical field of fundus imaging device.</p><p id="p-0049" num="0048">For example, the imaging optical systems <b>10</b> and <b>20</b> may irradiate the fundus with three colors of red (R), green (G), and blue (B) when a color fundus image is captured. In this case, infrared (IR) light may be applied to the fundus in addition to or instead of R light. Here, when a color fundus image is captured, light of three or four colors of light is applied to the fundus, but the present disclosure is not limited to this, and the light applied to the fundus may be light of two colors or light of five or more colors. The above color combination is only an example, and a color fundus image may be captured by using another color combination.</p><p id="p-0050" num="0049">The imaging optical systems <b>10</b> and <b>20</b> may be confocal optical systems. In a case of the confocal optical system, the irradiation optical system <b>10</b> has an optical scanner, collects illumination light (here, monochromatic light) in a point-like or line-like manner on the fundus, and scans the fundus with the illumination light by using the optical scanner. The light receiving optical system <b>20</b> is provided with a harmful light removing portion (for example, a pinhole and a slit aperture) at a fundus conjugate position. The harmful light removing portion guides fundus reflected light from a region irradiated with the illumination light to the light receiving element <b>25</b>, and removes the rest. As a result of sequential light reception by the light receiving element <b>25</b>, a front image of the fundus is acquired. In a line scan method, the light receiving element <b>25</b> may also serve as a harmful light removing portion. In this case, a line sensor used as the light receiving element <b>25</b> is disposed at the fundus conjugate position. An example of a non-confocal imaging optical system is an optical system of a general fundus camera. For more details of the confocal optical system, refer to, for example, JP-A-2016-059539 filed by the present applicant. This document discloses a scanning laser ophthalmoscope, which is an example of a fundus imaging device having a confocal optical system.</p><p id="p-0051" num="0050">&#x3c;Image Processor&#x3e;</p><p id="p-0052" num="0051">As described above, the image processor <b>80</b> generates a fundus image on the basis of the signal from the light receiving element <b>25</b>. In the present embodiment, at least a color fundus image is generated as the fundus image. However, the present disclosure is not limited to this, and the image processor <b>80</b> may additionally generate a monochrome fundus image on the basis of the signal from the light receiving element <b>25</b>.</p><p id="p-0053" num="0052">The image processor performs a correction process for bringing the color fundus image captured by the present device <b>1</b> employing the confocal method closer to a color tint of a fundus photograph (a color fundus image captured according to the non-confocal method by using white light). For example, the image processor generates a first image (color tone-corrected image) and a second image (color gamut-corrected image) in a case where a color fundus image is captured. The first image and the second image are generated by correcting a pixel value of an original image by using the color fundus image obtained as a result of imaging as a processing target (that is, the original image). The first image and the second image in the present example are both color fundus images having color components of R, G, and B.</p><p id="p-0054" num="0053">In the following description, for convenience of the description, a color that does not exist empirically in a fundus photograph will be referred to as an &#x201c;unnatural color&#x201d;, and an existing color will be referred to as a &#x201c;natural color&#x201d;. However, the distinction between natural and unnatural is only a convenience to show a color tint difference between different imaging methods, and it should be noted that in each imaging method, the distinction is not related to the question of whether or not original characteristics are properly depicted.</p><p id="p-0055" num="0054">A method of color correction for a color fundus image of the present example will be described with reference to <figref idref="DRAWINGS">FIGS. <b>2</b> to <b>8</b>C</figref>.</p><p id="p-0056" num="0055">In the present example, as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, first, a color fundus image as an original image is captured, and then a color tone of the original image is corrected to generate and acquire a first image. By correcting a color gamut in the first image, a second image is generated and acquired.</p><p id="p-0057" num="0056">In this case, as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a color fundus image <b>200</b>, the GUI <b>210</b> for color tone correction, and GUIs <b>220</b> and <b>230</b> for color gamut correction are displayed on a screen. A color in the color fundus image <b>200</b> displayed on the screen is corrected according to an operation on the GUIs <b>210</b> to <b>230</b>.</p><p id="p-0058" num="0057">First, the original image is displayed on the screen as the color fundus image <b>200</b>. An examiner first operates the GUI <b>210</b> for color tone correction. Consequently, a color tone of the original image is corrected, and thus the first image is generated and displayed on the screen.</p><p id="p-0059" num="0058">&#x3c;Color Tone Correction&#x3e;</p><p id="p-0060" num="0059">Since the color fundus image acquired by the imaging optical systems <b>10</b> and <b>20</b> in the present example uses monochromatic light as illumination light, compared with an image captured by using white light, such as a fundus photograph, reflection characteristics of the fundus easily affect a color tone, and the color tone is difficult to stabilize. Since the imaging optical systems <b>10</b> and <b>20</b> in the present example have higher confocal characteristics than those of a fundus camera, an individual difference in the fundus shape and the alignment state greatly affect the color tone. As a result, the color fundus image acquired by the imaging optical systems <b>10</b> and <b>20</b> in the present example is difficult to reproduce with a constant color tone. In the field of fundus examination, as a result of many years of utilization of color fundus images captured with white light, color tones of color fundus images captured with white light have widely penetrated examiners. In comparison with this, it cannot be said that color tones of color fundus images captured by using monochromatic light have sufficiently penetrated examiners.</p><p id="p-0061" num="0060">In contrast, in the present embodiment, the first image (color tone-corrected image) is a color fundus image expressed in a predetermined color tone regardless of a subject eye and imaging conditions. The first image is generated by correcting a grayscale value of each pixel in an original image such that a feature value based on a distribution of grayscale values of pixels in the original image, which is the feature value for each color component, is fitted to a feature value predetermined as a target pattern for each color component.</p><p id="p-0062" num="0061">The target pattern in the present example represents a histogram pattern of each color component (each color component of R, G, and B) in a fundus photograph. A light source that emits white light may be any of a xenon lamp, a white LED, or the like. The color fundus image may be, for example, an image captured by a fundus camera. For example, the target pattern may be predetermined on the basis of an average luminance distribution in an actual fundus photograph.</p><p id="p-0063" num="0062">A feature value defined as a target pattern is a value that defines a histogram based on a distribution of grayscale values of each pixel. As an example, in the present example, a target value of brightness and a target value of contrast may be predetermined for each color component as feature values. As an example, as the target value of brightness, any one of an average value, a median value, and a mode value of grayscale values in a target grayscale distribution may be used. As the target value of contrast, any value of standard deviation, variance, and full width at half maximum in a target grayscale distribution may be used.</p><p id="p-0064" num="0063">With reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, features of a color tone-corrected image, in which a color tone is corrected by applying a target pattern in the present example, will be described in detail. Each graph in <figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a histogram for each color component (for each color component of R, G, and B).</p><p id="p-0065" num="0064">In the color tone-corrected image shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the histogram for each color component is corrected so as to fit a target pattern defined by the following target values.</p><p id="p-0066" num="0065">Each target value is in units of grayscale values in 256 grayscales.</p><p id="p-0067" num="0066">[Target Value of Brightness (Average Value of Grayscale Distribution)]</p><p id="p-0068" num="0067">R: 122</p><p id="p-0069" num="0068">G: 66</p><p id="p-0070" num="0069">B: 32</p><p id="p-0071" num="0070">[Target Value (Standard Deviation) of Contrast]</p><p id="p-0072" num="0071">R: 40</p><p id="p-0073" num="0072">G: 27.5</p><p id="p-0074" num="0073">B: 16.6</p><p id="p-0075" num="0074">These target values, shown as an example, are set on the basis of a fundus photograph. The first image acquired as described above is meaningful because the reproducibility is guaranteed with a color tone familiar to the examiner.</p><p id="p-0076" num="0075">&#x3c;Color Gamut Correction&#x3e;</p><p id="p-0077" num="0076">However, the first image is depicted in a color that does not give a sense of uncomfortable when compared with a fundus photograph or the like, but may be depicted in an unnatural color that is unfamiliar in the fundus photograph in a partial region of a part of the image. As an example, an unnatural color is likely to occur in a tissue having a shape different from the surroundings such as the optic nerve head, a lesion, or the like. In a portion where unnaturalness occurs, there is a tendency for the red component to be less than in the fundus photograph, and as a result, the optic nerve head or the like is depicted greenish (or bluish) that is unfamiliar in the fundus photograph, and thus a sense of discomfort is caused.</p><p id="p-0078" num="0077">However, in the first image, a greenish tinge of the optic nerve head or the lesion can be used as an index regarding a shape of the optic nerve head or the presence or absence of the lesion. Therefore, it may be possible to select whether to display the first image or the second image according to an operation of the examiner. Therefore, in the present example, the color gamut correction can be enabled/disabled via the GUI <b>220</b>.</p><p id="p-0079" num="0078">In a case where the GUI <b>220</b> is operated and the color gamut correction is enabled, color information of the first image is corrected, and the second image is displayed on the screen as the color fundus image <b>200</b>.</p><p id="p-0080" num="0079">According to the study of the present inventor, an unnatural color development is reduced by supplementing the red component to an unnatural color region (a region expressed greenish). However, for example, if the balance of the red component in the entire image is changed, most of colors of the image expressed in natural colors in the first image will change.</p><p id="p-0081" num="0080">In contrast, in the present example, the second image is generated by correcting a pixel value of at least any color component in the first image on the basis of a predetermined color gamut. In the present example, correction is performed by clipping the color gamut of the first image (details will be described later) on the basis of the color gamut information indicating a predetermined color gamut. Here, the color gamut information is a predetermined color gamut to be applied to a color fundus image, and in the present example, a color gamut as a target (hereinafter, referred to as a &#x201c;target color gamut&#x201d; for convenience) is specified. The target color gamut does not depend on hardware performance (that is, for example, a color reproduction gamut on the monitor <b>90</b>) of an image output device.</p><p id="p-0082" num="0081">The target color gamut indicated by the color gamut information may be set empirically. For example, the target color gamut in the present example may be set on the basis of a hue (an average value of hue variance) in the first image in which an unnatural color region does not occur. According to this, since the first image is an image of which a color tone is close to that of the fundus photograph, the target color gamut is indirectly set in consideration of the hue section of the color fundus image. The target color gamut may be set on the basis of a hue (an average value of hue variance) in the fundus photograph. Since an unnatural color in the first image does not exist in the target fundus photograph or the like, some examiners feel a sense of discomfort, and such a color is unlikely to be included in the hue section in the fundus photograph or the like. On the other hand, since most of the pixels in the first image are depicted in natural colors, most of these pixels are likely to be included in the hue section in the fundus photograph or the like. Therefore, unnatural colors in the first image can be appropriately excluded from the target color gamut set in consideration of the hue section in the fundus photograph or the like, and most of the colors used in the first image are included in the target color gamut of the present example almost as they are.</p><p id="p-0083" num="0082">Here, with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, a color gamut correction method in the present example will be described in detail. In the present example, a color gamut is corrected through clipping. In the clipping shown in the present example, a pixel having the color information outside the target color gamut is corrected to have a color of a color gamut boundary in the target color gamut.</p><p id="p-0084" num="0083">The graph on the left side of <figref idref="DRAWINGS">FIG. <b>5</b></figref> shows an example of color gamut information on a color space. In <figref idref="DRAWINGS">FIG. <b>5</b></figref>, a region of the cube surrounded by the dotted line shows the original color gamut in which an image can be expressed.</p><p id="p-0085" num="0084">On the other hand, a region of the quadrangular pyramid surrounded by the solid line indicates the target color gamut. As an example, the region of the quadrangular pyramid in <figref idref="DRAWINGS">FIG. <b>5</b></figref> corresponds to a hue section in which the hue H takes a value from &#x2212;60&#xb0; to +60&#xb0; in the HSV color space. In the hue section, an image is expressed in colors in the range from magenta to yellow. Each pixel in a general fundus photograph is expressed by this hue section. However, the target color gamut is not necessarily limited to this. For example, the target color gamut may be set on the basis of an average and a variance of the hue of each pixel in an actual fundus photograph or the like.</p><p id="p-0086" num="0085">In <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the fundus image on the right side of the graph shows a fundus image (that is, the first image in the present example) that is a target of color gamut correction. In the color gamut correction process of the present example, it is determined for each pixel of the first image whether or not color information of the pixel is outside the target color gamut. In this determination, pixel values of R, G, and B of each pixel may be referred to when comparing with the target color gamut, or a value of H may be referred to by converting each pixel into HSV.</p><p id="p-0087" num="0086">A value of the hue H can be obtained from R, G, and B by the conversion formula shown as the following equation (1). That is, the hue H is derived on the basis of the ratio of R, G, and B.</p><p id="p-0088" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mi>H</mi>     <mo>=</mo>     <mrow>      <mo>{</mo>      <mtable>       <mtr>        <mtd>         <mrow>          <mrow>           <mrow>            <mn>60</mn>            <mo>&#xd7;</mo>            <mfrac>             <mrow>              <mi>G</mi>              <mo>-</mo>              <mi>R</mi>             </mrow>             <mrow>              <mrow>               <mi>max</mi>               <mo>&#x2061;</mo>               <mo>(</mo>               <mrow>                <mi>R</mi>                <mo>,</mo>                <mi>G</mi>                <mo>,</mo>                <mi>B</mi>               </mrow>               <mo>)</mo>              </mrow>              <mo>-</mo>              <mrow>               <mi>min</mi>               <mo>&#x2061;</mo>               <mo>(</mo>               <mrow>                <mi>R</mi>                <mo>,</mo>                <mi>G</mi>                <mo>,</mo>                <mi>B</mi>               </mrow>               <mo>)</mo>              </mrow>             </mrow>            </mfrac>           </mrow>           <mo>+</mo>           <mn>60</mn>          </mrow>          <mo>,</mo>          <mrow>           <mo>(</mo>           <mrow>            <mrow>             <mi>min</mi>             <mo>&#x2061;</mo>             <mo>(</mo>             <mrow>              <mi>R</mi>              <mo>,</mo>              <mi>G</mi>              <mo>,</mo>              <mi>B</mi>             </mrow>             <mo>)</mo>            </mrow>            <mo>=</mo>            <mi>B</mi>           </mrow>           <mo>)</mo>          </mrow>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mrow>           <mrow>            <mn>60</mn>            <mo>&#xd7;</mo>            <mfrac>             <mrow>              <mi>B</mi>              <mo>-</mo>              <mi>G</mi>             </mrow>             <mrow>              <mrow>               <mi>max</mi>               <mo>&#x2061;</mo>               <mo>(</mo>               <mrow>                <mi>R</mi>                <mo>,</mo>                <mi>G</mi>                <mo>,</mo>                <mi>B</mi>               </mrow>               <mo>)</mo>              </mrow>              <mo>-</mo>              <mrow>               <mi>min</mi>               <mo>&#x2061;</mo>               <mo>(</mo>               <mrow>                <mi>R</mi>                <mo>,</mo>                <mi>G</mi>                <mo>,</mo>                <mi>B</mi>               </mrow>               <mo>)</mo>              </mrow>             </mrow>            </mfrac>           </mrow>           <mo>+</mo>           <mn>180</mn>          </mrow>          <mo>,</mo>          <mrow>           <mo>(</mo>           <mrow>            <mrow>             <mi>min</mi>             <mo>&#x2061;</mo>             <mo>(</mo>             <mrow>              <mi>R</mi>              <mo>,</mo>              <mi>G</mi>              <mo>,</mo>              <mi>B</mi>             </mrow>             <mo>)</mo>            </mrow>            <mo>=</mo>            <mi>R</mi>           </mrow>           <mo>)</mo>          </mrow>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mrow>           <mrow>            <mn>60</mn>            <mo>&#xd7;</mo>            <mfrac>             <mrow>              <mi>R</mi>              <mo>-</mo>              <mi>B</mi>             </mrow>             <mrow>              <mrow>               <mi>max</mi>               <mo>&#x2061;</mo>               <mo>(</mo>               <mrow>                <mi>R</mi>                <mo>,</mo>                <mi>G</mi>                <mo>,</mo>                <mi>B</mi>               </mrow>               <mo>)</mo>              </mrow>              <mo>-</mo>              <mrow>               <mi>min</mi>               <mo>&#x2061;</mo>               <mo>(</mo>               <mrow>                <mi>R</mi>                <mo>,</mo>                <mi>G</mi>                <mo>,</mo>                <mi>B</mi>               </mrow>               <mo>)</mo>              </mrow>             </mrow>            </mfrac>           </mrow>           <mo>+</mo>           <mn>300</mn>          </mrow>          <mo>,</mo>          <mrow>           <mo>(</mo>           <mrow>            <mrow>             <mi>min</mi>             <mo>&#x2061;</mo>             <mo>(</mo>             <mrow>              <mi>R</mi>              <mo>,</mo>              <mi>G</mi>              <mo>,</mo>              <mi>B</mi>             </mrow>             <mo>)</mo>            </mrow>            <mo>=</mo>            <mi>G</mi>           </mrow>           <mo>)</mo>          </mrow>         </mrow>        </mtd>       </mtr>      </mtable>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>1</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0089" num="0087">Here, the number of unnatural colors in the first image is sufficiently small. In particular, in the present example, the number is sufficiently small in combination with the color tone correction performed in advance. For example, a pixel having such a small number of colors, such as a pixel in the optic nerve head in the fundus image in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, is determined to be outside the target color gamut in the first image, and a pixel value of the pixel is changed to be included in the target color gamut. In this case, in the present example, a pixel value of at least the red component is changed to a high luminance side. In the present example, the pixel value is changed on the basis of the following equation (2).</p><p id="p-0090" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>R&#x2032;=max{R,G,B}&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0091" num="0088">Here, R&#x2032; on the left side of equation (2) is a pixel value of a corrected R component. R, G, and B on the right side of equation (2) are pixel values of the respective color components before correction. According to equation (2), a pixel value of only the R component is changed for a pixel determined to have color information outside the target color gamut and is thus corrected to a color of the color gamut boundary.</p><p id="p-0092" num="0089">As in the present example, when the target color gamut is defined as the hue section from &#x2212;60&#xb0; to +60&#xb0; of the hue H in the HSV color space, a grayscale value of the R component is always a value on the low luminance side with respect to at least one of G and B grayscale values outside the target color gamut. Therefore, even if equation (2) is applied to all the pixels of the first image without determining whether or not the pixels are outside the target color gamut in the first image, the same result as when the determination is performed can be obtained. Therefore, the above determination is not always necessary depending on the setting of the target color gamut.</p><p id="p-0093" num="0090">On the other hand, for example, pixels determined to be inside the target color gamut in the first image, such as pixels corresponding to blood vessels or many fundus tissues in the fundus image in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, are maintained to have their pixel values. Since such pixels occupy a large number in the first image, the color information of the pixels is maintained in the second image.</p><p id="p-0094" num="0091">As described above, the color tone correction process can be restricted to a pixel having an unnatural color in the first image, and a color in which the pixel is expressed can be replaced with a color in the range from magenta to yellow (that is, a color that does not give a sense of discomfort when the fundus photograph is used as a reference). As a result, the color fundus image captured by the present device <b>1</b> is appropriately expressed while using only natural colors.</p><p id="p-0095" num="0092">&#x3c;Manual Correction&#x3e;</p><p id="p-0096" num="0093">In the present example, the target color gamut can be further set (changed) on the basis of a user's operation. For example, an operation of setting (changing) the target color gamut is accepted via the GUI <b>230</b>. In the present example, the GUI <b>230</b> is a slider, and the hue section is set by moving a knob along an arrow. In the present example, the hue section of hue H generally has two end points on the blue side and on the green side, but since there is almost no blue in the first image, the blue side has a fixed value (&#x2212;60&#xb0; in the present example), and the end point on the green side is changed via the GUI <b>230</b>. In the GUI <b>230</b>, an adjustment range of the end point on the green side is defined between 0&#xb0; and 60&#xb0;. Generally, a hue section of a certain hue is in a range of &#x2212;180&#xb0; to 180&#xb0;, but the hue section of the fundus photograph is a part thereof as described above. In the present example, since the adjustment range is limited to the necessary and sufficient adjustment range for reproducing a color tint of the fundus photograph, an examiner can appropriately adjust a target hue section.</p><p id="p-0097" num="0094">The second image of which the hue section is changed on the basis of an operation on the GUI <b>230</b> is sequentially displayed on the screen. In the present example, a value indicating an end point of the hue section after setting is displayed in conjunction with movement of the knob of the GUI <b>230</b>. In the GUI <b>230</b>, a slider is displayed in a color corresponding to the set hue section (with a color gradation). Consequently, it becomes easier for an examiner to intuitively understand the color gamut after setting. As a result, a user can intuitively change the color fundus image to a desired color tint.</p><p id="p-0098" num="0095">A GUI <b>300</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> may be used instead of the GUI <b>230</b>. The GUI <b>300</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> imitates a hue wheel, and a user manually moves end points <b>310</b><i>a </i>and <b>310</b><i>b </i>between colors. A hue section between the two end points <b>310</b><i>a </i>and <b>310</b><i>b </i>is set as the target color gamut. In the present example, the second image with the hue section changed on the basis of the operation is sequentially displayed on the screen. As a result, a user can intuitively change the color fundus image to a desired color tint.</p><p id="p-0099" num="0096">Here, for example, in the description of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, in the preset target color gamut is the hue section from &#x2212;60&#xb0; to +60&#xb0; of the hue H, in an actual fundus photograph, the target color gamut tends to be expressed in a narrower hue section. Therefore, in order to depict the color fundus image captured by the present device <b>1</b> in a color close to that of the fundus photograph, a target section may be narrowed to the hue section from &#x2212;60&#xb0; to +60&#xb0; of the hue H. In this case, a pixel value is changed on the basis of the following equation (3).</p><p id="p-0100" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msup>      <mi>R</mi>      <mo>&#x2032;</mo>     </msup>     <mo>=</mo>     <mrow>      <mo>{</mo>      <mtable>       <mtr>        <mtd>         <mrow>          <mfrac>           <mrow>            <mrow>             <mn>60</mn>             <mo>&#x2062;</mo>             <mi>G</mi>            </mrow>            <mo>+</mo>            <mrow>             <mrow>              <mo>(</mo>              <mrow>               <mrow>                <mi>f</mi>                <mo>&#x2061;</mo>                <mo>(</mo>                <mi>H</mi>                <mo>)</mo>               </mrow>               <mo>-</mo>               <mn>60</mn>              </mrow>              <mo>)</mo>             </mrow>             <mo>&#x2062;</mo>             <mi>B</mi>            </mrow>           </mrow>           <mrow>            <mi>f</mi>            <mo>&#x2061;</mo>            <mo>(</mo>            <mi>H</mi>            <mo>)</mo>           </mrow>          </mfrac>          <mo>&#x2062;</mo>          <mrow>           <mo>(</mo>           <mrow>            <mrow>             <mi>H</mi>             <mo>&#x3c;</mo>             <mn>180</mn>            </mrow>            <mo>,</mo>            <mrow>             <mrow>              <mi>f</mi>              <mo>&#x2061;</mo>              <mo>(</mo>              <mi>H</mi>              <mo>)</mo>             </mrow>             <mo>&#x2264;</mo>             <mn>60</mn>            </mrow>           </mrow>           <mo>)</mo>          </mrow>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mfrac>           <mrow>            <mrow>             <mrow>              <mo>-</mo>              <mn>60</mn>             </mrow>             <mo>&#x2062;</mo>             <mi>B</mi>            </mrow>            <mo>+</mo>            <mrow>             <mrow>              <mo>(</mo>              <mrow>               <mrow>                <mi>f</mi>                <mo>&#x2061;</mo>                <mo>(</mo>                <mi>H</mi>                <mo>)</mo>               </mrow>               <mo>-</mo>               <mn>300</mn>              </mrow>              <mo>)</mo>             </mrow>             <mo>&#x2062;</mo>             <mi>G</mi>            </mrow>           </mrow>           <mrow>            <mrow>             <mi>f</mi>             <mo>&#x2061;</mo>             <mo>(</mo>             <mi>H</mi>             <mo>)</mo>            </mrow>            <mo>-</mo>            <mn>360</mn>           </mrow>          </mfrac>          <mo>&#x2062;</mo>          <mrow>           <mo>(</mo>           <mrow>            <mrow>             <mi>H</mi>             <mo>&#x2265;</mo>             <mn>180</mn>            </mrow>            <mo>,</mo>            <mrow>             <mrow>              <mi>f</mi>              <mo>&#x2061;</mo>              <mo>(</mo>              <mi>H</mi>              <mo>)</mo>             </mrow>             <mo>&#x2265;</mo>             <mn>300</mn>            </mrow>           </mrow>           <mo>)</mo>          </mrow>         </mrow>        </mtd>       </mtr>      </mtable>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>3</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0101" num="0097">Here, f(H) is a target hue (target value of hue) of a color after conversion using equation (3). f(H) is represented by equation (4).</p><p id="p-0102" num="0000"><maths id="MATH-US-00003" num="00003"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>f</mi>      <mo>&#x2061;</mo>      <mo>(</mo>      <mi>H</mi>      <mo>)</mo>     </mrow>     <mo>=</mo>     <mrow>      <mo>{</mo>      <mtable>       <mtr>        <mtd>         <mrow>          <mi>H</mi>          <mo>&#x2061;</mo>          <mo>(</mo>          <mrow>           <mrow>            <mi>H</mi>            <mo>&#x2264;</mo>            <msub>             <mi>H</mi>             <mi>G</mi>            </msub>           </mrow>           <mo>,</mo>           <mrow>            <mi>H</mi>            <mo>&#x2265;</mo>            <msub>             <mi>H</mi>             <mi>B</mi>            </msub>           </mrow>          </mrow>          <mo>)</mo>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <msub>           <mi>H</mi>           <mi>G</mi>          </msub>          <mo>(</mo>          <mrow>           <msub>            <mi>H</mi>            <mi>G</mi>           </msub>           <mo>&#x3c;</mo>           <mi>H</mi>           <mo>&#x3c;</mo>           <mn>180</mn>          </mrow>          <mo>)</mo>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <msub>           <mi>H</mi>           <mi>B</mi>          </msub>          <mo>(</mo>          <mrow>           <mn>180</mn>           <mo>&#x2264;</mo>           <mi>H</mi>           <mo>&#x3c;</mo>           <msub>            <mi>H</mi>            <mi>B</mi>           </msub>          </mrow>          <mo>)</mo>         </mrow>        </mtd>       </mtr>      </mtable>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>4</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0103" num="0098">Here, H is a hue of a pixel before conversion. H<sub>B </sub>is closer to blue between the end points <b>310</b><i>a </i>and <b>310</b><i>b </i>of the hue section, while H<sub>G </sub>is the rest closer to green. The target color gamut in this case is shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. Depending on a combination of the setting of the hue section and a pixel value before conversion, a pixel value after conversion may exceed the maximum value that can be expressed (R&#x2032;&#x3e;255), but in this case, may be replaced with the maximum value (R&#x2032;=255).</p><p id="p-0104" num="0099">Consequently, even if the target color gamut is changed, a pixel having color information outside the target color gamut is appropriately corrected to a color of the color boundary in the target color gamut by a changing at least a pixel value of the red component.</p><p id="p-0105" num="0100">&#x3c;Simultaneous Display of Second Image and Color Component Image of Each Color Component&#x3e;</p><p id="p-0106" num="0101">In the present example, a color fundus image may be displayed together with a monochrome fundus image (color component image) corresponding to each color component. In this case, the color fundus image and the color component image may be simultaneously displayed to be arranged on the same screen, or may be switched and displayed in one window.</p><p id="p-0107" num="0102">The spectral reflectances of light of red (R), green (G), and blue (B) applied from the present device <b>1</b> are different for each tissue (for example, for each layer). Thus, different characteristics can be depicted in respective color component images corresponding to red (R), green (G), and blue (B). Therefore, by displaying the color component image corresponding to each color component together with the color fundus image, an examiner can ascertain a structure of the fundus from various angles.</p><p id="p-0108" num="0103"><figref idref="DRAWINGS">FIGS. <b>8</b>A and <b>8</b>B</figref> show color fundus images (before correction: <b>401</b>, after correction: <b>402</b>) and color component images (before correction: <b>401</b>R, <b>401</b>G, and <b>401</b>B, after correction: <b>402</b>R, <b>402</b>G, and <b>402</b>B) corresponding to respective color components of the color fundus images before and after color gamut correction is performed. In the color component image <b>402</b>R corresponding to the R component of the second image shown in <figref idref="DRAWINGS">FIG. <b>8</b>B</figref>, a grayscale value of the R component is corrected through a hue correction process, and as a result, an image that does not originally exist has been drawn in a location (particularly an optic nerve head or a lesion) subjected to correction of a grayscale value surrounded by the dotted line.</p><p id="p-0109" num="0104">Therefore, in the present example, in a case where the second image is displayed, a combination in <figref idref="DRAWINGS">FIG. <b>8</b>C</figref>, that is, the second image <b>402</b> and the color component images <b>401</b>R, <b>401</b>G, and <b>401</b>B corresponding to respective color components in the first image are simultaneously displayed. As a result, in the present example, an appropriate color component image for at least the R component is displayed. As a result, even in a case where the second image is displayed, an examiner can ascertain a structure of the fundus by using an appropriate color component image.</p><heading id="h-0008" level="1">Modification Example</heading><p id="p-0110" num="0105">In the above embodiment, as one of methods of correcting a color gamut (compressing the color gamut), a method of correcting a pixel having color information outside the target color gamut to a color of the color gamut boundary in the target color gamut has been described. However, a method for correcting a color gamut is not necessarily limited to this. For example, the second image may be generated by non-linearly compressing a color gamut as follows.</p><p id="p-0111" num="0106">A method of non-linearly compressing the color gamut will be described with reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref>. In <figref idref="DRAWINGS">FIG. <b>9</b></figref>, a hue of the first image in a certain hue (for example, the hue H) is shown on the horizontal axis, and a target hue (a target value of a hue) specified by color gamut information is shown on the vertical axis.</p><p id="p-0112" num="0107">In the method of the above-described Example, a color in the target color gamut is used without replacement, and a color outside the target color gamut is replaced with a color of the target color gamut boundary. In contrast, the method of the present modification example is a method in which a difference in hue outside the target color gamut is reflected in a corrected image by replacing a color in the target color gamut with another color. In this case, the following equation (5) may be applied to the hue f(H) in the above equation (3).</p><p id="p-0113" num="0000"><maths id="MATH-US-00004" num="00004"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>f</mi>      <mo>&#x2061;</mo>      <mo>(</mo>      <mi>H</mi>      <mo>)</mo>     </mrow>     <mo>=</mo>     <mrow>      <mo>{</mo>      <mtable>       <mtr>        <mtd>         <mrow>          <mi>H</mi>          <mo>&#x2061;</mo>          <mo>(</mo>          <mrow>           <mrow>            <mi>H</mi>            <mo>&#x2264;</mo>            <msubsup>             <mi>H</mi>             <mi>G</mi>             <mo>&#x2032;</mo>            </msubsup>           </mrow>           <mo>,</mo>           <mrow>            <mi>H</mi>            <mo>&#x2265;</mo>            <msubsup>             <mi>H</mi>             <mi>B</mi>             <mo>&#x2032;</mo>            </msubsup>           </mrow>          </mrow>          <mo>)</mo>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <msubsup>           <mi>H</mi>           <mi>G</mi>           <mo>&#x2032;</mo>          </msubsup>          <mo>+</mo>          <mrow>           <mn>2</mn>           <mo>&#x2062;</mo>           <mrow>            <mo>(</mo>            <mrow>             <msub>              <mi>H</mi>              <mi>G</mi>             </msub>             <mo>-</mo>             <msubsup>              <mi>H</mi>              <mi>G</mi>              <mo>&#x2032;</mo>             </msubsup>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#x2062;</mo>           <mrow>            <mo>(</mo>            <mrow>             <mfrac>              <mn>1</mn>              <mrow>               <mn>1</mn>               <mo>+</mo>               <mrow>                <mi>exp</mi>                <mo>&#x2061;</mo>                <mo>(</mo>                <mrow>                 <mo>-</mo>                 <mfrac>                  <mrow>                   <mi>H</mi>                   <mo>-</mo>                   <msubsup>                    <mi>H</mi>                    <mi>G</mi>                    <mo>&#x2032;</mo>                   </msubsup>                  </mrow>                  <mrow>                   <mn>0.5</mn>                   <mrow>                    <mo>(</mo>                    <mrow>                     <msub>                      <mi>H</mi>                      <mi>G</mi>                     </msub>                     <mo>-</mo>                     <msubsup>                      <mi>H</mi>                      <mi>G</mi>                      <mo>&#x2032;</mo>                     </msubsup>                    </mrow>                    <mo>)</mo>                   </mrow>                  </mrow>                 </mfrac>                </mrow>                <mo>)</mo>               </mrow>              </mrow>             </mfrac>             <mo>-</mo>             <mn>0.5</mn>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#x2062;</mo>           <mrow>            <mo>(</mo>            <mrow>             <msubsup>              <mi>H</mi>              <mi>G</mi>              <mo>&#x2032;</mo>             </msubsup>             <mo>&#x3c;</mo>             <mi>H</mi>             <mo>&#x3c;</mo>             <mn>180</mn>            </mrow>            <mo>)</mo>           </mrow>          </mrow>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <msubsup>           <mi>H</mi>           <mi>B</mi>           <mo>&#x2032;</mo>          </msubsup>          <mo>+</mo>          <mrow>           <mn>2</mn>           <mo>&#x2062;</mo>           <mrow>            <mo>(</mo>            <mrow>             <msub>              <mi>H</mi>              <mi>B</mi>             </msub>             <mo>-</mo>             <msubsup>              <mi>H</mi>              <mi>B</mi>              <mo>&#x2032;</mo>             </msubsup>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#x2062;</mo>           <mrow>            <mo>(</mo>            <mrow>             <mfrac>              <mn>1</mn>              <mrow>               <mn>1</mn>               <mo>+</mo>               <mrow>                <mi>exp</mi>                <mo>&#x2061;</mo>                <mo>(</mo>                <mrow>                 <mo>-</mo>                 <mfrac>                  <mrow>                   <mi>H</mi>                   <mo>-</mo>                   <msubsup>                    <mi>H</mi>                    <mi>B</mi>                    <mo>&#x2032;</mo>                   </msubsup>                  </mrow>                  <mrow>                   <mn>0.5</mn>                   <mrow>                    <mo>(</mo>                    <mrow>                     <msub>                      <mi>H</mi>                      <mi>B</mi>                     </msub>                     <mo>-</mo>                     <msubsup>                      <mi>H</mi>                      <mi>B</mi>                      <mo>&#x2032;</mo>                     </msubsup>                    </mrow>                    <mo>)</mo>                   </mrow>                  </mrow>                 </mfrac>                </mrow>                <mo>)</mo>               </mrow>              </mrow>             </mfrac>             <mo>-</mo>             <mn>0.5</mn>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#x2062;</mo>           <mrow>            <mo>(</mo>            <mrow>             <mn>180</mn>             <mo>&#x2264;</mo>             <mi>H</mi>             <mo>&#x3c;</mo>             <msubsup>              <mi>H</mi>              <mi>B</mi>              <mo>&#x2032;</mo>             </msubsup>            </mrow>            <mo>)</mo>           </mrow>          </mrow>         </mrow>        </mtd>       </mtr>      </mtable>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>5</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0114" num="0108">Here, a case where a boundary of the color gamut is set as a combination of a straight line with a slope of 1 and a sigmoid curve is described, but this combination is only an example. H&#x2032;<sub>G </sub>indicates a switching point between a straight line and a curve on the green side, and H&#x2032;<sub>B </sub>indicates a switching point between a straight line and a curve on the blue side.</p><p id="p-0115" num="0109">In the above Example, the conversion from the original image to the first image is performed on the basis of a predetermined histogram target pattern for each color component, but is not necessarily limited to this, and at least one of brightness, contrast, gamma, and the like of each color component may be manually adjustable. These parameters may be preset for each device.</p><p id="p-0116" num="0110">Similarly, a value defined by an examiner in advance may also be used for the target color gamut in the conversion from the first image to the second image.</p><p id="p-0117" num="0111">In the above Example, the color gamut of the entire image of the first image is corrected, but the present disclosure is not limited to this, and a color gamut of a partial region of the first image may be corrected. As a partial region, a color gamut of at least an optic nerve head region may be corrected. For example, a color gamut of the optic nerve head region in the first image may be corrected according to the method in the present example, and a color of the first image may be maintained outside the optic nerve head region. A difference in a color tint of the optic nerve head is conspicuous when comparing the first image and the fundus photograph, the color gamut of the optic nerve head region is corrected according to the method in the present embodiment and is expressed in a color of the fundus photograph. Therefore, a sense of discomfort received by an examiner is suppressed. By maintaining the color of the first image outside the optic nerve head region, a lesion portion or the like can be expressed and conspicuous with a color tint different from that of the fundus photograph. In this case, the optic nerve head region may be detected through image processing, may be set manually, or may be set at a predetermined position on an image.</p><p id="p-0118" num="0112">In the above Example, in order to perform color correction using equation (2), the hue H is obtained from R, G, and B according to the conversion formula of equation (1). However, the same result as equation (2) can be obtained without calculating a hue. In this case, a corrected R component R&#x2032; can be obtained by the following equation (6).</p><p id="p-0119" num="0000"><maths id="MATH-US-00005" num="00005"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msup>      <mi>R</mi>      <mo>&#x2032;</mo>     </msup>     <mo>=</mo>     <mrow>      <mi>max</mi>      <mo>&#x2061;</mo>      <mo>(</mo>      <mrow>       <mi>R</mi>       <mo>,</mo>       <mfrac>        <mrow>         <mrow>          <mn>60</mn>          <mo>&#x2062;</mo>          <mi>G</mi>         </mrow>         <mo>+</mo>         <mrow>          <mrow>           <mo>(</mo>           <mrow>            <msub>             <mi>H</mi>             <mi>G</mi>            </msub>            <mo>-</mo>            <mn>60</mn>           </mrow>           <mo>)</mo>          </mrow>          <mo>&#x2062;</mo>          <mi>B</mi>         </mrow>        </mrow>        <msub>         <mi>H</mi>         <mi>G</mi>        </msub>       </mfrac>       <mo>,</mo>       <mfrac>        <mrow>         <mrow>          <mrow>           <mo>-</mo>           <mn>60</mn>          </mrow>          <mo>&#x2062;</mo>          <mi>B</mi>         </mrow>         <mo>+</mo>         <mrow>          <mrow>           <mo>(</mo>           <mrow>            <msub>             <mi>H</mi>             <mi>B</mi>            </msub>            <mo>-</mo>            <mn>300</mn>           </mrow>           <mo>)</mo>          </mrow>          <mo>&#x2062;</mo>          <mi>G</mi>         </mrow>        </mrow>        <mrow>         <msub>          <mi>H</mi>          <mi>B</mi>         </msub>         <mo>-</mo>         <mn>360</mn>        </mrow>       </mfrac>      </mrow>      <mo>)</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>6</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230000348A1-20230105-M00001.NB"><img id="EMI-M00001" he="19.05mm" wi="76.20mm" file="US20230000348A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230000348A1-20230105-M00002.NB"><img id="EMI-M00002" he="13.04mm" wi="76.20mm" file="US20230000348A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00003" nb-file="US20230000348A1-20230105-M00003.NB"><img id="EMI-M00003" he="8.81mm" wi="76.20mm" file="US20230000348A1-20230105-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00004" nb-file="US20230000348A1-20230105-M00004.NB"><img id="EMI-M00004" he="39.54mm" wi="76.20mm" file="US20230000348A1-20230105-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00005" nb-file="US20230000348A1-20230105-M00005.NB"><img id="EMI-M00005" he="6.01mm" wi="76.20mm" file="US20230000348A1-20230105-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A non-transitory computer-readable storage medium storing an ophthalmic image processing program comprising instructions which, when the ophthalmic image processing program is executed by a processor of a computer, cause the computer to perform:<claim-text>a first image acquisition step of acquiring a first image as a color fundus image; and</claim-text><claim-text>a color gamut-corrected image generation step of correcting a pixel value of at least any color component in the first image, based on color gamut information for specifying a predetermined color gamut to be applied to a color fundus image, to generate a color gamut-corrected image.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The storage medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the first image is a color fundus image according to a first imaging method, and</claim-text><claim-text>the color gamut information indicates a color gamut corresponding to a color fundus image acquired according to a second imaging method different from the first imaging method.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The storage medium according to <claim-ref idref="CLM-00002">claim 2</claim-ref>,<claim-text>wherein the first imaging method is a confocal method, and the second imaging method is a non-confocal method.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The storage medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the color gamut information is defined as a hue section.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The storage medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the color gamut information is set based on a hue of each pixel in the first image.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The storage medium according to <claim-ref idref="CLM-00003">claim 3</claim-ref>,<claim-text>wherein the ophthalmic image processing program comprises instructions which cause the computer to further perform:<claim-text>an original image acquisition step of acquiring an original image as a color fundus image captured according to the first imaging method; and</claim-text><claim-text>a color tone-corrected image generation step of converting a pixel value of each color component in the original image according to a process different from the color gamut-corrected image generation step, to generate the first image.</claim-text></claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The storage medium according to <claim-ref idref="CLM-00003">claim 3</claim-ref>,<claim-text>wherein in the color gamut-corrected image generation step, a pixel value of at least a red component in the first image is corrected based on the color gamut information.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The storage medium according to <claim-ref idref="CLM-00006">claim 6</claim-ref>,<claim-text>wherein in the color gamut-corrected image generation step, a pixel value of at least a red component in the first image is corrected based on the color gamut information.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The storage medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the ophthalmic image processing program comprises instructions which cause the computer to further perform:<claim-text>a GUI display step of displaying a GUI for accepting an operation of changing a color gamut specified by the color gamut information; and</claim-text><claim-text>a color gamut information change step of changing the color gamut information based on a change operation via the GUI.</claim-text></claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The storage medium according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the ophthalmic image processing program comprises instructions which cause the computer to further perform:<claim-text>an image output step of outputting the color gamut-corrected image and a color component image corresponding to the first image to an image output device such that the color component image that is a fundus image for each color component in the first image is displayed together with the color gamut-corrected image.</claim-text></claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. An ophthalmic image processing apparatus comprising a processor configured to:<claim-text>acquire a first image as a color fundus image; and</claim-text><claim-text>correct a pixel value of at least any color component in the first image, based on color gamut information for specifying a predetermined color gamut to be applied to a color fundus image, to generate a color gamut-corrected image.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004305A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004305</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17942163</doc-number><date>20220911</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0613</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0659</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0688</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>067</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0629</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">HOST TECHNIQUES FOR STACKED MEMORY SYSTEMS</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17127707</doc-number><date>20201218</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11455098</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17942163</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>62953825</doc-number><date>20191226</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Micron Technology, Inc.</orgname><address><city>Boise</city><state>ID</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Pawlowski</last-name><first-name>Joseph T.</first-name><address><city>Boise</city><state>ID</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Techniques are provided for operating a memory package and more specifically to increasing bandwidth of a system having stacked memory. In an example, a system can include a storage device having a first type of volatile memory and a second type of volatile memory, and a host device coupled to the storage device. The host device can issue commands to the storage device to store and retrieve information of the system. The host device can include a memory map of the storage device and latency information associated with each command of the commands. The host can sort and schedule pending commands according to the latency information and can intermix commands for the first type of volatile memory and commands for the second type of volatile memory to maintain a high utilization or efficiency of a data interface between the host device and the storage device.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="206.59mm" wi="149.18mm" file="US20230004305A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="219.46mm" wi="151.21mm" file="US20230004305A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="231.82mm" wi="180.42mm" file="US20230004305A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="185.25mm" wi="159.00mm" file="US20230004305A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="123.19mm" wi="159.00mm" file="US20230004305A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="123.19mm" wi="159.00mm" file="US20230004305A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="151.72mm" wi="144.10mm" file="US20230004305A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="209.21mm" wi="96.44mm" orientation="landscape" file="US20230004305A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="212.60mm" wi="73.24mm" orientation="landscape" file="US20230004305A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="200.83mm" wi="159.00mm" file="US20230004305A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="227.33mm" wi="147.74mm" file="US20230004305A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">PRIORITY AND RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of U.S. application Ser. No. 17/127,707, filed Dec. 18, 2020, which claims the benefit of priority to Pawlowski, U.S. Provisional Patent Application No. 62/953,825, titled, &#x201c;HOST TECHNIQUES FOR STACKED MEMORY SYSTEMS&#x201d;, filed Dec. 26, 2019, all of which are hereby incorporated by reference herein in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The following relates generally to operating a memory array and more specifically to increasing bandwidth of a system having stacked memory.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Memory devices are widely used to store information in various electronic devices such as computers, wireless communication devices, cameras, digital displays, and the like. Information is stored by programming different states of a memory device. For example, binary devices have two states, often denoted by a logic &#x201c;1&#x201d; or a logic &#x201c;0.&#x201d; In other systems, more than two states may be stored. To access the stored information, a component of the electronic device may read, or sense, the stored state in the memory device. To store information, a component of the electronic device may write, or program, the state in the memory device.</p><p id="p-0005" num="0004">Various types of memory devices exist, including magnetic hard disks, random-access memory (RAM), read only memory (ROM), DRAM, synchronous dynamic RAM (SDRAM), ferroelectric RAM (FeRAM), magnetic RAM (MRAM), resistive RAM (RRAM), flash memory, phase change memory (PCM), and others. Memory devices may be volatile or non-volatile.</p><p id="p-0006" num="0005">Improving memory devices, generally, may include increasing memory cell density, increasing read/write speeds, increasing reliability, increasing data retention, reducing power consumption, or reducing manufacturing costs, among other metrics. Advancing memory technology has realized improvements for many of these metrics, however, as improvements in processing speed are developed, memory bandwidth can become a bottleneck to overall system performance improvements.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0007" num="0006">In the drawings, which are not necessarily drawn to scale, like numerals may describe similar components in different views. Like numerals having different letter suffixes may represent different instances of similar components. The drawings illustrate generally, by way of example, but not by way of limitation, various embodiments discussed in the present document.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example of a memory die that supports features and operations in accordance with examples of the present disclosure.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIGS. <b>2</b>A and <b>2</b>B</figref> illustrate generally an example of a device that supports features and operations in accordance with examples of the present disclosure.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates generally an example storage system including a host device that can request and receive information from the storage system according to the present subject matter.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref> illustrate generally an example truth table extension of existing high bandwidth memory protocols to allow access to a second type of random-access memory within a stack of memory die of a high bandwidth memory device.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref> illustrate generally an example truth table extension of existing high bandwidth memory protocols to allow access to a second type of random-access memory within a stack of random-access memory die.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates generally a flowchart of an example method for operating a storage system including a stack of first memory.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates generally an example method for sorting and scheduling memory access commands to maximize use of a data bus of an example system.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a further example method of sorting and scheduling memory access commands to maximize utilization of a data bus of an interface between a host and the stacked memory package.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates generally a flowchart of an example method <b>900</b> of operating a host device according to various examples of the present subject matter.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates generally a diagram of a system including a device that supports a storage system including stacked DRAM in accordance with aspects disclosed herein.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0018" num="0017">Techniques are provided for operating a memory package and more specifically to increasing bandwidth of a system having stacked memory. In an example, a system can include a storage device having a first type of volatile memory and a second type of volatile memory, and a host device coupled to the storage device. The host device can issue commands to the storage device to store and retrieve information of the system. The host device can include a memory map of the storage device and latency information associated with each command of the commands. The host can sort and schedule pending commands according to the latency information and can intermix commands for the first type of volatile memory and commands for the second type of volatile memory to maintain a high utilization or efficiency of a data interface between the host device and the storage device.</p><p id="p-0019" num="0018">Features of the disclosure introduced above are further described below in the context of an exemplary array (e.g., <figref idref="DRAWINGS">FIG. <b>1</b></figref>). Specific examples are then described for various examples or aspects of systems (e.g., <figref idref="DRAWINGS">FIGS. <b>2</b>-<b>4</b></figref>).</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example of a memory die <b>100</b> in accordance with various aspects disclosed herein. Memory die <b>100</b> may also be referred to as an electronic memory apparatus, a memory array, an array of memory cells, or a deck of memory cells, in some examples. The memory die <b>100</b> may include memory cells <b>105</b> that are programmable to store different states. Memory cells <b>105</b> may be arranged in one or more banks of memory cells that may be independently accessible. Each memory cell <b>105</b> may be programmable to store two states, denoted as a logic 0 and a logic 1. In some cases, memory cell <b>105</b> may be configured to store more than two logic states.</p><p id="p-0021" num="0020">In some examples, a memory cell <b>105</b> may store a charge representative of the programmable states in a capacitor; for example, a charged and uncharged capacitor may represent two logic states, respectively. DRAM architectures may use such a design, and the capacitor employed may include a dielectric material with linear or para-electric electric polarization properties as the insulator. FeRAM architectures may also employ such a design. In some examples, a memory cell <b>105</b> may store a representation of the programmable states in a cross-coupled inverter configuration. Static RAM (SRAM) architectures may use such a design.</p><p id="p-0022" num="0021">Operations such as reading and writing may be performed on memory cells <b>105</b> by activating access line <b>110</b> and digit line <b>115</b>. Access lines <b>110</b> may also be known as word lines <b>110</b>, and bit lines <b>115</b> may also be known digit lines <b>115</b>. References to word lines and bit lines, or their analogues, are interchangeable without loss of understanding or operation. Activating a word line <b>110</b> or a digit line <b>115</b> may include applying a voltage to the respective line.</p><p id="p-0023" num="0022">According to the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, each row of memory cells <b>105</b> may be connected to a single word line <b>110</b>, and each column of memory cells <b>105</b> may be connected to a single digit line <b>115</b>. By activating one word line <b>110</b> and one digit line <b>115</b> (e.g., applying a voltage to the word line <b>110</b> or digit line <b>115</b>), a single memory cell <b>105</b> may be accessed at their intersection. Accessing the memory cell <b>105</b> may include reading or writing the memory cell <b>105</b>. The intersection of a word line <b>110</b> and digit line <b>115</b> may be referred to as an address of a memory cell. Additionally or alternatively, for example, each row of memory cells <b>105</b> may be arranged in one or more banks of memory cells.</p><p id="p-0024" num="0023">In some architectures, the logic storing device of a cell, e.g., a capacitor, flip-flop, may be electrically isolated from the digit line by a selection component (not shown). The word line <b>110</b> may be connected to and may control the selection component. For example, the selection component may be a transistor and the word line <b>110</b> may be connected to the gate of the transistor. Activating the word line <b>110</b> may result in an electrical connection or closed circuit between the capacitor of a memory cell <b>105</b> and its corresponding digit line <b>115</b>. The digit line may then be accessed to either read or write the memory cell <b>105</b>.</p><p id="p-0025" num="0024">Accessing memory cells <b>105</b> may be controlled through a row decoder <b>120</b> and a column decoder <b>130</b>. For example, a row decoder <b>120</b> may receive a row address from the memory controller <b>140</b> and activate the appropriate word line <b>110</b> based on the received row address. Similarly, a column decoder <b>130</b> may receive a column address from the memory controller <b>140</b> and activate the appropriate digit line <b>115</b>. Row decoder <b>120</b> and column decoder <b>130</b> may receive a row address and a column address, respectively, for a memory cell located within one specific bank of memory cells. Additionally or alternatively, each bank of memory cells may be in electronic communication with a separate row decoder <b>120</b> and column decoder <b>130</b>. For example, memory die <b>100</b> may include multiple word lines <b>110</b>, labeled WL_<b>1</b> through WL_M, and multiple digit lines <b>115</b>, labeled DL_<b>1</b> through DL_N, where M and N depend on the array size. Thus, by activating a word line <b>110</b> and a digit line <b>115</b>, e.g., WL_<b>2</b> and DL_<b>3</b>, the memory cell <b>105</b> at their intersection may be accessed.</p><p id="p-0026" num="0025">Upon accessing a memory cell <b>105</b>, the cell may be read, or sensed, by sense component <b>125</b> to determine the stored state of the memory cell <b>105</b>. For example, after accessing the memory cell <b>105</b>, the capacitor of memory cell <b>105</b> may discharge onto its corresponding digit line <b>115</b>. Discharging the capacitor may in some cases result from biasing, or applying a voltage, to the capacitor. The discharging may cause a change in the voltage of the digit line <b>115</b>, which sense component <b>125</b> may compare to a reference voltage (not shown) to determine the stored state of the memory cell <b>105</b>. For example, if digit line <b>115</b> has a higher voltage than the reference voltage, then sense component <b>125</b> may determine that the stored state in memory cell <b>105</b> was a logic 1 and vice versa. Sense component <b>125</b> may include various transistors or amplifiers to detect and amplify a difference in the signals, which may be referred to as latching. The detected logic state of memory cell <b>105</b> may then be output through column decoder <b>130</b> as output <b>135</b>. In some cases, sense component <b>125</b> may be part of a column decoder <b>130</b> or row decoder <b>120</b>. Or, sense component <b>125</b> may be connected to or in electronic communication with column decoder <b>130</b> or row decoder <b>120</b>.</p><p id="p-0027" num="0026">A memory cell <b>105</b> may be set, or written, by similarly activating the relevant word line <b>110</b> and digit line <b>115</b>&#x2014;e.g., a logic value may be stored in the memory cell <b>105</b>. Column decoder <b>130</b> or row decoder <b>120</b> may accept data, for example input/output <b>135</b>, to be written to the memory cells <b>105</b>. A memory cell <b>105</b> may be written by applying a voltage across the capacitor.</p><p id="p-0028" num="0027">The memory controller <b>140</b> may control the operation (e.g., read, write, re-write, refresh, discharge, etc.) of memory cells <b>105</b> through the various components, for example, row decoder <b>120</b>, column decoder <b>130</b>, and sense component <b>125</b>. Memory controller <b>140</b> may be a component of memory die <b>100</b> or may be external to memory die <b>100</b> in various examples. In some cases, one or more of the row decoder <b>120</b>, column decoder <b>130</b>, and sense component <b>125</b> may be co-located with the memory controller <b>140</b>. Memory controller <b>140</b> may generate row and column address signals to activate the desired word line <b>110</b> and digit line <b>115</b>. The memory controller <b>140</b> may activate the desired word line <b>110</b> and digit line <b>115</b> of a specific bank of memory cells via at least one channel traversing the memory die <b>100</b>. Memory controller <b>140</b> may also generate and control various voltages or currents used during the operation of memory die <b>100</b>. For example, it may apply discharge voltages to a word line <b>110</b> or digit line <b>115</b> after accessing one or more memory cells <b>105</b>. Memory controller <b>140</b> may be coupled to memory cells <b>105</b> via channels <b>145</b>. Channels <b>145</b> are illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> as logical connections with row decoder <b>120</b> and column decoder <b>130</b>, but those skilled in the art will recognize that other configurations may be employed. As described herein, memory controller <b>140</b> may exchange data (e.g., from a read or write operation) with cells <b>105</b> multiple times per clock cycle.</p><p id="p-0029" num="0028">The memory controller <b>140</b> may also be configured to communicate commands, data, and other information with a host device (not shown). The memory controller <b>140</b> may use a modulation scheme to modulate signals communicated between the memory array and the host device. An I/O interface may be configured based on what type of modulation scheme is selected. In general, the amplitude, shape, or duration of an applied voltage or current discussed herein may be adjusted or varied and may be different for the various operations discussed in operating the memory die <b>100</b>. Furthermore, one, multiple, or all memory cells <b>105</b> within memory die <b>100</b> may be accessed simultaneously or concurrently; for example, multiple or all cells of memory die <b>100</b> may be accessed simultaneously or concurrently during a reset operation in which all memory cells <b>105</b>, or a group of memory cells <b>105</b>, are set to a single logic state.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an apparatus or system <b>290</b> that supports channel routing for a memory device in accordance with various examples disclosed herein. The system <b>290</b> may include a host device <b>205</b> and a plurality of stacks <b>210</b>. In conventional systems, the plurality of stacks can include stacked memory die of the same type, such as DRAM memory die. In certain examples, the stacks can include a mix of capacitive based memory devices such as DRAM and cross-linked inverter memory such a SRAM. The present inventor has recognized that bandwidth improvements can be realized if the host has direct access to a second, faster, deterministic type of memory, such as SRAM memory.</p><p id="p-0031" num="0030">The host device <b>205</b> may be an example of a processor (e.g., a central processing unit (CPU), a graphics processing unit (GPU)), or a system on a chip (SoC). In some cases, the host device <b>205</b> may be a separate component from the memory device such that the host device <b>205</b> may be manufactured separately from the memory device. The host device <b>205</b> may be external to the stacks <b>210</b> (e.g., a laptop, server, personal computing device, smartphone, personal computer). In the system <b>290</b>, the stacks of memory die <b>210</b> may be configured to store data for the host device <b>205</b>.</p><p id="p-0032" num="0031">The host device <b>205</b> may exchange information with the stacks of memory die <b>210</b> using signals communicated over signal paths. A signal path may be a path that a message or transmission may take from a transmitting component to a receiving component. In some cases, a signal path may be a conductor coupled with at least two components, where the conductor may selectively allow electrons to flow between the at least two components. The signal path may be formed in a wireless medium as in the case for wireless communications (e.g., radio frequency (RF) or optical). The signal paths may at least partially include a first substrate, such as an organic substrate of the memory device, and/or a second substrate, such as a package substrate (e.g., a second organic substrate) that may be coupled with at least one, if not both, of the stacks <b>210</b> and the host device <b>205</b>. In some cases, the stacks <b>210</b> may function as a slave-type device to the host device <b>205</b>, which may function as a master-type device.</p><p id="p-0033" num="0032">In some applications, the system <b>290</b> may benefit from a high-speed connection between the host device <b>205</b> and the memory devices <b>210</b>. As such, some stacks <b>210</b> support applications, processes, host devices, or processors that have multiple terabytes per second (TB/s) bandwidth needs. Satisfying such a bandwidth constraint within an acceptable energy budget may pose challenges in certain contexts.</p><p id="p-0034" num="0033">The memory dies <b>200</b> of the stacks <b>210</b> may be configured to work with multiple types of communication mediums <b>211</b> (e.g., substrates such as organic substrates and/or high-density interposers such as silicon interposers). The host device <b>205</b> may, in some cases, be configured with an interface or ball-out comprising a design (e.g., a matrix or pattern) of terminals.</p><p id="p-0035" num="0034">In some cases, a buffer layer may be positioned between the memory dies <b>200</b> and the communication medium <b>211</b>. The buffer layer may be configured to drive (e.g., redrive) signals to and from the memory dies <b>200</b>. In some cases, the stacks <b>210</b> of memory dies <b>200</b> may be bufferless meaning that either no buffer layer is present or that a base layer does not include re-drivers, among other components. In certain examples of bufferless memory, a routing layer or logic die <b>206</b> may be positioned between the memory die <b>200</b>, or stack of memory die <b>200</b> and the communication medium <b>211</b>. In certain examples, the logic die <b>206</b> can form a lower layer of a memory die <b>200</b>. In certain examples, a bufferless memory stack <b>210</b> can include a lower most memory die <b>200</b> having a logic die layer <b>206</b>.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates generally an example storage system <b>391</b> including a host device <b>305</b> that can request and receive information from a storage system <b>310</b> according to the present subject matter. The host device <b>305</b> may be, but is not limited to, a CPU, graphics processing unit (GPU), accelerated processing unit (GPU), digital signal processor (DSP), field-programmable gate array (FPGA), application specific integrated circuit (ASIC) and any other component of a larger system that communicates with the storage system <b>310</b>. In some embodiments, the device <b>305</b> may be multiple devices accessing the same storage system <b>310</b>. The storage system <b>310</b> can include a logic die <b>306</b> integrated with a memory stack <b>320</b>, such as a stack of dynamic random-access memory (DRAM) devices.</p><p id="p-0037" num="0036">The logic die <b>306</b> can include a host interface <b>331</b> connected to a stacked DRAM control <b>332</b> and prefetch and cache logic <b>333</b>. The stacked DRAM control <b>332</b> is connected to and interfaces with the memory stack <b>320</b>. The prefetch and cache logic <b>333</b> can be connected with a prefetcher, prefetch buffers and a cache array <b>334</b>. The prefetcher may be a hardware prefetcher. The prefetch buffers and cache array <b>334</b> may be, but is not limited to, an SRAM array, any other memory array technology, or a register.</p><p id="p-0038" num="0037">The host interface <b>331</b> can include a command decoder <b>335</b> and interface registers <b>336</b>. The host interface <b>331</b>, and more specifically, the command decoder <b>335</b> can receive all incoming memory requests to the memory stack <b>320</b> from the device <b>305</b>. The requests can be sent to the prefetch and cache logic <b>333</b>, (for example, next-line, stride, and the like). The prefetch and cache logic <b>333</b> can monitor the incoming memory requests. Prefetched data can be placed into the prefetch buffers and cache array <b>334</b>. The prefetch and cache logic <b>333</b> can also check any incoming memory requests against the data in the prefetch buffers and cache array <b>334</b>. Any hits can be served directly from the prefetch buffers and cache array <b>334</b> without going to the stacked DRAM control <b>332</b>. This can reduce service latencies for these requests, as well as reduce contention in the stacked DRAM control <b>332</b> of any remaining requests, (i.e., those that do not hit in the prefetch buffers and cache array <b>334</b>).</p><p id="p-0039" num="0038">The prefetcher may encompass any prefetching algorithm/method or combination of algorithms/methods. Due to the row-buffer-based organization of most memory technologies, (for example, DRAM), prefetch algorithms that exploit spatial locality, (for example, next-line, small strides and the like), have relatively low overheads because the prefetch requests will (likely) hit in the memory's row buffer(s). Implementations may issue prefetch requests for large blocks of data, (i.e., more than one 64B cache line's worth of data), such as prefetching an entire row buffer, half of a row buffer, or other granularities.</p><p id="p-0040" num="0039">The prefetch buffers and cache array <b>334</b> may be implemented as a direct-mapped, set-associative, to a fully-associative cache-like structure. In an embodiment, the prefetch buffers and cache array <b>334</b> may be used to service only read requests, (i.e., writes cause invalidations of prefetch buffer entries, or a write-through policy must be used). In another embodiment, the prefetch buffers and cache array <b>334</b> may employ replacement policies such as Least Recently Used (LRU), Least Frequency Used (LFU), or First In First Out (FIFO). If the prefetch unit generates requests for data sizes larger than a cache line, (as described hereinabove), the prefetch buffers and cache array <b>334</b> may also need to be organized with a correspondingly wider data block size. In some embodiments, sub-blocking may be used.</p><p id="p-0041" num="0040">While described herein as being employed in a memory organization consisting of one logic chip and one or more memory chips, there are other physical manifestations. Although described as a vertical stack of a logic die with one or more memory chips, another embodiment may place some or all of the logic on a separate chip horizontally on an interposer or packaged together in a multi-chip module (MCM). More than one logic chip may be included in the overall stack or system.</p><p id="p-0042" num="0041">In certain examples, the host interface <b>331</b> can directly access a portion of the buffers and cache array <b>334</b> or can directly access a separate instance of SRAM-type memory <b>337</b>. In such examples, the command decoder <b>335</b> is responsive to a command truth table that includes commands that extend beyond accessing and servicing the DRAM memory stack <b>320</b>. More specifically, the command decoder <b>335</b> can be responsive to commands for directly accessing SRAM-type storage located <b>337</b> on the logic die <b>306</b>. As used herein, SRAM-type memory includes memory that has less latency than the DRAM memory of the storage system. In such memory, information can be accessed with less latency than information stored at the stacked memory <b>320</b>. In certain examples, directly accessing an instance of, for example, SRAM <b>337</b> at the logic die <b>306</b>, information can be accessed with less latency than information available at the prefetch buffers or cache array <b>334</b> via the prefetch and cache logic <b>333</b>.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref> illustrate generally an example truth table extension of existing high bandwidth memory protocols to allow access to a second type of random-access memory within a stack of random-access memory dies. Such stacks can be used in storage devices including for example, a high bandwidth memory packages. In certain examples, systems adapted to operate with a memory stack including a mix of DRAM and faster SRAM can also work with conventional memory stack systems that include a homogeneous stack of memory die. The present inventor has recognized that unused states of existing interface protocols can be exploited to allow for a memory controller to specifically command and control the faster memory so as to improve overall storage system bandwidth. In certain examples, each channel can provide independent access to an area of memory of the memory stack. In certain examples, each channel can act independent of another channel. Each channel can include an independent command and data interface. In certain examples, each command and data interface can include a number signals or terminations including data (DQ[N<sub>D</sub>:0), column command/address (C[N<sub>C</sub>:0]) and row command/address (R[N<sub>R</sub>:0]) among others, where N<sub>D</sub>, N<sub>C </sub>and N<sub>R </sub>can be the maximum signal address of the respective group or bus of signals or terminations. In certain examples, specific operations of a stack of memory die can be initiated by properly setting the respective signals of the row command/address and column command/address while receiving a clock signal. Conventional operations of DRAM stacks use the first few signals (R[3:0] of the row command/address signals and the first few signal (C[3:0]) of the column command/address signals to initiate various operations of the stack of DRAM devices. In certain examples, the channels couple an interface of the memory controller with a device interface and device control circuitry of one or more of the memory die in the stack.</p><p id="p-0044" num="0043">In certain examples, where the stack of memory die includes one or more SRAM arrays, the memory controller can access the SRAM arrays using an extension of the conventional row and column command truth tables, such as the row and column truth tables provided in JEDEC Standard No. 235B. <figref idref="DRAWINGS">FIG. <b>4</b>A</figref> illustrates generally an example row command truth table extension. <figref idref="DRAWINGS">FIG. <b>4</b>B</figref> illustrates generally a column truth table extension. In certain examples, unlike conventional methods, the row and column command/address signals can work in tandem to initiate individual operations to access the one or more SRAM arrays within the stack of memory die.</p><p id="p-0045" num="0044">As an example, upon receiving a rising clock signal and additional signals on the row command/address where R0-R2 are logic &#x201c;high&#x201d; (H), &#x201c;low&#x201d; (L), H, respectively, the memory device controller of an SRAM device can recognize that the memory controller is requesting access to the SRAM device. The remaining row command/address signals, as well as the column command/address signals, can provide additional information to confirm the SRAM access request, provide address information, and specific command information such as whether the request is a read request, write request and whether or not the request is to use a buffer for the data. Referring to <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>, signals or terminations R3-R5 on the riding edge of the clock signal, and R0, R4 and R5 on the falling edge of the clock signal can provide a portion of the SRAM address (A10-A15) for the requested SRAM access. The &#x201c;D&#x201d; at R6 on the falling edge of the clock (CLK) stands for &#x201c;Do Not Care&#x201d; and indicates the logic level is not relevant for the illustrated example. Referring to <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, signals of the column command/address interface of the same channel, including C3-C7 on the rising edge of the clock, and C1 and C3-C6 on the falling edge of the clock signal can provide the rest of the SRAM address (A0-A9) for the requested SRAM access. On the rising edge of the clock signal, C0 and C1 can verify that the command address information provided to the memory controller is a SRAM access request when C0 is set &#x201c;low&#x201d; and C1 is set &#x201c;high&#x201d;. Also, on the rising edge, the state of C2 can indicate whether the access is a &#x201c;read&#x201d; access or a &#x201c;write&#x201d; access. SID0 and SID1 can indicate a stack identification of the device for the SRAM access command.</p><p id="p-0046" num="0045">Existing stacked DRAM devices can operate in a number of modes. Some modes have been added as the stacked DRAM technology has evolved. In certain examples, one such mode of operation is generally referred to a pseudo channel mode. Pseudo channel mode can divide a channel into two individual sub channels or pseudo channels. Both pseudo channels can operate semi-independently. The pseudo channels can share the channel's row command/address bus and column command/address bus, however, each pseudo channel can execute and decode commands individually. Command/address signal BA4 can be used to direct a SRAM access command to one of the two pseudo channels. In certain examples, the command information can include a parity bit (PAR) that can be used to insure the command information on ether the row command/address interface or the column command address interface did not get corrupted before being received by the memory controller.</p><p id="p-0047" num="0046">In certain examples, SRAM and DRAM access commands can be isolated from the external bus connecting the host with the host interface. In such examples, a memory access command does not provide read data to the external bus or receive write data from the external bus, but instead, uses an internal buffer, such as a prefetch buffer or similar register to capture data read from SRAM or Stacked DRAM and to provide data for an SRAM write or a stacked DRAM write command. In such examples, column command address signal C8, on a falling edge of the clock signal, can provide a binary state to indicate whether the internal buffer or the external bus is to be used as the data target of a memory access command. In certain examples, a column command/address bit, such as the C8 bit can be used, on the falling edge of the clock signal (CLK) to indicate to the memory controller or the command decoder of the host interface, the data location to use for the direct SRAM or stacked DRAM access command. In a first state, the C8 bit can indicate the memory controller can use the external data bus as the data location for the memory access command. In a second state, the C8 bit can indicate that the memory controller can use an internal buffer as the data location for the memory access command.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref> illustrate generally an example truth table extension of existing high bandwidth memory protocols to allow access to a second type of random-access memory within a stack of random-access memory die. Such stacks can be used in high bandwidth memory packages. The example of <figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref> allow for a larger capacity SRAM than can be addressed by the example of <figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref>.</p><p id="p-0049" num="0048">As an example, upon receiving a rising clock signal and additional signals on the row command/address where R0-R2 are logic &#x201c;high&#x201d; (H), &#x201c;low&#x201d; (L), H, respectively, the memory device controller of an SRAM device can recognize that the memory controller is requesting access to the SRAM device. The remaining row command/address signals, as well as the column command/address signals, can provide additional information to confirm the SRAM access request, provide address information, and specific command information such as whether the request is a read request, write request and whether or not the request is to use a buffer for the data. Referring to <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, signals or terminations R3-R5 on the riding edge of the clock signal, and R0, R4 and R5 on the falling edge of the clock signal can provide a portion of the SRAM address (A12-A20) for the requested SRAM access. Referring to <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, signals of the column command/address interface of the same channel, including C3-C7 on the rising edge of the clock, and C1 and C3-C6 on the falling edge of the clock signal can provide the rest of the SRAM address (A0-A11) for the requested SRAM access. On the rising edge of the clock signal, C0 and C1 can verify that the command address information provided to the memory controller is a SRAM access request when C0 is set &#x201c;low&#x201d; and C1 is set &#x201c;high&#x201d;. Also, on the rising edge, the state of C2 can indicate whether the access is a &#x201c;read&#x201d; access or a &#x201c;write&#x201d; access.</p><p id="p-0050" num="0049">Existing stacked DRAM die can operate in a number of modes. Some modes have been added as the stacked DRAM technology has evolved. In certain examples, one such mode of operation is generally referred to a pseudo channel mode. Pseudo channel mode can divide a channel into two individual sub channels or pseudo channels. Both pseudo channels can operate semi-independently. The pseudo channels can share the channel's row command/address bus and column command/address bus however, each pseudo channel can execute and decode commands individually. Command/address signal BA4 can be used to direct a SRAM access command to one of the two pseudo channels. In certain examples, the command information can include a parity bit (PAR) that can be used to insure the command information on ether the row command/address interface or the column command address interface did not get corrupted before being received by the memory controller.</p><p id="p-0051" num="0050">In certain examples, SRAM and DRAM access commands can be isolated from the external bus connecting the host with the host interface. In such examples, a memory access command does not provide read data to the external bus or receive write data from the external bus, but instead, uses an internal buffer, such as a prefetch buffer or similar register to capture data read from SRAM or Stacked DRAM and to provide data for an SRAM write or a stacked DRAM write command. In such examples, column command address signal C8, on a falling edge of the clock signal, can provide a binary state to indicate whether the internal buffer or the external bus is to be used as the data target of a memory access command. In certain examples, a column command/address bit, such as the C8 bit can be used, on the falling edge of the clock signal (CLK) to indicate to the memory controller or the command decoder of the host interface, the data location to use for the direct SRAM or stacked DRAM access command. In a first state, the C8 bit can indicate the memory controller can use the external data bus as the data location for the memory access command. In a second state, the C8 bit can indicate that the memory controller can use an internal buffer as the data location for the memory access command.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates generally a flowchart of an example method <b>600</b> for operating a storage system including a stack of first memory. In certain examples, the storage system can include a logic die, a memory controller, a first interface and a second interface. The logic die can receive and decode requests received from the host via the first interface. The logic die can initiate data access of the storage system via the memory controller of the stack of first memory, via a cache, via a second memory of the logic die, or combinations thereof. In some examples, the first memory can include DRAM die coupled to the memory controller via the second interface. In some examples, the second memory can be SRAM memory. The logic die may or may not include the memory controller. In certain examples, the memory controller can reside as a separate controller on each of the memory die of the stack of memory die. At <b>601</b>, first memory operations of the first memory can be initiated and executed using only a first command/address bus of the first interface to identify the first memory operations. In certain examples, the first command address bus can be the row command address bus associated with, for example, high bandwidth memory devices. In some examples, the first memory operations do not include read operations or write operation. In some examples, the first memory operations include pre-charge operations, refresh operations, power down operations or combinations thereof.</p><p id="p-0053" num="0052">At <b>603</b>, second memory operations of the first memory can be initiated and executed using only a second command/address bus of the first interface to identify the second memory access operation. In certain examples, the second command address bus can be the column command/address bus associated with, for example, high bandwidth memory devices. In some examples, the second memory operations include read operations or write operations. At <b>605</b>, a third memory access operation, of the second memory, such as an SRAM array of the logic die, can be initiated or executed using both the first command/address bus and the second command address bus to identify the third memory operation. In certain examples, the first memory can be a capacitive based random-access memory device such as a DRAM and the second memory can be SRAM. Having direct access to faster SRAM-type memory in a stacked DRAM storage system can provide opportunities for improved bandwidth of the storage system compared to conventional stacked DRAM memory or storage systems.</p><p id="p-0054" num="0053">In certain examples, in addition to providing new commands for directly accessing, for example, SRAM device within a storage system including a stack of DRAM memory devices, and without violating standards for implementing stacked DRAM high bandwidth storage systems, the present subject matter can also allow internal data movement between the DRAM memory and the SRAM memory using a buffer of the logic die and the extended command truth table, instead of requiring the information to be transferred via the host interface bus. Such internal transfer commands can be implemented by setting a bit of the second command/address bus to a particular state on a second transition of a clock of the second command/address bus. In some examples, the bit to allow movement between memory and a buffer can be the C8 bit of the column command/address bus associated with high bandwidth memory devices.</p><p id="p-0055" num="0054">In certain examples, modification of the command truth table for a stack of random access memory (RAM) as disclosed herein can allow direct access to a different type of RAM within a logic die of the stack, such as an SRAM memory in a stacked DRAM storage system and can provide specific commands to directly access and utilize the benefits of the SRAM. Such commands can allow for the ability of a memory controller to read or write the SRAM using the external data bus, read and write the SRAM using a buffer internal to the storage system, read and write the DRAM using the external bus, and read and write the DRAM using the buffer. In certain examples, commands that use the buffer as the data location do not affect the data bus of the channel (e.g., the external data bus) associated with the memory addressed in the command/operation and can allow the data bus to be used for other operations.</p><p id="p-0056" num="0055">In certain examples, a storage system according to the present subject matter can provide an increase in bandwidth for high bandwidth memory without passing the stress of the bandwidth increase to for example, the performance limited conventional memory of a conventional high bandwidth device. In some examples, the bandwidth increase can be achieved without modification of the pinout of the existing high bandwidth memory package.</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates generally an example method <b>700</b> for sorting and scheduling memory access commands to maximize use of a data bus of an example system. The system can include a host connected to a stacked memory package by a bus. The bus can include the data bus and one or more command busses. In certain examples, the host is configured to map the stack memory package. The host can also be aware that the stacked memory package includes more than one memory type. The host can also be aware of the latency of each memory type of the stacked memory package or the latency of commands for each memory type of the tacked memory package. <figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates one method <b>700</b> the host can employ to sort and schedule memory access commands to increase or maximize utilization of the data bus. The method <b>700</b> is shown via plots of a system clock (CLK), command transmission (CMD), and data bus (DATA) utilization over time. For illustration and understanding purposes, the commands are limited to read commands, but the present subject matter is not limited as such. Read commands directed to memory of a first type are denoted by an upper case &#x201c;R&#x201d; and read commands directed to memory of the second type are denoted by a lower case &#x201c;r&#x201d;. Arrows from the commands of the command transmission (CMD) to the data plot indicate when data associated with a corresponding command is transferred via the data bus between the host and the memory package. Data associated with memory of the first type and with a corresponding command are indicated by an upper case &#x201c;Q&#x201d;, and data associated with memory of the second type and with a corresponding command are indicated by a lower case &#x201c;q&#x201d;. At a first clock signal <b>701</b>, the host can transmit a first read command (R) for data in the first type of memory. As an example, the host can be aware that data requested from memory of the first type has a latency of 20 reference clock cycles. As such, if the host waits for the data requested via the first read command for the first memory type before doing anything else, the data bus can be idle for 20 clock cycles or longer. In certain examples, the host can sort pending commands and can schedule read commands (r) for memory of the second type to be sent while the first read command (R) is executing. In certain examples, the memory of the second type can have a much shorter latency than that of the first memory type. As an example, the latency of memory of the second type can be 1 reference clock cycle for a read command. As such, the host can schedule, and the memory package can execute, 17 read commands (r) for the memory of the second type while the first read command (R) executes. In doing so, over the course of transmission and execution of the first read command (R), the data bus can be utilized for 18 of the 20 slots available for data transmission. Such a system can result in 90% utilization of the data bus. Over a longer sample of time, the data buss utilization can approach 97% utilization. 97% utilization can be realized by repeatedly executing a block of 4 or more commands for memory of the second type and then a block of 16 or more commands for memory of the first type, where each block is the same type of command (e.g., read command or write command). Also, for a read operation, a latency ratio for a read command is about 85 for the memory of the first type to about 6 for memory of the second type. Thus, the read operations of the memory of the second type are about 14 times faster than the read operations of the memory of the first type.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a further example method of sorting and scheduling memory access commands to maximize utilization of a data bus of an interface between a host and the stacked memory package. The example of <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a system during a more active bi-directional flow of data between the host and the stacked memory package. The example of <figref idref="DRAWINGS">FIG. <b>8</b></figref> intermixes commands for memory of the first type with commands for memory of the second type just as shown in the example of <figref idref="DRAWINGS">FIG. <b>7</b></figref>. In addition, the example of <figref idref="DRAWINGS">FIG. <b>8</b></figref> also intermixes read command and write commands of both memory of the first type and memory of the second type. Read commands directed to memory of a first type are denoted by an upper case &#x201c;R&#x201d; and read commands directed to memory of the second type are denoted by a lower case &#x201c;r&#x201d;. Write commands directed to memory of a first type are denoted by an upper case &#x201c;W&#x201d; and read commands directed to memory of the second type are denoted by a lower case &#x201c;w&#x201d;. Data associated with memory of the first type and with a corresponding command (e.g., &#x201c;R&#x201d; or &#x201c;W&#x201d;) are indicated by an upper case &#x201c;Q&#x201d;, and data associated with memory of the second type and with a corresponding command (e.g., &#x201c;r&#x201d; or &#x201c;w&#x201d;) are indicated by a lower case &#x201c;q&#x201d;. In certain examples, the data bus may need some extra time to transition from providing read data to accepting write data and vice-versa. As illustrated, the data bus can be utilized for 25 of the 32 slots available for data transmission. Such a system can result in over 78% utilization of the data bus. In certain examples, where commands are sorted and scheduled in larger groups of commands of the same type and to the same memory type, the data bus utilization can be about 83% or more.</p><p id="p-0059" num="0058">It is understood that for <figref idref="DRAWINGS">FIGS. <b>7</b> and <b>8</b></figref>, the plot of the command transmission (CMD) and data bus utilization (DATA) represent general activity of a command bus and a data bus, each of which can include multiple conductors. For example, the command bus can include a row command bus and a column command bus each including multiple conductors. It is also understood that other commands beside read command and write commands can be sorted and scheduled, each other command having a latency known to the host, without departing from the scope of the present subject matter.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates generally a flowchart of an example method <b>900</b> of operating a host device according to various examples of the present subject matter. At <b>901</b>, the host can map volatile memory of a memory package. The memory package can include more than one memory type. For example, the memory package can include a stack of memory of a first type having a first general latency and memory of a second type having a second, shorter, general latency. In certain example, the memory of the first type can include DRAM and memory of the second type can include SRAM.</p><p id="p-0061" num="0060">At <b>903</b>, latency information for each type of memory can be maintained at the host. In certain example, the latency information can include latency information for more than one command associated with each type of memory of the memory package. At <b>905</b>, the host can sort and schedule pending memory command according to a latency associated with each type of memory of the memory package. In some examples, the host can also sort and schedule the pending commands based on the type of command. At <b>907</b>, the scheduling of the pending commands can include intermixing command for the different type of memories of the memory package to maintain a high utilization of the data bus connecting the host with the memory package. In certain examples, the latency of a first memory type can allow transmission and execution of one or more commands directed to a second memory type having a lower latency while a command of the first memory type is executing at the memory package. In certain examples, such sorting and scheduling based on memory-type latency of the memory package can result in high data bus utilization and better overall system performance. As discussed above and depending on the bi-directional activity level of the data bus of the system, data bus utilization can be greater than 78%. In some examples, where prolonged operation of the data bus in one direction is possible, data buss utilization can be as high as 97% or more.</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates generally a diagram of a system <b>1000</b> including a device <b>1005</b> that supports a storage system including stacked DRAM in accordance with aspects disclosed herein. Device <b>1005</b> may include components for bi-directional voice and data communications including components for transmitting and receiving communications, including memory controller <b>1015</b>, memory cells <b>1020</b>, basic input/output system (BIOS) component <b>1025</b>, processor <b>1030</b>, I/O controller <b>1035</b>, peripheral components <b>1040</b>, memory chip <b>1055</b>, system memory controller <b>1060</b>, encoder <b>1065</b>, decoder <b>1070</b>, and multiplexer <b>1075</b>. These components may be in electronic communication via one or more busses (e.g., bus <b>1010</b>). Bus <b>1010</b>, for example, may have a bus width of 16 data lines (&#x201c;DQ&#x201d; lines). Bus <b>1010</b> may be in electronic communication with <b>32</b> banks of memory cells.</p><p id="p-0063" num="0062">Memory controller <b>1015</b> or <b>1060</b> may operate one or more memory cells as described herein. Specifically, memory controller may be configured to support flexible multi-channel memory. In some cases, memory controller <b>1015</b> or <b>1060</b> may operate a row decoder, column decoder, or both, as described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Memory controller <b>1015</b> or <b>1060</b> may be in electronic communication with a host and may be configured to transfer data during each of a rising edge and a falling edge of a clock signal of the memory controller <b>1015</b> or <b>1060</b>.</p><p id="p-0064" num="0063">Memory cells <b>1020</b> may store information (i.e., in the form of a logical state) as described herein. Memory cells <b>1020</b> may represent, for example, memory cells <b>105</b> described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Memory cells <b>1020</b> may be in electronic communication with memory controller <b>1015</b> or <b>1060</b>, and memory cells <b>1020</b> and memory controller <b>1015</b> or <b>1060</b> may be located on a chip <b>1055</b>, which may be one or several planar memory devices as described herein. Chip <b>1055</b> may, for example, be managed by system memory controller <b>1015</b> or <b>1060</b>.</p><p id="p-0065" num="0064">Memory cells <b>1020</b> may represent a first array of memory cells with a plurality of regions coupled to a substrate. Each region of the plurality of regions may include a plurality of banks of memory cells and a plurality of channels traversing the first array of memory cells. At least one of the plurality of channels may be coupled to at least one region. Memory controller <b>1015</b> or <b>1060</b> may be configured to transfer data between the coupled region and the memory controller <b>1015</b> or <b>1060</b>.</p><p id="p-0066" num="0065">BIOS component <b>1025</b> be a software component that includes BIOS operated as firmware, which may initialize and run various hardware components. BIOS component <b>1025</b> may also manage data flow between a processor and various other components, e.g., peripheral components, input/output control component, etc. BIOS component <b>1025</b> may include a program or software stored in read only memory (ROM), flash memory, or any other non-volatile memory.</p><p id="p-0067" num="0066">Processor <b>1030</b> may include an intelligent hardware device, (e.g., a general-purpose processor, a digital signal processor (DSP), a central processing unit (CPU), a microcontroller, an application-specific integrated circuit (ASIC), a field programmable gate array (FPGA), a programmable logic device, a discrete gate or transistor logic component, a discrete hardware component, or any combination thereof). In some cases, processor <b>1030</b> may be configured to operate a memory array using a memory controller <b>1015</b> or <b>1060</b>. In other cases, a memory controller <b>1015</b> or <b>1060</b> may be integrated into processor <b>1030</b>. Processor <b>1030</b> may be configured to execute computer-readable instructions stored in a memory to perform various functions (e.g., functions or tasks supporting flexible multi-channel memory).</p><p id="p-0068" num="0067">I/O controller <b>1035</b> may manage input and output signals for device <b>1005</b>. I/O controller <b>1035</b> may also manage peripherals not integrated into device <b>1005</b>. In some cases, I/O controller <b>1035</b> may represent a physical connection or port to an external peripheral. I/O controller <b>1035</b> may utilize an operating system such as iOS&#xae;, ANDROID&#xae;, MS-DOS&#xae;, MS-WINDOWS&#xae;, OS/2&#xae;, UNIX&#xae;, LINUX&#xae;, or another known operating system. In other cases, I/O controller <b>1035</b> may represent or interact with a modem, a keyboard, a mouse, a touchscreen, or a similar device. In some cases, I/O controller <b>1035</b> may be implemented as part of a processor. A user may interact with device <b>1005</b> via I/O controller <b>1035</b> or via hardware components controlled by I/O controller <b>1035</b>.</p><p id="p-0069" num="0068">Peripheral components <b>1040</b> may include any input or output device, or an interface for such devices. Examples may include disk controllers, sound controller, graphics controller, Ethernet controller, modem, universal serial bus (USB) controller, a serial or parallel port, or peripheral card slots, such as peripheral component interconnect (PCI) or accelerated graphics port (AGP) slots.</p><p id="p-0070" num="0069">Input <b>1045</b> may represent a device or signal external to device <b>1005</b> that provides input to device <b>1005</b> or its components. This may include a user interface or an interface with or between other devices. In some cases, input <b>1045</b> may be managed by I/O controller <b>1035</b> and may interact with device <b>1005</b> via a peripheral component <b>1040</b>.</p><p id="p-0071" num="0070">Output <b>1050</b> may also represent a device or signal external to device <b>1005</b> configured to receive output from device <b>1005</b> or any of its components. Examples of output <b>1050</b> may include a graphics display, audio speakers, a printing device, another processor or printed circuit board, etc. In some cases, output <b>1050</b> may be a peripheral element that interfaces with device <b>1005</b> via peripheral component(s) <b>1040</b>. Output <b>1050</b> may be managed by I/O controller <b>1035</b>.</p><p id="p-0072" num="0071">System memory controller <b>1015</b> or <b>1060</b> may be in electronic communication with a first array of memory cells (e.g., memory cells <b>1020</b>). A host may be a component or device that controls or directs operations for a device of which memory controller <b>1015</b> or <b>1060</b> and corresponding memory array are a part. A host may be a component of a computer, mobile device, or the like. Or device <b>1005</b> may be referred to as a host. In some examples, system memory controller <b>1015</b> or <b>1060</b> is a GPU.</p><p id="p-0073" num="0072">Encoder <b>1065</b> may represent a device or signal external to device <b>1005</b> that provides performs error correction encoding on data to be stored to device <b>1005</b> or its components. Encoder <b>1065</b> may write the encoded data to the at least one selected memory via the at least one channel and may also encode data via error correction coding.</p><p id="p-0074" num="0073">Decoder <b>1070</b> may represent a device or signal external to device <b>1005</b> that sequences command signals and addressing signals to device <b>1005</b> or its components. In some examples, memory controller <b>1015</b> or <b>1060</b> may be co-located within decoder <b>1070</b>.</p><p id="p-0075" num="0074">Multiplexer <b>1075</b> may represent a device or signal external to device <b>1005</b> that multiplexes data to device <b>1005</b> or its components. Multiplexer <b>1075</b> may multiplex the data to be transmitted to the encoder <b>1065</b> and de-multiplex data received from the encoder <b>1065</b>. A multiplexer <b>1075</b> may be in electronic communication with the decoder <b>1070</b>. In some examples, multiplexer <b>1075</b> may be in electronic communication with a controller, such as system memory controller <b>1015</b> or <b>1060</b>.</p><p id="p-0076" num="0075">The components of device <b>1005</b> may include circuitry designed to carry out their functions. This may include various circuit elements, for example, conductive lines, transistors, capacitors, inductors, resistors, amplifiers, or other active or inactive elements, configured to carry out the functions described herein. Device <b>1005</b> may be a computer, a server, a laptop computer, a notebook computer, a tablet computer, a mobile phone, a wearable electronic device, a personal electronic device, or the like. Or device <b>1005</b> may be a portion or aspect of such a device. In some examples, device <b>1005</b> is an aspect of a computer with high reliability, mission critical, or low latency constraints or parameters, such as a vehicle (e.g., an autonomous automobile, airplane, a spacecraft, or the like). Device <b>1005</b> may be or include logic for artificial intelligence (AI), augmented reality (AR), or virtual reality (VR) applications.</p><p id="p-0077" num="0076">Information and signals described herein may be represented using any of a variety of different technologies and techniques. For example, data, instructions, commands, information, signals, bits, symbols, and chips that may be referenced throughout the above description may be represented by voltages, currents, electromagnetic waves, magnetic fields or particles, optical fields or particles, or any combination thereof. Some drawings may illustrate signals as a single signal; however, it will be understood by a person of ordinary skill in the art that the signal may represent a bus of signals, where the bus may have a variety of bit widths.</p><p id="p-0078" num="0077">As may be used herein, the term &#x201c;virtual ground&#x201d; refers to a node of an electrical circuit that is held at a voltage of approximately zero volts (0V) but that is not directly connected with ground. Accordingly, the voltage of a virtual ground may temporarily fluctuate and return to approximately 0V at steady state. A virtual ground may be implemented using various electronic circuit elements, such as a voltage divider consisting of operational amplifiers and resistors. Other implementations are also possible. &#x201c;Virtual grounding&#x201d; or &#x201c;virtually grounded&#x201d; means connected to approximately 0V.</p><p id="p-0079" num="0078">The may be used herein, the term &#x201c;electronic communication&#x201d; and &#x201c;coupled&#x201d; refer to a relationship between components that support electron flow between the components. This may include a direct connection between components or may include intermediate components. Components in electronic communication or coupled to one another may be actively exchanging electrons or signals (e.g., in an energized circuit) or may not be actively exchanging electrons or signals (e.g., in a de-energized circuit) but may be configured and operable to exchange electrons or signals upon a circuit being energized. By way of example, two components physically connected via a switch (e.g., a transistor) are in electronic communication or may be coupled regardless of the state of the switch (i.e., open or closed).</p><p id="p-0080" num="0079">The term &#x201c;layer&#x201d; used herein refers to a stratum or sheet of a geometrical structure. Each layer may have three dimensions (e.g., height, width, and depth) and may cover some or all of a surface. For example, a layer may be a three-dimensional structure where two dimensions are greater than a third, e.g., a thin-film. Layers may include different elements, components, and/or materials. In some cases, one layer may be composed of two or more sublayers. In some of the appended figures, two dimensions of a three-dimensional layer are depicted for purposes of illustration. Those skilled in the art will, however, recognize that the layers are three-dimensional in nature.</p><p id="p-0081" num="0080">As used herein, the term &#x201c;electrode&#x201d; may refer to an electrical conductor, and in some cases, may be employed as an electrical contact to a memory cell or other component of a memory array. An electrode may include a trace, wire, conductive line, conductive layer, or the like that provides a conductive path between elements or components of a memory array.</p><p id="p-0082" num="0081">The term &#x201c;isolated&#x201d; refers to a relationship between components in which electrons are not presently capable of flowing between them; components are isolated from each other if there is an open circuit between them. For example, two components physically connected by a switch may be isolated from each other when the switch is open.</p><p id="p-0083" num="0082">The devices discussed herein, including a memory array, may be formed on a semiconductor substrate, such as silicon, germanium, silicon-germanium alloy, gallium arsenide, gallium nitride, etc. In some cases, the substrate is a semiconductor wafer. In other cases, the substrate may be a silicon-on-insulator (SOI) substrate, such as silicon-on-glass (SOG) or silicon-on-sapphire (SOP), or epitaxial layers of semiconductor materials on another substrate. In some examples, the substrate may be an organic build up substrate formed from materials such as ABF or BT. The conductivity of the substrate, or sub-regions of the substrate, may be controlled through doping using various chemical species including, but not limited to, phosphorous, boron, or arsenic. Doping may be performed during the initial formation or growth of the substrate, by ion-implantation, or by any other doping means.</p><p id="p-0084" num="0083">A transistor or transistors discussed herein may represent a field-effect transistor (FET) and comprise a three terminal device including a source, drain, and gate. The terminals may be connected to other electronic elements through conductive materials, e.g., metals. The source and drain may be conductive and may comprise a heavily-doped, e.g., degenerate, semiconductor region. The source and drain may be separated by a lightly-doped semiconductor region or channel. If the channel is n-type (i.e., majority carriers are electrons), then the FET may be referred to as a n-type FET. If the channel is p-type (i.e., majority carriers are holes), then the FET may be referred to as a p-type FET. The channel may be capped by an insulating gate oxide. The channel conductivity may be controlled by applying a voltage to the gate. For example, applying a positive voltage or negative voltage to an n-type FET or a p-type FET, respectively, may result in the channel becoming conductive. A transistor may be &#x201c;on&#x201d; or &#x201c;activated&#x201d; when a voltage greater than or equal to the transistor's threshold voltage is applied to the transistor gate. The transistor may be &#x201c;off&#x201d; or &#x201c;deactivated&#x201d; when a voltage less than the transistor's threshold voltage is applied to the transistor gate.</p><p id="p-0085" num="0084">The various illustrative blocks and modules described in connection with the disclosure herein may be implemented or performed with a general-purpose processor, a DSP, an ASIC, an FPGA or other programmable logic device, discrete gate or transistor logic, discrete hardware components, or any combination thereof designed to perform the functions described herein. A general-purpose processor may be a microprocessor, but in the alternative, the processor may be any processor, controller, microcontroller, or state machine.</p><p id="p-0086" num="0085">A processor may also be implemented as a combination of computing devices (e.g., a combination of a DSP and a microprocessor, multiple microprocessors, one or more microprocessors in conjunction with a DSP core, or any other such configuration).</p><p id="p-0087" num="0086">In a first Example, Example 1, a system can include a storage device having a first type of volatile memory and a second type of volatile memory, and a host device coupled to the storage device, the host device configured to issue commands to the storage device to store and retrieve information of the system. The host device can include a memory map of the storage device and latency information associated with each command of the commands, and the host device can be configured to sort pending commands according to the latency information and to intermix commands for the first type of volatile memory and commands for the second type of volatile memory to provide a command schedule and to maintain an efficiency of a data interface between the host device and the storage device greater than 90% as measured from transmission of a first command for the first type of volatile memory to completion of the first command at the storage device. A latency of the first command can be greater than an accumulated latency of a multiple serially issued commands for the second type of volatile memory.</p><p id="p-0088" num="0087">In Example 2, the first type of volatile memory of Example 1 optionally is dynamic random-access memory (DRAM).</p><p id="p-0089" num="0088">In Example 3, the second type of volatile memory of any one or more of Examples 1-2 optionally is static random-access memory (SRAM).</p><p id="p-0090" num="0089">In Example 4, the storage device of any one or more of Examples 1-3 optionally includes a stack of memory devices of the first type of volatile memory, the stack configured to store the information of the system, and a logic die. The logic die can include an interface circuit configured to receive the commands from the host device using an external bus, the external bus comprising a first command bus, a second command bus, and a data bus, and a controller configured to control data exchanges between the interface circuit and the stack of memory devices wherein each respective data exchange passes data via the second type of volatile memory.</p><p id="p-0091" num="0090">In Example 5, the interface circuit of any one or more of Examples 1&#x2dc;4 optionally is configured to directly access the second type of volatile memory in response to a first command of the commands.</p><p id="p-0092" num="0091">In Example 6, the second type of volatile memory of any one or more of Examples 1-5 optionally is configured as an exclusive data target for exchanging data between the storage device and the host device.</p><p id="p-0093" num="0092">In Example 7, the external bus of any one or more of Examples 1-6 optionally includes a first command bus, a second command bus, and a data bus.</p><p id="p-0094" num="0093">In Example 8, the first command bus of any one or more of Examples 1-7 optionally is a row command bus.</p><p id="p-0095" num="0094">In Example 9, the second command bus of any one or more of Examples 1-8 optionally is a column command bus.</p><p id="p-0096" num="0095">In Example 10, a first three bits of the first command bus of any one or more of Examples 1-9 optionally are configured to provide a command identifier upon a first transition of a clock signal of the first command bus, and the controller of any one or more of Examples 1-9 optionally is configured to directly access the second type of volatile memory when the first three bits of the first command bus are HIGH, LOW, HIGH, respectively, upon the first transition of the clock signal of the first command bus.</p><p id="p-0097" num="0096">In Example 11, the interface circuit of any one or more of Examples 1-10 optionally is configured to read data of the second type of volatile memory in response to a first state of a bit of the second command bus at a first transition of a clock of the second command bus.</p><p id="p-0098" num="0097">In Example 12, the interface circuit of any one or more of Examples 1-11 optionally is configured to write data to the second type of volatile memory in response to a second state of the bit of the second command bus at the first transition of the clock of the second command bus.</p><p id="p-0099" num="0098">In Example 13, a method can include mapping volatile memory of a memory package at a host device, maintaining command latency information of a multiple volatile memory types of the memory package, sorting pending commands according to a command latency associated with each of the volatile memory types of the multiple volatile memory types, intermixing commands for a first type of volatile memory and commands for a second type of volatile memory to provide a command schedule and to maintain an efficiency of a data interface between the host device and the memory package greater than 90% as measured from transmission of a first command for the first type of volatile memory to completion of the first command at the memory package, and wherein a latency of a command for the first type of volatile memory is greater than an accumulated latency of a multiple serially issued commands for the second type of volatile memory.</p><p id="p-0100" num="0099">In Example 14, the method of any one or more of Examples 1-13 optionally includes transmitting a first command of the command schedule to access the first type of volatile memory from the host device to a memory package including the volatile memory and executing the first command at the memory.</p><p id="p-0101" num="0100">In Example 15, the method of any one or more of Examples 1-2 optionally includes transmitting a multiple second commands of the command schedule to access the second type of volatile memory from the host device to the memory package and executing the multiple second commands at the memory package during the latency of the first command.</p><p id="p-0102" num="0101">In Example 16, the volatile memory of the memory package of any one or more of Examples 1-15 optionally includes a stack of memory devices of the first type of volatile memory.</p><p id="p-0103" num="0102">In Example 17, the volatile memory of any one or more of Examples 1-16 optionally includes the second type of volatile memory.</p><p id="p-0104" num="0103">In Example 18, the first type of volatile memory of any one or more of Examples 1-17 optionally is dynamic random-access memory (DRAM).</p><p id="p-0105" num="0104">In Example 19, the second type of volatile memory of any one or more of Examples 1-18 optionally is static random-access memory (SRAM).</p><p id="p-0106" num="0105">In Example 20, the executing the first command, and the executing the multiple second commands of any one or more of Examples 1-19 optionally includes routing data associated with each respective command through the second type of volatile memory.</p><p id="p-0107" num="0106">Example 21 can include or use, or can optionally be combined with any portion or combination of any portions of any one or more of Examples 1 through 20 to include or use, subject matter that can include means for performing any one or more of the functions of Examples 1 through 20, or a machine-readable medium including instructions that, when performed by a machine, cause the machine to perform any one or more of the functions of Examples 1 through 20.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system comprising:<claim-text>a storage device including a first memory device of a first type of volatile memory and a second memory device of a second type of volatile memory;</claim-text><claim-text>a host device coupled to the storage device, the host device configured to issue commands to the storage device to store and retrieve information of the system; and</claim-text><claim-text>a logic die comprising:<claim-text>an interface circuit configured to receive the commands from the host device using an external bus; and</claim-text><claim-text>a controller configured to control data communication between the interface circuit and the first memory device, wherein the data passes to the host device via the second memory device.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the interface circuit is configured to directly access the second memory device in response to a first command of the commands from the host device.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the second memory device is configured as an exclusive data target for exchanging data between the storage device and the host device.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first memory device comprises a dynamic random access memory (DRAM) device, and wherein the second memory device comprises a static random access memory (SRAM) device, and wherein the first and second memory devices have different latency characteristics.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the external bus comprises a data bus, a row command bus, and a column command bus.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein a first three bits of the row command bus are configured to provide a command identifier upon a first transition of a clock signal of the row command bus, and wherein the controller is configured to directly access the second memory device when the first three bits of the row command bus are HIGH, LOW, HIGH, respectively, upon the first transition of the clock signal of the row command bus.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the host device includes a memory map of the storage device and latency information associated with each command of the commands.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the host device is configured to sort pending commands according to the latency information and to use commands for the first type of volatile memory and commands for the second type of volatile memory to provide a high-efficiency command schedule.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the host device is configured to sort pending commands according to the latency information to provide a command schedule, and wherein the commands include read and write commands for each of the first and second memory devices.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A method comprising:<claim-text>mapping volatile memory of a memory package at a host device;</claim-text><claim-text>maintaining command latency information of multiple volatile memory types of the memory package;</claim-text><claim-text>sorting pending commands according to a command latency associated with each of the volatile memory types of the multiple volatile memory types; and</claim-text><claim-text>determining a command schedule for a data interface between the host device and the memory package using commands for a first type of volatile memory and commands for a second type of volatile memory;</claim-text><claim-text>wherein a latency of a command for the first type of volatile memory is greater than a combined latency of multiple, serially-issued commands for the second type of volatile memory.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, comprising:<claim-text>transmitting, from the host device to the memory package, a first command of the command schedule to access the first type of volatile memory, and executing the first command at the memory;</claim-text><claim-text>transmitting, from the host device to the memory package, multiple second commands of the command schedule to access the second type of volatile memory; and</claim-text><claim-text>executing the multiple second commands at the memory package during the latency of the first command.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein executing the first command and executing the multiple second commands includes routing data associated with each of the commands through the second type of volatile memory.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the first type of volatile memory is dynamic random-access memory (DRAM), and wherein the second type of volatile memory is static random-access memory (SRAM).</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein determining the command schedule for the data interface includes intermixing read and/or write commands for each of the first and second types of volatile memory.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A stacked memory device comprising:<claim-text>a first memory device of a first type of volatile memory;</claim-text><claim-text>a second memory device of a second type of volatile memory; and</claim-text><claim-text>a logic die comprising:<claim-text>an interface circuit configured to receive a commands from a host device using an external bus, wherein the interface circuit is configured to directly access the second memory device; and</claim-text><claim-text>a controller configured to control data communication between the interface circuit and the first memory device, wherein data transactions between the first memory device and the host device are communicated via the second memory device.</claim-text></claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The stacked memory device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the first memory device comprises a dynamic random access memory (DRAM) device, and wherein the second memory device comprises a static random access memory (SRAM) device, and wherein the first and second memory devices have different latency characteristics.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The stacked memory device of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the second memory device comprises a prefetch buffer configured to store information from the first memory device.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The stacked memory device of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the controller comprises a command decoder configured to route commands from the external bus to at least one of the prefetch buffer, the first memory device, and the second memory device.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The stacked memory device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the external bus comprises a data bus, a row command bus, and a column command bus.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The stacked memory device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the second memory device is configured to be an exclusive data target for exchanging data between the stacked memory device and the host device.</claim-text></claim></claims></us-patent-application>
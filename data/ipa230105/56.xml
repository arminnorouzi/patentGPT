<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000057A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221220" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000057</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17837494</doc-number><date>20220610</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2021-0087867</doc-number><date>20210705</date></priority-claim><priority-claim sequence="02" kind="national"><country>KR</country><doc-number>10-2121-0157695</doc-number><date>20211116</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>01</class><subclass>K</subclass><main-group>29</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>01</class><subclass>K</subclass><main-group>27</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>30</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>30</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>01</class><subclass>K</subclass><main-group>29</main-group><subgroup>005</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>01</class><subclass>K</subclass><main-group>27</main-group><subgroup>009</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>30</main-group><subgroup>0631</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>30</main-group><subgroup>0251</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e79">METHOD, SYSTEM, AND COMPUTER PROGRAM PRODUCT FOR MONITORING STATE OF ANIMAL AND PROVIDING SOLUTION</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>DD Cares Co., Ltd</orgname><address><city>Seongnam-si</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Sang Hyun</first-name><address><city>Gyeonggi-do</city><country>KR</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">This application relates to a non-transitory computer-readable storage medium. In one aspect, the computer-readable storage medium includes instructions configured to cause a processor for calculating an appropriate feed amount based on animal characteristic information to receive one or more pieces of first animal characteristic information. The one or more pieces of first animal characteristic information may include at least piece of activity level information of a first animal. The instructions may further cause the processor to calculate a maintenance energy requirement (MER) of the first animal, based on the received one or more pieces of first animal characteristic information and an MER calculation model.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="147.66mm" wi="150.96mm" file="US20230000057A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="96.60mm" wi="104.31mm" file="US20230000057A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="106.68mm" wi="142.83mm" file="US20230000057A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="155.02mm" wi="146.13mm" file="US20230000057A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="163.32mm" wi="96.44mm" file="US20230000057A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="167.39mm" wi="87.46mm" file="US20230000057A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="167.39mm" wi="84.92mm" file="US20230000057A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="167.39mm" wi="84.92mm" file="US20230000057A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="167.39mm" wi="74.17mm" file="US20230000057A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="167.39mm" wi="84.84mm" file="US20230000057A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="101.60mm" wi="105.07mm" file="US20230000057A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="80.43mm" wi="65.28mm" file="US20230000057A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="82.72mm" wi="88.90mm" file="US20230000057A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="102.53mm" wi="106.51mm" file="US20230000057A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="111.42mm" wi="87.71mm" file="US20230000057A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="152.48mm" wi="151.64mm" file="US20230000057A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="175.68mm" wi="82.55mm" orientation="landscape" file="US20230000057A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="162.81mm" wi="90.68mm" file="US20230000057A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="203.12mm" wi="138.09mm" orientation="landscape" file="US20230000057A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="166.37mm" wi="152.99mm" file="US20230000057A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="50.55mm" wi="156.80mm" file="US20230000057A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="145.54mm" wi="150.54mm" file="US20230000057A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="212.60mm" wi="142.66mm" orientation="landscape" file="US20230000057A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00023" num="00023"><img id="EMI-D00023" he="90.51mm" wi="124.04mm" file="US20230000057A1-20230105-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00024" num="00024"><img id="EMI-D00024" he="89.66mm" wi="134.70mm" file="US20230000057A1-20230105-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00025" num="00025"><img id="EMI-D00025" he="198.71mm" wi="156.46mm" orientation="landscape" file="US20230000057A1-20230105-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00026" num="00026"><img id="EMI-D00026" he="198.54mm" wi="104.73mm" orientation="landscape" file="US20230000057A1-20230105-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00027" num="00027"><img id="EMI-D00027" he="136.57mm" wi="125.48mm" file="US20230000057A1-20230105-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00028" num="00028"><img id="EMI-D00028" he="136.06mm" wi="125.31mm" file="US20230000057A1-20230105-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00029" num="00029"><img id="EMI-D00029" he="135.81mm" wi="125.56mm" file="US20230000057A1-20230105-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00030" num="00030"><img id="EMI-D00030" he="143.76mm" wi="150.03mm" file="US20230000057A1-20230105-D00030.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00031" num="00031"><img id="EMI-D00031" he="222.25mm" wi="148.25mm" orientation="landscape" file="US20230000057A1-20230105-D00031.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00032" num="00032"><img id="EMI-D00032" he="200.83mm" wi="138.68mm" orientation="landscape" file="US20230000057A1-20230105-D00032.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00033" num="00033"><img id="EMI-D00033" he="95.17mm" wi="140.38mm" file="US20230000057A1-20230105-D00033.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00034" num="00034"><img id="EMI-D00034" he="85.43mm" wi="72.39mm" file="US20230000057A1-20230105-D00034.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is based on and claims priority under 35 U.S.C. &#xa7; 119 to Korean Patent Application No. 10-2021-0087867, filed on Jul. 5, 2021 and Korean Patent Application No. 10-2021-0157695, filed on Nov. 16, 2021, in the Korean Intellectual Property Office, the disclosure of each of which is incorporated by reference herein in its entirety.</p><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Technical Field</heading><p id="p-0003" num="0002">The disclosure relates to a method, system, and computer program product for monitoring a state of an animal and providing a solution.</p><heading id="h-0004" level="1">Description of Related Technology</heading><p id="p-0004" num="0003">The number of people who perceive animals, especially dogs and cats, as animals and manage the animals is continuously increasing. Recently, a large number of animals suffer from obesity, arthritis, separation anxiety, skin diseases, and allergies, but due to limitations on communication with animals, it is difficult to detect health problems during initial symptoms, and thus health may deteriorate and treatment costs may increase.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0005" num="0004">Provided are a method, system, and computer program product for monitoring a state of an animal and providing a solution. Additional aspects will be set forth in part in the description which follows and, in part, will be apparent from the description, or may be learned by practice of the presented embodiments of the disclosure.</p><p id="p-0006" num="0005">According to one aspect of the disclosure, a system for monitoring a state of an animal and providing a solution, includes: a wearable device for collecting real-time state information of the animal by being worn on a part of a body of the animal; and a user terminal for communicating with the wearable device, wherein the user terminal receives the real-time state information from the wearable device, determines a health abnormality type of the animal based on the real-time state information, and provides a solution according to the health abnormality type.</p><p id="p-0007" num="0006">The system may provide, as the solution, at least one task helpful to health of the animal, based on the health abnormality type.</p><p id="p-0008" num="0007">The user terminal may provide, to a user, a reward according to a performance achievement of the at least one task.</p><p id="p-0009" num="0008">The user terminal may receive new real-time state information from the wearable device after the at least one task has been performed, and update the at least one task, based on the performance achievement of the at least one task and the new real-time state information.</p><p id="p-0010" num="0009">The user terminal may provide, as the solution, feed information helpful to the health of the animal, based on the health abnormality type.</p><p id="p-0011" num="0010">The user terminal may obtain basic information of the animal by receiving an input from the user, and determine the health abnormality type of the animal based on the real-time state information and the basic information.</p><p id="p-0012" num="0011">The user terminal may provide, as the solution, the at least one task helpful to the health of the animal, based on the health abnormality type and the basic information.</p><p id="p-0013" num="0012">The user terminal may verify the basic information by comparing the real-time state information with the basic information.</p><p id="p-0014" num="0013">According to another aspect of the disclosure, a computer program product for monitoring a state of an animal and providing a solution, includes one or more computer-readable recording media storing a program for: receiving real-time state information of the animal from a wearable device worn on a part of a body of the animal; determining a health abnormality type of the animal based on the real-time state information; and providing a solution according to the health abnormality type.</p><p id="p-0015" num="0014">According to another aspect of the disclosure, a method of monitoring a state of an animal and providing a solution, includes: receiving real-time state information of the animal from a wearable device worn on a part of a body of the animal; determining a health abnormality type of the animal based on the real-time state information; and providing the solution according to the health abnormality type.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0016" num="0015">The above and other aspects, features, and advantages of certain embodiments of the disclosure will be more apparent from the following description taken in conjunction with the accompanying drawings.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a system diagram including a user terminal and a wearable device, according to an embodiment.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram showing an example in which a wearable device transmits real-time state information of an animal to a user terminal, according to an embodiment.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram for describing an example of determining a health abnormality type of an animal, based on real-time state information of the animal, according to an embodiment.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram for describing an example of providing a task as a solution, according to an embodiment.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram for describing an example of providing feed information as a solution, according to an embodiment.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIGS. <b>6</b>A and <b>6</b>B</figref> are diagrams for describing an example of updating a task in consideration of a task performance achievement, according to an embodiment.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref> are diagrams for describing an example of providing a task in consideration of basic information of an animal, according to an embodiment.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart of a method of monitoring a state of an animal and providing a solution, according to an embodiment.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram of an external server according to an embodiment.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram of an example of a product recommendation apparatus, according to an embodiment.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart of an example of a method of recommending a product, based on a state of an animal, according to an embodiment.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram for describing an example in which basic information and illness information of an animal are stored in a memory, according to an embodiment.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram for describing an example in which real-time state information of an animal is output, according to an embodiment.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram for describing an example in which a processor estimates a current state of an animal, according to an embodiment.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram for describing an example in which a processor recommends a product, according to an embodiment.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram for describing an example in which a system recommends a product, according to an embodiment.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flowchart of an example of calculating a recommended feed amount for an animal, based on animal characteristic information, and transmitting a feed repurchase notification to a user, according to an embodiment.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a diagram showing an example of a maintenance energy requirement (MER) calculation model, according to an embodiment.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a diagram showing an example of a conversion criterion for converting animal characteristic information into activity level information, according to an embodiment.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a diagram showing an example of data for generating state information of an animal.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIGS. <b>21</b> and <b>22</b></figref> respectively illustrate a wearable device for managing health of an animal and a method of managing health of an animal by using the wearable device, according to an embodiment of the disclosure.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>23</b></figref> is a diagram showing an example of processes for obtaining activity data of an animal and estimating a specific behavior of the animal from the activity data, according to an embodiment of the disclosure.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIGS. <b>24</b>A through <b>24</b>D</figref> illustrate examples of estimating a specific behavior of an animal, based on activity data of the animal, according to an embodiment of the disclosure.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>25</b></figref> illustrates an example of a frequency with respect to a specific behavior estimated for an animal, according to an embodiment of the disclosure.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>26</b></figref> is a diagram for describing an example of detecting a health abnormality sign of an animal by using a deep learning inference model, according to an embodiment of the disclosure.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>27</b></figref> is a diagram for describing an example of estimating a risk of obesity of an animal by using a deep learning inference model, according to an embodiment of the disclosure.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>28</b></figref> is a table for describing a battery management scenario of a wearable device, according to an embodiment of the disclosure.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>29</b></figref> illustrates an example of a wearable device, according to an embodiment of the disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0045" num="0044">There are various methods for managing animals, and one of general animal management methods only provides a simple management function, such as simply providing an image or putting food in a container, for animals left alone after owners go out. Accordingly, there is a need for a technology that can help the owners to manage health of the animals and prevent illnesses by identifying, in real-time, health conditions of the animals, beyond the general animal management methods.</p><p id="p-0046" num="0045">Reference will now be made in detail to embodiments, examples of which are illustrated in the accompanying drawings, wherein like reference numerals refer to like elements throughout. In this regard, the present embodiments may have different forms and should not be construed as being limited to the descriptions set forth herein. Accordingly, the embodiments are merely described below, by referring to the figures, to explain aspects. As used herein, the term &#x201c;and/or&#x201d; includes any and all combinations of one or more of the associated listed items. Expressions such as &#x201c;at least one of,&#x201d; when preceding a list of elements, modify the entire list of elements and do not modify the individual elements of the list.</p><p id="p-0047" num="0046">Hereinafter, embodiments of the disclosure will be described in detail with reference to the accompanying drawings such that one of ordinary skill in the art may easily implement the disclosure. However, the disclosure may be implemented in various different forms and is not limited to embodiments of the disclosure described herein. Also, in the drawings, parts irrelevant to the description are omitted in order to clearly describe the disclosure, and like reference numerals designate like elements throughout the specification.</p><p id="p-0048" num="0047">Throughout the specification, when a part is &#x201c;connected&#x201d; to another part, the part may not only be &#x201c;directly connected&#x201d; to the other part, but may also be &#x201c;electrically connected&#x201d; to the other part with another element in between. In addition, when a part &#x201c;includes&#x201d; a certain element, the part may further include another element instead of excluding the other element, unless otherwise stated.</p><p id="p-0049" num="0048">Hereinafter, the disclosure will be described in detail with reference to accompanying drawings.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a system diagram including a user terminal <b>1000</b> and a wearable device <b>2000</b>, according to an embodiment.</p><p id="p-0051" num="0050">A system according to an embodiment may include the user terminal <b>1000</b> and the wearable device <b>2000</b>. In addition, the system may further include an external server <b>3000</b>.</p><p id="p-0052" num="0051">The user terminal <b>1000</b>, the wearable device <b>2000</b>, and the external server <b>3000</b> may perform communication by using a network. For example, the network may include a local area network (LAN), a wide area network (WAN), a value-added network (VAN), a mobile radio communication network, a satellite communication network, or a combination thereof, is a data communication network in a comprehensive sense that enables network configuration entities shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> to communicate smoothly with each other, and may include a wired Internet, a wireless Internet, and a mobile wireless communication network. Wireless communication may include, for example, wireless LAN (Wi-Fi), Bluetooth, Bluetooth low energy, Zigbee, Wi-Fi direct (WFD), ultra-wideband (UWB), infrared data association (IrDA), or near field communication (NFC), but is not limited thereto.</p><p id="p-0053" num="0052">The user terminal <b>1000</b> may include a smartphone, a tablet personal computer (PC), a PC, a smart television (TV), a mobile phone, a personal digital assistant (PDA), a laptop computer, a media player, a micro server, a global positioning system (GPS) device, an electronic book terminal, a digital broadcasting terminal, a navigation device, a kiosk, an MP3 player, a digital camera, a home appliance, a device on which a camera is mounted, or another mobile or non-mobile computing device, but is not limited thereto.</p><p id="p-0054" num="0053">The wearable device <b>2000</b> may be worn on a part of a body of an animal to collect real-time state information of the animal. The wearable device <b>2000</b> may include a plurality of sensors. For example, the wearable device <b>2000</b> may include at least one of an electromyography (EMG) sensor, an electrodermal activity sensor, a skin temperature measurer, a blood volume pulse measurer, an electrocardiogram (ECG) sensor, a respiration sensor, a blood pressure measurer, and a heart rate measurer. In addition, the wearable device <b>2000</b> may include a 3-axis accelerometer, a 6-axis gyroscope and accelerometer, or a 9-axis gyroscope, accelerometer, and geomagnetic sensor.</p><p id="p-0055" num="0054">The external server <b>3000</b> may communicate with the user terminal <b>1000</b> and the wearable device <b>2000</b> through the network.</p><p id="p-0056" num="0055">According to an embodiment, referring to a first arrow, the wearable device <b>2000</b> may transmit the real-time state information of the animal to the user terminal <b>1000</b>. The wearable device <b>2000</b> may transmit the real-time state information of the animal to the user terminal <b>1000</b> through a communication method, such as wireless LAN (Wi-Fi), Bluetooth, or Bluetooth low energy. Referring to a second arrow, the user terminal <b>1000</b> may request the external server <b>3000</b> to analyze the real-time state information while transmitting the same. The external server <b>3000</b> may analyze the real-time state information to determine a health abnormality type of the animal, and may determine a solution according to the health abnormality type. Referring to a third arrow, the external server <b>3000</b> may transmit the health abnormality type of the animal and the solution to the user terminal <b>1000</b>, and the user terminal <b>1000</b> may provide the health abnormality type of the animal and the solution to a user. The user terminal <b>1000</b> and the external server <b>3000</b> may exchange data through the wired Internet, the wireless Internet, or the mobile wireless communication network.</p><p id="p-0057" num="0056">According to another embodiment, referring to the first arrow, the real-time state information of the animal obtained by the wearable device <b>2000</b> may be transmitted to the user terminal <b>1000</b>. In this case, instead of transmitting the real-time state information to the external server <b>3000</b>, the user terminal <b>1000</b> may self-analyze the real-time state information to determine the health abnormality type of the animal, and provide the solution according to the health abnormality type to the user.</p><p id="p-0058" num="0057">According to another embodiment, although not shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the wearable device <b>2000</b> may directly transmit the real-time state information to the external server <b>3000</b> without going through the user terminal <b>1000</b>, and request the external server <b>3000</b> to analyze the same. In this case, the external server <b>3000</b> may transmit the health abnormality type of the animal and the solution to the user terminal <b>1000</b>, and the user terminal <b>1000</b> may provide the health abnormality type of the animal and the solution to the user. The user terminal <b>1000</b>, the wearable device <b>2000</b>, and the external server <b>3000</b> may exchange data through the wired Internet, the wireless Internet, or the mobile wireless communication network.</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram showing an example in which the wearable device <b>2000</b> transmits real-time state information of an animal <b>200</b> to the user terminal <b>1000</b>, according to an embodiment.</p><p id="p-0060" num="0059">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the wearable device <b>2000</b> may be worn on a part of a body of the animal <b>200</b> to collect the real-time state information of the animal <b>200</b>.</p><p id="p-0061" num="0060">According to an embodiment, the real-time state information may be information indicating whether the animal <b>200</b> is currently in an activity state or in a sleep state. In detail, the real-time state information may be information indicating whether the animal <b>200</b> is in a play state, an activity state, a rest state, or a sleep state. However, the real-time state information is not limited thereto.</p><p id="p-0062" num="0061">The wearable device <b>2000</b> may include at least one sensor, and the wearable device <b>2000</b> may collect the real-time state information of the animal <b>200</b>, based on a sensing value of the at least one sensor.</p><p id="p-0063" num="0062">For example, the wearable device <b>2000</b> may include at least one of an EMG sensor, an electrodermal activity sensor, a skin temperature measurer, a blood volume pulse measurer, an ECG sensor, a respiration sensor, a blood pressure measurer, a heart rate measurer, a 3-axis accelerometer, a 6-axis gyroscope and accelerometer, and a 9-axis gyroscope, accelerometer, and geomagnetic sensor. The EMG sensor denotes a sensor that detects action potential of a muscle. The electrodermal activity sensor denotes a sensor that measures conductivity of a skin. The skin temperature measurer may include a sensor for detecting a temperature of a skin surface. The blood volume pulse measurer denotes a device that measures the amount of blood flowing in a blood vessel. The ECG sensor denotes a sensor that detects an electric potential related to a heartbeat on a body surface. The respiration sensor denotes a sensor that measures the number and speed of respirations. The heart rate measurer denotes a device that measures the number of times the heart beats per unit time. The 3-axis accelerometer measures acceleration, the 6-axis gyroscope and accelerometer measures acceleration and angular velocity, and the 9-axis gyroscope, accelerometer, and geomagnetic sensor measures acceleration, angular velocity, and geomagnetism.</p><p id="p-0064" num="0063">The user terminal <b>1000</b> may receive the real-time state information of the animal <b>200</b> from the wearable device <b>2000</b>.</p><p id="p-0065" num="0064">The user terminal <b>1000</b> may determine a health abnormality type of the animal <b>200</b>, based on the real-time state information. For example, the health abnormality type of the animal <b>200</b> may include arthritis, skin disease, allergy, and separation anxiety, but is not limited thereto.</p><p id="p-0066" num="0065">Also, the user terminal <b>1000</b> may provide a solution according to the health abnormality type of the animal <b>200</b>. The solution may be at least one task helpful to the health of the animal <b>200</b>. Alternatively, the solution may be feed information helpful to the health of the animal <b>200</b>.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram for describing an example of determining a health abnormality type of an animal, based on real-time state information of the animal, according to an embodiment.</p><p id="p-0068" num="0067">The user terminal <b>1000</b> may receive the real-time state information of the animal from a wearable device, and determine the health abnormality type of the animal, based on the real-time state information of the animal.</p><p id="p-0069" num="0068">Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the user terminal <b>1000</b> may receive the real-time state information of the animal from the wearable device, accumulate the received real-time state information on daily, weekly, monthly, and yearly bases, and provide the same to a user.</p><p id="p-0070" num="0069">According to an embodiment, the user terminal <b>1000</b> may provide the user with a total of accumulated time of each of a play state, an activity state, and a rest state among the real-time state information. Also, the user terminal <b>1000</b> may accumulate a time of a sleep state among the real-time state information, and provide the same to the user.</p><p id="p-0071" num="0070">The user terminal <b>1000</b> may not only provide the user with the real-time state information, but also determine the health abnormality type of the animal, based on the real-time state information.</p><p id="p-0072" num="0071">For example, when, as a result of analyzing activity information <b>310</b> among the real-time state information, a time corresponding to the play state of the animal is equal to or greater than a threshold time, the user terminal <b>1000</b> may determine the health abnormality type of the animal as separation anxiety.</p><p id="p-0073" num="0072">Alternatively, when, as the result of analyzing the activity information <b>310</b>, a time corresponding to the rest state of the animal is equal to or greater than a threshold time, the user terminal <b>1000</b> may determine the health abnormality type of the animal as arthritis.</p><p id="p-0074" num="0073">However, the user terminal <b>1000</b> may determine the health abnormality type of the animal, taking into account various sensing values received from the wearable device, in addition to the times corresponding to the play state, activity state, rest state, and sleep state of the animal. For example, the user terminal <b>1000</b> may determine the health abnormality type of the animal, considering sensing values received from an EMG sensor, an electrodermal activity sensor, a skin temperature measurer, a blood pressure measurer, an accelerometer, and the like of the wearable device.</p><p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram for describing an example of providing a task <b>410</b> as a solution, according to an embodiment.</p><p id="p-0076" num="0075">The user terminal <b>1000</b> may provide, as a solution, at least one task <b>410</b> helpful to health of an animal, based on a health abnormality type of the animal. The task <b>410</b> provided by the user terminal <b>1000</b> may include the number of walks, a walking time, a sleeping time, or the like.</p><p id="p-0077" num="0076">Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the user terminal <b>1000</b> may provide wearing a device, a walking time, and a sleeping time as the tasks <b>410</b>. In detail, when the health abnormality type of the animal is obesity, the user terminal <b>1000</b> may provide a minimum walking time as the task <b>410</b>. Alternatively, when the health abnormality type of the animal is arthritis, the user terminal <b>1000</b> may provide a resting time as the task <b>410</b>.</p><p id="p-0078" num="0077">Also, the user terminal <b>1000</b> may provide a reward <b>430</b> to a user according to a performance achievement of the at least one task <b>410</b>. For example, among today's tasks, 23 points may be provided as a reward if a &#x201c;wear device&#x201d; task is performed, 23 points may be provided as a reward if a &#x201c;walk 17 minutes&#x201d; task is performed, and 50 points may be provided as a reward if a &#x201c;sleep 60 minutes&#x201d; task is performed.</p><p id="p-0079" num="0078">According to an embodiment, the reward <b>430</b> may be provided differentially. The reward <b>430</b> may be provided differentially depending on a task performance rate. When 50 points are provided as a reward if the &#x201c;sleep 60 minutes&#x201d; task is completed, 25 points may be provided as a reward if only &#x201c;sleep 30 minutes&#x201d; is achieved. Also, the reward <b>430</b> may be provided differentially according to a performance rate for each task <b>410</b>. Depending on content of the tasks <b>410</b>, certain tasks <b>410</b> may have high performance rates while other tasks <b>410</b> may have low performance rates. All tasks <b>410</b> are helpful to health of the animal, and thus, to increase a performance rate of the task <b>410</b> with a low performance rate, a higher reward <b>430</b> may be provided when the task <b>410</b> with the low performance rate is performed.</p><p id="p-0080" num="0079">Meanwhile, the user may use the reward <b>430</b> in various ways. According to an embodiment, the user may redeem reward points in cash. According to another embodiment, the user may use the reward points to purchase a feed product provided as a solution. According to another embodiment, the user may use the reward points to take out an insurance product provided as a solution. A case in which a feed product or an insurance product is provided as a solution will be described with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram for describing an example of providing feed information <b>510</b> as a solution, according to an embodiment.</p><p id="p-0082" num="0081">The user terminal <b>1000</b> may provide the feed information <b>510</b> helpful to health of an animal as a solution, based on health abnormality type of the animal. The feed information <b>510</b> provided by the user terminal <b>1000</b> may include necessary nutrient information, feed product information, and the like.</p><p id="p-0083" num="0082">In detail, when the health abnormality type of the animal is obesity, the user terminal <b>1000</b> may provide, as the feed information <b>510</b>, nutrient information for a diet or a diet feed product. Alternatively, when the health abnormality type of the animal is arthritis, the user terminal <b>1000</b> may provide, as the feed information <b>510</b>, nutrient information for strengthening bones/joints or a feed product for improving arthritis.</p><p id="p-0084" num="0083">According to an embodiment, when a user purchases a feed product provided as the feed information <b>510</b>, the user terminal <b>1000</b> may provide a reward.</p><p id="p-0085" num="0084">According to an embodiment, the user may purchase the feed product provided as the feed information <b>510</b> by using the reward. Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the user terminal <b>1000</b> may provide the reward <b>430</b> to the user according to a performance achievement of the at least one task <b>410</b>. The user may purchase the feed product provided as the feed information <b>510</b> by using a reward obtained by performing a task.</p><p id="p-0086" num="0085">Meanwhile, the user may select an additional condition <b>520</b>. The user terminal <b>1000</b> may receive an input of selecting the additional condition <b>520</b> by the user. When the additional condition <b>520</b> is determined, the user terminal <b>1000</b> may provide, to the user, only feed products that satisfy the additional condition <b>520</b> from among the feed products provided as the feed information <b>510</b>.</p><p id="p-0087" num="0086">For example, when the health abnormality type of the animal is arthritis, the user terminal <b>1000</b> may provide, as the feed information <b>510</b>, a feed product for improving arthritis to strengthen bones/joints. At this time, when &#x201c;natural food&#x201d; is determined as the additional condition <b>520</b>, the user terminal <b>1000</b> may provide, to the user, only feed products that satisfy a &#x201c;natural food&#x201d; condition from among the feed products for improving arthritis.</p><p id="p-0088" num="0087">Although not shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the user terminal <b>1000</b> may provide animal insurance information as a solution, based on the health abnormality type of the animal. The animal insurance information provided by the user terminal <b>1000</b> may include insurance product information. For example, when the health abnormality type of the animal is arthritis, the user terminal <b>1000</b> may provide, to the user, an insurance product including an arthritis guarantee condition. The user may use reward points to take out the insurance product provided as a solution. Also, when the user took out the insurance product provided as the solution, the user terminal <b>1000</b> may provide a reward to the user.</p><p id="p-0089" num="0088"><figref idref="DRAWINGS">FIGS. <b>6</b>A and <b>6</b>B</figref> are diagrams for describing an example of updating a task in consideration of a task performance achievement, according to an embodiment.</p><p id="p-0090" num="0089">After at least one task is performed, the user terminal <b>1000</b> may receive new real-time state information from a wearable device, and update the at least one task based on a performance achievement of the at least one task and the new real-time state information.</p><p id="p-0091" num="0090">For example, when a health abnormality type of an animal is obesity, &#x201c;walk 20 minutes&#x201d; may be provided as a three-week task.</p><p id="p-0092" num="0091">Referring to <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, it is identified that a three-week task performance rate <b>610</b> is very high. In addition, as a result of analyzing the new real-time state information received from the wearable device after performing the task, the user terminal <b>1000</b> may derive a result that the animal moves more actively than before performing the task.</p><p id="p-0093" num="0092">After determining that a degree of obesity of the animal has improved based on the performance achievement of the task and the new real-time state information, the user terminal <b>1000</b> may provide a &#x201c;walking&#x201d; task, which is decreased from existing 20 minutes to 17 minutes. Also, when a task performance rate is high, the user terminal <b>1000</b> may provide a higher reward (50 points) to the user.</p><p id="p-0094" num="0093">On the other hand, referring to <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, it is identified that a three-week task performance rate <b>620</b> is very low. In addition, as the result of analyzing the new real-time state information received from the wearable device after performing the task, the user terminal <b>1000</b> may derive a result that the animal moves less actively than before performing the task.</p><p id="p-0095" num="0094">After determining that the degree of obesity of the animal has not improved based on the performance achievement of the task and the new real-time state information, the user terminal <b>1000</b> may provide a &#x201c;walking&#x201d; task, which is increased from existing 20 minutes to 26 minutes.</p><p id="p-0096" num="0095"><figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref> are diagrams for describing an example of providing a task in consideration of basic information of an animal, according to an embodiment.</p><p id="p-0097" num="0096">The user terminal <b>1000</b> may receive an input from a user to obtain the basic information of the animal. The basic information of the animal may include information on a dog breed, an age, a gender, whether the animal is neutered, an illness the animal has, and whether the animal has an allergy, but the information that may be included in the basic information is not limited thereto.</p><p id="p-0098" num="0097">As described above in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the user terminal <b>1000</b> may receive real-time state information of the animal from a wearable device, and determine a health abnormality type of the animal based on the real-time state information of the animal.</p><p id="p-0099" num="0098">According to an embodiment, the user terminal <b>1000</b> may determine the health abnormality type of the animal in consideration of not only the real-time state information of the animal but also the basic information of the animal.</p><p id="p-0100" num="0099">For example, when, as a result of analyzing activity information among the real-time state information, a time corresponding to a rest state of the animal is equal to or greater than a threshold time, the user terminal <b>1000</b> may generally determine the health abnormality type of the animal as arthritis. On the other hand, when information indicating that an age of the animal is 2 is input as the basic information of the animal, a probability of the animal suffering from arthritis at the age of 2 is slim, and thus the user terminal <b>1000</b> may determine the health abnormality type of the animal as a body ache.</p><p id="p-0101" num="0100">In the disclosure, the health abnormality type of the animal may be more accurately determined by determining the health abnormality type in consideration of the basic information of the animal as well as the real-time state information of the animal.</p><p id="p-0102" num="0101">As described above in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the user terminal <b>1000</b> may provide, as a solution, at least one task helpful to health of the animal, based on the health abnormality type of the animal. Also, as described above in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the user terminal <b>1000</b> may provide, as a solution, feed information and animal insurance information helpful to the health of the animal, based on the health abnormality type of the animal.</p><p id="p-0103" num="0102">According to an embodiment, the user terminal <b>1000</b> may provide, as a solution, at least one task, in consideration of the basic information of the animal as well as the health abnormality type of the animal. Hereinafter, an embodiment will be described based on a premise that the health abnormality type of the animal is obesity.</p><p id="p-0104" num="0103">Referring to <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, as basic information <b>711</b> of an animal, information indicating that the animal is 3 years old may be input. Since a health abnormality type of the animal is obesity, &#x201c;walk 40 minutes&#x201d; may be provided as a today's task.</p><p id="p-0105" num="0104">On the other hand, referring to <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, as basic information <b>712</b> of an animal, information indicating that the animal is 15 years old and has arthritis may be input. Since a health abnormality type of the animal is obesity, &#x201c;walk 40 minutes&#x201d; is generally provided as a today's task, but considering the basic information <b>712</b> of the animal, there is a possibility that a long walk may aggravate the arthritis. The user terminal <b>1000</b> may provide, as the today's task, &#x201c;walk 17 minutes&#x201d; that has a reduced time than a general case, in consideration of not only the health abnormality type of the animal, but also the basic information <b>712</b> of the animal.</p><p id="p-0106" num="0105">According to another embodiment, the user terminal <b>1000</b> may provide, as a solution, feed information, in consideration of basic information of an animal as well as health abnormality type of the animal. For example, information indicating that the animal is allergic to a specific ingredient may be input as the basic information of the animal. In this case, the user terminal <b>1000</b> may provide, to a user, only feed products that do not contain the specific ingredient from among diet feed products.</p><p id="p-0107" num="0106">According to another embodiment, the user terminal <b>1000</b> may provide, as a solution, animal insurance information, in consideration of basic information of an animal as well as health abnormality type of the animal. For example, information indicating that the animal is 15 years old and a dog breed of the animal may be input as the basic information of the animal. In this case, the user terminal <b>1000</b> may provide, to a user, insurance products that guarantee an illness a specific dog breed type generally has when the specific dog breed ages.</p><p id="p-0108" num="0107">In the disclosure, a more accurate solution customized for each animal may be provided by providing a solution in consideration of not only the health abnormality type of the animal, but also the basic information of the animal.</p><p id="p-0109" num="0108">The user terminal <b>1000</b> may compare real-time state information with basic information to verify whether input basic information is correct.</p><p id="p-0110" num="0109">According to an embodiment, the user terminal <b>1000</b> may obtain, as basic information of an animal, information indicating that the animal has an illness A. As a result of analyzing real-time state information of the animal, the user terminal <b>1000</b> may determine that a health abnormality type of the animal is more likely to correspond to an illness B than the illness A. As such, there is a possibility that the basic information of the animal, which the user knows, is wrong or that the basic information has changed over time.</p><p id="p-0111" num="0110">The real-time state information of the disclosure is information that most accurately shows a current state of the animal, and in the disclosure, by comparing the real-time state information with the basic information, more accurate basic information about the animal may be provided to a user.</p><p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart of a method of monitoring a state of an animal and providing a solution, according to an embodiment.</p><p id="p-0113" num="0112">Referring to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, in operation <b>810</b>, a processor may receive real-time state information of an animal from a wearable device worn on a part of a body of the animal.</p><p id="p-0114" num="0113">The wearable device may include at least one sensor, and the wearable device may collect the real-time state information of the animal, based on a sensing value of the at least one sensor.</p><p id="p-0115" num="0114">According to an embodiment, the real-time state information may be information indicating whether the animal is currently in an activity state or in a sleep state. In detail, the real-time state information may be information indicating whether the animal is in a play state, an activity state, a rest state, or a sleep state. However, the real-time state information is not limited thereto.</p><p id="p-0116" num="0115">In operation <b>820</b>, the processor may determine a health abnormality type of the animal based on the real-time state information.</p><p id="p-0117" num="0116">The health abnormality type may include arthritis, skin disease, allergy, and separation anxiety, but is not limited thereto.</p><p id="p-0118" num="0117">For example, when, as a result of analyzing activity information among the real-time state information, a time corresponding to the play state of the animal is equal to or greater than a threshold time, the processor may determine the health abnormality type of the animal as separation anxiety. Alternatively, when, as the result of analyzing the activity information, a time corresponding to the rest state of the animal is equal to or greater than a threshold time, the processor may determine the health abnormality type of the animal as arthritis.</p><p id="p-0119" num="0118">According to an embodiment, the processor may receive an input from a user to obtain basic information of the animal, and determine the health abnormality type of the animal based on the real-time state information and the basic information.</p><p id="p-0120" num="0119">The basic information of the animal may include information on a dog breed, an age, a gender, whether the animal is neutered, an illness the animal has, and whether the animal has an allergy, but the information that may be included in the basic information is not limited thereto.</p><p id="p-0121" num="0120">For example, when, as the result of analyzing the activity information among the real-time state information, the time corresponding to the rest state of the animal is equal to or greater than the threshold time, the processor may generally determine the health abnormality type of the animal as arthritis. On the other hand, when information indicating that the animal is 2 years old is input as the basic information of the animal, a probability of the animal suffering from arthritis at the age of 2 is slim, and thus the processor may determine the health abnormality type of the animal as a body ache.</p><p id="p-0122" num="0121">According to an embodiment, the processor may verify the basic information by comparing the real-time state information with the basic information. The processor may obtain, as the basic information of the animal, information indicating that the animal has the illness A. As the result of analyzing the real-time state information of the animal, the processor may determine that the health abnormality type of the animal is more likely to correspond to the illness B than the illness A.</p><p id="p-0123" num="0122">In operation <b>830</b>, the processor may provide a solution according to the health abnormality type.</p><p id="p-0124" num="0123">According to an embodiment, the processor may provide, as the solution, at least one task helpful to health of the animal, based on the health abnormality type.</p><p id="p-0125" num="0124">Also, the processor may provide a reward to the user according to a performance achievement of the at least one task.</p><p id="p-0126" num="0125">After the at least one task is performed, the processor may receive new real-time state information from the wearable device, and update the at least one task based on a performance achievement of the at least one task and the new real-time state information.</p><p id="p-0127" num="0126">According to another embodiment, the processor may provide, as the solution, feed information helpful to the health of the animal, based on the health abnormality type.</p><p id="p-0128" num="0127">When the basic information of the animal is obtained from the user, the processor may provide, as the solution, at least one task or feed information helpful to the health of the animal, based on the health abnormality type and the basic information.</p><p id="p-0129" num="0128"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram of an external server <b>900</b> according to an embodiment.</p><p id="p-0130" num="0129">Referring to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the external server <b>900</b> may include a communication unit <b>910</b>, a processor <b>920</b>, and a database (DB) <b>930</b>. Only components related to an embodiment are shown in the external server <b>900</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>. Accordingly, it may be understood by one of ordinary skill in the art that other general-purpose components may be further included in addition to the components shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0131" num="0130">The communication unit <b>910</b> may include one or more components for performing wired/wireless communication with user terminals and payment information providing servers. For example, the communication unit <b>910</b> may include at least one of a short-range communication unit (not shown), a mobile communication unit (not shown), and a broadcast receiving unit (not shown).</p><p id="p-0132" num="0131">The DB <b>930</b> is hardware storing various types of data processed in the external server <b>900</b>, and may store a program for processing and controlling by the processor <b>920</b>.</p><p id="p-0133" num="0132">The DB <b>930</b> may include a random-access memory (RAM) such as a dynamic random-access memory (DRAM) or a static random-access memory (SRAM), a read-only memory (ROM), an electrically erasable programmable read-only memory (EEPROM), CD-ROM, Blu-ray or another optical disk storage, a hard disk drive (HDD), a solid-state drive (SSD), or a flash memory.</p><p id="p-0134" num="0133">The processor <b>920</b> controls overall operations of the external server <b>900</b>. For example, the processor <b>920</b> may generally control an input unit (not shown), a display (not shown), the communication unit <b>910</b>, the DB <b>930</b>, and the like by executing programs stored in the DB <b>930</b>. The processor <b>920</b> may control operations of the external server <b>900</b> by executing programs stored in the DB <b>930</b>.</p><p id="p-0135" num="0134">The processor <b>920</b> may be realized by using at least one of an application specific integrated circuit (ASIC), a digital signal processor (DSP), a digital signal processing device (DSPD), a programmable logic device (PLD), a field programmable gate array (FPGA), a controller, a micro-controller, a microprocessor, and other electrical units for performing functions.</p><p id="p-0136" num="0135">The external server <b>900</b> may communicate with a user terminal and a wearable device worn on a part of a body of an animal, through the communication unit <b>910</b>.</p><p id="p-0137" num="0136">The communication unit <b>910</b> may receive real-time state information of the animal from the user terminal or the wearable device.</p><p id="p-0138" num="0137">The DB <b>930</b> may store the real-time state information of the animal.</p><p id="p-0139" num="0138">The processor <b>920</b> may determine a health abnormality type of the animal, based on the real-time state information of the animal. Also, the processor <b>920</b> may determine a solution according to the health abnormality type.</p><p id="p-0140" num="0139">The DB <b>930</b> may store the health abnormality type according to the real-time state information of the animal and the solution according to the health abnormality type, which are determined by the processor <b>920</b>.</p><p id="p-0141" num="0140">The communication unit <b>910</b> may transmit the health abnormality type and solution to the user terminal or the wearable device.</p><p id="p-0142" num="0141">As a selective embodiment, the external server <b>900</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref> may communicate with the user terminal and the wearable device worn on the part of the body of the animal, through the communication unit <b>910</b>.</p><p id="p-0143" num="0142">The communication unit <b>910</b> may receive animal characteristic information from the user terminal or the wearable device.</p><p id="p-0144" num="0143">The animal characteristic information may be stored in the DB <b>930</b>.</p><p id="p-0145" num="0144">The processor <b>920</b> may determine a maintenance energy requirement (MER) of the animal based on the animal characteristic information. Also, the processor <b>920</b> may determine at least one of a notification regarding whether to repurchase a feed according to the MER, state information of the animal, and recommended feed information.</p><p id="p-0146" num="0145">The DB <b>930</b> may store at least one of the MER according to the animal characteristic information, the notification regarding whether to repurchase a feed according to the MER, the state information of the animal, and the recommended feed information, which are determined by the processor <b>920</b>.</p><p id="p-0147" num="0146">The communication unit <b>910</b> may transmit, to the user terminal or the wearable device, at least one of the MER, the notification regarding whether to repurchase a feed, the state information of the animal, and the recommended feed information.</p><p id="p-0148" num="0147"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram of an example of a product recommendation apparatus <b>1000</b>A, according to an embodiment.</p><p id="p-0149" num="0148">Referring to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the product recommendation apparatus <b>1000</b>A includes a communication interface <b>1010</b>A, a processor <b>1020</b>A, and a memory <b>330</b>A. Only components related to an embodiment are shown in the product recommendation apparatus <b>1000</b>A of <figref idref="DRAWINGS">FIG. <b>10</b></figref>. Accordingly, it may be understood by one of ordinary skill in the art that general-purpose components other than those shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref> may be further included in the product recommendation apparatus <b>1000</b>A.</p><p id="p-0150" num="0149">The product recommendation apparatus <b>1000</b>A may be the user terminal <b>1000</b> or the external server <b>3000</b> described above with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Accordingly, details described above with reference to the user terminal <b>1000</b> or the external server <b>3000</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> may be applied to the product recommendation apparatus <b>1000</b>A of <figref idref="DRAWINGS">FIG. <b>10</b></figref> even if omitted below.</p><p id="p-0151" num="0150">The communication interface <b>1010</b>A may include one or more components for performing wired or wireless communication with an external device. For example, the communication interface <b>1010</b>A may include at least one of a short-range communication unit (not shown), a mobile communication unit (not shown), and a broadcast receiving unit (not shown).</p><p id="p-0152" num="0151">For example, the communication interface <b>1010</b>A may receive basic information and illness information of an animal from the external device. When the product recommendation apparatus <b>1000</b>A is the user terminal <b>1000</b>, the external device may be the external server <b>3000</b> or the wearable device <b>2000</b>. Alternatively, when the product recommendation apparatus <b>1000</b>A is the external server <b>3000</b>, the external device may be the user terminal <b>1000</b> or the wearable device <b>2000</b>.</p><p id="p-0153" num="0152">In the above-described embodiment, it is described that the product recommendation apparatus <b>1000</b>A receives the basic information and illness information of the animal from the external device, but the embodiment is not limited thereto. In other words, the basic information and illness information of the animal may be self-obtained or generated by the product recommendation apparatus <b>1000</b>A.</p><p id="p-0154" num="0153">The memory <b>330</b>A is hardware storing various types of data processed in the product recommendation apparatus <b>1000</b>A, and may store a program for processing and controlling by the processor <b>1020</b>A.</p><p id="p-0155" num="0154">For example, the memory <b>330</b>A may store the basic information and illness information of the animal, information on a current state of the animal, and information about a recommended product.</p><p id="p-0156" num="0155">The memory <b>330</b>A may include RAM such as DRAM or SRAM, ROM, EEPROM, CD-ROM, Blu-ray or another optical disk storage, a HDD, an SSD, or a flash memory.</p><p id="p-0157" num="0156">The processor <b>1020</b>A controls overall operations of the product recommendation apparatus <b>1000</b>A. For example, the processor <b>1020</b>A may generally control an input unit (not shown), a display (not shown), the communication interface <b>1010</b>A, the memory <b>330</b>A, and the like by executing programs stored in the memory <b>330</b>A. The processor <b>1020</b>A may control operation of the product recommendation apparatus <b>1000</b>A by executing programs stored in the memory <b>330</b>A.</p><p id="p-0158" num="0157">For example, the processor <b>1020</b>A may estimate the current state of the animal, based on the basic information and illness information of the animal. In addition, the processor <b>1020</b>A may recommend a product corresponding to the current state of the animal. Also, the processor <b>1020</b>A may provide a reward to a user, based on whether the recommended product is purchased.</p><p id="p-0159" num="0158">For example, the processor <b>1020</b>A may be realized by using at least one of an ASIC, a DSP, a DSPD, a PLD, an FPGA, a controller, a micro-controller, a microprocessor, and other electrical units for performing functions.</p><p id="p-0160" num="0159">Hereinafter, a method in which the processor <b>1020</b>A recommends a product based on a state of an animal will be described in detail with reference to <figref idref="DRAWINGS">FIGS. <b>11</b> to <b>16</b></figref>.</p><p id="p-0161" num="0160"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart of an example of a method of recommending a product, based on a state of an animal, according to an embodiment.</p><p id="p-0162" num="0161">Referring to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the method of recommending a product, based on the state of the animal includes operations performed in time series by the user terminal <b>1000</b>, the wearable device <b>2000</b>, or the external server <b>3000</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Thus, even if omitted below, details described above with respect to the user terminal <b>1000</b>, the wearable device <b>2000</b>, or the external server <b>3000</b> shown in <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref> may be applied to the method of <figref idref="DRAWINGS">FIG. <b>11</b></figref> of recommending a product, based on the state of the animal.</p><p id="p-0163" num="0162">In operation <b>1110</b>, the communication interface <b>1010</b>A receives basic information and illness information of the animal.</p><p id="p-0164" num="0163">The basic information of the animal includes at least one of a type of the animal, a breed of the animal, an age of the animal, a gender of the animal, a real-time state of the animal, and whether the animal is neutered. For example, when the animal is a dog, the type of the animal denotes a dog, and the breed of the animal denotes a Dobermann, a poodle, a bulldog, an Alaskan malamute, or the like.</p><p id="p-0165" num="0164">Meanwhile, real-time state information of the animal may be collected by the wearable device <b>2000</b>, and received through the communication interface <b>1010</b>A. In detail, the real-time state information may be information indicating whether the animal is in a play state, an activity state, a rest state, or a sleep state. However, types of the real-time state information are not limited to the above examples. An example of collecting the real-time state information of the animal by the wearable device <b>2000</b> is as described above with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0166" num="0165">The illness information of the animal includes at least one of an illness the animal currently suffers from, an illness the animal has suffered in the past, and an allergy of the animal. Here, a type of illness is not limited, and a cause of allergy is not limited to specific examples.</p><p id="p-0167" num="0166">Meanwhile, the basic information and illness information of the animal may be stored in the memory <b>330</b>A. Hereinafter, an example in which the basic information and illness information of the animal are stored in the memory <b>330</b>A will be described with reference to <figref idref="DRAWINGS">FIG. <b>12</b></figref>.</p><p id="p-0168" num="0167"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram for describing an example in which the basic information and illness information of the animal are stored in the memory <b>330</b>A, according to an embodiment.</p><p id="p-0169" num="0168"><figref idref="DRAWINGS">FIG. <b>12</b></figref> shows an example in which the basic information and illness information of the animal are stored in the memory <b>330</b>A. The basic information and illness information may be very diverse. Accordingly, the memory <b>330</b>A may store various pieces of information included in the basic information and various pieces of information included in the illness information separately from each other. Also, when a user raises a plurality of animals, the basic information and the illness information may be separately stored in the memory <b>330</b>A for each of the plurality of animals.</p><p id="p-0170" num="0169">The processor <b>1020</b>A may output the real-time state information of the animal through a display, and the user may identify the real-time state of the animal based on the output real-time state information. Hereinafter, an example in which the processor <b>1020</b>A outputs the real-time state information of the animal will be described with reference to <figref idref="DRAWINGS">FIG. <b>13</b></figref>.</p><p id="p-0171" num="0170"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram for describing an example in which the real-time state information of the animal is output, according to an embodiment.</p><p id="p-0172" num="0171">The communication interface <b>1010</b>A may receive the real-time state information of the animal from the wearable device <b>2000</b>, and the processor <b>1020</b>A may output the real-time state information of the animal through the display.</p><p id="p-0173" num="0172">For example, referring to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the user terminal <b>1000</b> may receive the real-time state information of the animal from the wearable device <b>2000</b>, accumulate the received real-time state information on daily, weekly, monthly, and yearly bases, and provide the same to the user.</p><p id="p-0174" num="0173">According to an embodiment, the user terminal <b>1000</b> may provide the user with, as activity information <b>1310</b>, a total of accumulated time of each of a play state, an activity state, and a rest state among the real-time state information. Also, the user terminal <b>1000</b> may accumulate a time of a sleep state among the real-time state information, and provide the same to the user as sleep information <b>1320</b>.</p><p id="p-0175" num="0174">The user terminal <b>1000</b> may not only provide the user with the real-time state information of the animal, but also determine a health abnormality type of the animal, based on the real-time state information.</p><p id="p-0176" num="0175">For example, when, as a result of analyzing the activity information <b>1310</b> among the real-time state information, a time corresponding to the play state of the animal is equal to or greater than a threshold time, the user terminal <b>1000</b> may determine the health abnormality type of the animal as separation anxiety.</p><p id="p-0177" num="0176">Alternatively, when, as the result of analyzing the activity information <b>1310</b>, a time corresponding to the rest state of the animal is equal to or greater than a threshold time, the user terminal <b>1000</b> may determine the health abnormality type of the animal as arthritis.</p><p id="p-0178" num="0177">However, the user terminal <b>1000</b> may determine the health abnormality type of the animal, taking into account various sensing values received from the wearable device <b>2000</b>, in addition to the times corresponding to the play state, activity state, rest state, and sleep state of the animal. For example, the user terminal <b>1000</b> may determine the health abnormality type of the animal, considering sensing values received from the EMG sensor, the electrodermal activity sensor, the skin temperature measurer, the blood pressure measurer, the accelerometer, and the like of the wearable device <b>2000</b>.</p><p id="p-0179" num="0178">Referring back to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, in operation <b>1120</b>, the processor <b>1020</b>A estimates a current state of the animal based on the basic information and the illness information.</p><p id="p-0180" num="0179">The processor <b>1020</b>A may estimate the current state of the animal by considering all of the basic information and the illness information stored in the memory <b>330</b>A, or by selecting some of the basic information and the illness information. For example, the processor <b>1020</b>A may estimate the current state of the animal by combining a plurality of first elements (information) included in the basic information and a plurality of second elements (information) included in the illness information. Here, the processor <b>1020</b>A may estimate the current state of the animal by applying a predetermined weight to each of the first and second elements. Hereinafter, an example in which the processor <b>1020</b>A estimates the current state of the animal will be described with reference to <figref idref="DRAWINGS">FIG. <b>14</b></figref>.</p><p id="p-0181" num="0180"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram for describing an example in which the processor <b>1020</b>A estimates the current state of the animal, according to an embodiment.</p><p id="p-0182" num="0181"><figref idref="DRAWINGS">FIG. <b>14</b></figref> shows various types of basic information and illness information of the animal. For example, various types of basic information and illness information may include a type, a breed, an age, a gender, neutralization, a current illness, a past illness, allergy, and the like of the animal.</p><p id="p-0183" num="0182">The processor <b>1020</b>A may estimate the current state of the animal, by combining the various types of information of the animal. Here, the processor <b>1020</b>A may estimate the current state of the animal by applying a predetermined weight to each of various types of information.</p><p id="p-0184" num="0183">For example, the processor <b>1020</b>A may set weights for a current illness <b>1410</b> and allergy <b>1420</b> of the animal to be different from weights for other pieces of information. In general, the current illness <b>1410</b> and allergy <b>1420</b> are identified as very important factors in estimating the current state of the animal. Accordingly, the processor <b>1020</b>A may assign higher weights to the current illness <b>1410</b> and allergy <b>1420</b> than other pieces of information. In this case, while estimating the current state of the animal, the current illness <b>1410</b> and allergy <b>1420</b> may have greater influences than the other pieces of information.</p><p id="p-0185" num="0184">Although <figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates that the current illness <b>1410</b> and the allergy <b>1420</b> have the same weights, the disclosure is not limited thereto. In other words, when the current illness <b>1410</b> is more important information for estimating the current state of the animal, the processor <b>1020</b>A may assign a higher weight for the current illness <b>1410</b> than that for the allergy <b>1420</b>.</p><p id="p-0186" num="0185">Referring back to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, in operation <b>1130</b>, the processor <b>1020</b>A recommends a product corresponding to the current state of the animal.</p><p id="p-0187" num="0186">Here, the product may be a feed and/or nutritional supplement consumed by the animal. As described above with reference to operation <b>1120</b>, the processor <b>1020</b>A estimates the current state of the animal. Accordingly, the product recommended by the processor <b>1020</b>A may be a product helpful to the health of the animal. Thus, the user may not only identify the current state of his/her animal, but also identify a product capable of resolving a health issue of the animal.</p><p id="p-0188" num="0187">Hereinafter, an example in which the processor <b>1020</b>A recommends a product corresponding to the current state of the animal will be described with reference to FIG.</p><p id="p-0189" num="0188"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram for describing an example in which the processor <b>1020</b>A recommends a product, according to an embodiment.</p><p id="p-0190" num="0189">The user terminal <b>1000</b> may provide, as a solution, information <b>1510</b> about product helpful to health of an animal, based on health abnormality type of the animal. For example, when the product is a feed for the animal, the user terminal <b>1000</b> may provide, as the information <b>1510</b>, necessary nutrient information, feed product information, and the like.</p><p id="p-0191" num="0190">In detail, when the animal is currently obese, the user terminal <b>1000</b> may provide the information <b>1510</b> about nutrient information for a diet or a diet feed product. Alternatively, when the animal is currently suffering from arthritis, the user terminal <b>1000</b> may provide the information <b>1510</b> about nutrient information for strengthening bones/joints or a feed product for improving arthritis.</p><p id="p-0192" num="0191">For example, when a user purchases a product provided as the information <b>1510</b>, the user terminal <b>1000</b> may provide a reward. At this time, the user may use the reward to purchase another product.</p><p id="p-0193" num="0192">The user may select an additional condition <b>1520</b>. The user terminal <b>1000</b> may receive an input of selecting the additional condition <b>1520</b> by the user. When the additional condition <b>1520</b> is determined, the user terminal <b>1000</b> may filter only products that satisfy the additional condition <b>1520</b> from among the products provided as the information <b>1510</b>, and provide the same to the user.</p><p id="p-0194" num="0193">Alternatively, when the animal is currently suffering from arthritis, the user terminal <b>1000</b> may provide the information <b>1510</b> about a feed product for improving arthritis to strengthen bones/joints. At this time, when &#x201c;natural food&#x201d; is determined as the additional condition <b>1520</b>, the user terminal <b>1000</b> may filter only products that satisfy a &#x201c;natural food&#x201d; condition from among the feed products for improving arthritis, and provide the same to the user.</p><p id="p-0195" num="0194">The user may use reward points to purchase a product provided as a solution. Also, when the user has purchased the product provided as the solution, the user terminal <b>1000</b> may provide a reward to the user.</p><p id="p-0196" num="0195">Although not shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, the user terminal <b>1000</b> may provide animal insurance information as a solution, based on the current state of the animal. The animal insurance information provided by the user terminal <b>1000</b> may include insurance product information. For example, when the animal is currently suffering from arthritis, the user terminal <b>1000</b> may provide, to the user, an insurance product including an arthritis guarantee condition. The user may use reward points to take out the insurance product provided as a solution. Also, when the user took out the insurance product provided as the solution, the user terminal <b>1000</b> may provide a reward to the user.</p><p id="p-0197" num="0196"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram for describing an example in which a system <b>4000</b> recommends a product, according to an embodiment.</p><p id="p-0198" num="0197">Referring to <figref idref="DRAWINGS">FIG. <b>16</b></figref>, the system <b>4000</b> includes the user terminal <b>1000</b>, the wearable device <b>2000</b>, and the external server <b>3000</b>. Only components related to an embodiment are shown in the system <b>4000</b> of <figref idref="DRAWINGS">FIG. <b>16</b></figref>. Accordingly, it may be understood by one of ordinary skill in the art that general-purpose components other than those shown in <figref idref="DRAWINGS">FIG. <b>16</b></figref> may be further included in the system <b>4000</b>.</p><p id="p-0199" num="0198">The product recommendation apparatus <b>1000</b>A illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> may correspond to the user terminal <b>1000</b> or the external server <b>3000</b> of the system <b>4000</b>. Accordingly, even if omitted, details of the user terminal <b>1000</b> or the external server <b>3000</b> described above with reference to <figref idref="DRAWINGS">FIGS. <b>10</b> to <b>15</b></figref> may also be applied to the system <b>4000</b> of <figref idref="DRAWINGS">FIG. <b>16</b></figref>.</p><p id="p-0200" num="0199">In operation <b>1610</b>, the wearable device <b>2000</b> transmits information about an animal to the user terminal <b>1000</b>. For example, the wearable device <b>2000</b> may transmit the information about the animal to the user terminal <b>1000</b> through a wireless or wired communication method. Here, the information about the animal may include basic information and illness information of the animal.</p><p id="p-0201" num="0200">The user terminal <b>1000</b> may obtain the information about the animal, in operation <b>1620</b>. In other words, the user terminal <b>1000</b> may receive the information about the animal from the wearable device <b>2000</b> or self-obtain the same through a user input.</p><p id="p-0202" num="0201">The user terminal <b>1000</b> transmits the information about the animal to the external server <b>3000</b>, in operation <b>1630</b>. For example, the user terminal <b>1000</b> may transmit the information about the animal to the external server <b>3000</b> through a wireless or wired communication method.</p><p id="p-0203" num="0202">The user terminal <b>1000</b> may estimate a current state of the animal by using the information about the animal, which is transmitted from the wearable device <b>2000</b> or self-obtained, in operation <b>1640</b>. Alternatively, the external server <b>3000</b> may estimate the current state of the animal by using the information about the animal transmitted from the user terminal <b>1000</b>, in operation <b>1650</b>. If the user terminal <b>1000</b> estimates the current state of the animal, the user terminal <b>1000</b> may transmit information about the estimated current state to the external server <b>3000</b>.</p><p id="p-0204" num="0203">The external server <b>3000</b> transmits information about a recommended product to the user terminal <b>1000</b>, in operation <b>1660</b>. Here, a product denotes a feed or nutritional supplement that may be consumed by the animal.</p><p id="p-0205" num="0204">The user terminal <b>1000</b> may display the information about the recommended product transmitted from the external server <b>3000</b>, and a user may determine whether to purchase the recommended product. When the user purchases the recommended product, the external server <b>3000</b> may provide a reward to the user through the user terminal <b>1000</b>, in operation <b>1670</b>.</p><p id="p-0206" num="0205"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flowchart of an example of calculating a recommended feed amount for an animal, based on animal characteristic information, and transmitting a feed repurchase notification to a user, according to an embodiment.</p><p id="p-0207" num="0206">For convenience of description, it is assumed that individual operations shown in <figref idref="DRAWINGS">FIG. <b>17</b></figref> are performed by a processor of the external server <b>3000</b>. However, as described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>, it should be understood that each operation described below may also be performed by the user terminal <b>1000</b> or the wearable device <b>2000</b>.</p><p id="p-0208" num="0207">Referring to <figref idref="DRAWINGS">FIG. <b>17</b></figref>, the processor of the external server <b>3000</b> may receive animal characteristic information, in operation S<b>1710</b>. In the disclosure, the animal characteristic information may be information pre-stored in the external server <b>3000</b> or the user terminal <b>1000</b>, information measured by the wearable device <b>2000</b>, or information obtained by processing the measured information. One piece of animal characteristic information is related to one animal, and may be information representing physical and activity characteristics of the corresponding animal. The animal characteristic information may include one or more pieces of animal characteristic sub-information so as to represent various physical and active characteristics of the corresponding animal.</p><p id="p-0209" num="0208">The processor of the external server <b>3000</b> may determine whether the received animal characteristic information is sufficient, in operation S<b>1720</b>. As will be described below with reference to <figref idref="DRAWINGS">FIG. <b>18</b></figref>, the animal characteristic information according to the disclosure is applied to an MER calculation model according to the disclosure to calculate an MER of the animal. The processor of the external server <b>3000</b> may calculate a recommended feed amount for the animal, based on the calculated MER, and transmit the same to a user. In this regard, the processor of the external server <b>3000</b> may examine whether the received animal characteristic information is sufficient to be applied to the MER calculation model. When the animal characteristic information is sufficient to be applied to the MER calculation model, the processor of the external server <b>3000</b> may calculate the MER of the animal by using the received animal characteristic information and the MER calculation model, in operation S<b>1740</b>. On the other hand, when the animal characteristic information is not sufficient to be applied to the MER calculation model, the processor of the external server <b>3000</b> may calculate the MER of the animal by using a simple model, in operation S<b>1730</b>. In the disclosure, a description about the simple model for calculating an MER will be omitted.</p><p id="p-0210" num="0209">The processor of the external server <b>3000</b> may use the MER of the animal calculated in operation S<b>1730</b> or S<b>1740</b> to calculate the recommended feed amount of the animal, in operation S<b>1750</b>. In particular, the recommended feed amount of the animal may be calculated by dividing the MER of the animal by metabolizable energy (ME) of a feed. In the disclosure, the MER may denote the amount of daily energy required for the animal, and the ME may denote the amount of energy in a form that may be used purely by the animal per unit weight of feed. In other words, the processor of the external server <b>3000</b> according to the disclosure may calculate a daily recommended feed amount of the animal by dividing a daily required energy amount of the animal by energy per unit weight of a metabolizable feed. Hereinafter, an example in which the processor calculates energy per unit weight of a feed to calculate the daily recommended feed amount of the animal will be described.</p><p id="p-0211" num="0210">According to an embodiment, the size of ME for calculating the recommended feed amount of the animal may be determined according to an ingredient composition ratio of the feed. In detail, the ME may be determined based on the amounts of crude protein, crude fat, and crude carbohydrate per unit weight of the feed. According to an embodiment, the processor may perform a process of multiplying each of the amounts of crude protein, crude fat, and crude carbohydrate by a preset coefficient so as to determine the ME. Also, in particular, commercially available feeds often do not indicate the amount of crude carbohydrate, and thus the processor may calculate the amount of crude carbohydrate by using an ingredient composition ratio of a known feed. The amount of crude carbohydrate is also referred to as nitrogen-free extract (NFE), and the content or ingredient ratio of the NFE in the feed may be calculated by subtracting the amount of crude protein, the amount of crude fat, the amount of crude fiber, the amount of moisture, and the amount of crude ash from a total feed amount or ingredient ratio. In addition, according to an embodiment, the processor may calculate the amount of crude carbohydrates, assuming that the amount of moisture is 10%. A process by which the processor calculates the amount of energy per unit weight of the feed through the above-described process may be different for each individual feed. The processor may calculate the energy per unit weight of the feed by referring to ingredient information of the individual feed stored in a DB of the external server <b>3000</b>. The above-described method by which the processor calculates the energy per unit weight of the feed is merely an example, and thus the method is not limited thereto.</p><p id="p-0212" num="0211">The processor of the external server <b>3000</b> compares the calculated recommended feed amount with a remaining feed amount stored in the DB of the external server <b>3000</b>, and when the remaining feed amount is sufficient (Yes in operation S<b>1760</b>), the method is ended, and when the remaining feed amount is insufficient (No in operation S<b>1760</b>), a feed repurchase notification, recommended feed information, and advertisement information may be transmitted to the user terminal <b>1000</b> or the wearable device <b>2000</b>, in operation S<b>1770</b>.</p><p id="p-0213" num="0212">As described above, the processor of the external server <b>3000</b> according to the disclosure may provide the user with the feed repurchase notification, based on the calculated recommended feed amount. Content of the feed repurchase notification provided to the user may vary. According to an embodiment, the content thereof may include information indicating that the feed needs to be repurchased. According to another embodiment, the content thereof may include the recommended feed information, advertisement information on a feed, and the like. When the feed repurchase notification includes the recommended feed information, the recommended feed information may be determined in consideration of the animal characteristic information. As described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>, the animal characteristic information may include physical level information and activity level information of the animal, the physical level information may include information such as a species, an age, and a weight, and the activity level information may include an indicator regarding activity of the animal. Accordingly, according to an embodiment according to the disclosure, the processor of the external server <b>3000</b> may determine, as a recommended feed, a feed suitable for characteristics of the animal, in consideration of the physical level information of the animal, that is, the species and age of the animal. Alternatively, the processor of the external server <b>3000</b> may use the activity level information of the animal to determine, as the recommended feed, a feed suitable for an activity level of the animal. For example, when the activity level of the animal is high, the processor may determine, as the recommended feed, a feed having high ME, and provide information related to the determined recommended feed to the user together with the advertisement information. The processor according to the disclosure provides the recommended feed information to the user, based on the animal characteristic information including the animal activity level information measured by the wearable device <b>2000</b>, and thus the processor is able to determine the recommended feed more suitable for the animal considering changes in the physical and activity levels of the animal, compared to a general recommended feed determined by only using general physical information of the animal (only considering a species or age of the animal). Also, when the advertisement information is transmitted to the user through the user terminal <b>1000</b> or the wearable device <b>2000</b>, based on the recommended feed, it is possible to guide the user to rationally purchase the feed, thereby increasing loyalty of users towards a platform using the method and apparatus according to the disclosure.</p><p id="p-0214" num="0213"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a diagram showing an example of an MER calculation model, according to an embodiment.</p><p id="p-0215" num="0214">As described above with reference to <figref idref="DRAWINGS">FIG. <b>17</b></figref>, an MER may denote a daily required energy amount of an animal. The external server <b>3000</b>, the user terminal <b>1000</b>, or the wearable device <b>2000</b> according to the disclosure may calculate the MER of the animal, based on the MER calculation model and animal characteristic information. For convenience of description, the disclosure is described based on the external server <b>3000</b>, but a following description related to <figref idref="DRAWINGS">FIG. <b>18</b></figref> may also be applied to the user terminal <b>1000</b> or the wearable device <b>2000</b>. The MER calculation model will be described in detail below.</p><p id="p-0216" num="0215">Referring to <figref idref="DRAWINGS">FIG. <b>18</b></figref>, an embodiment of the MER calculation model according to the disclosure may be calculated by using a resting energy requirement (RER), a neutralization characteristic value <b>1810</b>, an activity characteristic value <b>1830</b>, and a weight characteristic value <b>1850</b>. According to an embodiment of the disclosure, physical level information or activity level information of an animal related to a characteristic value may be an indicator processed for MER calculation. For example, the processor of the external server <b>3000</b> may set a neutralization characteristic value to 0.8 for a neutered dog or cat, and 1.0 for an unneutered dog or cat. A characteristic value according to the disclosure may be calculated by converting physical level information or animal activity level information of a corresponding animal. For example, the physical level information or activity level information of the animal may be represented by a value indicating a related characteristic. As another example, physical level information or activity level information may also be represented by a label indicating a level of a related characteristic. Accordingly, the processor of the external server <b>3000</b> according to an embodiment of the disclosure may directly convert the physical level information or the activity level information into a neutralization characteristic value, an activity characteristic value, and a weight characteristic value by using a conversion model. The processor of the external server <b>3000</b> according to another embodiment may convert the physical level information or activity level information represented in a form of a label by using data such as a preset conversion table.</p><p id="p-0217" num="0216">In the disclosure, the RER may denote basic energy for maintaining metabolic processes in a body when the animal does nothing in a rest state. This will be described in detail below.</p><p id="p-0218" num="0217">In the disclosure, the neutralization characteristic value <b>1810</b> may be a value obtained by converting information about whether an animal is neutered, from among animal characteristic information, to be applied to the MER calculation model. Even when the animal is neutered, an effect of neutralization on MER calculation may vary depending on physical details, such as a species, an age, and the like, and thus the neutralization characteristic value <b>1810</b> may be determined differently according to the animal characteristic information. In detail, the processor may determine the neutralization characteristic value <b>1810</b> differently by reflecting species information and age information of the animal.</p><p id="p-0219" num="0218">In the disclosure, the activity characteristic value <b>1830</b> may be a value obtained by converting information on the activity level information, from among the animal characteristic information, to be applied to the MER calculation model. Like the neutralization characteristic value <b>1810</b>, activities of animals having a same level of activity may have different effects on the MERs, and thus the activity characteristic value <b>1830</b> may be determined differently according to the animal characteristic information. In detail, the processor may determine the activity characteristic value <b>1830</b> by reflecting the species information and age information of the animal. For example, regarding a 4-month-old dog A and a 96-month-old dog B, of which activity level information is active, the processor may determine an activity characteristic value to be 2.0 for the dog A and to be 1.5 for the dog B.</p><p id="p-0220" num="0219">In the disclosure, the weight characteristic value <b>1850</b> may be a value obtained by converting weight information from among animal characteristic information, to be applied to the MER calculation model. Like the neutralization characteristic value <b>1810</b> and the activity characteristic value <b>1830</b>, activities of animals having a same weight may have different effects on the MERs, and thus the weight characteristic value <b>1850</b> may be determined differently according to the animal characteristic information. In detail, the processor may determine the weight characteristic value <b>1850</b> by reflecting the species information and age information of the animal. For example, regarding a 4-month-old dog A and a 96-month-old dog B, of which weight levels are &#x201c;overweight&#x201d;, the processor may determine a weight characteristic value to be 1.8 for the dog A and to be 1.2 for the dog B.</p><p id="p-0221" num="0220">Compared with general models presented by the NRC and National Institute of Animal Science, the MER calculation model according to the disclosure differs in that activity of an animal is reflected to MER calculation. It is clear that there are differences between individual beings even between animals of a same species and same physical characteristics. In particular, although activity is a very important factor in determining energy consumption of an individual being, conventional models do not directly reflect the activity. In other words, the conventional model determines activity indirectly and uniformly, considering an age, neutralization, pregnancy, and the like of an animal, and thus activity of an individual being is not reflected in MER calculation. Accordingly, even if an owner determines a feed amount according to the model, a feed amount suitable for an individual being may be unable to be determined. On the other hand, the MER calculation model according to the disclosure considers an activity characteristic value of an individual being. Therefore, the MER calculation model according to the disclosure may determine recommended feed amounts suitable for the individual beings by sufficiently reflecting a difference between the individual beings. Furthermore, in the disclosure, characteristic values used for MER calculation are measured by the wearable device <b>2000</b>, and such measurements are performed in real time/periodically. Accordingly, the MER and recommended feed amount may be updated according to physical changes of the individual being by suitably detecting changes in characteristic information of the individual being. In other words, the MER may be suitably adjusted by considering an increase in the amount of activity, a change in activity according to an environment change, a weight change, and the like in real time while the animal grows into an adult, and accordingly, information about an appropriate level of the recommended feed amount may be transmitted to the user. Accordingly, more appropriate animal feeding management may be achieved.</p><p id="p-0222" num="0221"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a diagram showing an example of a conversion criterion for converting animal characteristic information into activity level information, according to an embodiment.</p><p id="p-0223" num="0222">Referring to <figref idref="DRAWINGS">FIG. <b>19</b></figref>, the processor of the external server <b>3000</b> according to the disclosure may determine an activity level of an animal, based on an activity level determination model <b>1910</b>. The processor may determine activity level information <b>1914</b> of the animal by applying, to the activity level determination model <b>1910</b>, dog breed information <b>1911</b> of the animal, an animal activity value <b>1912</b>, and a recommended activity value <b>1913</b> for each dog breed. In the disclosure, the dog breed information <b>1911</b> may be one of pieces of animal characteristic sub-information included in the animal characteristic information. For example, the processor of the external server <b>3000</b> may manage the dog breed information <b>1911</b> by including the dog breed information <b>1911</b> in animal physical level information among the animal characteristic information. As described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>, the animal activity value <b>1912</b> may be a measurement activity value measured by the wearable device <b>2000</b> or a processed activity value obtained by processing the measured information. A detailed description about the measurement activity value or processed activity value has been described above with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and thus details thereof are not provided again. The recommended activity value <b>1913</b> for each dog breed is a level of daily activity amount recommended for each dog breed information <b>1911</b>, and may be used to determine the activity level information <b>1914</b> through comparison with the individual animal activity value <b>1912</b>. According to an embodiment, the recommended activity value <b>1913</b> for each dog breed may be stored in the DB of the external server <b>3000</b>, and updated through communication with a related organization (National Institute of Animal Science or the like) related to corresponding information. According to another embodiment, the recommended activity value <b>1913</b> for each dog breed may be determined by using a plurality of pieces of animal activity value information received from a plurality of wearable devices. For example, the external server <b>3000</b> may obtain the animal activity value <b>612</b> for a beagle <b>611</b><i>a </i>from a plurality of wearable devices or user terminals, and perform statistical processing on the obtained animal activity value <b>612</b> to use the same to determine the recommended activity value <b>613</b> for the beagle <b>611</b><i>a</i>. In detail, animal activity values <b>612</b> of beagles <b>611</b><i>a </i>in a normal weight range may be obtained from the plurality of wearable devices or user terminals, and an average value thereof may be determined as the recommended activity value <b>613</b> for the beagles <b>611</b><i>a. </i></p><p id="p-0224" num="0223">Although it has been described above that the activity level information <b>1914</b> is determined by the external server <b>3000</b>, since the same processing may be performed by the wearable device <b>2000</b> or the user terminal <b>1000</b>, a device that performs the processing related to the determining of the activity level information <b>1914</b> is not limited to the external server <b>3000</b>.</p><p id="p-0225" num="0224">The processor of the external server <b>3000</b> according to the disclosure may convert the animal characteristic information into a first characteristic value according to a preset conversion criterion <b>1920</b>. In detail, the converted animal characteristic information may be the activity level information <b>1914</b>, and the first characteristic value resulting from the conversion may be the activity characteristic value <b>1830</b> used in an MER calculation model. The processor of the external server <b>3000</b> according to the disclosure may use additional animal characteristic sub-information to determine the activity characteristic value <b>1830</b> according to the activity level information <b>1914</b>. The animal characteristic sub-information may be animal species information (for example, dog breed information <b>1922</b>) or animal age information. The conversion criterion <b>1920</b> may be pre-stored in the DB of the external server <b>3000</b>. The conversion criterion <b>1920</b> may be stored and updated through communication with an external related organization, such as the National Institute of Animal Science. Alternatively, the processor of the external server <b>3000</b> may establish the conversion criterion <b>1920</b> for determining the activity characteristic value <b>1830</b>, based on a plurality of pieces of animal characteristic information including the same animal characteristic sub-information. For example, the processor may establish a conversion criterion such that an activity characteristic value according to activity level information of beagles is determined differently from that of golden retrievers. As shown in <figref idref="DRAWINGS">FIG. <b>19</b></figref>, the conversion criterion <b>1920</b> may determine the activity characteristic value <b>1830</b> to be 1.5 for beagles and to be 1.6 for golden retrievers, with respect to individual beings having active as the activity level information <b>1914</b>. The processor of the external server <b>3000</b> may establish such a conversion criterion <b>1920</b> by collecting a plurality of pieces of animal characteristic information having the same animal characteristic sub-information (for example, the dog breed information <b>1922</b>), and continuously update the same. In other words, for example, when an activity characteristic value of 1.5 has been assigned to beagles of which activity level information is &#x201c;Active&#x201d; on May 16, 2021, the processor may adjust the activity characteristic value according to a result of analyzing weight changes of the beagles during a certain period of time thereafter. For example, when an average weight of the beagles of which the activity characteristic value <b>1830</b> is 1.5 is increased, the processor may update a model by adjusting the activity characteristic value <b>1830</b> to 1.45. It has been described above that the external server <b>3000</b> establishes and updates the conversion criterion <b>1920</b>, and determines the activity characteristic value <b>1830</b> according to the conversion criterion <b>1920</b>, but such processing may be performed not only by the external server <b>3000</b>, but also by the user terminal <b>1000</b> and the wearable device <b>2000</b>. Also, it will be apparent that a type of animal characteristic sub-information used in the conversion criterion <b>1920</b> is not limited to the dog breed information <b>1922</b>. When a conversion criterion for determining an activity characteristic value is established and updated by analyzing a plurality of pieces of data including the same or similar pieces of animal characteristic sub-information, animal characteristic information of other animals having a physical level characteristic similar to an individual being may be reflected during MER calculation, and thus the MER calculation may be more accurately performed.</p><p id="p-0226" num="0225"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a diagram showing an example of data for generating state information <b>2040</b> of an animal.</p><p id="p-0227" num="0226">Referring to <figref idref="DRAWINGS">FIG. <b>20</b></figref>, the processor of the external server <b>3000</b> according to the disclosure may generate the state information <b>2040</b> of the animal, based on animal characteristic information. Here, the state information <b>2040</b> may be information indicating appropriateness of the animal characteristic information at the time of generating the state information <b>2040</b>. Alternatively, the state information <b>2040</b> may be information obtained by selecting one of a plurality of pieces of candidate state information that are related expressions, and converting the same into the appropriateness of the animal characteristic information at the time of generation. This will be described with reference to <figref idref="DRAWINGS">FIG. <b>20</b></figref>.</p><p id="p-0228" num="0227">Referring to <figref idref="DRAWINGS">FIG. <b>20</b></figref>, the processor of the external server <b>3000</b> may generate the state information <b>2040</b> that is a responding phrase, considering an age <b>2010</b> of the animal, a weight range <b>2020</b> of the animal, and a one-time activity amount range <b>2030</b> of the animal. In detail, with reference to an adult dog, when the activity amount range <b>2030</b> of an overweight adult dog is 20&#x2dc;, based on animal characteristic information, the processor may generate a phrase &#x201c;No more walking!! I like low-calorie food&#x2dc;&#x2dc;&#x201d; that is corresponding state information <b>2040</b> and transmit the same to the user terminal <b>1000</b> or wearable device <b>2000</b>. As such, a current state of the animal is notified to a user such that feeding and activity amount of the animal may be suitably adjusted. When generating the state information <b>2040</b> according to the disclosure, the processor may arbitrarily generate a phrase. In detail, the processor may arbitrarily select one of a plurality of pieces of candidate state information. A method by which the processor generates the state information <b>2040</b> is not limited thereto. It has been described above that the processor of the external server <b>3000</b> generates and transmits the state information <b>2040</b>, but these processes may also be performed by the user terminal <b>1000</b> and the wearable device <b>2000</b>.</p><p id="p-0229" num="0228"><figref idref="DRAWINGS">FIGS. <b>21</b> and <b>22</b></figref> respectively illustrate a wearable device <b>10</b> for managing health of an animal and a method of managing health of an animal by using the wearable device <b>10</b>, according to an embodiment of the disclosure.</p><p id="p-0230" num="0229">Here, the wearable device <b>10</b> may be in a form of a wearable device capable of being attached to the animal's collar, necklace, clothes, bag, or the like. In this case, the wearable device <b>10</b> may be manufactured in a size that does not interfere with the activity of the animal, and may be attached to the body or clothes of the animal.</p><p id="p-0231" num="0230">Referring to <figref idref="DRAWINGS">FIG. <b>21</b></figref>, the wearable device <b>10</b> may include a sensor <b>12</b>, a memory <b>13</b>, a processor <b>14</b>, and a communication module <b>15</b>.</p><p id="p-0232" num="0231">The sensor <b>12</b> may obtain activity data of the animal in units of predetermined times. The sensor <b>12</b> may include an accelerometer, a gyroscope, or a global positioning system (GPS) sensor.</p><p id="p-0233" num="0232">For example, the accelerometer is a sensor that detects a change in speed, and may detect size information measured from three vectors having x, y, and z axes. For example, when the sensor <b>12</b> includes the accelerometer, the sensor <b>12</b> may collect raw-data corresponding to acceleration information 10 to 100 times per second. In detail, the sensor <b>12</b> may collect the raw-data 30 to 70 times per second. In more detail, the sensor <b>12</b> may collect the raw-data 50 times per second. Compared to prior art, the sensor <b>12</b> obtains the raw-data more frequently per unit of predetermined time (for example, 1 second). Accordingly, the wearable device <b>10</b> or a server may infer a daily life pattern of the animal more accurately than in the prior art.</p><p id="p-0234" num="0233">As another example, the gyroscope is a sensor that detects angular velocity, and may collect rotation angle information of the animal. For example, when the sensor <b>12</b> includes the gyroscope, the sensor <b>12</b> may measure data regarding a moving direction of the animal from the angular velocity in units of seconds.</p><p id="p-0235" num="0234">The sensor <b>12</b> may collect the activity data of the animal per unit of predetermined time. For example, the sensor <b>12</b> may include the accelerometer or the gyroscope, a combination thereof, or another type of sensor.</p><p id="p-0236" num="0235">The GPS sensor may receive, from a satellite, location information indicating a current location of the wearable device <b>10</b>. When the animal equipped with the wearable device <b>10</b> performs an external activity such as a walk, the location of the animal may be tracked through a GPS signal, and the wearable device <b>10</b> may provide the location information of the animal to the user. The location of the animal may be collected through another positioning method by using a communication module, in indoors where a GPS reception signal is weak.</p><p id="p-0237" num="0236">The memory <b>13</b> may store the obtained activity data. The activity data of the animal collected by the sensor <b>12</b> may be accumulated and stored in the memory <b>13</b>. In addition, the memory <b>13</b> may record, through the processor <b>14</b>, the activity data, and a specific behavior or daily life pattern of the animal estimated through a deep learning inference model. Also, the memory <b>13</b> may record an activity log of the animal, which is obtained by processing information collected with respect to the daily life pattern or specific behavior of the animal through the processor <b>14</b>.</p><p id="p-0238" num="0237">The processor <b>14</b> may detect a health abnormality sign of the animal or manage a weight of the animal, based on the stored activity data by using the deep learning inference model.</p><p id="p-0239" num="0238">Here, there may be several types of deep learning inference models. Examples of the deep learning inference model may include a recurrent neural network (RNN) model, a convolutional long short-term memory (C-LSTM) model, and a gated recurrent unit (GRU) model, which are models that handle sequential data with respect to time.</p><p id="p-0240" num="0239">In order for the deep learning inference model of the disclosure to detect the daily life pattern and health abnormality sign of the animal or manage the weight of the animal, based on the activity data of the animal, a deep learning model having a structure of RNN, in which a previous time step is input as a state in a following layer, may be selected. Although the deep learning model having the structure of RNN model has several advantages, there may be some issues when long-term log records are input to the corresponding deep learning inference model. In this regard, in the disclosure, the health abnormality sign of the animal may be detected by mainly using an inference model, such as the C-LSTM model, the GRU model, or a combination thereof.</p><p id="p-0241" num="0240">For example, an optimal inference model is selected from among deep learning inference models to stabilize a performance of the wearable device <b>10</b> and obtain better inference results. The C-LSTM model or GRU model shows better efficiency in terms of gradient loss, congestion, and long-term dependency, than the RNN model.</p><p id="p-0242" num="0241">According to an embodiment of the disclosure, the wearable device <b>10</b> may select the C-LSTM and/or the GRU model as the deep learning inference model. The C-LSTM model may perform inference dependent on a predetermined time by adding a cell state of a previous layer as a hidden state vector in a time step of each layer. The wearable device <b>10</b> may delete some of memories up to a previous cell by adding a forget gate in some layers in the C-LSTM model. Accordingly, the wearable device <b>10</b> may prevent congestion of a function according to an increase in the amount of data to be processed when using the C-LSTM model, and collect meaningful information.</p><p id="p-0243" num="0242">The GRU model is a model having a structure more standardized than the C-LSTM model, and capable of quick calculation. Unlike the C-LSTM model that uses a cell state vector and a hidden state vector, the GRU model may only use a hidden state vector.</p><p id="p-0244" num="0243">According to an embodiment, the processor <b>14</b> may infer the daily life pattern of the animal from the activity data, by using the deep learning inference model, in operation <b>2210</b>. The deep learning inference model used in the disclosure may be referred to as &#x201c;NeuroSense algorithm&#x201d; below.</p><p id="p-0245" num="0244">For example, the processor <b>14</b> may learn, as training data, an activity data accumulation record for a predetermined long period of time, which is collected from the sensor <b>12</b>. Here, the activity data may be in a form of a graph in which magnitude of a speed change over time is recorded, and the processor <b>14</b> may store the activity data in units of time or units of days, and process the activity data into raw-data to infer the daily life pattern.</p><p id="p-0246" num="0245">The processor <b>14</b> may output, as first activity content of the animal, an intermediate output obtained by analyzing the number of repetitions of the specific behavior of the animal and an aspect of the specific behavior, through the NeuroSense algorithm. For example, the processor <b>14</b> may infer the daily life pattern of the animal, which is repeated for a predetermined time, based on the first activity content through the NeuroSense algorithm, and output the same as the intermediate output.</p><p id="p-0247" num="0246">The processor <b>14</b> may detect the health abnormality sign of the animal, based on the daily life pattern, in operation <b>2220</b>.</p><p id="p-0248" num="0247">For example, the processor <b>14</b> may determine a predetermined behavior corresponding to the activity data of the animal, based on the activity data, by using the NeuroSense algorithm. Also, the processor <b>14</b> may identify a specific behavior related to a health abnormality from among determined predetermined behaviors. In addition, the processor <b>14</b> may detect the health abnormality sign of the animal by comparing the first activity content of the animal, which is obtained by analyzing the number of repetitions of the specific behavior of the animal and the aspect of the specific behavior, estimated from the activity data, the daily life pattern of the animal, and second activity content corresponding to a normal activity range of a same breed as the animal.</p><p id="p-0249" num="0248">For example, when the animal performs specific scratching more than a threshold value than the usual by referring to the daily life pattern of the animal, the processor <b>14</b> may detect such a behavior as the health abnormality sign (for example, a suspicious sign of a skin disease).</p><p id="p-0250" num="0249">As another example, when the animal toss and turns a lot in bed or wakes up often without a deep sleep, with respect to a sleep behavior, the processor <b>14</b> may detect such a sleep behavior as the health abnormality sign of the animal. In this case, the wearable device <b>10</b> may notify the user that an &#x201c;abnormality sign&#x201d; has been found even if it is unable to accurately infer reasons for a change in a behavior pattern of the animal. When such an &#x201c;abnormality sign&#x201d; is continuously detected for a certain period of time, the wearable device <b>10</b> may transmit a countermeasure or recommendation for the &#x201c;abnormality sign&#x201d; to the user together.</p><p id="p-0251" num="0250">Scratching or licking by the animal may not be unusual even compared with the daily life pattern of the animal or daily life patterns of other animals. The NeuroSense algorithm may further consider the second activity content corresponding to the normal activity range of the same breed in order to make an inference result more suitable for the animal.</p><p id="p-0252" num="0251">For example, the NeuroSense algorithm may use a database about activity contents corresponding to normal activity ranges for each breed and age of the animal. It may be noted that more pieces of activity data may be collected when the animal is younger, and less pieces of activity data may be collected when the animal is older. For example, the NeuroSense algorithm may apply the age or the like of the animal as an additive or subtractive factor while setting a threshold value for classifying the excess or deficiency of a specific behavior of the animal.</p><p id="p-0253" num="0252">According to another embodiment, the processor <b>14</b> may manage a weight of the animal, based on the daily life pattern, in operation <b>2220</b>. The processor <b>14</b> may receive, as animal information, information about the activity data, type, age, and weight, to manage the weight of the animal. Here, the wearable device <b>10</b> may estimate a risk of obesity of the animal even if there is no some of the animal information described above. For example, even if the weight of the animal is not input by the user, the wearable device <b>10</b> may estimate the risk of obesity of the animal, based on the age and breed of the animal.</p><p id="p-0254" num="0253">Here, the processor <b>14</b> may use the GRU model as an inference model for the NeuroSense algorithm. For example, the processor <b>14</b> may learn in advance a second normal activity range corresponding to a normal weight group of the same breed as the animal or a third normal activity range corresponding to an overweight group of the same breed, and estimate the risk of obesity of the animal or determine appropriateness of a weight of a specific animal by using the same.</p><p id="p-0255" num="0254">For example, the processor <b>14</b> may calculate differences between the activity data accumulation record of the animal and normal activity amounts of the normal weight/overweight groups of the same breed, and reflect, as factors, the differences to a GRU cell to estimate the risk of obesity of the animal. A detailed description thereof will be described below with reference to <figref idref="DRAWINGS">FIG. <b>25</b></figref>.</p><p id="p-0256" num="0255">The processor <b>14</b> may upload, to a server, the intermediate output or output data using the NeuroSense algorithm, thereby sharing corresponding details with the user. Here, the server may be a server that drives an application interworking with the wearable device <b>10</b>, and the application may provide the user with a result of analyzing activity content or activity amount of the animal, or daily life pattern information of the animal. At this time, the application may process data output through the deep learning inference model in a form of an activity log of the animal, and provide the same to the user.</p><p id="p-0257" num="0256">For example, the user may obtain, through the application from the wearable device <b>10</b>, information about the animal's activity data, activity log, daily life pattern, proper weight, risk of obesity estimation value, and health abnormality sign. When the health abnormality sign of the animal is detected, the wearable device <b>10</b> may further provide a warning notification to the user through the application.</p><p id="p-0258" num="0257">The communication module <b>15</b> may support at least one communication method from among Wi-Fi, Bluetooth, and mobile communication, and the processor <b>14</b> may adaptively select a communication method supported through the communication module <b>15</b>, according to circumstances. Here, the mobile communication may include an eMTC communication method supporting LTE.</p><p id="p-0259" num="0258">For example, the processor <b>14</b> may estimate a current location of the wearable device <b>10</b>, based on a received GPS signal, and determine to switch the communication method according to a battery management scenario depending on the current location of the wearable device <b>10</b> and circumstances. A detailed description about the battery management scenario will be described below with reference to <figref idref="DRAWINGS">FIG. <b>28</b></figref>.</p><p id="p-0260" num="0259"><figref idref="DRAWINGS">FIG. <b>23</b></figref> is a diagram showing an example of processes for obtaining activity data of an animal and estimating a specific behavior of the animal from the activity data, according to an embodiment of the disclosure.</p><p id="p-0261" num="0260">First, the wearable device <b>10</b> may obtain activity data, in operation <b>2310</b>. The activity data contains size values obtained from various types of sensors, and by plotting the activity data, various types of activity data may be compared on a same plane. For example, x-axis, y-axis, and z-axis activity data of the animal may be obtained from a sensor attached to the wearable device <b>10</b>.</p><p id="p-0262" num="0261">Then, the wearable device <b>10</b> may store the obtained activity data in a memory, in operation <b>2320</b>.</p><p id="p-0263" num="0262">Next, the wearable device <b>10</b> may perform behavior estimation of the animal by using the NeuroSense algorithm, in operation <b>2330</b>. Here, the behavior estimation may include estimating behaviors of the animal corresponding to the obtained activity data, and further may further include estimating the specific behavior that may be an indicator of a health abnormality from among the behaviors of the animal, in operation <b>2340</b>. For example, the wearable device <b>10</b> may classify specific behaviors as several indicators for estimating health abnormalities of the animal, from among numerous behaviors of the animal, in operation <b>2350</b>.</p><p id="p-0264" num="0263">For example, when the wearable device <b>10</b> selects, as the indicators indicating health abnormalities, the specific behaviors, such as sleeping, licking, scratching, and drinking, the wearable device <b>10</b> may estimate the specific behavior, and analyze the number of occurrences and aspects of the specific behavior.</p><p id="p-0265" num="0264">For example, the processor <b>14</b> may classify the sleeping of the animal as restful, slightly disturbed, disrupted, or the like, by using a classifier model.</p><p id="p-0266" num="0265">As another example, the processor <b>14</b> may count the number of lickings or the number of scratchings of the animal. For example, the processor <b>14</b> may classify the licking or scratching of the animal as infrequent, occasional, elevated, severe, or the like, depending on the number of lickings or scratchings, by using the classifier model.</p><p id="p-0267" num="0266">As another example, the processor <b>14</b> compares the drinking of the animal with a predetermined average value, and classify the drinking as below average, average, above average, or the like, by using the classifier model.</p><p id="p-0268" num="0267"><figref idref="DRAWINGS">FIGS. <b>24</b>A through <b>24</b>D</figref> illustrate examples of estimating a behavior of an animal, based on activity data of the animal, according to an embodiment of the disclosure.</p><p id="p-0269" num="0268">According to an embodiment, the activity data obtained through the wearable device <b>10</b> may be specifically learned according to a behavior pattern of the animal. In this case, an image obtained by capturing the animal may be used to match a specific behavior of the animal with a pattern of the activity data. For example, the specific behavior of the animal may be recognized from the image of the animal, and the specific behavior of the animal and the activity data of the animal matching the specific behavior may be acquired through time synchronization with the activity data obtained from the wearable device <b>10</b>. Referring to <figref idref="DRAWINGS">FIG. <b>24</b>A</figref>, the wearable device <b>10</b> may overlap x-axis, y-axis, and z-axis activity data collected through a plurality of sensors, and match a pattern indicated by each graph and the behavior of the animal through the NeuroSense algorithm. In the example of <figref idref="DRAWINGS">FIG. <b>24</b>A</figref>, it may be estimated that the animal has performed behaviors, such as shaking <b>2401</b>, walking <b>2402</b>, running <b>2403</b>, and shaking <b>2404</b> for a predetermined period of time.</p><p id="p-0270" num="0269">Referring to <figref idref="DRAWINGS">FIG. <b>24</b>B</figref>, activity data obtained for each dog may be collected differently depending on a behavior aspect of a specific dog, and thus activity data obtained from a dog A and activity data obtained from a dog B may show different patterns even with same shaking.</p><p id="p-0271" num="0270">Referring to <figref idref="DRAWINGS">FIG. <b>24</b>B</figref>, shaking <b>2411</b> of the dog A and shaking <b>2412</b> of the dog B may not be accurately distinguished by the eyes of a person, but the NeuroSense algorithm is able to distinguish the shaking <b>2411</b> and the shaking <b>2412</b> by learning behavior patterns of animals. Here, a NeuroSense algorithm may use types, ages, or the like of the animals as additive or subtractive factors while estimating a behavior of each animal.</p><p id="p-0272" num="0271">Similarly, referring to <figref idref="DRAWINGS">FIGS. <b>24</b>C and <b>24</b>D</figref>, <figref idref="DRAWINGS">FIG. <b>24</b>C</figref> illustrates activity data regarding scratching <b>2431</b> of the dog A and scratching <b>2432</b> of the dog B. As another example, <figref idref="DRAWINGS">FIG. <b>24</b>D</figref> illustrates activity data regarding drinking and eating <b>2441</b> of the dog A, and drinking and eating <b>2442</b> of the dog B.</p><p id="p-0273" num="0272"><figref idref="DRAWINGS">FIG. <b>25</b></figref> illustrates an example of a frequency with respect to an estimated specific behavior of an animal, according to an embodiment of the disclosure. Referring to <figref idref="DRAWINGS">FIG. <b>25</b></figref>, a daily life pattern of the animal may be inferred from behaviors of the animal estimated for a predetermined period of time. For example, referring to <figref idref="DRAWINGS">FIG. <b>25</b></figref>, the animal has a high behavior frequency for running. Also, a behavior frequency for walking of the animal is also at an upper-middle level. Here, high or low, or a high/middle/low level of the behavior frequency may be presented as a relative value compared with an average behavior frequency of other animals.</p><p id="p-0274" num="0273">When an animal has a very little activity amount, such as walking or running, or when an activity amount of the animal that was full of activity is rapidly decreased, the wearable device <b>10</b> may detect a health abnormality sign of the animal from an activity frequency of a specific behavior of the animal.</p><p id="p-0275" num="0274"><figref idref="DRAWINGS">FIG. <b>26</b></figref> is a diagram for describing an example of detecting a health abnormality sign of an animal by using a NeuroSense algorithm, according to an embodiment of the disclosure.</p><p id="p-0276" num="0275">Referring to <figref idref="DRAWINGS">FIG. <b>26</b></figref>, pieces of data handled through the C-LSTM inference model among the NeuroSense algorithm may be largely described as below during a learning stage, an input stage, an intermediate output stage, and an output stage.</p><p id="p-0277" num="0276">In the input stage, the wearable device <b>10</b> may input, as input data <b>2410</b>, activity data of the animal to the C-LSTM inference model. Here, the wearable device <b>10</b> may perform predetermined preprocessing of performing an intermediate process using several inputs according to a predetermined time step, so as to input an input value to each layer of the C-LSTM inference model, by using the C-LSTM inference model.</p><p id="p-0278" num="0277">In the learning stage, training data <b>2420</b> may include an activity data accumulation record and second activity content corresponding to a normal activity range of a same breed as the animal. Here, the activity data accumulation record may be a record in which activity data collected in predetermined units of time is accumulated. The activity data accumulation record of the animal may each be input to a hidden layer of the C-LSTM inference model, or may be used to infer a repeated daily life pattern of the animal.</p><p id="p-0279" num="0278">For example, when activity data on the animal is collected over several days or months, the processor <b>14</b> may discover a pattern regarding behavior estimation of the animal through the C-LSTM inference model, and set the same as the normal activity range of the animal. Also, the processor <b>14</b> may monitor a change in the daily life pattern of the animal through activity data newly added after predetermined learning.</p><p id="p-0280" num="0279">In addition, the processor <b>14</b> may learn an inference model using, as a parameter, a characteristic value for each behavior corresponding to the normal activity range of the same breed. For example, the processor <b>14</b> builds a breed-specific database for each animal belonging to the same breed, while collecting the activity data of the animal and behaviors of the animal corresponding to the activity data to build a training data set for training the C-LSTM inference model via supervised learning.</p><p id="p-0281" num="0280">Here, when the training data set is built, the processor <b>14</b> may group main variables and dependent variables to calculate a correlation between variables, and the C-LSTM inference model may set the same as a parameter for detecting a health abnormality sign of the animal.</p><p id="p-0282" num="0281">The C-LSTM inference model is a type of neural network model, and may be used to output an intermediate output <b>2430</b> and output data <b>2440</b> through following operations.</p><p id="p-0283" num="0282">For example, the intermediate output <b>2430</b> may be first activity content of the animal, such as a first daily life pattern of the animal, specific behavior estimation of the animal, the number of repetitions of a specific behavior, and an aspect analysis.</p><p id="p-0284" num="0283">For example, the C-LSTM inference model may extract features of N-gram through convolution. For example, one-dimensional convolution may include a filter vector that slides over a sequence and detects features at different locations. Accordingly, n feature maps generated for n filters having a same length may be rearranged into feature representations for each window.</p><p id="p-0285" num="0284">Also, the C-LSTM inference model may perform maximum over-pooling or dynamic K max-pooling through max-pooling, and select a feature related to a specific behavior required to detect the health abnormality sign of the animal from among the features rearranged through the convolution.</p><p id="p-0286" num="0285">The C-LSTM inference model may include at least 22 layers, and a cell state in each layer may be input, as an input, to a next layer. For example, the intermediate output <b>2430</b> may be input, as a vector, in a first layer and a subsequent layer of the C-LSTM inference model.</p><p id="p-0287" num="0286">Each layer of the C-LSTM inference model may receive a previous calculation result as input to a next layer, and some layers may include a forget gate to prevent overfitting of an inference model. A fully connected (FC) layer may perform linear conversion according to a pre-set parameter, and output, as a final result, an abnormality sign detection result for an animal as a probability.</p><p id="p-0288" num="0287">Here, the C-LSTM inference model may use various types of classifiers (like Support Vector Machine), and may include setting a variable to be first applied in each layer and an appropriate weight for each variable.</p><p id="p-0289" num="0288">In the output stage, the C-LSTM inference model may detect the health abnormality sign of the animal as the output data <b>2440</b>, through at least two LSTM layers and a final layer (the FC layer).</p><p id="p-0290" num="0289">Here, when the activity data for the animal is input, the processor <b>14</b> may estimate the behavior of the animal from the activity data through the C-LSTM inference model, score specific behaviors related to the health abnormality sign from among the behaviors of the animal, and calculate a score for each behavior to analyze a behavior aspect of the behavior of the animal. Also, an analyzed activity history (second activity content) of the animal may be compared with the normal activity range by comparing the analyzed activity history with a predetermined threshold value.</p><p id="p-0291" num="0290">For example, when several behaviors have been estimated from the activity data in a first stage through the C-LSTM inference model, the specific behaviors and behavior aspects related to the health abnormality sign may be classified, in a second stage, from among the behaviors estimated in the first stage, and thus the first activity content may be analyzed. Then, based on the first activity content analyzed in the second stage, the health abnormality sign of the animal may be detected.</p><p id="p-0292" num="0291"><figref idref="DRAWINGS">FIG. <b>27</b></figref> is a diagram for describing an example of estimating a risk of obesity of an animal by using a NeuroSense algorithm, according to an embodiment of the disclosure. Here, determining of appropriateness of a weight of the animal and estimating of the risk of obesity of the animal through a GRU cell, which is an example of the NeuroSense algorithm, will be described.</p><p id="p-0293" num="0292">Referring to <figref idref="DRAWINGS">FIG. <b>27</b></figref>, an input stage, a learning stage, and an output stage (including an intermediate output) into which each input data is input in parallel by using the GRU cell will be described as below.</p><p id="p-0294" num="0293">In the input stage, the processor <b>14</b> may obtain a weight and activity data of a specific animal, and input the same to the NeuroSense algorithm, as input data <b>2710</b>. The input data <b>2710</b> is animal information, and may include activity data, and a type, age, weight, and the like of the animal. The processor <b>14</b> may input the above information to the NeuroSense algorithm by combining at least one or a plurality of pieces of the information.</p><p id="p-0295" num="0294">The processor <b>14</b> may analyze an activity amount of the animal from the activity data of the animal input through the NeuroSense algorithm. Here, the activity data may be used as a hidden state vector as a plurality of pieces of activity data collected in different time ranges according to predetermined units of time are each input to the GRU cell in parallel.</p><p id="p-0296" num="0295">In the learning stage, training data <b>2720</b> may include an activity data accumulation record, a second activity amount corresponding to a normal activity range of a normal weight group of a same breed as the animal, and/or a third activity amount corresponding to a normal activity range of an overweight group of the same breed.</p><p id="p-0297" num="0296">Here, activity data for animals of several breeds rather than the specific animal may be pre-collected. For example, a database may be built in which activity data collected for an animal of the same breed as the animal, and a corresponding second and/or third activity amount are used as a training data set.</p><p id="p-0298" num="0297">In the GRU cell, each state of the input data <b>2710</b> may be input as a hidden state vector in a next stage. Referring to <figref idref="DRAWINGS">FIG. <b>25</b></figref>, the GRU cell may calculate a final output through a predetermined intermediate estimation stage.</p><p id="p-0299" num="0298">Here, an intermediate output <b>2730</b> is a result estimated in an intermediate process for determining the appropriateness of the weight of the animal and estimating the risk of obesity of the animal, and may be obtained at any stage of the GRU cell. For example, the intermediate output <b>2730</b> may include a first activity amount of the animal estimated from the activity data, and a first daily life pattern of the animal.</p><p id="p-0300" num="0299">In a final output stage, the processor <b>14</b> may output, as output data <b>2740</b>, a result of determining the appropriateness of the weight of the animal and a result of estimating the risk of obesity of the animal. The result of estimating the risk of obesity may be presented as a probability value or an indicator corresponding to the probability value.</p><p id="p-0301" num="0300">Here, the processor <b>14</b> may determine the appropriateness of the weight of the animal by comparing the first activity amount of the animal estimated from the activity data obtained by using the NeuroSense algorithm with the second activity amount corresponding to the normal activity range of the normal weight group or the third activity amount corresponding to the normal activity range of the overweight group, from among other animal groups of a same type, and estimate the risk of obesity of the animal.</p><p id="p-0302" num="0301"><figref idref="DRAWINGS">FIG. <b>28</b></figref> is a table for describing a battery management scenario of the wearable device <b>10</b>, according to an embodiment of the disclosure. Referring to <figref idref="DRAWINGS">FIG. <b>26</b></figref>, the wearable device <b>10</b> may perform battery management by selecting an appropriate communication method according to circumstances.</p><p id="p-0303" num="0302">For example, when an animal wearing the wearable device <b>10</b> is with an owner, the wearable device <b>10</b> may first select a Bluetooth connection as a communication method with the owner's terminal (that is, the terminal currently owned by the owner). When the wearable device <b>10</b> communicates with the owner's terminal only via Bluetooth, a life (hereinafter, referred to as a battery life) of the wearable device <b>10</b> when a battery of the wearable device <b>10</b> is fully charged may be about 4 months, but the battery life is not limited thereto.</p><p id="p-0304" num="0303">Similarly, when the animal wearing the wearable device <b>10</b> is at home, Bluetooth and/or eMTC (LTE cellular) may be applied as a communication mode between the owner's terminal and the wearable device <b>10</b>, in this case, communication between the owner's terminal and the wearable device <b>10</b> may be performed every 2 to 5 minutes. In this case, the battery life of the wearable device <b>10</b> may be about 3 months, but is not limited thereto.</p><p id="p-0305" num="0304">When the animal wearing the wearable device <b>10</b> is outside, the wearable device <b>10</b> may use any one of Bluetooth and eMTC communication methods as a communication method with the owner's terminal. In this case, communication may be performed between the owner's terminal and the wearable device <b>10</b> every 2 to 5 minutes. In this case, the battery life of the wearable device <b>10</b> may be about one month, but is not limited thereto.</p><p id="p-0306" num="0305">When the animal is missing, the wearable device <b>10</b> may be switched to a rescue mode through an application of the owner's terminal. In this case, the wearable device <b>10</b> may receive a GPS signal every minute for location tracking based on the GPS signal. Also, at this time, the wearable device <b>10</b> may also use the eMTC method for communication with the application. In this case, the battery life of the wearable device <b>10</b> may be about 2 days, but is not limited thereto.</p><p id="p-0307" num="0306">The communication methods described in the above are according to a plurality of communication modes and battery usage scenarios that may be selected by the wearable device <b>10</b>, and in some cases, communication methods, such as Wi-Fi, cellular, short-distance wireless communication, and the like may be used interchangeably.</p><p id="p-0308" num="0307"><figref idref="DRAWINGS">FIG. <b>29</b></figref> illustrates an example of the wearable device <b>10</b>, according to an embodiment of the disclosure. The wearable device <b>10</b> of the disclosure is a type of smart wearable device, and may track a daily life of an animal and provide an activity log of the animal to a user.</p><p id="p-0309" num="0308">Here, data collected and analyzed by the wearable device <b>10</b> may be directly provided to the user through a communication method, such as Bluetooth, through an application interworking with the wearable device <b>10</b>, or the data may be uploaded to a server managing the application through Wi-Fi, or the like to provide various types of information to the user.</p><p id="p-0310" num="0309">Meanwhile, the disclosure may be implemented as a computer-readable recording medium having recorded thereon a program for executing the wearable device <b>10</b> for managing health of an animal on a computer.</p><p id="p-0311" num="0310">Various embodiments of the disclosure are limited to a case where a wearable device is worn on a part of a body of an animal, but may be equally applied to a case where the wearable device is worn on a part of a body of a person. In detail, the wearable device is worn on the part of the body of the person to collect real-time state information of the person, and a user terminal may receive the real-time state information of the person, determine a health abnormality type of the person, and provide a solution according to the health abnormality type.</p><p id="p-0312" num="0311">Various embodiments of the disclosure may be implemented as software (for example, a program) including one or more instructions stored in a machine-readable storage medium. For example, a processor of the machine may invoke and execute at least one of the one or more instructions stored from the storage medium. Accordingly, the machine is enabled to operate to perform at least one function according to the at least one invoked instruction. The one or more instructions may include code generated by a compiler or code executable by an interpreter. A machine-readable storage medium may be provided in a form of a non-transitory storage medium. Here, &#x2018;non-transitory&#x2019; only means that the storage medium is a tangible device and does not contain a signal (for example, electromagnetic waves). This term does not distinguish a case where data is stored in the storage medium semi-permanently and a case where the data is stored in the storage medium temporarily.</p><p id="p-0313" num="0312">According to an embodiment, a method according to various embodiments of the disclosure may be provided by being included in a computer program product. The computer program product is a product that can be traded between sellers and buyers. The computer program product may be distributed in a form of machine-readable storage medium (for example, a compact disc read-only memory (CD-ROM)), or distributed through an application store (for example, Play Store&#x2122;) or directly or online between two user devices (for example, download or upload). In the case of online distribution, at least a part of the computer program product may be temporarily stored or temporarily generated in the machine-readable storage medium such as a server of a manufacturer, a server of an application store, or a memory of a relay server.</p><p id="p-0314" num="0313">Furthermore, in the specification, the term &#x201c;unit&#x201d; may be a hardware component such as a processor or circuit and/or a software component that is executed by a hardware component such as a processor.</p><p id="p-0315" num="0314">The scope of the disclosure is defined by the appended claims rather than the detailed description, and all changes or modifications within the scope of the appended claims and their equivalents will be construed as being included in the scope of the disclosure.</p><p id="p-0316" num="0315">According to embodiments of the disclosure, health of an animal may be more efficiently managed by receiving real-time state information of the animal from a wearable device, and providing a health abnormality type and solution of the animal, based on the real-time state information.</p><p id="p-0317" num="0316">According to embodiments of the disclosure, a solution most suitable to a current health condition of an animal may be provided by updating the solution based on a performance achievement of a task provided as the solution and new real-time state information received after the task is performed.</p><p id="p-0318" num="0317">According to embodiments of the disclosure, a health abnormality type of an animal may be more accurately determined by considering not only real-time state information of an animal, but also basic information of the animal.</p><p id="p-0319" num="0318">It should be understood that embodiments described herein should be considered in a descriptive sense only and not for purposes of limitation. Descriptions of features or aspects within each embodiment should typically be considered as available for other similar features or aspects in other embodiments. While one or more embodiments have been described with reference to the figures, it will be understood by those of ordinary skill in the art that various changes in form and details may be made therein without departing from the spirit and scope as defined by the following claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A non-transitory computer-readable storage medium storing instructions configured to cause a processor for calculating a recommended feed amount based on animal characteristic information to:<claim-text>receive one or more pieces of first animal characteristic information, wherein the one or more pieces of first animal characteristic information include at least piece of activity level information of a first animal; and</claim-text><claim-text>calculate a maintenance energy requirement (MER) of the first animal, based on the received one or more pieces of first animal characteristic information and an MER calculation model.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The storage medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one piece of activity level information of the first animal is generated based on a measurement activity value measured by a wearable device attached to the first animal or a processed activity value generated based on the measurement activity value.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The storage medium of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the measurement activity value comprises an acceleration value measured by the attached wearable device according to activity of the first animal.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The storage medium of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the processed activity value comprises at least one of an activity energy value or an activity intensity value generated based on the acceleration value.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The storage medium of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the at least one piece of activity level information is generated by using an activity level determination model for determining the at least one piece of activity level information according to the measurement activity value or the processed activity value, and<claim-text>the activity level determination model generates the at least one piece of activity level information by using a level of the measurement activity value or the processed activity value compared to a recommended activity amount of the first animal.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The storage medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions further cause the processor to convert the one or more pieces of first animal characteristic information into a first characteristic value according to a preset conversion criterion,<claim-text>wherein the preset conversion criterion is constructed based on a plurality of pieces of animal characteristic information, in which at least one of pieces of animal characteristic sub-information is the same as the first animal.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The storage medium of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the animal characteristic sub-information comprises at least one of species information of an animal or animal age information.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The storage medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions further cause the processor to generate state information of the first animal based on the one or more pieces of first animal characteristic information, wherein the one or more pieces of first animal characteristic information further includes species information of the first animal.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The storage medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the state information of the first animal is generated by selecting one of one or more pieces of candidate state information, based on the species information of the first animal.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The storage medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions further cause the processor to:<claim-text>calculate a recommended feed amount for the first animal based on the MER of the first animal; and</claim-text><claim-text>provide, to a user, a notification of whether to repurchase feed, based on the recommended feed amount.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The storage medium of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the instructions further cause the processor to provide, to the user, recommended feed information based on the one or more pieces of first animal characteristic information.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A method of calculating a recommended feed amount, based on animal characteristic information, the method comprising:<claim-text>receiving, at a processor, one or more pieces of first animal characteristic information, wherein the one or more pieces of first animal characteristic information are related to one or more pieces of information measured by a wearable device attached to a first animal; and</claim-text><claim-text>calculating, at the processor, a maintenance energy requirement (MER) of the first animal, based on the received one or more pieces of first animal characteristic information and an MER calculation model.</claim-text></claim-text></claim></claims></us-patent-application>
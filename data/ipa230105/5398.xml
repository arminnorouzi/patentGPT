<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005399A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005399</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17779990</doc-number><date>20201116</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2019-214703</doc-number><date>20191127</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>09</class><subclass>G</subclass><main-group>3</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>02</class><subclass>B</subclass><main-group>27</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>3</main-group><subgroup>002</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>013</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>02</class><subclass>B</subclass><main-group>27</main-group><subgroup>0101</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>02</class><subclass>B</subclass><main-group>27</main-group><subgroup>0179</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>2354</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>2380</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>2340</main-group><subgroup>0464</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>02</class><subclass>B</subclass><main-group>2027</main-group><subgroup>0187</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>K</subclass><main-group>35</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">HEAD-UP DISPLAY, HEAD-UP DISPLAY SYSTEM, AND MOVABLE BODY</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>KYOCERA CORPORATION</orgname><address><city>Kyoto-shi, Kyoto</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KUSAFUKA</last-name><first-name>Kaoru</first-name><address><city>Setagaya-ku, Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>MURATA</last-name><first-name>Mitsuhiro</first-name><address><city>Yao-shi, Osaka</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>HASHIMOTO</last-name><first-name>Sunao</first-name><address><city>Yokohama-shi, Kanagawa</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/042682</doc-number><date>20201116</date></document-id><us-371c12-date><date>20220525</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A head-up display includes a display panel, a reflective optical element, a controller, and an obtainer. The display panel displays a first image. The reflective optical element reflects image light from the first image displayed by the display panel. The controller controls a position at which the first image is displayed on the display panel. The obtainer obtains, as positional information, a position of an eye of a user. The controller changes the position at which the first image is displayed on the display panel in accordance with the positional information.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="111.42mm" wi="158.75mm" file="US20230005399A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="217.85mm" wi="139.28mm" orientation="landscape" file="US20230005399A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="232.92mm" wi="140.55mm" orientation="landscape" file="US20230005399A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="246.30mm" wi="156.97mm" orientation="landscape" file="US20230005399A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="241.72mm" wi="152.82mm" orientation="landscape" file="US20230005399A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="211.33mm" wi="143.26mm" file="US20230005399A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="238.51mm" wi="146.47mm" orientation="landscape" file="US20230005399A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="218.95mm" wi="134.87mm" orientation="landscape" file="US20230005399A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="227.25mm" wi="127.51mm" orientation="landscape" file="US20230005399A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="229.45mm" wi="145.80mm" orientation="landscape" file="US20230005399A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="229.19mm" wi="138.18mm" orientation="landscape" file="US20230005399A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="230.21mm" wi="146.90mm" orientation="landscape" file="US20230005399A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="226.99mm" wi="129.79mm" orientation="landscape" file="US20230005399A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD</heading><p id="p-0002" num="0001">The present disclosure relates to a head-up display, a head-up display system, and a movable body.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">A known technique is described in, for example, Patent Literature 1.</p><heading id="h-0003" level="1">CITATION LIST</heading><heading id="h-0004" level="1">Patent Literature</heading><p id="p-0004" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0003">Patent Literature 1: Japanese Unexamined Patent Application Publication No. 2009-008722</li></ul></p><heading id="h-0005" level="1">BRIEF SUMMARY</heading><p id="p-0005" num="0004">A head-up display according to one embodiment of the present disclosure includes a display panel, a reflective optical element, a controller, and an obtainer. The display panel displays a first image. The reflective optical element reflects image light from the first image displayed by the display panel. The controller controls a position at which the first image is displayed on the display panel. The obtainer obtains, as positional information, a position of an eye of a user. The controller changes the position at which the first image is displayed on the display panel in accordance with the positional information.</p><p id="p-0006" num="0005">A head-up display system according to one embodiment of the present disclosure includes a head-up display and a detector. The detector detects, as positional information, a position of an eye of a user. The head-up display includes a display panel, a reflective optical element, a controller, and an obtainer. The display panel displays a first image. The reflective optical element reflects image light from the first image displayed by the display panel. The controller controls a position at which the first image is displayed on the display panel. The obtainer obtains the positional information from the detector. The controller changes the position at which the first image is displayed on the display panel in accordance with the positional information.</p><p id="p-0007" num="0006">A movable body according to one embodiment of the present disclosure includes a head-up display system. The head-up display system includes a head-up display and a detector. The detector detects, as positional information, a position of an eye of a user. The head-up display includes a display panel, a reflective optical element, a controller, and an obtainer. The display panel displays a first image. The reflective optical element reflects image light from the first image displayed by the display panel. The controller controls a position at which the first image is displayed on the display panel. The obtainer obtains the positional information from the detector. The controller changes the position at which the first image is displayed on the display panel in accordance with the positional information.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0008" num="0007">The objects, features, and advantages of the present disclosure will become more apparent from the following detailed description and the drawings.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram of an example head-up display (HUD) system mounted on a movable body.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram of an example display performed by the HUD system in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram describing an image display performed when a user's eye position is lower than in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic diagram of another example HUD system mounted on a movable body.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram of areas on a display panel shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram of the display panel shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> viewed in the depth direction.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram of an example parallax optical element shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> viewed in the depth direction.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram describing the relationship between a virtual image and the user's eyes shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram showing an area viewable with a left eye in the virtual image for the display panel.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram showing an area viewable with a right eye in the virtual image for the display panel.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram describing switching of the parallax optical element in response to a change in the positions of the user's eyes.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram of an example display performed by the HUD system in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0021" num="0020">As a head-up display (HUD) with the structure that forms the basis of a HUD according to one or more embodiments of the present disclosure, a known HUD causes images having parallax between them to reach the left and right eyes of a user and projects a virtual image in the field of view of the user to be viewed as a three-dimensional (3D) image with depth.</p><p id="p-0022" num="0021">With a HUD mounted on a movable body such as a vehicle, the user's eye positions may change depending on the sitting posture or the sifting height, thus causing an image to be less easily viewable to the user. A HUD that can provide an image easily viewable to the user as appropriate at the user's eye positions is awaited.</p><p id="p-0023" num="0022">One or more embodiments of the present disclosure will now be described with reference to the drawings. The drawings used herein are schematic and are not drawn to scale relative to the actual size of each component.</p><heading id="h-0008" level="2">Head-Up Display System</heading><p id="p-0024" num="0023">As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a head-up display system <b>1</b> according to an embodiment of the present disclosure includes a head-up display <b>2</b> and a detector <b>3</b>. The head-up display system <b>1</b> is hereafter also referred to as a HUD system <b>1</b>. The HUD system <b>1</b> may be mounted on a movable body <b>20</b>. The HUD system <b>1</b> mounted on the movable body <b>20</b> displays an image for a user <b>30</b> aboard the movable body <b>20</b>.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows the HUD system <b>1</b> mounted on the movable body <b>20</b>. In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, x-direction refers to an interocular direction of the user <b>30</b>, or the direction along a line passing through a left eye <b>31</b><i>l </i>and a right eye <b>31</b><i>r </i>of the user <b>30</b>, z-direction refers to the front-rear direction as viewed from the user <b>30</b>, and y-direction refers to the height direction orthogonal to x-direction and z-direction.</p><p id="p-0026" num="0025">The movable body according to one or more embodiments of the present disclosure includes a vehicle, a vessel, or an aircraft. The vehicle according to one or more embodiments of the present disclosure includes, but is not limited to, an automobile or an industrial vehicle, and may also include a railroad vehicle, a community vehicle, or a fixed-wing aircraft traveling on a runway. The automobile includes, but is not limited to, a passenger vehicle, a truck, a bus, a motorcycle, or a trolley bus, and may also include another vehicle traveling on a road. The industrial vehicle includes an agricultural vehicle or a construction vehicle. The industrial vehicle includes, but is not limited to, a forklift or a golf cart. The agricultural vehicle includes, but is not limited to, a tractor, a cultivator, a transplanter, a binder, a combine, or a lawn mower. The construction vehicle includes, but is not limited to, a bulldozer, a scraper, a power shovel, a crane vehicle, a dump truck, or a road roller. The vehicle includes a man-powered vehicle. The classification of the vehicle is not limited to the above. For example, the automobile may include an industrial vehicle traveling on a road, and one type of vehicle may fall within a plurality of classes. The vessel according to one or more embodiments of the present disclosure includes a jet ski, a boat, or a tanker. The aircraft according to one or more embodiments of the present disclosure includes a fixed-wing aircraft or a rotary-wing aircraft. Structure of Detector</p><p id="p-0027" num="0026">The detector <b>3</b> detects the positions of the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b>. The detector <b>3</b> outputs the detected positions of the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> to an obtainer <b>7</b>. The detector <b>3</b> may include an imaging device or a sensor. For the HUD system <b>1</b> mounted on the movable body <b>20</b> being a vehicle, the detector <b>3</b> may be installed in any of various places such as on a rearview mirror, an instrument panel, a steering wheel, or a dashboard.</p><p id="p-0028" num="0027">When the detector <b>3</b> includes an imaging device, the imaging device captures an image of a subject. The imaging device includes an image sensor. The image sensor may include, for example, a charge-coupled device (CCD) image sensor or a complementary metal-oxide-semiconductor (CMOS) image sensor. The imaging device is arranged to have the face of the user <b>30</b> being at the position of the subject. For example, the detector <b>3</b> may define a predetermined position as the origin and detect the direction and the amount of displacements of the positions of the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>from the origin. The detector <b>3</b> may detect, with two or more imaging devices, the position of at least one of the left eye <b>31</b><i>l </i>or the right eye <b>31</b><i>r </i>as the coordinates in a 3D space.</p><p id="p-0029" num="0028">The detector <b>3</b> may include no imaging device and may be connected to an external imaging device. The detector <b>3</b> may include an input terminal for receiving signals from the external imaging device. The external imaging device may be directly connected to the input terminal. The external imaging device may be connected to the input terminal indirectly through a shared network.</p><p id="p-0030" num="0029">For the detector <b>3</b> including a sensor, the sensor may be an ultrasonic sensor or an optical sensor.</p><heading id="h-0009" level="2">Structure of Head-Up Display</heading><p id="p-0031" num="0030">The HUD <b>2</b> includes a reflective optical element <b>4</b>, a controller <b>5</b>, a display panel <b>6</b>, and the obtainer <b>7</b>.</p><p id="p-0032" num="0031">The display panel <b>6</b> displays an image in response to an instruction from the controller <b>5</b>. The display panel <b>6</b> may include a flat display panel selected from a liquid crystal display (LCD), an organic electroluminescent (EL) display, an inorganic EL display, a plasma display panel (PDP), a field-emission display (FED), an electrophoresis display, and a twisting-ball display. The display panel <b>6</b> being a transmissive LCD may have a backlight on the back.</p><p id="p-0033" num="0032">The reflective optical element <b>4</b> reflects at least a part of image light from the first image displayed on the display panel <b>6</b>. The reflective optical element <b>4</b> reflects image light from the first image emitted from the display panel <b>6</b> toward the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b>. The HUD system <b>1</b> mounted on the movable body <b>20</b> being a vehicle may use a windshield of the vehicle as the reflective optical element <b>4</b>.</p><p id="p-0034" num="0033">In one of multiple embodiments, the display panel <b>6</b> emits image light directly toward the reflective optical element <b>4</b> as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The image light reflected by the reflective optical element <b>4</b> reaches the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b>. This causes the user <b>30</b> to view a virtual image V<b>1</b> of the display panel <b>6</b> reflected by the reflective optical element <b>4</b>.</p><p id="p-0035" num="0034">The controller <b>5</b> may be connected to each of the components of the HUD <b>2</b> to control these components. The controller <b>5</b> may be, for example, a processor. The controller <b>5</b> may include one or more processors. The processors may include a general-purpose processor that reads a specific program to perform a specific function, and a processor dedicated to specific processing. The dedicated processor may include an application-specific integrated circuit (ASIC). The processor may include a programmable logic device (PLD). The PLD may include a field-programmable gate array (FPGA). The controller <b>5</b> may be either a system on a chip (SoC) or a system in a package (SiP) in which one or more processors cooperate with other components.</p><p id="p-0036" num="0035">The controller <b>5</b> includes a memory. The memory includes any storage device such as a random-access memory (RAM) or a read-only memory (ROM). The memory may store any programs and information for various processes. For example, the memory may store, as a first image, a display item to be displayed. Examples of the display item include text, graphics, and animations combining text and graphics.</p><p id="p-0037" num="0036">The controller <b>5</b> controls the details and the position of the image on the display panel <b>6</b>. The controller <b>5</b> obtains information about the positions of the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> from the detector <b>3</b> through the obtainer <b>7</b>. The controller <b>5</b> can change the position at which the first image is displayed on the display panel <b>6</b> in accordance with positional information obtained from the obtainer <b>7</b>.</p><p id="p-0038" num="0037">The obtainer <b>7</b> can obtain positional information about the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> detected by the detector <b>3</b>. The detector <b>3</b> and the obtainer <b>7</b> are connected to each other through wired or wireless communication or both. For the movable body <b>20</b> being a vehicle, the detector <b>3</b> and the obtainer <b>7</b> may be connected to a vehicle network such as a controller area network (CAN). The obtainer <b>7</b> may include a connector for wired communication, such as an electrical connector or an optical connector. The obtainer <b>7</b> may include an antenna for wireless communication.</p><p id="p-0039" num="0038">The HUD <b>2</b> may further include an input unit <b>8</b> that obtains external information. For the HUD system <b>1</b> mounted on the movable body <b>20</b>, the input unit <b>8</b> can obtain information from an electronic control unit (ECU) <b>9</b> in the movable body <b>20</b>. The ECU <b>9</b> is a computer that electronically controls various devices mounted on the movable body <b>20</b>. The ECU <b>9</b> may include a navigation system or a system for controlling the inter-vehicle distance. The input unit <b>8</b> can receive a vehicle speed signal representing the vehicle speed from the ECU <b>9</b> to receive an input of the speed of the movable body <b>20</b>.</p><p id="p-0040" num="0039">The HUD <b>2</b> can cause a first image <b>11</b> to appear in the field of view of the user <b>30</b> as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The first image <b>11</b> appears in an image display area <b>12</b>. The image display area <b>12</b> is an area on the reflective optical element <b>4</b> onto which an image displayed on the display panel <b>6</b> can be projected. The controller <b>5</b> can change the position at which the first image is displayed on the display panel <b>6</b> in accordance with positional information about the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r</i>. Changing the position of the first image on the display panel <b>6</b> changes the display position of the first image <b>11</b> within the image display area <b>12</b>.</p><p id="p-0041" num="0000">Displaying with Head-Up Display</p><p id="p-0042" num="0040">As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the reflective optical element <b>4</b> may include a first reflective area <b>4</b><i>a </i>that reflects a part of image light being incident and transmits another part of the image light. The display panel <b>6</b> may project at least a part of the first image <b>11</b> onto the first reflective area <b>4</b><i>a</i>. This allows the part of the first image <b>11</b> in the first reflective area <b>4</b><i>a </i>to appear in the field of view of the user <b>30</b> in a manner superimposed on the background opposite to the user <b>30</b> from the reflective optical element <b>4</b>.</p><p id="p-0043" num="0041">The reflective optical element <b>4</b> may include a second reflective area <b>4</b><i>b </i>that reflects a part of image light being incident and substantially blocks another part of the image light. This allows the first image <b>11</b> projected onto the second reflective area <b>4</b><i>b </i>to appear clearly in the field of view of the user <b>30</b> without being superimposed on the background opposite to the user <b>30</b> from the reflective optical element <b>4</b>. For example, the display panel <b>6</b> may project a part of the first image <b>11</b> onto the second reflective area <b>4</b><i>b</i>. This allows the first image <b>11</b> to show information independent of information about the background.</p><p id="p-0044" num="0042">In the HUD system <b>1</b> mounted on the movable body <b>20</b> being a vehicle, the windshield may include a lower black portion as the second reflective area <b>4</b><i>b</i>. The lower black portion of the windshield may be referred to as a black ceramic portion. The second reflective area <b>4</b><i>b </i>in the movable body <b>20</b> may be usable for displaying information from measuring instruments such as a speedometer, a tachometer, or a direction indicator, which may be located on an instrument panel in a known movable body.</p><p id="p-0045" num="0043">The first image <b>11</b> is viewed by the user <b>30</b> differently as the positions of the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> change in y-direction. The controller <b>5</b> controls the display panel <b>6</b> to display the first image <b>11</b> at a position in the display area in a manner easily viewable to the user <b>30</b>. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, for example, the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> are at positions lower than in the example shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> due to the sitting height or the posture of the user <b>30</b>. In this case, some optical paths of image light may interfere with components inside the movable body <b>20</b>. A part of the image display area <b>12</b> located below the reflective optical element <b>4</b> is not viewable to the user <b>30</b>. The controller <b>5</b> thus causes the position at which the first image <b>11</b> is displayed on the display panel <b>6</b> to be in a range in which the first image <b>11</b> is viewable to the user <b>30</b>. The controller <b>5</b> may set the lower limit of the position at which the first image <b>11</b> is displayed in the image display area <b>12</b> in the viewable range for the user <b>30</b> on the reflective optical element <b>4</b>. The controller <b>5</b> may control the display position of the first image on the display panel <b>6</b> to cause the first image <b>11</b> to appear at a position above the lower limit in the image display area <b>12</b>.</p><p id="p-0046" num="0044">When the positions of the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> change, the positional relationship changes between the position on the display panel <b>6</b> and the position on the reflective optical element <b>4</b> viewable to the user <b>30</b>. For example, an image displayed in the second reflective area <b>4</b><i>b </i>to be viewable to the user <b>30</b> with the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>at high positions may not be displayable in the second reflective area <b>4</b><i>b </i>when the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> are at low positions. The controller <b>5</b> may thus change the position at which the first image <b>11</b> is displayed on the display panel <b>6</b> in accordance with positional information about the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b>. The controller <b>5</b> may display a specific first image <b>11</b> in the second reflective area <b>4</b><i>b </i>to allow the image to appear clearly. The controller <b>5</b> displays another specific first image <b>11</b> in the first reflective area <b>4</b><i>a </i>to cause the first image <b>11</b> to be superimposed on the intended background.</p><p id="p-0047" num="0045">As described above, the HUD system <b>1</b> according to one or more embodiments of the present disclosure can provide an image that is easily viewable to the user <b>30</b> independently of the user's eye positions.</p><p id="p-0048" num="0000">Display Position in Accordance with Speed</p><p id="p-0049" num="0046">As described above, the HUD <b>2</b> can receive, from the input unit <b>8</b>, an input of the speed at which the movable body <b>20</b> moves. The controller <b>5</b> may thus change the position at which the first image <b>11</b> is displayed on the display panel <b>6</b> in accordance with the speed of the movable body <b>20</b> in addition to the positional information about the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b>. For example, the controller <b>5</b> may change the position at which the first image <b>11</b> is displayed on the display panel <b>6</b> to cause the first image <b>11</b> to be viewable in the field of view of the user <b>30</b> at a higher position as the speed of the movable body <b>20</b> is higher. For example, the controller <b>5</b> may change the position at which the first image <b>11</b> is displayed on the display panel <b>6</b> to cause the first image <b>11</b> to be viewable in the field of view of the user <b>30</b> at a lower position as the speed of the movable body <b>20</b> is lower.</p><p id="p-0050" num="0047">The user <b>30</b> is more likely to direct the gaze farther as the speed of the movable body <b>20</b> is higher. The gaze direction of the user <b>30</b> thus shifts upward. The user <b>30</b> can view the first image <b>11</b> that is viewable at a higher position without moving the gaze greatly. The user <b>30</b> is more likely to direct the gaze toward an object located closer, such as a road surface, as the speed of the movable body <b>20</b> is lower. The gaze direction of the user <b>30</b> thus shifts downward. The user <b>30</b> can view the first image <b>11</b> that is viewable at a lower position without moving the gaze greatly.</p><p id="p-0051" num="0048">The controller <b>5</b> displays, for example, an image of a speedometer as the first image <b>11</b>. As the speed is higher, the first image <b>11</b> is displayed at a higher position. As the speed is lower, the first image <b>11</b> is displayed at a lower position. The user <b>30</b> can visually obtain rough information about the speed without viewing the first image <b>11</b> in detail.</p><p id="p-0052" num="0000">Head-Up Display System with Multiple Image Display</p><p id="p-0053" num="0049"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a HUD system <b>1</b>A according to one or more embodiments of the present disclosure that can display multiple images. The HUD system <b>1</b>A includes a HUD <b>2</b>A and a detector <b>3</b>. The HUD <b>2</b>A in the HUD system <b>1</b>A includes a reflective optical element <b>4</b>A, a controller <b>5</b>A, a display panel <b>6</b>A, an obtainer <b>7</b>A, an input unit <b>8</b>A, a parallax optical element <b>13</b>, and an optical system <b>14</b>. The reflective optical element <b>4</b>A, the controller <b>5</b>A, the display panel <b>6</b>A, the obtainer <b>7</b>A, and the input unit <b>8</b>A are similar to the reflective optical element <b>4</b>, the controller <b>5</b>, the display panel <b>6</b>, the obtainer <b>7</b>, and the input unit <b>8</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The differences between the corresponding components will now be described.</p><p id="p-0054" num="0050">As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the display panel <b>6</b>A includes a planar active area A including a first area <b>51</b> and a second area <b>52</b>. The first area <b>51</b> is located near a lower end of the reflective optical element <b>4</b>A. The first area <b>51</b> is an area in which a two-dimensional (2D) image can be displayed. The second area <b>52</b> is an area in which a parallax image viewable to the user <b>30</b> as a 3D image can be displayed. The parallax image includes a left eye image and a right eye image (described later). The right eye image has parallax with respect to the left eye image. The HUD <b>2</b>A projects a second image displayed in the first area <b>51</b> and a third image displayed in the second area <b>52</b> onto the reflective optical element <b>4</b>A to allow these images to appear in the field of view of the user <b>30</b>. The second image and the third image are included in the first image.</p><p id="p-0055" num="0051">The HUD <b>2</b>A can cause the second image to appear in the field of view of the user <b>30</b> in the same manner as the HUD <b>2</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The third image displayed by the HUD <b>2</b>A will be described below.</p><p id="p-0056" num="0052">As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the display panel <b>6</b> includes the planar active area A including multiple divisional areas. <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the second area <b>52</b> in the active area A. In <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the divisional areas are defined in u-direction and in v-direction orthogonal to u-direction. The direction orthogonal to u-direction and v-direction is referred to as w-direction. The u-direction may be referred to as a horizontal direction. The v-direction may be referred to as a vertical direction. The w-direction may be referred to as a depth direction. The u-direction is the direction corresponding to the parallax direction of the user <b>30</b>.</p><p id="p-0057" num="0053">Each divisional area corresponds to a subpixel. Thus, the active area A includes multiple subpixels arranged in a lattice in u-direction and v-direction. Each subpixel has one of the colors red (R), green (G), and blue (B). One pixel may be a set of three subpixels with R, G, and B. One pixel may include four or any other number of subpixels, instead of three subpixels. One pixel may include subpixels with a combination of colors different from R, G, and B. A pixel may be referred to as a picture element. For example, multiple subpixels included in one pixel may be arranged in the horizontal direction. Multiple subpixels having the same color may be arranged, for example, in the vertical direction.</p><p id="p-0058" num="0054">The multiple subpixels arranged in the second area <b>52</b> in the active area A form multiple subpixel groups Pg under control by the controller <b>5</b>. The multiple subpixel groups Pg are arranged repeatedly in u-direction. Each subpixel group Pg may be aligned with or shifted from the corresponding subpixel group Pg in v-direction. For example, the subpixel groups Pg are repeatedly arranged in v-direction at positions shifted by one subpixel in u-direction from the corresponding subpixel group Pg in adjacent rows. The subpixel groups Pg each include multiple subpixels in predetermined rows and columns. More specifically, the multiple subpixel groups Pg each include (2&#xd7;n&#xd7;b) subpixels P<b>1</b> to PN (N=2&#xd7;n&#xd7;b), which are consecutively arranged in b rows in v-direction and in (2&#xd7;n) columns in u-direction. In the example shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, n is 6, and b is 1. The second area <b>52</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> includes the subpixel groups Pg each including 12 subpixels P<b>1</b> to P<b>12</b> consecutively arranged in one row in v-direction and in 12 columns in u-direction. In the example shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, some of the subpixel groups Pg are denoted by reference signs.</p><p id="p-0059" num="0055">Each subpixel group Pg is the smallest unit controllable by the controller <b>5</b> to display an image. The subpixels included in each subpixel group Pg are identified using identification reference signs P<b>1</b> to PN (N=2&#xd7;n&#xd7;b). The subpixels P<b>1</b> to PN (N=2&#xd7;n&#xd7;b) included in each subpixel group Pg with the same identification reference signs are controlled by the controller <b>5</b> at the same time. Being controlled at the same time includes being controlled simultaneously and substantially simultaneously. Being controlled at the same time includes being controlled based on the same single clock and in the same frame. For example, the controller <b>5</b> can switch the image to be displayed by the subpixels P<b>1</b> from the left eye image to the right eye image at the same time in all the subpixel groups Pg.</p><p id="p-0060" num="0056">As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the parallax optical element <b>13</b> extends along the display panel <b>6</b>A. The parallax optical element <b>13</b> is separate from the second area <b>52</b> in the display panel <b>6</b>A by a gap g, or a distance. The parallax optical element <b>13</b> may be located opposite to the reflective optical element <b>4</b>A from the display panel <b>6</b>A.</p><p id="p-0061" num="0057">The parallax optical element <b>13</b> can define the traveling direction of image light emitted from the multiple subpixels. The parallax optical element <b>13</b> can substantially define a viewing zone <b>32</b> for a parallax image. The viewing zone <b>32</b> is the range of space from which the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> can view the parallax image as a 3D image. In one example, the parallax optical element <b>13</b> is a liquid crystal shutter as shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. The liquid crystal shutter includes multiple pixels P, similarly to the display panel <b>6</b>. The parallax optical element <b>13</b> being a liquid crystal shutter can control the light transmittance of each pixel P. Each pixel P in the parallax optical element <b>13</b> can switch between a high light-transmittance state and a low light-transmittance state. A pixel P with a higher light transmittance may be hereafter referred to as an open pixel. The multiple pixels P included in the parallax optical element <b>13</b> may correspond to the multiple subpixels included in the display panel <b>6</b>. The multiple pixels P in the parallax optical element <b>13</b> differ from the subpixels in the display panel <b>6</b> in that the pixels P have no color components.</p><p id="p-0062" num="0058">The parallax optical element <b>13</b> includes multiple transmissive portions <b>13</b><i>a </i>and multiple light-reducing portions <b>13</b><i>b </i>as controlled by the controller <b>5</b>. For the parallax optical element <b>13</b> being a liquid crystal shutter, the transmissive portions <b>13</b><i>a </i>include pixels P with a higher light transmittance. The light-reducing portions <b>13</b><i>b </i>include pixels P with a lower light transmittance. The light-reducing portions <b>13</b><i>b </i>are strip areas extending in a predetermined direction in the plane of the parallax optical element <b>13</b>. The light-reducing portions <b>13</b><i>b </i>define transmissive portions <b>13</b><i>a </i>between adjacent light-reducing portions <b>13</b><i>b</i>. The transmissive portions <b>13</b><i>a </i>and the light-reducing portions <b>13</b><i>b </i>extend in a predetermined direction along the active area A. The transmissive portions <b>13</b><i>a </i>and the light-reducing portions <b>13</b><i>b </i>are arranged alternately in a direction orthogonal to the predetermined direction. The transmissive portions <b>13</b><i>a </i>have a higher light transmittance than the light-reducing portions <b>13</b><i>b</i>. The transmissive portions <b>13</b><i>a </i>may have a light transmittance 10 or more times, or 100 or more times, or 1000 or more times the light transmittance of the light-reducing portions <b>13</b><i>b</i>. The light-reducing portions <b>13</b><i>b </i>have a lower light transmittance than the transmissive portions <b>13</b><i>a</i>. The light-reducing portions <b>13</b><i>b </i>may block image light.</p><p id="p-0063" num="0059">The direction in which the transmissive portions <b>13</b><i>a </i>and the light-reducing portions <b>13</b><i>b </i>extend may correspond to the direction in which the subpixel groups Pg in the display panel <b>6</b>A are arranged. The parallax optical element <b>13</b> is controlled to simultaneously cause subpixels in the subpixel groups Pg identified with the same identification reference signs P<b>1</b> to P<b>12</b> to be light-transmissive or light-reducing as viewed with the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b>.</p><p id="p-0064" num="0060">The optical system <b>14</b> causes image light from the third image emitted from the second area <b>52</b> on the display panel <b>6</b>A to travel toward the reflective optical element <b>4</b>A. The optical system <b>14</b> may have a positive refractive index. The optical system <b>14</b> with a predetermined positive refractive index causes the third image on the second area <b>52</b> to be projected as an enlarged virtual image at a position farther than the reflective optical element <b>4</b>A in the field of view of the user <b>30</b>. The optical system <b>14</b> may include a convex lens, a concave mirror, or both.</p><p id="p-0065" num="0061">Image light from the third image emitted from the second area <b>52</b> on the display panel <b>6</b>A partially transmits through the transmissive portions <b>13</b><i>a </i>and reaches the reflective optical element <b>4</b>A through the optical system <b>14</b>. The image light reaching the reflective optical element <b>4</b>A is reflected by the reflective optical element <b>4</b>A and reaches the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b>. This allows the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> to view a second virtual image V<b>2</b> in the second area <b>52</b> frontward from the reflective optical element <b>4</b>A. As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the user <b>30</b> perceives an image including a third virtual image V<b>3</b> that is a virtual image of the parallax optical element <b>13</b> appearing to define the direction of image light from the second virtual image V<b>2</b>.</p><p id="p-0066" num="0062">The user <b>30</b> thus views the third image appearing as the second virtual image V<b>2</b> through the third virtual image V<b>3</b>. In reality, the user <b>30</b> does not view the third virtual image V<b>3</b>, or the virtual image of the parallax optical element <b>13</b>. However, the third virtual image V<b>3</b> is hereafter referred to as appearing at the position at which the virtual image of the parallax optical element <b>13</b> is formed and as defining the traveling direction of image light from the second virtual image V<b>2</b>. Areas in the second virtual image V<b>2</b> viewable to the user <b>30</b> with image light reaching the position of the left eye <b>31</b><i>l </i>of the user <b>30</b> are hereafter referred to as left viewable areas VaL. Areas in the second virtual image V<b>2</b> viewable to the user <b>30</b> with image light reaching the position of the right eye <b>31</b><i>r </i>of the user <b>30</b> are referred to as right viewable areas VaR.</p><p id="p-0067" num="0063">As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, a virtual image barrier pitch VBp and a virtual image gap Vg are determined to satisfy Formula 1 and Formula 2 below using an optimum viewing distance Vd.</p><p id="p-0068" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>E:Vd</i>=(<i>n&#xd7;VHp</i>):<i>Vg</i>&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0069" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Vd:VBp</i>=(<i>Vdv+Vg</i>):(2&#xd7;<i>n&#xd7;VHp</i>)&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0070" num="0064">The virtual image barrier pitch VBp is the interval in x-direction at which the light-reducing portions <b>12</b><i>b </i>projected as the third virtual image V<b>3</b> are arranged in a direction corresponding to u-direction. The virtual image gap Vg is the distance between the third virtual image V<b>3</b> and the second virtual image V<b>2</b>. The optimum viewing distance Vd is the distance between the position of the left eye <b>31</b><i>l </i>or the right eye <b>31</b><i>r </i>of the user <b>30</b> and the third virtual image V<b>3</b>, or the virtual image of the parallax optical element <b>13</b>. An interocular distance E is the distance between the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r</i>. The interocular distance E may be, for example, 61.1 to 64.4 mm, as calculated through studies conducted by the National Institute of Advanced Industrial Science and Technology. VHp is the horizontal length of each subpixel of the virtual image. VHp is the length of each subpixel of the second virtual image V<b>2</b> in a direction corresponding to x-direction.</p><p id="p-0071" num="0065">As described above, the left viewable areas VaL in <figref idref="DRAWINGS">FIG. <b>8</b></figref> are defined on the second virtual image V<b>2</b> and viewable with the left eye <b>31</b><i>l </i>of the user <b>30</b> when image light transmitted through the transmissive portions <b>13</b><i>a </i>of the parallax optical element <b>13</b> reaches the left eye <b>31</b><i>l </i>of the user <b>30</b>. As described above, the right viewable areas VaR are defined on the second virtual image V<b>2</b> and viewable with the right eye <b>31</b><i>r </i>of the user <b>30</b> when image light transmitted through the transmissive portions <b>13</b><i>a </i>of the parallax optical element <b>13</b> reaches the right eye <b>31</b><i>r </i>of the user <b>30</b>.</p><p id="p-0072" num="0066"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows an example array of subpixels of the second virtual image V<b>2</b> as viewed with the left eye <b>31</b><i>l </i>of the user <b>30</b> using the parallax optical element <b>13</b> with an aperture ratio of 50%. The subpixels on the second virtual image V<b>2</b> are denoted by the same identification reference signs P<b>1</b> to P<b>12</b> as the subpixels shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. The parallax optical element <b>13</b> with an aperture ratio of 50% includes the transmissive portions <b>13</b><i>a </i>and the light-reducing portions <b>13</b><i>b </i>each having the same width in the interocular direction (x-direction). The second virtual image V<b>2</b> includes left light-reducing areas VbL with light reduced by the third virtual image V<b>3</b>. The left light-reducing areas VbL are less easily viewable with the left eye <b>31</b><i>l </i>of the user <b>30</b> when the image light is reduced by the light-reducing portions <b>13</b><i>b </i>on the parallax optical element <b>13</b>.</p><p id="p-0073" num="0067"><figref idref="DRAWINGS">FIG. <b>10</b></figref> shows an example array of subpixels of the second virtual image V<b>2</b> viewed with the right eye <b>31</b><i>r </i>of the user <b>30</b> when the left viewable areas VaL and the left light-reducing areas VbL located as shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref> are viewed with the right eye <b>31</b><i>r </i>of the user <b>30</b>. The second virtual image V<b>2</b> includes right light-reducing areas VbR with light reduced by the third virtual image V<b>3</b>. The right light-reducing areas VbR are less easily viewable with the right eye <b>31</b><i>r </i>of the user <b>30</b> when the image light is reduced by the light-reducing portions <b>13</b><i>b </i>on the parallax optical element <b>13</b>.</p><p id="p-0074" num="0068">With the parallax optical element <b>13</b> having an aperture ratio of 50%, the multiple left viewable areas VaL can match the multiple right light-reducing areas VbR. The multiple right viewable areas VaR can match the multiple left light-reducing areas VbL. With the parallax optical element <b>13</b> having an aperture ratio of 50%, the multiple left viewable areas VaL can include the multiple right light-reducing areas VbR. The multiple right viewable areas VaR can include the multiple left light-reducing areas VbL. Thus, the multiple right viewable areas VaR are not easily viewable with the left eye <b>31</b><i>l</i>. The multiple left viewable areas VaL are not easily viewable with the right eye <b>31</b><i>r. </i></p><p id="p-0075" num="0069">In the example shown in <figref idref="DRAWINGS">FIGS. <b>9</b> and <b>10</b></figref>, each left viewable area VaL includes the virtual image of each of the subpixels P<b>1</b> to P<b>6</b> arranged in the second area <b>52</b>. The virtual image of the subpixels P<b>7</b> to P<b>12</b> arranged in the second area <b>52</b> are less easily viewable with the left eye <b>31</b><i>l </i>of the user <b>30</b>. Each right viewable area VaR includes the virtual image of each of the subpixels P<b>7</b> to P<b>12</b> arranged in the second area <b>52</b>. The virtual image of the subpixels P<b>1</b> to P<b>6</b> arranged in the second area <b>52</b> are less easily viewable with the right eye <b>31</b><i>r </i>of the user <b>30</b>. The controller <b>5</b> can cause the subpixels P<b>1</b> to P<b>6</b> to display the left eye image. The controller <b>5</b> can cause the subpixels P<b>7</b> to P<b>12</b> to display the right eye image. This allows the left eye <b>31</b><i>l </i>of the user <b>30</b> to view the virtual image of the left eye image on the multiple left viewable areas VaL and allows the right eye <b>31</b>R of the user <b>30</b> to view the virtual image of the right eye image on the multiple right viewable areas VaR. As described above, the right eye image and the left eye image are parallax images having parallax between them. The user <b>30</b> can thus view the right eye image and the left eye image as a 3D image.</p><p id="p-0076" num="0070">A change in the positions of the eyes <b>31</b> of the user <b>30</b> changes the parts of the subpixels P<b>1</b> to P<b>12</b> used to display the virtual image viewable with the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b>. The controller <b>5</b> obtains positional information about the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> detected by the detector <b>3</b> through the obtainer <b>7</b>A. The controller <b>5</b> controls, based on the position of the left eye <b>31</b><i>l </i>of the user <b>30</b>, the parallax optical element <b>13</b> to cause the subpixels P<b>1</b> to P<b>6</b> displaying the left eye image to be viewed with the left eye <b>31</b><i>l</i>. The controller <b>5</b> controls, based on the position of the right eye <b>31</b><i>r </i>of the user <b>30</b>, the parallax optical element <b>13</b> to cause the subpixels P<b>7</b> to P<b>12</b> displaying the right eye image to be viewed with the right eye <b>31</b><i>r. </i></p><p id="p-0077" num="0071">For example, the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> observing the second virtual image V<b>2</b> as shown in <figref idref="DRAWINGS">FIGS. <b>9</b> and <b>10</b></figref> may move relatively to the left. This causes the third virtual image V<b>3</b> that is a virtual image of the parallax optical element <b>13</b> to appear to move to the right. <figref idref="DRAWINGS">FIG. <b>11</b></figref> shows the second virtual image V<b>2</b> viewable to the user <b>30</b> when the left eye <b>31</b><i>l </i>of the user <b>30</b> has moved to the left in the state shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. As the left eye <b>30</b><i>l </i>of the user <b>30</b> moves to the left, the left viewable areas VaL and the left light-reducing areas VbL move to the right.</p><p id="p-0078" num="0072">In the example shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, each left viewable area VaL includes the entire part of each of the subpixels P<b>2</b> to P<b>6</b> and a part of each of the subpixels P<b>1</b> and P<b>7</b>. Each right viewable area VaR includes the entire part of each of the subpixels P<b>8</b> to P<b>12</b> and a part of each of the subpixels P<b>7</b> and P<b>1</b>. The controller <b>5</b> controls the parallax optical element <b>13</b> to cause each left viewable area VaL to include the largest part of each of the subpixels P<b>1</b> to P<b>6</b> displaying the left eye image. For example, in response to the left eye <b>30</b><i>l </i>of the user <b>30</b> moving further to the left in the state shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, causing each left viewable area VaL to include a larger part of each subpixel P<b>7</b> than the part of each subpixel P<b>1</b> included, the controller <b>5</b> may switch open pixels P in the parallax optical element <b>13</b>. In this case, the controller <b>5</b> switches, to open pixels, pixels with a lower light transmittance in the parallax optical element <b>13</b> for which virtual images are located adjacent to the left of the left viewable areas VaL. The controller <b>5</b> switches, to pixels with a lower light transmittance, open pixels in the parallax optical element <b>13</b> for which virtual images are located adjacent to the left of the left light-reducing areas VbL. The controller <b>5</b> switches open pixels P to maintain the subpixels P<b>1</b> to P<b>6</b> displaying the left eye image to be most easily viewable with the left eye <b>30</b><i>l </i>of the user <b>30</b>. The controller <b>5</b> controls the parallax optical element <b>13</b> for the right eye <b>31</b><i>r </i>in the same manner.</p><p id="p-0079" num="0073">In some embodiments, the parallax optical element <b>13</b> may have an aperture ratio of less than 50%. When, for example, one subpixel group Pg in the second area <b>52</b> includes 12 subpixels P<b>1</b> to P<b>12</b> as in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the controller <b>5</b> may control one subpixel group Pg to constantly include five subpixels with a higher light transmittance. In the state in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the controller <b>5</b> may control the parallax optical element <b>13</b> to add another pixel P with a lower light transmittance to the left of each left light-reducing area VbL to reduce image light from the subpixel P<b>7</b>.</p><p id="p-0080" num="0074">In one of multiple embodiments, the HUD <b>2</b>A may be switchable, for the user <b>30</b>, between a first state for displaying a third image as a 3D image and a second state for displaying the third image as a 2D image in the manner described above. In the first state, the controller <b>5</b> displays a parallax image on the display panel <b>6</b>A and displays, on the parallax optical element <b>13</b>, the transmissive portions <b>13</b><i>a </i>and the light-reducing portions <b>13</b><i>b </i>for defining the traveling direction of image light. In the second state, the controller <b>5</b> displays a 2D image representing a 2D image on the display panel <b>6</b>A and causes the parallax optical element <b>13</b> to be entirely in a light transmission state to transmit image light uniformly. The controller <b>5</b> performs control to synchronize the switching of the states of the display panel <b>6</b>A and the parallax optical element <b>13</b>. This allows the HUD <b>2</b>A to select either a 2D image or a 3D image as appropriate and display the image as the third image for the user <b>30</b>.</p><p id="p-0081" num="0075">The HUD system <b>1</b>A with the above structure can display a second image <b>61</b> and a third image <b>62</b> on the reflective optical element <b>4</b>A as viewed from the user <b>30</b>, as shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>. The second image <b>61</b> appears as a 2D image in a first display area <b>63</b> corresponding to the first area <b>51</b> on the display panel <b>6</b>A. The third image <b>62</b> appears as a 3D image in a second display area <b>64</b> corresponding to the second area <b>52</b> on the display panel <b>6</b>A. The third image <b>62</b> is also switchable between a 2D image and a 3D image.</p><p id="p-0082" num="0076">The controller <b>5</b> may thus change the positions at which the second image <b>61</b> and the third image <b>62</b> are displayed in accordance with positional information about the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> obtained from the obtainer <b>7</b>A. The controller <b>5</b> may change the position at which either the second image <b>61</b> or the third image <b>62</b> is displayed alone in accordance with positional information about the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b>. For example, the controller <b>5</b> may change the position of the second image <b>61</b> on the display panel <b>6</b>A and may not change the position of the third image <b>62</b> on the display panel <b>6</b>A in accordance with positional information about the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b>. When the left eye <b>31</b><i>l </i>and the right eye <b>31</b><i>r </i>of the user <b>30</b> are at lower positions, the position of the second image <b>61</b> at a lower position as viewed from the user <b>30</b> alone can be changed to a position to be viewable to the user.</p><p id="p-0083" num="0077">The controller <b>5</b> may change the positions at which the second image <b>61</b> and the third image <b>62</b> are displayed in accordance with the speed of the movable body <b>20</b> received from the input unit <b>8</b>A. The controller <b>5</b> may change the position at which either the second image <b>61</b> or the third image <b>62</b> is displayed alone in accordance with the speed of the movable body <b>20</b>. For example, the controller <b>5</b> may change the position of the second image <b>61</b> on the display panel <b>6</b>A and may not change the position of the third image <b>62</b> on the display panel <b>6</b>A in accordance with the speed. When the speed of the movable body <b>20</b> is higher, the position of the second image <b>61</b> at a lower position as viewed from the user <b>30</b> alone can be changed to a higher position to match the gaze direction of the user.</p><p id="p-0084" num="0078">Although the above embodiments are described as typical examples, various modifications and substitutions to the embodiments are apparent to those skilled in the art without departing from the spirit and scope of the present disclosure. Thus, the above embodiments should not be construed to be restrictive, but may be variously modified or altered within the scope of the present disclosure. For example, multiple structural blocks described in the above embodiments or examples may be combined into a structural block, or each structural block may be divided. The embodiments of the present disclosure can also be implemented as a method or a program implementable by a processor included in the device, or as a storage medium storing the program. These method, program, and storage medium also fall within the scope of the present disclosure.</p><p id="p-0085" num="0079">In one or more embodiments of the present disclosure, the parallax optical element is a liquid crystal shutter. The parallax optical element is not limited to a liquid crystal shutter but may be another optical element that can substantially define the viewing zone for the parallax image. For example, the parallax optical element may be a parallax barrier plate with slits that are arranged parallel to one another. The slits allow transmission of the right eye image in the parallax image along the optical path toward the right eye and the left eye image toward the left eye. For the parallax optical element being the parallax barrier with fixed openings as described above, the controller may switch, based on the movement of the head of the user, between subpixels displaying the left eye image and subpixels displaying the right eye image on the second display panel. In this manner, the controller can continue displaying a 3D image for the user independently of any displacements of the eyes of the user.</p><p id="p-0086" num="0080">The parallax optical element may be an optical component including multiple lenticular lenses arranged parallel to one another in a flat surface. The lenticular lenses can deflect the left eye image and the right eye image in the parallax image alternately displayed on the second display panel respectively to the optical path toward the right eye and the optical path toward the left eye.</p><p id="p-0087" num="0081">The present disclosure may be implemented in the following forms.</p><p id="p-0088" num="0082">A head-up display according to one embodiment of the present disclosure includes a display panel, a reflective optical element, a controller, and an obtainer. The display panel displays a first image. The reflective optical element reflects image light from the first image displayed by the display panel. The controller controls a position at which the first image is displayed on the display panel. The obtainer obtains, as positional information, a position of an eye of a user. The controller changes the position at which the first image is displayed on the display panel in accordance with the positional information.</p><p id="p-0089" num="0083">A head-up display system according to one embodiment of the present disclosure includes a head-up display and a detector. The detector detects, as positional information, a position of an eye of a user. The head-up display includes a display panel, a reflective optical element, a controller, and an obtainer. The display panel displays a first image. The reflective optical element reflects image light from the first image displayed by the display panel. The controller controls a position at which the first image is displayed on the display panel. The obtainer obtains the positional information from the detector. The controller changes the position at which the first image is displayed on the display panel in accordance with the positional information.</p><p id="p-0090" num="0084">A movable body according to one embodiment of the present disclosure includes a head-up display system. The head-up display system includes a head-up display and a detector. The detector detects, as positional information, a position of an eye of a user. The head-up display includes a display panel, a reflective optical element, a controller, and an obtainer. The display panel displays a first image. The reflective optical element reflects image light from the first image displayed by the display panel. The controller controls a position at which the first image is displayed on the display panel. The obtainer obtains the positional information from the detector. The controller changes the position at which the first image is displayed on the display panel in accordance with the positional information.</p><p id="p-0091" num="0085">The structure according to the embodiments of the present disclosure can provide an image easily viewable to the user as appropriate at the user's eye positions.</p><p id="p-0092" num="0086">Although embodiments of the present disclosure have been described in detail, the present disclosure is not limited to the embodiments described above, and may be changed or modified in various manners without departing from the spirit and scope of the present disclosure. The components described in the above embodiments may be entirely or partially combined as appropriate unless any contradiction arises.</p><heading id="h-0010" level="1">REFERENCE SIGNS LIST</heading><p id="p-0093" num="0000"><ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0087"><b>1</b>, <b>1</b>A head-up display system (HUD system)</li>    <li id="ul0002-0002" num="0088"><b>2</b>, <b>2</b>A HUD</li>    <li id="ul0002-0003" num="0089"><b>3</b> detector</li>    <li id="ul0002-0004" num="0090"><b>4</b>, <b>4</b>A reflective optical element</li>    <li id="ul0002-0005" num="0091"><b>4</b><i>a </i>first reflective area</li>    <li id="ul0002-0006" num="0092"><b>4</b><i>b </i>second reflective area</li>    <li id="ul0002-0007" num="0093"><b>5</b> controller</li>    <li id="ul0002-0008" num="0094"><b>6</b> display panel</li>    <li id="ul0002-0009" num="0095"><b>7</b>, <b>7</b>A obtainer</li>    <li id="ul0002-0010" num="0096"><b>8</b>, <b>8</b>A input unit</li>    <li id="ul0002-0011" num="0097"><b>9</b> electronic control unit (ECU)</li>    <li id="ul0002-0012" num="0098"><b>11</b> first image</li>    <li id="ul0002-0013" num="0099"><b>12</b> image display area</li>    <li id="ul0002-0014" num="0100"><b>13</b> parallax optical element</li>    <li id="ul0002-0015" num="0101"><b>13</b><i>a </i>transmissive portion</li>    <li id="ul0002-0016" num="0102"><b>13</b><i>b </i>light-reducing portion</li>    <li id="ul0002-0017" num="0103"><b>14</b> optical system</li>    <li id="ul0002-0018" num="0104"><b>20</b> movable body</li>    <li id="ul0002-0019" num="0105"><b>30</b> user</li>    <li id="ul0002-0020" num="0106"><b>31</b>L left eye</li>    <li id="ul0002-0021" num="0107"><b>31</b>R right eye</li>    <li id="ul0002-0022" num="0108"><b>32</b> viewing zone</li>    <li id="ul0002-0023" num="0109"><b>51</b> first area</li>    <li id="ul0002-0024" num="0110"><b>52</b> second area</li>    <li id="ul0002-0025" num="0111"><b>61</b> second image</li>    <li id="ul0002-0026" num="0112"><b>62</b> third image</li>    <li id="ul0002-0027" num="0113"><b>63</b> first display area</li>    <li id="ul0002-0028" num="0114"><b>74</b> second display area</li>    <li id="ul0002-0029" num="0115">A active area</li>    <li id="ul0002-0030" num="0116">P pixel</li>    <li id="ul0002-0031" num="0117">Pg subpixel group</li>    <li id="ul0002-0032" num="0118">V<b>1</b> first virtual image</li>    <li id="ul0002-0033" num="0119">V<b>2</b> second virtual image</li>    <li id="ul0002-0034" num="0120">V<b>3</b> third virtual image</li>    <li id="ul0002-0035" num="0121">VaL left viewable area</li>    <li id="ul0002-0036" num="0122">VbL left light-reducing area</li>    <li id="ul0002-0037" num="0123">VaR right viewable area</li>    <li id="ul0002-0038" num="0124">VbR right light-reducing area</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A head-up display, comprising:<claim-text>a display panel configured to display a first image;</claim-text><claim-text>a reflective optical element configured to reflect image light from the first image displayed by the display panel;</claim-text><claim-text>a controller configured to control a position at which the first image is displayed on the display panel; and</claim-text><claim-text>an obtainer configured to obtain, as positional information, a position of an eye of a user,</claim-text><claim-text>wherein the controller changes the position at which the first image is displayed on the display panel in accordance with the positional information.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The head-up display according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the controller causes the position at which the first image is displayed on the display panel to be in a range in which the first image is viewable to the user in accordance with the positional information.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The head-up display according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the head-up display is mountable on a movable body, and further comprises an input unit configured to receive an input of a speed of the movable body, and</claim-text><claim-text>the controller changes the position at which the first image is displayed on the display panel in accordance with the speed.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The head-up display according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein<claim-text>the controller changes the position at which the first image is displayed on the display panel to cause the first image to be viewed at a higher position in a field of view of the user as the speed is higher.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The head-up display according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein<claim-text>the controller changes the position at which the first image is displayed on the display panel to cause the first image to be viewed at a lower position in a field of view of the user as the speed is lower.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The head-up display according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein<claim-text>the first image includes a second image and a third image,</claim-text><claim-text>the controller changes a position at which the second image is displayed on the display panel in accordance with the speed, and</claim-text><claim-text>the controller does not change a position at which the third image is displayed on the display panel in accordance with the speed.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The head-up display according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein<claim-text>the controller changes the position at which the second image is displayed on the display panel in accordance with the positional information.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The head-up display according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the reflective optical element includes a first reflective area to reflect a part of image light being incident and to transmit another part of the image light.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The head-up display according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein<claim-text>the controller performs control to cause projection of light for at least a part of the first image onto the first reflective area.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The head-up display according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the reflective optical element includes a second reflective area to reflect a part of image light being incident and to substantially block another part of the image light.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The head-up display according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein<claim-text>the controller performs control to cause projection of light for at least a part of the first image onto the second reflective area.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A head-up display system, comprising:<claim-text>a head-up display; and</claim-text><claim-text>a detector configured to detect, as positional information, a position of an eye of a user,</claim-text><claim-text>wherein the head-up display includes<claim-text>a display panel configured to display a first image,</claim-text><claim-text>a reflective optical element configured to reflect image light from the first image displayed by the display panel,</claim-text><claim-text>a controller configured to control a position at which the first image is displayed on the display panel, and</claim-text><claim-text>an obtainer configured to obtain the positional information from the detector, and</claim-text></claim-text><claim-text>the controller changes the position at which the first image is displayed on the display panel in accordance with the positional information.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A movable body, comprising:<claim-text>a head-up display system including<claim-text>a head-up display, and</claim-text><claim-text>a detector configured to detect, as positional information, a position of an eye of a user, wherein the head-up display includes</claim-text><claim-text>a display panel configured to display a first image,</claim-text><claim-text>a reflective optical element configured to reflect image light from the first image displayed by the display panel,</claim-text><claim-text>a controller configured to control a position at which the first image is displayed on the display panel, and</claim-text><claim-text>an obtainer configured to obtain the positional information from the detector, and</claim-text></claim-text><claim-text>the controller changes the position at which the first image is displayed on the display panel in accordance with the positional information.</claim-text></claim-text></claim></claims></us-patent-application>
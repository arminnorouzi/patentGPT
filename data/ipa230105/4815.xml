<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004816A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004816</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17716292</doc-number><date>20220408</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2021-0085534</doc-number><date>20210630</date></priority-claim><priority-claim sequence="02" kind="national"><country>KR</country><doc-number>10-2021-0114779</doc-number><date>20210830</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>10</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>105</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>0454</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e79">METHOD OF OPTIMIZING NEURAL NETWORK MODEL AND NEURAL NETWORK MODEL PROCESSING SYSTEM PERFORMING THE SAME</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>SAMSUNG ELECTRONICS CO., LTD.</orgname><address><city>Suwon-si</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Lee</last-name><first-name>Changgwun</first-name><address><city>Hwaseong-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Kim</last-name><first-name>Kyoungyoung</first-name><address><city>Suwon-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Kim</last-name><first-name>Byeoungsu</first-name><address><city>Hwaseong-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Kim</last-name><first-name>Jaegon</first-name><address><city>Hwaseong-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Yim</last-name><first-name>Hanyoung</first-name><address><city>Suwon-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>Choi</last-name><first-name>Jungmin</first-name><address><city>Hwaseong-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="06" designation="us-only"><addressbook><last-name>Ha</last-name><first-name>Sanghyuck</first-name><address><city>Yongin-si</city><country>KR</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>SAMSUNG ELECTRONICS CO., LTD.</orgname><role>03</role><address><city>Suwon-si</city><country>KR</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">In a method of optimizing a neural network model, first model information about a first neural network model is received. Device information about a first target device that is used to execute the first neural network model is received. An analysis whether the first neural network model is suitable for executing on the first target device is performed, based on the first model information, the device information, and at least one of a plurality of suitability determination algorithms. A result of the analysis is output such that the first model information and the result of the analysis are displayed on a screen.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="124.80mm" wi="135.47mm" file="US20230004816A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="156.63mm" wi="137.50mm" file="US20230004816A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="248.24mm" wi="134.03mm" file="US20230004816A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="123.53mm" wi="128.02mm" file="US20230004816A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="247.73mm" wi="137.24mm" orientation="landscape" file="US20230004816A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="247.31mm" wi="140.63mm" orientation="landscape" file="US20230004816A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="207.09mm" wi="143.09mm" file="US20230004816A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="235.71mm" wi="155.45mm" file="US20230004816A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="235.71mm" wi="144.27mm" file="US20230004816A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="201.76mm" wi="137.50mm" file="US20230004816A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="146.30mm" wi="150.45mm" file="US20230004816A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="106.93mm" wi="150.45mm" file="US20230004816A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="159.09mm" wi="128.27mm" file="US20230004816A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="209.89mm" wi="156.29mm" orientation="landscape" file="US20230004816A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="221.06mm" wi="156.21mm" orientation="landscape" file="US20230004816A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="221.06mm" wi="156.13mm" orientation="landscape" file="US20230004816A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="221.15mm" wi="156.13mm" orientation="landscape" file="US20230004816A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="220.98mm" wi="163.24mm" orientation="landscape" file="US20230004816A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="221.15mm" wi="156.13mm" orientation="landscape" file="US20230004816A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="170.69mm" wi="137.50mm" file="US20230004816A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="107.02mm" wi="131.57mm" file="US20230004816A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="190.84mm" wi="128.44mm" file="US20230004816A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="209.38mm" wi="156.21mm" orientation="landscape" file="US20230004816A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00023" num="00023"><img id="EMI-D00023" he="229.19mm" wi="156.21mm" orientation="landscape" file="US20230004816A1-20230105-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00024" num="00024"><img id="EMI-D00024" he="223.44mm" wi="156.29mm" orientation="landscape" file="US20230004816A1-20230105-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00025" num="00025"><img id="EMI-D00025" he="221.23mm" wi="156.13mm" orientation="landscape" file="US20230004816A1-20230105-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00026" num="00026"><img id="EMI-D00026" he="170.52mm" wi="137.50mm" file="US20230004816A1-20230105-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00027" num="00027"><img id="EMI-D00027" he="107.19mm" wi="131.49mm" file="US20230004816A1-20230105-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00028" num="00028"><img id="EMI-D00028" he="196.60mm" wi="128.52mm" file="US20230004816A1-20230105-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00029" num="00029"><img id="EMI-D00029" he="220.73mm" wi="156.29mm" orientation="landscape" file="US20230004816A1-20230105-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00030" num="00030"><img id="EMI-D00030" he="220.90mm" wi="156.21mm" orientation="landscape" file="US20230004816A1-20230105-D00030.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00031" num="00031"><img id="EMI-D00031" he="220.98mm" wi="156.21mm" orientation="landscape" file="US20230004816A1-20230105-D00031.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00032" num="00032"><img id="EMI-D00032" he="189.06mm" wi="156.72mm" orientation="landscape" file="US20230004816A1-20230105-D00032.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO THE RELATED APPLICATION(S)</heading><p id="p-0002" num="0001">This application is based on and claims priority under 35 USC &#xa7; 119 to Korean Patent Application No. 10-2021-0085534 filed on Jun. 30, 2021 and to Korean Patent Application No. 10-2021-0114779 filed on Aug. 30, 2021 in the Korean Intellectual Property Office (KIPO), the contents of which are herein incorporated by reference in their entireties.</p><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Field</heading><p id="p-0003" num="0002">Example embodiments relate generally to machine learning techniques, and more particularly to methods of optimizing neural network models, and neural network model processing systems performing the methods of optimizing the neural network models.</p><heading id="h-0004" level="1">2. DESCRIPTION OF THE RELATED ART</heading><p id="p-0004" num="0003">There are various methods of classifying data based on machine learning. Among them is a method of classifying data using a neural network or an artificial neural network (ANN). The ANN may be obtained by engineering a cell structure model of a human brain where a process of efficiently recognizing a pattern is performed. The ANN refers to a calculation model that is based on software or hardware and is designed to imitate biological calculation abilities by applying many artificial neurons interconnected through connection lines. The human brain consists of neurons that are basic units of a nerve, and encrypts or decrypts information according to different types of dense connections between these neurons. Artificial neurons in the ANN are obtained through simplification of biological neuron functionality. The ANN performs a cognition or learning process by interconnecting the artificial neurons having connection intensities.</p><p id="p-0005" num="0004">Recently, deep learning processes and services have been researched to overcome limitation of the ANN, and researches are conducting various research projects of analyzing and optimizing improving neural network models as the deep learning processes and services have been developed. Conventionally, optimization techniques using general-purpose algorithms have been used.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0006" num="0005">At least one example embodiment of the disclosure provides a method of efficiently optimizing a neural network model to be most appropriate or suitable for a target device.</p><p id="p-0007" num="0006">At least one example embodiment of the disclosure provides a neural network model processing system that performs the method of optimizing the neural network model.</p><p id="p-0008" num="0007">At least one example embodiment of the disclosure provides a method of efficiently operating the neural network model.</p><p id="p-0009" num="0008">According to example embodiments, in a method of optimizing a neural network model, first model information about a first neural network model is received. Device information about a first target device used to execute the first neural network model is received. An analysis whether the first neural network model is suitable for executing on the first target device is performed, based on the first model information, the device information and at least one of a plurality of suitability determination algorithms. A result of the analysis is output such that the first model information and the result of the analysis are displayed on a screen.</p><p id="p-0010" num="0009">According to example embodiments, a neural network model processing system includes an input device, a storage device, an output device and a processor. The input device receives first model information about a first neural network model and device information about a first target device used to execute the first neural network model. The storage device stores information about program routines. The program routines are configured to cause the processor to perform an analysis whether the first neural network model is suitable for executing on the first target device, based on the first model information, the device information and at least one of a plurality of suitability determination algorithms, and to generate a result of the analysis such that the first model information and the result of the analysis are displayed on a screen. The output device visually outputs the result of the analysis. The processor is connected to the input device, the storage device and the output device, and controls execution of the program routines.</p><p id="p-0011" num="0010">According to example embodiments, in a method of optimizing a neural network model, a graphical user interface (GUI) for optimizing the neural network model is provided. First model information about a first neural network model that is to be optimized is received through the GUI. Device information about a first target device used to execute the first neural network model is received through the GUI. An analysis whether the first neural network model is suitable for executing on the first target device is performed, based on the first model information, the device information and at least one of a plurality of suitability determination algorithms. A result of the analysis is visually output on the GUI such that the first model information and the result of the analysis are displayed on one screen. A first user input for selecting a first layer from among layers of the first neural network model is received through the GUI based on the result of the analysis. The first layer is changed into a second layer based on the first user input. A result of changing the first layer into the second layer is visually output on the GUI. A second user input for selecting a third layer from among the layers of the first neural network model is received through the GUI. A quantization scheme of the third layer is changed based on the second user input. A result of changing the quantization scheme of the third layer is visually output on the GUI. When performing the analysis, performance scores of a structure and the layers of the first neural network model are obtained by performing a first analysis on the first neural network model based on a first algorithm. The first algorithm is used to determine performance efficiency of the structure and the layers of the first neural network model associated with the first target device. Complexity scores of the structure and the layers of the first neural network model are obtained by performing a second analysis on the first neural network model based on a second algorithm. The second algorithm is used to analyze complexity and capacity of the structure and the layers of the first neural network model. Memory footprint scores of the structure and the layers of the first neural network model are obtained by performing a third analysis on the first neural network model based on a third algorithm. The third algorithm is used to determine memory efficiency of the structure and the layers of the first neural network model associated with the first target device. Total scores of the first neural network model are obtained based on the performance scores, the complexity scores and the memory footprint scores.</p><p id="p-0012" num="0011">According to example embodiments, in a method, a graphical user interface (GUI) is provided. First model information about a first neural network model is received. Device information about a first target device used to execute the first neural network model is received. An analysis whether the first neural network model is suitable for executing on the first target device is performed, based on the first model information, the device information and at least one of a plurality of suitability determination algorithms. A first graphical representation is displayed on the GUI such that the first model information and a result of the analysis are displayed on one screen. The first graphical representation includes the first model information and the result of the analysis. A second graphical representation is displayed on the GUI such that a result of changing at least one of the layers of the first neural network model based on the result of the analysis is displayed. The second graphical representation includes the process and the result of changing the at least one of the layers of the first neural network model.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0013" num="0012">Illustrative, non-limiting example embodiments will be more clearly understood from the following detailed description taken in conjunction with the accompanying drawings.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a flowchart illustrating a method of optimizing a neural network model according to example embodiments.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIGS. <b>2</b>, <b>3</b> and <b>4</b></figref> are block diagrams illustrating a neural network model processing system according to example embodiments.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. <b>5</b>A, <b>5</b>B, <b>5</b>C and <b>6</b></figref> are diagrams for describing examples of a neural network model that is a target of a method of optimizing a neural network model according to example embodiments.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart illustrating an example of performing an analysis in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating an example of performing a first analysis in <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example of performing an analysis in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart illustrating an example of performing a second analysis in <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart illustrating an example of performing an analysis in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIGS. <b>12</b> and <b>13</b></figref> are flowcharts illustrating examples of performing a third analysis in <figref idref="DRAWINGS">FIG. <b>11</b></figref>.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart illustrating an example of performing an analysis in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart illustrating an example of a method of optimizing a neural network model of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIGS. <b>16</b>A, <b>16</b>B, <b>16</b>C, <b>16</b>D, <b>16</b>E and <b>16</b>F</figref> are diagrams for describing an operation of <figref idref="DRAWINGS">FIG. <b>15</b></figref>.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flowchart illustrating a method of optimizing a neural network model according to example embodiments.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a flowchart illustrating an example of changing at least one of layers of a first neural network model in <figref idref="DRAWINGS">FIG. <b>17</b></figref>.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a flowchart illustrating an example of a method of optimizing a neural network model of <figref idref="DRAWINGS">FIG. <b>17</b></figref>.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIGS. <b>20</b>A, <b>20</b>B, <b>20</b>C and <b>20</b>D</figref> are diagrams for describing an operation of <figref idref="DRAWINGS">FIG. <b>19</b></figref>.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>21</b></figref> is a flowchart illustrating a method of optimizing a neural network model according to example embodiments.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>22</b></figref> is a flowchart illustrating an example of applying different quantization schemes to at least some of layers of a first neural network model in <figref idref="DRAWINGS">FIG. <b>21</b></figref>.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>23</b></figref> is a flowchart illustrating an example of a method of optimizing a neural network model of <figref idref="DRAWINGS">FIG. <b>21</b></figref>.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIGS. <b>24</b>A, <b>24</b>B and <b>24</b>C</figref> are diagrams for describing an operation of <figref idref="DRAWINGS">FIG. <b>23</b></figref>.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>25</b></figref> is a block diagram illustrating a system that performs a method of optimizing a neural network model according to example embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0035" num="0034">Various example embodiments will be described more fully with reference to the accompanying drawings, in which example embodiments are shown. The disclosure may, however, be embodied in many different forms and should not be construed as limited to the example embodiments set forth herein. Like reference numerals refer to like elements throughout this application.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a flowchart illustrating a method of optimizing a neural network model according to example embodiments.</p><p id="p-0037" num="0036">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a method of optimizing a neural network model according to example embodiments is performed and/or executed by a computer-based neural network model processing system in which at least some of components are implemented with hardware and/or software. A detailed configuration of the neural network model processing system will be described with reference to <figref idref="DRAWINGS">FIGS. <b>2</b>, <b>3</b> and <b>4</b></figref>.</p><p id="p-0038" num="0037">In the method of optimizing the neural network model according to example embodiments, first model information of a first neural network model is received (step S<b>100</b>). For example, the first neural network model may be a neural network model in which a training has been completed (e.g., a pre-trained neural network model), or may be a neural network model in which a training is being performed. In other words, the method of optimizing the neural network model according to example embodiments may be performed and/or executed after the training on the first neural network model is completed, or while the training on the first neural network model is performed. Examples of the neural network model will be described with reference to <figref idref="DRAWINGS">FIGS. <b>5</b>A, <b>5</b>B and <b>5</b>C</figref>.</p><p id="p-0039" num="0038">A training (or training operation) on a neural network model indicates a process of solving a task in an optimized manner when the task to be solved and a set of functions for the task are given, and indicates a process for improving or enhancing the performance and/or accuracy of the neural network model. For example, the training on the neural network model may include an operation of determining a network structure of the neural network model, an operation of determining parameters, such as weights, used in the neural network model, or the like. In addition, during the training on the neural network model, parameters other than an architecture and data type may be changed while the architecture and data type are maintained.</p><p id="p-0040" num="0039">Device information of a first target device used to execute or drive the first neural network model is received (step S<b>200</b>). For example, the first target device may include a processing element that executes or drives the first neural network model, and/or a neural network system (or electronic system) that includes the processing element. An example of the neural network system will be described with reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0041" num="0040">An analysis whether the first neural network model is appropriate for executing or driving on the first target device is performed, based on the first model information, the device information, and at least one of a plurality of suitability determination algorithms (step S<b>300</b>). For example, the plurality of suitability determination algorithms may include a first algorithm that is used to determine performance efficiency of the first neural network model, a second algorithm that is used to analyze complexity and capacity of the first neural network model, a third algorithm that is used to determine memory efficiency of the first neural network model, or the like. Examples of the plurality of suitability determination algorithms and the analysis in step S<b>300</b> will be described with reference to <figref idref="DRAWINGS">FIGS. <b>7</b> through <b>14</b></figref>.</p><p id="p-0042" num="0041">A result of the analysis is visualized and output such that the first model information and the result of the analysis are displayed on a screen (step S<b>400</b>). For example, step S<b>400</b> may be performed using a graphical user interface (GUI). For example, the result of the analysis may be displayed based on at least one of scores and color, and a graphic representation including the first model information and the result of the analysis may be displayed on the GUI such that the first model information and the result of the analysis are displayed together. The GUI will be described with reference to <figref idref="DRAWINGS">FIGS. <b>16</b>A, <b>16</b>B, <b>16</b>C, <b>16</b>D, <b>16</b>E, <b>16</b>F, <b>20</b>A, <b>20</b>B, <b>20</b>C, <b>20</b>D, <b>24</b>A, <b>24</b>B and <b>24</b>C</figref>.</p><p id="p-0043" num="0042">In the method of optimizing the neural network model according to example embodiments, a neural network model determined to be most appropriate or suitable for a target device may be efficiently implemented. For example, before a training is performed on a neural network model, the neural network model optimized for the target device may be designed. After the training is completed on the neural network model, it may be checked and/or determined whether the neural network model is suitable for the target device, and if necessary, the neural network model may be modified and/or a new configuration that is more suitable may be suggested. In addition, optimized performance may be obtained by applying suitable quantization scheme to each component of the neural network model. Further, the GUI for such operations may be provided. Accordingly, a user may efficiently design and modify the neural network model to be most optimized for the target device, and may apply the suitable quantization scheme.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIGS. <b>2</b>, <b>3</b> and <b>4</b></figref> are block diagrams illustrating a neural network model processing system according to example embodiments.</p><p id="p-0045" num="0044">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a neural network model processing system <b>1000</b> is a computer-based neural network model processing system, and includes a processor <b>1100</b>, a storage device <b>1200</b> and an input/output (I/O) device <b>1300</b>. The I/O device <b>1300</b> includes an input device <b>1310</b> and an output device <b>1320</b>.</p><p id="p-0046" num="0045">The processor <b>1100</b> may be used to perform the method of optimizing the neural network model according to example embodiments. For example, the processor <b>1100</b> may include a microprocessor, an application processor (AP), a digital signal processor (DSP), a graphic processing unit (GPU), or the like. Although only one processor <b>1100</b> is illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, example embodiments are not limited thereto. For example, a plurality of processors may be included in the neural network model processing system <b>1000</b>. In addition, the processor <b>1100</b> may include cache memories to increase computation capacity.</p><p id="p-0047" num="0046">The storage device <b>1200</b> may store and/or include a program (PR) <b>1210</b> for the method of optimizing the neural network model according to example embodiments. The storage device <b>1200</b> may further store and/or include suitability determination algorithms (SDA) <b>1220</b>, updating algorithms (UA) <b>1230</b> and quantization schemes (QS) <b>1240</b> that are used to perform the method of optimizing the neural network model according to example embodiments. The program <b>1210</b>, the suitability determination algorithms <b>1220</b>, the updating algorithms <b>1230</b> and the quantization schemes <b>1240</b> may be provided from the storage device <b>1200</b> to the processor <b>1100</b>.</p><p id="p-0048" num="0047">In some example embodiments, the storage device <b>1200</b> may include at least one of various non-transitory computer-readable storage mediums used to provide commands and/or data to a computer. For example, the non-transitory computer-readable storage mediums may include a volatile memory such as a static random access memory (SRAM), a dynamic random access memory (DRAM), or the like, and/or a nonvolatile memory such as a flash memory, a magnetoresistive random access memory (MRAM), a phase-change random access memory (PRAM), a resistive random access memory (RRAM), or the like. The non-transitory computer-readable storage mediums may be inserted into the computer, may be integrated in the computer, or may be connected to the computer through a communication medium such as a network and/or a wireless link.</p><p id="p-0049" num="0048">The input device <b>1310</b> may be used to receive an input for the method of optimizing the neural network model according to example embodiments. For example, the input device <b>1310</b> may receive model information MI and device information DI, and may further receive a user input. For example, the input device <b>1310</b> may include at least one of various input means, such as a keyboard, a keypad, a touch pad, a touch screen, a mouse, a remote controller, or the like.</p><p id="p-0050" num="0049">The output device <b>1320</b> may be used to provide an output for the method of optimizing the neural network model according to example embodiments. For example, the output device <b>1320</b> may provide visualized output VOUT. For example, the output device <b>1320</b> may include an output means for displaying the visualized output VOUT, such as a display device, and may further include at least one of various output means, such as a speaker, a printer, or the like.</p><p id="p-0051" num="0050">The neural network model processing system <b>1000</b> may perform the method of optimizing the neural network model according to example embodiments, which is described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. For example, the input device <b>1310</b> may receive first model information (e.g., the model information MI) of a first neural network model and device information (e.g., the device information DI) of a first target device used to execute or drive the first neural network model. The storage device <b>1200</b> may store information of program routines, and the program routines may be configured to perform an analysis whether the first neural network model is appropriate for executing on the first target device, based on the first model information, the device information and at least one of a plurality of suitability determination algorithms, and to generate a result of the analysis such that the first model information and the result of the analysis are displayed on a screen. The output device <b>1320</b> may visualize and output the result of the analysis. The processor <b>1100</b> may be connected to the input device <b>1310</b>, the storage device <b>1200</b> and the output device <b>1320</b>, and may control execution of the program routines. In addition, the neural network model processing system <b>1000</b> may perform a method of optimizing a neural network model according to example embodiments, which will be described with reference to <figref idref="DRAWINGS">FIGS. <b>17</b> and <b>21</b></figref>.</p><p id="p-0052" num="0051">Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a neural network model processing system <b>2000</b> includes a processor <b>2100</b>, an I/O device <b>2200</b>, a network interface <b>2300</b>, a random access memory (RAM) <b>2400</b>, a read only memory (ROM) <b>2500</b> and a storage device <b>2600</b>.</p><p id="p-0053" num="0052">In some example embodiments, the neural network model processing system <b>2000</b> may be a computing system. For example, the computing system may be a fixed computing system such as a desktop computer, a workstation or a server, or may be a portable computing system such as a laptop computer.</p><p id="p-0054" num="0053">The processor <b>2100</b> may be substantially the same as or similar to the processor <b>1100</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. For example, the processor <b>2100</b> may include a core or a processor core for executing an arbitrary instruction set (for example, intel architecture-32 (IA-32), 64 bit extension IA-32, x86-64, PowerPC, Sparc, MIPS, ARM, IA-64, etc.). For example, the processor <b>2100</b> may access a memory (e.g., the RAM <b>2400</b> or the ROM <b>2500</b>) through a bus, and may execute instructions stored in the RAM <b>2400</b> or the ROM <b>2500</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the RAM <b>2400</b> may store a program PR for the method of optimizing the neural network model according to example embodiments or at least some elements of the program PR, and the program PR may allow the processor <b>2100</b> to perform operations of optimizing the neural network model.</p><p id="p-0055" num="0054">In other words, the program PR may include a plurality of instructions and/or procedures executable by the processor <b>2100</b>, and the plurality of instructions and/or procedures included in the program PR may allow the processor <b>2100</b> to perform the method of optimizing the neural network model according to example embodiments. Each of the procedures may denote a series of instructions for performing a certain task. A procedure may be referred to as a function, a routine, a subroutine, or a subprogram. Each of the procedures may process data provided from the outside and/or data generated by another procedure.</p><p id="p-0056" num="0055">The storage device <b>2600</b> may be substantially the same as or similar to the storage device <b>1200</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. For example, the storage device <b>2600</b> may store the program PR, and may store suitability determination algorithms SDA, updating algorithms UA and quantization schemes QS. The program PR or at least some elements of the program PR may be loaded from the storage device <b>2600</b> to the RAM <b>2400</b> before being executed by the processor <b>2100</b>. The storage device <b>2600</b> may store a file written in a program language, and the program PR generated by a compiler or at least some elements of the program PR may be loaded to the RAM <b>2400</b>.</p><p id="p-0057" num="0056">The storage device <b>2600</b> may store data, which is to be processed by the processor <b>2100</b>, or data obtained through processing by the processor <b>2100</b>. The processor <b>2100</b> may process the data stored in the storage device <b>2600</b> to generate new data, based on the program PR and may store the generated data in the storage device <b>2600</b>.</p><p id="p-0058" num="0057">The I/O device <b>2200</b> may be substantially the same as or similar to the I/O device <b>1300</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The I/O device <b>2200</b> may include an input device, such as a keyboard, a pointing device, or the like, and may include an output device such as a display device, a printer, or the like. For example, a user may trigger, through the I/O devices <b>2200</b>, execution of the program PR by the processor <b>2100</b>, may input the model information MI and the device information DI in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and/or a user input UI in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, and may check the visualized output VOUT in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and/or a graphical representation GR in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0059" num="0058">The network interface <b>2300</b> may provide access to a network outside the neural network model processing system <b>2000</b>. For example, the network may include a plurality of computing systems and communication links, and the communication links may include wired links, optical links, wireless links, or arbitrary other type links. The model information MI and the device information DI in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and/or the user input UI in <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be provided to the neural network model processing system <b>2000</b> through the network interface <b>2300</b>, and the visualized output VOUT in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and/or the graphical representation GR in <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be provided to another computing system through the network interface <b>2300</b>.</p><p id="p-0060" num="0059">Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a neural network model optimizing module <b>100</b> may be executed and/or controlled by the neural network model processing systems <b>1000</b> and <b>2000</b> of <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>. The neural network model optimizing module <b>100</b> may include a GUI control module <b>200</b> and an analysis module <b>300</b>, and may further include an updating module <b>400</b> and a quantization module <b>500</b>. The neural network model optimizing module <b>100</b> may provide a GUI for optimizing a neural network model.</p><p id="p-0061" num="0060">Herein, the term &#x201c;module&#x201d; may indicate, but is not limited to, a software and/or hardware component, such as a field programmable gate array (FPGA) or an application specific integrated circuit (ASIC), which performs certain tasks. A module may be configured to reside in a tangible addressable storage medium and be configured to execute on one or more processors. For example, a &#x201c;module&#x201d; may include components such as software components, object-oriented software components, class components and task components, and processes, functions, routines, segments of program code, drivers, firmware, microcode, circuitry, data, databases, data structures, tables, arrays, and variables. A &#x201c;module&#x201d; may be divided into a plurality of &#x201c;modules&#x201d; that perform detailed functions.</p><p id="p-0062" num="0061">The analysis module <b>300</b> may perform an analysis (or analyzing operation) whether a neural network model is appropriate for executing on a target device, based on suitability determination algorithms (e.g., the suitability determination algorithms SDA in <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>).</p><p id="p-0063" num="0062">The analysis module <b>300</b> may include a pre-listed table (PT) <b>310</b> for the target device, a performance estimator (PE) <b>320</b>, a pre-trained deep learning model (PM) <b>330</b> for the target device, a complexity determining unit (CD) <b>340</b>, a capacity measuring unit (CM) <b>350</b>, and a memory estimator (ME) <b>360</b>. Detailed operations associated with the analysis using each component will be described with reference to <figref idref="DRAWINGS">FIGS. <b>7</b> through <b>14</b></figref>.</p><p id="p-0064" num="0063">The updating module <b>400</b> may perform an update (or updating algorithms) on the neural network model based on updating algorithms (e.g., the updating algorithms UA in <figref idref="DRAWINGS">FIGS. <b>2</b></figref> and <b>3</b>). For example, the update on the neural network model may include a setting change, a layer change, or the like. Detailed operations associated with the update will be described with reference to <figref idref="DRAWINGS">FIG. <b>17</b></figref>.</p><p id="p-0065" num="0064">The quantization module <b>500</b> may perform a quantization (or quantizing operation) on the neural network model based on quantization schemes (e.g., the quantization schemes QS in <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>). Detailed operations associated with the quantization will be described with reference to <figref idref="DRAWINGS">FIG. <b>21</b></figref>.</p><p id="p-0066" num="0065">The GUI control module <b>200</b> may control a GUI to perform an optimization on the neural network model. For example, the GUI control module <b>200</b> may control the GUI to receive a user input UI and to output a graphical representation GR. For example, the user input UI may include the model information MI and the device information DI in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and the graphical representation GR may correspond to the visualized output VOUT in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0067" num="0066">In some example embodiments, at least some elements of the neural network model optimizing module <b>100</b> may be implemented as instruction codes or program routines (e.g., a software program). For example, the instruction codes or the program routines may be executed by a computer-based electronic system, and may be stored in any storage device located inside or outside the computer-based electronic system. In other example embodiments, at least some elements of the neural network model optimizing module <b>100</b> may be implemented as hardware. For example, at least some elements of the neural network model optimizing module <b>100</b> may be included in a computer-based electronic system.</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIGS. <b>5</b>A, <b>5</b>B, <b>5</b>C and <b>6</b></figref> are diagrams for describing examples of a neural network model that is a target of a method of optimizing a neural network model according to example embodiments.</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIGS. <b>5</b>A, <b>5</b>B and <b>5</b>C</figref> illustrate examples of a network structure of a neural network model, and <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an example of a neural network system that is used to execute and/or drive the neural network model. For example, the neural network model may include at least one of an artificial neural network (ANN) model, a convolutional neural network (CNN) model, a recurrent neural network (RNN) model, a deep neural network (DNN) model, or the like. However, example embodiments are not limited thereto. For another example, the neural network model may include a variety of learning models, such as deconvolutional neural networks, stacked neural networks (SNN), state-space dynamic neural networks (SSDNN), deep belief networks (DBN), generative adversarial networks (GAN), and/or restricted Boltzmann machines (RBM). Alternatively or additionally, the neural network model may include other forms of machine learning models, such as, for example, linear and/or logistic regression, statistical clustering, Bayesian classification, decision trees, dimensionality reduction such as principal component analysis, and expert systems; and/or combinations thereof, including ensembles such as random forests.</p><p id="p-0070" num="0069">Referring to <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, a general neural network may include an input layer IL, a plurality of hidden layers HL<b>1</b>, HL<b>2</b>, . . . , HLn and an output layer OL.</p><p id="p-0071" num="0070">The input layer IL may include i input nodes x<sub>1</sub>, x<sub>2</sub>, . . . , x<sub>i</sub>, where i is a natural number. Input data (e.g., vector input data) IDAT whose length is i may be input to the input nodes x<sub>1</sub>, x<sub>2</sub>, . . . , x<sub>i </sub>such that each element of the input data IDAT is input to a respective one of the input nodes x<sub>1</sub>, x<sub>2</sub>, . . . , x<sub>i</sub>.</p><p id="p-0072" num="0071">The plurality of hidden layers HL<b>1</b>, HL<b>2</b>, HLn may include n hidden layers, where n is a natural number, and may include a plurality of hidden nodes h<sup>1</sup><sub>1</sub>, h<sup>1</sup><sub>2</sub>, h<sup>1</sup><sub>3</sub>, h<sup>1</sup><sub>m</sub>, h<sup>2</sup><sub>1</sub>, h<sup>2</sup><sub>2</sub>, h<sup>2</sup><sub>3</sub>, . . . h<sup>2</sup><sub>m</sub>, h<sup>n</sup><sub>1</sub>, h<sup>n</sup><sub>2</sub>, h<sup>n</sup><sub>3</sub>, . . . h<sup>n</sup><sub>m</sub>. For example, the hidden layer HL<b>1</b> may include m hidden nodes h<sup>1</sup><sub>1</sub>, h<sup>1</sup><sub>2</sub>, h<sup>1</sup><sub>3</sub>, . . . h<sup>1</sup><sub>m</sub>, the hidden layer HL<b>2</b> may include m hidden nodes h<sup>2</sup><sub>1</sub>, h<sup>2</sup><sub>2</sub>, h<sup>2</sup><sub>3</sub>, . . . , h<sup>2</sup><sub>m</sub>, and the hidden layer HLn may include m hidden nodes h<sup>n</sup><sub>1</sub>, h<sup>n</sup><sub>2</sub>, h<sup>n</sup><sub>3</sub>, . . . , h<sup>n</sup><sub>m</sub>, where m is a natural number.</p><p id="p-0073" num="0072">The output layer OL may include j output nodes y<sub>1</sub>, y<sub>2</sub>, . . . y<sub>j</sub>, where j is a natural number. Each of the output nodes y<sub>1</sub>, y<sub>2</sub>, . . . y<sub>j </sub>may correspond to a respective one of classes to be categorized. The output layer OL may generate output values (e.g., class scores or numerical output such as a regression variable) and/or output data ODAT associated with the input data IDAT for each of the classes. In some example embodiments, the output layer OL may be a fully-connected layer and may indicate, for example, a probability that the input data IDAT corresponds to a car.</p><p id="p-0074" num="0073">A structure of the neural network illustrated in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> may be represented by information on branches (or connections) between nodes illustrated as lines, and a weighted value assigned to each branch, which is not illustrated. In some neural network models, nodes within one layer may not be connected to one another, but nodes of different layers may be fully or partially connected to one another. In some other neural network models, such as unrestricted Boltzmann machines, at least some nodes within one layer may also be connected to other nodes within one layer in addition to (or alternatively with) one or more nodes of other layers.</p><p id="p-0075" num="0074">Each node (e.g., the node WO may receive an output of a previous node (e.g., the node x<sub>1</sub>), may perform a computing operation, computation or calculation on the received output, and may output a result of the computing operation, computation or calculation as an output to a next node (e.g., the node h<sup>2</sup><sub>1</sub>). Each node may calculate a value to be output by applying the input to a specific function, e.g., a nonlinear function.</p><p id="p-0076" num="0075">In some example embodiments, the structure of the neural network is set in advance, and the weighted values for the connections between the nodes are set appropriately by using data having an already known answer of which class the data belongs to (sometimes referred to as a &#x201c;label&#x201d;). The data with the already known answer is sometimes referred to as &#x201c;training data&#x201d;, and a process of determining the weighted value is sometimes referred to as &#x201c;training&#x201d;. The neural network &#x201c;learns&#x201d; to associate the data with corresponding labels during the training process. A group of an independently trainable structure and the weighted value is sometimes referred to as a &#x201c;model&#x201d;, and a process of predicting, by the model with the determined weighted value, which class input data belongs to, and then outputting the predicted value, is sometimes referred to as a &#x201c;testing&#x201d; process.</p><p id="p-0077" num="0076">The general neural network illustrated in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> may not be suitable for handling input image data (or input sound data) because each node (e.g., the node h<sup>1</sup><sub>1</sub>) is connected to all nodes of a previous layer (e.g., the nodes x<sub>i</sub>, x<sub>2</sub>, . . . , x<sub>i </sub>included in the layer IL) and then the number of weighted values drastically increases as the size of the input image data increases. Thus, a CNN, which is implemented by combining the filtering technique with the general neural network, has been researched such that a two-dimensional image, as an example of the input image data, is efficiently trained by the CNN.</p><p id="p-0078" num="0077">Referring to <figref idref="DRAWINGS">FIG. <b>5</b>B</figref>, a CNN may include a plurality of layers CONV<b>1</b>, RELU<b>1</b>, CONV<b>2</b>, RELU<b>2</b>, POOL<b>1</b>, CONV<b>3</b>, RELU<b>3</b>, CONV<b>4</b>, RELU<b>4</b>, POOL<b>2</b>, CONV<b>5</b>, RELU<b>5</b>, CONV<b>6</b>, RELU<b>6</b>, POOL<b>3</b> and FC. Here, CONV is a convolution layer, RELU is a Rectified Linear Unit, POOL is a pooling layer and FC is a fully connected layer.</p><p id="p-0079" num="0078">Unlike the general neural network, each layer of the CNN may have three dimensions of a width, a height and a depth, and thus data that is input to each layer may be volume data having three dimensions of a width, a height and a depth. For example, if an input image in <figref idref="DRAWINGS">FIG. <b>5</b>B</figref> has a size of 32 widths (e.g., 32 pixels) and 32 heights and three color channels R, G and B, input data IDAT corresponding to the input image may have a size of 32*32*3. The input data IDAT in <figref idref="DRAWINGS">FIG. <b>5</b>B</figref> may be referred to as input volume data or input activation volume.</p><p id="p-0080" num="0079">Each of the convolutional layers CONV<b>1</b>, CONV<b>2</b>, CONV<b>3</b>, CONV<b>4</b>, CONV<b>5</b> and CONV<b>6</b> may perform a convolutional operation on input volume data. In an image processing, the convolutional operation indicates an operation in which image data is processed based on a mask with weighted values and an output value is obtained by multiplying input values by the weighted values and adding up the total multiplication results. The mask may be referred to as a filter, a window or a kernel.</p><p id="p-0081" num="0080">Parameters of each convolutional layer may include a set of learnable filters. Every filter may be small spatially (along a width and a height), but may extend through the full depth of an input volume. For example, during the forward pass, each filter may be slid (e.g., convolved) across the width and height of the input volume, and dot products may be computed between the entries of the filter and the input at any position. As the filter is slid over the width and height of the input volume, a two-dimensional activation map corresponding to responses of that filter at every spatial position may be generated. As a result, an output volume may be generated by stacking these activation maps along the depth dimension. For example, if input volume data having a size of 32*32*3 passes through the convolutional layer CONV<b>1</b> having four filters with zero-padding, output volume data of the convolutional layer CONV<b>1</b> may have a size of 32*32*12 (e.g., a depth of volume data increases).</p><p id="p-0082" num="0081">Each of the RELU layers RELU<b>1</b>, RELU<b>2</b>, RELU<b>3</b>, RELU<b>4</b>, RELU<b>5</b> and RELU<b>6</b> may perform a rectified linear unit (RELU) operation that corresponds to an activation function defined by, e.g., a function f(x)=max(0, x) (e.g., an output is zero for all negative input x). For example, if input volume data having a size of 32*32*12 passes through the RELU layer RELU<b>1</b> to perform the rectified linear unit operation, output volume data of the RELU layer RELU<b>1</b> may have a size of 32*32*12 (e.g., a size of volume data is maintained).</p><p id="p-0083" num="0082">Each of the pooling layers POOL<b>1</b>, POOL<b>2</b> and POOL<b>3</b> may perform a down-sampling operation on input volume data along spatial dimensions of width and height. For example, four input values arranged in a 2*2 matrix formation may be converted into one output value based on a 2*2 filter. For example, a maximum value of four input values arranged in a 2*2 matrix formation may be selected based on 2*2 maximum pooling, or an average value of four input values arranged in a 2*2 matrix formation may be obtained based on 2*2 average pooling. For example, if input volume data having a size of 32*32*12 passes through the pooling layer POOL<b>1</b> having a 2*2 filter, output volume data of the pooling layer POOL<b>1</b> may have a size of 16*16*12 (e.g., a width and a height of volume data decreases, and a depth of volume data is maintained).</p><p id="p-0084" num="0083">Typically, one convolutional layer (e.g., CONV<b>1</b>) and one RELU layer (e.g., RELU<b>1</b>) may form a pair of CONV/RELU layers in the CNN, pairs of the CONV/RELU layers may be repeatedly arranged in the CNN, and the pooling layer may be periodically inserted in the CNN, thereby reducing a spatial size of image and extracting a characteristic of image.</p><p id="p-0085" num="0084">The output layer or fully-connected layer FC may output results (e.g., class scores) of the input volume data IDAT for each of the classes. For example, the input volume data IDAT corresponding to the two-dimensional image may be converted into a one-dimensional matrix or vector as the convolutional operation and the down-sampling operation are repeated. For example, the fully-connected layer FC may indicate probabilities that the input volume data IDAT corresponds to a car, a truck, an airplane, a ship and a horse.</p><p id="p-0086" num="0085">The types and number of layers included in the CNN may not be limited to an example described with reference to <figref idref="DRAWINGS">FIG. <b>5</b>B</figref> and may be changed according to example embodiments. In addition, although not illustrated in <figref idref="DRAWINGS">FIG. <b>5</b>B</figref>, the CNN may further include other layers such as a softmax layer for converting score values corresponding to predicted results into probability values, a bias adding layer for adding at least one bias, or the like.</p><p id="p-0087" num="0086">Referring to <figref idref="DRAWINGS">FIG. <b>5</b>C</figref>, a RNN may include a repeating structure using a specific node or cell N illustrated on the left side of <figref idref="DRAWINGS">FIG. <b>5</b>C</figref>.</p><p id="p-0088" num="0087">A structure illustrated on the right side of <figref idref="DRAWINGS">FIG. <b>5</b>C</figref> may indicate that a recurrent connection of the RNN illustrated on the left side is unfolded (or unrolled). The term &#x201c;unfolded&#x201d; means that the network is written out or illustrated for the complete or entire sequence including all nodes NA, NB and NC. For example, if the sequence of interest is a sentence of 3 words, the RNN may be unfolded into a 3-layer neural network, one layer for each word (e.g., without recurrent connections or without cycles).</p><p id="p-0089" num="0088">In the RNN in <figref idref="DRAWINGS">FIG. <b>5</b>C</figref>, X indicates an input of the RNN. For example, X<sub>t </sub>may be an input at time step t, and X<sub>t&#x2212;1 </sub>and X<sub>t+1 </sub>may be inputs at time steps t&#x2212;1 and t+1, respectively.</p><p id="p-0090" num="0089">In the RNN in <figref idref="DRAWINGS">FIG. <b>5</b>C</figref>, S indicates a hidden state. For example, S<sub>t </sub>may be a hidden state at the time step t, and S<sub>t&#x2212;1 </sub>and S<sub>t+1 </sub>may be hidden states at the time steps t&#x2212;1 and t+1, respectively. The hidden state may be calculated based on a previous hidden state and an input at a current step. For example, S<sub>t</sub>=f(UX<sub>t</sub>+WS<sub>t&#x2212;1</sub>). For example, the function f may be generally a nonlinearity function such as tanh or RELU. S<sub>&#x2212;1</sub>, which is required to calculate a first hidden state, may be typically initialized to all zeroes.</p><p id="p-0091" num="0090">In the RNN in <figref idref="DRAWINGS">FIG. <b>5</b>C</figref>, O indicates an output of the RNN. For example, O<sub>t </sub>may be an output at the time step t, and O<sub>t&#x2212;1 </sub>and O<sub>t+1 </sub>may be outputs at the time steps t&#x2212;1 and t+1, respectively. For example, if it is required to predict a next word in a sentence, it would be a vector of probabilities across a vocabulary. For example, O<sub>t</sub>=softmax(VS<sub>t</sub>).</p><p id="p-0092" num="0091">In the RNN in <figref idref="DRAWINGS">FIG. <b>5</b>C</figref>, the hidden state may be a &#x201c;memory&#x201d; of the network. For example, the RNN may have a &#x201c;memory&#x201d; which captures information about what has been calculated so far. The hidden state S<sub>t </sub>may capture information about what happened in all the previous time steps. The output O<sub>t </sub>may be calculated solely based on the memory at the current time step t. In addition, unlike a traditional neural network, which uses different parameters at each layer, the RNN may share the same parameters (e.g., U, V and W in <figref idref="DRAWINGS">FIG. <b>5</b>C</figref>) across all time steps. This may indicate the fact that the same task may be performed at each step, only with different inputs. This may greatly reduce the total number of parameters required to be trained or learned.</p><p id="p-0093" num="0092">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a neural network system <b>600</b> may include a plurality of heterogeneous resources for executing and/or driving a neural network model, and a resource manager <b>601</b> for managing and/or controlling the plurality of heterogeneous resources.</p><p id="p-0094" num="0093">The plurality of heterogeneous resources may include a central processing unit (CPU) <b>610</b>, a neural processing unit (NPU) <b>620</b>, a graphic processing unit (GPU) <b>630</b>, a digital signal processor (DSP) <b>640</b> and an image signal processor (ISP) <b>650</b>, and may further include a dedicated hardware (DHW) <b>660</b>, a memory (MEM) <b>670</b>, a direct memory access unit (DMA) <b>680</b> and a connectivity <b>690</b>. The CPU <b>610</b>, the NPU <b>620</b>, the GPU <b>630</b>, the DSP <b>640</b>, the ISP <b>650</b> and the dedicated hardware <b>660</b> may be referred to as processors, processing units (PE), computing resources, etc. The DMA <b>680</b> and the connectivity <b>690</b> may be referred to as communication resources.</p><p id="p-0095" num="0094">The CPU <b>610</b>, the NPU <b>620</b>, the GPU <b>630</b>, the DSP <b>640</b>, the ISP <b>650</b> and the dedicated hardware <b>660</b> may perform various computational functions such as particular calculations and tasks, and may be used to execute a neural network model. For example, the dedicated hardware <b>660</b> may include a vision processing unit (VPU), a vision intellectual property (VIP), etc. The memory <b>670</b> may operate as a working memory or a data storage for data processed by the plurality of heterogeneous resources, and may store data associated with the neural network model. The DMA <b>680</b> may control an access to the memory <b>670</b>. For example, the DMA <b>680</b> may include a memory DMA (MDMA), a peripheral DMA (PDMA), a remote DMA (RDMA), a smart DMA (SDMA), etc. The connectivity <b>690</b> may perform wire/wireless communication with an internal element and/or an external device. For example, the connectivity <b>690</b> may include an internal bus that supports an internal communication such as a system bus, peripheral component interconnect (PCI), PCI express (PCIe), etc., and/or may support an external communication such as a mobile telecommunication, universal serial bus (USB), Ethernet, WiFi, Bluetooth, near field communication (NFC), radio frequency identification (RFID), etc.</p><p id="p-0096" num="0095">Although not illustrates in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the computing resources may further include a microprocessor, an application processor (AP), a customized hardware, a compression hardware, etc., and the communication resources may further include memory copy capable resources, etc.</p><p id="p-0097" num="0096">In some example embodiments, the neural network system <b>600</b> may be included in any computing device and/or mobile device.</p><p id="p-0098" num="0097">In some example embodiments, at least one of various services and/or applications, e.g., a computer vision (e.g., image classifying, image detection, image segmentation, image tracking, etc.) service, a user authentication service based on bio-information or biometric data, an advanced driver assistance system (ADAS) service, a voice assistant service, an automatic speech recognition (ASR) service, or the like, may be performed, executed and/or processed by the neural network model described with reference to <figref idref="DRAWINGS">FIGS. <b>5</b>A, <b>5</b>B and <b>5</b>C</figref> and the neural network system <b>600</b> described with reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0099" num="0098"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart illustrating an example of performing an analysis in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0100" num="0099">Referring to <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>7</b></figref>, when performing the analysis whether the first neural network model is appropriate for executing on the first target device (step S<b>300</b>), the plurality of suitability determination algorithms that are used to perform the analysis may include a first algorithm that is used to determine performance efficiency of a structure and layers of the first neural network model associated with the first target device, and a first analysis may be performed on the first neural network model based on the first algorithm (step S<b>310</b>). For example, step S<b>310</b> may be performed by the analysis module <b>300</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0101" num="0100">As described with reference to <figref idref="DRAWINGS">FIGS. <b>5</b>A, <b>5</b>B and <b>5</b>C</figref>, the first neural network model may include a plurality of layers having various characteristics, and may have a structure (or network structure) in which several layers are grouped together. Among the structure and the layers of the first neural network model, a structure, layer and/or element that are not appropriate or suitable for an operation of the first target device may exist. In step S<b>310</b>, it may be determined or checked whether the structure and layers of the first neural network model are efficient for the first target device, and a result of the determination may be scored and visually displayed in step S<b>400</b>.</p><p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating an example of performing a first analysis in <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0103" num="0102">Referring to <figref idref="DRAWINGS">FIGS. <b>7</b> and <b>8</b></figref>, when performing the first analysis on the first neural network model based on the first algorithm (step S<b>310</b>), first scores of the structure and the layers of the first neural network model may be obtained using a pre-listed table (e.g., the pre-listed table <b>310</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>) for the first target device (step S<b>312</b>).</p><p id="p-0104" num="0103">For example, it may be analyzed whether the structure and the layers of the first neural network model are efficient for the first target device based on the pre-listed table <b>310</b> (step S<b>312</b><i>a</i>), and the first scores may be obtained based on a result of step S<b>312</b><i>a </i>(step S<b>312</b><i>b</i>). For example, the pre-listed table <b>310</b> used in step S<b>312</b><i>a </i>may be a table or list in which structures and layers that are efficient and/or inefficient for inference in the first target device are pre-defined. For example, the pre-listed table <b>310</b> may be included in the model information (e.g., the model information MI in <figref idref="DRAWINGS">FIG. <b>2</b></figref>), and may be received with the model information MI. For example, the scoring in step S<b>312</b><i>b </i>may be performed based on the order of efficiency, and a higher score may be given for a structure or layer having higher efficiency and a lower score may be given for a structure or layer having lower efficiency.</p><p id="p-0105" num="0104">In addition, second scores of the structure and the layers of the first neural network model may be obtained by predicting processing time of the structure and the layers of the first neural network model using a performance estimator (e.g., the performance estimator <b>320</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>) (step S<b>314</b>).</p><p id="p-0106" num="0105">For example, the performance of the structure and the layers of the first neural network model may be analyzed using the performance estimator <b>320</b> (step S<b>314</b><i>a</i>), and the second scores may be obtained based on a result of step S<b>314</b><i>a </i>(step S<b>314</b><i>b</i>). For example, the performance estimator <b>320</b> used in step S<b>314</b><i>a </i>may be a tool for estimating the processing time of the neural network model, and may be implemented in the form of software and/or hardware. For example, the scoring in step S<b>314</b><i>b </i>may be performed such that a structure and/or layer that drop the performance are represented, and a higher score may be given for a structure or layer having higher performance and a lower score may be given for a structure or layer having lower performance.</p><p id="p-0107" num="0106">Further, third scores of the structure and the layers of the first neural network model may be obtained using a pre-trained deep learning model (e.g., the pre-trained deep learning model <b>330</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>) for the first target device (step S<b>316</b>).</p><p id="p-0108" num="0107">For example, the pre-trained deep learning model <b>330</b> used in step S<b>316</b> may be a model that is trained using different components depending on the first target device. For example, the pre-trained deep learning model <b>330</b> may be included in the model information MI, and may be received with the model information MI. For example, the scoring in step S<b>316</b> may be performed based on a determination output of the pre-trained deep learning model <b>330</b>.</p><p id="p-0109" num="0108">In other words, in step S<b>312</b>, the structures and/or layers of the models that are efficient and/or inefficient for the inference in the first target device may be pre-defined, the inefficient layer may be detected using the pre-listed table <b>310</b>, and a defined solution may be provided. In step S<b>314</b>, each component may be simulated using the tool for estimating the processing time, and the performance of each component may be predicted and scored. In step S<b>316</b>, the deep learning model may be pre-trained by recording the performance obtained by executing several models having various structures and layers on the first target device, and the performance and suitability of each component of the first neural network model may be measured using the pre-trained deep learning model.</p><p id="p-0110" num="0109">Although <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates that steps S<b>312</b>, S<b>314</b> and S<b>316</b> are substantially simultaneously performed, example embodiments are not limited thereto, and steps S<b>312</b>, S<b>314</b> and S<b>316</b> may be sequentially performed or in any given order.</p><p id="p-0111" num="0110">Performance scores of the structure and the layers of the first neural network model may be obtained based on the first scores, the second scores and the third scores (step S<b>318</b>). For example, the performance scores may be obtained based on a weight summing scheme in which the first, second and third scores are summed with different weights. For example, the weights may be differently set for each target device. For example, first, second and third weights for the first, second and third scores may be included in the model information MI, and may be received with the model information MI.</p><p id="p-0112" num="0111">In some example embodiments, the first scores, the second scores, the third scores, and the performance scores may be obtained for each of the structure and the layers of the first neural network model.</p><p id="p-0113" num="0112"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example of performing an analysis in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0114" num="0113">Referring to <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>9</b></figref>, when performing the analysis whether the first neural network model is appropriate for executing on the first target device (step S<b>300</b>), the plurality of suitability determination algorithms that are used to perform the analysis may include a second algorithm that is used to analyze complexity and capacity of the structure and the layers of the first neural network model, and a second analysis may be performed on the first neural network model based on the second algorithm (step S<b>320</b>). For example, step S<b>320</b> may be performed by the analysis module <b>300</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0115" num="0114">In step S<b>320</b>, the optimization point may be determined and guided by analyzing the complexity and capacity of the structure and the layers of the first neural network model, and a result of the determination may be scored and visually displayed in step S<b>400</b>.</p><p id="p-0116" num="0115"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart illustrating an example of performing a second analysis in <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0117" num="0116">Referring to <figref idref="DRAWINGS">FIGS. <b>9</b> and <b>10</b></figref>, when performing the second analysis on the first neural network model based on the second algorithm (step S<b>320</b>), fourth scores of the structure and the layers of the first neural network model may be obtained by determining the complexity of the structure and the layers of the first neural network model (step S<b>322</b>).</p><p id="p-0118" num="0117">For example, the complexity of the structure and the layers of the first neural network model may be analyzed by using a complexity determining unit (e.g., the complexity determining unit <b>340</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>) (step S<b>322</b><i>a</i>), and the fourth scores may be obtained based on a result of step S<b>322</b><i>a </i>(step S<b>322</b><i>b</i>). For example, the complexity determining unit <b>340</b> used in step S<b>322</b><i>a </i>may be a tool for determining the complexity of the neural network model, and may be implemented in the form of software and/or hardware. For example, the scoring in step S<b>322</b><i>b </i>may be performed based on a threshold of the complexity for the first target device, and a lower score may be given for a structure or layer having higher complexity and a higher score may be given for a structure or layer having lower complexity.</p><p id="p-0119" num="0118">In some example embodiments, a criterion for determining the complexity by the complexity determining unit <b>340</b> may include the number of parameters, units and layers included in the neural network model. In some example embodiments, a scheme and/or algorithm for determining the complexity by the complexity determining unit <b>340</b> may include a complexity evaluation function, which is disclosed in the paper &#x201c;On the Complexity of Neural Network Classifiers: A Comparison Between Shallow and Deep Architectures&#x201d; by Monica Bianchini and Franco Scarselli. However, example embodiments are not limited thereto, and the complexity may be determined and/or checked using various criteria, schemes and/or algorithms.</p><p id="p-0120" num="0119">In addition, fifth scores of the structure and the layers of the first neural network model may be obtained by measuring the capacity of the structure and the layers of the first neural network model (step S<b>324</b>).</p><p id="p-0121" num="0120">For example, the capacity of the structure and the layers of the first neural network model may be analyzed by using a capacity measuring unit (e.g., the capacity measuring unit <b>350</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>) (step S<b>324</b><i>a</i>), and the fifth scores may be obtained based on a result of step S<b>324</b><i>a </i>(step S<b>324</b><i>b</i>). For example, the capacity measuring unit <b>350</b> used in step S<b>324</b><i>a </i>may be a tool for measuring the capacity of the neural network model, and may be implemented in the form of software and/or hardware. For example, the scoring in step S<b>324</b><i>b </i>may be performed depending on capacity requirements, and a higher score may be given for a structure or layer having larger capacity and a lower score may be given for a structure or layer having smaller capacity.</p><p id="p-0122" num="0121">In some example embodiments, a scheme and/or algorithm for measuring the capacity by the capacity measuring unit <b>350</b> may include an algorithm, which is disclosed in the paper &#x201c;Deep Neural Network Capacity&#x201d; by Aosen Wang et al. However, example embodiments are not limited thereto, and the capacity may be measured using various criteria, schemes and/or algorithms.</p><p id="p-0123" num="0122">In other words, in step S<b>322</b>, the degree of overhead in which the first neural network model is executed on the first target device may be measured using the algorithm for determining the complexity of the first neural network model, and the overhead of the first neural network model may be predicted by measuring the performance of the first target device depending on the complexity of the first neural network model. In step S<b>324</b>, the capacity of the first neural network model may be measured, the optimization point may be determined and guided using the capacity of the first neural network model, and it may be easier to optimize the first neural network model as the capacity of the first neural network model become large.</p><p id="p-0124" num="0123">Although <figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates that steps S<b>322</b> and S<b>324</b> are substantially simultaneously performed, example embodiments are not limited thereto, and steps S<b>322</b> and S<b>324</b> may be sequentially performed or in any given order.</p><p id="p-0125" num="0124">Complexity scores of the structure and the layers of the first neural network model may be obtained based on the fourth scores and the fifth scores (step S<b>326</b>). For example, the complexity scores may be obtained based on a weight summing scheme in which the fourth and fifth scores are summed with different weights. For example, the weights may be differently set for each target device. For example, fourth and fifth weights for the fourth and fifth scores may be included in the model information MI, and may be received with the model information MI.</p><p id="p-0126" num="0125">In some example embodiments, the fourth scores, the fifth scores, and the complexity scores may be obtained for each of the structure and the layers of the first neural network model.</p><p id="p-0127" num="0126"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart illustrating an example of performing an analysis in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0128" num="0127">Referring to <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>11</b></figref>, when performing the analysis whether the first neural network model is appropriate for executing on the first target device (step S<b>300</b>), the plurality of suitability determination algorithms that are used to perform the analysis may include a third algorithm that is used to determine memory efficiency of the structure and the layers of the first neural network model associated with the first target device, and a third analysis may be performed on the first neural network model based on the third algorithm (step S<b>330</b>). For example, step S<b>330</b> may be performed by the analysis module <b>300</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0129" num="0128">In step S<b>330</b>, the optimization point depending on the memory utilization may be determined and guided by analyzing the memory footprint of the structure and the layers of the first neural network model, and a result of the determination may be scored and visually displayed in step S<b>400</b>.</p><p id="p-0130" num="0129"><figref idref="DRAWINGS">FIGS. <b>12</b> and <b>13</b></figref> are flowcharts illustrating examples of performing a third analysis in <figref idref="DRAWINGS">FIG. <b>11</b></figref>.</p><p id="p-0131" num="0130">Referring to <figref idref="DRAWINGS">FIGS. <b>11</b> and <b>12</b></figref>, when performing the third analysis on the first neural network model based on the third algorithm (step S<b>330</b>), memory limitation of the first target device may be loaded (step S<b>332</b>), and memory footprint scores of the structure and the layers of the first neural network model may be obtained based on the memory limitation of the first target device (step S<b>334</b>).</p><p id="p-0132" num="0131">For example, due to the characteristic of the first target device, there may be the limitation of a memory such as an SRAM, a DRAM, or the like, and thus the performance of the first target device may vary depending on the limitation of the memory (e.g., read/write operations). The memory usage, bottleneck point, memory sharing, or the like, which may occur in each operation depending on the structure and/or type of the first neural network model, may be calculated in advance using a memory estimator (e.g., the memory estimator <b>360</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>), and thus the optimized model may be designed based on the expected performance. For example, the memory estimator <b>360</b> used in step S<b>334</b> may be a tool for analyzing the memory footprint of the neural network model, and may be implemented in the form of software and/or hardware.</p><p id="p-0133" num="0132">In some example embodiments, the memory footprint scores may be obtained for each of the structure and the layers of the first neural network model.</p><p id="p-0134" num="0133">Referring to <figref idref="DRAWINGS">FIGS. <b>11</b> and <b>13</b></figref>, when performing the third analysis on the first neural network model based on the third algorithm (step S<b>330</b>), steps S<b>332</b> and S<b>334</b> may be substantially the same as or similar to steps S<b>332</b> and S<b>334</b> in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, respectively.</p><p id="p-0135" num="0134">When the first neural network model is unavailable (or is not available) within the memory limitation (step S<b>512</b>: NO), the first neural network model may be changed, modified or updated (step S<b>514</b>). For example, the first neural network model may be changed depending on the memory usage, bottleneck point, memory sharing, or the like. Steps S<b>512</b> and S<b>514</b> may correspond to step S<b>500</b> in <figref idref="DRAWINGS">FIG. <b>17</b></figref>, which will be described later.</p><p id="p-0136" num="0135">When the first neural network model is available within the memory limitation (step S<b>512</b>: YES), the process may be terminated without changing the first neural network model.</p><p id="p-0137" num="0136"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart illustrating an example of performing an analysis in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0138" num="0137">Referring to <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>14</b></figref>, when performing the analysis whether the first neural network model is appropriate for executing on the first target device (step S<b>300</b>), step S<b>310</b> may be substantially the same as or similar to step S<b>310</b> which is described with reference to <figref idref="DRAWINGS">FIGS. <b>7</b> and <b>8</b></figref>, step S<b>320</b> may be substantially the same as or similar to step S<b>320</b> which is described with reference to <figref idref="DRAWINGS">FIGS. <b>9</b> and <b>10</b></figref>, and step S<b>330</b> may be substantially the same as or similar to step S<b>330</b> which is described with reference to <figref idref="DRAWINGS">FIGS. <b>11</b>, <b>12</b> and <b>13</b></figref>.</p><p id="p-0139" num="0138">Total scores of the first neural network model may be obtained based on the performance scores obtained in step S<b>310</b>, the complexity scores obtained in step S<b>320</b> and the memory footprint scores obtained in step S<b>330</b> (step S<b>340</b>). For example, the total scores may be obtained based on a weight summing scheme in which the performance scores, the complexity scores and the memory footprint scores are summed with different weights. For example, the weights may be differently set for each target device. For example, the weights for the performance scores, the complexity scores and the memory footprint scores may be included in the model information MI, and may be received with the model information MI.</p><p id="p-0140" num="0139"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart illustrating an example of a method of optimizing a neural network model of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The descriptions repeated with <figref idref="DRAWINGS">FIG. <b>1</b></figref> will be omitted.</p><p id="p-0141" num="0140">Referring to <figref idref="DRAWINGS">FIG. <b>15</b></figref>, in the method of optimizing the neural network model according to example embodiments, a GUI for optimizing the neural network model is provided (step S<b>1100</b>). Detailed configurations of the GUI will be described later.</p><p id="p-0142" num="0141">The first model information of the first neural network model is received through the GUI (step S<b>100</b><i>a</i>). The device information of the first target device used to execute or drive the first neural network model is received through the GUI (step S<b>200</b><i>a</i>). The analysis whether the first neural network model is appropriate for executing or driving on the first target device is performed, based on the first model information, the device information, and at least one of the plurality of suitability determination algorithms (step S<b>300</b>). The result of the analysis is displayed on the GUI such that the first model information and the result of the analysis are displayed on a screen (step S<b>400</b><i>a</i>). Steps S<b>100</b><i>a</i>, S<b>200</b><i>a </i>and S<b>400</b><i>a </i>may be similar to steps S<b>100</b>, S<b>200</b> and S<b>400</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, respectively, and step S<b>300</b> may be substantially the same as or similar to step S<b>300</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. For example, steps S<b>300</b> and S<b>400</b><i>a </i>may be performed by the analysis module <b>300</b> and the GUI control module <b>200</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0143" num="0142"><figref idref="DRAWINGS">FIGS. <b>16</b>A, <b>16</b>B, <b>16</b>C, <b>16</b>D, <b>16</b>E and <b>16</b>F</figref> are diagrams for describing an operation of <figref idref="DRAWINGS">FIG. <b>15</b></figref>.</p><p id="p-0144" num="0143">Referring to <figref idref="DRAWINGS">FIGS. <b>15</b> and <b>16</b>A</figref>, in step S<b>400</b><i>a</i>, a graphical representation GR<b>11</b>, which includes the structure and the layers of the first neural network model, may be displayed on the GUI at an initial operation time. For example, the graphical representation GR<b>11</b> may include a network structure of a plurality of layers LAYER<b>1</b>, LAYER<b>2</b>, LAYER<b>3</b>, LAYER<b>4</b>, LAYER<b>5</b> and LAYER<b>6</b> between an input and an output of the first neural network model. For example, the graphical representation GR<b>11</b> may include a plurality of layer boxes (e.g., rectangles) each of which corresponds to a respective one of the plurality of layers, and a plurality of arrows each of which indicates a connection between layers.</p><p id="p-0145" num="0144">Referring to <figref idref="DRAWINGS">FIGS. <b>15</b>, <b>16</b>B, <b>16</b>C, <b>16</b>D, <b>16</b>E and <b>16</b>F</figref>, in step S<b>400</b><i>a</i>, graphical representations GR<b>12</b>, GR<b>13</b>, GR<b>14</b>, GR<b>15</b> and GR<b>16</b>, each of which includes the structure and the layers of the first neural network model and the result of the analysis together, may be displayed on the GUI. For example, the result of the analysis may be displayed based on selection of one of buttons <b>112</b>, <b>114</b>, <b>116</b> and <b>118</b> included in a menu <b>110</b> included in the graphical representations GR<b>12</b>, GR<b>13</b>, GR<b>14</b>, GR<b>15</b> and GR<b>16</b>.</p><p id="p-0146" num="0145"><figref idref="DRAWINGS">FIGS. <b>16</b>B, <b>16</b>C, <b>16</b>D and <b>16</b>E</figref> illustrate examples where the result of the analysis is displayed based on scores. In an example of <figref idref="DRAWINGS">FIG. <b>16</b>B</figref>, the button <b>114</b> corresponding to the performance score may be selected, and the graphical representation GR<b>12</b>, which includes the plurality of layers LAYER<b>1</b> to LAYER<b>6</b> and a plurality of performance scores SVP<b>1</b>, SVP<b>2</b>, SVP<b>3</b>, SVP<b>4</b>, SVP<b>5</b> and SVP<b>6</b> obtained by step S<b>310</b> as a result of the first analysis, may be displayed on the GUI. In an example of <figref idref="DRAWINGS">FIG. <b>16</b>C</figref>, the button <b>116</b> corresponding to the complexity score may be selected, and the graphical representation GR<b>13</b>, which includes the plurality of layers LAYER<b>1</b> to LAYER<b>6</b> and a plurality of complexity scores SVC<b>1</b>, SVC<b>2</b>, SVC<b>3</b>, SVC<b>4</b>, SVC<b>5</b> and SVC<b>6</b> obtained by step S<b>320</b> as a result of the second analysis, may be displayed on the GUI. In an example of <figref idref="DRAWINGS">FIG. <b>16</b>D</figref>, the button <b>118</b> corresponding to the memory footprint score may be selected, and the graphical representation GR<b>14</b>, which includes the plurality of layers LAYER<b>1</b> to LAYER<b>6</b> and a plurality of memory footprint scores SVM<b>1</b>, SVM<b>2</b>, SVM<b>3</b>, SVM<b>4</b>, SVM<b>5</b> and SVM<b>6</b> obtained by step S<b>330</b> as a result of the third analysis, may be displayed on the GUI. In an example of <figref idref="DRAWINGS">FIG. <b>16</b>E</figref>, the button <b>112</b> corresponding to the total score based on the performance score, the complexity score, and the memory footprint score may be selected, and the graphical representation GR<b>15</b>, which includes the plurality of layers LAYER<b>1</b> to LAYER<b>6</b> and a plurality of total scores SVT<b>1</b>, SVT<b>2</b>, SVT<b>3</b>, SVT<b>4</b>, SVT<b>5</b> and SVT<b>6</b> obtained by step S<b>340</b>, may be displayed on the GUI.</p><p id="p-0147" num="0146">In some example embodiments, the graphical representations GR<b>12</b>, GR<b>13</b>, GR<b>14</b> and GR<b>15</b> of <figref idref="DRAWINGS">FIGS. <b>16</b>B, <b>16</b>C, <b>16</b>D and <b>16</b>E</figref> may be switchable with each other.</p><p id="p-0148" num="0147"><figref idref="DRAWINGS">FIG. <b>16</b>F</figref> illustrates an example where the result of the analysis is displayed based on color. As with the example of <figref idref="DRAWINGS">FIG. <b>16</b>E</figref>, the button <b>112</b> corresponding to the total score may be selected in an example of <figref idref="DRAWINGS">FIG. <b>16</b>F</figref>, and the graphical representation GR<b>16</b>, which includes the plurality of layers LAYER<b>1</b> to LAYER<b>6</b> and some colored layer boxes, may be displayed on the GUI. For convenience of illustration, colors are indicated by hatching in <figref idref="DRAWINGS">FIG. <b>16</b>F</figref>, and a layer box with higher hatching density may correspond to a layer box with darker color. For example, colored layers LAYER<b>2</b> to LAYER<b>4</b> may correspond to layers having relatively low total scores, a layer box with darker color may correspond to a layer having a lower total score, and thus the total score SVT<b>3</b> corresponding to the layer LAYER<b>3</b> may be the lowest total score. This is merely an example, and darker colors may be used to indicate a layer with a higher total score. Although not illustrated in detail, when one of the buttons <b>112</b>, <b>114</b> and <b>116</b> is selected, the result of the analysis may be displayed based on color, as with the example of <figref idref="DRAWINGS">FIG. <b>16</b>F</figref>.</p><p id="p-0149" num="0148">However, example embodiments are not limited thereto, and graphical representations may be implemented using different shapes, or the like, as long as the graphical representations may indicate a layer having a lower score in a visually distinguishable manner from other layers.</p><p id="p-0150" num="0149">In some example embodiments, one of the buttons <b>112</b>, <b>114</b>, <b>116</b> and <b>118</b> may be selected by receiving a user input using an input device <b>1310</b> such as, for example, a mouse or a touch screen included in the neural network model processing system <b>1000</b>.</p><p id="p-0151" num="0150"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flowchart illustrating a method of optimizing a neural network model according to example embodiments. The descriptions repeated with <figref idref="DRAWINGS">FIG. <b>1</b></figref> will be omitted.</p><p id="p-0152" num="0151">Referring to <figref idref="DRAWINGS">FIG. <b>17</b></figref>, in a method of optimizing a neural network model according to example embodiments, steps S<b>100</b>, S<b>200</b>, S<b>300</b> and S<b>400</b> may be substantially the same as or similar to steps S<b>100</b>, S<b>200</b>, S<b>300</b> and S<b>400</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, respectively.</p><p id="p-0153" num="0152">At least one of the layers of the first neural network model is changed or modified based on the result of the analysis (step S<b>500</b>). For example, as with step S<b>400</b>, a result of the model change may be visualized and output in step S<b>500</b>, and S<b>500</b> may be performed using the GUI. For example, step S<b>500</b> may be performed by the updating module <b>400</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0154" num="0153"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a flowchart illustrating an example of changing at least one of layers of a first neural network model in <figref idref="DRAWINGS">FIG. <b>17</b></figref>.</p><p id="p-0155" num="0154">Referring to <figref idref="DRAWINGS">FIGS. <b>17</b> and <b>18</b></figref>, when changing the at least one of the layers of the first neural network model based on the result of the analysis (step S<b>500</b>), a first layer having the lowest score may be selected from among the layers of the first neural network model (step S<b>522</b>). At least one second layer that is capable of replacing the first layer and has a score higher than that of the first layer may be recommended (step S<b>524</b>). The first layer may be changed based on the at least one second layer (step S<b>526</b>). For example, steps S<b>522</b> and S<b>526</b> may be performed based on a user input (e.g., user input UI in <figref idref="DRAWINGS">FIG. <b>4</b></figref>). For example, the first layer may be changed into the second layer.</p><p id="p-0156" num="0155"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a flowchart illustrating an example of a method of optimizing a neural network model of <figref idref="DRAWINGS">FIG. <b>17</b></figref>. The descriptions repeated with <figref idref="DRAWINGS">FIGS. <b>15</b> and <b>17</b></figref> will be omitted.</p><p id="p-0157" num="0156">Referring to <figref idref="DRAWINGS">FIG. <b>19</b></figref>, in the method of optimizing the neural network model according to example embodiments, steps S<b>1100</b>, S<b>100</b><i>a</i>, S<b>200</b><i>a</i>, S<b>300</b> and S<b>400</b><i>a </i>may be substantially the same as or similar to steps S<b>1100</b>, S<b>100</b><i>a</i>, S<b>200</b><i>a</i>, S<b>300</b> and S<b>400</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, respectively.</p><p id="p-0158" num="0157">The process and the result of the model change may be displayed on the GUI such that the first model information and the process and the result of the model change are displayed on a screen (step S<b>500</b><i>a</i>). Step S<b>500</b><i>a </i>may be similar to step S<b>500</b> in <figref idref="DRAWINGS">FIG. <b>17</b></figref>. For example, step S<b>500</b><i>a </i>may be performed by the updating module <b>400</b> and the GUI control module <b>200</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0159" num="0158"><figref idref="DRAWINGS">FIGS. <b>20</b>A, <b>20</b>B, <b>20</b>C and <b>20</b>D</figref> are diagrams for describing an operation of <figref idref="DRAWINGS">FIG. <b>19</b></figref>. The descriptions repeated with <figref idref="DRAWINGS">FIGS. <b>16</b>A, <b>16</b>B, <b>16</b>C, <b>16</b>D, <b>16</b>E and <b>16</b>F</figref> will be omitted.</p><p id="p-0160" num="0159">Referring to <figref idref="DRAWINGS">FIGS. <b>16</b>E, <b>16</b>F, <b>19</b> and <b>20</b>A</figref>, in step S<b>500</b><i>a</i>, the layer LAYER<b>3</b> having the lowest total score SVT<b>3</b> may be selected from among the plurality of layers LAYER<b>1</b> to LAYER<b>6</b>, and thus a graphical representation GR<b>21</b>, which includes information of the layer LAYER<b>3</b> (on a menu <b>120</b>), may be displayed on the GUI. For example, a size of an input data of the layer LAYER<b>3</b> may be (1, 64, 512, 512), a size of an output data of the layer LAYER<b>3</b> may be (1, 137, 85, 85), and the layer LAYER<b>3</b> may be implemented based on configurations displayed on the menu <b>120</b>.</p><p id="p-0161" num="0160">Referring to <figref idref="DRAWINGS">FIGS. <b>19</b> and <b>20</b>B</figref>, in step S<b>500</b><i>a</i>, a graphical representation GR<b>22</b>, which includes information of recommended layers LAYER<b>31</b>, LAYER<b>32</b> and LAYER<b>33</b> that are capable of replacing a first layer LAYER<b>3</b>, may be displayed on the GUI. For example, a first recommended layer LAYER<b>31</b> may be implemented with a single layer and based on configurations displayed on a menu <b>122</b>. For example, second recommended layers LAYER<b>32</b> and LAYER<b>33</b> may be implemented with two layers and based on configurations displayed on the menu <b>122</b>. For example, when the first layer LAYER<b>3</b> is changed into the first recommended layer LAYER<b>31</b>, the similarity between the model before the change and the model after the change may be higher. For example, when the first layer LAYER<b>3</b> is changed into the second recommended layers LAYER<b>32</b> and LAYER<b>33</b>, the performance may be more improved.</p><p id="p-0162" num="0161">Referring to <figref idref="DRAWINGS">FIGS. <b>19</b> and <b>20</b>C</figref>, in step S<b>500</b><i>a</i>, the first recommended layer LAYER<b>31</b> may be selected to change the layer LAYER<b>3</b> into the first recommended layer LAYER<b>31</b>, and a graphical representation GR<b>23</b>, which includes a graphical representation of an operation of selecting the first recommended layer LAYER<b>31</b>, may be displayed on the GUI.</p><p id="p-0163" num="0162">Referring to <figref idref="DRAWINGS">FIGS. <b>19</b> and <b>20</b>D</figref>, in step S<b>500</b><i>a</i>, after the layer LAYER<b>3</b> is changed into the first recommended layer LAYER<b>31</b>, a graphical representation GR<b>24</b>, which includes a plurality of layers LAYER<b>1</b>, LAYER<b>2</b>, LAYER<b>31</b>, LAYER<b>4</b>, LAYER<b>5</b> and LAYER<b>6</b> of the changed model and a plurality of total scores SVT<b>1</b>, SVT<b>2</b>, SVT<b>31</b>, SVT<b>4</b>, SET<b>5</b> and SVT<b>6</b> of the changed model, may be displayed on the GUI. For example, the total score SVT<b>31</b> of the changed layer LAYER<b>31</b> may be higher than the total score SVT<b>3</b> of the layer LAYER<b>3</b> before the change.</p><p id="p-0164" num="0163">In some example embodiments, the layer and corresponding layer box may be selected in <figref idref="DRAWINGS">FIGS. <b>20</b>A and <b>20</b>C</figref> by receiving a user input via the input device <b>1310</b>, such as a mouse or a touch screen, included in the neural network model processing system <b>1000</b>.</p><p id="p-0165" num="0164">As described above, the neural network model may be changed or modified using the visual interface based on the suitability determination algorithm, and the neural network model optimized for the target device may be designed by repeating such modification process. From simple modifications to new alternative structures may be proposed, and both an automatic optimization function and a conditional optimization function based on a user's input condition may be provided.</p><p id="p-0166" num="0165"><figref idref="DRAWINGS">FIG. <b>21</b></figref> is a flowchart illustrating a method of optimizing a neural network model according to example embodiments. The descriptions repeated with <figref idref="DRAWINGS">FIG. <b>1</b></figref> will be omitted.</p><p id="p-0167" num="0166">Referring to <figref idref="DRAWINGS">FIG. <b>21</b></figref>, in a method of optimizing a neural network model according to example embodiments, steps S<b>100</b>, S<b>200</b>, S<b>300</b> and S<b>400</b> may be substantially the same as or similar to steps S<b>100</b>, S<b>200</b>, S<b>300</b> and S<b>400</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, respectively.</p><p id="p-0168" num="0167">Different quantization schemes are applied to at least some of the layers of the first neural network model (step S<b>600</b>). For example, as with step S<b>400</b>, a result of the quantization scheme change may be visualized and output in step S<b>600</b>, and S<b>600</b> may be performed using the GUI. For example, step S<b>600</b> may be performed by the quantization module <b>500</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0169" num="0168"><figref idref="DRAWINGS">FIG. <b>22</b></figref> is a flowchart illustrating an example of applying different quantization schemes to at least some of layers of a first neural network model in <figref idref="DRAWINGS">FIG. <b>21</b></figref>.</p><p id="p-0170" num="0169">Referring to <figref idref="DRAWINGS">FIGS. <b>21</b> and <b>22</b></figref>, when applying the different quantization schemes to the at least some of the layers of the first neural network model (step S<b>600</b>), second model information of the first neural network model may be received (step S<b>610</b>). The second model information may be obtained after a training on the first neural network model is completed. A third layer whose quantization scheme is to be changed may be selected from among the layers of the first neural network model based on the second model information (step S<b>620</b>). The quantization scheme of the selected third layer may be changed (step S<b>630</b>). For example, steps S<b>620</b> and S<b>630</b> may be performed based on a user input (e.g., user input UI in <figref idref="DRAWINGS">FIG. <b>4</b></figref>).</p><p id="p-0171" num="0170">Unlike steps S<b>100</b>, S<b>200</b>, S<b>300</b> and S<b>400</b>, step S<b>600</b> may be performed after the training on the first neural network model is completed. For example, the second model information may be obtained by changing at least a part of the first model information. For example, although not illustrated in detail, step S<b>500</b> in <figref idref="DRAWINGS">FIG. <b>17</b></figref> may be performed between steps S<b>400</b> and S<b>600</b> in <figref idref="DRAWINGS">FIG. <b>21</b></figref> to obtain the second model information.</p><p id="p-0172" num="0171">A quantization is a kind of a compression on a neural network model. A compression (or compressing operation) on a neural network model indicates a process for reducing the size and amount of computation of the neural network model while the performance and/or accuracy of the neural network model that is pre-trained are maintained as much as possible. A quantization (or quantizing operation) indicates a technique for reducing a size in which a neural network model is actually stored by decreasing weights, which are generally expressed in floating points, to the specific number of bits.</p><p id="p-0173" num="0172"><figref idref="DRAWINGS">FIG. <b>23</b></figref> is a flowchart illustrating an example of a method of optimizing a neural network model of <figref idref="DRAWINGS">FIG. <b>21</b></figref>. The descriptions repeated with <figref idref="DRAWINGS">FIGS. <b>15</b> and <b>21</b></figref> will be omitted.</p><p id="p-0174" num="0173">Referring to <figref idref="DRAWINGS">FIG. <b>23</b></figref>, in the method of optimizing the neural network model according to example embodiments, steps S<b>1100</b>, S<b>100</b><i>a</i>, S<b>200</b><i>a</i>, S<b>300</b> and S<b>400</b><i>a </i>may be substantially the same as or similar to steps S<b>1100</b>, S<b>100</b><i>a</i>, S<b>200</b><i>a</i>, S<b>300</b> and S<b>400</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, respectively.</p><p id="p-0175" num="0174">The process and the result of the quantization scheme change may be displayed on the GUI such that the second model information and the process and the result of the quantization scheme change are displayed on a screen (step S<b>600</b><i>a</i>). Step S<b>600</b><i>a </i>may be similar to step S<b>600</b> in <figref idref="DRAWINGS">FIG. <b>21</b></figref>. For example, step S<b>600</b><i>a </i>may be performed by the quantization module <b>500</b> and the GUI control module <b>200</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0176" num="0175"><figref idref="DRAWINGS">FIGS. <b>24</b>A, <b>24</b>B and <b>24</b>C</figref> are diagrams for describing an operation of <figref idref="DRAWINGS">FIG. <b>23</b></figref>. The descriptions repeated with <figref idref="DRAWINGS">FIGS. <b>16</b>A, <b>16</b>B, <b>16</b>C, <b>16</b>D, <b>16</b>E, <b>16</b>F, <b>20</b>A, <b>20</b>B, <b>20</b>C and <b>20</b>D</figref> will be omitted.</p><p id="p-0177" num="0176">Referring to <figref idref="DRAWINGS">FIGS. <b>23</b> and <b>24</b>A</figref>, in step S<b>600</b><i>a</i>, a button <b>132</b> corresponding to quantization performance included in a menu <b>130</b> may be selected, and a graphical representation GR<b>31</b>, which includes a plurality of layers LAYER<b>1</b>, LAYER<b>2</b>, LAYER<b>31</b>, LAYER<b>4</b>, LAYER<b>5</b> and LAYER<b>6</b> and a plurality of quantization performances QP<b>1</b>, QP<b>2</b>, QP<b>3</b>, QP<b>4</b>, QP<b>5</b> and QP<b>6</b>, may be displayed on the GUI.</p><p id="p-0178" num="0177">Referring to <figref idref="DRAWINGS">FIGS. <b>23</b> and <b>24</b>B</figref>, in step S<b>600</b><i>a</i>, a button <b>134</b> corresponding to a change of a quantization scheme included in the menu <b>130</b> may be selected, the layer LAYER<b>31</b> whose quantization scheme is to be changed may be selected, the quantization scheme of the layer LAYER<b>31</b> may be changed from a first quantization scheme QS<b>1</b> into a second quantization scheme QS<b>2</b>, and a graphical representation GR<b>32</b>, which includes graphical representations corresponding to operations of selecting the layer LAYER<b>31</b> and changing the quantization scheme of the layer LAYER<b>31</b>, may be displayed on the GUI. The layer LAYER<b>31</b> may be re-quantized based on the second quantization scheme QS<b>2</b>, and the quantization scheme applied to the layer LAYER<b>31</b> may be different from the quantization scheme applied to the other layers.</p><p id="p-0179" num="0178">Referring to <figref idref="DRAWINGS">FIGS. <b>23</b> and <b>24</b>C</figref>, in step S<b>600</b><i>a</i>, the button <b>132</b> included in the menu <b>130</b> may be selected, and a graphical representation GR<b>33</b>, which includes a plurality of layers LAYER<b>1</b>, LAYER<b>2</b>, LAYER<b>31</b>, LAYER<b>4</b>, LAYER<b>5</b> and LAYER<b>6</b> and a plurality of quantization performances QP<b>1</b>, QP<b>2</b>, QP<b>31</b>, QP<b>4</b>, QP<b>5</b> and QP<b>6</b>, may be displayed on the GUI. For example, the quantization performance QP<b>31</b> of the layer LAYER<b>31</b> based on the second quantization scheme QS<b>2</b> may be higher than the quantization performance QP<b>3</b> of the layer LAYER<b>31</b> based on the first quantization scheme QS<b>1</b>.</p><p id="p-0180" num="0179">As described above, the accuracy of the quantization scheme applied to each component may be checked, and the accuracy may be improved by applying different quantization schemes to components depending on the loss rate by the degree of distribution restoration. For example, an algorithm to detect a suitable quantization scheme for each layer and feature map depending the degree of loss may be provided by comparing the quantization accuracy of layers and feature maps of the floating point model. An optimized quantization performance may be obtained by applying different quantization schemes to each component and checking a result immediately. A user may arbitrarily set the target minimum/maximum range for one or multiple components, may set the quantization distribution mode, and may perform a re-quantization by differently applying an asymmetric scheme, a symmetric scheme, or the like, and/or by applying different bit-widths.</p><p id="p-0181" num="0180"><figref idref="DRAWINGS">FIG. <b>25</b></figref> is a block diagram illustrating a system that performs a method of optimizing a neural network model according to example embodiments.</p><p id="p-0182" num="0181">Referring to <figref idref="DRAWINGS">FIG. <b>25</b></figref>, a system <b>3000</b> may include a user device <b>3100</b>, a cloud computing environment <b>3200</b> and a network <b>3300</b>. The user device <b>3100</b> may include a neural network model (NNM) optimizing engine frontend <b>3110</b>. The cloud computing environment <b>3200</b> may include a cloud storage <b>3210</b>, a database <b>3220</b>, an NNM optimizing engine backend <b>3230</b>, a cloud NNM engine <b>3240</b> and an inventory backend <b>3250</b>. The method of optimizing the neural network model according to example embodiments may be implemented on a cloud environment, and may be performed by the NNM optimizing engine frontend <b>3110</b> and/or the NNM optimizing engine backend <b>3230</b>.</p><p id="p-0183" num="0182">The inventive concept may be applied to various electronic devices and systems that include the deep learning, ANN and/or machine learning systems. For example, the inventive concept may be applied to systems such as a personal computer (PC), a server computer, a data center, a workstation, a mobile phone, a smart phone, a tablet computer, a laptop computer, a personal digital assistant (PDA), a portable multimedia player (PMP), a digital camera, a portable game console, a music player, a camcorder, a video player, a navigation device, a wearable device, an internet of things (IoT) device, an internet of everything (IoE) device, an e-book reader, a virtual reality (VR) device, an augmented reality (AR) device, a robotic device, a drone, etc.</p><p id="p-0184" num="0183">In the method of optimizing the neural network model and the neural network model processing system according to example embodiments, a neural network model to be most appropriate or suitable for a target device may be efficiently implemented. For example, before a training is performed on a neural network model, the neural network model optimized for the target device may be designed. After the training is completed on the neural network model, it may be checked and/or determined whether the neural network model is suitable for the target device, and if necessary, the neural network model may be modified and/or a new configuration that is more suitable may be suggested. In addition, optimized performance may be obtained by applying suitable quantization scheme to each component of the neural network model. Further, the GUI for such operations may be provided. Accordingly, a user may efficiently design and modify the neural network model to be most optimized for the target device, and may apply the suitable quantization scheme.</p><p id="p-0185" num="0184">At least one of the components, elements, modules or units (collectively &#x201c;components&#x201d; in this paragraph) represented by a block in the drawings may be embodied as various numbers of hardware, software and/or firmware structures that execute respective functions described above, according to an example embodiment. According to example embodiments, at least one of these components may use a direct circuit structure, such as a memory, a processor, a logic circuit, a look-up table, etc. that may execute the respective functions through controls of one or more microprocessors or other control apparatuses. Also, at least one of these components may be specifically embodied by a module, a program, or a part of code, which contains one or more executable instructions for performing specified logic functions, and executed by one or more microprocessors or other control apparatuses. Further, at least one of these components may include or may be implemented by a processor such as a central processing unit (CPU) that performs the respective functions, a microprocessor, or the like. Two or more of these components may be combined into one single component which performs all operations or functions of the combined two or more components. Also, at least part of functions of at least one of these components may be performed by another of these components. Functional aspects of the above exemplary embodiments may be implemented in algorithms that execute on one or more processors. Furthermore, the components represented by a block or processing steps may employ any number of related art techniques for electronics configuration, signal processing and/or control, data processing and the like.</p><p id="p-0186" num="0185">The foregoing is illustrative of example embodiments and is not to be construed as limiting thereof. Although some example embodiments have been described, those skilled in the art will readily appreciate that many modifications are possible in the example embodiments without materially departing from the novel teachings and advantages of the example embodiments. Accordingly, all such modifications are intended to be included within the scope of the example embodiments as defined in the claims. Therefore, it is to be understood that the foregoing is illustrative of various example embodiments and is not to be construed as limited to the specific example embodiments disclosed, and that modifications to the disclosed example embodiments, as well as other example embodiments, are intended to be included within the scope of the appended claims and their equivalents.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of optimizing a neural network model, the method comprising:<claim-text>receiving first model information about a first neural network model;</claim-text><claim-text>receiving device information about a first target device that is used to execute the first neural network model;</claim-text><claim-text>performing an analysis whether the first neural network model is suitable for executing on the first target device, based on the first model information, the device information, and at least one of a plurality of suitability determination algorithms; and</claim-text><claim-text>outputting a result of the analysis such that the first model information and the result of the analysis are displayed on a screen.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of suitability determination algorithms include a first algorithm that is used to determine a performance efficiency of a structure and layers of the first neural network model associated with the first target device.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the performing the analysis includes:<claim-text>performing a first analysis on the first neural network model based on the first algorithm.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein performing the first analysis includes:<claim-text>obtaining first scores of the structure and the layers of the first neural network model using a pre-listed table for the first target device;</claim-text><claim-text>obtaining second scores of the structure and the layers of the first neural network model by predicting a processing time of the structure and the layers of the first neural network model using a performance estimator;</claim-text><claim-text>obtaining third scores of the structure and the layers of the first neural network model using a pre-trained deep learning model for the first target device; and</claim-text><claim-text>obtaining performance scores of the structure and the layers of the first neural network model based on the first scores, the second scores, and the third scores.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of suitability determination algorithms include a second algorithm that is used to analyze a complexity and a capacity of a structure and layers of the first neural network model.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein performing the analysis includes:<claim-text>performing a second analysis on the first neural network model based on the second algorithm.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein performing the second analysis includes:<claim-text>obtaining fourth scores of the structure and the layers of the first neural network model by determining the complexity of the structure and the layers of the first neural network model;</claim-text><claim-text>obtaining fifth scores of the structure and the layers of the first neural network model by measuring the capacity of the structure and the layers of the first neural network model; and</claim-text><claim-text>obtaining complexity scores of the structure and the layers of the first neural network model based on the fourth scores and the fifth scores.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of suitability determination algorithms include a third algorithm that is used to determine a memory efficiency of a structure and layers of the first neural network model associated with the first target device.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein performing the analysis includes:<claim-text>performing a third analysis on the first neural network model based on the third algorithm.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein performing the third analysis includes:<claim-text>obtaining memory footprint scores of the structure and the layers of the first neural network model based on a memory limitation of the first target device.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising:<claim-text>changing the first neural network model based on the first neural network model being unavailable within the memory limitation.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein performing the analysis includes:<claim-text>obtaining performance scores of a structure and layers of the first neural network model associated with the first target device, by performing a first analysis on the first neural network model based on a first algorithm;</claim-text><claim-text>obtaining complexity scores of the structure and the layers of the first neural network model, by performing a second analysis on the first neural network model based on a second algorithm;</claim-text><claim-text>obtaining memory footprint scores of the structure and the layers of the first neural network model associated with the first target device, by performing a third analysis on the first neural network model based on a third algorithm; and</claim-text><claim-text>obtaining total scores of the structure and the layers of the first neural network model based on the performance scores, the complexity scores, and the memory footprint scores.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>changing at least one of layers of the first neural network model based on the result of the analysis.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the changing the at least one of the layers of the first neural network model includes:<claim-text>based on selecting of a first layer having a lowest score from among the layers of the first neural network model;</claim-text><claim-text>providing at least one second layer that has a score higher than that of the first layer as a candidate for replacing the first layer; and</claim-text><claim-text>changing the first layer based on the at least one second layer.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>applying different quantization schemes to at least some of layers of the first neural network model.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the applying the different quantization schemes to the at least some of the layers of the first neural network model includes:<claim-text>receiving second model information about the first neural network model, the second model information being obtained after a training on the first neural network model is completed;</claim-text><claim-text>changing a quantization scheme of a third layer, which is selected from among the layers of the first neural network model based on the second model information.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first model information and the result of the analysis are displayed on a graphical user interface (GUI).</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the result of the analysis is displayed based on at least one of scores or a color for a structure and layers of the first neural network model.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A computer-based neural network model processing system, comprising:<claim-text>an input device configured to receive first model information about a first neural network model and device information about a first target device that is used to execute the first neural network model;</claim-text><claim-text>a storage device configured to store information about program routines;</claim-text><claim-text>a processor configured to read and execute the program routines, which cause the processor to:<claim-text>perform an analysis whether the first neural network model is suitable for executing on the first target device, based on the first model information, the device information, and at least one of a plurality of suitability determination algorithms; and</claim-text><claim-text>generate a result of the analysis; and</claim-text></claim-text><claim-text>an output device configured to visually output the result of the analysis.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. (canceled)</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. A method of optimizing a neural network model, the method comprising:<claim-text>receiving first model information about a first neural network model;</claim-text><claim-text>receiving device information about a first target device that is used to execute the first neural network model;</claim-text><claim-text>performing an analysis whether the first neural network model is suitable for executing on the first target device, based on the first model information, the device information, and at least one of a plurality of suitability determination algorithms;</claim-text><claim-text>displaying a first graphical representation on a graphical user interface (GUI) such that the first model information and a result of the analysis are displayed on a screen, the first graphical representation including the first model information and the result of the analysis; and</claim-text><claim-text>displaying a second graphical representation on the GUI such that a result of changing at least one of layers of the first neural network model based on the result of the analysis is displayed.</claim-text></claim-text></claim></claims></us-patent-application>
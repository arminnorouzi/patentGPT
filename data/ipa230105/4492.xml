<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004493A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004493</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17902263</doc-number><date>20220902</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>12</main-group><subgroup>0811</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>12</main-group><subgroup>1009</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>12</main-group><subgroup>0811</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>12</main-group><subgroup>1009</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">BULK MEMORY INITIALIZATION</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/US2020/021153</doc-number><date>20200305</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17902263</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Huawei Technologies Co., Ltd.</orgname><address><city>Shenzhen</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Xie</last-name><first-name>Yuejian</first-name><address><city>Sunnyvale</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Wang</last-name><first-name>Qian</first-name><address><city>Santa Clara</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Jiang</last-name><first-name>Xingyu</first-name><address><city>Palo Alto</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Huawei Technologies Co., Ltd.</orgname><role>03</role><address><city>Shenzhen</city><country>CN</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The disclosure relates to technology for bulk initialization of memory in a computer system. The computer system comprises a processor core comprising a load store unit and a last level cache in communication with the processor core. The last level cache is configured to receive bulk store operations from the load store unit. Each bulk store operation includes a physical address in the memory to be initialized. The last level cache is configured to send multiple write transactions to the memory for each bulk store operation to perform a bulk initialization of the memory for each bulk store operation. The last level cache is configured to track status of the bulk store operations.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="174.07mm" wi="148.59mm" file="US20230004493A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="209.38mm" wi="122.17mm" file="US20230004493A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="131.15mm" wi="123.95mm" file="US20230004493A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="209.47mm" wi="109.05mm" file="US20230004493A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="220.30mm" wi="144.53mm" orientation="landscape" file="US20230004493A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="117.52mm" wi="116.59mm" file="US20230004493A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="229.28mm" wi="129.62mm" file="US20230004493A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="142.75mm" wi="123.27mm" file="US20230004493A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="181.53mm" wi="114.13mm" file="US20230004493A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="179.32mm" wi="129.62mm" file="US20230004493A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="174.16mm" wi="101.01mm" file="US20230004493A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="174.33mm" wi="133.94mm" file="US20230004493A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="196.68mm" wi="150.62mm" file="US20230004493A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CLAIM OF PRIORITY</heading><p id="p-0002" num="0001">This application is a continuation of PCT Patent Application No. PCT/US2020/021153, entitled &#x201c;BULK MEMORY INITIALIZATION&#x201d;, filed Mar. 5, 2020, the entire contents of which is hereby incorporated by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">The disclosure generally relates to memory initialization in a computing system.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Data movement is becoming a greater performance bottleneck in modern processors. To perform any operation on data that resides in main memory, a central processing unit (CPU) first issues a series of commands to the main memory (e.g., DRAM modules) across an off-chip bus that is commonly referred to as a memory channel. The main memory responds by sending the data to CPU, after which the data is placed within a cache. This process of moving data from the main memory to the CPU incurs a long latency, and consumes a significant amount of energy.</p><p id="p-0005" num="0004">Memory initialization is a process of establishing known values in the memory. Initialization of a region of memory could occur in response to an allocation of that region to, for example, a computer program or operating system. In some cases, memory is initialized to all zeroes. Initializing main memory is generally decomposed into a series of store instructions. Each store instruction may initialize a small region of main memory. For example, each store instruction may initialize a region of main memory that is the size of a cache line. The series of store instructions may be executed in CPU execution unit. Each store instruction may fetch a cache line into a cache, modify the cache line and write the cache line to the main memory. In those operations, the caches are not properly leveraged if the line brought into the caches are not reused later by the CPU.</p><heading id="h-0004" level="1">BRIEF SUMMARY</heading><p id="p-0006" num="0005">According to one aspect of the present disclosure, there is provided a computer system for initializing memory. The computer system comprises a processor core comprising a central processing unit (CPU), a load store unit, and an internal cache. The computer system comprises a last level cache in communication with the processor core. The last level cache is configured to receive bulk store operations from the load store unit. Each bulk store operation includes a physical address in the memory to be initialized. The last level cache is configured to send multiple write transactions to the memory for each bulk store operation to perform a bulk initialization of the memory for each bulk store operation. The last level cache is configured to track status of the bulk store operations.</p><p id="p-0007" num="0006">Optionally, in any of the preceding aspects, the last level cache is further configured to maintain cache coherence in a hierarchy of caches in the computer system when performing the bulk initialization of the memory for each bulk store operation.</p><p id="p-0008" num="0007">Optionally, in any of the preceding aspects, the load store unit comprises a bulk store combine buffer, and the load store unit is configured to store status of the bulk store operations in the bulk store combine buffer.</p><p id="p-0009" num="0008">Optionally, in any of the preceding aspects, the load store unit is further configured to send the bulk store operations directly to the last level cache while bypassing the internal cache.</p><p id="p-0010" num="0009">Optionally, in any of the preceding aspects, the load store unit is further configured to track bulk store operations that are pending. Each bulk store operation is associated with a region of the memory to be initialized. The load store unit is further configured to block younger loads associated with any region of the memory associated with any pending bulk store operation.</p><p id="p-0011" num="0010">Optionally, in any of the preceding aspects, the load store unit is configured to either set pending status for a bulk store operation to complete or remove the bulk store operation from the bulk store combine buffer in response to the last level cache indicating that the bulk store operation is complete.</p><p id="p-0012" num="0011">Optionally, in any of the preceding aspects, the last level cache is further configured to store information on intact status associated with each bulk store operation. The intact status indicates whether a region of the memory initialized by a bulk store operation is intact with initialization values. The last level cache is further configured to set the intact status to not intact responsive to another processor core writing to a region of the memory associated with a bulk store operation.</p><p id="p-0013" num="0012">Optionally, in any of the preceding aspects, the load store unit is further configured to invalidate an entry for a first bulk store operation in the bulk store combine buffer responsive to the intact status indicating that the status is not intact. The load store unit is further configured to maintain a corresponding entry for a second bulk store operation as a valid entry in the bulk store combine buffer responsive to the intact information indicating that the status is intact.</p><p id="p-0014" num="0013">Optionally, in any of the preceding aspects, the load store unit is further configured to respond to a younger load instruction that loads from a region of the memory initialized by a bulk store operation that is complete by providing known initialization values if the region is still intact.</p><p id="p-0015" num="0014">Optionally, in any of the preceding aspects, each bulk store operation initializes a region of the memory to all zeroes.</p><p id="p-0016" num="0015">Optionally, in any of the preceding aspects, each write transaction initializes a region of the memory that has a size of a cache line.</p><p id="p-0017" num="0016">Optionally, in any of the preceding aspects, each bulk store operation initializes a region of the memory that has a size of a page.</p><p id="p-0018" num="0017">Optionally, in any of the preceding aspects, the computer system further comprises logic configured to create a single bulk store operation from a plurality of store instructions that each are configured to initialize a cache line sized region in the memory.</p><p id="p-0019" num="0018">According to one other aspect of the present disclosure, there is provided a method of initializing memory in a computer system. The method comprises receiving, at a last level cache in a hierarchy of caches in the computer system, a bulk store operation from a load store unit in a processor core in the computer system. The method comprises performing a bulk initialization of the memory for each bulk store operation, including sending multiple write transactions from the last level cache to the memory for each bulk store operation. The method comprises tracking status of the bulk store operations.</p><p id="p-0020" num="0019">According to still one other aspect of the present disclosure, there is provided a computer system for initializing memory. The computer system comprises main memory, a central processing unit, a load store unit, and a hierarchy of caches comprising a last level cache. The load store unit comprises load store unit means for tracking status of page store operations. Each page store operation includes a physical address in the main memory. The last level cache comprises means for sending multiple write transactions to the main memory for each page store operation to initialize a page of the main memory. The last level cache comprises last level cache means for tracking status of the page store operations and reporting the status to the load store unit.</p><p id="p-0021" num="0020">This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter. The claimed subject matter is not limited to implementations that solve any or all disadvantages noted in the Background.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0022" num="0021">Aspects of the present disclosure are illustrated by way of example and are not limited by the accompanying figures for which like references indicate elements.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> is a block diagram of one embodiment of a computing system that may perform bulk initialization of memory.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>1</b>B</figref> is a block diagram of one embodiment of a last level cache that forms multiple write transactions from one bulk store operation.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts one embodiment of the bulk store engine in <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts one embodiment of bulk store operation buffer, which may reside in the bulk store engine.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts one embodiment of a load store unit.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts a flowchart of one embodiment of a process of performing a bulk initialization of memory.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts a flowchart of one embodiment of a process performed at load store unit with respect to a bulk store operation.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts a flowchart of one embodiment of a process of actions at the load store unit when a bulk store operation is initiated.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>8</b></figref> depicts one embodiment of a process of actions at the last level cache to track the status of a bulk store operation.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>9</b></figref> depicts a flowchart of one embodiment of a process of actions at the last level cache to initialize the memory for a bulk store operation.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>10</b></figref> depicts a flowchart of one embodiment of a process of actions at the last level cache to maintain cache coherence while processing a bulk store operation.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>11</b></figref> depicts a flowchart of one embodiment of a process of actions performed at the load store unit when a bulk store operation is completed.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>12</b></figref> depicts a flowchart of one embodiment of a process of a load store unit handling loads while, or after, a bulk store operation is pending.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0036" num="0035">The present disclosure will now be described with reference to the figures, which in general relate to bulk initialization of memory in a computing system. Bulk initialization of memory, as the term is used herein, refers to initializing a region of memory that is larger than a cache line in size. A cache line is a basic unit for cache storage and may also be referred to as a cache block. As one example, bulk initialization may be used to initialize a region that is four kilobytes in size (herein, a kilobyte is defined as 1024 bytes). In one embodiment, a load store unit in a processor core sends a bulk store operation to a last level cache. The last level cache is configured to send multiple write transactions to the memory for each bulk store operation in order to perform a bulk initialization of the memory. The last level cache is configured to track status of the bulk store operation. The last level cache is configured to maintain cache coherence in a hierarchy of caches when performing the bulk initialization of the memory for each bulk store operation. The bulk store operation may eliminate the need to have numerous store transactions at the load store unit, which saves considerable time. The bulk store operation may eliminate the need to transfer a series of store transactions over the cache hierarchy, thereby saving considerable time. The bulk store operation may reduce or eliminate the need to cache data in the cache hierarchy when performing bulk initialization of the memory, thereby saving considerable time and reducing complexity.</p><p id="p-0037" num="0036">In one embodiment, the load store unit has a bulk store combine buffer configured to hold status of the bulk store operations. The last level cache may report status of the bulk store operations to the load store unit. In one embodiment, the load store unit blocks younger loads associated with any region of the memory associated with any pending bulk store operation.</p><p id="p-0038" num="0037">It is understood that the present embodiments of the disclosure may be implemented in many different forms and that claims scopes should not be construed as being limited to the embodiments set forth herein. Rather, these embodiments are provided so that this disclosure will be thorough and complete and will fully convey the inventive embodiment concepts to those skilled in the art. Indeed, the disclosure is intended to cover alternatives, modifications and equivalents of these embodiments, which are included within the scope and spirit of the disclosure as defined by the appended claims. Furthermore, in the following detailed description of the present embodiments of the disclosure, numerous specific details are set forth in order to provide a thorough understanding. However, it will be clear to those of ordinary skill in the art that the present embodiments of the disclosure may be practiced without such specific details.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> is a block diagram of one embodiment of a computing system <b>100</b>. The computing system <b>100</b> is configured to perform bulk initialization of memory. The computing system <b>100</b> includes a processor core <b>102</b>, a last level cache (LLC) <b>104</b>, and main memory <b>108</b>. The main memory <b>108</b> is optional. In one embodiment, the main memory <b>108</b> is volatile memory, such as DRAM or SRAM. However, the main memory <b>108</b> is not required to be volatile memory.</p><p id="p-0040" num="0039">The processor core <b>102</b> contains at least one central processing unit (CPU) <b>110</b>, a load store unit (LSU) <b>112</b>, and internal cache <b>114</b>. The term internal cache <b>114</b> refers to cache that is on the same semiconductor die (chip) as the CPU <b>110</b>. In one embodiment, the internal cache <b>114</b> contains an L1 cache and an L2 cache. Thus, the internal cache <b>114</b> may include more than one level of caches. A computing system may use a cache to improve computing performance. For instance, a computing system may store data that it needs to access more frequently in a smaller, faster cache memory instead of storing the data in a slower, larger memory (e.g., main memory <b>108</b>).</p><p id="p-0041" num="0040">The computing system <b>100</b> has a hierarchy of caches that are ordered in what are referred to herein as cache levels. Typically, the cache levels are numbered from a highest level cache to lowest level cache. There may be two, three, four, or even more levels in the cache hierarchy. Herein, a convention is used to refer to the highest level cache with the lowest number, with progressively lower levels receiving progressively higher numbers. For example, the highest level cache in the hierarchy may be referred to as L1 cache. Here, the lower level cache levels may be referred to as L2 cache, L3 cache, L4 cache, etc. In one embodiment, the internal cache <b>114</b> has L1 cache, which is a small, fast cache near the central processing unit <b>110</b>. The lowest level cache is referred to as a last level cache (LLC) <b>104</b>.</p><p id="p-0042" num="0041">In one embodiment, the computing system <b>100</b> performs a bulk initialization of main memory <b>108</b>. In some conventional techniques, a processor core <b>102</b> initializes main memory <b>108</b> by sending commands to initialize cache line size regions of main memory <b>108</b>. In one embodiment, the processor core <b>102</b> sends a single bulk store operation to the last level cache <b>104</b> in order to initialize a large region in main memory <b>108</b>. As one example, the region could be four kilobytes in size. In one embodiment, the bulk store operation is used to initialize a region that has the size of page. Herein, a page is defined as the smallest unit of data for memory management in a virtual address space. A page is typically described by a single entry in a page table. A page could be the equivalent of, for example, 64 cache lines. Thus, the processor core <b>102</b> sends one bulk store operation instead of 64 store transactions, as one example. Moreover, the load store unit <b>112</b> may send the bulk store operation directly to the last level cache <b>104</b>, bypassing the internal cache <b>114</b> (e.g., L1 cache, L2 cache) in the processor core <b>102</b>. Bypassing the internal cache <b>114</b> improves efficiency. The bulk store operation may be referred to as a page store operation when the region of memory that is initialized is a page in size. In general, the bulk store operation is used to initialize a region of memory that is multiple cache lines in size.</p><p id="p-0043" num="0042">The last level cache <b>104</b> forms multiple write transactions from one bulk store operation. The last level cache <b>104</b> is configured to send multiple write transactions to the main memory <b>108</b> for each bulk store operation to perform a bulk initialization of the main memory <b>108</b> for each bulk store operation. The last level cache <b>104</b> is configured to track status of the bulk store operations received from the load store unit <b>112</b>. Further details of one embodiment of the last level cache are depicted in <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>.</p><p id="p-0044" num="0043">Note that the main memory <b>108</b> could be shared between the processor core <b>102</b> depicted in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> and other processors (not depicted in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>). It is possible that such other processors could attempt to access a region of main memory <b>108</b> during bulk initialization of that region. In other words, such accesses could leave the region in a state such that it is not certain that the region still contains the values to which it was initialized. Herein, the region being intact means that the region still contains the values to which it was initialized. The last level cache <b>104</b> is configured to track such possible accesses and, if necessary, change the status from intact to not intact. Such status may be reported to the load store unit <b>112</b>.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>1</b>B</figref> depicts of one embodiment of a last level cache <b>104</b> that forms multiple write transactions from one bulk store operation. The last level cache <b>104</b> has a bulk store engine <b>118</b> and a cache pipeline <b>120</b>. The bulk store engine <b>118</b> and cache pipeline <b>120</b> may be implemented in hardware. In one embodiment, bulk store engine <b>118</b> comprises combinational logic and sequential logic. In one embodiment, the cache pipeline <b>120</b> comprises combinational logic and sequential logic. In one embodiment, to initiate a bulk initialization of main memory <b>108</b>, the load store unit <b>112</b> in the processor core <b>102</b> sends a bulk store operation to the last level cache <b>104</b>. In one embodiment, the bulk store engine <b>118</b> generates multiple write transactions for the bulk store operation, and sends the multiple write transactions to the cache pipeline <b>120</b>. The cache pipeline <b>120</b> processes each write transaction. In one embodiment, the cache pipeline maintains cache coherency in the caches in the computer system <b>100</b>, while the bulk store operation is being processed. The write transactions may be cache line sized transactions.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts one embodiment of the bulk store engine <b>118</b> depicted in <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>. The bulk store engine <b>118</b> is configured to perform a bulk initialization of a region in main memory <b>108</b> for each bulk store operation. The bulk store engine <b>118</b> has write transaction former <b>202</b> that is configured to form multiple write transactions for each bulk store operation. In one embodiment, each write transaction is for a cache line sized region in main memory <b>108</b>. In one embodiment, the write transaction former <b>202</b> sends the write transactions cache pipeline <b>120</b>, which sends a corresponding number of write transactions to the main memory <b>108</b>.</p><p id="p-0047" num="0046">The bulk store engine <b>118</b> has a bulk store status tracker <b>204</b> that is configured to track the status of each bulk store operation. The bulk store status tracker <b>204</b> keeps track of the status in a bulk store operation buffer <b>206</b>. The write transaction former <b>202</b> and the bulk store status tracker <b>204</b> may be part of a cache controller in the last level cache <b>104</b>. In one embodiment, the write transaction former <b>202</b> is implemented in hardware. For example, the write transaction former <b>202</b> may be implemented with sequential and/or combinational logic. In one embodiment, bulk store status tracker <b>204</b> is implemented in hardware. For example, the bulk store status tracker <b>204</b> may be implemented with sequential and/or combinational logic. For purpose of discussion, the bulk store operation buffer <b>206</b> is depicted in the bulk store engine <b>118</b>. The bulk store operation buffer <b>206</b> may be implemented in a portion of the memory that is used for cache entries in the last level cache <b>104</b>. Further details of one embodiment of bulk store operation buffer <b>206</b> are shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts one embodiment of the bulk store operation buffer <b>206</b>. When the bulk store engine <b>118</b> receives a bulk store operation, the bulk store engine <b>118</b> creates a new entry in the bulk store operation buffer <b>206</b>. Each bulk store operation includes a physical address (PA) <b>304</b>, which is the starting physical address in memory (e.g., main memory <b>108</b>) to be initialized. In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, there are entries for two bulk store operations. One of the entries has a physical address of 0x8000 (in hexadecimal or HEX). The other entry has a physical address of 0x9000. The size of the region in memory to be initialized may be a default value. Hence, the size need not be specified in the bulk store operation. Optionally, the size of the region may be specified in the bulk store operation. For the sake of illustration, an example will be discussed in which the size is 4 kilobytes (or 1000 HEX). Hence, one of the bulk store operations may be used to initialize physical addresses between 0x8000 and 0x8FFF (inclusive). The other bulk store operation may be used to initialize physical addresses between 0x9000 and 0x9FFF (inclusive).</p><p id="p-0049" num="0048">As each bulk store operation is being processed, the bulk store engine <b>118</b> tracks status of the bulk store operation. The column labeled &#x201c;Progress&#x201d; <b>306</b> is used to track how far along the bulk store operation has proceeded. As noted above, the bulk store engine <b>118</b> forms multiple write transactions for each bulk store operation. The progress column <b>306</b> is used to track how many of the write transactions have been completed. In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, one of the bulk store operations is done, and the other has 53 write transactions completed. There may be, for example, 64 write transactions to main memory <b>108</b> for a bulk store operation.</p><p id="p-0050" num="0049">As each bulk store operation is being processed, the bulk store engine <b>118</b> also monitors whether the region in main memory <b>108</b> associated with a bulk store transaction is affected by any other stores to main memory <b>108</b>. For example, during the bulk initialization of a region in main memory <b>108</b>, a portion of that region could be written to. This write might come from a processor core other than the processor core that initiated the bulk store operation. The column labeled &#x201c;Intact&#x201d; (with each entry being referred to as intact flag <b>308</b>) is used to track whether the region is intact.</p><p id="p-0051" num="0050">The column labeled &#x201c;Valid&#x201d; (with each entry being referred to as an LLC valid flag <b>302</b>) is used to track whether the entry is still valid. In one embodiment, the entry for a bulk store operation is invalidated if the intact flag <b>308</b> is set to zero. Otherwise, the entry may remain in the bulk store operation buffer <b>206</b> after the bulk store operation is complete.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts one embodiment of a load store unit <b>112</b>. The load store unit <b>112</b> has a store queue <b>402</b>, a store combine buffer <b>404</b>, and a bulk store combine buffer <b>406</b>. The store queue <b>402</b>, store combine buffer <b>404</b>, and bulk store combine buffer <b>406</b> may be implemented in memory in the processor core <b>102</b>. The bulk store manager <b>408</b> is configured to maintain the bulk store combine buffer <b>406</b>. The bulk store manager <b>408</b> may be implemented in hardware.</p><p id="p-0053" num="0052">A number of entries <b>402</b>-<b>1</b> to <b>402</b>-<b>8</b> are depicted on the store queue <b>402</b>. The entries may be executed in an order from entry <b>402</b>-<b>1</b> to entry <b>402</b>-<b>8</b>. The entries correspond to the instructions in Table I. However, since instruction I4 is a load instruction, it is not represented on the store queue <b>402</b>. In the store instructions in Table I, the physical address in main memory at which to store some value may be derived from register R1. In some cases, register R1 contains a virtual address, which is converted into a physical address in main memory <b>108</b>.</p><p id="p-0054" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="offset" colwidth="35pt" align="left"/><colspec colname="1" colwidth="56pt" align="left"/><colspec colname="2" colwidth="126pt" align="left"/><thead><row><entry/><entry namest="offset" nameend="2" rowsep="1">TABLE I</entry></row><row><entry/><entry namest="offset" nameend="2" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/><entry>I0:</entry><entry>STR [R1], R8</entry></row><row><entry/><entry>I1:</entry><entry>STR [R1 + 0x40], R9</entry></row><row><entry/><entry>I2:</entry><entry>STR [R1 + 0x80], R9</entry></row><row><entry/><entry>I3:</entry><entry>DC ZVA PG [R1]</entry></row><row><entry/><entry>I4:</entry><entry>LDR R3, [R1 + 0x40]</entry></row><row><entry/><entry>I5:</entry><entry>STR [R1 + 0xc0], R9</entry></row><row><entry/><entry>I6:</entry><entry>DC ZVA PG [R1 + 0x1000]</entry></row><row><entry/><entry>I7:</entry><entry>DC ZVA PG [R1 + 0x2000]</entry></row><row><entry/><entry>I8:</entry><entry>DC ZVA PG [R1]</entry></row><row><entry/><entry namest="offset" nameend="2" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0055" num="0053">Entry <b>402</b>-<b>1</b> holds an operation (St0) corresponding to instruction I0 in Table I. Entry <b>402</b>-<b>1</b> is thus an operation to store the contents of register R8 to physical address 0x1000 in main memory <b>108</b>. Entry <b>402</b>-<b>2</b> holds an operation (St1) corresponding to instruction I1 in Table I. Entry <b>402</b>-<b>2</b> is thus an operation to store the contents of register R9 to physical address 0x1040 in main memory <b>108</b>. Entry <b>402</b>-<b>3</b> holds an operation (St2) corresponding to instruction I2 in Table I. Entry <b>402</b>-<b>3</b> is thus an operation to store the contents of register R9 to physical address 0x1080 in main memory <b>108</b>. These three store operations (St0, St1, St2) may be conventional store operations, which may each store to a region of memory equal to 64 bytes. The region may be larger or smaller (e.g., 32 bytes or 128 bytes). In one embodiment, 64 bytes is the size of a cache line. The cache line may be larger or smaller (e.g., 32 bytes or 128 bytes).</p><p id="p-0056" num="0054">Entry <b>402</b>-<b>4</b> corresponds to instruction I3 in Table I and holds a bulk store operation (BlkSt0). The bulk store operation has a physical address of 0x8000. In one embodiment, the bulk store operation is used to initialize a region of 0x1000 in main memory <b>108</b>. In one embodiment, the bulk store operation is used to initialize a region the size of a page in main memory <b>108</b>. The page may be, for example, 4 kilobytes (or 1000 HEX) in size. Note that in Table I, instruction I3 specifies register R3, which indicates that the physical address may be obtained based on the contents of register R3. In some embodiments, register R3 contains a virtual address, which is translated to a physical address in main memory <b>108</b>. Instruction I3 does not contain an operand for the data to be stored at the physical address, as the data may be implied by the DC ZVA PG instruction. In one embodiment, the DC ZVA PG instruction implies that the contents of memory are to be zeroed out. However, the DC ZVA PG instruction could be used to imply some other pattern, such as initializing the memory to all ones. Optionally, an operand could be provided in the DC ZVA PG instruction to, for example, provide a pattern to be written to memory. For example, a second register could be specified in the DC ZVA PG instruction, wherein the contents of the second register contain a pattern to be written to memory. Note that this pattern may be repeated many times, as the size of the region to be initialized in memory is typically much larger than the register.</p><p id="p-0057" num="0055">There is not an entry on the store queue <b>402</b> for instruction I4, as instruction I4 is a load instruction, as opposed to a store instruction. However, there may be a load queue (not depicted in <figref idref="DRAWINGS">FIG. <b>4</b></figref>) in the load store unit <b>112</b> on which a load operation for instruction I4 may be placed. In one embodiment, the bulk store manager <b>408</b> blocks younger loads to regions of memory that are being initialized by bulk store operations. Hence, it is possible that the bulk store manager <b>408</b> could block instruction I4 from executing due a pending bulk store operation to the region of memory from which instruction I4 is to load.</p><p id="p-0058" num="0056">Entry <b>402</b>-<b>5</b> holds an operation (St3) corresponding to I5 in Table I. Thus, entry <b>402</b>-<b>5</b> is an operation to store the contents of register R9 at a physical address 0x10c0 in main memory <b>108</b>. Entry <b>402</b>-<b>6</b> holds a bulk store operation (BlkSt1) corresponding to instruction I6 in Table 1. The bulk store operation St1 has a physical address of 0x9000, which is determined based on adding 0x1000 to the contents of register R1 (see Table 1). As noted above, the contents of register R1 could be a virtual address, which is translated to a physical address. Entry <b>402</b>-<b>7</b> holds a bulk store operation (BlkSt2) corresponding to instruction I7 in Table 1. The bulk store operation St2 has a physical address of 0xa000, which is determined based on adding 0x2000 to the contents of register R1 (see Table 1). Entry <b>402</b>-<b>8</b> holds a bulk store operation (BlkSt3) corresponding to instruction I8 in Table 1. The bulk store operation St3 has a physical address of 0x8000, which is determined based on the contents of register R1 (see Table 1).</p><p id="p-0059" num="0057">The store combine buffer <b>404</b> is used to track store operations. As indicated by the physical addresses, entries for the first three conventional store operations (St0, St1, St2) are represented in the store combine buffer <b>404</b>. The store combine buffer <b>404</b> has a column that indicates whether the respective store operation resulted in a cache hit. The store combine buffer <b>404</b> has a column that indicates whether the entry is currently valid.</p><p id="p-0060" num="0058">The bulk store combine buffer <b>406</b> is used to track bulk store operations. As indicated by the physical addresses in the physical address column <b>424</b>, entries for the first three bulk store operations (BlkSt0, BlkSt1, BlkSt2) are represented in the bulk store combine buffer <b>406</b>. The bulk store combine buffer <b>406</b> has a column that indicates whether the respective bulk store operation is pending (referred to a pending flag <b>426</b>). The bulk store combine buffer <b>406</b> has a column that indicates whether the entry is currently valid (referred to a LSU valid flag <b>422</b>).</p><p id="p-0061" num="0059">The bulk store manager <b>408</b> is configured to maintain the bulk store combine buffer <b>406</b>. The bulk store manager <b>408</b> may add entries to the bulk store combine buffer <b>406</b> when a bulk store operation is initiated. The bulk store manager <b>408</b> may update the status (e.g., pending, valid) in response to status reports from the bulk store engine <b>118</b> in the LLC <b>104</b>. Further details of one embodiment of maintaining the bulk store combine buffer <b>406</b> are described in connection with <figref idref="DRAWINGS">FIG. <b>12</b></figref> to be discussed below. In one embodiment, the bulk store manager <b>408</b> blocks younger loads to any region of main memory <b>108</b> for which a bulk store operation is pending. Further details of one embodiment of blocking younger loads are described in connection with <figref idref="DRAWINGS">FIG. <b>12</b></figref> to be discussed below. The bulk store manager <b>408</b> may be implemented in hardware. In one embodiment, the bulk store manager <b>408</b> comprises combinational logic and sequential logic.</p><p id="p-0062" num="0060"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts a flowchart of one embodiment of a process <b>500</b> of performing a bulk initialization of memory. The process <b>500</b> may be used in computer system <b>100</b> to initialize main memory <b>108</b>. In one embodiment, process <b>500</b> is performed by bulk store engine <b>118</b> in LLC <b>104</b>. Reference will be made to elements in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> when discussing process <b>500</b>; however, process <b>500</b> is not limited to <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>. Steps <b>504</b>-<b>506</b> in process <b>500</b> are described in a certain order as a matter of convenience of explanation and do not necessarily occur in the depicted order. Thus, steps <b>504</b>-<b>506</b> could occur in a different order. Also, steps <b>504</b>-<b>506</b> may be performed concurrently.</p><p id="p-0063" num="0061">Step <b>502</b> includes receiving a bulk store operation at a last level cache (LLC) <b>104</b> in a computer system <b>100</b>. In one embodiment, the processor core <b>102</b> sends the bulk store operation to the LLC <b>104</b>. In one embodiment, the load store unit <b>112</b> sends the bulk store operation to the LLC <b>104</b>. The bulk store operation may bypass the other caches, such as internal cache <b>114</b> (e.g., L1 cache and L2 cache). Therefore, the other caches may be offloaded during the bulk store operation.</p><p id="p-0064" num="0062">Step <b>504</b> includes performing a bulk initialization of memory for the bulk store operation. In one embodiment, bulk initialization of main memory <b>108</b> is performed. In one embodiment, the bulk initialization results in a zeroing out of a region of the memory. In other words, the contents of the region of memory may be all zeros after the bulk initialization. However, a different pattern could result from the bulk initialization. For example, the contents of the region of memory may be all ones after the bulk initialization. A different pattern could result such as alternating ones and zeroes. Further details of one embodiment of performing a bulk initialization of memory are shown and described with respect to <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0065" num="0063">Step <b>506</b> includes tracking status of the bulk store operation. In one embodiment, the bulk store engine <b>118</b> updates the bulk store operation buffer <b>206</b>. For example, the bulk store engine <b>118</b> may update the progress column, the intact column, and the valid column. Further details of one embodiment of tracking status of a bulk initialization operation are shown and described with respect to <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0066" num="0064"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts a flowchart of one embodiment of a process <b>600</b> performed at load store unit <b>112</b> with respect to a bulk store operation. The process <b>600</b> may be initiated when instructions being executed in the processor core <b>102</b> indicate that a bulk store operation is to be performed.</p><p id="p-0067" num="0065">Process <b>600</b> describes two ways in which a bulk store operation may be initiated. Step <b>602</b><i>a </i>describes Option A in which the bulk store operation is obtained from a bulk store instruction in a set of instructions executed in the processor core <b>102</b>. Table I shows a set of instructions that contain four bulk store instructions (Instructions I3, I6, I7, and I8).</p><p id="p-0068" num="0066">Step <b>602</b><i>b </i>describes Option B in which the bulk store operation is formed based on a number of store instructions. Each of these store instructions are to store the same values to memory. For example, each of the store instructions may be to zero out memory. However, each of these store instructions may be to store to a different region in memory. Collectively, the store instructions may be configured to store to a contiguous region of the memory. Table II depicts example store instructions from which a bulk store operation may be formed. Forming a single bulk store operation from multiple store instructions may be referred to as code morphing. In one embodiment, the bulk store manager <b>408</b> is able to perform the code morphing. For convenience of explanation the instructions are numbered from I0 to I63 in Table II, but these are not the same instructions as in Table I.</p><p id="p-0069" num="0000"><tables id="TABLE-US-00002" num="00002"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="offset" colwidth="35pt" align="left"/><colspec colname="1" colwidth="63pt" align="left"/><colspec colname="2" colwidth="119pt" align="left"/><thead><row><entry/><entry namest="offset" nameend="2" rowsep="1">TABLE II</entry></row><row><entry/><entry namest="offset" nameend="2" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/><entry>I0:</entry><entry>STR [R1], R8</entry></row><row><entry/><entry>I1:</entry><entry>STR [R1 + 0x040], R8</entry></row><row><entry/><entry>I2:</entry><entry>STR [R1 + 0x080], R8</entry></row><row><entry/><entry>.</entry></row><row><entry/><entry>.</entry></row><row><entry/><entry>.</entry></row><row><entry/><entry>I63:</entry><entry>STR [R1 + 0xFC0], R8</entry></row><row><entry/><entry namest="offset" nameend="2" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0070" num="0067">In Table II, each store instruction is associated with a region of memory having a size of 40 HEX (or 64 bytes). In Table II, each of the store instructions specifies the address based on the contents of register R1. In one embodiment, register R1 contains a virtual address that is translated to a physical address in main memory <b>108</b>. The 64 store instructions are thus to write to a contiguous region of memory totaling four kilobytes. Note that the size of the region to which each instruction writes, the total size of the region that all instructions write, and the number of instructions are all for the purpose of example. However, the store instructions from which the bulk store operation is formed should write to a contiguous region of memory.</p><p id="p-0071" num="0068">In Table II, each of the store instructions specifies the data based on the contents of register R8. This is for the purpose of illustration. In one embodiment, the data should be the same for all of the store instructions. In one embodiment, the data is not expressly provided, but is implied. For example, the second register (R8 in Table II) need not be provided in one embodiment, wherein the data is implied. The implied data could be to zero out the memory.</p><p id="p-0072" num="0069">Step <b>604</b> includes calculating a physical address to be initialized in memory. Step <b>604</b> may include a virtual address to physical address translation. In one embodiment, the addresses contained in the register(s) referenced in the instructions from which bulk store operations are formed are virtual addresses. For example, the address in register R1 in the instructions in Table I may be a virtual address. Likewise, the address in register R1 in the instructions in Table II may be a virtual address.</p><p id="p-0073" num="0070">Step <b>606</b> includes allocating an entry in the bulk store combine buffer <b>406</b> for the bulk store operation.</p><p id="p-0074" num="0071">Step <b>608</b> includes the load store unit <b>112</b> sending a bulk store operation to the last level cache <b>104</b>. The bulk store operation includes the physical address in main memory <b>108</b> that is to be initialized. The bulk store operation also includes an operand or other identifier that indicates that this is a bulk store operation. In one embodiment, the load store unit <b>112</b> sends the bulk store operation directly to the last level cache <b>104</b>, bypassing all other caches in a cache hierarchy (such as internal cache <b>114</b>). This has the benefit of offloading the other caches from processing the bulk store operation.</p><p id="p-0075" num="0072">Step <b>610</b> includes the load store unit <b>112</b> waiting for the bulk store operation to complete. By waiting for the bulk store operation it is meant that the load store unit <b>112</b> does not take action to initialize the main memory <b>108</b>, as that is left to the last level cache <b>104</b>.</p><p id="p-0076" num="0073">Step <b>612</b> is performed while waiting for the bulk store operation to complete. Step <b>612</b> includes blocking younger loads to the region of main memory <b>108</b> being initialized by the bulk store operation. A younger load means a load that, in strict accordance with the order of instructions, is to occur after the bulk store operation. Note that sometimes instructions to load from memory or store to memory may be executed out of order. With respect to Table I, instruction I4 is a younger load relative to instruction I3. Thus, if the bulk store operation originated from instruction I3, the load associated with instruction I4 would be blocked until the bulk store operation completes, under the assumption that the load is from a region of main memory <b>108</b> being initialized by the bulk store operation. However, instruction I4 is not a younger load with respect to instructions I6, I7 or I8. Thus, if the bulk store operation originated from any of instructions I6, I7 or I8, the load associated with instruction I4 would not be blocked. Further details of one embodiment of blocking younger loads are described below in connection with <figref idref="DRAWINGS">FIG. <b>12</b></figref>.</p><p id="p-0077" num="0074">After the bulk store operation is finished, step <b>614</b> is performed. In one embodiment, the last level cache <b>104</b> informs the load store unit <b>112</b> when the bulk store operation is finished. Step <b>614</b> includes releasing/updating the entry for the bulk store operation in the bulk store combine buffer <b>406</b>. Releasing the entry means to remove or otherwise mark the entry so that it is no longer used. In one embodiment, the entry is marked invalid to release it. In one embodiment, the entry is physically deleted to release it. Updating the entry means that the entry is changed in some manner and that the information in the entry may still be used. In one embodiment, the pending status is changed from pending to not pending, and the LSU valid flag <b>422</b> is kept at valid when updating the entry. A status of not pending may also be referred to as complete. Further details of one embodiment of releasing/updating the entry for the bulk store operation are described below in connection with <figref idref="DRAWINGS">FIG. <b>11</b></figref>.</p><p id="p-0078" num="0075"><figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts a flowchart of one embodiment of a process <b>700</b> of actions at the load store unit <b>112</b> when a bulk store operation is initiated. Process <b>700</b> may be performed after a bulk store operation has been added to the store queue <b>402</b>. Process <b>700</b> describes further details of one embodiment of step <b>606</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0079" num="0076">Step <b>702</b> includes the load store unit <b>112</b> accessing a bulk store operation from the store queue <b>402</b>. For the sake of illustration, the bulk store operation at entry <b>402</b>-<b>6</b> will be discussed in process <b>700</b>.</p><p id="p-0080" num="0077">Step <b>704</b> includes creating an entry for the bulk store operation to the bulk store combine buffer <b>406</b>. Step <b>704</b> also includes adding the physical address for the bulk store operation to the entry. Step <b>706</b> includes setting the pending flag <b>426</b> in the entry to &#x201c;1&#x201d;. Step <b>708</b> includes setting the LSU valid flag <b>422</b> in the entry to &#x201c;1&#x201d;. With reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the entry having physical address 0x9000 as added. The pending flag <b>426</b> for the entry is set to &#x201c;1&#x201d;. The LSU valid flag <b>422</b> for the entry is set to &#x201c;1&#x201d;.</p><p id="p-0081" num="0078"><figref idref="DRAWINGS">FIG. <b>8</b></figref> depicts one embodiment of a process <b>800</b> of actions at the last level cache <b>104</b> to track the status of a bulk store operation. Process <b>800</b> provides further details of one embodiment of step <b>506</b> in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. In one embodiment, process <b>800</b> is performed by bulk store status tracker <b>204</b>.</p><p id="p-0082" num="0079">Step <b>802</b> includes the last level cache <b>104</b> receiving a bulk store operation from the load store unit <b>112</b>. In one embodiment, step <b>802</b> occurs as a result of step <b>608</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. The bulk store operation contains an operand (or other type of identifier) that indicates that this is a bulk store operation. In an embodiment, the last level cache <b>104</b> identifies this as a bulk store operation based on the operand. In an embodiment, the bulk store operation also contains a physical address in main memory <b>108</b> that is to be initialized.</p><p id="p-0083" num="0080">Step <b>804</b> includes the bulk store engine <b>118</b> in the last level cache <b>104</b> creating an entry for the bulk store operation in the bulk store operation buffer <b>206</b>. Step <b>804</b> also includes adding the physical address in the bulk store operation to the buffer entry.</p><p id="p-0084" num="0081">Step <b>806</b> includes setting the intact flag <b>308</b> in the entry to &#x201c;1&#x201d;. Step <b>808</b> includes setting the LLC valid flag <b>302</b> in the entry to &#x201c;1&#x201d;. With reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the entry having physical address 0x9000 as added, as one example. The pending flag for the entry is set to &#x201c;1&#x201d;. The LLC valid flag <b>302</b> for the entry is set to &#x201c;1&#x201d;. The progress field is initially set to 0 to indicate that the process of sending write transactions to the main memory <b>108</b> has not yet started.</p><p id="p-0085" num="0082">Step <b>810</b> includes tracking the status of the bulk store operation. Step <b>810</b> includes modifying the progress field as more of the memory is initialized for this bulk store operation. Further details of updating the progress field are described in connection with <figref idref="DRAWINGS">FIG. <b>9</b></figref>. Step <b>810</b> may include modifying the intact flag <b>308</b> for the entry. Step <b>810</b> may include modifying the LLC valid flag <b>302</b> for the entry.</p><p id="p-0086" num="0083">Step <b>812</b> includes the last level cache <b>104</b> reporting the completion of the bulk store operation to the load store unit <b>112</b>. Step <b>812</b> also includes the last level cache <b>104</b> reporting the status of the bulk store operation to the load store unit <b>112</b>. In one embodiment, the status includes the intact status.</p><p id="p-0087" num="0084"><figref idref="DRAWINGS">FIG. <b>9</b></figref> depicts a flowchart of one embodiment of a process <b>900</b> of actions at the last level cache <b>104</b> to initialize the memory for a bulk store operation. Process <b>900</b> provides further details of one embodiment of step <b>504</b> in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0088" num="0085">Step <b>902</b> includes setting an initial physical address to the address in the bulk store operation. This is a physical address in main memory <b>108</b>, in one embodiment.</p><p id="p-0089" num="0086">Step <b>904</b> includes forming a write transaction to write at the current physical address. In one embodiment, the write transaction is a write transaction that writes one cache line. In one embodiment, the write transaction is a WriteUnique transaction. In one embodiment, the WriteUnique transaction is compliant with the AMBA&#xae; 5 CHI Architecture Specification, which is published by ARM Ltd. As known to those of ordinary skill in the art, there are a variety of types of WriteUnique transactions (e.g., WriteUniquePtl, WriteUniqueFull, WriteUniquePtlStash, WriteUniqueFullStash).</p><p id="p-0090" num="0087">Step <b>906</b> includes sending the write transaction to the main memory <b>108</b>. Step <b>906</b> may also include receiving a response from the main memory reporting the status of the write transaction. For the sake of discussion, it is assumed in process <b>900</b> that all write transactions complete successfully. However, if there is an error with one or more write transactions, then the process <b>900</b> could end with an error status.</p><p id="p-0091" num="0088">In one embodiment, step <b>906</b> includes sending the WriteUnique transaction that was formed in step <b>904</b> to the cache pipeline <b>120</b>. The WriteUnique transaction may be used to remove all copies of a cache line before issuing a write transaction to main memory <b>108</b>. The WriteUnique transaction could result in a back snoop to the processor core <b>102</b>. The WriteUnique transaction could result in snoops of other processor cores, as well. After the snoops are done, the data is written to the main memory <b>108</b>.</p><p id="p-0092" num="0089">Step <b>908</b> includes updating the progress of the bulk store operation in the buffer <b>206</b> in the bulk store engine <b>118</b>. In one embodiment, the progress field serves as a counter of the number of write transaction that have successfully completed. Thus, the progress field may be incremented by one each time a write transaction successfully completes.</p><p id="p-0093" num="0090">Step <b>910</b> is a determination of whether the bulk store operation is done. In other words, the bulk store engine <b>118</b> determines whether all of the write transactions have successfully completed. If not, then control passes to step <b>912</b>, wherein the physical address is incremented. The size of the increment is equal to the size of each write transaction, in one embodiment. The size of the increment is equal to the size of a cache line, in one embodiment.</p><p id="p-0094" num="0091">After step <b>912</b>, control passes to step <b>904</b>. In step <b>904</b> another write transaction is formed using the current value of the physical address. When all write transactions successfully complete (step <b>910</b> is yes), control passes to step <b>914</b>. Step <b>914</b> includes the last level cache <b>104</b> sending a completion status for the bulk store operation to the load store unit <b>112</b>. In one embodiment, the completion status includes an indication of whether the bulk store operation was successful at initializing memory. In one embodiment, the completion status includes the intact status for the bulk store operation entry in buffer <b>206</b>.</p><p id="p-0095" num="0092"><figref idref="DRAWINGS">FIG. <b>10</b></figref> depicts a flowchart of one embodiment of a process <b>1000</b> of actions at the last level cache <b>104</b> to maintain cache coherence while processing a bulk store operation. In one embodiment, process <b>1000</b> is performed for each of the write transactions in step <b>906</b> of process <b>900</b>. Thus, process <b>1000</b> provides further details for one embodiment of step <b>906</b>. In one embodiment, process <b>1000</b> is performed by the cache pipeline <b>120</b> in the last level cache <b>104</b>. Process <b>1000</b> may be performed for each write transaction (e.g., each WriteUnique transaction) sent to the cache pipeline <b>120</b>.</p><p id="p-0096" num="0093">Step <b>1002</b> includes the bulk store engine <b>118</b> sending a write transaction to the cache pipeline <b>120</b>. As noted above, this may be a WriteUnique transaction. In one embodiment, the write transaction is to write to a region of memory having the size of a cache line.</p><p id="p-0097" num="0094">Step <b>1004</b> includes the last level cache <b>104</b> checking the tag and the snoop filter. The tag may be used to determine whether the last level cache <b>104</b> has a cache line associated with the address in main memory to be initialized by the write transaction. The snoop filter may be examined to determine whether another cache has a cache line associated with the address in main memory to be initialized by the write transaction. The snoop filter thus keeps track of coherency states of cache lines.</p><p id="p-0098" num="0095">Step <b>1006</b> includes the last level caching <b>104</b> snooping. Step <b>1006</b> may result in a back snoop to the processor core <b>102</b> that initiated the bulk store operation. Step <b>1006</b> may result in a snoop of other processor cores that share the main memory <b>108</b>.</p><p id="p-0099" num="0096">Step <b>1008</b> includes the last level cache <b>104</b> updating the tag and the snoop filter. Hence, the last level cache is able to maintain cache coherence while processing the bulk store operation.</p><p id="p-0100" num="0097">Step <b>1010</b> includes updating the status for the bulk store operation, if necessary. Note that during process <b>1000</b>, other processor cores could be trying to read or write to a portion of the main memory <b>108</b> that is being initialized by the bulk store operation. In one embodiment, if any read request touches the region of main memory <b>108</b> being initialized, the intact flag <b>308</b> in the bulk store operation buffer <b>206</b> is set to 0. In one embodiment, if any snoop request touches the region of main memory <b>108</b> being initialized, the intact flag <b>308</b> is set to 0.</p><p id="p-0101" num="0098">Step <b>1012</b> includes the last level cache sending a write transaction to the main memory <b>108</b>.</p><p id="p-0102" num="0099"><figref idref="DRAWINGS">FIG. <b>11</b></figref> depicts a flowchart of one embodiment of a process <b>1100</b> of actions performed at the load store unit <b>112</b> when a bulk store operation is completed.</p><p id="p-0103" num="0100">Step <b>1102</b> includes the load store unit <b>112</b> receiving an indication from the last level cache <b>104</b> that the bulk store operation has completed.</p><p id="p-0104" num="0101">Step <b>1104</b> includes the load store unit <b>112</b> checking whether an intact flag <b>308</b> in the response is set to 1 or 0. The last level cache <b>104</b> sets the intact flag <b>308</b> to 1 to indicate that the region of memory being initialized is still intact. The last level cache sets the intact flag <b>308</b> to 0 to indicate that the region of memory being initialized is no longer intact.</p><p id="p-0105" num="0102">Steps <b>1106</b> and <b>1108</b> are performed in response to the intact flag <b>308</b> being 1. In step <b>1106</b>, the pending flag <b>426</b> in the entry for this bulk store operation in the bulk store combine buffer <b>406</b> is set to 0, which indicates that the bulk store operation is no longer pending (otherwise referred to as complete). Step <b>1108</b> includes keeping the LSU valid flag <b>422</b> in the entry in the bulk store combine buffer <b>406</b> at 1. A the LSU valid flag <b>422</b> of 1, along with a pending flag <b>426</b> of 0, may be interpreted as the region in memory that was initialized still being intact after completion of the bulk store operation.</p><p id="p-0106" num="0103">Step <b>1110</b> is performed in response to the intact flag <b>308</b> being 0. In step <b>1110</b>, the entry for this bulk store operation in the bulk store combine buffer <b>406</b> invalidated. In one embodiment, this includes setting the LSU valid flag <b>422</b> in the entry in the bulk store combine buffer <b>406</b> to 0, which indicates that the entry is no longer valid. Other techniques may be used to invalidate the entry.</p><p id="p-0107" num="0104">After either steps <b>1106</b> and <b>1108</b> or, alternatively, step <b>1110</b> is performed, control passes to step <b>1112</b>. Step <b>1112</b> includes the load store unit <b>112</b> sending a completion acknowledgment (ACK) to the bulk store engine <b>118</b>.</p><p id="p-0108" num="0105"><figref idref="DRAWINGS">FIG. <b>12</b></figref> depicts a flowchart of one embodiment of a process <b>1200</b> of a load store unit <b>112</b> handling loads while, or after, a bulk store operation is pending.</p><p id="p-0109" num="0106">Step <b>1202</b> includes the load store unit <b>112</b> accessing a load operation. The load operation may be accessed from a load queue in the load store unit <b>112</b>. The load operation may be associated with a load instruction, such as instruction I4 in Table I.</p><p id="p-0110" num="0107">Step <b>1204</b> includes checking the bulk store combine buffer <b>406</b> for a bulk store operation that covers the physical address in the load command. The following examples will be used to illustration. A first example load instruction is to load the data at 0x6040 in main memory <b>108</b> to register R3. A second example load instruction is to load the data at 0x8040 in main memory <b>108</b> to register R3. A third example load instruction is to load the data at 0x9040 in main memory <b>108</b> to register R3.</p><p id="p-0111" num="0108">With reference to the values depicted in the bulk store combine buffer <b>406</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, there is not a bulk store operation that covers 0x6040 in main memory <b>108</b>. Therefore, for the first load instruction step <b>1206</b> is no. Therefore, control passes to step <b>1208</b> to load the data for that first example instruction. Hence, the data at 0x6040 in main memory <b>108</b> may be loaded into, for example, register R3.</p><p id="p-0112" num="0109">For the second example load instruction, there is a bulk store operation that covers 0x8040 in main memory <b>108</b>. Specifically, the bulk store operation with physical address 0x8000 in main memory <b>108</b> covers 0x8040 in main memory <b>108</b> (due to the 1000 HEX length of the bulk store operation). For the third example load instruction, there is a bulk store operation that covers 0x9040 in main memory <b>108</b>. Specifically, the bulk store operation with physical address 0x9000 in main memory <b>108</b> covers 0x9040 in main memory <b>108</b> (due to the 1000 HEX length of the bulk store operation). Hence, for example instructions two and three, control would pass to step <b>1210</b>.</p><p id="p-0113" num="0110">Step <b>1210</b> includes a determination of whether the pending flag <b>426</b> for the bulk store operation is set. If so, control passes to step <b>1212</b>. In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the pending flag <b>426</b> is set for bulk store operation with physical address 0x9000 in main memory <b>108</b>. Hence, the load from 0x9040 in main memory <b>108</b> is blocked, in step <b>1212</b>. In other words, the load store unit <b>112</b> does not allow the third example load instruction to load the data at 0x9040 in main memory <b>108</b> into register R3. The blocking is enforced until the bulk store operation with physical address 0x9000 in main memory <b>108</b> is completed.</p><p id="p-0114" num="0111">In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the pending flag <b>426</b> is not set for bulk store operation with physical address 0x8000 in main memory <b>108</b>. The pending flag <b>426</b> not being set indicates that the bulk store operation is complete. Hence, the load from 0x8040 in main memory <b>108</b> is not blocked. Thus, for the second example load instruction, control passes to step <b>1214</b>. Step <b>1214</b> includes a determination of whether the LSU valid flag <b>422</b> is sent for the relevant entry in the bulk store combine buffer <b>406</b>. If the LSU valid flag <b>422</b> is not set (step <b>1214</b> is no), then the data is loaded from the relevant address in main memory <b>108</b>, in step <b>1216</b>. If the LSU valid flag <b>422</b> is set (step <b>1214</b> is yes), then the data need not be loaded from the relevant address in main memory <b>108</b>. Instead, since the initialization values are known, the known initialization values can be provided in step <b>1218</b>. For example, if it is known that the memory is initialized to all zeroes, then all zeroes are provided to respond to the load operation, without the need to access main memory <b>108</b>. Hence, time can be saved by avoiding a memory access. Also, it is not necessary to store the initialization values in, for example, 64 cache lines. In one embodiment, one entry in the bulk store combine buffer <b>406</b> contains information to respond to load requests in step <b>1218</b>. In step <b>1218</b>, the information in the entry in the bulk store combine buffer <b>406</b> may be used to respond to load instructions that request data for any portion of a large (e.g., page sized) region in memory that was initialized by a completed bulk store operation. Hence, cache space may be saved by not storing initialization values in, for example, 64 cache lines.</p><p id="p-0115" num="0112">In one embodiment, the load store unit means for tracking status of page store operations comprises bulk store manager. In one embodiment, the load store unit means for tracking status of page store operations is configured to perform process <b>700</b>. In one embodiment, the load store unit means for tracking status of page store operations is configured to perform process <b>1100</b>.</p><p id="p-0116" num="0113">In one embodiment, means for sending multiple write transactions to the main memory for each page store operation to initialize a page of the main memory comprises one or more of bulk store engine and cache pipeline. In one embodiment, the means for sending multiple write transactions to the main memory for each page store operation to initialize a page of the main memory is configured to perform process <b>900</b>.</p><p id="p-0117" num="0114">In one embodiment, means for tracking status of the page store operations and reporting the status to the load store unit comprises one or more of bulk store engine and cache pipeline. In one embodiment, the means for tracking status of the page store operations and reporting the status to the load store unit is configured to perform process <b>1000</b>.</p><p id="p-0118" num="0115">In one embodiment, means for maintaining cache coherence in the hierarchy of caches when initializing the page of the main memory for each page store operation comprises one or more of bulk store engine and cache pipeline. In one embodiment, the means for maintaining cache coherence in the hierarchy of caches when initializing the page of the main memory for each page store operation is configured to perform process <b>1000</b>.</p><p id="p-0119" num="0116">In one embodiment, the means for tracking page store operations that are pending, wherein each page store operation is associated with a region of the memory to be initialized comprises bulk store manager. In one embodiment, the means for tracking page store operations that are pending, wherein each page store operation is associated with a region of the memory to be initialized is configured to perform process <b>700</b>. In one embodiment, the means for tracking page store operations that are pending, wherein each page store operation is associated with a region of the memory to be initialized is configured to perform process <b>1100</b>.</p><p id="p-0120" num="0117">In one embodiment, the means for blocking younger loads associated with any region of the memory associated with any pending page store operation comprises bulk store manager. In one embodiment, the means for blocking younger loads associated with any region of the memory associated with any pending page store operation is configured to perform process <b>1200</b>.</p><p id="p-0121" num="0118">The technology described herein can be implemented using hardware, software, or a combination of both hardware and software. The software used is stored on one or more of the processor readable storage devices described above to program one or more of the processors to perform the functions described herein. The processor readable storage devices can include computer readable media such as volatile and non-volatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer readable storage media and communication media. Computer readable storage media may be implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Examples of computer readable storage media include RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by a computer. A computer readable medium or media does (do) not include propagated, modulated or transitory signals.</p><p id="p-0122" num="0119">Communication media typically embodies computer readable instructions, data structures, program modules or other data in a propagated, modulated or transitory data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term &#x201c;modulated data signal&#x201d; means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as RF and other wireless media. Combinations of any of the above are also included within the scope of computer readable media.</p><p id="p-0123" num="0120">In alternative embodiments, some or all of the software can be replaced by dedicated hardware logic components. For example, and without limitation, illustrative types of hardware logic components that can be used include Field-programmable Gate Arrays (FPGAs), Application-specific Integrated Circuits (ASICs), Application-specific Standard Products (ASSPs), System-on-a-chip systems (SOCs), Complex Programmable Logic Devices (CPLDs), special purpose computers, etc. In one embodiment, software (stored on a storage device) implementing one or more embodiments is used to program one or more processors. The one or more processors can be in communication with one or more computer readable media/storage devices, peripherals and/or communication interfaces.</p><p id="p-0124" num="0121">It is understood that the present subject matter may be embodied in many different forms and should not be construed as being limited to the embodiments set forth herein. Rather, these embodiments are provided so that this subject matter will be thorough and complete and will fully convey the disclosure to those skilled in the art. Indeed, the subject matter is intended to cover alternatives, modifications and equivalents of these embodiments, which are included within the scope and spirit of the subject matter as defined by the appended claims. Furthermore, in the following detailed description of the present subject matter, numerous specific details are set forth in order to provide a thorough understanding of the present subject matter. However, it will be clear to those of ordinary skill in the art that the present subject matter may be practiced without such specific details.</p><p id="p-0125" num="0122">Aspects of the present disclosure are described herein with reference to flowchart illustrations and/or block diagrams of methods, apparatuses (systems) and computer program products according to embodiments of the disclosure. It will be understood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable instruction execution apparatus, create a mechanism for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks.</p><p id="p-0126" num="0123">The description of the present disclosure has been presented for purposes of illustration and description, but is not intended to be exhaustive or limited to the disclosure in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the disclosure. The aspects of the disclosure herein were chosen and described in order to best explain the principles of the disclosure and the practical application, and to enable others of ordinary skill in the art to understand the disclosure with various modifications as are suited to the particular use contemplated.</p><p id="p-0127" num="0124">For purposes of this document, each process associated with the disclosed technology may be performed continuously and by one or more computing devices. Each step in a process may be performed by the same or different computing devices as those used in other steps, and each step need not necessarily be performed by a single computing device.</p><p id="p-0128" num="0125">Although the subject matter has been described in language specific to structural features and/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather, the specific features and acts described above are disclosed as example forms of implementing the claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer system for initializing memory, the computer system comprising:<claim-text>a processor core comprising a central processing unit (CPU), a load store unit, and an internal cache; and</claim-text><claim-text>a last level cache in communication with the processor core, the last level cache configured to:<claim-text>receive bulk store operations from the load store unit, each bulk store operation including a physical address in the memory to be initialized;</claim-text><claim-text>send multiple write transactions to the memory for each bulk store operation to perform a bulk initialization of the memory for each bulk store operation; and</claim-text><claim-text>track status of the bulk store operations.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the last level cache is further configured to:<claim-text>maintain cache coherence in a hierarchy of caches in the computer system when performing the bulk initialization of the memory for each bulk store operation.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the load store unit comprises a bulk store combine buffer; and</claim-text><claim-text>the load store unit is configured to store status of the bulk store operations in the bulk store combine buffer.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the load store unit is further configured to:<claim-text>send the bulk store operations directly to the last level cache while bypassing the internal cache.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the load store unit is further configured to:<claim-text>track bulk store operations that are pending, wherein each bulk store operation is associated with a region of the memory to be initialized; and</claim-text><claim-text>block younger loads associated with any region of the memory associated with any pending bulk store operation.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the load store unit is configured to either set pending status for a bulk store operation to complete or remove the bulk store operation from the bulk store combine buffer in response to the last level cache indicating that the bulk store operation is complete.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the last level cache is further configured to store information on intact status associated with each bulk store operation, the intact status indicates whether a region of the memory initialized by a bulk store operation is intact with initialization values; and</claim-text><claim-text>the last level cache is further configured to set the intact status to not intact responsive to another processor core writing to a region of the memory associated with a bulk store operation.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The computer system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the load store unit is further configured to:<claim-text>invalidate an entry for a first bulk store operation in the bulk store combine buffer responsive to the intact status indicating that the status is not intact; and</claim-text><claim-text>maintain a corresponding entry for a second bulk store operation as a valid entry in the bulk store combine buffer responsive to the intact information indicating that the status is intact.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the load store unit is further configured to:<claim-text>respond to a younger load instruction that loads from a region of the memory initialized by a bulk store operation that is complete by providing known initialization values if the region is still intact.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein each bulk store operation initializes a region of the memory to all zeroes.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein each write transaction initializes a region of the memory that has a size of a cache line.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein each bulk store operation initializes a region of the memory that has a size of a page.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The computer system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising logic configured to:<claim-text>create a single bulk store operation from a plurality of store instructions that each are configured to initialize a cache line sized region in the memory.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A method of initializing memory in a computer system, the method comprising:<claim-text>receiving, at a last level cache in a hierarchy of caches in the computer system, a bulk store operation from a load store unit in a processor core in the computer system;</claim-text><claim-text>performing a bulk initialization of the memory for each bulk store operation, including sending multiple write transactions from the last level cache to the memory for each bulk store operation; and</claim-text><claim-text>tracking status of the bulk store operations.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:<claim-text>maintaining cache coherence in the hierarchy of caches when performing the bulk initialization of the memory for each bulk store operation.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein sending multiple write transactions from the last level cache to the memory for each bulk store operation comprises:<claim-text>sending multiple write transaction to a cache pipeline in the last level cache.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:<claim-text>tracking bulk store operations that are pending, wherein each bulk store operation is associated with a region of the memory to be initialized; and</claim-text><claim-text>blocking younger loads associated with any region of the memory associated with any pending bulk store operation.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. A computer system for initializing memory, the computer system comprising:<claim-text>main memory;</claim-text><claim-text>a central processing unit;</claim-text><claim-text>a load store unit, the load store unit comprising load store unit means for tracking status of page store operations, each page store operation including a physical address in the main memory; and</claim-text><claim-text>a hierarchy of caches comprising a last level cache;</claim-text><claim-text>the last level cache comprising means for sending multiple write transactions to the main memory for each page store operation to initialize a page of the main memory; and</claim-text><claim-text>the last level cache comprising last level cache means for tracking status of the page store operations and reporting the status to the load store unit.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The computer system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein each page store operation initializes a page of the main memory to all zeroes.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The computer system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein:<claim-text>the last level cache further comprises means for maintaining cache coherence in the hierarchy of caches when initializing the page of the main memory for each page store operation.</claim-text></claim-text></claim></claims></us-patent-application>
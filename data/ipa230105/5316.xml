<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005317A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005317</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17853234</doc-number><date>20220629</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>07</class><subclass>C</subclass><main-group>9</main-group><subgroup>32</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>R</subclass><main-group>1</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>07</class><subclass>C</subclass><main-group>9</main-group><subgroup>32</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>00536</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>R</subclass><main-group>1</main-group><subgroup>1041</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEM AND METHOD FOR AUTHENTICATING A PERSON BASED ON MOTION DATA FOR ONE OR MORE EARPIECES WORN BY THE PERSON</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63216604</doc-number><date>20210630</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Kyocera AVX Components Corporation</orgname><address><city>Fountain Inn</city><state>SC</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Desclos</last-name><first-name>Laurent</first-name><address><city>San Diego</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A person authentication system is provided. The person authentication system includes one or more earpieces. The one or more earpieces can include one or more motion sensors. The person authentication system includes a computing system communicatively coupled to the one or more earpieces. The computing system is configured to obtain motion data indicative of motion of the one or more earpieces when the one or more earpieces are being worn by the person. The computing system is configured to determine a motion signature for the person based, at least in part, on the motion data. The motion signature can be unique to the person. The computing system can be even further configured to authenticate an identity of the person based, at least in part, on the motion signature.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="113.54mm" wi="158.75mm" file="US20230005317A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="184.23mm" wi="154.52mm" orientation="landscape" file="US20230005317A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="203.62mm" wi="84.75mm" file="US20230005317A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="213.44mm" wi="82.47mm" file="US20230005317A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="193.21mm" wi="89.15mm" file="US20230005317A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="193.21mm" wi="88.98mm" file="US20230005317A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="193.21mm" wi="89.07mm" file="US20230005317A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="224.79mm" wi="120.57mm" file="US20230005317A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="199.14mm" wi="59.61mm" file="US20230005317A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="210.57mm" wi="115.99mm" file="US20230005317A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="225.81mm" wi="101.60mm" file="US20230005317A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">PRIORITY CLAIM</heading><p id="p-0002" num="0001">This application claims the benefit of priority of U.S. Provisional Patent Application Ser. No. 63/216,604, filed on Jun. 30, 2021, titled &#x201c;System and Method for Authenticating a Person Based on Motion Data for One or more Earpieces Worn by the Person,&#x201d; which is incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">The present disclosure relates generally to earpieces and, more particularly, to a system and method for authenticating a person wearing one or more earpieces based, at least in part, on motion data indicative of motion of the one or more earpieces.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Earpieces are wearable devices that can be inserted into an ear of a person. Earpieces can include one or more electronic components (e.g., transducers) associated with converting an electrical signal into an audio signal. For example, the audio signal can be associated with an incoming call to a mobile computing device (e.g., smartphone, tablet) associated with the person. In this manner, the person can listen to the audio signal in private.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0005" num="0004">Aspects and advantages of embodiments of the present disclosure will be set forth in part in the following description, or may be learned from the description, or may be learned through practice of the embodiments.</p><p id="p-0006" num="0005">In one aspect, a method of authenticating an identity of a person wearing one or more earpieces is provided. The method includes obtaining motion data indicative of motion of one or more earpieces worn by the person. The method includes determining a motion signature of the person based, at least in part, on the motion data. The motion signature can be unique to the person. The method includes authenticating the identity of the person based, at least in part, on the motion signature.</p><p id="p-0007" num="0006">In another aspect, a person authentication system is provided. The person authentication system includes one or more earpieces. The one or more earpieces can include one or more motion sensors. The person authentication system includes a computing system communicatively coupled to the one or more earpieces. The computing system is configured to obtain motion data indicative of motion of the one or more earpieces when the one or more earpieces are being worn by the person. The computing system is configured to determine a motion signature for the person based, at least in part, on the motion data. The motion signature can be unique to the person. The computing system can be even further configured to authenticate an identity of the person based, at least in part, on the motion signature.</p><p id="p-0008" num="0007">These and other features, aspects and advantages of various embodiments will become better understood with reference to the following description and appended claims. The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate embodiments of the present disclosure and, together with the description, serve to explain the related principles.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0009" num="0008">Detailed discussion of embodiments directed to one of ordinary skill in the art are set forth in the specification, which makes reference to the appended figures, in which:</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a block diagram of a person authentication system.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts a block diagram of components of an earpiece according to example embodiments of the present disclosure.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts a flow diagram of a method for authenticating identity of a person wearing one or more earpieces according to example embodiments of the present disclosure.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts a flow diagram of a method of determining a motion signature for a person according to example embodiments of the present disclosure.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts a flow diagram of a method of authenticating an identity of a person wearing one or more earpieces according to example embodiments of the present disclosure.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts a flow diagram of a method of authenticating an identity of a person wearing one or more earpieces according to example embodiments of the present disclosure.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> depicts motion data indicative of motion of an earpiece according to example embodiments of the present disclosure.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> depicts motion data indicative of motion of an earpiece according to example embodiments of the present disclosure.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>7</b>C</figref> depicts motion data indicative of motion of an earpiece according to example embodiments of the present disclosure.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>8</b></figref> depicts a block diagram of components of a computing system according to example embodiments of the present disclosure.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>9</b></figref> depicts a modal antenna according to example embodiments of the present disclosure.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>10</b></figref> depicts a two-dimensional radiation pattern associated with a modal antenna according to example embodiments of the present disclosure.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>11</b></figref> depicts a frequency plot of a modal antenna according to example embodiments of the present disclosure.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>12</b></figref> depicts a method a flow diagram of a method for authenticating identity of a person wearing one or more earpieces according to example embodiments of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0024" num="0023">Reference now will be made in detail to embodiments, one or more examples of which are illustrated in the drawings. Each example is provided by way of explanation of the embodiments, not limitation of the present disclosure. In fact, it will be apparent to those skilled in the art that various modifications and variations can be made to the embodiments without departing from the scope or spirit of the present disclosure. For instance, features illustrated or described as part of one embodiment can be used with another embodiment to yield a still further embodiment. Thus, it is intended that aspects of the present disclosure cover such modifications and variations.</p><p id="p-0025" num="0024">Example aspects of the present disclosure are directed to authentication systems. A person authentication system can include or more earpieces. For instance, in some implementations, the one or more earpieces can include a first earpiece configured to be worn in a right ear of a person and/or a second earpiece configured to be worn in a left ear of the person. In some implementations, the one or more earpieces can include over-the-ear earpieces. In alternative implementations, the one or more earpieces can include in-ear earpieces.</p><p id="p-0026" num="0025">The one or more earpieces can include one or more motion sensors. The one or more motion sensors can be configured to obtain motion data indicative of motion of the one or more earpieces. For instance, in some implementations, the one or more motion sensors can include one or more accelerometers configured to obtain data indicative of acceleration of the one or more earpieces along one or more axes. Alternatively, or additionally, the one or more motion sensors can include one or more gyroscopes configured to obtain data indicative of angular velocity of the one or more earpieces. It should be understood that the one or more motion sensors can include any suitable sensor configured to obtain data indicative of motion (e.g., acceleration, velocity, etc.) of the one or more earpieces.</p><p id="p-0027" num="0026">The person authentication system can include a computing system. The computing system can be communicatively coupled to the one or more earpieces worn by the person. In some implementations, the computing system can be communicatively coupled to the one or more earpieces via one or more wireless networks. In this manner, the computing system can obtain motion data indicative of motion of the one or more earpieces being worn by the person. For instance, in some implementations, the computing system can obtain first motion data indicative of motion of a first earpiece worn in a first ear of the person. Additionally, the computing system can obtain second motion data indicative of motion of a second earpiece worn in a second ear of the person.</p><p id="p-0028" num="0027">The computing system can be configured to determine a motion signature for the person based, at least in part, on the motion data indicative of motion of the one or more earpieces worn by the person. The motion signature can be indicative of a motion that is unique to the person. For instance, in some implementations, the motion signature can be indicative of a gait of the person. It should be understood that the motion signature can include any type of motion that is unique to the person. In some implementations, the computing system can include one or more machine-learned motion classifier models. In such implementations, the computing system can be configured to provide the motion data indicative of the motion of the one or more earpieces as an input to the one or more machine-learned motion classifier models. The one or more learned motion classifier models can be configured to classify the motion data to determine the motion signature for the person. Furthermore, in such implementations, the motion signature for the person can be provided as an output of the one or more machine-learned motion classifier models. The computing system can be configured to authenticate an identity of the person wearing the one or more earpieces based, at least in part, on the motion signature. For instance, in some implementations, the computing system can be configured to provide the motion signature as an input to one or more machine-learned motion classifier models. The one or more machine-learned motion classifier models can be configured to classify the motion signature to determine an identity of the person wearing the one or more earpieces. Furthermore, in such implementations, the identity of the person can be provided as an output of the one or more machine-learned motion classifier models.</p><p id="p-0029" num="0028">The person authentication system according to example aspects of the present disclosure can provide numerous technical benefits and advantages. For instance, the computing system can determine a motion signature for a person wearing one or more earpieces based, at least in part, on motion data indicative of motion of the one or more earpieces. Furthermore, since the motion signature is unique to the person wearing the one or more earpieces, the computing system can authenticate the identity of the person wearing the one or more earpieces based, at least in part, on the motion signature. In this manner, person authentications systems according to example aspects of the present disclosure can more accurately authenticate the identity of persons wearing the one or more earpieces since authentication is based, at least in part, on motion (e.g., gait) that is unique to the person waring the one or more earpieces.</p><p id="p-0030" num="0029">Referring now to the FIGS, <figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a person authentication system <b>100</b> is provided. The person authentication system <b>100</b> can include one or more earpieces <b>110</b> configured to be worn by a person <b>102</b>. For instance, in some implementations, the one or more earpieces can include a first earpiece and a second earpiece. The first earpiece can be configured to be worn in a first ear <b>104</b> (e.g., right ear) of the person <b>102</b>. The second earpiece can be configured to be worn in a second ear <b>106</b> (e.g., left ear) of the person <b>102</b>. In alternative implementations, the person authentication system <b>100</b> can include fewer earpieces (e.g., only one earpiece). It should be understood that the one or more earpieces <b>110</b> can include any suitable earpiece. For instance, in some implementations, the one or more earpieces <b>110</b> can include an over-the-ear earpiece. In alternative implementations, the one or more earpieces <b>110</b> can include an in-ear earpiece.</p><p id="p-0031" num="0030">The person authentication system <b>100</b> can include a computing system <b>120</b>. The computing system <b>120</b> can be communicatively coupled to the one or more earpieces <b>110</b>. For instance, in some implementations, the computing system <b>120</b> can be communicatively coupled to the one or more earpieces <b>110</b> via one or more wireless networks <b>130</b>. In some implementations, the one or more wireless networks <b>130</b> can include a cellular network. Alternatively, or additionally, the one or more wireless networks <b>130</b> can include a wireless local area network (WLAN), such as a 802.11 network (e.g., WiFi network). It should also be understood that the one or more wireless networks <b>130</b> can have any suitable topology. For instance, in some implementations, the one or more wireless networks <b>130</b> can be a mesh network. In such implementations, the one or more earpieces <b>110</b> (e.g., first earpiece and second earpiece) can communicate with one another via the mesh network. Alternatively, or additionally, the one or more earpieces <b>110</b> worn by the person <b>102</b> can communicate with one or more earpieces <b>110</b> worn by a different person via the mesh network.</p><p id="p-0032" num="0031">The computing system <b>120</b> can be configured to obtain motion data indicative of motion of the one or more earpieces <b>110</b> being worn by the person <b>102</b>. In some implementations, the motion data can include one or more signals transmitted from the one or more earpieces <b>110</b>. For instance, in some implementations, the first earpiece worn in the first ear <b>104</b> of the person <b>102</b> can transmit one or more signals indicative of motion of the first earpiece. Additionally, the second earpiece worn in the second ear <b>106</b> of the person <b>102</b> can transmit one or more signals indicative of motion of the second earpiece.</p><p id="p-0033" num="0032">In some implementations, the one or more earpieces <b>110</b> can be communicatively coupled to one or more motion sensor systems (e.g., wristband, smartwatch, etc.) worn by the person <b>102</b>. For instance, the one or more earpieces <b>110</b> can be communicatively coupled to the one or more motion sensor systems via the one or more wireless networks <b>130</b>. In this manner, the one or more earpieces <b>110</b> can obtain motion data from the one or more motion sensor systems. In some implementations, the one or more earpieces <b>110</b> can communicate the motion data obtained from the one or more motion sensor systems to the computing system <b>120</b>. In alternative implementations, the one or more motion sensor systems can be communicatively coupled to the computing system <b>120</b> via the one or more wireless networks <b>130</b>. In such implementations, the one or more motion sensor systems can communicate motion data to the computing system <b>120</b> via the one or more wireless networks <b>130</b>.</p><p id="p-0034" num="0033">The computing system <b>120</b> can be configured to determine a motion signature for the person <b>102</b> based, at least in part, on the motion data indicative of motion of the one or more earpieces <b>110</b>. Furthermore, in some implementations, the computing system <b>120</b> can be configured to determine the motion signature for the person <b>102</b> based on the motion data indicative of motion of the one or more earpieces <b>110</b> and motion data captured by one or more motion sensor systems (e.g., wrist watch) worn by the person <b>102</b>. The motion signature can be indicative of a motion that is unique to the person <b>102</b>. For instance, in some implementations, the motion signature can be indicative of a gait of the person <b>102</b>. It should be understood that the motion signature can include any type of motion that is unique to the person <b>102</b>.</p><p id="p-0035" num="0034">In some implementations, the computing system <b>120</b> can include one or more machine-learned motion classifier models. In such implementations, the computing system <b>120</b> can be configured to provide the motion data indicative of the motion of the one or more earpieces as an input to the one or more machine-learned motion classifier models. The one or more learned motion classifier models can be configured to classify the motion data to determine the motion signature for the person <b>102</b>. Furthermore, in such implementations, the motion signature for the person <b>102</b> can be provided as an output of the one or more machine-learned motion classifier models.</p><p id="p-0036" num="0035">The computing system <b>120</b> can be configured to authenticate an identity of the person <b>102</b> wearing the one or more earpieces <b>110</b> based, at least in part, on the motion signature. For instance, in some implementations, the computing system <b>120</b> can be configured to provide the motion signature as an input to one or more machine-learned motion classifier models. The one or more machine-learned motion classifier models can be configured to classify the motion signature to determine an identity of the person <b>102</b> wearing the one or more earpieces <b>110</b>. Furthermore, in such implementations, the identity of the person <b>102</b> can be provided as an output of the one or more machine-learned motion classifier models.</p><p id="p-0037" num="0036">In alternative implementations, the computing system <b>120</b> can be configured to compare the motion signature for the person <b>102</b> to a plurality of motion signatures. It should be appreciated that each of the plurality of motion signatures can be associated with a different person. In this manner, the computing system <b>120</b> can determine whether the motion signature for the person <b>102</b> corresponds to the motion signature for one of the plurality of motion signatures. For example, the computing system <b>120</b> can determine the motion signature for the person <b>102</b> corresponds to a first motion signature of the plurality of motion signatures. Furthermore, since each of the plurality of motion signatures is associated with a different person, the computing system <b>120</b> can determine the identity of the person <b>102</b> wearing the one or more earpieces <b>110</b> corresponds to the identity of the person associated with the first motion signature of the plurality of motion signatures.</p><p id="p-0038" num="0037">In some implementations, the computing system <b>120</b> can be configured to provide a notification indicative of whether the identity of the person <b>102</b> wearing the earpiece <b>110</b> has been authenticated. For instance, the notification can be displayed via one or more output devices <b>140</b> (e.g., display screen, speaker, etc.) of the person authentication system <b>100</b>. It should be appreciated that the notification can include at least one of an audible or visual alert. In some implementations, the one or more output devices <b>140</b> can be positioned at the entrance to the restricted area. In this manner, personnel posted at the entrance to the restricted area can determine whether to permit the person <b>102</b> wearing the earpiece <b>110</b> to enter the restricted area based, at least in part, on the notification.</p><p id="p-0039" num="0038">In some implementations, the computing system <b>120</b> can be communicatively coupled with one or more wearable devices <b>150</b> other than the one or more earpieces <b>110</b>. The one or more wearable devices <b>150</b> can include one or more biometric sensors configured to obtain biometrics of the person <b>102</b>. For instance, in some implementations, the one or more wearable devices <b>150</b> can include a heart rate monitor. It should be understood, however, that the one or more wearable devices <b>150</b> can include any device capable of being worn by the person <b>102</b> and having one or more biometric sensors.</p><p id="p-0040" num="0039">Referring now to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, components of the one or more earpieces <b>110</b> are provided according to example embodiments of the present disclosure. As shown, the one or more earpieces <b>110</b> can include a communication circuit <b>210</b> and an antenna <b>212</b>. In this manner the one or more earpieces <b>110</b> can transmit and receive data. In some implementations, the communication circuit <b>210</b> can include a near-field communication circuit. The antenna <b>212</b> can, in some implementations, include an antenna having a fixed radiation pattern.</p><p id="p-0041" num="0040">In alternative implementations, the antenna <b>212</b> can include a modal antenna configurable in a plurality of antenna modes. Furthermore, each of the plurality of antenna modes can have a distinct radiation pattern, polarization, or both. In some implementations, the modal antenna can be configured in different antenna modes based, at least in part, on a link quality (e.g., channel quality indicator) between the modal antenna and a receiver (e.g., another earpiece, access point, base station).</p><p id="p-0042" num="0041">For instance, the modal antenna can be configured in different antenna modes as the person <b>102</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>) navigates an area to steer the radiation pattern towards the receiver (e.g., other earpieces, access points, base stations) in the area. In this manner, a link quality (e.g., channel quality indicator) between the modal antenna and the receiver (e.g., other earpieces, access points, base stations, etc.) can be improved.</p><p id="p-0043" num="0042">The one or more earpieces <b>110</b> can further include one or more transducers <b>220</b>. The one or more transducers <b>220</b> can be configured to convert an electrical signal to an audio signal. For instance, the electrical signal can be received via the antenna <b>212</b> and can be provided as an input to the one or more transducers <b>220</b>. The one or more transducers <b>220</b> can convert the electrical signal to output the audio signal. In this manner, audible noise associated with the audio signal can be provided to a corresponding ear <b>104</b>, <b>106</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>) of the person <b>102</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>).</p><p id="p-0044" num="0043">The one or more earpieces <b>110</b> can include one or more processors <b>230</b> configured to perform a variety of computer-implemented functions (e.g., performing the methods, steps, calculations and the like disclosed herein). As used herein, the term &#x201c;processor&#x201d; refers not only to integrated circuits referred to in the art as being included in a computer, but also refers to a controller, microcontroller, a microcomputer, a programmable logic controller (PLC), an application specific integrated circuit (ASIC), a Field Programmable Gate Array (FPGA), and other programmable circuits.</p><p id="p-0045" num="0044">The one or more earpieces <b>110</b> can include a memory device <b>232</b>. Examples of the memory device <b>232</b> can include computer-readable media including, but not limited to, non-transitory computer-readable media, such as RAM, ROM, hard drives, flash drives, or other suitable memory devices. The memory device <b>232</b> can store information accessible by the one or more processors <b>230</b> including the unique identifier <b>234</b> associated with the one or more earpieces <b>110</b>. The one or more processors <b>230</b> can access the memory device <b>232</b> to obtain the unique identifier <b>234</b>. For instance, in some implementations, the one or more processors <b>230</b> can be configured to generate a beacon signal that includes the unique identifier <b>234</b>. Furthermore, the one or more processors <b>230</b> can be further configured to transmit the beacon signal via the antenna <b>212</b>.</p><p id="p-0046" num="0045">In some implementations, the one or more earpiece <b>110</b> can include one or more motion sensors <b>240</b> configured to obtain motion data indicative of motion of the one or more earpieces <b>110</b>. For instance, in some implementations, the one or more motion sensors <b>240</b> can include an accelerometer. The accelerometer can be configured to obtain data indicative of acceleration of the earpiece <b>110</b> along one or more axes. Alternatively, or additionally, the one or more motion sensors <b>240</b> can include a gyroscope. The gyroscope can be configured to obtain data indicative of orientation of the earpiece <b>110</b>. Additionally, the gyroscope can be configured to obtain data indicative of angular velocity of the one or more earpieces <b>110</b>. Referring now to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a flow diagram of a method <b>300</b> of authenticating an identity of a person is provided according to example embodiments of the present disclosure. In general, the method <b>400</b> will be discussed herein with reference to the person authentication system <b>100</b> described above with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In addition, although <figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts steps performed in a particular order for purposes of illustration and discussion, the method discussed herein is not limited to any particular order or arrangement. One skilled in the art, using the disclosure provided herein, will appreciate that various steps of the method disclosed herein can be omitted, rearranged, combined, and/or adapted in various ways without deviating from the scope of the present disclosure.</p><p id="p-0047" num="0046">At (<b>302</b>), the method <b>300</b> can include obtaining, by a computing system having one or more computing devices, motion data indicative of motion of one or more earpieces worn by a person. In some implementations, obtaining motion data indicative of motion of the one or more earpieces worn by the person can include obtaining, by the computing system, first motion data indicative of motion of a first earpiece worn in a first ear (e.g., right ear) of the person. Additionally, obtaining motion data indicative of motion of the one or more earpieces worn by the person can further include obtaining, by the computing system, second motion data indicative of motion of a second earpiece worn in a second ear (e.g., left ear) of the person.</p><p id="p-0048" num="0047">At (<b>304</b>), the method <b>300</b> can include determining, by the computing system, a motion signature for the person based, at least in part, on the motion data obtained at (<b>302</b>). The motion signature can be unique to the person wearing the one or more earpieces. For instance, in some implementations, the motion signature can be indicative of a gait of the person. It should be appreciated, however, that the motion signature can be indicative of any suitable motion that is unique to the person <b>102</b>.</p><p id="p-0049" num="0048">At (<b>306</b>), the method <b>300</b> can include authenticating, by the computing system, the identity of the person wearing the one or more earpieces based, at least in part, on the motion signature determined at (<b>304</b>). For instance, in some implementations, authenticating the identity of person wearing the one or more earpieces can include determining a name of the person wearing the one or more earpieces based, at least in part, on the motion signature.</p><p id="p-0050" num="0049">At (<b>308</b>), the method <b>300</b> can include determining, by the computing system, whether the person wearing the one or more earpiece is permitted to access a restricted area the person is attempting to enter. For instance, determining whether the person wearing the earpiece is permitted to access the restricted area can include, for instance, accessing, by the computing system, a database storing data that is indicative of persons permitted to access the restricted area. In some implementations, the data stored in the database can include a list of persons that are permitted to access the restricted area. It should be understood, however, that the data can be stored in the database in any suitable format.</p><p id="p-0051" num="0050">At (<b>310</b>), the method <b>300</b> can include providing, by the computing system, a notification indicative of whether the person wearing the earpiece is permitted to access the restricted area. For instance, in some implementations, providing the notification can include providing, by the computing system, the notification for display on the one or more output devices located at an entrance to the restricted area. It should be understood that the notification can include at least one of an audible alert or a visual alert.</p><p id="p-0052" num="0051">Referring now to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a flow diagram of a process for determining a motion signature for the person at (<b>304</b>) of the method <b>300</b> discussed above with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref> is provided according to an example embodiment of the present disclosure. As shown, determining the motion signature for the person can include, at (<b>402</b>), providing the motion data as an input to one or more machine-learned motion classifier models. The process of determining the motion signature of the person can further include, at (<b>404</b>), classifying the motion data to determine the motion signature for the person. Still further, the process of determining the motion signature for the person can include, at (<b>406</b>), providing the motion signature as an output of the one or more machine-learned motion-classifier models.</p><p id="p-0053" num="0052">Referring now to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, a flow diagram of a process for authenticating the identity of the person at (<b>306</b>) of the method <b>300</b> discussed above with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref> is provided according to an example embodiment of the present disclosure. As shown, authenticating the identity of the person wearing the one or more earpieces can include, at (<b>502</b>), comparing the motion signature for the person to a plurality of different motion signatures. It should be understood that each of the plurality of motion signatures can be associated with a different person. At (<b>504</b>), the process for authenticating the identity of the person can include determining a first motion signature of the plurality of motion signatures corresponds to the motion signature for the person. At (<b>506</b>), the process for authenticating the identity of the person wearing the one or more earpieces can include authenticating the identity of the person wearing the one or more earpieces based, at least in part, on the first motion signature of the plurality of motion signatures.</p><p id="p-0054" num="0053">Referring now to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a flow diagram of a process for authenticating the identity of the person at (<b>306</b>) of the method <b>300</b> discussed above with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref> is provided according to an example embodiment of the present disclosure. As shown, authenticating the identity of the person waring the one or more earpieces can include, at (<b>602</b>), providing the motion signature for the person as an input to one or more machine-learned motion classifier models. The process of authenticating the identity of the person wearing the one or more earpieces can further include, at (<b>604</b>), classifying the motion data to determine the motion signature for the person. Still further, the process of authenticating the identity of the person wearing the one or more earpieces can include, at (<b>606</b>), providing the motion signature as an output of the one or more machine-learned motion classifier models.</p><p id="p-0055" num="0054">Referring now to <figref idref="DRAWINGS">FIGS. <b>7</b>A-<b>7</b>C</figref>, various examples of motion data indicative of motion of an earpiece are provided according to example embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> depicts motion data indicative of velocity of the earpiece as a function of time. For instance, curve <b>702</b> depicts velocity of the earpiece along a first axis (e.g., roll axis). Curve <b>704</b> depicts velocity of the earpiece along a second axis (e.g., pitch axis). Curve <b>706</b> depicts velocity of the earpiece along a third axis (e.g., yaw axis).</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> depicts motion data indicative of acceleration of the earpiece as a function of time. For instance, curve <b>712</b> depicts acceleration of the earpiece along the first axis (e.g., roll axis). Curve <b>712</b> depicts acceleration of the earpiece along the second axis (e.g., pitch axis). Curve <b>714</b> depicts acceleration of the earpiece along the third axis (e.g., yaw axis). <figref idref="DRAWINGS">FIG. <b>7</b>C</figref> depicts motion data indicative of orientation of the earpiece relative to Earth's horizontal axis as a function of time. For instance, curve <b>720</b> depicts a roll attitude of the earpiece, where curve <b>722</b> depicts a pitch attitude of the earpiece.</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates suitable components of the computing system <b>120</b> according to example embodiments of the present disclosure. The computing system <b>120</b> can include one or more computing devices <b>800</b>. The one or more computing devices <b>700</b> can include one or more processors <b>802</b> configured to perform a variety of computer-implemented functions (e.g., performing the methods, steps, calculations and the like disclosed herein). As used herein, the term &#x201c;processor&#x201d; refers not only to integrated circuits referred to in the art as being included in a computer, but also refers to a controller, microcontroller, a microcomputer, a programmable logic controller (PLC), an application specific integrated circuit (ASIC), a Field Programmable Gate Array (FPGA), and other programmable circuits.</p><p id="p-0058" num="0057">As shown, the computing system <b>120</b> can include a memory device <b>804</b>. Examples of the memory device <b>804</b> can include computer-readable media including, but not limited to, non-transitory computer-readable media, such as RAM, ROM, hard drives, flash drives, or other suitable memory devices. The memory device <b>804</b> can store information accessible by the one or more processors <b>802</b> including computer-readable instructions <b>806</b> that can be executed by the one or more processors <b>802</b>. The computer-readable instructions <b>806</b> can be any set of instructions that, when executed by the one or more processors <b>802</b>, cause the one or more processors <b>802</b> to perform operations associated with authenticating the identity of the person wearing the earpiece. The computer-readable instructions <b>806</b> can be software written in any suitable programming language or can be implemented in hardware. In some implementations, the computing system <b>120</b> can include one or more motion classifier models <b>808</b>. For example, the one or more motion classifier models <b>808</b> can include various machine-learned models, such as a random forest classifier; a logistic regression classifier; a support vector machine; one or more decision trees; a neural network; and or other types of machine-learned models, including both linear models and non-linear models. Example neural networks can include feed-forward neural networks, recurrent neural networks (e.g., long short-term memory recurrent neural networks), or other forms of neural networks.</p><p id="p-0059" num="0058">In some implementations, the computing system <b>120</b> can train the one or more motion classifier models <b>808</b> through use of a model trainer <b>810</b>. The model trainer <b>810</b> can train the one or more classifier models <b>708</b> using one or more training or learning algorithms. One example training technique is backwards propagation of errors (&#x201c;backpropagation&#x201d;). For example, backpropagation can include Levenberg-Marquardt backpropagation. In some implementations, the model trainer <b>810</b> can perform supervised training techniques using a set of labeled training data. In other implementations, the model trainer <b>810</b> can perform unsupervised training techniques using a set of unlabeled training data. The model trainer <b>710</b> can perform a number of generalization techniques to improve the generalization capability of the models being trained. Generalization techniques include weight decays, dropouts, or other techniques.</p><p id="p-0060" num="0059">In particular, the model trainer <b>810</b> can train the one or more motion classifier models <b>808</b> based on a set of training data <b>812</b>. The training data <b>812</b> can includes a number of training examples. Each training example can include example images of the ear (e.g., inner portion, outer portion) of different persons. In this manner, the one or more classifier models <b>708</b> can learn to classify the different images of the ear.</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an example embodiment of a modal antenna <b>900</b> according to the present disclosure. The modal antenna <b>900</b> can, for instance, be used in the earpiece <b>110</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>). For instance, the antenna <b>212</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) of the earpiece <b>110</b> can include the modal antenna <b>900</b>. The modal antenna can be configurable in a plurality of antenna modes. Each of the antenna modes can have a distinct radiation pattern, polarization, or both. The modal antenna <b>900</b> can be configured in different antenna modes based, at least in part, on a link quality (e.g., channel quality indicator) between the earpiece and another device (e.g., other earpiece, access point, base station) to steer the radiation pattern of the modal antenna <b>900</b> towards the device. In this manner, the antenna mode of the modal antenna <b>900</b> can be adjusted as needed to maintain the communication link between the earpiece and another device as the user navigates an area.</p><p id="p-0062" num="0061">As shown, the driven element <b>904</b> of the modal antenna <b>900</b> can be disposed on an circuit board <b>902</b>. An antenna volume may be defined between the circuit board <b>902</b> (e.g., and the ground plane) and the driven element <b>904</b>. The modal antenna <b>900</b> can include a first parasitic element <b>906</b> positioned at least partially within the antenna volume. The modal antenna <b>900</b> can further include a first tuning element <b>908</b> coupled with the first parasitic element <b>906</b>. The first tuning element <b>908</b> can be a passive or active component or series of components and can be configured to alter a reactance on the first parasitic element <b>906</b> either by way of a variable reactance or shorting to ground. It should be appreciated that altering the reactance of the first parasitic element <b>906</b> can result in a frequency shift of the modal antenna <b>900</b>. It should also be appreciated that the first tuning element <b>908</b> can include at least one of a tunable capacitor, MEMS device, tunable inductor, switch, a tunable phase shifter, a field-effect transistor, or a diode.</p><p id="p-0063" num="0062">In some implementations, the modal antenna <b>900</b> can include a second parasitic element <b>910</b> disposed adjacent the driven element <b>904</b> and outside of the antenna volume. The modal antenna <b>900</b> can further include a second tuning element <b>912</b>. In some implementations, the second tuning element <b>912</b> can be a passive or active component or series of components and may be configured to alter a reactance on the second parasitic element <b>910</b> by way of a variable reactance or shorting to ground. It should be appreciated that altering the reactance of the second parasitic element <b>910</b> can result in a frequency shift of the modal antenna <b>900</b>. It should also be appreciated that the second tuning element <b>912</b> can include at least one of a tunable capacitor, MEMS device, tunable inductor, switch, a tunable phase shifter, a field-effect transistor, or a diode.</p><p id="p-0064" num="0063">In some implementations, operation of at least one of the first tuning element <b>908</b> and the second tuning element <b>912</b> can be controlled to adjust (e.g., shift) the antenna radiation pattern of the driven element <b>904</b>. For example, a reactance of at least one of the first tuning element <b>908</b> and the second tuning element <b>912</b> can be controlled to adjust the antenna radiation pattern of the driven element <b>904</b>.</p><p id="p-0065" num="0064">Adjusting the antenna radiation pattern can be referred to as &#x201c;beam steering&#x201d;. However, in instances where the antenna radiation pattern includes a null, a similar operation, commonly referred to as &#x201c;null steering&#x201d;, can be performed to shift the null to an alternative position about the driven element <b>904</b> (e.g., to reduce interference). <figref idref="DRAWINGS">FIG. <b>10</b></figref> depicts antenna radiation patterns associated with the modal antenna <b>900</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref> according to example embodiments of the present disclosure. It should be appreciated that operation of at least one of the first parasitic element <b>906</b> and the second parasitic element <b>910</b> can be controlled to configure the modal antenna <b>900</b> in a plurality of modes. It should also be appreciated that the modal antenna <b>900</b> can have a distinct antenna radiation pattern or antenna polarization when configured in each of the plurality of modes.</p><p id="p-0066" num="0065">In some implementations, the modal antenna <b>900</b> can have a first antenna radiation pattern <b>1000</b> when the modal antenna <b>900</b> is configured in a first mode of the plurality of modes. In addition, the modal antenna <b>900</b> can have a second antenna radiation pattern <b>1002</b> when the modal antenna <b>900</b> is configured in a second mode of the plurality of modes. Furthermore, the modal antenna <b>900</b> can have a third antenna radiation pattern <b>1004</b> when the modal antenna <b>900</b> is configured in a third mode of the plurality of modes. As shown, the first antenna radiation pattern <b>1000</b>, the second antenna radiation pattern <b>1002</b>, and the third antenna radiation pattern <b>1004</b> can be distinct from one another. In this manner, the modal antenna <b>900</b> can have a distinct radiation pattern when configured in each of the first mode, second mode, and third mode.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>11</b></figref> depicts an example frequency plot of the modal antenna <b>900</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref> according to example embodiments the present disclosure. It should be understood that an electrical characteristic (e.g., reactance) of at least one of the first parasitic element <b>906</b> and the second parasitic element <b>910</b> can be controlled. In this manner, the electrical characteristic of at least one of the first parasitic element <b>906</b> and the second parasitic element <b>910</b> can be adjusted to shift a frequency at which the modal antenna <b>900</b> is operating.</p><p id="p-0068" num="0067">In some implementations, the modal antenna <b>900</b> can be tuned to a first frequency f<sub>0 </sub>when the first parasitic element <b>906</b> and the second parasitic element <b>910</b> are deactivated (e.g., switched off). Alternatively, or additionally, the modal antenna <b>900</b> can be tuned to frequencies f<sub>L </sub>and f<sub>H </sub>when the second parasitic element <b>910</b> is shorted to ground. Furthermore, the modal antenna <b>900</b> can be tuned to frequency f<sub>4 </sub>when both the first parasitic element <b>906</b> and the second parasitic element <b>910</b> are shorted to ground. Still further, the modal antenna <b>900</b> can be tuned to frequencies f<sub>4 </sub>and f<sub>0 </sub>when the first parasitic element <b>906</b> and the second parasitic element <b>910</b> are each shorted to ground. It should be understood that other configurations are within the scope of this disclosure. For example, more or fewer parasitic elements may be employed. The positioning of the parasitic elements may be altered to achieve additional modes that may exhibit different frequencies and/or combinations of frequencies.</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIGS. <b>9</b>-<b>11</b></figref> depict one example modal antenna having a plurality of modes for purposes of illustration and discussion. Those of ordinary skill in the art, using the disclosures provided herein, will understand that other modal antennas and/or antenna configurations can be used without deviating from the scope of the present disclosure. As used herein a &#x201c;modal antenna&#x201d; refers to an antenna capable of operating in a plurality of modes where each mode is associated with a distinct radiation pattern.</p><p id="p-0070" num="0069">Referring now to <figref idref="DRAWINGS">FIG. <b>12</b></figref>, a flow diagram of a method <b>1100</b> of authenticating an identity of a person is provided according to example embodiments of the present disclosure. In general, the method <b>1100</b> will be discussed herein with reference to the person authentication system <b>100</b> described above with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In addition, although <figref idref="DRAWINGS">FIG. <b>12</b></figref> depicts steps performed in a particular order for purposes of illustration and discussion, the method <b>1100</b> described herein is not limited to any particular order or arrangement. One skilled in the art, using the disclosure provided herein, will appreciate that various steps of the method <b>1110</b> disclosed herein can be omitted, rearranged, combined, and/or adapted in various ways without deviating from the scope of the present disclosure.</p><p id="p-0071" num="0070">At (<b>1102</b>), the method <b>1100</b> can include obtaining, by a computing system having one or more computing devices, motion data indicative of motion of one or more earpieces worn by a person. In some implementations, obtaining motion data indicative of motion of the one or more earpieces worn by the person can include obtaining, by the computing system, first motion data indicative of motion of a first earpiece worn in a first ear (e.g., right ear) of the person. Additionally, obtaining motion data indicative of motion of the one or more earpieces worn by the person can further include obtaining, by the computing system, second motion data indicative of motion of a second earpiece worn in a second ear (e.g., left ear) of the person.</p><p id="p-0072" num="0071">At (<b>1104</b>), the method <b>1100</b> can include obtaining, by the computing system, biometric data (e.g., heart rate) for the person. For instance, in some implementations, the one or more earpieces can include one or more biometric sensors (e.g., heart rate sensor) configured to obtain biometrics (e.g., heart rate) of the person. Alternatively, or additionally, the one or more earpieces can be communicatively coupled with one or more wearable devices (e.g., heart rate monitor) that include one or more biometric sensors configured to obtain biometrics of the person.</p><p id="p-0073" num="0072">At (<b>1106</b>), the method <b>1100</b> can include determining, by the computing system, a motion signature of the person based, at least in part, on the motion data obtained at (<b>1102</b>). It should be understood that the motion signature of the person can be determined using method discussed above with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0074" num="0073">At (<b>1108</b>), the method <b>1100</b> can include authenticating, by the computing system, the identity of the person wearing the one or more pieces based, at least in part, on the motion signature determined at (<b>1106</b>) and the biometric data obtained at (<b>1104</b>). It should be understood that the methods for authenticating the identity of the person based on the motion signature as discussed above with reference to <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref> can be implemented. Additionally, the identity of the person wearing the one or more earpieces can be further authenticated based on the biometric data obtained at (<b>1104</b>). For instance, in instances in which the motion signature of the person wearing the one or more earpieces corresponds to a recognized motion signature, the biometric data can be used to further authenticate the identity of the person. If, for example, the biometric data (e.g., heart rate) indicates the person is nervous (e.g., heart rate is above a threshold value), the computing system can be configured to require additional information in order to authenticate the identity of the person. In this manner, the computing system avoid authenticating the identity of the person wearing the one or more earpieces in instances in which the person's motion signature matches a recognized motion signature but biometric data indicates that the person may not be the person corresponding to the recognized motion signature.</p><p id="p-0075" num="0074">At (<b>1110</b>), the method <b>1100</b> can include determining, by the computing system, whether the person wearing the one or more earpiece is permitted to access a restricted area the person is attempting to enter. For instance, determining whether the person wearing the earpiece is permitted to access the restricted area can include, for instance, accessing, by the computing system, a database storing data that is indicative of persons permitted to access the restricted area. In some implementations, the data stored in the database can include a list of persons that are permitted to access the restricted area. It should be understood, however, that the data can be stored in the database in any suitable format.</p><p id="p-0076" num="0075">At (<b>1112</b>), the method <b>1100</b> can include providing, by the computing system, a notification indicative of whether the person wearing the earpiece is permitted to access the restricted area. For instance, in some implementations, providing the notification can include providing, by the computing system, the notification for display on the one or more output devices located at an entrance to the restricted area. It should be understood that the notification can include at least one of an audible alert or a visual alert.</p><p id="p-0077" num="0076">While the present subject matter has been described in detail with respect to specific example embodiments thereof, it will be appreciated that those skilled in the art, upon attaining an understanding of the foregoing may readily produce alterations to, variations of, and equivalents to such embodiments. Accordingly, the scope of the present disclosure is by way of example rather than by way of limitation, and the subject disclosure does not preclude inclusion of such modifications, variations and/or additions to the present subject matter as would be readily apparent to one of Zo ordinary skill in the art.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of authenticating an identity of a person wearing one or more earpieces, the method comprising:<claim-text>obtaining, by a computing system comprising one or more computing devices, motion data indicative of motion of one or more earpieces worn by the person;</claim-text><claim-text>determining, by the computing system, a motion signature for the person based, at least in part, on the motion data, the motion signature being unique to the person; and</claim-text><claim-text>authenticating, by the computing system, the identity of the person based, at least in part, on the motion signature.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein obtaining motion data indicative of motion of one or more earpieces comprises:<claim-text>obtaining, by the computing system, first motion data indicative of motion of a first earpiece worn in a first ear of the person; and</claim-text><claim-text>obtaining, by the computing system, second motion data indicative of motion of a second earpiece worn in a second ear of the person.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein:<claim-text>obtaining first motion data indicative of motion of the first earpiece comprises obtaining, by the computing system, one or more signals from one or more motion sensors of the first earpiece; and</claim-text><claim-text>obtaining second data from the second earpiece comprises obtaining, by the computing system, one or more signals from one or more motion sensors of the second earpiece.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the one or more motion sensors of at least one of the first earpiece and the second earpiece comprise at least one of an accelerometer and a gyroscope.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the motion signature for the person based, at least in part, on the motion data comprises:<claim-text>providing, by the computing system, the motion data as an input to one or more machine-learned motion classifier models;</claim-text><claim-text>classifying, by the computing system, the motion data via the one or more machine-learned motion classifier models to determine the motion signature for the person; and</claim-text><claim-text>obtaining, by the computing system, the motion signature for the person as an output of the one or more machine-learned motion classifier models.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein authenticating the identity of the person comprises:<claim-text>providing, by the computing system, the motion signature as an input to one or more machine-learned motion classifier models;</claim-text><claim-text>classifying, by the computing system, the motion signature via the one or more machine-learned motion classifier models to determine the identity of the person wearing the one or more earpieces; and</claim-text><claim-text>obtaining, by the computing system, the identity of the person as an output of the one or more machine-learned motion classifier models.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein authenticating the identity of the person comprises:<claim-text>comparing, by the computing system, the motion signature for the person to a plurality of motion signatures, each of the plurality of motion signatures associated with a different person;</claim-text><claim-text>determining, by the computing system, a first motion signature of the plurality of motion signatures corresponds to the motion signature for the person; and</claim-text><claim-text>determining, by the computing system, the identity of the person wearing the one or more earpieces based, at least in part, on the first motion signature.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>responsive to authenticating the identity of the person, determining, by the computing system, whether the person is permitted to access an area based, at least in part, on the identity of the person.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>obtaining, by the computing system, biometric data for the person; and</claim-text><claim-text>wherein authenticating the identity of the person comprises authenticating, by the computing system, the identity of the person based on the motion signature and the biometric data.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A person authentication system comprising:<claim-text>one or more earpieces, the one or more earpieces comprising one or more motion sensors; and</claim-text><claim-text>a computing system communicatively coupled to the one or more earpieces, the computing system comprising one or more computing devices, the computing system configured to perform operations, the operations comprising:<claim-text>obtaining motion data indicative of motion of the one or more earpieces when the one or more earpieces are being worn by the person;</claim-text><claim-text>determining a motion signature for the person based, at least in part, on the motion data, the motion signature being unique to the person; and</claim-text><claim-text>authenticating an identity of the person based, at least in part, on the motion signature.</claim-text></claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The person authentication system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the one or more earpieces comprise a first earpiece and a second earpiece, the first earpiece configured to be worn in a first ear of the person, the second earpiece configured to be worn in a second ear of the person.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The person authentication system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the one or more motion sensors comprise at least one of an accelerometer and a gyroscope.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The person authentication system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the one or more earpieces comprise a modal antenna configurable in a plurality of antenna modes, each of the plurality of antenna modes having a distinct radiation pattern.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The person authentication system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein obtaining motion data indicative of motion of the one or more earpieces comprises:<claim-text>obtaining first motion data indicative of motion of a first earpiece worn in a first ear of the person; and</claim-text><claim-text>obtaining second motion data indicative of motion of a second earpiece worn in a second ear of the person.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The person authentication system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein<claim-text>obtaining first motion data indicative of motion of the first earpiece comprises obtaining, by the computing system, one or more signals from one or more motion sensors of the first earpiece; and</claim-text><claim-text>obtaining second data from the second earpiece comprises obtaining, by the computing system, one or more signals from one or more motion sensors of the second earpiece.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The person authentication system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the operation of determining the motion signature for the person based, at least in part, on the motion data comprises:<claim-text>Providing the motion data as an input to one or more machine-learned motion classifier models;</claim-text><claim-text>classifying the motion data via the one or more machine-learned motion classifier models to determine the motion signature for the person; and</claim-text><claim-text>obtaining the motion signature for the person as an output of the one or more machine-learned motion classifier models.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The person authentication system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the operation of authenticating the identity of the person comprises:<claim-text>providing the motion signature as an input to one or more machine-learned motion classifier models;</claim-text><claim-text>classifying the motion signature via the one or more machine-learned motion classifier models to determine the identity of the person wearing the one or more earpieces; and</claim-text><claim-text>obtaining the identity of the person as an output of the one or more machine-learned motion classifier models.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The person authentication system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the computing system is communicatively coupled to the one or more earpieces via a wireless network.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The person authentication system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the motion signature is indicative of a gait of the person.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The person authentication system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the one or more earpieces are communicatively coupled to one or more motion sensor systems worn by the person.</claim-text></claim></claims></us-patent-application>
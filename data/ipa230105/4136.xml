<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004137A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004137</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17742482</doc-number><date>20220512</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2021-0086980</doc-number><date>20210702</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>05</class><subclass>B</subclass><main-group>19</main-group><subgroup>402</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>23</class><subclass>Q</subclass><main-group>15</main-group><subgroup>12</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>05</class><subclass>B</subclass><main-group>19</main-group><subgroup>4155</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>B</subclass><main-group>19</main-group><subgroup>402</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>23</class><subclass>Q</subclass><main-group>15</main-group><subgroup>12</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>B</subclass><main-group>19</main-group><subgroup>4155</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>B</subclass><main-group>2219</main-group><subgroup>36088</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">APPARATUS FOR CORRECTING ASSEMBLY DEVIATION OF AN APPARATUS AND CORRECTING A PROCESS ERROR USING AN APRILTAG, AND AN APPARATUS FOR CORRECTING AN ASSEMBLY DEVIATION OF THE APPARATUS AND CORRECTING A PROCESS ERROR USING THE SAME</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>REALOOK &#x26; COMPANY CO., LTD</orgname><address><city>Suwon-si</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>LIM</last-name><first-name>Nam Il</first-name><address><city>Suwon-si</city><country>KR</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An apparatus for correcting a process error includes: a frame; a machining unit formed inside or outside the frame with respect to the frame and performing a predetermined process; a conveying unit formed inside or outside the frame with respect to the frame and performing predetermined conveying; a sensing mark formed on the frame, the machining unit, or the conveying unit; an imaging unit formed inside or outside the frame and creating an original image by imaging the sensing mark; and a measuring unit deriving a 3D position variation value of the frame, the machining unit, or the conveying unit by deriving an image variation value of the sensing mark by analyzing the original image transmitted from the imaging unit imaging the sensing mark formed on the frame, the machining unit, or the conveying unit.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="127.17mm" wi="144.10mm" file="US20230004137A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="140.80mm" wi="146.13mm" file="US20230004137A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="175.51mm" wi="143.85mm" file="US20230004137A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="167.22mm" wi="139.53mm" file="US20230004137A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="125.81mm" wi="99.74mm" file="US20230004137A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="125.39mm" wi="95.59mm" file="US20230004137A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="121.07mm" wi="101.09mm" file="US20230004137A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading><heading id="h-0002" level="1">Field of the Invention</heading><p id="p-0002" num="0001">The present disclosure relates to an apparatus for correcting an assembly deviation and a process error thereof using a sensing mark, and a method of correcting an assembly deviation and process error using the apparatus. More specifically, the present disclosure relates to a technology of reducing in real time deviations that are caused by gaps and tolerances when an apparatus is assembled and driven by continuously monitoring in real time position variation values and angle variation values Ox, Oy, and Oz in X, Y, and Z axes of each of a frame, a machining unit, a conveying unit, an actuating unit, a measuring unit, a flexure, etc. that constitute the apparatus using sensing marks, such as an AprilTag, and a camera.</p><heading id="h-0003" level="1">Description of the Related Art</heading><p id="p-0003" num="0002">Attempts to 3-dimensionally restore objects have been continuously made throughout the industry, and it is actually possible to 3-dimensionally restore objects with the development of computer vision technology. When a laser or pattern light is used in such attempts, there is a defect that the equipment is expensive and difficult to actually use while the accuracy is high. However, 3D restoration technologies that do not use an artificial light source have an advantage that the equipment is simple although the precision is low in comparison to an active type.</p><p id="p-0004" num="0003">A method of using a camera of such attempts is actively studied due to improvement of the resolution and performance of cameras. This method may be classified into types such as Structure From Motion (SFM), stereo vision, and space carving that defines a space with voxels, projects the voxels to image, and keeps only voxels that satisfy consistency and visibility of colors. However, these types have a defect that they are difficult to apply when the restoration target has an insufficient texture or colors are almost similar.</p><p id="p-0005" num="0004">On the other hand, an AprilTag, which is a visual reference that is useful in various types of work including augmented reality, robotics, and camera correction, makes it possible to easily create a target in common printers and to calculate accurate 3D position, direction, etc. of the tag through a camera using sensing software even if there is limitation in lighting or viewing angle.</p><p id="p-0006" num="0005">An AprilTag is conceptually similar to a QR code in that it is a kind of 2D barcodes but is designed to encode less data payload (4-12 bits), so it is stronger and can be sensed in a longer range, whereby it is possible to calculate a 3D position with high accuracy in terms of detection rate and accuracy.</p><p id="p-0007" num="0006">A localization method that is performed by a computer system has been disclosed in Korean Patent Application Publication No. 10-2021-0057586 (title of disclosure: Method and system for camera-based visual localization using blind watermarking). The computer system includes at least one processor configured to execute computer-readable instructions included in a memory, and the localization method includes: recognizing a combined image including an invisible marker from a query image; and calculating a pose of the query image on the basis of the identification tag of the marker and matched coordinates through the at least one processor.</p><heading id="h-0004" level="1">CITATION LIST</heading><heading id="h-0005" level="1">Patent Literature</heading><p id="p-0008" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0007">Patent Literature 1: Korean Patent Application Publication No. 10-2021-0057586</li></ul></p><heading id="h-0006" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0009" num="0008">In order to solve the problems described above, an objective of the present disclosure is to minimize in real time deviations that are caused by gaps and tolerances when an apparatus is assembled and driven by continuously monitoring in real time position variation values and angle variation values &#x3b8;x, &#x3b8;y, and &#x3b8;z in X, Y, and Z axes of each of a frame, a machining unit, a conveying unit, a actuating unit, a measuring unit, a flexure, etc. that constitute the apparatus using sensing marks, such as an AprilTag, and a camera.</p><p id="p-0010" num="0009">The objectives to be implemented in the present disclosure are not limited to the technical problems described above, and other objects that are not stated herein will be clearly understood by those skilled in the art from the following specifications.</p><p id="p-0011" num="0010">In order the achieve the objectives described above, the present disclosure includes: a frame; a machining unit formed inside or outside the frame with respect to the frame and performing a predetermined process; a conveying unit formed inside or outside the frame with respect to the frame and performing predetermined conveying; a sensing mark formed on the frame, the machining unit, or the conveying unit; an imaging unit formed inside or outside the frame and creating an original image by imaging the sensing mark; and a measuring unit deriving a 3D position variation value of the frame, the machining unit, or the conveying unit by deriving an image variation value of the sensing mark by analyzing the original image transmitted from the imaging unit imaging the sensing mark formed on the frame, the machining unit, or the conveying unit.</p><p id="p-0012" num="0011">In an embodiment of the present disclosure, the sensing mark may be an AprilTag, an Aruco marker, an ARtag, or an ARToolKit.</p><p id="p-0013" num="0012">In an embodiment of the present disclosure, the measuring unit may transmit a control signal to the machining unit or the conveying unit so that a 3D position of the machining unit or the conveying unit is corrected in accordance with a 3D position variation value of the frame, the machining unit, or the conveying unit.</p><p id="p-0014" num="0013">In an embodiment of the present disclosure, the sensing mark may be carved, printed, or attached.</p><p id="p-0015" num="0014">In an embodiment of the present disclosure, a conveying unit coupled to the imaging unit and the frame and moving the imaging unit may be further included.</p><p id="p-0016" num="0015">In an embodiment of the present disclosure, the measuring unit may sense lines in an image of the sensing mark in the original image using least square method (LSM) in clusters of similar pixel gradients.</p><p id="p-0017" num="0016">In an embodiment of the present disclosure, the measuring unit may derive a 3D position variation value of the frame, the machining unit, or the conveying unit having a sensing mark by analyzing 3D inclination or movement of the sensing mark.</p><p id="p-0018" num="0017">In order to achieve the objectives described above, the present disclosure includes: a first step in which an original image of the sensing mark is taken by the imaging unit; a second step in which the measuring unit derives an image variation value of the sensing mark by analyzing the original image transmitted from the imaging unit; a third step in which the measuring unit derives a 3D position variation value of the machining unit; and a fourth step in which the measuring unit transmits a control signal to the machining unit, whereby the 3D position of the machining unit is corrected.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0007" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is schematic view of an apparatus according to an embodiment of the present disclosure;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a perspective view of an apparatus according to another embodiment of the present disclosure;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram of a conveying unit according to another embodiment of the present disclosure;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIGS. <b>4</b>A-<b>4</b>D and <b>5</b>A-<b>5</b>D</figref> are images of sensing marks according to a plurality of embodiments of the present disclosure; and</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIGS. <b>6</b>A-<b>6</b>D</figref> are images for analysis of a sensing mark according to an embodiment of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0008" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading><p id="p-0024" num="0023">Hereinafter, the present disclosure is described with reference to the accompanying drawings. However, the present disclosure may be modified in various different ways and is not limited to the embodiments described herein. Further, in the accompanying drawings, components irrelevant to the description will be omitted in order to clearly describe the present disclosure, and similar reference numerals will be used to describe similar components throughout the specification.</p><p id="p-0025" num="0024">Throughout the specification, when an element is referred to as being &#x201c;connected with (coupled to, combined with, in contact with)&#x201d; another element, it may be &#x201c;directly connected&#x201d; to the other element and may also be &#x201c;indirectly connected&#x201d; to the other element with another element intervening therebetween. Further, unless explicitly described otherwise, &#x201c;comprising&#x201d; any components will be understood to imply the inclusion of other components rather than the exclusion of any other components.</p><p id="p-0026" num="0025">The terminology used herein is for the purpose of describing particular embodiments only and is not intended to limit the present disclosure Singular forms are intended to include plural forms unless the context clearly indicates otherwise. It will be further understood that the terms &#x201c;comprise&#x201d; or &#x201c;have&#x201d; used in this specification specify the presence of stated features, numerals, steps, operations, components, parts, or a combination thereof, but do not preclude the presence or addition of one or more other features, numerals, steps, operations, components, parts, or a combination thereof.</p><p id="p-0027" num="0026">Hereinafter, the present disclosure is described in detail with reference to the accompanying drawings.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is schematic view of an apparatus according to an embodiment of the present disclosure, and <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a perspective view of an apparatus according to another embodiment of the present disclosure. <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram of a conveying unit <b>300</b> according to another embodiment of the present disclosure.</p><p id="p-0029" num="0028">As shown in <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>, an apparatus for correcting a process error of the present invention includes: a frame <b>410</b>; a machining unit formed inside or outside the frame <b>410</b> with respect to the frame <b>410</b> and performing a predetermined process; a conveying unit formed inside or outside the frame <b>410</b> with respect to the frame <b>410</b> and performing predetermined conveying; a sensing mark <b>10</b> formed on the frame <b>410</b>, the machining unit, or the conveying unit <b>300</b>; an imaging unit <b>100</b> formed inside or outside the frame <b>410</b> and creating an original image by imaging the sensing mark <b>10</b>; and a measuring unit deriving a 3D position variation value of the frame <b>410</b>, the machining unit, or the conveying unit <b>300</b> by deriving an image variation value of the sensing mark <b>10</b> by analyzing the original image transmitted from the imaging unit <b>100</b> imaging the sensing mark <b>10</b> formed on the frame <b>410</b>, the machining unit, or the conveying unit <b>300</b>.</p><p id="p-0030" num="0029">The sensing mark <b>10</b> installed on the conveying unit <b>300</b> may be imaged with the conveying unit <b>300</b> stopped.</p><p id="p-0031" num="0030">The sensing mark <b>10</b> may be an AprilTag, an Aruco marker, an ARtag, or an ARToolKit. The sensing mark <b>10</b> is described as being limited to the types described above in an embodiment of the present disclosure, but it is apparent that the sensing mark <b>10</b> is not necessarily limited thereto and other 2D barcodes that can perform the same function may be used.</p><p id="p-0032" num="0031">As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the machining unit may include a machining tool <b>210</b> that is a tool for machining a machining target <b>500</b>, a machining base <b>220</b> supporting the machining target <b>500</b>, a tool actuator <b>230</b> coupled to the machining tool <b>210</b> and 3-dimensionally moving or rotating the machining tool <b>210</b>, and a base actuator <b>240</b> coupled to the machining base <b>220</b> and 3-dimensionally moving or rotating the machining base <b>220</b>.</p><p id="p-0033" num="0032">The machining tool <b>210</b>, the machining base <b>220</b>, the tool actuator <b>230</b>, and the base actuator <b>240</b> each may have a multi-axis robot or an orthogonal robot, and the machining unit may be partially or entirely installed inside or outside the frame with respect to the frame. The case in which the machining unit is formed inside the frame is described in the present disclosure for the convenience of description. The machining unit may be a component including all equipment including actuating equipment, flexure, etc. required for machining.</p><p id="p-0034" num="0033">The sensing mark <b>10</b> may be formed on each of the components constituting the machining unit, as described above, the frame <b>410</b>, etc., and the sensing mark <b>10</b> may be carved, printed, or attached.</p><p id="p-0035" num="0034">In detail, the sensing mark <b>10</b> may be carved on each surface by a laser, etc., or the sensing mark <b>10</b> may be printed on each surface. Alternatively, the sensing mark <b>10</b> may be installed by carving or printing a sensing mark <b>10</b> on a substrate and attaching the substrate to each surface.</p><p id="p-0036" num="0035">The conveying unit <b>300</b> is coupled to the imaging unit <b>100</b> and the frame <b>410</b> and can move the imaging unit <b>100</b>. The conveying unit <b>300</b> may include a supporting arm <b>310</b> coupled to the imaging unit <b>100</b> and supporting the imaging unit <b>100</b>, a driver <b>320</b> coupled to the supporting arm <b>310</b> and 3-dimensionally moving or rotating the supporting arm <b>310</b>, and a support <b>330</b> coupled to the driver <b>320</b> and supporting the driver <b>320</b>. The driver <b>320</b> may move along the support <b>330</b> or may rotate about the support <b>330</b>.</p><p id="p-0037" num="0036">The imaging unit <b>100</b> may be not only coupled to the conveying unit <b>300</b>, as described above, but also formed at each of a plurality of positions where the sensing mark <b>10</b> can be imaged inside the frame <b>410</b>. The installation position and number of the imaging unit <b>100</b> may depend on the process.</p><p id="p-0038" num="0037">However, it may be advantageous that the imaging unit <b>100</b> is coupled to the conveying unit <b>300</b> in terms of space use and process efficiency, and it is exemplified that the imaging unit <b>100</b> is coupled to the conveying unit <b>300</b> in the present disclosure. It is apparent that the fundamental principle is the same even when the imaging unit <b>100</b> is installed at a plurality of positions.</p><p id="p-0039" num="0038">The imaging unit <b>100</b> includes a position sensor <b>110</b>, and information about position and posture changes of the imaging unit <b>100</b> collected by the position sensor <b>110</b> can be transmitted to the measuring unit. The measuring unit transmits a control signal to the driver <b>320</b> by analyzing the information about position and posture changes of the imaging unit <b>100</b> received from the position sensor <b>110</b>, whereby the position and posture of the imaging unit <b>100</b> can be controlled. The information obtained by the position sensor <b>110</b> may be transmitted to the measuring unit in a wired or wireless type.</p><p id="p-0040" num="0039">The imaging unit <b>100</b> that images one sensing mark <b>10</b> can image a position change of the sensing mark <b>10</b> only if it images the sensing mark <b>10</b> while maintaining a reference position, which is the reference for imaging the sensing mark <b>10</b>. Accordingly, the position of the imaging unit <b>100</b> can be controlled such that the position, posture, and optical axis of the imaging unit <b>100</b> are maintained for one sensing mark <b>10</b>.</p><p id="p-0041" num="0040">Information about the position for imaging each sensing mark <b>10</b> may be stored in the measuring unit. When the imaging unit <b>100</b> is moved by the conveying unit <b>300</b> to image one sensing mark <b>10</b>, the measuring unit can transmit a control signal to the conveying unit <b>300</b> so that the imaging unit <b>100</b> can perform imaging while maintaining the posture and optical axis suitable for imaging the sensing mark <b>10</b> at the reference position for imaging the sensing mark <b>10</b>.</p><p id="p-0042" num="0041">Such control of the posture and optical axis of the imaging unit <b>100</b> may be performed in the same way even when the imaging unit <b>100</b> is coupled to the frame <b>410</b>. When the imaging unit <b>100</b> is fixed to a portion of the frame <b>410</b> and images a sensing mark <b>10</b>, the position of the imaging unit <b>100</b> can be controlled such that the imaging unit <b>100</b> performs imaging while maintaining the posture and optical axis suitable for imaging the sensing mark <b>10</b> at the reference position for imaging the sensing mark <b>10</b>. In this case, the driver <b>320</b> may be coupled between the imaging unit <b>100</b> and the frame <b>410</b> to control the position of the imaging unit <b>100</b>.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIGS. <b>4</b>A-<b>4</b>D and <b>5</b>A-<b>5</b>D</figref> are images of sensing marks <b>10</b> according to a plurality of embodiments of the present disclosure. <figref idref="DRAWINGS">FIGS. <b>6</b>A-<b>6</b>D</figref> are images for analysis of a sensing mark <b>10</b> according to an embodiment of the present disclosure.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIGS. <b>4</b>A-<b>4</b>D</figref> are images of AprilTags of different embodiments. <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> is an image of an ARToolKit, <figref idref="DRAWINGS">FIG. <b>5</b>B</figref> is an image of an ARtag, <figref idref="DRAWINGS">FIG. <b>5</b>C</figref> is an image of an AprilTag, and <figref idref="DRAWINGS">FIG. <b>5</b>D</figref> is an image of an Aruco marker.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIGS. <b>6</b>A-<b>6</b>D</figref> are images for analysis of a sensing mark <b>10</b> according to an embodiment of the present disclosure. In detail, <figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is an original image taken by the imaging unit <b>100</b>, <figref idref="DRAWINGS">FIG. <b>6</b>B</figref> is an image that shows sensing of lines in the original image, <figref idref="DRAWINGS">FIG. <b>6</b>C</figref> is an image that shows sensing of all quads, and <figref idref="DRAWINGS">FIG. <b>6</b>D</figref> is an image that shows extraction of a quad having a valid code system from the image.</p><p id="p-0046" num="0045">As shown in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, the imaging unit <b>100</b> creates an original image by imaging the sensing mark <b>10</b>, and the original image can be transmitted to the measuring unit. As shown in <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, the measuring unit can sense lines in the image of the sensing mark in the original image using least square method (LSM) in clusters of similar pixel gradients.</p><p id="p-0047" num="0046">Next, as shown in <figref idref="DRAWINGS">FIG. <b>6</b>C</figref>, quads can be sensed as many as possible in the gradient directions, and then, as shown in <figref idref="DRAWINGS">FIG. <b>6</b>D</figref>, a quad having a valid code system can be extracted from the original image. The measuring unit obtains the pose of the sensing mark (AprilTag) <b>10</b> in the original image using homograph and intrinsic estimation, measures a coordinate change of each of the apexes of the outermost rectangle, and measures 3D inclination or movement, thereby being able to derive an image variation value of the sensing mark <b>10</b>.</p><p id="p-0048" num="0047">Further, it is possible to derive 3D position variation values of the frame <b>410</b>, the machining unit, and the conveying unit <b>300</b> having the sensing mark <b>10</b> by analyzing 3D inclination (angle variation values in X, Y, and Z axes, &#x3b8;x, &#x3b8;y, and &#x3b8;z) or 3D position variation values x, y, and z of the sensing mark <b>10</b>.</p><p id="p-0049" num="0048">When the apparatus of the present disclosure is in operation, angle variation values &#x3b8;x, &#x3b8;y, and &#x3b8;z in the X, Y, and Z axes or position variation values x, y, and z in the X, Y, and Z axes may be generated due to spacing at joints by changes in tension, compressing, bending, shearing, twisting, etc. and accumulation of vibration in operation at portions of each part of the machining unit or the frame <b>410</b>. In this case, 3D inclination or movement may be generated at the sensing mark <b>10</b>.</p><p id="p-0050" num="0049">The measuring unit can derive 3D coordinate variation values at each portion of the sensing mark <b>10</b> by analyzing 3D inclination or movement of the sensing mark <b>10</b> using a predetermined program, and can derive 3D position variation values of the frame <b>410</b>, the machining unit, the conveying unit <b>300</b>, etc. having the sensing mark <b>10</b> using the derived 3D coordinate variation values.</p><p id="p-0051" num="0050">Data obtained for each case by performing simulation on the 3D coordinate variation values of each portion of the sensing mark <b>10</b> due to 3D inclination or movement of the sensing mark <b>10</b> are stored in the program. It is possible to derive a 3D coordinate variation value of each portion of the sensing mark <b>10</b> by comparing a reference image of the sensing mark <b>10</b> based on the stored data with data about 3D inclination or movement of the sensing mark <b>10</b> in an original image.</p><p id="p-0052" num="0051">The measuring unit can transmit a control signal to the machining unit or the conveying unit <b>300</b> so that the 3D position of the machining unit or the conveying unit <b>300</b> is corrected in accordance with the 3D position variation value of the frame <b>410</b>, the machining unit, or the conveying unit <b>300</b>.</p><p id="p-0053" num="0052">In this case, the imaging unit <b>100</b> can continuously image the sensing mark <b>10</b>, and original images can be transmitted to the measuring unit. When an original image and the reference image of a corresponding sensing mark <b>10</b> are the same, the measuring unit can determine that the machining unit has been moved or rotated to a predetermined position and can finish controlling the machining unit. Control of the machining unit may include control of each of the machining tool <b>210</b>, the machining base <b>220</b>, the tool actuator <b>230</b>, and the base actuator <b>240</b>. This configuration can be applied in the same way to control of the conveying unit <b>300</b>.</p><p id="p-0054" num="0053">As a detailed embodiment, as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, one module may be formed by forming the machining unit in a housing <b>420</b>. A plurality of such modules may be formed and each of them may be coupled to the frame <b>410</b>. In this configuration, the imaging unit <b>100</b> can image the machining unit formed in each of the modules, and accordingly, a control signal is transmitted to the plurality of machining units from the measuring unit, whereby each of the machining unit can be controlled.</p><p id="p-0055" num="0054">Further, as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a linear motor <b>341</b> and a rotary motor <b>342</b> may be provided as a configuration corresponding to the driver <b>320</b>. An end of the supporting arm <b>310</b> may be coupled to the linear motor <b>341</b> and the other end of the supporting arm <b>310</b> may be coupled to the imaging unit <b>100</b>. Further, the imaging unit <b>100</b> itself may tilt, rotate, etc. a camera provided in the imaging unit <b>100</b>, and the imaging range of the camera may be increased.</p><p id="p-0056" num="0055">Further, the conveying unit <b>300</b> may include a motor support <b>350</b> vertically elongated inside the frame <b>410</b> and supporting the linear motor <b>341</b> and the rotary motor <b>342</b> may be coupled to the bottom of the motor support <b>350</b>, so the rotary motor <b>342</b> rotates the motor support <b>350</b>, whereby the imaging unit <b>100</b> can be rotated.</p><p id="p-0057" num="0056">As described above, when the measuring unit receives information from the position sensor <b>110</b> of the imaging unit <b>100</b>, the measuring unit transmits a control signal to one or more of the linear motor <b>341</b>, the rotary motor <b>342</b>, and a servo motor, thereby being able to control 3D movement and rotation of the imaging unit <b>100</b>. Further, the measuring unit transmits a control signal to the conveying unit <b>300</b> to change the imaging position from one sensing mark <b>10</b> to another sensing mark <b>10</b>, thereby being able to change the position of the imaging unit <b>100</b>.</p><p id="p-0058" num="0057">Further, the sensing mark <b>10</b> may be formed on fixed components such as the motor support <b>350</b> and the rotary motor <b>342</b>, it is possible to image a sensing mark <b>10</b> of the fixed components through other imaging units <b>100</b> installed on the frame <b>410</b>, and the measuring unit can measure 3D position or rotation variation values of each of the fixed components using original images obtained in this case.</p><p id="p-0059" num="0058">Further, the frame <b>410</b> may be included in the fixed component, and the imaging unit <b>100</b> images the sensing mark <b>10</b> formed on each portion of the frame <b>410</b> and the measuring unit analyzes the image, whereby it is possible to measure deformation (3D position or twist variation value) of a portion of the frame <b>410</b>.</p><p id="p-0060" num="0059">Further, when the measuring unit determines that a fixed component has been 3-dimensionally moved, rotated, or deformed, the measuring unit can transmit information of the determination to an electronic device of a user and the user can correct wrong position and posture of the fixed component. Accordingly, it is possible to quickly take measures against problems with each of the components in the apparatus.</p><p id="p-0061" num="0060">Hereafter, a method of correcting an assembly deviation and process error using the apparatus of the present disclosure is described.</p><p id="p-0062" num="0061">In a first step, an original image of a sensing mark <b>10</b> can be taken by the imaging unit <b>100</b>. Further, in a second step, the measuring unit can derive an image variation value of the sensing mark <b>10</b> by analyzing the original image transmitted from the imaging unit <b>100</b>.</p><p id="p-0063" num="0062">Next, in a third step, the measuring unit can derive a 3D position variation value of the machining unit. Thereafter, in a fourth step, the measuring unit transmits a control signal to the machining unit, whereby the 3D position of the machining unit can be corrected.</p><p id="p-0064" num="0063">The other details of the method of correcting an assembly deviation and a process error according to the present disclosure are the same as those of the apparatus of the present disclosure described above.</p><p id="p-0065" num="0064">It is possible to minimize a process error due to each component by correcting the 3D position value of each component by reflecting deviations that are caused by gaps and tolerances when an apparatus is assembled and driven by continuously monitoring in real time position variation values and angle variation values &#x3b8;x, &#x3b8;y, and &#x3b8;z in X, Y, and Z axes of each of a frame, a machining unit, a conveying unit, an actuating unit, a measuring unit, a flexure, etc. that constitute an apparatus, by using the apparatus and method of the present disclosure described above. That is, it is possible to improve the quality of products that are manufactured by the apparatus of the present disclosure by minimizing an assembly deviation of equipment, which is assembled by the apparatus of the present disclosure, a process error in another process, etc. Further, it is possible to prevent generation of accumulated tolerances by minimizing an error that may be generated in an assembly process of equipment (machining unit, etc.) itself installed in the apparatus of the present disclosure.</p><p id="p-0066" num="0065">The present disclosure having the configuration described above has an effect that it is possible to minimize a process error due to each component by correcting the 3D position value of each component by reflecting deviations that are caused by gaps and tolerances when an apparatus is assembled and driven by continuously monitoring in real time position variation values and angle variation values &#x3b8;x, &#x3b8;y, and &#x3b8;z in X, Y, and Z axes of each of a frame, a machining unit, a conveying unit, an actuating unit, a measuring unit, a flexure, etc. that constitute an apparatus.</p><p id="p-0067" num="0066">The effects of the present disclosure are not limited thereto, and it should be understood that the effects include all effects that can be inferred from the configuration of the present disclosure described in the following specification or claims.</p><p id="p-0068" num="0067">The above description is provided as an exemplary embodiment of the present disclosure, and it should be understood that the present disclosure may be easily modified in other various ways without changing the spirit or the necessary features of the present disclosure by those skilled in the art. Therefore, the embodiments described above are only examples and should not be construed as being limitative in all respects. For example, the components described as a single part may be divided and the components described as separate parts may be integrated.</p><p id="p-0069" num="0068">The scope of the present disclosure is defined by the following claims, and all of changes and modifications obtained from the meaning and range of claims and equivalent concepts should be construed as being included in the scope of the present disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An apparatus for correcting an assembly deviation and a process error thereof using a sensing mark, the apparatus comprising:<claim-text>a frame;</claim-text><claim-text>a machining unit formed inside or outside the frame with respect to the frame and performing a predetermined process;</claim-text><claim-text>a conveying unit formed inside or outside the frame with respect to the frame and performing predetermined conveying;</claim-text><claim-text>a sensing mark formed on the frame, the machining unit, or the conveying unit;</claim-text><claim-text>an imaging unit formed inside or outside the frame and creating an original image by imaging the sensing mark; and</claim-text><claim-text>a measuring unit deriving a 3D position variation value of the frame, the machining unit, or the conveying unit by deriving an image variation value of the sensing mark by analyzing the original image transmitted from the imaging unit imaging the sensing mark formed on the frame, the machining unit, or the conveying unit.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensing mark is an AprilTag, an Aruco marker, an ARtag, or an ARToolKit.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the measuring unit transmits a control signal to the machining unit or the conveying unit so that a 3D position of the machining unit or the conveying unit is corrected in accordance with a 3D position variation value of the frame, the machining unit, or the conveying unit.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensing mark is carved, printed, or attached.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the conveying unit is coupled to the imaging unit and the frame and moves the imaging unit.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the measuring unit senses lines in an image of the sensing mark in the original image using least square method (LSM) in clusters of similar pixel gradients.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the measuring unit derives a 3D position variation value of the frame, the machining unit, or the conveying unit having a sensing mark by analyzing 3D inclination or movement of the sensing unit.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A method of correcting an assembly deviation and a process error using the apparatus for correcting an assembly deviation and a process error thereof using a sensing mark of <claim-ref idref="CLM-00001">claim 1</claim-ref>, the method comprising:<claim-text>a first step in which an original image of the sensing mark is taken by the imaging unit;</claim-text><claim-text>a second step in which the measuring unit derives an image variation value of the sensing mark by analyzing the original image transmitted from the imaging unit;</claim-text><claim-text>a third step in which the measuring unit derives a 3D position variation value of the machining unit; and</claim-text><claim-text>a fourth step in which the measuring unit transmits a control signal to the machining unit, whereby the 3D position of the machining unit is corrected.</claim-text></claim-text></claim></claims></us-patent-application>
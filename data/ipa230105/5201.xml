<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005202A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005202</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17765094</doc-number><date>20210709</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2021-0085515</doc-number><date>20210630</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>13</main-group><subgroup>20</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>13</main-group><subgroup>80</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>13</main-group><subgroup>205</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>13</main-group><subgroup>80</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">SPEECH IMAGE PROVIDING METHOD AND COMPUTING DEVICE FOR PERFORMING THE SAME</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>DEEPBRAIN AI INC.</orgname><address><city>Seoul</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Doo Hyun</first-name><address><city>Gyeonggi-do</city><country>KR</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/KR2021/008828</doc-number><date>20210709</date></document-id><us-371c12-date><date>20220330</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A computing device according to an embodiment includes one or more processors, a memory storing one or more programs executed by the one or more processors, a standby state image generating module configured to generate a standby state image in which a person is in a standby state, and generate a back-motion image set including a plurality of back-motion images at a preset frame interval from the standby state image for image interpolation between a preset reference frame of the standby state image, a speech state image generating module configured to generate a speech state image in which a person is in a speech state based on a source of speech content, and an image playback module configured to generate a synthetic speech image by combining the standby state image and the speech state image while playing the standby state image.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="67.90mm" wi="120.82mm" file="US20230005202A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="83.74mm" wi="122.85mm" file="US20230005202A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="148.93mm" wi="127.25mm" file="US20230005202A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="102.11mm" wi="149.69mm" file="US20230005202A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="187.54mm" wi="134.87mm" file="US20230005202A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="180.42mm" wi="150.71mm" orientation="landscape" file="US20230005202A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="174.07mm" wi="115.40mm" orientation="landscape" file="US20230005202A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="125.65mm" wi="123.61mm" file="US20230005202A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS AND CLAIM OF PRIORITY</heading><p id="p-0002" num="0001">This application claims benefit under 35 U.S.C. 119, 120, 121, or 365(c), and is a National Stage entry from International Application No. PCT/KR2021/008828, filed Jul. 9, 2021, which claims priority to the benefit of Korean Patent Application No. 10-2021-0085515 filed in the Korean Intellectual Property Office on Jun. 30, 2021, the entire contents of which are incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">1. Technical Field</heading><p id="p-0003" num="0002">Embodiments of the present disclosure relate to a technology for providing a speech image.</p><heading id="h-0004" level="1">2. Background Art</heading><p id="p-0004" num="0003">With the recent technological development in the field of artificial intelligence, various types of content are being generated based on artificial intelligence (AI) technology. For example, there is a case in which, when there is a voice message to be transmitted, a speech image is generated as if a famous person (e.g., a president) speaks the voice message in order to draw people's attention. This is achieved by generating mouth shapes or the like to fit a specific message, just like a famous person speaking the specific message in an image of the famous person.</p><p id="p-0005" num="0004">In addition, technologies that allow artificial intelligence (AI) to conduct conversations with humans (e.g., video calls, or the like) are being studied. In the technologies, synthesizing the speech image takes time and requires a lot of data, and thus it is difficult to generate an image of a conversation (or an image of speech) in real time, which may be a problem. That is, the artificial intelligence has to recognize the other person's words and decide what kind of answer to give, and it takes time to generate a speech image corresponding to the answer, and thus the artificial intelligence speech image feels unnatural from the other person's point of view.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0006" num="0005">Embodiments of the present disclosure is to provide a new technology for providing an artificial intelligence-based speech image in real time.</p><p id="p-0007" num="0006">According to an embodiment, a computing device including one or more processors and a memory storing one or more programs executed by the one or more processors includes: a standby state image generating module configured to generate a standby state image in which a person in the image is in a standby state, and generate a back-motion image set including a plurality of back-motion images at a preset frame interval from the standby state image for image interpolation between a preset reference frame of the standby state image; a speech state image generating module configured to generate a speech state image in which a person is in a speech state based on a source of speech content; and an image playback module configured to generate a synthetic speech image by combining the standby state image and the speech state image while playing the standby state image.</p><p id="p-0008" num="0007">The back-motion image set may include a plurality of back-motion images having different initial speech shapes of the person in the images.</p><p id="p-0009" num="0008">The image playback module may be further configured to extract a back-motion image set based on a point of time when the generating of the speech state image is completed, return a standby state image being played to a preset reference frame based on the back-motion image set, and generate a synthetic speech image in combination with a frame of the speech state image from the reference frame.</p><p id="p-0010" num="0009">The image playback module may be further configured to detect a closest frame having a back-motion image set among frames after a current frame of the standby state image being played, at the point of time when the generating of the speech state image is completed, and extract the back-motion image set of the detected frame.</p><p id="p-0011" num="0010">The image playback module may be further configured to extract a back-motion image having an initial speech shape corresponding to a source of speech content from the back-motion image set, and return the standby state image to the reference frame using the extracted back-motion image as an interpolation image.</p><p id="p-0012" num="0011">The image playback module may be further configured to play the standby state image again from an end point of time of the speech state image when the speech state image is ended during playback of the synthetic speech image.</p><p id="p-0013" num="0012">The speech state image generating module may be further configured to generate each of an audio part and an image part of the speech state image based on the source of speech content, the image part being generated for a face portion of a person in the standby state image.</p><p id="p-0014" num="0013">The image playback module may be further configured to replace the face portion of the standby state image with the image part of the speech state image, and generate the synthetic speech image by combining the standby state image where the face portion is replaced and the audio part of the speech state image.</p><p id="p-0015" num="0014">According to another embodiment, a computing device including one or more processors and a memory storing one or more programs executed by the one or more processors includes: a standby state image generating module configured to generate a standby state image in which a person is in a standby state, and generate a back-motion image set including a plurality of back-motion images at a preset frame interval from the standby state image for image interpolation between a preset reference frame of the standby state image, and an image playback module configured to transmit a source of speech content to a server, receives a speech state image in which a person is in a speech state from the server, and generate a synthetic speech image by combining the standby state image and the speech state image while playing the standby state image.</p><p id="p-0016" num="0015">According to an embodiment, a speech image providing method performed by a computing device including one or more processors and a memory storing one or more programs executed by the one or more processors includes: generating a standby state image in which a person is in a standby state; generating a back-motion image set including a plurality of back-motion images at a preset frame interval from the standby state image for image interpolation between a preset reference frame of the standby state image; generating a speech state image in which a person is in a speech state based on a source of speech content; and generating a synthetic speech image by combining the standby state image and the speech state image while playing the standby state image.</p><p id="p-0017" num="0016">According to another embodiment, a speech image providing method performed by a computing device including one or more processors and a memory storing one or more programs executed by the one or more processors includes: generating a standby state image in which a person is in a standby state; generating a back-motion image set including a plurality of back-motion images at a preset frame interval from the standby state image for image interpolation between a preset reference frame of the standby state image; transmitting a source of the speech content to a server; receiving a speech state image in which a person is in a speech state from the server; and generating a synthetic speech image by combining the standby state image and the speech state image while playing the standby state image.</p><p id="p-0018" num="0017">According to the disclosed embodiments, the standby state image is prepared in advance, and the speech state image is generated during playback of the standby state image and combined with the standby state image, thereby making it possible to generate the synthetic speech image in real time, and accordingly, possible to provide conversation-related services based on artificial intelligence in real time.</p><p id="p-0019" num="0018">In addition, the synthetic speech image is generated by generating the image part for the face portion of the person in the standby state image when generating the speech state image, and replacing the face portion of the standby state image with the image part of the speech state image, thereby making is possible to reduce the amount of data while reducing the time required for generating the synthetic speech image.</p><p id="p-0020" num="0019">In addition, a back-motion image set is prepared at a preset interval in the standby state image, the current frame of the current standby state is connected to the first frame thereof by playing the back-motion image corresponding to the source of speech content in a back-motion image set, and the speech state image is combined with the first frame of the standby state image, thereby making it possible to easily generate a synthetic speech image without considering other variables no matter when the speech state image is generated during playback of the standby state image, and to naturally connect the speech shape of the person in the synthetic speech image.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating a configuration of a speech image providing device according to an embodiment of the present disclosure.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating a state in which a back-motion image is generated in an embodiment of the present disclosure.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram schematically illustrating a state of combining a standby state image and a speech state image in an embodiment of the present disclosure.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram schematically illustrating a state in which an image playback module returns a standby state image being played to the first frame in an embodiment of the present disclosure.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram schematically illustrating a process until the image playback module plays a synthetic speech image in an embodiment of the present disclosure.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram illustrating a configuration of a speech image providing system according to an embodiment of the present disclosure.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram exemplarily illustrating a computing environment that includes a computing device suitable for use in exemplary embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0028" num="0027">Hereinafter, specific embodiments of the present disclosure will be described with reference to the accompanying drawings. The following detailed description is provided to assist in a comprehensive understanding of the methods, devices and/or systems described herein. However, the detailed description is only for illustrative purposes and the present disclosure is not limited thereto.</p><p id="p-0029" num="0028">In describing the embodiments of the present disclosure, when it is determined that detailed descriptions of known technology related to the present disclosure may unnecessarily obscure the gist of the present disclosure, the detailed descriptions thereof will be omitted. The terms used below are defined in consideration of functions in the present disclosure, but may be changed depending on the customary practice or the intention of a user or operator. Thus, the definitions should be determined based on the overall content of the present specification. The terms used herein are only for describing the embodiments of the present disclosure, and should not be construed as limitative. Unless expressly used otherwise, a singular form includes a plural form. In the present description, the terms &#x201c;including&#x201d;, &#x201c;comprising&#x201d;, &#x201c;having&#x201d;, and the like are used to indicate certain characteristics, numbers, steps, operations, elements, and a portion or combination thereof, but should not be interpreted to preclude one or more other characteristics, numbers, steps, operations, elements, and a portion or combination thereof.</p><p id="p-0030" num="0029">In the following description, the terminology &#x201c;transmission&#x201d;, &#x201c;communication&#x201d;, &#x201c;reception&#x201d; of a signal or information and terminology similar thereto may include a meaning in which the signal or information is directly transmitted from one element to another element and transmitted from one element to another element through an intervening element. In particular, &#x201c;transmission&#x201d; or &#x201c;sending&#x201d; of the signal or information to one element may indicate a final destination of the signal or information and may not imply a direct destination. The same is true for &#x201c;reception&#x201d; of the signal or information. In addition, in the present specification, a meaning in which two or more pieces of data or information are &#x201c;related&#x201d; indicates that when any one piece of data (or information) is obtained, at least a portion of other data (or information) may be obtained based thereon.</p><p id="p-0031" num="0030">Further, it will be understood that, although the terms first, second, etc. may be used herein to describe various elements, these elements should not be limited by these terms. These terms may be used to distinguish one element from another element. For example, without departing from the scope of the present disclosure, a first element could be termed a second element, and similarly, a second element could be termed a first element.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating a configuration of a speech image providing device according to an embodiment of the present disclosure.</p><p id="p-0033" num="0032">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the speech image providing device <b>100</b> may include a standby state image generating module <b>102</b>, a speech state image generating module <b>104</b>, and an image playback module <b>106</b>.</p><p id="p-0034" num="0033">In an embodiment, the standby state image generating module <b>102</b>, the speech state image generating module <b>104</b>, and the image playback module <b>106</b> may be implemented by using one or more physically separated devices, or may be implemented by one or more processors or a combination of one or more processors and software, and may not be clearly distinguished in specific operations, unlike the illustrated example.</p><p id="p-0035" num="0034">In an exemplary embodiment, the speech image providing device <b>100</b> may be a device for performing a conversation (AI conversation), a video call (AI video call), or the like, using artificial intelligence, but is not limited thereto. The speech image providing device <b>100</b> may generate a speech image (e.g., a speech image for a conversation or video call) based on artificial intelligence, and may display the generated speech image on a screen or transmit it to the outside (e.g., a terminal of the conversation partner or a relay server that relays the terminal of the conversation partner and the speech image providing device <b>100</b>).</p><p id="p-0036" num="0035">For example, the speech image providing device <b>100</b> may be installed in a user terminal that wants to have a conversation with artificial intelligence, and may be installed in various devices or facilities such as an unmanned ordering kiosk, an electronic information desk, an outdoor advertising screen, a robot, or the like.</p><p id="p-0037" num="0036">Here, the speech image is a synthesized image based on artificial intelligence, and is an image in which a predetermined person is speaking. Here, the predetermined person may be a fictional person or a person widely known to the public (e.g., entertainer, sports player, president, announcer, or the like), but is not limited thereto.</p><p id="p-0038" num="0037">The standby state image generating module <b>102</b> may generate an image in which a person in the image is in a standby state (hereinafter, may be referred to as a standby state image). Here, the standby state may be a state before the person in the image speaks (e.g., a state in which the person is listening to the other party or a state in which there is no speech before there is a conversation, or the like).</p><p id="p-0039" num="0038">The standby state image generating module <b>102</b> may generate a standby state image having a preset playback time (e.g., 5 seconds, 30 seconds, or the like). The standby state image may be provided to express a natural motion while the person in the image is in the standby state. That is, the standby state image may be provided to naturally represent the facial expression, posture, and action (e.g., nodding, holding hands and listening, tilting the head, and smiling) of the person in the image while the person is listening to the other party.</p><p id="p-0040" num="0039">The standby state image has a preset playback period and includes a plurality of frames. In addition, each frame of the standby state image may include a changed image in order to express a natural motion while the person in the image is in the standby state. In an exemplary embodiment, the standby state image may be provided to be returned from the last frame to the first frame again and repeatedly played, when being played from the first frame to the last frame.</p><p id="p-0041" num="0040">The standby state image generating module <b>102</b> may generate a back-motion image in addition to each frame of the standby state image. The back-motion image may be for image interpolation between an arbitrary frame of the standby state image and a preset reference frame of the standby state image. Hereinafter, it will be described that the reference frame is the first frame of the standby state image as an example. However, the reference frame is not limited thereto.</p><p id="p-0042" num="0041">The standby state image generating module <b>102</b> may generate the back-motion image so as to naturally connect an arbitrary frame of the standby state image with the first frame (that is, reference frame) of the standby state image when the standby state image is returned from the arbitrary frame to the first frame.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating a state in which a back-motion image is generated in an embodiment of the present disclosure. Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the standby state image generating module <b>102</b> may generate a back-motion image at every preset time interval (or frame interval) from the standby state image. Hereinafter, a point at which a back-motion image is generated in the standby state image may be referred to as a back-motion point. That is, the standby state image generating module <b>102</b> may generate a back-motion image such that a frame corresponding to each back-motion point of the standby state image and a reference frame of the standby state image are naturally connected.</p><p id="p-0044" num="0043">In this case, the standby state image generating module <b>102</b> may generate a plurality of back-motion images having different initial speech shapes of the person in the image for each back-motion point. Here, the initial speech shape means the shape of the mouth and the shape around the mouth when the person in the image tries to speak, and may vary depending on the content of the speech that the person in the image intends to speak.</p><p id="p-0045" num="0044">For example, the standby state image generating module <b>102</b> may generate, for each back-motion point, a back-motion image set IS including a first back-motion image #<b>1</b> in which the person in the image has a first initial speech shape, a second back-motion image #<b>2</b> in which the person in the image has a second initial speech shape, a third back-motion image #<b>3</b> in which the person in the image has a third initial speech shape, a fourth back-motion image #<b>4</b> in which the person in the image has a fourth initial speech shape, and a fifth back-motion image #<b>5</b> in which the person in the image has a fifth initial speech shape. Here, it has been described that there are five initial speech shapes as an example, but the number of initial speech shapes is not limited thereto and the initial speech shapes may be classified into various other numbers.</p><p id="p-0046" num="0045">The speech state image generating module <b>104</b> may generate an image in which a person in the image (a person having the same identity as the person in the standby state image) is in a speech state (hereinafter, referred to as a speech state image). Here, the speech state may refer to a state in which the person in the image is speaking (e.g., a state in which the person is speaking to the other party in a conversation, a video call, or the like).</p><p id="p-0047" num="0046">The speech state image generating module <b>104</b> may generate a speech state image based on the source of input speech content. The source of speech content may be in the form of text, but is not limited thereto, and may be in the form of a voice.</p><p id="p-0048" num="0047">The source of speech content may be generated through artificial intelligence by the speech image providing device <b>100</b> analyzing the speech of the other party, but is not limited thereto, and may be input from an external device (not shown) (e.g., a device that analyzes the speech of the other party and generates the source of speech content) or an administrator. Hereinafter, it will be described that the source of speech content is text as an example.</p><p id="p-0049" num="0048">The speech state image generating module <b>104</b> may generate an audio part and an image part for a speech state image based on text of speech content (e.g., &#x201c;Hello, I am AI tutor Danny&#x201d;), and generate the speech state image by combining the generated audio part and the image part. The text-based audio and video generation technology is a known technology, and therefore a detailed description thereof will be omitted.</p><p id="p-0050" num="0049">The image playback module <b>106</b> may play the standby state image generated by the standby state image module <b>102</b>. The image playback module <b>106</b> may play the standby state image and provide it to the conversation partner. In an exemplary embodiment, the image playback module <b>106</b> may play the standby state image and display it on a screen provided in the speech image providing device <b>100</b>. In this case, the conversation partner may have a conversation with the person in the image while looking at the screen of the speech image providing device <b>100</b>.</p><p id="p-0051" num="0050">In addition, the image playback module <b>106</b> may play the standby state image and transmit it to an external device (e.g., a terminal of the conversation partner or a relay server). In this case, the conversation partner may receive the image through his/her terminal (e.g., smartphone, tablet PC, laptop computer, desktop PC, or the like), or an unmanned ordering kiosk, an electronic information desk, an outdoor advertising screen, or the like to have a conversation with the person in the image.</p><p id="p-0052" num="0051">When the speech state image is generated while the standby state image is being played, the image playback module <b>106</b> may generate a synthetic speech image by combining the standby state image and the speech state image, and play the synthetic speech image. The image playback module <b>106</b> may provide the synthetic speech image to the conversation partner.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram schematically illustrating a state of combining a standby state image and a speech state image in an embodiment of the present disclosure. Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the image playback module <b>106</b> may generate a synthetic speech image by replacing the face portion of the standby state image with the image part (that is, the face portion of the person) of the speech state image and combining the replaced image and the voice part of the speech state image.</p><p id="p-0054" num="0053">In an exemplary embodiment, when the generation of the speech state image is completed during playback of the standby state image, the image playback module <b>106</b> may return the standby state image to the reference frame and generate the synthetic speech image in combination with frames of the speech state image from the preset reference frame of the standby state image. For example, the combination of the standby state image and the speech state image may be performed in a first frame of the standby state image.</p><p id="p-0055" num="0054">In this case, by standardizing a combining point of the standby state image and the speech state image as the reference frame of the standby state image, it is possible to combine the standby state image and the speech state image to easily generate the synthetic speech image, even without considering other factors (e.g., the network environment between the speech image providing device <b>100</b> and the terminal of the other party), no matter when the speech state image is generated during playback of the standby state image.</p><p id="p-0056" num="0055">In this case, the image playback module <b>106</b> may return the standby state image being played to the first frame (that is, the reference frame) in order to combine the first frame of the standby state image and the speech state image, and then may combine the first frame of the standby state image and the speech state image.</p><p id="p-0057" num="0056">That is, when a source of speech content is input while the image playback module <b>106</b> is playing the standby state image, the speech state image generating module <b>104</b> may generate the speech state image based on the source of the speech content. When the generation of the speech state image is completed, the image playback module <b>106</b> may return the standby state image to the first frame using, as interpolation images, the back-motion image set at the closest point of time (that is, back-motion point) to the point of time when the generation of the speech state image is completed. In this case, the image playback module <b>106</b> may extract a back-motion image having an initial speech shape corresponding to the source of speech content, from the back-motion image set.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram schematically illustrating a state in which the image playback module <b>106</b> returns a standby state image being played to the first frame in an embodiment of the present disclosure. Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, when the generation of the speech state image is completed in the j-th frame of the standby state image during playback of the standby state image, the image playback module <b>106</b> may detect the closest frame having a back-motion image set among frames after the j-th frame of the standby state image which is currently being played.</p><p id="p-0059" num="0058">For example, when the closest frame having a back-motion image set among frames after the j-th frame is the k-th frame, the image playback module <b>106</b> may extract a back-motion image set (e.g., the first back-motion image #<b>1</b> to the fifth back-motion image #<b>5</b>) of the k-th frame. The image playback module <b>106</b> may extract a back-motion image (e.g., a second back-motion image #<b>2</b>) having an initial speech shape corresponding to the source of speech content used to generate the speech state image, from the back-motion images set.</p><p id="p-0060" num="0059">The image playback module <b>106</b> may return the standby state image to the first frame using the extracted second back-motion image #<b>2</b> as an interpolation image. That is, the image playback module <b>106</b> may play the second back-motion image #<b>2</b> of the back-motion image set of the k-th frame to naturally return the standby state image to the first frame.</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram schematically illustrating a process until the image playback module plays a synthetic speech image in an embodiment of the present disclosure.</p><p id="p-0062" num="0061">Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, when the generation of the speech state image is completed while playing the standby state image ({circle around (1)}), the image playback module <b>106</b> may detect a frame (e.g., the k-th frame) having a back-motion image set closest to the point of time when the generation of the speech state image is completed. The image playback module <b>106</b> plays the second back-motion image #<b>2</b> having an initial speech shape corresponding to the source of speech content in the back-motion image set of the k-th frame ({circle around (2)}) to naturally connect the k-th frame of the standby state image and the first frame thereof.</p><p id="p-0063" num="0062">Next, the image playback module <b>106</b> may generate and play a synthetic speech image in combination with frames of the speech state image from the first frame of the standby state image ({circle around (3)}). The image playback module <b>106</b> may generate the synthetic speech image by replacing the face portion of the first frame of the standby state image with the image part of the speech state image. In this case, the second back-motion image having the initial speech shape corresponding to the source of speech content is played as the interpolation image, and then the synthetic speech image is played, and thus the shape of the speech of the person in the synthetic speech image is naturally expressed.</p><p id="p-0064" num="0063">According to the disclosed embodiments, the standby state image is prepared in advance, and the speech state image is generated during playback of the standby state image and combined with the standby state image, thereby making it possible to generate the synthetic speech image in real time, and accordingly, possible to provide conversation-related services based on artificial intelligence in real time.</p><p id="p-0065" num="0064">In addition, the synthetic speech image is generated by generating the image part for the face portion of the person in the standby state image when generating the speech state image, and replacing the face portion of the standby state image with the image part of the speech state image, thereby making is possible to reduce the amount of data while reducing the time required for generating the synthetic speech image.</p><p id="p-0066" num="0065">In addition, a back-motion image set is prepared at a preset interval in the standby state image, the current frame of the current standby state is connected to the first frame thereof by playing the back-motion image corresponding to the source of speech content in a back-motion image set, and the speech state image is combined with the first frame of the standby state image, thereby making it possible to easily generate a synthetic speech image without considering other variables no matter when the speech state image is generated during playback of the standby state image, and to naturally connect the speech shape of the person in the synthetic speech image.</p><p id="p-0067" num="0066">In the present specification, a module may mean a functional and structural combination of hardware for carrying out the technical idea of the present disclosure and software for driving the hardware. For example, the &#x201c;module&#x201d; may mean a logical unit of a predetermined code and a hardware resource for executing the predetermined code, and does not necessarily mean physically connected code or a single type of hardware.</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram illustrating a configuration of a speech image providing system according to an embodiment of the present disclosure.</p><p id="p-0069" num="0068">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a speech image providing system <b>200</b> may include a speech image providing device <b>201</b>, a server <b>203</b>, and a terminal <b>205</b> of the other party. The speech image providing device <b>201</b> may be communicatively connected to the server <b>203</b> and the terminal <b>205</b> of the other part through a communication network <b>250</b>.</p><p id="p-0070" num="0069">In some embodiments, the communication network <b>250</b> may include the Internet, one or more local area networks, wide area networks, cellular networks, mobile networks, other types of networks, or a combination of the above networks.</p><p id="p-0071" num="0070">The speech image providing device <b>201</b> may include a standby state image generating module <b>211</b> and an image playback module <b>213</b>. Here, the standby state image generating module <b>211</b> is the same as the standby state image generating module <b>102</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, and thus a detailed description thereof will be omitted.</p><p id="p-0072" num="0071">When a source of speech content is input, the image playback module <b>213</b> may transmit the source of speech content to the server <b>203</b>. The server <b>203</b> may generate a speech state image based on the source of speech content. That is, the server <b>203</b> may include a speech state image generating module <b>221</b>. In an exemplary embodiment, the server <b>203</b> may generate a speech state image (that is, an audio part and an image part) from the source of speech content based on machine learning technology. The server <b>203</b> may transmit the generated speech state image to the image playback module <b>213</b>.</p><p id="p-0073" num="0072">The image playback module <b>213</b> may play the standby state image and provide it to the terminal <b>205</b> of the other party. When a preset time amount of speech state image is received from the server <b>203</b> during playback of the standby state image, the image playback module <b>213</b> may generate a synthetic speech image by combining the received speech state image and the standby state image. The image playback module <b>213</b> may provide the synthetic speech image to the terminal <b>205</b> of the other party.</p><p id="p-0074" num="0073">When a next time amount of speech state image is not received from the server <b>203</b>, the image playback module <b>213</b> may wait until the next time amount of speech state image is received from the server <b>203</b> and then generate a synthetic speech image by combining the received speech state image and the standby state image.</p><p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram exemplarily illustrating a computing environment <b>10</b> that includes a computing device suitable for use in exemplary embodiments. In the illustrated embodiment, each component may have different functions and capabilities in addition to those described below, and additional components may be included in addition to those described below.</p><p id="p-0076" num="0075">The illustrated computing environment <b>10</b> includes a computing device <b>12</b>. In an embodiment, the computing device <b>12</b> may be the speech image providing device <b>100</b>.</p><p id="p-0077" num="0076">The computing device <b>12</b> includes at least one processor <b>14</b>, a computer-readable storage medium <b>16</b>, and a communication bus <b>18</b>. The processor <b>14</b> may cause the computing device <b>12</b> to operate according to the above-described exemplary embodiments. For example, the processor <b>14</b> may execute one or more programs stored in the computer-readable storage medium <b>16</b>. The one or more programs may include one or more computer-executable instructions, which may be configured to cause, when executed by the processor <b>14</b>, the computing device <b>12</b> to perform operations according to the exemplary embodiments.</p><p id="p-0078" num="0077">The computer-readable storage medium <b>16</b> is configured to store computer-executable instructions or program codes, program data, and/or other suitable forms of information. A program <b>20</b> stored in the computer-readable storage medium <b>16</b> includes a set of instructions executable by the processor <b>14</b>. In an embodiment, the computer-readable storage medium <b>16</b> may be a memory (a volatile memory such as a random-access memory, a non-volatile memory, or any suitable combination thereof), one or more magnetic disk storage devices, optical disc storage devices, flash memory devices, other types of storage media that are accessible by the computing device <b>12</b> and may store desired information, or any suitable combination thereof.</p><p id="p-0079" num="0078">The communication bus <b>18</b> interconnects various other components of the computing device <b>12</b>, including the processor <b>14</b> and the computer-readable storage medium <b>16</b>.</p><p id="p-0080" num="0079">The computing device <b>12</b> may also include one or more input/output interfaces <b>22</b> that provide an interface for one or more input/output devices <b>24</b>, and one or more network communication interfaces <b>26</b>. The input/output interface <b>22</b> and the network communication interface <b>26</b> are connected to the communication bus <b>18</b>. The input/output device <b>24</b> may be connected to other components of the computing device <b>12</b> via the input/output interface <b>22</b>. The exemplary input/output device <b>24</b> may include a pointing device (a mouse, a trackpad, or the like), a keyboard, a touch input device (a touch pad, a touch screen, or the like), a voice or sound input device, input devices such as various types of sensor devices and/or imaging devices, and/or output devices such as a display device, a printer, an interlocutor, and/or a network card. The exemplary input/output device <b>24</b> may be included inside the computing device <b>12</b> as a component constituting the computing device <b>12</b>, or may be connected to the computing device <b>12</b> as a separate device distinct from the computing device <b>12</b>.</p><p id="p-0081" num="0080">Although the representative embodiments of the present disclosure have been described in detail as above, those skilled in the art will understand that various modifications may be made thereto without departing from the scope of the present disclosure. Therefore, the scope of rights of the present disclosure should not be limited to the described embodiments, but should be defined not only by the claims set forth below but also by equivalents of the claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computing device comprising:<claim-text>one or more processors;</claim-text><claim-text>a memory storing one or more programs executed by the one or more processors;</claim-text><claim-text>a standby state image generating module configured to generate a standby state image in which a person is in a standby state, and generate a back-motion image set including a plurality of back-motion images at a preset frame interval from the standby state image for image interpolation between a preset reference frame of the standby state image;</claim-text><claim-text>a speech state image generating module configured to generate a speech state image in which a person is in a speech state based on a source of speech content; and</claim-text><claim-text>an image playback module configured to generate a synthetic speech image by combining the standby state image and the speech state image while playing the standby state image.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the back-motion image set comprises a plurality of back-motion images having different initial speech shapes of the person in the images.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computing device of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the image playback module is further configured to extract a back-motion image set based on a point of time when the generating of the speech state image is completed, return a standby state image being played to a preset reference frame based on the back-motion image set, and generate a synthetic speech image in combination with a frame of the speech state image from the reference frame.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computing device of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the image playback module is further configured to detect a closest frame having a back-motion image set among frames after a current frame of the standby state image being played, at the point of time when the generating of the speech state image is completed, and extract the back-motion image set of the detected frame.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computing device of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the image playback module is further configured to extract a back-motion image having an initial speech shape corresponding to a source of speech content from the back-motion image set, and return the standby state image to the reference frame using the extracted back-motion image as an interpolation image.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computing device of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the image playback module is further configured to play the standby state image again from an end point of time of the speech state image when the speech state image is ended during playback of the synthetic speech image.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the speech state image generating module is further configured to generate each of an audio part and an image part of the speech state image based on the source of speech content, the image part being generated for a face portion of a person in the standby state image.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The computing device of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the image playback module is further configured to replace the face portion of the standby state image with the image part of the speech state image, and generate the synthetic speech image by combining the standby state image where the face portion is replaced and the audio part of the speech state image.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A computing device comprising:<claim-text>one or more processors;</claim-text><claim-text>a memory storing one or more programs executed by the one or more processors;</claim-text><claim-text>a standby state image generating module configured to generate a standby state image in which a person is in a standby state, and generate a back-motion image set including a plurality of back-motion images at a preset frame interval from the standby state image for image interpolation between a preset reference frame of the standby state image; and</claim-text><claim-text>an image playback module configured to transmit a source of speech content to a server, receive a speech state image in which a person is in a speech state from the server, and generate a synthetic speech image by combining the standby state image and the speech state image while playing the standby state image.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A method for providing speech image, the method performed by a computing device including one or more processors and a memory storing one or more programs executed by the one or more processors, the method comprising:<claim-text>generating a standby state image in which a person is in a standby state;</claim-text><claim-text>generating a back-motion image set including a plurality of back-motion images at a preset frame interval from the standby state image for image interpolation between a preset reference frame of the standby state image;</claim-text><claim-text>generating a speech state image in which a person is in a speech state based on a source of speech content; and</claim-text><claim-text>generating a synthetic speech image by combining the standby state image and the speech state image while playing the standby state image.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A method for providing speech image, the method performed by a computing device including one or more processors and a memory storing one or more programs executed by the one or more processors, the method comprising:<claim-text>generating a standby state image in which a person is in a standby state;</claim-text><claim-text>generating a back-motion image set including a plurality of back-motion images at a preset frame interval from the standby state image for image interpolation between a preset reference frame of the standby state image;</claim-text><claim-text>transmitting a source of the speech content to a server;</claim-text><claim-text>receiving a speech state image in which a person is in a speech state from the server; and</claim-text><claim-text>generating a synthetic speech image by combining the standby state image and the speech state image while playing the standby state image.</claim-text></claim-text></claim></claims></us-patent-application>
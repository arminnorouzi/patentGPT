<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005490A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005490</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17931174</doc-number><date>20220912</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>CN</country><doc-number>202111069091.0</doc-number><date>20210913</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>10</class><subclass>L</subclass><main-group>19</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>10</class><subclass>L</subclass><main-group>21</main-group><subgroup>0316</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>L</subclass><main-group>19</main-group><subgroup>0017</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>L</subclass><main-group>21</main-group><subgroup>0316</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">PACKET LOSS RECOVERY METHOD FOR AUDIO DATA PACKET, ELECTRONIC DEVICE AND STORAGE MEDIUM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>APOLLO INTELLIGENT CONNECTIVITY (BEIJING) TECHNOLOGY CO., LTD.</orgname><address><city>Beijing</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Zhou</last-name><first-name>Wenhuan</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>APOLLO INTELLIGENT CONNECTIVITY (BEIJING) TECHNOLOGY CO., LTD.</orgname><role>03</role><address><city>Beijing</city><country>CN</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The disclosure provides a packet loss recovery method for an audio data packet an electronic device and a storage medium. The method includes: receiving an audio data packet sent by a vehicle-mounted terminal, and identifying a discarded first sampling point set in response to detecting packet loss; obtaining a second sampling point set and a third sampling point set each adjacent to the first sampling point set, in which the second sampling point set is prior to the first sampling point set, the third sampling point set is behind the first sampling point set; and generating target audio data of the first sampling points based on first audio data sampled at the second sampling points and second audio data sampled at the third sampling points, and inserting the target audio data at sampling positions of the first sampling points.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="76.03mm" wi="132.84mm" file="US20230005490A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="203.03mm" wi="143.85mm" file="US20230005490A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="218.52mm" wi="143.85mm" file="US20230005490A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="125.90mm" wi="145.88mm" file="US20230005490A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="165.35mm" wi="168.15mm" file="US20230005490A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="200.07mm" wi="131.32mm" file="US20230005490A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is based on and claims priority to Chinese patent applications Serial No. 202111069091.0 filed on September 13, 2021, the entire contents of which are incorporated herein by reference.</p><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The disclosure relates to a technical field of data processing, in particular to a technical field of artificial intelligence (AI) such as voice technology, Internet of Vehicles, intelligent cockpit, and intelligent transportation.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">In an interaction scenario where a vehicle and a mobile phone are interconnected, packet loss may occur in audio data, which will lead to a poor quality of an audio source and affect a recognition efficiency of a speech engine. However, an existing solution to the quality problem of the audio source will result in a larger amount of transmitted data, and will test the compatibility and performance of the vehicle. Therefore, how to better avoid packet loss in the audio data is urgent to be solved.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0005" num="0004">The embodiments of the disclosure provide a packet loss recovery method for an audio data packet, an electronic device, a storage medium and a computer program product.</p><p id="p-0006" num="0005">According to a first aspect of the disclosure, a packet loss recovery method for an audio data packet is provided. The method includes: receiving an audio data packet sent by a vehicle-mounted terminal, and identifying a discarded first sampling point set in response to detecting packet loss, in which the first sampling point set includes N first sampling points, and N is a positive integer; obtaining a second sampling point set and a third sampling point set each adjacent to the first sampling point set, in which the second sampling point set is prior to the first sampling point set, the third sampling point set is behind the first sampling point set, the second sampling point set includes at least N second sampling points, and the third sampling point set includes at least N third sampling points; and generating target audio data of the first sampling points based on first audio data sampled at the second sampling points and second audio data sampled at the third sampling points, and inserting the target audio data at sampling positions of the first sampling points.</p><p id="p-0007" num="0006">According to a second aspect of the disclosure, an electronic device is provided. The electronic device includes: at least one processor and a memory communicatively coupled to the at least one processor. The memory stores instructions executable by the at least one processor, and when the instructions are executed by the at least one processor, the packet loss recovery method for an audio data packet according to embodiments of the first aspect of the disclosure is implemented.</p><p id="p-0008" num="0007">According to a third aspect of the disclosure, a non-transitory computer-readable storage medium having computer instructions stored thereon is provided. The computer instructions are configured to cause a computer to implement the packet loss recovery method for an audio data packet according to embodiments of the first aspect of the disclosure.</p><p id="p-0009" num="0008">It should be understood that the content described in this section is not intended to identify key or important features of the embodiments of the disclosure, nor is it intended to limit the scope of the disclosure. Additional features of the disclosure will be easily understood based on the following description.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0009">The drawings are used to better understand the solution and do not constitute a limitation to the disclosure, in which:</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram of a sampling point set.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram of a packet loss recovery apparatus for an audio data packet according to an embodiment of the disclosure.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram of an electronic device used to implement the packet loss recovery method for an audio data packet according to an embodiment of the disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0021" num="0020">The following describes the exemplary embodiments of the disclosure with reference to the accompanying drawings, which includes various details of the embodiments of the disclosure to facilitate understanding, which shall be considered merely exemplary. Therefore, those of ordinary skill in the art should recognize that various changes and modifications can be made to the embodiments described herein without departing from the scope and spirit of the disclosure. For clarity and conciseness, descriptions of well-known functions and structures are omitted in the following description.</p><p id="p-0022" num="0021">In order to facilitate understanding of the disclosure, the technical fields involved in the disclosure are briefly explained in the following contents.</p><p id="p-0023" num="0022">Data processing refers to collection, storage, retrieval, processing, transformation and transmission of data. Data processing can extract and deduce valuable and meaningful data for some specific people from a large amount of disorganized and incomprehensible data.</p><p id="p-0024" num="0023">The key technologies of speech technology in the computer field include an automatic speech recognition technology and a speech synthesis technology. It is a future development direction of human-computer interaction that computers are enabled to hear, see, speak, and feel. Voice has become the most promising human-computer interaction method in the future, which is advantaged over other interaction methods.</p><p id="p-0025" num="0024">Intelligent transportation is a real-time, accurate and efficient comprehensive transportation management technology that covers a wide range and play a role in all directions. Intelligent transportation is established by effectively integrating advanced information technology, data communication transmission technology, electronic sensing technology, control technology and computer technology into the entire ground traffic management system.</p><p id="p-0026" num="0025">AI is the study of making computers to simulate certain thinking processes and intelligent behaviors of people (such as learning, reasoning, thinking and planning), which has both hardware-level technologies and software-level technologies. AI hardware technologies generally include technologies such as sensors, dedicated AI chips, cloud computing, distributed storage, and big data processing. AI software technologies mainly include computer vision technology, speech recognition technology, natural language processing (NLP) technology and machine learning, deep learning, big data processing technology, knowledge graph technology and other major directions.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure. As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the method includes the following steps.</p><p id="p-0028" num="0027">In S<b>101</b>, an audio data packet sent by a vehicle-mounted terminal is received, and a discarded first sampling point set is identified in response to detecting packet loss, in which the first sampling point set includes N first sampling points, and N is a positive integer.</p><p id="p-0029" num="0028">In the embodiment of the disclosure, a terminal device may receive an audio data packet sent by a vehicle-mounted terminal through a communication link between the terminal device and the vehicle-mounted terminal. The terminal device and the vehicle-mounted terminal can be connected through a hotspot (Wi-Fi, Bluetooth), IrDA, ZigBee or USB.</p><p id="p-0030" num="0029">The vehicle-mounted terminal is provided with an audio collection device, which may be, for example, a microphone (mic) or a pickup. The voice of a driver and passengers may be collected by the audio collection device.</p><p id="p-0031" num="0030">The terminal device may be a mobile phone, a Bluetooth headset, a tablet computer, or a smart watch.</p><p id="p-0032" num="0031">After receiving the audio data packet sent by the vehicle-mounted terminal, the terminal device needs to determine whether packet loss occurs in the audio data packet so as to determine a quality of the audio. In some implementations, since the audio data packet should be continuous in time sequence, it is possible to determine whether the packet loss occurs based on the time, and determine a discontinuous time as a packet loss time, so that a sampling point corresponding to the packet loss time is determined as a packet loss sampling point, which is also called the first sampling point. In other implementations, the vehicle-mounted terminal numbers each piece of data when collecting the audio data, and adjacent sequence numbers are continuous. In response to detecting that the sequence numbers are not continuous, it is determined that packet loss occurs in the audio data packet, then the sampling point corresponding to the missing sequence number is determined as the packet loss sampling point, which is called the first sampling point.</p><p id="p-0033" num="0032">In S<b>102</b>, a second sampling point set and a third sampling point set each adjacent to the first sampling point set are obtained, in which the second sampling point set is prior to the first sampling point set, the third sampling point set is behind the first sampling point set, the second sampling point set includes at least N second sampling points, and the third sampling point set includes at least N third sampling points.</p><p id="p-0034" num="0033">Based on a position where the packet loss occurs, the adjacent second sampling point set prior to the first sampling point set and the adjacent third sampling point set behind the first sampling point set are obtained.</p><p id="p-0035" num="0034">Taking <figref idref="DRAWINGS">FIG. <b>2</b></figref> as an example, when the discarded first sampling point set includes the sampling points corresponding to sampling time points t<sub>21 </sub>to t<sub>30</sub>, the first 10 sampling points corresponding to sampling time points t<sub>11 </sub>to t<sub>20 </sub>can be collected as the second sampling point set, and the last 10 sampling points corresponding to sampling time points t<sub>31 </sub>to t<sub>40 </sub>are determined as the third sampling point set.</p><p id="p-0036" num="0035">In order to ensure an accuracy of data recovery, a certain amount of audio data needs to be collected. In the disclosure, optionally, the number of the second sampling points in the second sampling point set, the number of the third sampling points in the third sampling point set, and the number of the first sampling points can be set as N. Optionally, more than N sampling points can be collected.</p><p id="p-0037" num="0036">In S<b>103</b>, target audio data of the first sampling points is generated based on first audio data sampled at the second sampling points and second audio data sampled at the third sampling points, and the target audio data is inserted at sampling positions of the first sampling points.</p><p id="p-0038" num="0037">According to the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points, the target audio amplitude values corresponding respectively to the first sampling points can be obtained. The target audio data corresponding to the first sampling points may be generated according to the target audio amplitude values corresponding respectively to the first sampling points. The target audio data is inserted into a sampling position of the first sampling points, so that there is corresponding audio data at each sampling time point, to make sure that the audio data packet is complete, and the packet loss recovery of the audio data packet is completed.</p><p id="p-0039" num="0038">In the embodiment of the disclosure, the audio data packet sent by the vehicle-mounted terminal is received, and the discarded first sampling point set is identified in response to detecting packet loss. The first sampling point set includes N first sampling points, and N is a positive integer. The adjacent second sampling point set prior to the first sampling point set and the adjacent third sampling point set behind the first sampling point set are obtained, in which the second sampling point set includes at least N second sampling points, and the third sampling point set includes at least N third sampling points. The target audio data of the first sampling points is generated based on the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points, and the target audio data is inserted at the sampling positions corresponding respectively to the first sampling points. In the embodiment of the disclosure, the lost N data packets are recovered based on the adjacent N data packets prior to and the adjacent N data packets behind the packet loss position, which solves the problem of packet loss in audio transmission data of the vehicle and improves a quality of an audio source.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure. On the basis of the above embodiments, in combination with <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the process of generating the target audio data of the first sampling points based on the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points is described as follows. The process includes the following steps.</p><p id="p-0041" num="0040">In S<b>301</b>, target audio amplitude values corresponding respectively to the first sampling points are obtained based on the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points.</p><p id="p-0042" num="0041">In some embodiments, a first fitted curve is obtained based on the first audio data sampled at the second sampling points, and a second fitted curve is obtained based on the second audio data sampled at the third sampling points. For each first sampling point, the target audio amplitude value corresponding to the first sampling point is obtained based on the first fitted curve and the second fitted curve.</p><p id="p-0043" num="0042">In some embodiments, a combination is obtained by combining one of the second sampling points in the second sampling point set with one of the third sampling points in the third sampling point set, then an average value of a second audio amplitude value of the second sampling point in the combination and a third audio amplitude value of the third sampling point in the combination is determined as the target audio amplitude value.</p><p id="p-0044" num="0043">Optionally, the audio amplitude value of any sampling point can be obtained. One second sampling point is selected from the second sampling points in the second sampling point set successively according to a time sequence from early to late, one third sampling point is selected from the third sampling points in the third sampling point set successively according to a time sequence from late to early, and the second and third sampling points selected at the same n-th time are combined to obtain a combination, i.e., the second sampling point selected at the first time and third sampling point selected at the first time are combined as a combination, the second sampling point selected at the second time and third sampling point selected at the second time are combined as a combination, the second sampling point selected at the third time and third sampling point selected at the third time are combined as a combination, and so on. An average value of the second audio amplitude value of the second sampling point in the combination and the third audio amplitude value of the third sampling point in the combination is determined as the target audio amplitude value.</p><p id="p-0045" num="0044">Optionally, the audio amplitude value of any sampling point can be obtained. One second sampling point is selected from the second sampling points in the second sampling point set successively according to a time sequence from late to early, one third sampling point is selected from the third sampling points in the third sampling point set successively according to a time sequence from late to early, and the second and third sampling points selected at the same n-th time are combined to obtain a combination. An average value of the second audio amplitude value of the second sampling point in the combination and the third audio amplitude value of the third sampling point in the combination is determined as the target audio amplitude value.</p><p id="p-0046" num="0045">Optionally, the audio amplitude value of any sampling point can be obtained. One second sampling point is selected from the second sampling points in the second sampling point set successively according to a time sequence from late to early, one third sampling point is selected from the third sampling points in the third sampling point set successively according to a time sequence from early to late, and the second and third sampling points selected at the same n-th time are combined to obtain a combination. An average value of the second audio amplitude value of the second sampling point in the combination and the third audio amplitude value of the third sampling point in the combination is determined as the target audio amplitude value.</p><p id="p-0047" num="0046">In S<b>302</b>, the target audio data of the first sampling points is generated based on the target audio amplitude values corresponding respectively to the first sampling points.</p><p id="p-0048" num="0047">The target audio amplitude value contains the volume and frequency information of the audio source, which can be used to recovery the target audio data. The acquired audio amplitude value is inserted into the corresponding first sampling point, to generate the target audio data.</p><p id="p-0049" num="0048">In the embodiment of the disclosure, the target audio amplitude values corresponding respectively to the first sampling points are obtained according to the first audio data sampled at the second sampling point and the second audio data sampled at the third sampling point. The target audio data of the first sampling points is generated based on the target audio amplitude values corresponding respectively to the first sampling points. In the embodiment of the disclosure, the target audio amplitude value is obtained according to the audio data collected prior to and behind the packet loss position, to further generate the target audio data. The process of generating the target audio data is refined and decomposed to obtain more accurate data results.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure. On the basis of the above embodiments, in combination with <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the process of obtaining the corresponding audio frequency amplitude value of each first sampling point according to the generated fitted curve is explained as follows. The process includes the following steps.</p><p id="p-0051" num="0050">In S<b>401</b>, a first fitted curve is obtained based on the first audio data sampled at the second sampling points.</p><p id="p-0052" num="0051">The x-axis represents sampling time points of the second sampling points and the y-axis represents audio amplitude values of the second sampling points. Each second sampling point can be regarded as a data point, and the function of the first fitted curve, i.e., &#x3c6;<sub>1</sub>=a<sub>0</sub>+a<sub>1</sub>x+ . . . +a<sub>k</sub>x<sup>k</sup>, can be obtained by the least square method to achieve the smallest deviation between the fitted curve and the real value. a<sub>0</sub>,a<sub>1</sub>, . . . a<sub>k </sub>represent k parameters to be determined. For example, the k parameters can be determined to ensure that for any x value, a deviation between a real amplitude value y corresponding to the x value and the &#x3c6; value obtained by the function is the smallest.</p><p id="p-0053" num="0052">The least square method (also known as the method of least square) is a mathematical optimization technique, it finds the best functional match for the data by minimizing a sum of squared errors. Unknown data can be easily obtained by using the least square method, and the sum of squared errors between the obtained data and the actual data can be minimized. The least square method can also be used for curve fitting. Some other optimization problems can also be expressed by the least square method in the form of minimizing energy or maximizing entropy.</p><p id="p-0054" num="0053">In S<b>402</b>, a second fitted curve is obtained based on the second audio data sampled at the third sampling points.</p><p id="p-0055" num="0054">For a specific implementation of obtaining the second fitted curve according to the second audio data, reference may be made to the relevant introduction of obtaining the first fitted curve according to the first audio data in S<b>401</b>, which will not be repeated here.</p><p id="p-0056" num="0055">The function of the second fitted curve is: &#x3c6;<sub>2</sub>=b<sub>0</sub>+b<sub>1</sub>x+ . . . +b<sub>k</sub>x<sup>k</sup>. b<sub>0</sub>,b<sub>p </sub>. . . b<sub>k </sub>represent k parameters to be determined.</p><p id="p-0057" num="0056">In S<b>403</b>, for each first sampling point, the target audio amplitude value corresponding to the first sampling point is obtained based on the first fitted curve and the second fitted curve.</p><p id="p-0058" num="0057">In the disclosure, the x value in the first fitted curve and the second fitted curve represents the sampling time point. The sampling time point of the first sampling point is obtained and input into the first fitted curve and the second fitted curve, to obtain a first fitted amplitude value &#x3c6;<sub>1 </sub>and a second fitted amplitude value &#x3c6;<sub>2 </sub>corresponding to the sampling time point. The target audio amplitude value can be determined according to the first fitted amplitude value and the second fitted amplitude value.</p><p id="p-0059" num="0058">In some embodiments, an average amplitude value of the first fitted amplitude value and the second fitted amplitude value is directly determined as the target audio amplitude value, that is, the target audio amplitude value</p><p id="p-0060" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <mi>V</mi>  <mo>=</mo>  <mrow>   <mfrac>    <mrow>     <msub>      <mi>&#x3c6;</mi>      <mn>1</mn>     </msub>     <mo>+</mo>     <msub>      <mi>&#x3c6;</mi>      <mn>2</mn>     </msub>    </mrow>    <mn>2</mn>   </mfrac>   <mo>.</mo>  </mrow> </mrow></math></maths></p><p id="p-0061" num="0059">In the embodiment of the disclosure, the first fitted curve is obtained according to the first audio data sampled at the second sampling points, the second fitted curve is obtained according to the second audio data sampled at the third sampling points. For each first sampling point, the target audio amplitude value corresponding to the first sampling point is obtained based on the first fitted curve and the second fitted curve. In the embodiment of the disclosure, fitted curves of the first audio data and the second audio data are generated. The target audio amplitude value is obtained based on the fitted curves, and the target audio amplitude value is obtained by a mathematical model, so that the obtained data is more accurate and real.</p><p id="p-0062" num="0060"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure. Based on the above embodiments, in order to make the generated amplitude value curve smoother, in other implementations, after obtaining the average amplitude value of the first fitted amplitude value and the second fitted amplitude value, a binomial fitting is performed on a total of <b>3</b>N time points corresponding to the generated amplitude value curve, the process includes the following steps.</p><p id="p-0063" num="0061">In S<b>501</b>, a sampling time point of the first sampling point is obtained, and the sampling time point is input into the first fitted curve and the second fitted curve, to obtain a first fitted amplitude value and a second fitted amplitude value.</p><p id="p-0064" num="0062">For a specific implementation of step S<b>501</b>, reference may be made to relevant introductions in various embodiments of the disclosure, and details are not repeated here.</p><p id="p-0065" num="0063">In S<b>502</b>, an average amplitude value of the first fitted amplitude value and the second fitted amplitude value is obtained, and fitted audio data of the first sampling points is generated based on the average amplitude value.</p><p id="p-0066" num="0064">Each first sampling time point (the sampling time point of each first sampling point) has its corresponding first fitted amplitude value and second fitted amplitude value, the average amplitude value is calculated based on these two fitted amplitude values, to obtain the fitted audio amplitude value of each first sampling point, and the fitted audio data of each first sampling point can be generated according to the fitted audio amplitude value.</p><p id="p-0067" num="0065">In S<b>503</b>, a third fitted curve is generated based on the first audio data, the fitted audio data and the second audio data.</p><p id="p-0068" num="0066">At this time, the generated fitted audio amplitude value curve is not smooth. In order to make the recovered audio data more real and noise-free, a binomial fitting is performed according to the adjacent <b>3</b>N time points of the first audio data, the fitted audio data and the second audio data, to generate the third fitted curve &#x3c6;<sub>3</sub>=c<sub>0</sub>+c<sub>1</sub>x+ . . . +c<sub>k</sub>x<sup>k</sup>. c<sub>0</sub>,c<sub>1</sub>, . . . c<sub>k </sub>represent k parameters to be determined.</p><p id="p-0069" num="0067">For the process of generating the third fitted curve, reference may be made to the process of generating the first fitted curve in S<b>401</b>, which will not be repeated here.</p><p id="p-0070" num="0068">In S<b>504</b>, the target audio amplitude value is obtained by inputting the sampling time point into the third fitted curve.</p><p id="p-0071" num="0069">In the disclosure, x is the sampling time point in the third fitted curve, the sampling time point of the first sampling point is obtained and input into the third fitted curve, to directly obtain the target audio amplitude value corresponding to the sampling time point.</p><p id="p-0072" num="0070">In the embodiment of the disclosure, the sampling time point of the first sampling point is obtained, and the sampling time point is input into the first fitted curve and the second fitted curve respectively, to obtain the first fitted amplitude value and the second fitted amplitude value. The average amplitude value of the first fitted amplitude value and the second fitted amplitude value is obtained. Based on the average amplitude value, the fitted audio data of the first sampling points is generated. The third fitted curve is generated based on the first audio data, the fitted audio data and the second audio data. The target audio amplitude value is obtained by inputting the sampling time point into the third fitted curve. In the embodiment of the disclosure, after the fitted audio data is obtained based on the first audio data and the second audio data, the data of the 3N time points are re-fitted, to further obtain a smoother target audio amplitude value curve, so that the recovered audio data is more realistic and noise-free.</p><p id="p-0073" num="0071"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure. On the basis of the above embodiments, after inserting the target audio data at the sampling position of the first sampling point, as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the method further includes the following steps.</p><p id="p-0074" num="0072">In S<b>601</b>, semantic analysis is performed on a recovered audio data packet, and audio data collection is performed by turning on an audio collection device of a terminal device in response to the recovered audio data packet not meeting a semantic analysis requirement.</p><p id="p-0075" num="0073">The recovered audio data packet is sent to a speech engine for identification, and it is determined whether the recovered recorded data of the vehicle-mounted terminal meets requirements of the speech engine. If the speech engine cannot recognize the speech data in the audio data packet, it proves that the noise of the audio data packet is still too large and does not meet the semantic analysis requirement.</p><p id="p-0076" num="0074">In this case, the audio collection device of the terminal device is turned on to collect the audio data. Optionally, the audio collection device may be a microphone or a pickup on the terminal device.</p><p id="p-0077" num="0075">Optionally, the vehicle-mounted terminal can issue a voice prompt or a text prompt to the user to remind the user that the audio collection device has been changed due to a poor quality of the audio source, and a repeated voice command is required.</p><p id="p-0078" num="0076">In S<b>602</b>, an instruction of exiting an audio collection thread is sent to the vehicle-mounted terminal.</p><p id="p-0079" num="0077">Based on a connection mode, the mobile terminal sends the instruction of exiting the audio collection thread to the vehicle-mounted terminal, and the vehicle-mounted terminal closes the audio collection device after receiving the instruction.</p><p id="p-0080" num="0078">In the embodiment of the disclosure, semantic analysis is performed on the recovered audio data packet, audio data collection is carried out by turning on the audio collection device of the terminal device in response to the recovered audio data packet not meeting the semantic analysis requirement. The instruction of exiting the audio collection thread is sent to the vehicle-mounted terminal. In the embodiment of the disclosure, when the audio data packet obtained by the packet loss recovery still cannot meet the requirements of the speech engine, then the audio collection device is changed for audio collection, which can solve the problem of poor contact of the vehicle microphone or too much noise which seriously affects a quality of the recorded audio.</p><p id="p-0081" num="0079">In the above embodiments, the packet loss recovery strategy when the vehicle-mounted terminal sends the audio data packet to the terminal device is introduced, if the audio collection device of the vehicle-mounted terminal is occupied, then the audio data cannot be collected and sent to the terminal device, the audio collection device need to be changed. Before changing the audio collection device, it is determined whether the audio collection device of the vehicle-mounted terminal is occupied. <figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure. As illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the method includes the following steps.</p><p id="p-0082" num="0080">In S<b>701</b>, an audio amplitude value of the audio data packet initially sent by the vehicle-mounted terminal is obtained.</p><p id="p-0083" num="0081">After the vehicle-mounted terminal is connected to the terminal device, the microphone of the vehicle-mounted terminal is activated first to start recording. After the recording is completed, the vehicle-mounted terminal sends the audio data packet to the terminal device, and the terminal device obtains the audio amplitude value of the audio data packet.</p><p id="p-0084" num="0082">In S<b>702</b>, an occupancy state of an audio collection device of the vehicle-mounted terminal is identified according to the audio amplitude value.</p><p id="p-0085" num="0083">It is determined whether an audio value obtained by a receiver is greater than a given threshold. If the value is greater than or equal to the threshold, it indicates that the recorded data is normal and the audio collection device of the vehicle is not occupied. If the value is less than the threshold, it indicates that there is a problem with the recorded data of the vehicle and the audio collection device is in an occupied state.</p><p id="p-0086" num="0084">Under normal circumstances, the threshold is a minimum audio amplitude value when the audio collection device of the vehicle is not occupied. The threshold can be obtained through extensive experimental training.</p><p id="p-0087" num="0085">In response to the audio collection device not being in the occupied state, S<b>703</b> is executed. In response to the audio collection device being in the occupied state, S<b>704</b> is executed.</p><p id="p-0088" num="0086">In S<b>703</b>, the audio data packet sent by the vehicle-mounted terminal is continuously received.</p><p id="p-0089" num="0087">The mobile terminal continues to receive the audio data packet sent by the vehicle-mounted terminal.</p><p id="p-0090" num="0088">In S<b>704</b>, audio data collection is performed by turning on an audio collection device of the terminal device.</p><p id="p-0091" num="0089">The audio collection device of the terminal device itself is turned on to collect the audio data. Optionally, the audio collection device may be a mobile phone or a Bluetooth headset or other electronic device.</p><p id="p-0092" num="0090">Optionally, the vehicle can issue a voice prompt or a text prompt to the user, to remind the user that since the audio collection device of the vehicle-mounted terminal has been occupied, it has been replaced with the audio collection device of the mobile terminal, and a repeated voice command is required.</p><p id="p-0093" num="0091">In S<b>705</b>, an instruction of exiting an audio collection thread is sent to the vehicle-mounted terminal.</p><p id="p-0094" num="0092">For a specific implementation of step S<b>705</b>, reference may be made to relevant introductions in various embodiments of the disclosure, and details are not repeated here.</p><p id="p-0095" num="0093">In the embodiment of the disclosure, the audio amplitude value of the audio data packet initially sent by the vehicle-mounted terminal is received. The occupancy state of the audio collection device of the vehicle-mounted terminal is identified according to the audio amplitude value. The audio data packet sent is received continuously by the vehicle-mounted terminal in response to the audio collection device being not in the occupied state. The audio data collection is performed by turning on the audio collection device of the terminal device in response to the audio collection device of the vehicle-mounted terminal being in the occupied state. The instruction of exiting the audio collection thread is sent to the vehicle-mounted terminal. In the embodiment of the disclosure, it is determined whether the audio collection device of the vehicle terminal is in the occupied state, and when it is in the occupied state, it is replaced by the audio collection device of the mobile device for audio collection, which solves the problem that a voice function cannot be used when the vehicle microphone is occupied or unavailable.</p><p id="p-0096" num="0094"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart of a packet loss recovery method for an audio data packet according to an embodiment of the disclosure. As illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, Based on the packet loss recovery method for an audio data packet according to the disclosure, the packet loss recovery method for the audio data packet includes the following steps under a practical application scenario.</p><p id="p-0097" num="0095">In S<b>801</b>, a terminal device is connected with a vehicle-mounted terminal.</p><p id="p-0098" num="0096">In S<b>802</b>, after the connection is established, an audio collection device of the vehicle-mounted terminal starts to record.</p><p id="p-0099" num="0097">In S<b>803</b>, the terminal device determines whether a microphone of the vehicle-mounted terminal is occupied, if it is not occupied, S<b>804</b> is executed, otherwise S<b>807</b> is executed.</p><p id="p-0100" num="0098">In S<b>804</b>, the terminal device determines whether a packet loss occurs in an audio data packet.</p><p id="p-0101" num="0099">The terminal device identifies adjacent two pieces of audio data from the audio data packet, and a first sampling time point and a second sampling time point corresponding respectively to the two pieces of audio data. Since the audio packet should be continuous in time, it is possible to determine whether the packet loss occurs based on time. When the first sampling time point and the second sampling time point is not continuous, it indicates that the packet loss occurs in the audio data packet. A discarded sampling time point between the first sampling time point and the second sampling time point is obtained, where one discarded sampling time point corresponds to one first sampling point, and the first sampling point set includes N first sampling points, where N is a positive integer.</p><p id="p-0102" num="0100">If the packet loss occurs, S<b>805</b> is executed.</p><p id="p-0103" num="0101">In S<b>805</b>, the terminal device recovers audio data based on an audio packet loss recovery strategy.</p><p id="p-0104" num="0102">The audio packet loss recovery strategy is a strategy of recovering the target audio data according to the first audio data and the second audio data described in the above embodiments.</p><p id="p-0105" num="0103">In S<b>806</b>, the terminal device determines whether the recovered recorded data of the vehicle terminal meets requirements of a speech engine.</p><p id="p-0106" num="0104">If the requirements are not met, S<b>807</b> is executed. If the requirements are met, S<b>808</b> is executed.</p><p id="p-0107" num="0105">In S<b>807</b>, an audio collection device of the terminal device is used to record.</p><p id="p-0108" num="0106">In S<b>808</b>, a recorded audio data stream is provided to the speech engine.</p><p id="p-0109" num="0107">In the embodiment of the disclosure, the mobile device is connected to the vehicle-mounted terminal. After the connection is established, the audio collection device of the vehicle-mounted terminal is started to record audio by default. When the audio collection device of the vehicle-mounted terminal is occupied, the audio collection device of the terminal device is automatically selected for audio recording. When the audio collection device of the vehicle-mounted terminal is not occupied and the packet loss occurs in the audio data, the audio packet loss recovery strategy is used to recover the audio data. If the recovered recorded data still cannot meet the requirements of the speech engine, it is required to use the audio collection device of the terminal device to record audio, and finally the recorded audio data that meets the requirements is provided to the speech engine. In the embodiment of the disclosure, the audio data is recovered based on the audio packet loss recovery strategy, and an appropriate audio collection device can be automatically selected by determining the audio data, which effectively solves the problem of packet loss of the audio transmission data of the vehicle, the problem that audio recording quality is affected seriously due to poor contact of the audio collection device of the vehicle-mounted terminal or too much noise, and the problem that the voice function is unavailable when the audio collection device of the vehicle-mounted terminal is occupied or unavailability, thereby greatly improving the user experience.</p><p id="p-0110" num="0108"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a structure diagram of a packet loss recovery apparatus for an audio data packet according to an embodiment of the disclosure. As illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the packet loss recovery apparatus <b>900</b> for an audio data packet includes: a detecting module <b>910</b>, an obtaining module <b>920</b> and a generating module <b>930</b>.</p><p id="p-0111" num="0109">The detecting module <b>910</b> is configured to receive an audio data packet sent by a vehicle-mounted terminal, and identify a discarded first sampling point set in response to detecting packet loss. The first sampling point set includes N first sampling points, and N is a positive integer.</p><p id="p-0112" num="0110">The obtaining module <b>920</b> is configured to obtain a second sampling point set and a third sampling point set each adjacent to the first sampling point set. The second sampling point set is prior to the first sampling point set, the third sampling point set is behind the first sampling point set. The second sampling point set includes at least N second sampling points, and the third sampling point set includes at least N third sampling points.</p><p id="p-0113" num="0111">The generating module <b>930</b> is configured to generate target audio data of the first sampling point based on first audio data sampled at the second sampling points and second audio data sampled at the third sampling points, and insert the target audio data at sampling positions of the first sampling points.</p><p id="p-0114" num="0112">In the embodiment of the disclosure, the lost N data packets are recovered based on the adjacent N data packets prior to and adjacent N data packets behind the packet loss position, which solves the problem of packet loss of audio transmission data of the vehicle and improves a quality of the audio source.</p><p id="p-0115" num="0113">It should be noted that the foregoing explanations of the embodiment of the packet loss recovery method for an audio data packet are also applicable to the packet loss recovery apparatus for an audio data packet in this embodiment, which will not be repeated here.</p><p id="p-0116" num="0114">In a possible implementation of the embodiments of the disclosure, the generating module <b>903</b> is further configured to: obtain target audio amplitude values corresponding respectively to the first sampling points based on the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points; and generate the target audio data of the first sampling points based on the target audio amplitude values corresponding respectively to the first sampling points.</p><p id="p-0117" num="0115">In a possible implementation of the embodiments of the disclosure, the generating module <b>930</b> is further configured to: obtain a first fitted curve based on the first audio data sampled at the second sampling points; obtain a second fitted curve based on the second audio data sampled at the third sampling points; and for each first sampling point, obtain the target audio amplitude value corresponding to the first sampling point based on the first fitted curve and the second fitted curve.</p><p id="p-0118" num="0116">In a possible implementation of the embodiments of the disclosure, the generating module <b>930</b> is further configured to: obtain a sampling time point of the first sampling point, and input the sampling time point into the first fitted curve and the second fitted curve respectively, to obtain a first fitted amplitude value and a second fitted amplitude value; and determine the target audio amplitude value corresponding to the first sampling point based on the first fitted amplitude value and the second fitted amplitude value.</p><p id="p-0119" num="0117">In a possible implementation of the embodiments of the disclosure, the generating module <b>930</b> is further configured to: determine an average amplitude value of the first fitted amplitude value and the second fitted amplitude value as the target audio amplitude value.</p><p id="p-0120" num="0118">In a possible implementation of the embodiments of the disclosure, the generating module <b>930</b> is further configured to: obtain an average amplitude value of the first fitted amplitude value and the second fitted amplitude value, and generate fitted audio data of the first sampling points based on the average amplitude value; generate a third fitted curve based on the first audio data, the fitted audio data and the second audio data; and obtain the target audio amplitude value by inputting the sampling time point into the third fitted curve.</p><p id="p-0121" num="0119">In a possible implementation of the embodiments of the disclosure, the generating module <b>930</b> is further configured to: for any sampling point in the second sampling point set or the third sampling point set, obtain an audio amplitude value of the sampling point; obtain a combination by combining one second sampling point in the second sampling point set with one third sampling point in the third sampling point set; and determine an average value of a second audio amplitude value of the second sampling point in the combination and a third audio amplitude value of the third sampling point in the combination as the target audio amplitude value.</p><p id="p-0122" num="0120">In a possible implementation of the embodiments of the disclosure, the detecting module <b>910</b> is further configured to: identify adjacent two pieces of audio data from the audio data packet, and a first sampling time point and a second sampling time point corresponding respectively to the two pieces of audio data; and obtain a discarded sampling time point between the first sampling time point and the second sampling time point in response to the first sampling time point and the second sampling time point being discontinuous, in which each first sampling point corresponds to one discarded sampling time point.</p><p id="p-0123" num="0121">In a possible implementation of the embodiments of the disclosure, the packet loss recovery apparatus <b>900</b> for an audio data packet further includes: a semantic analysis module <b>940</b>. The semantic analysis module <b>940</b> is configured to: perform semantic analysis on a recovered audio data packet, and perform audio data collection by turning on an audio collection device of a terminal device in response to the recovered audio data packet not meeting a semantic analysis requirement; and send an instruction of exiting an audio collection thread to the vehicle-mounted terminal.</p><p id="p-0124" num="0122">In a possible implementation of the embodiments of the disclosure, the packet loss recovery apparatus <b>900</b> for an audio data packet further includes: a device selecting module <b>950</b>. The device selecting module <b>950</b> is configured to: obtain an audio amplitude value of the audio data packet initially sent by the vehicle-mounted terminal; identify an occupancy state of an audio collection device of the vehicle-mounted terminal according to the audio amplitude value; and continuously receive the audio data packet sent by the vehicle-mounted terminal in response to the audio collection device being not in an occupied state.</p><p id="p-0125" num="0123">In a possible implementation of the embodiments of the disclosure, the device selecting module <b>950</b> is further configured to: perform audio data collection by turning on an audio collection device of a terminal device in response to the audio collection device of the vehicle-mounted terminal being in the occupied state; and send an instruction of exiting an audio collection thread to the vehicle-mounted terminal.</p><p id="p-0126" num="0124">In the technical solution of the disclosure, the acquisition, storage and application of the user's personal information involved are all in compliance with the provisions of relevant laws and regulations, and do not violate public order and good customs.</p><p id="p-0127" num="0125">According to the embodiments of the disclosure, the disclosure also provides an electronic device, a readable storage medium and a computer program product.</p><p id="p-0128" num="0126"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram of an example electronic device <b>1000</b> used to implement the embodiments of the disclosure. Electronic devices are intended to represent various forms of digital computers, such as laptop computers, desktop computers, workbenches, personal digital assistants, servers, blade servers, mainframe computers, and other suitable computers. Electronic devices may also represent various forms of mobile devices, such as personal digital processing, cellular phones, smart phones, wearable devices, and other similar computing devices. The components shown here, their connections and relations, and their functions are merely examples, and are not intended to limit the implementation of the disclosure described and/or required herein.</p><p id="p-0129" num="0127">As illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the device <b>1000</b> includes a computing unit <b>1001</b> performing various appropriate actions and processes based on computer programs stored in a read-only memory (ROM) <b>1002</b> or computer programs loaded from the storage unit <b>1008</b> to a random access memory (RAM) <b>1003</b>. In the RAM <b>1003</b>, various programs and data required for the operation of the device <b>1000</b> are stored. The computing unit <b>1001</b>, the ROM <b>1002</b>, and the RAM <b>1003</b> are connected to each other through a bus <b>1004</b>. An input/output (I/O) interface <b>1005</b> is also connected to the bus <b>1004</b>.</p><p id="p-0130" num="0128">Components in the device <b>1000</b> are connected to the I/O interface <b>1005</b>, including: an inputting unit <b>1006</b>, such as a keyboard, a mouse; an outputting unit <b>1007</b>, such as various types of displays, speakers; a storage unit <b>1008</b>, such as a disk, an optical disk; and a communication unit <b>1009</b>, such as network cards, modems, and wireless communication transceivers. The communication unit <b>1009</b> allows the device <b>1000</b> to exchange information/data with other devices through a computer network such as the Internet and/or various telecommunication networks.</p><p id="p-0131" num="0129">The computing unit <b>1001</b> may be various general-purpose and/or dedicated processing components with processing and computing capabilities. Some examples of computing unit <b>1001</b> include, but are not limited to, a central processing unit (CPU), a graphics processing unit (GPU), various dedicated AI computing chips, various computing units that run machine learning model algorithms, and a digital signal processor (DSP), and any appropriate processor, controller and microcontroller. The computing unit <b>1001</b> executes the various methods and processes described above, such as the packet loss recovery method for an audio data packet. For example, in some embodiments, the method may be implemented as a computer software program, which is tangibly contained in a machine-readable medium, such as the storage unit <b>1008</b>. In some embodiments, part or all of the computer program may be loaded and/or installed on the device <b>1000</b> via the ROM <b>1002</b> and/or the communication unit <b>1009</b>. When the computer program is loaded on the RAM <b>1003</b> and executed by the computing unit <b>1001</b>, one or more steps of the method described above may be executed. Alternatively, in other embodiments, the computing unit <b>1001</b> may be configured to perform the method in any other suitable manner (for example, by means of firmware).</p><p id="p-0132" num="0130">Various implementations of the systems and techniques described above may be implemented by a digital electronic circuit system, an integrated circuit system, Field Programmable Gate Arrays (FPGAs), Application Specific Integrated Circuits (ASICs), Application Specific Standard Products (ASSPs), System on Chip (SOCs), Load programmable logic devices (CPLDs), computer hardware, firmware, software, and/or a combination thereof. These various embodiments may be implemented in one or more computer programs, the one or more computer programs may be executed and/or interpreted on a programmable system including at least one programmable processor, which may be a dedicated or general programmable processor for receiving data and instructions from the storage system, at least one input device and at least one output device, and transmitting the data and instructions to the storage system, the at least one input device and the at least one output device.</p><p id="p-0133" num="0131">The program code configured to implement the method of the disclosure may be written in any combination of one or more programming languages. These program codes may be provided to the processors or controllers of general-purpose computers, dedicated computers, or other programmable data processing devices, so that the program codes, when executed by the processors or controllers, enable the functions/operations specified in the flowchart and/or block diagram to be implemented. The program code may be executed entirely on the machine, partly executed on the machine, partly executed on the machine and partly executed on the remote machine as an independent software package, or entirely executed on the remote machine or server.</p><p id="p-0134" num="0132">In the context of the disclosure, a machine-readable medium may be a tangible medium that may contain or store a program for use by or in connection with an instruction execution system, apparatus, or device. The machine-readable medium may be a machine-readable signal medium or a machine-readable storage medium. A machine-readable medium may include, but is not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, or device, or any suitable combination of the foregoing. More specific examples of machine-readable storage media include electrical connections based on one or more wires, portable computer disks, hard disks, random access memories (RAM), read-only memories (ROM), electrically programmable read-only-memory (EPROM), flash memory, fiber optics, compact disc read-only memories (CD-ROM), optical storage devices, magnetic storage devices, or any suitable combination of the foregoing.</p><p id="p-0135" num="0133">In order to provide interaction with a user, the systems and techniques described herein may be implemented on a computer having a display device (e.g., a Cathode Ray Tube (CRT) or a Liquid Crystal Display (LCD) monitor for displaying information to a user); and a keyboard and pointing device (such as a mouse or trackball) through which the user can provide input to the computer. Other kinds of devices may also be used to provide interaction with the user. For example, the feedback provided to the user may be any form of sensory feedback (e.g., visual feedback, auditory feedback, or haptic feedback), and the input from the user may be received in any form (including acoustic input, voice input, or tactile input).</p><p id="p-0136" num="0134">The systems and technologies described herein can be implemented in a computing system that includes background components (for example, a data server), or a computing system that includes middleware components (for example, an application server), or a computing system that includes front-end components (for example, a user computer with a graphical user interface or a web browser, through which the user can interact with the implementation of the systems and technologies described herein), or include such background components, intermediate computing components, or any combination of front-end components. The components of the system may be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include: local area network (LAN), wide area network (WAN), and the Internet.</p><p id="p-0137" num="0135">The computer system may include a client and a server. The client and server are generally remote from each other and interacting through a communication network. The client-server relation is generated by computer programs running on the respective computers and having a client-server relation with each other. The server may be a cloud server, a server of a distributed system, or a server combined with a block-chain.</p><p id="p-0138" num="0136">It should be understood that the various forms of processes shown above can be used to reorder, add or delete steps. For example, the steps described in the disclosure could be performed in parallel, sequentially, or in a different order, as long as the desired result of the technical solution disclosed in the disclosure is achieved, which is not limited herein.</p><p id="p-0139" num="0137">The above specific embodiments do not constitute a limitation on the protection scope of the disclosure. Those skilled in the art should understand that various modifications, combinations, sub-combinations and substitutions can be made according to design requirements and other factors. Any modification, equivalent replacement and improvement made within the spirit and principle of the disclosure shall be included in the protection scope of the disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230005490A1-20230105-M00001.NB"><img id="EMI-M00001" he="4.91mm" wi="76.20mm" file="US20230005490A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A packet loss recovery method for an audio data packet, comprising:<claim-text>receiving, by a terminal device, an audio data packet sent by a vehicle-mounted terminal, and identifying, by the terminal device, a discarded first sampling point set in response to detecting packet loss, wherein the first sampling point set comprises N first sampling points, and N is a positive integer;</claim-text><claim-text>obtaining, by the terminal device, a second sampling point set and a third sampling point set each adjacent to the first sampling point set, wherein the second sampling point set is prior to the first sampling point set, the third sampling point set is behind the first sampling point set, the second sampling point set comprises at least N second sampling points, and the third sampling point set comprises at least N third sampling points;</claim-text><claim-text>generating, by the terminal device, target audio data of the first sampling points based on first audio data sampled at the second sampling points and second audio data sampled at the third sampling points; and</claim-text><claim-text>inserting, by the terminal device, the target audio data at sampling positions of the first sampling points to obtain a recovered audio data packet.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the target audio data of the first sampling points based on the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points, comprises:<claim-text>obtaining target audio amplitude values corresponding respectively to the first sampling points based on the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points; and</claim-text><claim-text>generating the target audio data of the first sampling points based on the target audio amplitude values corresponding respectively to the first sampling points.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein obtaining the target audio amplitude values corresponding respectively to the first sampling points based on the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points, comprises:<claim-text>obtaining a first fitted curve based on the first audio data sampled at the second sampling points;</claim-text><claim-text>obtaining a second fitted curve based on the second audio data sampled at the third sampling points; and</claim-text><claim-text>for each first sampling point, obtaining the target audio amplitude value corresponding to the first sampling point based on the first fitted curve and the second fitted curve.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein for each first sampling point, obtaining the target audio amplitude value corresponding to the first sampling point based on the first fitted curve and the second fitted curve, comprises:<claim-text>obtaining a sampling time point of the first sampling point;</claim-text><claim-text>inputting the sampling time point into the first fitted curve and the second fitted curve respectively, to obtain a first fitted amplitude value and a second fitted amplitude value; and</claim-text><claim-text>determining the target audio amplitude value corresponding to the first sampling point based on the first fitted amplitude value and the second fitted amplitude value.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein determining the target audio amplitude value corresponding to the first sampling point based on the first fitted amplitude value and the second fitted amplitude value, comprises:<claim-text>determining an average amplitude value of the first fitted amplitude value and the second fitted amplitude value as the target audio amplitude value.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein determining the target audio amplitude value corresponding to the first sampling point based on the first fitted amplitude value and the second fitted amplitude value comprises:<claim-text>obtaining an average amplitude value of the first fitted amplitude value and the second fitted amplitude value;</claim-text><claim-text>generating fitted audio data of the first sampling points based on the average amplitude value;</claim-text><claim-text>generating a third fitted curve based on the first audio data, the fitted audio data and the second audio data; and</claim-text><claim-text>obtaining the target audio amplitude value by inputting the sampling time point into the third fitted curve.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein obtaining the target audio amplitude values corresponding respectively to the first sampling point based on the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points, comprises:<claim-text>for any sampling point in the second sampling point set or the third sampling point set, obtaining an audio amplitude value of the sampling point;</claim-text><claim-text>obtaining a combination by combining one second sampling point in the second sampling point set with one third sampling point in the third sampling point set; and</claim-text><claim-text>determining an average value of a second audio amplitude value of the second sampling point in the combination and a third audio amplitude value of the third sampling point in the combination as the target audio amplitude value.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein identifying the discarded first sampling point set comprises:<claim-text>identifying adjacent two pieces of audio data from the audio data packet, and a first sampling time point and a second sampling time point corresponding respectively to the two pieces of audio data,; and</claim-text><claim-text>obtaining a discarded sampling time point between the first sampling time point and the second sampling time point in response to the first sampling time point and the second sampling time point being discontinuous, wherein each first sampling point corresponds to one discarded sampling time point.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein after inserting the target audio data at sampling positions of the first sampling points, the method further comprises:<claim-text>performing semantic analysis on the recovered audio data packet;</claim-text><claim-text>performing audio data collection by turning on an audio collection device of the terminal device in response to the recovered audio data packet not meeting a semantic analysis requirement; and</claim-text><claim-text>sending an instruction of exiting an audio collection thread to the vehicle-mounted terminal.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>obtaining an audio amplitude value of the audio data packet initially sent by the vehicle-mounted terminal;</claim-text><claim-text>identifying an occupancy state of an audio collection device of the vehicle-mounted terminal according to the audio amplitude value; and</claim-text><claim-text>continuously receiving the audio data packet sent by the vehicle-mounted terminal in response to the audio collection device being not in an occupied state.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising:<claim-text>performing audio data collection by turning on an audio collection device of the terminal device in response to the audio collection device of the vehicle-mounted terminal being in the occupied state; and</claim-text><claim-text>sending an instruction of exiting an audio collection thread to the vehicle-mounted terminal.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. An electronic device, comprising:<claim-text>at least one processor; and</claim-text><claim-text>a memory communicatively coupled to the at least one processor; wherein,</claim-text><claim-text>the memory stores instructions executable by the at least one processor, when the instructions are executed by the at least one processor, the at least one processor is enabled to performing the following:</claim-text><claim-text>receiving an audio data packet sent by a vehicle-mounted terminal, and identifying a discarded first sampling point set in response to detecting packet loss, wherein the first sampling point set comprises N first sampling points, and N is a positive integer;</claim-text><claim-text>obtaining a second sampling point set and a third sampling point set each adjacent to the first sampling point set, wherein the second sampling point set is prior to the first sampling point set, the third sampling point set is behind the first sampling point set, the second sampling point set comprises at least N second sampling points, and the third sampling point set comprises at least N third sampling points;</claim-text><claim-text>generating target audio data of the first sampling points based on first audio data sampled at the second sampling points and second audio data sampled at the third sampling points; and</claim-text><claim-text>inserting the target audio data at sampling positions of the first sampling points to obtain a recovered audio data packet.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein generating the target audio data of the first sampling points based on the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points, comprises:<claim-text>obtaining target audio amplitude values corresponding respectively to the first sampling points based on the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points; and</claim-text><claim-text>generating the target audio data of the first sampling points based on the target audio amplitude values corresponding respectively to the first sampling points.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein obtaining the target audio amplitude values corresponding respectively to the first sampling points based on the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points, comprises:<claim-text>obtaining a first fitted curve based on the first audio data sampled at the second sampling points;</claim-text><claim-text>obtaining a second fitted curve based on the second audio data sampled at the third sampling points; and</claim-text><claim-text>for each first sampling point, obtaining the target audio amplitude value corresponding to the first sampling point based on the first fitted curve and the second fitted curve.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein for each first sampling point, obtaining the target audio amplitude value corresponding to the first sampling point based on the first fitted curve and the second fitted curve, comprises:<claim-text>obtaining a sampling time point of the first sampling point;</claim-text><claim-text>inputting the sampling time point into the first fitted curve and the second fitted curve respectively, to obtain a first fitted amplitude value and a second fitted amplitude value; and</claim-text><claim-text>determining the target audio amplitude value corresponding to the first sampling point based on the first fitted amplitude value and the second fitted amplitude value.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein determining the target audio amplitude value corresponding to the first sampling point based on the first fitted amplitude value and the second fitted amplitude value, comprises:<claim-text>determining an average amplitude value of the first fitted amplitude value and the second fitted amplitude value as the target audio amplitude value.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein determining the target audio amplitude value corresponding to the first sampling point based on the first fitted amplitude value and the second fitted amplitude value comprises:<claim-text>obtaining an average amplitude value of the first fitted amplitude value and the second fitted amplitude value;</claim-text><claim-text>generating fitted audio data of the first sampling points based on the average amplitude value;</claim-text><claim-text>generating a third fitted curve based on the first audio data, the fitted audio data and the second audio data; and</claim-text><claim-text>obtaining the target audio amplitude value by inputting the sampling time point into the third fitted curve.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein obtaining the target audio amplitude values corresponding respectively to the first sampling point based on the first audio data sampled at the second sampling points and the second audio data sampled at the third sampling points, comprises:<claim-text>for any sampling point in the second sampling point set or the third sampling point set, obtaining an audio amplitude value of the sampling point;</claim-text><claim-text>obtaining a combination by combining one second sampling point in the second sampling point set with one third sampling point in the third sampling point set; and</claim-text><claim-text>determining an average value of a second audio amplitude value of the second sampling point in the combination and a third audio amplitude value of the third sampling point in the combination as the target audio amplitude value.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein identifying the discarded first sampling point set comprises:<claim-text>identifying adjacent two pieces of audio data from the audio data packet, and a first sampling time point and a second sampling time point corresponding respectively to the two pieces of audio data,; and</claim-text><claim-text>obtaining a discarded sampling time point between the first sampling time point and the second sampling time point in response to the first sampling time point and the second sampling time point being discontinuous, wherein each first sampling point corresponds to one discarded sampling time point.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A non-transitory computer readable storage medium storing computer instructions, wherein the computer instructions are configured to cause a computer to performing the following:<claim-text>receiving an audio data packet sent by a vehicle-mounted terminal, and identifying a discarded first sampling point set in response to detecting packet loss, wherein the first sampling point set comprises N first sampling points, and N is a positive integer;</claim-text><claim-text>obtaining a second sampling point set and a third sampling point set each adjacent to the first sampling point set, wherein the second sampling point set is prior to the first sampling point set, the third sampling point set is behind the first sampling point set, the second sampling point set comprises at least N second sampling points, and the third sampling point set comprises at least N third sampling points;</claim-text><claim-text>generating target audio data of the first sampling points based on first audio data sampled at the second sampling points and second audio data sampled at the third sampling points; and</claim-text><claim-text>inserting the target audio data at sampling positions of the first sampling points to obtain a recovered audio data packet.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230001915A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230001915</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17364161</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>W</subclass><main-group>30</main-group><subgroup>045</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>62</class><subclass>D</subclass><main-group>15</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>30</main-group><subgroup>045</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>62</class><subclass>D</subclass><main-group>15</main-group><subgroup>025</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2520</main-group><subgroup>14</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2520</main-group><subgroup>26</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2520</main-group><subgroup>28</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200201</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2530</main-group><subgroup>201</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2510</main-group><subgroup>205</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">ESTIMATING ANGLE OF A VEHICLE WHEEL BASED ON NON-STEERING VARIABLES</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Zoox, Inc.</orgname><address><city>Foster City</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Bosse</last-name><first-name>Michael Carsten</first-name><address><city>Cupertino</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Rebsamen</last-name><first-name>Brice</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><orgname>Zoox, Inc.</orgname><role>02</role></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Techniques for using a set of non-steering variables to estimate an angle of a wheel are described. For example, a yaw rate, a linear velocity of a wheel, and vehicle dimensions (e.g., offset between the wheel and a turn-center reference line), can be used to estimate the angle of the wheel. Among other things, estimating angles based on non-steering variables may provide redundancy (e.g., when determined in parallel with steering-based command angles or other commanded angles) and/or may be used to validate commanded angles based on steering components.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="61.38mm" wi="158.75mm" file="US20230001915A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="258.66mm" wi="172.04mm" file="US20230001915A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="239.69mm" wi="171.70mm" file="US20230001915A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="256.96mm" wi="168.83mm" file="US20230001915A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="253.66mm" wi="172.64mm" file="US20230001915A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="236.64mm" wi="170.35mm" orientation="landscape" file="US20230001915A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">A vehicle may include various sensors, which may be utilized for many different purposes. For example, sensors may be used to detect information about a surrounding environment (e.g., other vehicles, roadway conditions, pedestrians, street signs, etc.), as well as to monitor vehicle operations (e.g., braking, accelerating, steering, system(s) status, vehicle position, etc.). In some instances, sensor data may be consumed by downstream operations. For example, steering data (e.g., describing a steering angle or a command angle for a wheel) may be used for dead reckoning or other localization processes. As such, accuracy and reliability of the sensor data is important to allow the vehicle to safely and reliably navigate through an environment.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0002" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0003" num="0002">The detailed description is described with reference to the accompanying figures. In the figures, the left-most digit(s) of a reference number identifies the figure in which the reference number first appears. The use of the same reference numbers in different figures indicates similar or identical components or features.</p><p id="p-0004" num="0003"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> illustrates a perspective view of an example vehicle with two wheels turned at an angle.</p><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. <b>1</b>B</figref> illustrates a plan view of the vehicle of <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> showing an estimated wheel angle and a measured command angle for each of the two wheels, as described herein.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a schematic of a vehicle traversing a turn with two wheels rotated at respective angles, the schematic including variables that may be used to describe the turn or a component of the vehicle, as described herein.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a schematic of a vehicle traversing a turn with four wheels rotated at respective angles, the schematic including variables that may be used to describe the turn or a component of the vehicle, as described herein.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>4</b></figref> includes a flow diagram illustrating an example process for determining estimated steering data, as described herein.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram illustrating an example system for performing techniques as described herein.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0003" level="1">DETAILED DESCRIPTION</heading><p id="p-0010" num="0009">As discussed above, accuracy and reliability of sensor data (and determinates derived from sensor data) are important to allow a vehicle to safely and reliably navigate through an environment. This application relates to techniques for using a set of non-steering variables (e.g., variables that are independent of a steering system) to estimate an angle of a wheel. As used in this disclosure, the angle of a wheel is an angle between the orientation of the wheel (e.g., a direction in which the wheel is pointed) and the longitudinal orientation or axis of the vehicle. In examples of this disclosure, a yaw rate (e.g., from an inertial measurement unit, gyroscope, etc.), a linear speed at or near a wheel speed (e.g., from an encoder), and vehicle dimensions (e.g., distance between the wheel and a turn-center reference line), can be used to estimate the angle of the wheel. Among other things, angles estimated based on non-steering variables may provide redundancy (e.g., when determined in parallel with steering-based angles) and validation and may be less susceptible to inaccuracies from steering-component slippage and/or loss of tire traction, model inaccuracies, and the like. In addition, estimated wheel angles may be used in various manners, such as for estimating vehicle velocity.</p><p id="p-0011" num="0010">A vehicle may include various steering components used to affect or control an angle of a vehicle wheel. For example, a vehicle may include a steering motor that generates a rotational output, which is transferred to a wheel and/or to linear travel of a steering rack. A steering sensor may measure the rotation of the steering motor, and the rotation may be used to determine (e.g., from a correlation between rotation and linear rack travel) steering rack travel (or other steering data associated with a command angle of the wheel). In other examples, steering rack travel may be directly measured or may be derived from other sensor data associated with the steering system or the suspension assembly. This steering data (e.g., motor rotation data, rack travel distance, etc.) may in turn be used to estimate an angle of a wheel. In some instances, steering components (e.g., belts, racks, pinions, gear teeth, etc.) may experience slippage (e.g., mechanical slip) that can affect the accuracy of the steering-based estimated angle. In other instances, the wheel may lose traction against pavement, which can cause an inconsistency between the angle commanded by the vehicle and the actual angle.</p><p id="p-0012" num="0011">In examples of this disclosure, by using non-steering variables to estimate a wheel angle, the determination may avoid or mitigate inaccuracies that can arise from relying solely on the steering system (e.g., inaccuracies arising from steering-component component slippage or wear, loss of tire traction, model-predication inaccuracies, etc.). The estimated angle may be used in various respects to control vehicle operations. For example, the estimated angle may be compared to a commanded wheel angle to determine whether the commanded wheel angle was executed. As used in this disclosure, a &#x201c;commanded wheel angle&#x201d; is a wheel angle generated by one or more vehicle components and selected for executed by the vehicle. For example, a trajectory planner may select a trajectory (e.g., turn maneuver) to be executed by the vehicle, and the trajectory may include a wheel angle (e.g., the commanded wheel angle) at which a wheel should be turned (e.g., by using steering components) in order to execute the trajectory. In other examples, a steering wheel may be rotated to a degree that correlates with a wheel angle (e.g., the commanded wheel angle), which can be attempted using the steering motor, rack, and/or other steering components. Based on these examples, the commanded wheel angle may be generated or provided by the trajectory planner and/or by the steering components. For example, the commanded wheel angle may be an angle that is provided by (or retrieved from) a vehicle-trajectory planner, steering components (e.g., steering sensor, steering motor, and/or steering rack), or any combination thereof. By comparing the estimated angle to the commanded wheel angle, the reliability of various information and components may be assessed. For example, the reliability of the commanded wheel angle (e.g., for downstream processing when estimating vehicle velocity) may be assessed, as well as the condition of the steering components (e.g., where sufficient differences between the estimated angle and the commanded wheel angle may suggest component wear, slippage, etc.). In further examples, a difference (e.g., variance) between the estimated angle and the commanded angle may be used to detect and/or flag conditions, such as wheel slip. In additional examples, the estimated angle from non-steering variables may be combined with the commanded angle (e.g., averaged) for use by downstream components (e.g., localization). In addition, the estimated angle may be directly used (e.g., independent of commanded angle) by downstream processes to determine vehicle position or other vehicle states (e.g., velocity), which may be used for localization or other map-related operations. In some examples, a difference may be determined between an estimated wheel angle and a commanded angle and operations that use (e.g., rely on or consume) the wheel angle could be augmented (e.g., increased or decreased accordingly) by the difference.</p><p id="p-0013" num="0012">The techniques described herein can be implemented in a number of ways to use non-steering variables to estimate wheel angle. Examples are provided below with reference to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>5</b></figref>. Examples are discussed in the context of autonomous vehicles; however, the methods, apparatuses, and components described herein can be applied to a variety of components (e.g., a sensor component or a robotic platform), and are not limited to autonomous vehicles. In one example, the techniques described herein may be utilized in driver-controlled vehicles. Furthermore, the techniques described herein can be used with real data (e.g., captured using sensor(s)), simulated data (e.g., generated by a simulator), or any combination of the two.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>1</b>B</figref> illustrate different views of an example vehicle <b>102</b> with components for using non-steering variables to estimate angles of wheels of the vehicle <b>102</b>. <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> depicts a perspective view of the vehicle <b>102</b>, which is ghosted in broken lines to help illustrate internally positioned components; and <figref idref="DRAWINGS">FIG. <b>1</b>B</figref> presents a plan view of the vehicle <b>102</b>. Among other things, the vehicle <b>102</b> includes a front end <b>104</b>, a rear end <b>106</b>, a left side <b>108</b>, and a right side <b>110</b>. In addition, for reference in this disclosure, the vehicle <b>102</b> includes a longitudinal axis <b>112</b> extending along a front-to-back orientation (e.g., longitudinal orientation) and a lateral axis <b>114</b> extending along a side-to-side orientation (e.g., lateral orientation) and substantially perpendicular to the longitudinal axis <b>112</b>. Furthermore, a vertical axis <b>116</b> may extend top-to-bottom and perpendicular to the longitudinal axis <b>112</b> and to the lateral axis <b>114</b>. <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> also depicts a yaw action <b>118</b>, which indicates the vehicle <b>102</b> may rotate relative to the vertical axis <b>116</b>, such as when the vehicle <b>102</b> executes a turn. For example, the vehicle <b>102</b> includes four wheels <b>120</b><i>a</i>-<b>120</b><i>d</i>, each oriented in a direction indicated by a respective directional arrow <b>122</b><i>a</i>-<b>122</b><i>d</i>. In <figref idref="DRAWINGS">FIGS. <b>1</b>A and <b>1</b>B</figref>, the front wheels <b>120</b><i>a </i>and <b>120</b><i>b </i>are depicted rotated at a command angle towards the left in a direction indicated by a respective directional arrow <b>122</b><i>a </i>and <b>122</b><i>b</i>. The placement of the yaw action <b>118</b> in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> illustrates an example, and the vehicle <b>102</b> a yaw action, yaw event, or yaw rotation may occur at various locations or positions of the vehicle.</p><p id="p-0015" num="0014">In one example, the vehicle <b>102</b> is a bidirectional vehicle having a first drive module positioned in the front end <b>104</b> and a second drive module positioned in the rear end <b>106</b>. As used herein, a bidirectional vehicle is one that is configured to switch between traveling in a first direction of the vehicle and a second, opposite, direction of the vehicle. In other words, there is no fixed &#x201c;front&#x201d; or &#x201c;rear&#x201d; of the vehicle <b>102</b>. Rather, whichever longitudinal end of the vehicle <b>102</b> is leading at the time becomes the &#x201c;front&#x201d; and the trailing longitudinal end becomes the &#x201c;rear.&#x201d; In other examples, the techniques described herein may be applied to vehicles other than bidirectional vehicles. Also, whether or not the vehicle is bidirectional, the first drive and second drive modules may be different from one another. For example, one drive module may have a subset of the features of the other drive module. In one such example, the first drive module may include a first, comprehensive set of vehicle systems (e.g., drive motor, battery, steering system, braking system, suspension system, HVAC, sensors, lights, body panels, facia, etc.) while the second drive module includes a limited subset of vehicle systems (e.g., suspension system, braking system, sensors, lights, and facia). In various instances, the wheels positioned in the front end <b>104</b> are steerable, and the wheels positioned in the rear end <b>106</b> are also steerable, such that the vehicle <b>102</b> includes four-wheel steering (e.g., including each set of wheels having the respective steering components). In other examples, the drive modules may have one or more distinct or mutually exclusive vehicle systems (e.g., one drive module has an HVAC system and the other drive module has a drive motor). As another non-limiting example of such, one module may have a first HVAC system while the other drive module has a second HVAC system that is different from the first HVAC system.</p><p id="p-0016" num="0015">In addition, the vehicle <b>102</b> may include various sensors for detecting one or more different conditions. For example, the vehicle <b>102</b> may include sensors <b>124</b><i>a</i>-<b>124</b><i>d</i>, each of which may include a perception sensor for capturing data of an environment around the vehicle <b>102</b> (e.g., lidar, camera, time-of-flight, sonar, radar, etc.). These sensors <b>124</b><i>a</i>-<b>124</b><i>d </i>may be used for various operations, such as object detection, route planning, localization, etc. In at least one example, the vehicle <b>102</b> may also include a yaw rate sensor <b>125</b>, such as an inertial measurement unit (IMU), gyroscope, or other sensor for measuring a yaw rate of the vehicle <b>102</b>. The position of the yaw rate sensor <b>125</b> is an example, and the yaw rate sensor <b>125</b> may include various other positions or locations of the vehicle <b>102</b>. In a further example, the vehicle <b>102</b> may include one or more sensors <b>126</b><i>a</i>-<b>126</b><i>d </i>(e.g., encoders) for measuring a wheel speed of a respective wheel (e.g., determining a linear speed of the vehicle <b>102</b> at a wheel). In <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, the sensors <b>126</b><i>a </i>and <b>126</b><i>c </i>are depicted in broken lines to convey that, in some examples, the sensors <b>126</b><i>a </i>and <b>126</b><i>c </i>may be obscured behind a respective wheel (at least from the perspective provided in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>). These are just some examples of sensors, and the vehicle may include other sensors, such as those described with respect to the system <b>500</b>. In addition, the placement of the sensors relative to the vehicle <b>102</b> in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> is an example, and in other examples, the sensors (e.g., <b>124</b><i>a</i>-<b>124</b><i>d </i>and <b>125</b>) may be arranged at other positions on the vehicle <b>102</b>.</p><p id="p-0017" num="0016">In additional examples, the vehicle <b>102</b> may include various steering components, such as a steering motor <b>128</b> and a steering rack <b>130</b> that operate to affect a commanded angle of each wheel <b>120</b><i>a</i>-<b>120</b><i>d </i>(e.g., autonomously commanded and/or manually commanded). For example, the steering motor <b>128</b> may generate a rotational output based on steering input (e.g., direction and amount) from a manually operated steering wheel (not shown), from a computing device (e.g., planning <b>536</b> in <figref idref="DRAWINGS">FIG. <b>5</b></figref>), or from a combination thereof. The rotational output may be transferred to the steering rack <b>130</b> to create linear steering rack travel in one direction or another. The steering rack <b>130</b> may interface with each wheel at a knuckle of the suspension assembly or some other coupling that transfers the linear rack travel to the wheel to cause the wheel to pivot or rotate about an axis. In examples, the vehicle <b>102</b> may include one or more steering sensors <b>132</b> for determining steering data associated with the commanded angle of each of the wheels <b>120</b><i>a</i>-<b>120</b><i>d</i>. For example, the steering sensor <b>132</b> may determine an amount of steering-motor rotation, an amount of steering rack travel, or other data, which may be related to the commanded angle of each wheel. That is, in some instances, a commanded angle may be selected for execution, and the commanded angle may correlate with an amount of steering motor rotation and/or rack travel. As such, in some examples, a commanded angle may be determined based on given steering data by referencing the correlation. In other examples, a correlated command angle that is based on the steering data may be compared to a command angle selected by or received from another component (e.g., trajectory planner) to assess consistency. In <figref idref="DRAWINGS">FIGS. <b>1</b>A and <b>1</b>B</figref>, a steering assembly is depicted in the front end <b>104</b> and rear end <b>106</b> of the vehicle. In other aspects, only one end of the vehicle may include a steering assembly while the other end is fixed. Alternative aspects of the disclosure may include a different steering arrangement. For example, each suspension assembly may include a respective steering motor that, without a shared or common steering rack, affects the command angle of a wheel (e.g., by rotating about a steering axis). As such, the steering motor rotation may affect the wheel command angle without relying on the shared or common steering rack.</p><p id="p-0018" num="0017">In some instances, steering components may be used to impart an angle on one or more wheels of the vehicle <b>102</b>, such as when the vehicle is executing a turn. For example, in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> the front wheels <b>120</b><i>a </i>and <b>120</b><i>b </i>are rotated to the left. In addition, the steering components may impart the actual wheel angle based on a commanded wheel angle from another component (e.g., trajectory planner, manual steering wheel, etc.) or the steering sensor data may be used to determine a commanded angle based on a correlation. However, in some instances, such as loss of tire traction, mechanical slip of steering components, component noise or inaccuracies, the commanded angle (e.g., from the other component or based on the steering data correlation) may not accurately reflect the actual angle of each wheel. For example, referring to <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>, the actual orientations of the front wheels <b>120</b><i>a </i>and <b>120</b><i>b </i>are illustrated with the directional arrows <b>122</b><i>a </i>and <b>122</b><i>b</i>; however, the orientations reflected by the commanded angles <b>132</b><i>a </i>and <b>132</b><i>b </i>(also indicated in <figref idref="DRAWINGS">FIG. <b>1</b>B</figref> by &#x398;&#x2033; and &#x398;&#x2032;&#x2033;) are indicated by the broken-line command arrows <b>134</b><i>a </i>and <b>134</b><i>b </i>and are inconsistent with the actual-orientation arrows <b>122</b><i>a </i>and <b>122</b><i>b</i>. As such, examples of the present disclosure are directed to estimating a wheel angle (e.g., <b>136</b><i>a</i>/&#x398; and <b>136</b><i>b</i>/&#x398;&#x2032;) of a wheel (e.g., <b>120</b><i>a </i>and <b>120</b><i>b</i>) based on non-steering variables.</p><p id="p-0019" num="0018">Referring to <figref idref="DRAWINGS">FIGS. <b>1</b>A, <b>1</b>B, and <b>2</b></figref>, various non-steering variables are schematically depicted in the context of the vehicle <b>102</b> executing a curved trajectory <b>200</b> (or turn maneuver), which is illustrated by the dashed line circles in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the curved trajectory <b>200</b> includes a turn center <b>204</b> (or rotation center), and a turn-center reference line <b>140</b> (see also the turn-center reference line <b>140</b> in <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>), which extends through the turn center <b>204</b> and normal to the longitudinal axis <b>112</b> of the vehicle <b>102</b>. In addition, based on the dimensions of the vehicle <b>102</b>, an offset distance <b>142</b> for the wheel <b>120</b><i>b </i>and an offset distance <b>251</b> for the wheel <b>120</b><i>a </i>(<figref idref="DRAWINGS">FIGS. <b>1</b>B and <b>2</b></figref>) extends perpendicularly from the turn-center reference line <b>140</b> to the center of the wheel <b>120</b><i>b</i>. In general, the offset distances <b>142</b> and <b>251</b> extend from the wheel (e.g., a rotation axis of the wheel) to a position aligned with the turn center <b>204</b> and/or the turn-center reference line <b>140</b> (e.g., aligned along a plane or line extending through the turn center <b>204</b> and normal to the longitudinal orientation of the vehicle).</p><p id="p-0020" num="0019">The turn center <b>204</b> and the turn-center reference line <b>140</b> may be established using various techniques. For example, if a vehicle is executing a turn using only front-wheel steering (while the rear wheel do not rotate about a steering axis), such as the vehicle <b>102</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref> in which the front left wheel <b>120</b><i>b </i>and the front right wheel <b>120</b><i>a </i>rotate about a steering axis, then the turn-center reference line <b>140</b> is co-axial with a rear axle of the vehicle, and the offset distance may be pre-determined based on vehicle dimensions. In other examples, the turn center <b>204</b> may be at an intersection of a radius (R&#x2032;) <b>246</b> (e.g., of the curve or arc traversed by the front left wheel <b>120</b><i>b</i>) and a radius (R) <b>247</b> (e.g., of the curve or arc traversed by the front right wheel <b>120</b><i>a</i>). These radii (and the resulting turn center) may be initially estimated from various data, such as the commanded angles the vehicle is attempting to execute (e.g., as provided by or retrieved from a trajectory planner and/or steering component). While some degree of error may exist in this initial estimate of the turn center, which is based on the commanded angles, in many instances it may only exist in the lateral orientation, which would still provide an accurate offset distance <b>142</b> based on the turn-center reference line <b>140</b> being in the same location regardless of the lateral position of the turn center. In addition, in some instances, the turn center <b>204</b> may be determined using only two radii generated from respective commanded angles (even if the vehicle is using four-wheel steering), such that noisier commanded angles may be omitted (or given less weight) when determining the turn center <b>204</b> and offset distance <b>142</b>. Furthermore, an average turn center may be determined, which may also reduce the impact of an imprecise or inaccurate commanded steering angle on the offset distance determination.</p><p id="p-0021" num="0020">Furthermore, in some examples of this disclosure, a yaw rate (&#x3c9;) <b>218</b> may be received from a yaw rate sensor (e.g., IMU, gyroscope, etc.) and a linear velocity at each wheel (e.g., linear velocity (V) <b>243</b> and linear velocity (V&#x2032;) <b>244</b>) may be derived from a variety of different sources. For example, in some instances, linear velocity at each wheel may be derived from data received from an encoder (or other sensor, such as radar). In some examples, linear velocity at each wheel may be determined or solved using the common velocity of the vehicle (e.g., velocity of the vehicle at the vehicle center based on sensor data), the yaw rate, and an amount by which the common velocity is transformed at the wheel. For example, the velocity at the wheel may be determined by combining (e.g., summing) the common velocity of the vehicle at a position with a cross product between the yaw rate and the vector between the two positions (e.g., coordinates) of the wheel from/to the common velocity is being transformed (e.g., yaw rate cross lever arm from the position of the common velocity to the wheel).</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts additional variables with respect to each of the front wheels <b>120</b><i>a </i>and <b>120</b><i>b</i>. For example, <figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts an estimated wheel angle <b>136</b><i>a </i>(&#x398;<sub>EA</sub>) associated with the wheel <b>120</b><i>a</i>, as well as a central angle <b>249</b> (&#x398;<sub>CA</sub>) between the turn-center reference line <b>140</b>, the turn center <b>204</b>, and a radius (R) <b>247</b> intersecting the center of the wheel <b>120</b><i>a</i>. In addition, <figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts an estimated wheel angle <b>136</b><i>b </i>(&#x398;<sub>EA</sub>&#x2032;) associated with the wheel <b>120</b><i>b</i>, as well as a central angle <b>248</b> (&#x398;<sub>CA</sub>&#x2032;) between the turn-center reference line <b>140</b>, the turn center <b>204</b>, and a radius (R&#x2032;) <b>246</b> intersecting the center of the wheel <b>120</b><i>a</i>. In examples, the estimated wheel angle associated with a wheel is equal to the central angle associated with the wheel. Based on the non-steering variables depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, various functions may be expressed to describe relationships among the variables. For example, a sine trigonometric function may be expressed as:</p><p id="p-0023" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>sin(&#x398;<sub>CA</sub>)=<i>B/R</i>&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0024" num="0000">where &#x398;<sub>CA </sub>is the central angle <b>249</b> (e.g., between the turn-center reference line <b>140</b>, the turn center <b>204</b>, and the radius (R) <b>247</b> passing through the center of the wheel <b>120</b><i>a</i>); B is equal to the offset distance <b>251</b>; and R is equal to the radius <b>247</b>.</p><p id="p-0025" num="0022">In addition, a relationship exists between the radius (R) <b>247</b> (e.g., expressed in meters), the linear velocity (V) <b>243</b> at the wheel <b>120</b><i>a </i>(e.g., expressed in meters/second), and the yaw rate (&#x3c9;) <b>218</b> (e.g., expressed as 1/second or s<sup>&#x2212;1</sup>), where:</p><p id="p-0026" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>R=V/&#x3c9;</i>&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0027" num="0000">By substituting R in Function 1 with Function 2, an estimated wheel angle <b>136</b><i>a </i>(&#x398;) may be calculated using:</p><p id="p-0028" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x398;<sub>EA</sub>=arcsin(<i>B</i>*(&#x3c9;/<i>V</i>))&#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0029" num="0000">As indicated above, the estimated wheel angle associated with a wheel is equal to the central angle associated with the wheel. As such, using Function 3, an estimated wheel angle <b>136</b><i>a </i>(&#x398;<sub>EA</sub>) between the orientation of the wheel and the vehicle longitudinal orientation <b>112</b> may be calculated based on non-steering variables including the offset distance (B) <b>251</b>, the linear wheel velocity (V) <b>243</b>, and the yaw rate (&#x3c9;) <b>218</b>. In addition, using Function 3 with a respective linear wheel velocity <b>244</b>, an estimated wheel angle <b>136</b><i>b </i>(&#x398;<sub>EA</sub>&#x2032;) may be calculated for the wheel <b>120</b><i>b. </i></p><p id="p-0030" num="0023">An estimated wheel angle determined using non-steering variables may be used in various manners. For example, an estimated wheel angle <b>136</b><i>a </i>and <b>136</b><i>b </i>may be calculated for each wheel <b>120</b><i>a </i>and <b>120</b><i>b </i>using Function 3, which may provide additional insight into the actual motion of the vehicle. Among other things, the estimated wheel angles may provide redundancy (e.g., when determined in addition to commanded angles from other systems) or may be directly used to control vehicle operations. In some examples, the estimated wheel angle <b>136</b><i>a </i>and <b>136</b><i>b </i>for each wheel <b>120</b><i>a </i>and <b>120</b><i>b </i>may be compared to a commanded angle <b>132</b><i>a </i>and <b>132</b><i>b </i>for each wheel. The comparison may be used in various manners. For example, the comparison may be used to determine whether the estimated wheel angle and/or the command angle are reliable. In some examples, if a difference (e.g., variance) between the estimated angle and the commanded angle exceeds a threshold, then the commanded angle may be down weighted (e.g., given a lower weight or give zero weight) in subsequent processes (e.g., dead reckoning algorithm or other localization processes; velocity calculations; etc.). In some examples, one or more of the estimated wheel angles may be used to estimate a vehicle velocity. That is, one or more of the estimated wheel angles may be used in a least squares method or algorithm to estimate the vehicle velocity. For example, vehicle velocity may be determined assuming rotation around the turn center (e.g., based on vehicle velocity being equal to the product of the yaw right and the center of rotation). Among other things, vehicle velocity may be used to estimated relative positions (e.g., pose) of the vehicle as the vehicle executes one or more maneuvers, and in this respect, the relative position may be at least partially based on the estimated wheel angle. In some examples, a relative position of the vehicle may be based at least partially on the estimated wheel angle with or without solving for the vehicle velocity based on the least squares method.</p><p id="p-0031" num="0024">In other examples, if a difference (e.g., variance) between the estimated angle and the commanded angle exceeds a threshold, then a slip event (e.g., wheel slip, mechanical slippage, vehicle skid, etc.) may be flagged (e.g., recorded, reported, tracked, etc.) indicating the subject wheel may have lost traction or slipped or the steering components controlling the command angle may have experienced mechanical slippage. For example, when one or more tires lose traction, then a yaw rate may be higher than the wheels have commanded to. In other words, the wheels may be commanded to a particular angle that, without a loss in traction, are expected to result in a particular yaw rate; however, when a loss in traction occurs, the yaw rate may be higher, which could result in a different estimated wheel angle. This in turn may generate a signal to the vehicle to regain control, such as by adjusting the steering, applying brakes, reducing an acceleration, powering opposite wheels, depressing or releasing a throttle, etc. In further examples, if a total count or frequency of slip events exceeds a threshold, then maintenance may be suggested (e.g., check tire tread or steering components). In additional examples, if slip events are flagged at multiple wheels, then a vehicle-skid event may be flagged indicating the vehicle skidded across a ground surface. In additional examples, the estimated command angle from non-steering variables may be combined with the measured command angle (e.g., averaged) for use by downstream components (e.g., localization).</p><p id="p-0032" num="0025">In addition, the estimated angle may be directly used (e.g., independent of measured command angle) by downstream processes to determine vehicle position, which may be used for localization or other map related operations (e.g., pose estimation). In other examples, the estimated angle may be used to determine or quantify other conditions associated with a wheel suspension assembly. For example, in some examples, a relationship may exist between the command angle of the wheel, a ride height of the vehicle at the wheel (e.g., damper displacement), and a ball-joint articulation angle (e.g., associated with a ball joint in the suspension assembly), such that the command angle may be used in combination with a ball-joint articulation angle to estimate the vehicle ride height. In at least one example, the estimated command angle may be used (e.g., in combination with ball joint sensor data) to estimate vehicle ride height as described in U.S. application Ser. No. 17/246,375 (titled &#x201c;Determining Vehicle Ride Height Using A Ball Joint Sensor&#x201d; and filed Apr. 30, 2021), which is incorporated herein by reference in its entirety and for all purposes.</p><p id="p-0033" num="0026">Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, another example is depicted including a schematic of a vehicle <b>302</b> executing a curved trajectory <b>300</b>, which is illustrated by the dashed line circles. In FIG. <b>3</b>, the vehicle <b>302</b> includes four-wheel steering, such that the front wheels <b>320</b><i>a </i>and <b>320</b><i>b </i>and the back wheels <b>320</b><i>c </i>and <b>320</b><i>d </i>pivot or rotate about a respective steering axis to an angle when executing the curved trajectory. In examples of this disclosure, as between the vehicle <b>102</b> executing two-wheel steering and the vehicle <b>302</b> executing four-wheel steering, the respective turn-center reference lines may be different; however, estimated wheel angles may still be determined based on yaw rate, wheel linear velocity, and offset. For example, in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the curved trajectory <b>300</b> includes a turn center <b>304</b>, and a turn-center reference line <b>340</b>, which extends through the turn center <b>304</b> and normal to the longitudinal axis <b>312</b> of the vehicle <b>302</b>. As explained above, the turn center <b>304</b> and the turn center-reference line <b>340</b> may be determine in various manners, such as based on the commanded angles of the wheels (e.g., at an intersection of a radius of two or more of the wheels). In addition, where the left-side wheels (e.g., front-left wheel and back-left wheel) include similar angles (except in different directions) and the right-side wheels (e.g., front-right wheel and back-right wheel) includes similar angles (except in different directions), then the turn-center reference line <b>340</b> may bisect a gap spacing apart the front axle and the rear axle. Furthermore, based on the dimensions of the vehicle <b>302</b>, an offset distance <b>342</b> extends perpendicularly from the turn-center reference line <b>340</b> to the center of each wheel. In further examples, a radius <b>346</b> of the curve or arc traversed by each wheel extends from the turn center <b>304</b> to the respective wheel. Furthermore, a yaw rate (&#x3c9;) <b>318</b> may be received from a yaw rate sensor (e.g., IMU, gyroscope, etc.) and a linear wheel velocity (V) <b>344</b> may be received from an encoder (or other sensor). With these non-steering variables, Function 3 illustrated above may be solved for the wheel <b>320</b><i>c </i>to calculate an estimated command angle <b>336</b><i>c</i>. <figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates the variables as they relate to the wheel <b>320</b><i>c</i>, and similar (but respective) variables may be determined for each of the other wheels <b>320</b><i>a</i>, <b>320</b><i>b</i>, and <b>320</b><i>d </i>to calculate a respective estimated command angle for each wheel. Each of the command angles may be used as described above, such as for direct consumption by a downstream component and/or to assess reliability of measured command angles based on steering data.</p><p id="p-0034" num="0027"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart showing an example process involving techniques as described herein. The process illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be described with reference to components and elements described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b>A, <b>1</b>B, <b>2</b></figref>, and/or <b>3</b> for convenience and ease of understanding. However, the process illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> is not limited to being performed using these components, and the components are not limited to performing the process illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. The process illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> is illustrated as a logical flow graph, each operation of which represents a sequence of operations that can be implemented in hardware, software, or a combination thereof. In the context of software, the operations represent computer-executable instructions stored on one or more computer-readable storage media that, when executed by one or more processors, perform the recited operations. Generally, computer-executable instructions include routines, programs, objects, components, data structures, and the like that perform particular functions or implement particular abstract data types. The order in which the operations are described is not intended to be construed as a limitation, and any number of the described operations can be omitted or combined in any order and/or in parallel to implement the process.</p><p id="p-0035" num="0028"><figref idref="DRAWINGS">FIG. <b>4</b></figref> includes a flow diagram with operations or steps for a process <b>400</b> for determining an estimated wheel angle of wheel of a vehicle, the estimated wheel angle being usable to control an operation of the vehicle. For example, the process <b>400</b> may be used to determine an estimated wheel angle <b>136</b><i>b </i>of the wheel <b>120</b><i>b </i>of the vehicle <b>102</b> or the estimated wheel angle <b>136</b><i>a </i>of the wheel <b>120</b><i>a</i>. The process <b>400</b> includes, at step <b>402</b>, determining a linear velocity at a wheel, and the pictorial representation associated with step <b>402</b> depicts the linear velocity (V) while the wheel <b>420</b><i>b </i>is turned to an orientation represented by the vector arrow. For example, sensor data may be received (e.g., when the vehicle is executing a turn <b>202</b>) from the sensor <b>126</b><i>b </i>(e.g., wheel encoder) associated with the wheel <b>120</b><i>b</i>. In other examples, linear velocity at a wheel may be calculated or derived from a common velocity of the vehicle.</p><p id="p-0036" num="0029">At step <b>404</b>, the process <b>400</b> includes receiving, from a second sensor, a vehicle yaw rate, and the pictorial representation associated with step <b>404</b> labels the yaw rate (&#x3c9;) as the vehicle rotates about the turn center. For example, sensor data may be received from the yaw rate sensor <b>124</b> (e.g., IMU, gyroscope, etc.).</p><p id="p-0037" num="0030">The process <b>400</b> includes, at step <b>406</b>, receiving an offset distance of the wheel away from the turn-center reference line, and the pictorial representation associated with step <b>406</b> labels the wheel offset (B) between the wheel <b>420</b><i>b </i>and the turn-center reference line <b>440</b>. In some examples, the offset distance <b>142</b> may be based on the dimensions and geometry of the vehicle <b>102</b>. For example, if the vehicle is executing a front-wheel steering turn (e.g., by rotating only front wheels while rear wheels remain aligned in the longitudinal orientation) then the turn-center reference line <b>440</b> may pass through (e.g., be co-axial with) the rear axle and the offset distance, based on vehicle dimensions, is the shortest distance between the wheel and the turn-center reference line <b>440</b>. In another example, if the vehicle is executing a four-wheel steering turn, with left-side wheels rotated to similar angles (but in different directions) and right-side wheels rotate to similar angles (but in different directions), then the turn-center reference line may bisect the space between the front and rear axle and the offset distance is, based on vehicle dimensions, the shortest distance between the wheel and the turn-center reference line. In some examples, the offset distance may be determined by estimating a turn center (e.g., based on commanded wheel angles of two or more wheels) and a position of a turn-center reference line (based on the estimated turn center), and then determining the offset distance from the estimated position of the turn-center reference line.</p><p id="p-0038" num="0031">In addition, at <b>408</b>, the process <b>400</b> includes determining the estimated wheel angle (&#x398;). For example, Function 3 may be solved for the estimated command angle using the linear velocity (V) from step <b>402</b>, the yaw rate (&#x3c9;) from step <b>404</b>, and the offset distance (B) from step <b>406</b>.</p><p id="p-0039" num="0032">In examples of this disclosure, the estimated wheel angle may be used in various manners. For example, at step <b>410</b>, the estimated command angle is compared to a commanded wheel angle (e.g., from a trajectory planner and/or based on steering components) to determine whether the command angle is within a threshold value of the estimated wheel angle. If the measured command angle is within the threshold value (&#x201c;Yes&#x201d; at step <b>410</b>), then at step <b>412</b>, the vehicle may be controlled based on the commanded wheel angle. For example, the commanded wheel angle may be used for localization or other downstream operations. If the commanded angle is not within the threshold value (&#x201c;No&#x201d; at step <b>410</b>), then at step <b>414</b>, the vehicle may be controlled based on the estimated wheel angle. For example, a weight value associated with the measured command angle may be reduced (e.g., receive a lower weight or zero weight) for use with downstream components based on a lower confidence in the measured command angle. In some examples, at step <b>414</b>, the commanded wheel angle and the estimated wheel angle may be combined (e.g., averaged) and the vehicle may be controlled based on the averaged wheel angle. In some examples, at step <b>414</b>, the estimated wheel angle may be used by downstream processes (e.g., for localization, positioning, dead reckoning, etc.) independently of the commanded angle. For example, the estimated wheel angle may be used in combination with one or more other estimated wheel angles (e.g., using a least squares method) to estimate a vehicle velocity, which may be used for determining relative positions as the vehicle maneuvers. In some examples, a difference may be determined between an estimated wheel angle and a commanded angle and operations that use (e.g., rely on or consume) the wheel angle could be augmented (e.g., increased or decreased accordingly) by the difference. In some examples, if the measured command angle is not within the threshold value, then at step <b>414</b> a slip event may be flagged or recorded (e.g., loss of tire traction, vehicle skidding, steering-component mechanical slippage, etc.).</p><p id="p-0040" num="0033"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts a block diagram of an example system <b>500</b> for implementing the techniques described herein. In at least one example, the system <b>500</b> can include a vehicle <b>502</b>. In the illustrated example system <b>500</b>, the vehicle <b>502</b> is an autonomous vehicle; however, the vehicle <b>502</b> can be any other type of vehicle. The vehicle <b>502</b> may be the vehicle <b>102</b> depicted in <figref idref="DRAWINGS">FIGS. <b>1</b>A, <b>1</b>B, and <b>2</b></figref> and/or the vehicles depicted in <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref>.</p><p id="p-0041" num="0034">The vehicle <b>502</b> can be a driverless vehicle, such as an autonomous vehicle configured to operate according to a Level <b>5</b> classification issued by the U.S. National Highway Traffic Safety Administration, which describes a vehicle capable of performing all safety-critical functions for the entire trip, with the driver (or occupant) not being expected to control the vehicle at any time. In such examples, because the vehicle <b>502</b> can be configured to control all functions from start to completion of the trip, including all parking functions, it may not include a driver and/or controls for driving the vehicle <b>502</b>, such as a steering wheel, an acceleration pedal, and/or a brake pedal. This is merely an example, and the systems and methods described herein may be incorporated into any ground-borne, airborne, or waterborne vehicle, including those ranging from vehicles that need to be manually controlled by a driver at all times, to those that are partially or fully autonomously controlled.</p><p id="p-0042" num="0035">The vehicle <b>502</b> can include one or more computing device(s) <b>504</b>, one or more sensor system(s) <b>506</b>, one or more emitter(s) <b>508</b>, one or more communication connection(s) <b>510</b> (also referred to as communication devices and/or modems), at least one direct connection <b>512</b> (e.g., for physically coupling with the vehicle <b>502</b> to exchange data and/or to provide power), and one or more drive system(s) <b>514</b>. The one or more sensor system(s) <b>506</b> can be configured to capture sensor data associated with an environment.</p><p id="p-0043" num="0036">The one or more sensor system(s) <b>506</b> can include time-of-flight sensors, location sensors (e.g., GPS, compass, etc.), inertial sensors (e.g., sensor <b>124</b> including inertial measurement units (IMUs), accelerometers, magnetometers, gyroscopes, etc.), lidar sensors, radar sensors, sonar sensors, infrared sensors, cameras (e.g., RGB, IR, intensity, depth, etc.), microphone sensors, environmental sensors (e.g., temperature sensors, humidity sensors, light sensors, pressure sensors, etc.), ultrasonic transducers, wheel encoders (e.g., <b>126</b><i>a</i>-<b>126</b><i>d</i>), ball joint sensors, chassis position sensors, etc. The one or more sensor system(s) <b>506</b> can include multiple instances of each of these or other types of sensors. For instance, the time-of-flight sensors can include individual time-of-flight sensors located at the corners, front, back, sides, and/or top of the vehicle <b>502</b>. As another example, the camera sensors can include multiple cameras disposed at various locations about the exterior and/or interior of the vehicle <b>502</b>. The one or more sensor system(s) <b>506</b> can provide input to the computing device <b>504</b>.</p><p id="p-0044" num="0037">The vehicle <b>502</b> can also include one or more emitter(s) <b>508</b> for emitting light and/or sound. The one or more emitter(s) <b>508</b> in this example include interior audio and visual emitters to communicate with passengers of the vehicle <b>502</b>. By way of example and not limitation, interior emitters can include speakers, lights, signs, display screens, touch screens, haptic emitters (e.g., vibration and/or force feedback), mechanical actuators (e.g., seatbelt tensioners, seat positioners, headrest positioners, etc.), and the like. The one or more emitter(s) <b>508</b> in this example also include exterior emitters. By way of example and not limitation, the exterior emitters in this example include lights to signal a direction of travel or other indicator of vehicle action (e.g., indicator lights, signs, light arrays, etc.), and one or more audio emitters (e.g., speakers, speaker arrays, horns, etc.) to audibly communicate with pedestrians or other nearby vehicles, one or more of which may comprise acoustic beam steering technology.</p><p id="p-0045" num="0038">The vehicle <b>502</b> can also include one or more communication connection(s) <b>510</b> that enable communication between the vehicle <b>502</b> and one or more other local or remote computing device(s) (e.g., a remote teleoperation computing device) or remote services. For instance, the one or more communication connection(s) <b>510</b> can facilitate communication with other local computing device(s) on the vehicle <b>502</b> and/or the one or more drive system(s) <b>514</b>. Also, the one or more communication connection(s) <b>510</b> can allow the vehicle <b>502</b> to communicate with other nearby computing device(s) (e.g., other nearby vehicles, traffic signals, etc.).</p><p id="p-0046" num="0039">The one or more communications connection(s) <b>510</b> can include physical and/or logical interfaces for connecting the computing device <b>504</b> to another computing device or one or more external networks <b>542</b> (e.g., the Internet). For example, the one or more communications connection(s) <b>510</b> can enable Wi-Fi-based communication such as via frequencies defined by the IEEE 802.11 standards, short range wireless frequencies such as Bluetooth, cellular communication (e.g., 2G, 3G, 4G, 4G LTE, 5G, etc.), satellite communication, dedicated short-range communications (DSRC), or any suitable wired or wireless communications protocol that enables the respective computing device to interface with the other computing device(s).</p><p id="p-0047" num="0040">In at least one example, the vehicle <b>502</b> can include one or more drive system(s) <b>514</b>. In some examples, the vehicle <b>502</b> can have a single drive system <b>514</b>. In at least one example, if the vehicle <b>502</b> has multiple drive systems <b>514</b>, individual drive systems <b>514</b> can be positioned on opposite ends of the vehicle <b>502</b> (e.g., the front and the rear, etc.). In at least one example, the drive system(s) <b>514</b> can include one or more sensor system(s) <b>506</b> to detect conditions of the drive system(s) <b>514</b> and/or the surroundings of the vehicle <b>502</b>. By way of example and not limitation, the sensor system(s) <b>506</b> can include one or more wheel encoders (e.g., rotary encoders) to sense rotation of the wheels of the drive systems, inertial sensors (e.g., inertial measurement units, accelerometers, gyroscopes, magnetometers, etc.) to measure orientation and acceleration of the drive system, cameras or other image sensors, ultrasonic sensors to acoustically detect objects in the surroundings of the drive system, lidar sensors, radar sensors, etc. Some sensors, such as the wheel encoders can be unique to the drive system(s) <b>514</b>. In some cases, the sensor system(s) <b>506</b> on the drive system(s) <b>514</b> can overlap or supplement corresponding systems of the vehicle <b>502</b> (e.g., sensor system(s) <b>506</b>). The drive system(s) <b>514</b> may also include one or more steering motors (e.g., <b>128</b>), steering motor sensors (e.g., <b>132</b>), and steering racks (e.g., <b>130</b>).</p><p id="p-0048" num="0041">The drive system(s) <b>514</b> can include many of the vehicle systems, including a high voltage battery, a motor to propel the vehicle, an inverter to convert direct current from the battery into alternating current for use by other vehicle systems, a steering system including a steering motor and steering rack (which can be electric), a braking system including hydraulic or electric actuators, a suspension system including hydraulic and/or pneumatic components, a stability control system for distributing brake forces to mitigate loss of traction and maintain control, an HVAC system, lighting (e.g., lighting such as head/tail lights to illuminate an exterior surrounding of the vehicle), and one or more other systems (e.g., cooling system, safety systems, onboard charging system, other electrical components such as a DC/DC converter, a high voltage junction, a high voltage cable, charging system, charge port, etc.). Additionally, the drive system(s) <b>514</b> can include a drive system controller which can receive and preprocess data from the sensor system(s) <b>506</b> and to control operation of the various vehicle systems. In some examples, the drive system controller can include one or more processor(s) and memory communicatively coupled with the one or more processor(s). The memory can store one or more components to perform various functionalities of the drive system(s) <b>514</b>. Furthermore, the drive system(s) <b>514</b> also include one or more communication connection(s) that enable communication by the respective drive system with one or more other local or remote computing device(s).</p><p id="p-0049" num="0042">The computing device <b>504</b> can include one or more processor(s) <b>516</b> and memory <b>518</b> communicatively coupled with the one or more processor(s) <b>516</b>. In the illustrated example, the memory <b>518</b> of the computing device <b>504</b> stores a perception component <b>520</b>, a localization component <b>524</b>, a command angle monitor <b>530</b>, a prediction component <b>534</b>, a planning component <b>536</b>, a maps component <b>538</b>, and one or more system controller(s) <b>540</b>. Though depicted as residing in the memory <b>518</b> for illustrative purposes, it is contemplated that the perception component <b>520</b>, the localization component <b>524</b>, the command angle monitor <b>530</b>, the prediction component <b>534</b>, the planning component <b>536</b>, the maps component <b>538</b>, and the one or more system controller(s) <b>540</b> can additionally, or alternatively, be accessible to the computing device <b>504</b> (e.g., stored in a different component of vehicle <b>502</b>) and/or be accessible to the vehicle <b>502</b> (e.g., stored remotely).</p><p id="p-0050" num="0043">The perception component <b>520</b> can include functionality to perform object detection, segmentation, and/or classification. In some examples, the perception component <b>520</b> and/or the object detector <b>522</b> can provide processed sensor data that indicates a presence of an entity that is proximate to the vehicle <b>502</b> and/or a classification of the entity as an entity type (e.g., car, pedestrian, cyclist, building, tree, road surface, curb, sidewalk, unknown, etc.). In additional and/or alternative examples, the perception component <b>520</b> can provide processed sensor data that indicates one or more characteristics associated with a detected entity and/or the environment in which the entity is positioned. In some examples, characteristics associated with an entity can include, but are not limited to, an x-position (global position), a y-position (global position), a z-position (global position), an orientation, an entity type (e.g., a classification), a velocity of the entity, an extent of the entity (size), etc. Characteristics associated with the environment can include, but are not limited to, a presence of another entity in the environment, a state of another entity in the environment, a time of day, a day of a week, a season, a weather condition, an indication of darkness/light, etc. In one example, the perception component <b>520</b> may detect a ground surface and determine a ride height based on sensor data.</p><p id="p-0051" num="0044">Further, the perception component <b>520</b> can include functionality to store perception data generated by the perception component <b>520</b>. In some instances, the perception component <b>520</b> can determine a track corresponding to an object that has been classified as an object type. For purposes of illustration only, the perception component <b>520</b>, using sensor system(s) <b>506</b> can capture one or more images of an environment, which may be used to determine information about an environment.</p><p id="p-0052" num="0045">The stored perception data can, in some examples, include fused perception data captured by the vehicle. Fused perception data can include a fusion or other combination of sensor data from sensor system(s) <b>506</b>, such as image sensors, lidar sensors, radar sensors, time-of-flight sensors, sonar sensors, global positioning system sensors, internal sensors, and/or any combination of these. The stored perception data can additionally or alternatively include classification data including semantic classifications of objects (e.g., pedestrians, vehicles, buildings, road surfaces, etc.) represented in the sensor data. The stored perception data can additionally or alternatively include track data (positions, orientations, sensor features, etc.) corresponding to motion of objects classified as dynamic objects through the environment. The track data can include multiple tracks of multiple different objects over time. This track data can be mined to identify images of certain types of objects (e.g., pedestrians, animals, etc.) at times when the object is stationary (e.g., standing still) or moving (e.g., walking, running, etc.). In this example, the computing device determines a track corresponding to a pedestrian.</p><p id="p-0053" num="0046">In general, the object detector <b>522</b> can detect (among other things) semantic objects represented by sensor data. In some examples, the object detector <b>522</b> can identify such semantic objects and can determine a two-dimensional or a three-dimensional bounding box associated with the object. The object detector <b>522</b> can determine additional information such as a location, orientation, pose, and/or size (e.g., length, width, height, etc.) associated with the object. The object detector <b>522</b> can send data to other components of the system <b>500</b> for localization and/or determining calibration information, as discussed herein.</p><p id="p-0054" num="0047">The localization component <b>524</b> can include functionality to receive data from the sensor system(s) <b>506</b> and/or other components to determine a position of the vehicle <b>502</b>. For example, the localization component <b>524</b> can include and/or request/receive a three-dimensional map of an environment and can continuously determine a location of the autonomous vehicle within the map. In some instances, the localization component <b>524</b> can use SLAM (simultaneous localization and mapping) or CLAMS (calibration, localization and mapping, simultaneously) to receive time-of-flight data, image data, lidar data, radar data, sonar data, IMU data, GPS data, wheel encoder data, or any combination thereof, and the like to accurately determine a location of the autonomous vehicle. In some instances, the localization component <b>524</b> can provide data to various components of the vehicle <b>502</b> to determine an initial position of an autonomous vehicle for generating a trajectory or for initial calibration. In examples of this disclosure, the localization component <b>524</b> may determine a position of the vehicle <b>502</b> based on the estimated command angle derived from non-steering variables. That is, the estimated command angle derived from non-steering variables may be directly used to determine position and/or may be used to validate other information (e.g., measured command angle) for determining position.</p><p id="p-0055" num="0048">The command angle monitor <b>530</b> may determine command angles for wheels of the vehicle <b>502</b>. For example, the command angle monitor <b>530</b> may communicate with (or receive data provided by) the sensor system(s) (e.g., yaw rate sensor, wheel encoder, steering sensor, etc.), and, based on data from the sensor system(s) determine an estimated command angle using Equation 5 and determine a measured command angle (e.g., from the steering components). The command angle monitor <b>530</b> may communicate the estimated command angle(s) to other systems (e.g., localization <b>524</b>) or may use the estimated command angle to validate a measured command angles. The command angle monitor <b>530</b> may include (or interface with) a steering component <b>537</b> for determining steering data, such as a rack travel distance, steering motor rotation, etc. In some examples, the command angle monitor <b>530</b> may compare an estimated command angle to a measured command angle, and if the difference (e.g., variance) exceed a threshold, may trigger a slip event or communicate the difference (e.g., variance) in a manner that down weights the measured command angle. Furthermore, the command angle monitor <b>530</b> may also execute other operations described in this disclosure, including those described with respect to <figref idref="DRAWINGS">FIGS. <b>1</b>A, <b>1</b>B, and <b>2</b>-<b>4</b></figref>.</p><p id="p-0056" num="0049">The prediction component <b>534</b> can generate one or more probability maps representing prediction probabilities of possible locations of one or more objects in an environment. For example, the prediction component <b>534</b> can generate one or more probability maps for vehicles, pedestrians, animals, and the like within a threshold distance from the vehicle <b>502</b>. In some instances, the prediction component <b>534</b> can measure a track of an object and generate a discretized prediction probability map, a heat map, a probability distribution, a discretized probability distribution, and/or a trajectory for the object based on observed and predicted behavior. In some instances, the one or more probability maps can represent an intent of the one or more objects in the environment.</p><p id="p-0057" num="0050">The planning component <b>536</b> can determine a path for the vehicle <b>502</b> to follow to traverse through an environment. For example, the planning component <b>536</b> can determine various routes and paths and various levels of detail. In some instances, the planning component <b>536</b> can determine a route to travel from a first location (e.g., a current location) to a second location (e.g., a target location). For the purpose of this discussion, a route can be a sequence of waypoints for traveling between two locations. As non-limiting examples, waypoints include streets, intersections, global positioning system (GPS) coordinates, etc. Further, the planning component <b>536</b> can generate an instruction for guiding the autonomous vehicle along at least a portion of the route from the first location to the second location. In at least one example, the planning component <b>536</b> can determine how to guide the autonomous vehicle from a first waypoint in the sequence of waypoints to a second waypoint in the sequence of waypoints. In some examples, the instruction can be a path, or a portion of a path. In some examples, multiple paths can be substantially simultaneously generated (i.e., within technical tolerances) in accordance with a receding horizon technique. A single path of the multiple paths in a receding data horizon having the highest confidence level may be selected to operate the vehicle.</p><p id="p-0058" num="0051">In other examples, the planning component <b>536</b> can alternatively, or additionally, use data from the perception component <b>520</b> and/or the prediction component <b>534</b> to determine a path for the vehicle <b>502</b> to follow to traverse through an environment. For example, the planning component <b>536</b> can receive data from the perception component <b>520</b> and/or the prediction component <b>534</b> regarding objects associated with an environment. Using this data, the planning component <b>536</b> can determine a route to travel from a first location (e.g., a current location) to a second location (e.g., a target location) to avoid objects in an environment. In at least some examples, such a planning component <b>536</b> may determine there is no such collision free path and, in turn, provide a path which brings vehicle <b>502</b> to a safe stop avoiding all collisions and/or otherwise mitigating damage.</p><p id="p-0059" num="0052">The memory <b>518</b> can further include a maps component <b>538</b> that can be used by the vehicle <b>502</b> to navigate within the environment. For the purpose of this discussion, a map can be any number of data structures modeled in two dimensions, three dimensions, or N-dimensions that are capable of providing information about an environment, such as, but not limited to, topologies (such as intersections), streets, mountain ranges, roads, terrain, and the environment in general. A map can further include an object identifier, an object classification, a three-dimensional location, covariance data (e.g., represented in image data or a multi-resolution voxel space), and the like. In some instances, a map can include, but is not limited to: texture information (e.g., color information (e.g., RGB color information, Lab color information, HSV/HSL color information), and the like), intensity information (e.g., LIDAR information, RADAR information, and the like); spatial information (e.g., image data projected onto a mesh, individual &#x201c;surfels&#x201d; (e.g., polygons associated with individual color and/or intensity)), reflectivity information (e.g., specularity information, retroreflectivity information, BRDF information, BSSRDF information, and the like). In one example, a map can include a three-dimensional mesh of the environment. In some instances, the map can be stored in a tiled format, such that individual tiles of the map represent a discrete portion of an environment, and can be loaded into working memory as needed, as discussed herein. In at least one example, the one or more maps <b>538</b> can include at least one map (e.g., images and/or a mesh). In some examples, the vehicle <b>502</b> can be controlled based at least in part on the map(s) component <b>538</b>. That is, the map(s) component <b>538</b> can be used in connection with the perception component <b>520</b> (and sub-components), the localization component <b>524</b> (and sub-components), the prediction component <b>534</b>, and/or the planning component <b>536</b> to determine a location of the vehicle <b>502</b>, identify objects in an environment, generate prediction probabilit(ies) associated with objects and/or the vehicle <b>502</b>, and/or generate routes and/or trajectories to navigate within an environment.</p><p id="p-0060" num="0053">In at least one example, the computing device <b>504</b> can include one or more system controller(s) <b>540</b>, which can be configured to control steering, propulsion, braking, safety, emitters, communication, and other systems of the vehicle <b>502</b>. These system controller(s) <b>540</b> can communicate with and/or control corresponding systems of the drive system(s) <b>514</b> and/or other components of the vehicle <b>502</b>, which may be configured to operate in accordance with a path provided from the planning component <b>536</b>.</p><p id="p-0061" num="0054">The vehicle <b>502</b> can connect to computing device(s) <b>544</b> via network <b>542</b> and can include one or more processor(s) <b>546</b> and memory <b>548</b> communicatively coupled with the one or more processor(s) <b>546</b>. In at least one instance, the one or more processor(s) <b>546</b> can be similar to the processor(s) <b>516</b> and the memory <b>548</b> can be similar to the memory <b>518</b>. In the illustrated example, the memory <b>548</b> of the computing device(s) <b>544</b> stores a remote operation component <b>550</b> and/or a model component <b>552</b>. In at least one instance, the model component <b>552</b>, after empirical testing and/or simulations, can include the models for determining a location and/or determining a calibration parameter, as discussed herein. Though depicted as residing in the memory <b>548</b> for illustrative purposes, it is contemplated that the remote operation component <b>550</b> and the model component <b>552</b> can additionally, or alternatively, be accessible to the computing device(s) <b>544</b> (e.g., stored in a different component of computing device(s) <b>544</b> and/or be accessible to the computing device(s) <b>544</b> (e.g., stored remotely).</p><p id="p-0062" num="0055">The remote operation component <b>550</b> can include functionality to receive an indication of wheel-slip events, vehicle-skid events, steering-component slippage, and/or a request for preventative maintenance (e.g., based on a difference (e.g., variance) between estimated and measured command angles). In some examples, the remote operation component <b>550</b> can schedule a maintenance operation based on a command angle difference (e.g., variance) or a determination by the vehicle <b>502</b> that a difference is indicative of a degraded state (e.g., when steering data is inconsistent with estimated command angle data). In some examples, a remote operation component <b>550</b> can include teleoperators or operators who can control the vehicle <b>502</b> or can provide instructions to the vehicle based on a skid event (e.g., where a vehicle skid event suggest a loss of control).</p><p id="p-0063" num="0056">The model component <b>552</b> can include functionality to generate models for determining a location and/or determine slip or skid events, as discussed herein. For example, the model component <b>552</b> can receive sensor data and can determine command angles associated with such sensor data. The model component <b>552</b> can aggregate data across a plurality of vehicles (e.g., a fleet of vehicles) to determine command angle variances indicative of normal operations and command angle variances indicative of degraded operations. Further, the model component <b>552</b> can associate a command angle variance with a time period of operating a sensor and a performance of components associated with such metrics to determine a predictive maintenance schedule associated with various sensors, as discussed herein.</p><p id="p-0064" num="0057">The processor(s) <b>516</b> of the computing device <b>504</b> and the processor(s) <b>546</b> of the computing device(s) <b>544</b> can be any suitable processor capable of executing instructions to process data and perform operations as described herein. By way of example and not limitation, the processor(s) <b>516</b> and <b>546</b> can comprise one or more Central Processing Units (CPUs), Graphics Processing Units (GPUs), or any other device or portion of a device that processes electronic data to transform that electronic data into other electronic data that can be stored in registers and/or memory. In some examples, integrated circuits (e.g., ASICs, etc.), gate arrays (e.g., FPGAs, etc.), and other hardware devices can also be considered processors in so far as they are configured to implement encoded instructions.</p><p id="p-0065" num="0058">The memory <b>518</b> computing device <b>504</b> and the memory <b>548</b> of the computing device(s) <b>544</b> are examples of non-transitory computer-readable media. The memory <b>518</b> and <b>548</b> can store an operating system and one or more software applications, instructions, programs, and/or data to implement the methods described herein and the functions attributed to the various systems. In various implementations, the memory <b>518</b> and <b>548</b> can be implemented using any suitable memory technology, such as static random access memory (SRAM), synchronous dynamic RAM (SDRAM), nonvolatile/Flash-type memory, or any other type of memory capable of storing information. The architectures, systems, and individual elements described herein can include many other logical, programmatic, and physical components, of which those shown in the accompanying figures are merely examples that are related to the discussion herein.</p><p id="p-0066" num="0059">In some instances, aspects of some or all of the components discussed herein can include any models, algorithms, and/or machine-learning algorithms. For example, in some instances, the components in the memory <b>518</b> and <b>548</b> can be implemented as a neural network. In some examples, a machine learned model could be trained to determine an estimated command angle, slip event, skid event, or other condition of the vehicle based on sensor data received from the yaw rate sensor, encoder, steering sensor, etc.</p><p id="p-0067" num="0060">As described herein, an exemplary neural network is a biologically inspired algorithm which passes input data through a series of connected layers to produce an output. Each layer in a neural network can also comprise another neural network, or can comprise any number of layers (whether convolutional or not). As can be understood in the context of this disclosure, a neural network can utilize machine learning, which can refer to a broad class of such algorithms in which an output is generated based on learned parameters.</p><p id="p-0068" num="0061">Although discussed in the context of neural networks, any type of machine learning can be used consistent with this disclosure. For example, machine learning or machine-learned algorithms can include, but are not limited to, regression algorithms (e.g., ordinary least squares regression (OLSR), linear regression, logistic regression, stepwise regression, multivariate adaptive regression splines (MARS), locally estimated scatterplot smoothing (LOESS)), instance-based algorithms (e.g., ridge regression, least absolute shrinkage and selection operator (LASSO), elastic net, least-angle regression (LARS)), decisions tree algorithms (e.g., classification and regression tree (CART), iterative dichotomiser 3 (ID3), Chi-squared automatic interaction detection (CHAID), decision stump, conditional decision trees), Bayesian algorithms (e.g., na&#xef;ve Bayes, Gaussian na&#xef;ve Bayes, multinomial na&#xef;ve Bayes, average one-dependence estimators (AODE), Bayesian belief network (BNN), Bayesian networks), clustering algorithms (e.g., k-means, k-medians, expectation maximization (EM), hierarchical clustering), association rule learning algorithms (e.g., perceptron, back-propagation, hopfield network, Radial Basis Function Network (RBFN)), deep learning algorithms (e.g., Deep Boltzmann Machine (DBM), Deep Belief Networks (DBN), Convolutional Neural Network (CNN), Stacked Auto-Encoders), Dimensionality Reduction Algorithms (e.g., Principal Component Analysis (PCA), Principal Component Regression (PCR), Partial Least Squares Regression (PLSR), Sammon Mapping, Multidimensional Scaling (MDS), Projection Pursuit, Linear Discriminant Analysis (LDA), Mixture Discriminant Analysis (MDA), Quadratic Discriminant Analysis (QDA), Flexible Discriminant Analysis (FDA)), Ensemble Algorithms (e.g., Boosting, Bootstrapped Aggregation (Bagging), AdaBoost, Stacked Generalization (blending), Gradient Boosting Machines (GBM), Gradient Boosted Regression Trees (GBRT), Random Forest), SVM (support vector machine), supervised learning, unsupervised learning, semi-supervised learning, etc.</p><p id="p-0069" num="0062">Additional examples of architectures include neural networks such as ResNet50, ResNet101, VGG, DenseNet, PointNet, and the like.</p><p id="p-0070" num="0063">As described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>5</b></figref>, techniques described herein can be useful for using a set of non-steering variables to estimate a command angle of a wheel. As described, a yaw rate, a wheel speed, and vehicle dimensions, can be used to estimate the command angle of the wheel. Among other things, command angles based on non-steering variables may provide redundancy (e.g., when determined in parallel with (in addition to) steering-based command angles) and validation and may be less susceptible to inaccuracies from steering-component slippage and loss of tire traction.</p><heading id="h-0004" level="1">Example Clauses</heading><p id="p-0071" num="0064">Clause A: A system comprising: one or more processors; and one or more non-transitory computer-readable media storing instructions executable by the one or more processors, wherein the instructions, when executed, cause the system to perform operations comprising: determining a trajectory for a vehicle to follow to navigate a turn maneuver, the trajectory comprising a commanded angle of a wheel of the vehicle, wherein the turn maneuver comprises a turn center; determining, based at least in part on first sensor data from a first sensor, a yaw rate of the vehicle during the turn maneuver; determining, based at least in part on second sensor data associated with a second sensor, a linear velocity of the vehicle at the wheel of the vehicle during the turn maneuver; determining, based at least in part on the yaw rate, the linear velocity, and an offset distance, an estimated angle of the wheel, the offset distance defining a distance which extends from the wheel and to a position aligned with the turn center; and controlling an operation of the vehicle based at least in part on a difference between the commanded angle of the wheel and the estimated angle of the wheel.</p><p id="p-0072" num="0065">Clause B: The system of clause A, wherein controlling the operation of the vehicle comprises: determining that the difference between the commanded angle and the estimated angle exceeds a threshold; and detecting, based on the difference exceeding the threshold, one or more of a wheel-slip event, a vehicle-skid event, or steering-component slippage; and wherein controlling the operation of the vehicle is based at least in part on detecting the one or more of the wheel-slip event, the vehicle-skid event, or the steering-component slippage.</p><p id="p-0073" num="0066">Clause C: The system of clause A or B, wherein controlling the operation of the vehicle comprises: determining that the difference between the commanded angle and the estimated angle exceeds a threshold; and determining, based on the estimated angle, a relative position of the vehicle resulting from the turn maneuver.</p><p id="p-0074" num="0067">Clause D: The system of any of clauses A-C, wherein the position is aligned with a rear axle of the vehicle.</p><p id="p-0075" num="0068">Clause E: The system of any of clauses A-D, wherein the operations further comprise determining the commanded angle based at least in part on at least one of a steering rack travel or a steering motor rotation.</p><p id="p-0076" num="0069">Clause F: A method comprising: determining, based at least in part on first sensor data associated with a first sensor, a velocity of a wheel of a vehicle; determining, based at least in part on second sensor data associated with a second sensor, a yaw rate of the vehicle; determining, based at least in part on the velocity, an offset distance, and the yaw rate, an estimated angle of the wheel, the offset distance defining a distance which extends at least a portion of a length between a rear axle and a front axle of the vehicle; and controlling, based at least in part on the estimated angle, an operation of the vehicle.</p><p id="p-0077" num="0070">Clause G: The method of clause F further comprising: determining a commanded angle based at least in part on at least one of: a steering rack travel; or a steering motor rotation, wherein the controlling the operation of the vehicle is further based at least in part on the commanded angle.</p><p id="p-0078" num="0071">Clause H: The method of clause F or G, wherein the velocity of the wheel is based at least in part on a common velocity of the vehicle.</p><p id="p-0079" num="0072">Clause I: The method of any of clauses F-H further comprising, determining that a difference between the estimated angle and a commanded angle exceeds a threshold, and determining, based at least in part on the estimated angle, a relative position of the vehicle, wherein the controlling is based at least in part on the relative position.</p><p id="p-0080" num="0073">Clause J: The method of any of clauses F-I further comprising: determining a commanded angle based at least in part on a trajectory of the vehicle, wherein the controlling the operation of the vehicle is further based at least in part on the commanded angle.</p><p id="p-0081" num="0074">Clause K: The method of any of clauses F-J, further comprising: determining, based at least in part on a least squares algorithm that includes the estimated angle, a velocity of the vehicle, wherein the controlling the operation of the vehicle is based at least in part on the velocity of the vehicle.</p><p id="p-0082" num="0075">Clause L: The method of any of clauses F-K further comprising: determining a difference between the estimated angle and a commanded angle; and augmenting, based at least in part on the difference, the operation of the vehicle.</p><p id="p-0083" num="0076">Clause M: The method of any of clauses F-L, wherein the offset distance is measured from the wheel to a position aligned with a midpoint between the rear axle and the front axle.</p><p id="p-0084" num="0077">Clause N: One or more non-transitory computer-readable media storing instructions that, when executed, cause one or more processors to perform operations comprising: determining, based at least in part on first sensor data associated with a first sensor, a velocity of a wheel of a vehicle; determining, based at least in part on second sensor data associated with a second sensor, a yaw rate of the vehicle; determining, based at least in part on the velocity, an offset distance, and the yaw rate, an estimated angle of the wheel, the offset distance defining a distance which extends at least a portion of a length between a rear axle and a front axle of the vehicle; and controlling, based at least in part on the estimated angle, an operation of the vehicle.</p><p id="p-0085" num="0078">Clause O: The one or more non-transitory computer-readable media of clause N, wherein the operations further comprise: determining a commanded angle based at least in part on at least one of: a steering rack travel; or a steering motor rotation, wherein the controlling the operation of the vehicle is further based at least in part on the commanded angle.</p><p id="p-0086" num="0079">Clause P: The one or more non-transitory computer-readable media of clause N or O, wherein the velocity of the wheel is based at least in part on a common velocity of the vehicle</p><p id="p-0087" num="0080">Clause Q: The one or more non-transitory computer-readable media of any of clauses N-P, wherein the operations further comprise: determining, based on the estimated angle, a relative position of the vehicle, wherein the controlling is based at least in part on the relative position.</p><p id="p-0088" num="0081">Clause R: The one or more non-transitory computer-readable media of any of clauses N-Q, wherein the operations further comprise: determining a commanded angle based at least in part on a trajectory of the vehicle, wherein the controlling the operation of the vehicle is further based at least in part on the commanded angle.</p><p id="p-0089" num="0082">Clause S: The one or more non-transitory computer-readable media of any of clauses N-R, wherein the operations further comprise: determining a difference between the estimated angle and a commanded angle; and augmenting, based at least in part on the difference, the operation of the vehicle.</p><p id="p-0090" num="0083">Clause T: The one or more non-transitory computer-readable media of any of clauses N-S, the operations further comprising: determining, based at least in part on a least squares algorithm that includes the estimated angle, a velocity of the vehicle, wherein the controlling the operation of the vehicle is based at least in part on the velocity of the vehicle.</p><p id="p-0091" num="0084">While the example clauses described above are described with respect to one particular implementation, it should be understood that, in the context of this document, the content of the example clauses may also be implemented via a method, device, system, a computer-readable medium, and/or another implementation. Additionally, any of examples A-T may be implemented alone or in combination with any other one or more of the examples A-T.</p><heading id="h-0005" level="1">CONCLUSION</heading><p id="p-0092" num="0085">While one or more examples of the techniques described herein have been described, various alterations, additions, permutations and equivalents thereof are included within the scope of the techniques described herein.</p><p id="p-0093" num="0086">In the description of examples, reference is made to the accompanying drawings that form a part hereof, which show by way of illustration specific examples of the claimed subject matter. It is to be understood that other examples can be used and that changes or alterations, such as structural changes, can be made. Such examples, changes or alterations are not necessarily departures from the scope with respect to the intended claimed subject matter. While the steps herein can be presented in a certain order, in some cases the ordering can be changed so that certain inputs are provided at different times or in a different order without changing the function of the systems and methods described. The disclosed procedures could also be executed in different orders. Additionally, various computations that are herein need not be performed in the order disclosed, and other examples using alternative orderings of the computations could be readily implemented. In addition to being reordered, the computations could also be decomposed into sub-computations with the same results.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system comprising:<claim-text>one or more processors; and</claim-text><claim-text>one or more non-transitory computer-readable media storing instructions executable by the one or more processors, wherein the instructions, when executed, cause the system to perform operations comprising:<claim-text>determining a trajectory for a vehicle to follow to navigate a turn maneuver, the trajectory comprising a commanded angle of a wheel of the vehicle, wherein the turn maneuver comprises a turn center;</claim-text><claim-text>determining, based at least in part on first sensor data from a first sensor, a yaw rate of the vehicle during the turn maneuver;</claim-text><claim-text>determining, based at least in part on second sensor data associated with a second sensor, a linear velocity of the vehicle at the wheel of the vehicle during the turn maneuver;</claim-text><claim-text>determining, based at least in part on the yaw rate, the linear velocity, and an offset distance, an estimated angle of the wheel, the offset distance defining a distance which extends from the wheel and to a position aligned with the turn center; and</claim-text><claim-text>controlling an operation of the vehicle based at least in part on a difference between the commanded angle of the wheel and the estimated angle of the wheel.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein controlling the operation of the vehicle comprises:<claim-text>determining that the difference between the commanded angle and the estimated angle exceeds a threshold; and</claim-text><claim-text>detecting, based on the difference exceeding the threshold, one or more of a wheel-slip event, a vehicle-skid event, or steering-component slippage; and</claim-text><claim-text>wherein controlling the operation of the vehicle is based at least in part on detecting the one or more of the wheel-slip event, the vehicle-skid event, or the steering-component slippage.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein controlling the operation of the vehicle comprises:<claim-text>determining that the difference between the commanded angle and the estimated angle exceeds a threshold; and</claim-text><claim-text>determining, based on the estimated angle, a relative position of the vehicle resulting from the turn maneuver.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the position is aligned with a rear axle of the vehicle.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the operations further comprise determining the commanded angle based at least in part on at least one of a steering rack travel or a steering motor rotation.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. A method comprising:<claim-text>determining, based at least in part on first sensor data associated with a first sensor, a velocity of a wheel of a vehicle;</claim-text><claim-text>determining, based at least in part on second sensor data associated with a second sensor, a yaw rate of the vehicle;</claim-text><claim-text>determining, based at least in part on the velocity, an offset distance, and the yaw rate, an estimated angle of the wheel, the offset distance defining a distance which extends at least a portion of a length between a rear axle and a front axle of the vehicle; and</claim-text><claim-text>controlling, based at least in part on the estimated angle, an operation of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref> further comprising:<claim-text>determining a commanded angle based at least in part on at least one of:<claim-text>a steering rack travel; or</claim-text><claim-text>a steering motor rotation,</claim-text><claim-text>wherein the controlling the operation of the vehicle is further based at least in part on the commanded angle.</claim-text></claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the velocity of the wheel is based at least in part on a common velocity of the vehicle.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref> further comprising,<claim-text>determining that a difference between the estimated angle and a commanded angle exceeds a threshold, and</claim-text><claim-text>determining, based at least in part on the estimated angle, a relative position of the vehicle, wherein the controlling is based at least in part on the relative position.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref> further comprising:<claim-text>determining a commanded angle based at least in part on a trajectory of the vehicle, wherein the controlling the operation of the vehicle is further based at least in part on the commanded angle.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising:<claim-text>determining, based at least in part on a least squares algorithm that includes the estimated angle, a velocity of the vehicle, wherein the controlling the operation of the vehicle is based at least in part on the velocity of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref> further comprising:<claim-text>determining a difference between the estimated angle and a commanded angle; and</claim-text><claim-text>augmenting, based at least in part on the difference, the operation of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the offset distance is measured from the wheel to a position aligned with a midpoint between the rear axle and the front axle.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. One or more non-transitory computer-readable media storing instructions that, when executed, cause one or more processors to perform operations comprising:<claim-text>determining, based at least in part on first sensor data associated with a first sensor, a velocity of a wheel of a vehicle;</claim-text><claim-text>determining, based at least in part on second sensor data associated with a second sensor, a yaw rate of the vehicle;</claim-text><claim-text>determining, based at least in part on the velocity, an offset distance, and the yaw rate, an estimated angle of the wheel, the offset distance defining a distance which extends at least a portion of a length between a rear axle and a front axle of the vehicle; and</claim-text><claim-text>controlling, based at least in part on the estimated angle, an operation of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The one or more non-transitory computer-readable media of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the operations further comprise:<claim-text>determining a commanded angle based at least in part on at least one of:<claim-text>a steering rack travel; or</claim-text><claim-text>a steering motor rotation,</claim-text><claim-text>wherein the controlling the operation of the vehicle is further based at least in part on the commanded angle.</claim-text></claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The one or more non-transitory computer-readable media of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the velocity of the wheel is based at least in part on a common velocity of the vehicle</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The one or more non-transitory computer-readable media of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the operations further comprise:<claim-text>determining, based on the estimated angle, a relative position of the vehicle, wherein the controlling is based at least in part on the relative position.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The one or more non-transitory computer-readable media of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the operations further comprise:<claim-text>determining a commanded angle based at least in part on a trajectory of the vehicle, wherein the controlling the operation of the vehicle is further based at least in part on the commanded angle.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The one or more non-transitory computer-readable media of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the operations further comprise:<claim-text>determining a difference between the estimated angle and a commanded angle; and</claim-text><claim-text>augmenting, based at least in part on the difference, the operation of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The one or more non-transitory computer-readable media of <claim-ref idref="CLM-00014">claim 14</claim-ref>, the operations further comprising:<claim-text>determining, based at least in part on a least squares algorithm that includes the estimated angle, a velocity of the vehicle, wherein the controlling the operation of the vehicle is based at least in part on the velocity of the vehicle.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005483A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005483</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17805620</doc-number><date>20220606</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>IN</country><doc-number>202111029779</doc-number><date>20210702</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>10</class><subclass>L</subclass><main-group>15</main-group><subgroup>26</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>08</class><subclass>G</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>L</subclass><main-group>15</main-group><subgroup>26</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>08</class><subclass>G</subclass><main-group>5</main-group><subgroup>0013</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">SYSTEM AND METHOD FOR DISPLAYING RADIO COMMUNICATION TRANSCRIPTION</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>HONEYWELL INTERNATIONAL INC.</orgname><address><city>Charlotte</city><state>NC</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Garg</last-name><first-name>Chaya</first-name><address><city>Plymouth</city><state>MN</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Paulraj</last-name><first-name>Vasantha</first-name><address><city>Madurai</city><country>IN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>De Mers</last-name><first-name>Robert</first-name><address><city>Plymouth</city><state>MN</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Burgin</last-name><first-name>Roger</first-name><address><city>Phoenix</city><state>AZ</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Agarwal</last-name><first-name>Jitender Kumar</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>Sampath</last-name><first-name>Mahesh Kumar</first-name><address><city>Madurai</city><country>IN</country></address></addressbook></inventor><inventor sequence="06" designation="us-only"><addressbook><last-name>Thippeswamy</last-name><first-name>Mohan M.</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor><inventor sequence="07" designation="us-only"><addressbook><last-name>Nama</last-name><first-name>Naveen Venkatesh Prasad</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor><inventor sequence="08" designation="us-only"><addressbook><last-name>Pradhan</last-name><first-name>Rahul</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor><inventor sequence="09" designation="us-only"><addressbook><last-name>Sharma</last-name><first-name>Nitish</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>HONEYWELL INTERNATIONAL INC.</orgname><role>02</role><address><city>Charlotte</city><state>NC</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Methods and systems are provided for displaying transcriptions of radio communication transcription for an aircraft. The method comprises capturing audio signals of radio communication traffic to and from the aircraft. The captured audio signals are preprocessed to divide the signals into independent spoken utterances. Each spoken utterance is transcribed using a speech recognition decoder that utilizes an air traffic control (ATC) speech recognition model and classification data is extracted from the transcription of each spoken utterance. The transcription of each spoken utterance is logged with reference to the classification data and a textual display of the transcription is provided to a crew member of the aircraft.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="173.99mm" wi="158.67mm" file="US20230005483A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="163.91mm" wi="168.32mm" file="US20230005483A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="225.98mm" wi="132.25mm" orientation="landscape" file="US20230005483A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="229.70mm" wi="91.61mm" orientation="landscape" file="US20230005483A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="196.68mm" wi="152.40mm" orientation="landscape" file="US20230005483A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="233.76mm" wi="161.63mm" orientation="landscape" file="US20230005483A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="224.28mm" wi="151.89mm" file="US20230005483A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="224.45mm" wi="168.66mm" file="US20230005483A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="224.45mm" wi="151.89mm" file="US20230005483A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="192.36mm" wi="160.70mm" file="US20230005483A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION(S)</heading><p id="p-0002" num="0001">This application claims priority from Indian Provisional Patent Application No. 202111029779, titled &#x201c;SYSTEM AND METHOD FOR DISPLAYING RADIO COMMUNICATION TRANSCRIPTION&#x201d; that was filed Jul. 2, 2021.</p><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present invention generally relates to aircraft communications, and more particularly relates to displaying transcriptions of radio communication transcription for an aircraft.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">In radio transcription systems used by aircraft, voice communications received from an external source as well as initiated by the crew on the aircraft are susceptible to misinterpretation due to noisy environment, noisy medium of communication, regional differences in vocabulary usage, different English language accents, non-standard. phraseology and a high speaking rate. Hence, the availability of the text transcription of voice communication is deemed extremely useful by the crew in the aircraft.</p><p id="p-0005" num="0004">The radio communication channels are not of peer-to-peer communications between aircraft pilots and an air traffic controller (ATC), but instead they are a broadcast transmission. All ATC communications to and from the aircraft and other air traffic tuned to radio frequency are transmitted on the same radio channel. This leads to several issues including auditory overload, call sign confusion and misinterpretation of communicated messages. To address these issues there is a need for mechanisms to alert pilot with a callsign and message intended for the aircraft from ATC. Often a single radio communication is packed with multiple and complex instructions for pilot the including clearances, requests, and commands from an Air Traffic Control Officer (ATCO) which are of critical and important for the pilot to interpret accurately. Hence, there is a need for an efficient, usable, and understandable pilot interface for transcribed radio communications.</p><heading id="h-0004" level="1">BRIEF SUMMARY</heading><p id="p-0006" num="0005">This summary is provided to describe select concepts in a simplified form that are further described in the Detailed Description. This summary is not intended to identify key or essential features of the claimed subject matter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter.</p><p id="p-0007" num="0006">A method is provided for displaying transcriptions of radio communication transcription for an aircraft. The method comprises: capturing audio signals of radio communication traffic to and from the aircraft; preprocessing the captured audio signals to divide the signals into independent spoken utterances; transcribing each spoken utterance using a speech recognition decoder that utilizes an air traffic control (ATC) speech recognition model; extracting classification data from the transcription of each spoken utterance; logging the transcription of each spoken utterance with reference to the classification data; and providing a textual display of the transcription of each spoken utterance to a crew member of the aircraft.</p><p id="p-0008" num="0007">An apparatus is provided for displaying transcriptions of radio communication transcription for an aircraft. The apparatus comprises: a communications receiver that captures audio signals of radio communication traffic to and from the aircraft; a preprocessor that divides the captured audio signals into independent spoken utterances; a speech recognition decoder that transcribes each spoken utterance using an air traffic control (ATC) speech recognition model; a postprocess that extracts classification data from the transcription of each spoken utterance; a log manager that logs the transcription of each spoken utterance with reference to the classification data; and a textual display that displays the transcription of each spoken utterance to a crew member of the aircraft.</p><p id="p-0009" num="0008">Furthermore, other desirable features and characteristics of the method and system will become apparent from the subsequent detailed description and the appended claims, taken in conjunction with the accompanying drawings and the preceding background.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0009">The present invention will hereinafter be described in conjunction with the following drawing figures, wherein like numerals denote like elements, and wherein:</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a diagram of a system for providing displaying radio transcription onboard an aircraft in accordance with one embodiment;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a functional block diagram of a computing device, in accordance with one embodiment;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a flow diagram of the method for displaying radio communication transcription in accordance with one embodiment;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a diagram of the system for displaying radio communication transcription in accordance with one embodiment;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a block diagram of the system for displaying radio communication transcription in accordance with one embodiment;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a display screen for entry of an aircraft tail number in accordance with one embodiment;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows a display screen for transcribed texts of all radio communication traffic in accordance with one embodiment;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows a display screen for transcribed texts of the user's aircraft radio communication traffic in accordance with one embodiment; and</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows a flowchart of a method for displaying radio communication transcription in accordance with one embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0020" num="0019">The following detailed description is merely exemplary in nature and is not intended to limit the invention or the application and uses of the invention. As used herein, the word &#x201c;exemplary&#x201d; means &#x201c;serving as an example, instance, or illustration.&#x201d; Thus, any embodiment described herein as &#x201c;exemplary&#x201d; is not necessarily to be construed as preferred or advantageous over other embodiments. All of the embodiments described herein are exemplary embodiments provided to enable persons skilled in the art to make or use the invention and not to limit the scope of the invention which is defined by the claims. Furthermore, there is no intention to be bound by any expressed or implied theory presented in the preceding technical field, background, brief summary, or the following detailed description.</p><p id="p-0021" num="0020">A method for displaying transcriptions of radio communication transcription for an aircraft has been developed. The method comprises capturing audio signals of radio communication traffic to and from the aircraft; preprocessing the captured audio signals to divide the signals into independent spoken utterances; transcribing each spoken utterance using a speech recognition decoder that utilizes an air traffic control (ATC) speech recognition model; extracting classification data from the transcription of each spoken utterance; logging the transcription of each spoken utterance with reference to the classification data; and providing a textual display of the transcription of each spoken utterance to a crewmember of the aircraft. The embodiments of the method and systems described herein provide advantages which help the pilot efficiently reference voice communication information both in audio and text form which ultimately reduces workload, improves the user experience, and reduces errors due to misinterpretation of voice communication.</p><p id="p-0022" num="0021">As used herein, charts may be any aviation chart or aeronautical chart provided as an informational aid to a flight crew for flight planning purposes. Chart data is any data provided by an electronic chart or a data driven chart (DDC). Aircraft generally use electronic charts for providing a flight crew member with information specific to a particular route and/or airport. Electronic charts may include airport maps; intersections and taxiways data; procedures and data associated with approach, arrival, and departure; and any flight constraints associated with a current flight plan. A flight plan is a proposed strategy for an intended flight, includes details associated with the intended flight, and is usually filed with an aviation authority (e.g., Federal Aviation Administration). An intended flight may also be referred to as a &#x201c;trip&#x201d; and extends from a departure airport at the beginning point of the trip to a destination airport at the endpoint of the trip. An alert may be any signal or warning indicating potential non-compliance with constraints associated with the current flight plan. The alert may be implemented as a display of text and/or graphical elements, a sound, a light, or other visual or auditory warning signal onboard the aircraft.</p><p id="p-0023" num="0022">Turning now to the figures, <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram of a system <b>100</b> for providing displaying radio transcription onboard an aircraft, in accordance with the disclosed embodiments. The system <b>100</b> operates with a current flight of the aircraft <b>104</b>, to continuously monitor flight data and parameters during flight. The system <b>100</b> may include, without limitation, a computing device <b>102</b> that communicates with one or more avionics systems <b>106</b> onboard the aircraft <b>104</b>, at least one server system <b>114</b>, and air traffic control (ATC) <b>112</b>, via a data communication network <b>110</b>. In practice, certain embodiments of the system <b>100</b> may include additional or alternative elements and components, as desired for the particular application.</p><p id="p-0024" num="0023">The computing device <b>102</b> may be implemented by any computing device that includes at least one processor, some form of memory hardware, a user interface, and communication hardware. For example, the computing device <b>102</b> may be implemented using a personal computing device, such as a tablet computer, a laptop computer, a personal digital assistant (PDA), a smartphone, or the like. In this scenario, the computing device <b>102</b> is capable of storing, maintaining, and executing an Electronic Flight Bag (EFB) application configured to determine and present emergency alerts when flight constraints may not be satisfied by the current flight of the aircraft <b>104</b>. In other embodiments, the computing device <b>102</b> may be implemented using a computer system onboard the aircraft <b>104</b>, which is configured to determine and present such emergency alerts.</p><p id="p-0025" num="0024">The aircraft <b>104</b> may be any aviation vehicle for which flight constraints and alerts associated with non-compliance with flight constraints are relevant and applicable during completion of a flight route. The aircraft <b>104</b> may be implemented as an airplane, helicopter, spacecraft, hovercraft, or the like. The one or more avionics systems <b>106</b> may include a Flight Management System (FMS), crew alerting system (CAS) devices, automatic terminal information system (ATIS) devices, Automatic Dependent Surveillance&#x2014;Broadcast (ADS-B), Controller Pilot Data Link Communication (CPDLC), navigation devices, weather radar, aircraft traffic data, and the like. Data obtained from the one or more avionics systems <b>106</b> may include, without limitation: an approved flight plan, an estimated time of arrival, instructions from air traffic control (ATC), Automatic Terminal Information Service (ATIS) data, flight plan restriction data, onboard equipment failure data, aircraft traffic data, weather data, or the like.</p><p id="p-0026" num="0025">The server system <b>114</b> may include any number of application servers, and each server may be implemented using any suitable computer. In some embodiments, the server system <b>114</b> includes one or more dedicated computers. In some embodiments, the server system <b>114</b> includes one or more computers carrying out other functionality in addition to server operations. The server system <b>114</b> may store and provide any type of data used to determine compliance and/or non-compliance with constraints associated with the current flight. Such data may include, without limitation: flight plan data, flight plan constraint data, and other data compatible with the computing device <b>102</b>.</p><p id="p-0027" num="0026">The computing device <b>102</b> is usually located onboard the aircraft <b>104</b>, and the computing device <b>102</b> communicates with the server system <b>114</b> and air traffic control <b>112</b> via a wireless communication connection. The computing device <b>102</b> and the server system <b>114</b> are generally disparately located, and the computing device <b>102</b> and air traffic control <b>112</b> are generally disparately located. The computing device <b>102</b> communicates with the server system <b>114</b> and air traffic control <b>112</b> via the data communication network <b>110</b> and/or via communication mechanisms onboard the aircraft <b>104</b>.</p><p id="p-0028" num="0027">The data communication network <b>110</b> may be any digital or other communications network capable of transmitting messages or data between devices, systems, or components. In certain embodiments, the data communication network <b>110</b> includes a packet switched network that facilitates packet-based data communication, addressing, and data routing. The packet switched network could be, for example, a wide area network, the Internet, or the like. In various embodiments, the data communication network <b>110</b> includes any number of public or private data connections, links or network connections supporting any number of communications protocols. The data communication network <b>110</b> may include the Internet, for example, or any other network based upon TCP/IP or other conventional protocols. In various embodiments, the data communication network <b>110</b> could also incorporate a wireless and/or wired telephone network, such as a cellular communications network for communicating with mobile phones, personal digital assistants, and/or the like. The data communication network <b>110</b> may also incorporate any sort of wireless or wired local and/or personal area networks, such as one or more IEEE 802.3, IEEE 802.16, and/or IEEE 802.11 networks, and/or networks that implement a short range (e.g., Bluetooth) protocol. For the sake of brevity, conventional techniques related to data transmission, signaling, network control, and other functional aspects of the systems (and the individual operating components of the systems) may not be described in detail herein.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a functional block diagram of a computing device <b>200</b>, in accordance with the disclosed embodiments. It should be noted that the computing device <b>200</b> can be implemented with the computing device <b>102</b> depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In this regard, the computing device <b>200</b> shows certain elements and components of the computing device <b>102</b> in more detail.</p><p id="p-0030" num="0029">The computing device <b>200</b> generally includes, without limitation: a processor <b>202</b>; system memory <b>204</b>; a user interface <b>206</b>; a plurality of sensors <b>208</b>; a communication device <b>210</b>; and a display and/or playback device <b>216</b>. These elements and features of the computing device <b>200</b> may be operatively associated with one another, coupled to one another, or otherwise configured to cooperate with one another as needed to support the desired functionality. For ease of illustration and clarity, the various physical, electrical, and logical couplings and interconnections for these elements and features are not depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Moreover, it should be appreciated that embodiments of the computing device <b>200</b> will include other elements, modules, and features that cooperate to support the desired functionality. For simplicity, <figref idref="DRAWINGS">FIG. <b>2</b></figref> only depicts certain elements that are described in more detail below.</p><p id="p-0031" num="0030">The processor <b>202</b> may be implemented or performed with one or more general purpose processors, a content addressable memory, a digital signal processor, an application specific integrated circuit, a field programmable gate array, any suitable programmable logic device, discrete gate or transistor logic, discrete hardware components, or any combination designed to perform the functions described here. In particular, the processor <b>202</b> may be realized as one or more microprocessors, controllers, microcontrollers, or state machines. Moreover, the processor <b>202</b> may be implemented as a combination of computing devices, e.g., a combination of digital signal processors and microprocessors, a plurality of microprocessors, one or more microprocessors in conjunction with a digital signal processor core, or any other such configuration.</p><p id="p-0032" num="0031">The processor <b>202</b> is communicatively coupled to the system memory <b>204</b>. The system memory <b>204</b> is configured to store any obtained or generated data associated with generating alerts to redirect user attention from the computing device <b>200</b> to a critical or high-priority flight situation. The system memory <b>204</b> may be realized using any number of devices, components, or modules, as appropriate to the embodiment. Moreover, the computing device <b>200</b> could include system memory <b>204</b> integrated therein and/or a system memory <b>204</b> operatively coupled thereto, as appropriate to the particular embodiment. In practice, the system memory <b>204</b> could be realized as RAM memory, flash memory, EPROM memory, EEPROM memory, registers, a hard disk, a removable disk, or any other form of storage medium known in the art. In certain embodiments, the system memory <b>204</b> includes a hard disk, which may also be used to support functions of the computing device <b>200</b>. The system memory <b>204</b> can be coupled to the processor <b>202</b> such that the processor <b>202</b> can read information from, and write information to, the system memory <b>204</b>. In the alternative, the system memory <b>204</b> may be integral to the processor <b>202</b>. As an example, the processor <b>202</b> and the system memory <b>204</b> may reside in a suitably designed application-specific integrated circuit (ASIC).</p><p id="p-0033" num="0032">The user interface <b>206</b> may include or cooperate with various features to allow a user to interact with the computing device <b>200</b>. Accordingly, the user interface <b>206</b> may include various human-to-machine interfaces, e.g., a keypad, keys, a keyboard, buttons, switches, knobs, a touchpad, a joystick, a pointing device, a virtual writing tablet, a touch screen, a microphone, or any device, component, or function that enables the user to select options, input information, or otherwise control the operation of the computing device <b>200</b>. For example, the user interface <b>206</b> could be manipulated by an operator to provide flight data parameters during the operation of electronic flight bag (EFB) applications, as described herein.</p><p id="p-0034" num="0033">In certain embodiments, the user interface <b>206</b> may include or cooperate with various features to allow a user to interact with the computing device <b>200</b> via graphical elements rendered on a display element (e.g., the display device <b>216</b>). Accordingly, the user interface <b>206</b> may initiate the creation, maintenance, and presentation of a graphical user interface (GUI). In certain embodiments, the display device <b>216</b> implements touch-sensitive technology for purposes of interacting with the GUI. Thus, a user can manipulate the GUI by moving a cursor symbol rendered on the display device <b>216</b>, or by physically interacting with the display device <b>216</b> itself for recognition and interpretation, via the user interface <b>206</b>.</p><p id="p-0035" num="0034">The plurality of sensors <b>208</b> is configured to obtain data associated with active use of the computing device <b>200</b>, and may include, without limitation: touchscreen sensors, accelerometers, gyroscopes, or the like. Some embodiments of the computing device <b>200</b> may include one particular type of sensor, and some embodiments may include a combination of different types of sensors. Generally, the plurality of sensors <b>208</b> provides data indicating whether the computing device <b>200</b> is currently being used. Touchscreen sensors may provide output affirming that the user is currently making physical contact with the touchscreen (e.g., a user interface <b>206</b> and/or display device <b>216</b> of the computing device <b>200</b>), indicating active use of the computing device. Accelerometers and/or gyroscopes may provide output affirming that the computing device <b>200</b> is in motion, indicating active use of the computing device <b>200</b>.</p><p id="p-0036" num="0035">The communication device <b>210</b> is suitably configured to communicate data between the computing device <b>200</b> and one or more remote servers and one or more avionics systems onboard an aircraft. The communication device <b>210</b> may transmit and receive communications over a wireless local area network (WLAN), the Internet, a satellite uplink/downlink, a cellular network, a broadband network, a wide area network, or the like. As described in more detail below, data received by the communication device <b>210</b> may include, without limitation: avionics systems data and aircraft parameters (e.g., a heading for the aircraft, aircraft speed, altitude, aircraft position, ascent rate, descent rate, a current flight plan, a position of air spaces around a current flight plan, and activity of the air spaces around a current flight plan), and other data compatible with the computing device <b>200</b>. Data provided by the communication device <b>210</b> may include, without limitation, requests for avionics systems data, alerts and associated detail for display via an aircraft onboard display, and the like.</p><p id="p-0037" num="0036">The display/playback device <b>216</b> is configured to display various icons, text, and/or graphical elements associated with alerts related to situations requiring user attention, wherein the situations are associated with a device or system that is separate and distinct from the computing device <b>200</b>. In an exemplary embodiment, the display device <b>216</b> and the user interface <b>206</b> are communicatively coupled to the processor <b>202</b>. The processor <b>202</b>, the user interface <b>206</b>, and the display/playback device <b>216</b> are cooperatively configured to display, render, or otherwise convey one or more graphical representations or images associated with high-priority or critical flight situation alerts on the display/playback device <b>216</b>, as described in greater detail below. In an exemplary embodiment, the display/playback device <b>216</b> is realized as an electronic display configured to graphically display critical flight situation alerts and associated detail, as described herein. In some embodiments, the computing device <b>200</b> is an integrated computer system onboard an aircraft, and the display/playback device <b>216</b> is located within a cockpit of the aircraft, and is thus implemented as an aircraft display. In other embodiments, the display/playback device <b>216</b> is implemented as a display screen of a standalone, personal computing device (e.g., laptop computer, tablet computer). It will be appreciated that although the display/playback device <b>216</b> may be implemented using a single display, certain embodiments may use additional displays (i.e., a plurality of displays) to accomplish the functionality of the display/playback device <b>216</b> described herein.</p><p id="p-0038" num="0037">Turning now to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a flow diagram <b>300</b> is shown of the method for displaying radio communication transcription in accordance with one embodiment. Various embodiments provide method and features to display the ATC voice communication transcription in an efficient way for pilot. The system comprises of speech engine system which transcribes the input radio communication voice audio into post processed text. The system in scope continuously listens to the VHF audio by connecting to the audio panel <b>302</b>. In real-time continuous audio is processed <b>304</b> and converted to text using speech recognition <b>306</b>. The processed text. is made available to pilot via display application in a comprehensible manner <b>308</b>.</p><p id="p-0039" num="0038">Turning now to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a diagram is shown <b>400</b> of the system for displaying and/or playing audio of radio communication transcriptions in accordance with one embodiment described previously in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The system includes the ATC <b>402</b> in radio communication with the aircraft's communication system <b>404</b> which includes an audio panel <b>406</b> and an air traffic control transcription (ATCT) application <b>408</b> that are provided to the pilot <b>410</b>.</p><p id="p-0040" num="0039">Turning now to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, a block diagram <b>500</b> is shown of the system for displaying radio communication transcription in accordance with one embodiment. The system comprises of three primary components: a preprocessor <b>502</b>; a speech decoder <b>504</b>; and a postprocessor <b>506</b>. The preprocessor <b>502</b> component performs processing of continuous audio capture <b>508</b> containing both speech and silence component and segments them into independent spoken utterance. Each independent spoken utterance corresponds to individual ATC clearance/command/approval or pilot's responseireadback/requests or spoken phrase within the radio communication. The speech decoder component <b>504</b> is the automatic speech recognition component which transcribes the input utterance from preprocessor component <b>506</b> to text using ATCT speech recognition model <b>510</b> comprising of acoustic, lexicon and language model covering the ATC vocabulary and phraseology. Finally, the postprocessor component <b>506</b> is the text processor component responsible for extracting the aircraft's consign, and classifying the utterance transcription into either: traffic messages, the aircrafts messages, possible aircraft messages or unrecognized messages.</p><p id="p-0041" num="0040">The classified transcriptions are received by a log manager <b>512</b> for the system and stored in either an audio log <b>514</b>, a data log <b>516</b> and uploaded to cloud based storage <b>518</b> as needed. The classified transcriptions are also sent to a controller <b>520</b> which provides the transcriptions to user interface (UI) <b>524</b> with display features for use by an aircrew member <b>526</b>. The classified utterance transcriptions are sent for audio playback <b>522</b> through an audio speaker device <b>528</b>.</p><p id="p-0042" num="0041">The <b>524</b> may include login and usage help/guidance pages that allow the user to select different view modes and configurations. As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the UI includes a display screen <b>600</b> for entry of an aircraft tail number <b>602</b> in accordance with one embodiment. This feature enables the pilot to enter the tail number and call sign variations of the aircraft. It also provides options to select previously saved entries and tail number/call sign variations.</p><p id="p-0043" num="0042">The main view of the UI displays such information as a title label, various menus, status icons, transcription view tabs selections, bookmarks, and tail number entries. As shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the display screen <b>700</b> shows transcribed texts <b>702</b> of all radio communication traffic in accordance with one mode of operation. All of the transcribed messages <b>702</b> are displayed in a virtual table format and the display provides scroll view option to see older messages as well as a quick access button to go to the latest message. Since, the radio communication channels are broadcast, all ATC communication to and from the aircraft are transmitted on the same radio channel. The system receives all the radio communications and needs for triage the communication for easy access by the pilot. The system uses the entered tail number and call sign variation to perform the real-time traffic classification of the transcribed radio communications.</p><p id="p-0044" num="0043">The UI display of the proposed app has two tabs to select the transcription display mode. As shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the &#x201c;All&#x201d; tab <b>704</b> is selected to display <b>700</b> all of the communication transcription received through the radio channel the view provides virtual table view with three columns. In the embodiment shown, the right most column <b>706</b> displays only transcriptions corresponding to messages for the aircraft. The middle column <b>708</b> displays the possible aircraft and unrecognized tail number utterances. Some of the transcribed communication utterances, may not contain any call sign related info or may only contain partial aircraft call sign information. Those messages are indicated respectively as an unrecognized tail number or a possible aircraft message. Finally, the left column <b>710</b> displays the related transcribed utterances from the aircraft. As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the &#x201c;Ownship&#x201d; tab <b>802</b> is selected to display <b>800</b> only the communication transcription <b>804</b> received through the radio channel that are directed to the aircraft. This helps pilot to focus only the message intended for his aircraft.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows a flowchart <b>900</b> of a method for displaying radio communication transcription in accordance with one embodiment. First, audio signals of radio communication traffic to and from the aircraft are captured <b>902</b>. The captured audio signals are preprocessed to divide the signals into independent spoken utterances <b>904</b>. Each spoken utterance is then transcribed using a speech recognition decoder that utilizes an air traffic control (ATC) speech recognition model <b>906</b>. Next, classification data extracted from the transcription of each spoken utterance <b>908</b>. The transcription of each spoken utterance is logged with reference to the classification data <b>910</b>. Finally, a textual display of the transcription of each spoken utterance is provided to a crew member of the aircraft <b>912</b>.</p><p id="p-0046" num="0045">Other display features may include a transcription message box which displays the transcription text of each independent communication utterance, associated tail number and timestamp. The message box is also enabled with additional UI elements such as: a play button that plays of audio corresponding to the utterance; a bookmark button for bookmarking of the message for later reference; and a swipe arrow for moving the message from one classification column to other. Other UI elements include a most recent message box. The most recent message box gets displayed on the top of the transcription display view with different color. It has all the UI elements as the transcription message box except the swipe UI element. Additionally, it contains button for enabling the pilot to pause or continue the display of the transcriptions. The color of recent message box may be chosen by the pilot. Other UI elements include various status indicators or icons showing connection status, volume, menus, software updates, etc. In some embodiments, a last flight replay feature can be accessed via settings menu. The user can enable last flight replay mode to play and view the list of transcribed messages and audio playback. This is very useful for pilot for any post flight analysis, learning and inferences.</p><p id="p-0047" num="0046">Advantages of the various embodiments may include the use of a transcription view with tabs for either &#x201c;All&#x201d; and &#x201c;Ownship&#x201d; to display the realtime classified messages relevant to traffic and the aircraft. This allows the pilot flexibility to focus on aircraft communications only or to get more context by using the &#x201c;All&#x201d; view. Other advantages include the ability to configure all call sign and tail number variations spoken by pilot and ATC relevant to the aircraft. This allows the triaging of aircraft communications not only using the tail number or call sign but also using known nicknames and phonetic variations used during radio communication. Another advantage is the display of transcriptions with separate column views to display realtime classified messages of: traffic/inflight/broadcast messages; possible or unrecognized tail number; and ownship only messages. This functionality affords the pilot a mechanism to provide feedback by swiping utterances from one column to the other. It also clearly delineates aircraft communications to pilots while making available traffic communications to increase Situational Awareness (SA). Another advantage is the Ability to select and view ow only messages. This provides the pilot the option of an uncluttered view and the ability to focus on relevant aircraft communications.</p><p id="p-0048" num="0047">Other advantages include an abbreviated view of traffic/inflight audio and transcription for any validation. This feature provides immediate access to the audio of interest and requires no search for the audio corresponding to a specific clearance. This allows the pilot to listen to audio of interest a second time without any additional workload. In fact, it is expected to reduce the number of times pilots will ask ATC to repeat a clearance and thereby reduce frequency congestion. Another advantage is a unique transcription message UI element with callsign, timestamp, transcription text, playback, and bookmark. Integrated presentation of transcribed radio communications with related information such as timestamp, tail number, associated audio etc. Also, the ability to bookmark messages for later review and view in separate view/page/overlay. This addresses adjacent use cases. One example is when pilots need to refer to communications when implementing/dialing in values especially for conditional clearances since they need to be implemented after a condition is met such as a certain amount of time has elapsed or a waypoint/flight level has been reached. Another example is when pilots want to refer to the format for an infrequently used clearance. An advantage is the ability to view logs of previous flights with date and tail number reference. This is useful for the need to clarify what exactly was spoken by pilot and/or ATC. The logs also are a required input for real-time or post flight analytics. Also, the ability to playback the transcription and audio of last flight. This is very useful for training pilots and assessing proficiency in understanding and responding to radio communications. Another advantage is the ability to set a timer reminder associated with specific communications/clearances. This feature is especially useful when the pilot must refer to or remember specific instructions. Examples include reporting after reaching a specific waypoint or implementing a heading or speed target after a specified time/condition is met. The timer can be set by the pilot either by double tapping on the message or using the time icon provided in the message element.</p><p id="p-0049" num="0048">Techniques and technologies may be described herein in terms of functional and/or logical block components, and with reference to symbolic representations of operations, processing tasks, and functions that may be performed by various computing components or devices. Such operations, tasks, and functions are sometimes referred to as being computer-executed, computerized, software-implemented, or computer-implemented. In practice, one or more processor devices can carry out the described operations, tasks, and functions by manipulating electrical signals representing data bits at memory locations in the system memory, as well as other processing of signals. The memory locations where data bits are maintained are physical locations that have particular electrical, magnetic, optical, or organic properties corresponding to the data bits. It should be appreciated that the various block components shown in the figures may be realized by any number of hardware, software, and/or firmware components configured to perform the specified functions. For example, an embodiment of a system or a component may employ various integrated circuit components, e.g., memory elements, digital signal processing elements, logic elements, look-up tables, or the like, which may carry out a variety of functions under the control of one or more microprocessors or other control devices.</p><p id="p-0050" num="0049">When implemented in software or firmware, various elements of the systems described herein are essentially the code segments or instructions that perform the various tasks. The program or code segments can be stored in a processor-readable medium or transmitted by a computer data signal embodied in a carrier wave over a transmission medium or communication path. The &#x201c;computer-readable medium&#x201d;, &#x201c;processor-readable medium&#x201d;, or &#x201c;machine-readable medium&#x201d; may include any medium that can store or transfer information. Examples of the processor-readable medium include an electronic circuit, a semiconductor memory device, a ROM, a flash memory, an erasable ROM (EROM), a floppy diskette, a CD-ROM, an optical disk, a hard disk, a fiber optic medium, a radio frequency (RF) link, or the like. The computer data signal may include any signal that can propagate over a transmission medium such as electronic network channels, optical fibers, air, electromagnetic paths, or RF links. The code segments may be downloaded via computer networks such as the Internet, an intranet, a LAN, or the like.</p><p id="p-0051" num="0050">The following description refers to elements or nodes or features being &#x201c;connected&#x201d; or &#x201c;coupled&#x201d; together. As used herein, unless expressly stated otherwise, &#x201c;coupled&#x201d; means that one element/node/feature is directly or indirectly joined to (or directly or indirectly communicates with) another element/node/feature, and not necessarily mechanically. Likewise, unless expressly stated otherwise, &#x201c;connected&#x201d; means that one element/node/feature is directly joined to (or directly communicates with) another element/node/feature, and not necessarily mechanically. Thus, additional intervening elements, devices, features, or components may be present in an embodiment of the depicted subject matter.</p><p id="p-0052" num="0051">In addition, certain terminology may also be used in the following description for the purpose of reference only, and thus are not intended to be limiting. For example, terms such as &#x201c;upper&#x201d;, &#x201c;lower&#x201d;, &#x201c;above&#x201d;, and &#x201c;below&#x201d; refer to directions in the drawings to which reference is made. Terms such as &#x201c;front&#x201d;, &#x201c;back&#x201d;, &#x201c;rear&#x201d;, &#x201c;side&#x201d;, &#x201c;outboard&#x201d;, and &#x201c;inboard&#x201d; describe the orientation and/or location of portions of the component within a consistent but arbitrary frame of reference which is made clear by reference to the text and the associated drawings describing the component under discussion. Such terminology may include the words specifically mentioned above, derivatives thereof, and words of similar import. Similarly, the terms &#x201c;first&#x201d;, &#x201c;second&#x201d;, and other such numerical terms referring to structures do not imply a sequence or order unless clearly indicated by the context.</p><p id="p-0053" num="0052">For the sake of brevity, conventional techniques related to signal processing, data transmission, signaling, network control, and other functional aspects of the systems (and the individual operating components of the systems) may not be described in detail herein. Furthermore, the connecting lines shown in the various figures contained herein are intended to represent exemplary functional relationships and/or physical couplings between the various elements. It should be noted that many alternative or additional functional relationships or physical connections may be present in an embodiment of the subject matter.</p><p id="p-0054" num="0053">Some of the functional units described in this specification have been referred to as &#x201c;modules&#x201d; in order to more particularly emphasize their implementation independence. For example, functionality referred to herein as a module may be implemented wholly, or partially, as a hardware circuit comprising custom VLSI circuits or gate arrays, off-the-shelf semiconductors such as logic chips, transistors, or other discrete components. A module may also be implemented in programmable hardware devices such as field programmable gate arrays, programmable array logic, programmable logic devices, or the like. Modules may also be implemented in software for execution by various types of processors. An identified module of executable code may, for instance, comprise one or more physical or logical modules of computer instructions that may, for instance, be organized as an object, procedure, or function. Nevertheless, the executables of an identified module need not be physically located together but may comprise disparate instructions stored in different locations that, when joined logically together, comprise the module and achieve the stated purpose for the module. Indeed, a module of executable code may be a single instruction, or many instructions, and may even be distributed over several different code segments, among different programs, and across several memory devices. Similarly, operational data may be embodied in any suitable form and organized within any suitable type of data structure. The operational data may be collected as a single data set or may be distributed over different locations including over different storage devices, and may exist, at least partially, merely as electronic signals on a system or network.</p><p id="p-0055" num="0054">While at least one exemplary embodiment has been presented in the foregoing detailed description, it should be appreciated that a vast number of variations exist. It should also be appreciated that the exemplary embodiment or embodiments described herein are not intended to limit the scope, applicability, or configuration of the claimed subject matter in any way. Rather, the foregoing detailed description will provide those skilled in the art with a convenient road map for implementing the described embodiment or embodiments. It should be understood that various changes can be made in the function and arrangement of elements without departing from the scope defined by the claims, which includes known equivalents and foreseeable equivalents at the time of filing this patent application.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for displaying transcriptions of radio communication transcription for an aircraft, comprising:<claim-text>capturing audio signals of radio communication traffic to and from the aircraft;</claim-text><claim-text>preprocessing the captured audio signals to divide the signals into independent spoken utterances;</claim-text><claim-text>transcribing each spoken utterance using a speech recognition decoder that utilizes an air traffic control (ATC) speech recognition model;</claim-text><claim-text>extracting classification data from the transcription of each spoken utterance;</claim-text><claim-text>logging the transcription of each spoken utterance with reference to the classification data; and</claim-text><claim-text>providing a textual display of the transcription of each spoken utterance to a crew member of the aircraft.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the ATC speech recognition model comprises an acoustic recognition model.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the ATC speech recognition model comprises an lexicon recognition model.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the ATC speech recognition model comprises an language recognition model.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the extracted classification data comprises an aircraft call sign.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the extracted classification data comprises an aircraft tail number.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the extracted classification data comprises a traffic message.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the extracted classification data comprises a message for the aircraft.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the extracted classification data comprises a possible message for the aircraft.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the extracted classification data comprises an unrecognized message.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the logs of the transcriptions are uploaded to cloud based data storage.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the logs of the transcriptions are stored in audio log storage.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the logs of the transcriptions are stored in data log storage.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the textual display provides a separate sub-display for messages for the aircraft.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the textual display provides a separate sub-display for possible messages for the aircraft.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the textual display provides a separate sub-display for unrecognized messages.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, where the textual display provides a separate sub-display for messages from the aircraft.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. An apparatus for displaying transcriptions of radio communication transcription for an aircraft, comprising:<claim-text>a communications receiver that captures audio signals of radio communication traffic to and from the aircraft;</claim-text><claim-text>a preprocessor that divides the captured audio signals into independent spoken utterances;</claim-text><claim-text>a speech recognition decoder that transcribes each spoken utterance using an air traffic control (ATC) speech recognition model;</claim-text><claim-text>a postprocess that extracts classification data from the transcription of each spoken utterance;</claim-text><claim-text>a log manager that logs the transcription of each spoken utterance with reference to the classification data; and</claim-text><claim-text>a textual display that displays the transcription of each spoken utterance to a crew member of the aircraft.</claim-text></claim-text></claim></claims></us-patent-application>
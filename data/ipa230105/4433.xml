<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004434A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004434</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17813009</doc-number><date>20220715</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>50</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>2455</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>505</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>24568</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">AUTOMATED RECONFIGURATION OF REAL TIME DATA STREAM PROCESSING</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16825432</doc-number><date>20200320</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11392416</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17813009</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15084350</doc-number><date>20160329</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10599478</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16825432</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Amazon Technologies, Inc.</orgname><address><city>Seattle</city><state>WA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Ghare</last-name><first-name>Gaurav D.</first-name><address><city>Seattle</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Barga</last-name><first-name>Roger Shane</first-name><address><city>Woodinville</city><state>WA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Amazon Technologies, Inc.</orgname><role>02</role><address><city>Seattle</city><state>WA</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Automated reconfiguration of real time data stream processing may be implemented. A processing function that describes one or more operations to be performed with respect to one or more data streams may be executed at one or more processing nodes. Performance metrics describing the performance of the processing function at the processing nodes may be collected and monitored. A reconfiguration event may be detected for the processing function. A different execution configuration for the processing function may be determined and initiated in response to detecting the reconfiguration event.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="113.54mm" wi="158.75mm" file="US20230004434A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="238.42mm" wi="164.59mm" file="US20230004434A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="210.31mm" wi="136.23mm" orientation="landscape" file="US20230004434A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="216.75mm" wi="156.55mm" file="US20230004434A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="204.55mm" wi="162.73mm" orientation="landscape" file="US20230004434A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="162.81mm" wi="164.34mm" orientation="landscape" file="US20230004434A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="210.90mm" wi="166.20mm" file="US20230004434A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="186.61mm" wi="107.02mm" file="US20230004434A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="242.15mm" wi="119.72mm" file="US20230004434A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="202.10mm" wi="144.19mm" file="US20230004434A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 16/825,432, filed Mar. 20, 2020, which is a continuation of U.S. application Ser. No. 15/084,350, filed Mar. 29, 2016, now U.S. Pat. No. 10,599,478, which are hereby incorporated by reference herein in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Interconnected devices, such as networked sensors and computing devices, can generate and send data pertinent to various operations, transactions, or other events to remote devices for storage and further analysis. For example, mobile phones can generate data indicating their locations, the applications being used by the phone users, and so on, at least some of which can be collected and analyzed in order to present customized coupons, advertisements and the like to the users. The analysis of data collected by surveillance cameras may be useful in preventing and/or solving crimes, and data collected from sensors embedded at various location within airplane engines, automobiles or complex machinery may be used for various purposes such as preventive maintenance, improving efficiency and lowering costs.</p><p id="p-0004" num="0003">As a result of utilizing interconnected devices, large amounts of data may be generated and sent in streaming fashion so that the data can be captured in real time. However, over time the volume of streaming data may prove difficult to efficiently analyze. Different data formats for data records within data streams could require different operations to be performed in order to interpret or manipulate the data, making it difficult to utilize a common schema to handle multiple data streams. The volume of data within a data stream may change over time, complicating efforts to acquire the appropriate number of resources for efficiently analyzing the data stream.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0002" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a logical block diagram that illustrates automated reconfiguration of real time data stream processing, according to at least some embodiments.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a logical block diagram illustrating a provider network that implements a stream processing service that provides automated reconfiguration of real time data stream processing, according to at least some embodiments.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a logical block diagram of a stream processing service that implements automated reconfiguration of real time data stream processing, according to at least some embodiments.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a logical block diagram of a stream processing node, according to at least some embodiments.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates interactions between a client and a stream processing service via a programmatic interface, according to at least some embodiments.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIGS. <b>6</b>A-<b>6</b>C</figref> illustrate different reconfigurations that may be performed in response to detecting a reconfiguration event, according to at least some embodiments.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a high-level flowchart illustrating various methods and techniques to provide automated reconfiguration of real time data stream processing, according to at least some embodiments.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a high-level flowchart illustrating various methods and techniques to update execution state for a stream processing function in order to resume stream processing upon a reconfiguration event, according to at least some embodiments.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram illustrating an example computing system that may be used in at least some embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0014" num="0013">While embodiments are described herein by way of example for several embodiments and illustrative drawings, those skilled in the art will recognize that embodiments are not limited to the embodiments or drawings described. It should be understood, that the drawings and detailed description thereto are not intended to limit embodiments to the particular form disclosed, but on the contrary, the intention is to cover all modifications, equivalents and alternatives falling within the spirit and scope as defined by the appended claims. The headings used herein are for organizational purposes only and are not meant to be used to limit the scope of the description or the claims. As used throughout this application, the word &#x201c;may&#x201d; is used in a permissive sense (i.e., meaning having the potential to), rather than the mandatory sense (i.e., meaning must). Similarly, the words &#x201c;include,&#x201d; &#x201c;including,&#x201d; and &#x201c;includes&#x201d; mean including, but not limited to.</p><heading id="h-0003" level="1">DETAILED DESCRIPTION</heading><p id="p-0015" num="0014">Various embodiments of methods and apparatus to implement automated reconfiguration of real time data stream processing are described. The term &#x201c;data stream&#x201d;, as used herein, refers to a sequence of data records that may be generated by one or more data producers and accessed by one or more data consumers, where each data record is assumed to be an immutable sequence of bytes representing one or more attributes. The records of a stream may also be referred to as observation records, observations, points, or data records herein, and the data producers may be referred to as streaming data sources. A managed stream processing system may provide programmatic interfaces (e.g., application programming interfaces (APIs), web pages or web sites, graphical user interfaces, or command-line tools) to execute functions specified via the programmatic interfaces (or selected via the programmatic interfaces) in various ways and direct the reporting of processing results to one or more destinations.</p><p id="p-0016" num="0015">Stream processing functions may be specified according to standard programming languages or specifications, such as structure query language (SQL), custom programming or a numerical computation language like Matlab, domain specific languages (which may be defined and implemented by a managed stream processing system), or input forms or other interface elements (e.g., a function generation wizard) which provide a user with the ability to select input data streams, function operations (e.g., aggregation, filtering, statistical operations, etc.), and result destinations. A managed stream processing system may handle connecting or interfacing with input data streams, selecting or provisioning the appropriate stream processing nodes (or other processing resources) which may execute the specified stream processing function (e.g., implementing the appropriate execution engines, such as a storage engine that interprets SQL statements), and reporting results to result destinations. In this way, the managed stream processing system may allow users to connect, parse, and apply a real time schema on raw data streams.</p><p id="p-0017" num="0016">Executing stream processing functions at the managed stream processing system may provide users with capability to quickly build real time computations including data filters, transformations, and aggregations without burdening users with the additional time to manually managing the resources to carry out the specified stream processing function. Moreover a managed stream processing system may offer a library of predefined stream processing functions which may be customized to build various stream processing applications, including business-critical streaming applications like real time traffic congestion analysis, emergency call monitoring, fraud detection, and industrial sensor analytics. As part of managing and executing stream processing functions, automated reconfiguration of the execution of such functions may be performed by a managed stream processing system. In this way, users may be unaware of changes made to improve the performance, efficiency, or cost of executing processing functions and/or may be relieved of the burden of having to manually monitor and tune processing function performance.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a logical block diagram that illustrates automated reconfiguration of real time data stream processing, according to at least some embodiments. Clients of managed stream processing <b>110</b> may provide stream processing functions to managed stream processing system <b>110</b>. Managed stream processing system <b>110</b> may then implement stream processing provisioning and other management functions to execute the stream processing function on stream processing node(s) <b>120</b> so that as data records of data stream(s) <b>112</b> are received stream processing node(s) <b>120</b> may apply the stream processing function and provide result(s) <b>114</b> to a specified result destination.</p><p id="p-0019" num="0018">Clients may specify a stream processing function to implement different applications. For example, clients may include an operation in the stream processing function that selects certain attributes and then specify operation(s) that perform specific processing on the selected attribute (e.g., filtering out the attributes, validating the values of the attributes against known patterns, performing time series analytics). Key performance indicators (KPI) are one example of data attributes which may be extracted from a data stream for performing such operations. Clients may utilize a stream processing function to perform stream pattern generation so that real time alerts may be triggered when detecting certain events from data stream records or so that additional data may be inserted to enrich the data conveyed in data records of a data stream. Moreover, clients may specify stream processing functions that process across multiple data streams in order to perform complex stream processing (e.g., analyzing temporal patterns between streaming events in different streams). Stream processing records may be provided to managed stream processing system <b>110</b> complete and ready for execution (e.g., identify input streams, operations, result destinations, and other information). In some embodiments, clients may configure the performance of the stream processing function (e.g., by providing a distribution scheme to map data from one or multiple input data streams to a distributed set of stream processing nodes applying a stream processing function).</p><p id="p-0020" num="0019">Because clients may not implement the execution of the stream processing function manually, managed stream processing system <b>110</b> may implement reconfiguration management <b>130</b> to automatically determine when a reconfiguration of the stream processing node(s) <b>120</b> applying a stream processing function to data stream(s) <b>112</b> is appropriate. For instance, as illustrated in scene <b>102</b>, in various embodiments, reconfiguration management <b>130</b> may collect or receive various performance metrics <b>122</b> from nodes <b>120</b><i>a</i>, <b>120</b><i>b</i>, <b>120</b><i>c </i>describing the performance of applying the streaming processing function at the nodes (including the performance of individual operations of the function). Performance metrics <b>122</b> (e.g., metrics that indicate processor utilization, network utilization, memory utilization, or any other computational performance metric for processing nodes or hosts upon which the nodes are implement, metrics that indicate the behavior of the data stream, rate of data records received, average size of data records, number of data records in processing buffer or queue, or metrics that are specific to the performance of individual operations such as average time to perform a query operation, filter operation, aggregation operation, statistical analysis, etc.) may be monitored, evaluated, or otherwise analyzed with respect to various reconfiguration event criteria (e.g., thresholds) to detect events that trigger a reconfiguration of the execution of the stream processing function at nodes <b>120</b>.</p><p id="p-0021" num="0020">When a reconfiguration event is detected, reconfiguration management may determine a different execution configuration (e.g., number of stream processing nodes, type of stream processing nodes, workload distribution, data stream mapping, etc.) which may solve, cure, or otherwise optimize the detected reconfiguration event (e.g., add more storage, memory, or processing capacity). For example, as illustrated in scene <b>104</b>, reconfiguration management may provision a new stream processing node <b>120</b><i>d </i>as part of reconfiguration execution, which may be a different type of stream processing node for use in executing the stream processing function. Once the new execution configuration is determined and provisioned, reconfiguration management may initiate execution of the function according to the new execution configuration. For instance, as illustrated in scene <b>106</b>, stream processing node <b>120</b><i>d </i>has replaced stream processing node <b>120</b><i>b </i>and processing of data streams <b>112</b>, reporting of results <b>114</b> and performance metrics <b>124</b> has resumed. There are many different ways in which the reconfiguration operation may be performed without losing data records, such as utilizing execution state updated by stream processing nodes as discussed below with regard to <figref idref="DRAWINGS">FIGS. <b>4</b> and <b>8</b></figref>. Execution state may be maintained across multiple data streams (and/or partitions of data streams) processed by the stream processing function so that execution of the processing function may resume at the next data record to be processed in each data stream. In this way, different data streams may be processed at different rates, without interfering with processing of other data streams.</p><p id="p-0022" num="0021">Please note that previous descriptions are not intended to be limiting, but are merely provided as a logical example of automatic reconfiguration of data stream processing in real time. Different numbers or combinations of components, systems, and/or devices may be utilized to execute stream processing functions on behalf of clients.</p><p id="p-0023" num="0022">This specification begins with a general description of a provider network, which may implement a stream processing service that provides automatic reconfiguration of data stream processing in real time. Then various examples of a stream processing service are discussed, including different components/modules, or arrangements of components/module that may be employed as part of providing automatic reconfiguration of data stream processing in real time. A number of different methods and techniques to implement automatic reconfiguration of data stream processing in real time are then discussed, some of which are illustrated in accompanying flowcharts. Finally, a description of an example computing system upon which the various components, modules, systems, devices, and/or nodes may be implemented is provided. Various examples are provided throughout the specification.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a logical block diagram illustrating a provider network that implements a stream processing service that provides automated reconfiguration of real time data stream processing, according to at least some embodiments. Provider network <b>200</b> may be set up by an entity such as a company or a public sector organization to provide one or more services (such as various types of cloud-based computing or storage) accessible via the Internet and/or other networks to clients <b>210</b>. Provider network <b>200</b> may include numerous data centers hosting various resource pools, such as collections of physical and/or virtualized computer servers, storage devices, networking equipment and the like (e.g., computing system <b>1000</b> described below with regard to <figref idref="DRAWINGS">FIG. <b>9</b></figref>), needed to implement and distribute the infrastructure and services offered by the provider network <b>200</b>. In some embodiments, provider network <b>200</b> may implement a stream processing service <b>220</b>, described in detail below with regard to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, provide computing resources, such as virtual compute service <b>230</b> and storage services <b>240</b>, such as object storage services, block-based storage services, data warehouse storage services, stream management service <b>250</b>, and/or any other type of network based services <b>270</b> (which may include various other types of storage, processing, analysis, communication, event handling, visualization, and security services). Clients <b>210</b> may access these various services offered by provider network <b>200</b> via network <b>280</b>. Likewise network-based services may themselves communicate and/or make use of one another to provide different services. For example, computing resources offered to clients <b>210</b> in units called &#x201c;instances,&#x201d; such as virtual or physical compute instances or storage instances, may be implemented as data producers or data consumers for a data stream processed by stream processing service <b>220</b> and services such as storage service <b>240</b>, may serve as destinations for data records in the data stream, providing virtual block storage for the compute instances.</p><p id="p-0025" num="0024">As noted above, virtual compute service <b>230</b> may offer various compute instances to clients <b>210</b>. A virtual compute instance may, for example, comprise one or more servers with a specified computational capacity (which may be specified by indicating the type and number of CPUs, the main memory size, and so on) and a specified software stack (e.g., a particular version of an operating system, which may in turn run on top of a hypervisor). A number of different types of computing devices may be used singly or in combination to implement the compute instances of virtual compute service <b>230</b> in different embodiments, including special purpose computer servers, storage devices, network devices and the like. In some embodiments instance clients <b>210</b> or other any other user may be configured (and/or authorized) to direct network traffic to a compute instance. In various embodiments, compute instances may attach or map to one or more data volumes provided by a block-based storage service (not illustrated) in order to obtain persistent block-based storage for performing various operations.</p><p id="p-0026" num="0025">Compute instances may operate or implement a variety of different platforms, such as application server instances, Java&#x2122; virtual machines (JVMs), special-purpose operating systems, platforms that support various interpreted or compiled programming languages such as Ruby, Perl, Python, C, C++ and the like, or high-performance computing platforms) suitable for performing client applications, without for example requiring the client <b>210</b> to access an instance. In some embodiments, compute instances have different types or configurations based on expected uptime ratios. The uptime ratio of a particular compute instance may be defined as the ratio of the amount of time the instance is activated, to the total amount of time for which the instance is reserved. Uptime ratios may also be referred to as utilizations in some implementations. If a client expects to use a compute instance for a relatively small fraction of the time for which the instance is reserved (e.g., 30%-35% of a year-long reservation), the client may decide to reserve the instance as a Low Uptime Ratio instance, and pay a discounted hourly usage fee in accordance with the associated pricing policy. If the client expects to have a steady-state workload that requires an instance to be up most of the time, the client may reserve a High Uptime Ratio instance and potentially pay an even lower hourly usage fee, although in some embodiments the hourly fee may be charged for the entire duration of the reservation, regardless of the actual number of hours of use, in accordance with pricing policy. An option for Medium Uptime Ratio instances, with a corresponding pricing policy, may be supported in some embodiments as well, where the upfront costs and the per-hour costs fall between the corresponding High Uptime Ratio and Low Uptime Ratio costs.</p><p id="p-0027" num="0026">Compute instance configurations may also include compute instances with a general or specific purpose, such as computational workloads for compute intensive applications (e.g., high-traffic web applications, ad serving, batch processing, video encoding, distributed analytics, high-energy physics, genome analysis, and computational fluid dynamics), graphics intensive workloads (e.g., game streaming, 3D application streaming, server-side graphics workloads, rendering, financial modeling, and engineering design), memory intensive workloads (e.g., high performance databases, distributed memory caches, in-memory analytics, genome assembly and analysis), and storage optimized workloads (e.g., data warehousing and cluster file systems). Size of compute instances, such as a particular number of virtual CPU cores, memory, cache, storage, as well as any other performance characteristic. Configurations of compute instances may also include their location, in a particular data center, availability zone, geographic, location, etc. . . . and (in the case of reserved compute instances) reservation term length.</p><p id="p-0028" num="0027">Storage service <b>240</b> may include various types of storage services, such as different types of storage schemes. An object-based data store may be implemented, in various embodiments, to provide highly durable storage for data objects, such as data records stored as part of a data stream managed by stream management service <b>220</b>. For instance, the object-based data store may be implemented as a key-value data store, where a data object is associated with a unique key. The key for the data object is used to access or manage the data object stored in the object-based data store. Storage service <b>240</b> may also include a data warehouse, in various embodiments, to set up, operate, and scale a data warehouse in a cloud computing environment. Data warehouse clusters hosted by the data warehouse may provide an enterprise-class database query and management system that allows users to scale the clusters, such as by sending a cluster scaling request to a cluster control interface implemented by the web-service. Scaling clusters may allow users of the web service to perform their data warehouse functions, such as fast querying capabilities over structured data, integration with various data loading and ETL (extract, transform, and load) tools, client connections with best-in-class business intelligence (BI) reporting, data mining, and analytics tools, and optimizations for very fast execution of complex analytic queries such as those including multi-table joins, sub-queries, and aggregation, more efficiently. Storage service <b>240</b> may include various types of database systems and other data store schemes, such as a NoSQL database or various types of relational database systems. In at least some embodiments, updates or other interactions with storage service <b>240</b> may be a source for one or multiple data streams for processing by stream processing service <b>220</b>.</p><p id="p-0029" num="0028">Stream management service <b>250</b> may provide programmatic interfaces (e.g., application programming interfaces (APIs), web pages or web sites, graphical user interfaces, or command-line tools) to enable the creation, configuration and deletion of streams. The programmatic interfaces may also enable the submission, storage, analysis, transformation and/or retrieval of streaming data records in some embodiments. Some clients of the stream management system may develop applications that directly invoke the stream management system programmatic interfaces in various embodiments. For example, stream management service <b>250</b> may implement a data ingestion system configured to obtain data records of a particular data stream from data producers (e.g., by operating one or multiple ingestion nodes for a data stream). In some embodiments, data records of a stream may be obtained according to a scheme for partitioning the data stream. The partitioning scheme may be selected by a client of stream management service <b>250</b> for a data stream such that data records are received from data producer(s) indicating the particular partition to which the data record belongs. However, in some embodiments, a data stream may be fully managed by stream management service <b>250</b> and data producer(s) may send data records without any direction for partitioning. Instead, the data ingestion system may assign data records to route the data records to identified partition. Once ingested, stream management service may store obtained data records (e.g., on corresponding storage nodes provisioned for a the data stream). Such storage nodes may record, save, store or otherwise persist the data records on any of various types of storage devices (which may be performed in accordance with a persistence policy for the data stream).</p><p id="p-0030" num="0029">In order to retrieve data from the data stream, stream management service may provide a retrieval system (e.g., implementing retrieval nodes) that may access the stored data records of the data stream. In some embodiments, data retrieval may be performed in response to request from consumers (e.g., stream processing nodes that perform processing on data stream data).</p><p id="p-0031" num="0030">Stream management service <b>250</b> may provide an interface that supports one or more sets of programmatic interfaces (e.g., application programming interfaces (APIs), web pages or web sites, graphical user interfaces, or command-line tools) to enable the creation, configuration and deletion of data streams (both client-managed or fully-managed), as well as the submission, storage and retrieval of stream data records in some embodiments. For instance, data producers may be configured to place data records into a data stream by utilizing a client library provided by stream management service <b>250</b> to utilize requests, sending a &#x201c;putRecord&#x201d; request to stream management service <b>250</b> via the interface. Similarly, data consumer(s) may be configured to access stream management service <b>250</b> via the interface and utilize the client library provided by stream management service <b>250</b> to &#x201c;getNextRecords&#x201d; when executing an application to retrieve the next data records to be processed in the data stream.</p><p id="p-0032" num="0031">Other network-based services <b>260</b> may include various services, including services configure networking of client provider network resources (e.g., load balancing), security (e.g., firewalls, access control), communication (e.g., notification or messaging systems), event driven execution services, visualization services or services for further data processing. External data stream source(s)/destination(s) <b>270</b> may provide data streams which may be processed by stream processing service <b>220</b> and/or serve as destinations for the results generated by stream processing service <b>220</b>. For instance, external data stream sources may be system that collects crowd sourced information (e.g., traffic or temperature) and assembles single data stream of the sourced data for processing to stream processing service <b>220</b>. External data stream source(s)/destination(s) may be a private data store or processing system which may operate further on results reported from stream processing service <b>220</b>.</p><p id="p-0033" num="0032">Clients <b>210</b> may encompass any type of client configurable to submit requests to network provider <b>200</b>. For example, a given client <b>210</b> may include a suitable version of a web browser, or may include a plug-in module or other type of code module configured to execute as an extension to or within an execution environment provided by a web browser. Alternatively, a client <b>210</b> may encompass an application such as a database application (or user interface thereof), a media application, an office application or any other application that may make use of compute instances, a data volume <b>226</b>, or other network-based service in provider network <b>200</b> to perform various operations. In some embodiments, such an application may include sufficient protocol support (e.g., for a suitable version of Hypertext Transfer Protocol (HTTP)) for generating and processing network-based services requests without necessarily implementing full browser support for all types of network-based data. In some embodiments, clients <b>210</b> may be configured to generate network-based services requests according to a Representational State Transfer (REST)-style network-based services architecture, a document- or message-based network-based services architecture, or another suitable network-based services architecture. In some embodiments, a client <b>210</b> (e.g., a computational client) may be configured to provide access to a compute instance or data volume <b>226</b> in a manner that is transparent to applications implement on the client <b>210</b> utilizing computational resources provided by the compute instance or block storage provided by the data volume <b>226</b>.</p><p id="p-0034" num="0033">Clients <b>210</b> may convey network-based services requests to provider network <b>200</b> via external network <b>260</b>. In various embodiments, external network <b>280</b> may encompass any suitable combination of networking hardware and protocols necessary to establish network-based communications between clients <b>210</b> and provider network <b>200</b>. For example, a network <b>280</b> may generally encompass the various telecommunications networks and service providers that collectively implement the Internet. A network <b>280</b> may also include private networks such as local area networks (LANs) or wide area networks (WANs) as well as public or private wireless networks. For example, both a given client <b>210</b> and provider network <b>200</b> may be respectively provisioned within enterprises having their own internal networks. In such an embodiment, a network <b>280</b> may include the hardware (e.g., modems, routers, switches, load balancers, proxy servers, etc.) and software (e.g., protocol stacks, accounting software, firewall/security software, etc.) necessary to establish a networking link between given client <b>210</b> and the Internet as well as between the Internet and provider network <b>200</b>. It is noted that in some embodiments, clients <b>210</b> may communicate with provider network <b>200</b> using a private network rather than the public Internet.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a logical block diagram of a stream processing service that implements automated reconfiguration of real time data stream processing, according to at least some embodiments. Managed stream processing service <b>220</b> may receive stream processing functions via interface <b>312</b> and provision one or more processing nodes <b>370</b> from a pool of processing nodes <b>370</b> to execute the stream processing function. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, managed stream processing service <b>220</b> may implement control plane <b>310</b> to manage the execution of stream processing functions at stream processing nodes <b>370</b>.</p><p id="p-0036" num="0035">In various embodiments, control plane <b>310</b> may implement interface <b>312</b> which may be a programmatic interface invoked by various calls or interactions by clients of managed stream processing service <b>220</b>. For instance, a client may send a request to create a stream processing application that includes a stream processing function. This request may be formatted according to an API call (e.g., &#x201c;createStreamProcessor&#x201d;) and may include as parameters of the call one or more operations to perform with respect to the data stream (e.g. query, add, remove, transform, aggregate, calculate, etc.), input data streams (e.g., data stream names, network addresses, or other identification information), and result destinations (e.g., data store names, network addresses or other identification/connection information. Interface <b>312</b> may be invoked by a command line interface or may be implemented as part of a graphical user interface. Interface <b>312</b> may also provide for the uploading of stream processing functions (e.g., written in a coding language or provided as an executable or other object that may perform stream processing function).</p><p id="p-0037" num="0036">In at least some embodiments, control plane <b>310</b> may implement stream processing function interpretation <b>350</b>. Stream processing interpretation <b>350</b> may provide various libraries, compilers, or any other kind of interpreter that may receive a stream processing function (e.g., operations, input data streams, destinations, etc.) and generate an executable form (e.g., object code, byte code, workflow, or other set of instructions). For example, in some embodiments, processing nodes <b>370</b> may implement a common execution engine so that stream processing functioning interpretation <b>350</b> may provide an executable that can run on any available processing node. In some embodiments, stream processing function interpretation <b>350</b> may validate received stream processing functions for errors (e.g., same input and result destination), leaving interpretation and execution to other components, such as execution engines located at processing nodes <b>370</b>. In various embodiments, stream processing function <b>350</b> may evaluate input data streams to determine a data scheme for the execution of a stream processing function. For instance, stream processing function interpretation may access and analyze a group of data records to determine a schema for the data stream, including labeling or identifying common or expected attributes in data records, which may be provided back to a client via interface <b>312</b>.</p><p id="p-0038" num="0037">In at least some embodiments, control plane <b>310</b> may implement a stream processing function library <b>340</b> which may provide a collection of common and/or user submitted stream processing functions (or individual operations for stream processing functions). For example, stream processing functions to filter, aggregate, or generate a rolling average may be stored as part of stream processing function library <b>340</b>. A client may select a stream processing function from the library and adapt or customize it for execution (e.g., supply input data stream information, result destinations, etc.) via interface <b>312</b>. In this way, stream processing function library <b>340</b> may maintain stream processing functions that are common may be easily adapted for different stream processing applications.</p><p id="p-0039" num="0038">Processing node provisioning <b>330</b> may be implemented as part of control plane <b>310</b>, in various embodiments, in order to provision processing nodes for received stream processing functions. In at least some embodiments, processing node provisioning <b>330</b> may perform a preliminary analysis to determine the processing requirements or configuration for a stream processing function. If, for instance, multiple data input streams are indicated, then processing node provisioning <b>330</b> may determine whether one or multiple processing nodes <b>370</b> may need to be acquired in order to execute the stream processing function. If multiples stream processing nodes may be determined, then processing node provisioning <b>330</b> may determine a mapping scheme to distribute data amongst the processing nodes <b>370</b> and reconstitute or aggregate results from individual processing nodes <b>370</b> for reporting. Processing node provisioning may, as noted above, identify required performance characteristics or other stream processing function requirements and obtain and select the appropriate processing nodes</p><p id="p-0040" num="0039">Once processing nodes <b>370</b> are selected, processing node provisioning <b>330</b> may configure or obtain the appropriate access credentials to provide the processing nodes <b>370</b><i>a </i>with access to the input data streams and result destinations. For instance, if security credentials are required, then processing node provisioning may parse information supplied by a client to managed stream processing service when the stream processing function was submitted in order to extract the security credentials for providing process nodes <b>370</b> with access. Processing node provisioning <b>330</b> may provide the operation(s) and other information to processing nodes <b>370</b> in order to initiate execution of the stream processing function (e.g., by providing a SQL statement, executable, or other instructions for applying the stream processing function), which in some embodiments may be generated by stream processing function interpretation <b>350</b>.</p><p id="p-0041" num="0040">In various embodiments, control plane <b>310</b> may implement processing node management <b>320</b> to manage the execution of stream processing functions at processing nodes <b>370</b>. For instance, based on performance metrics received via stream processing function performance monitoring <b>360</b>, such as metrics that indicate processing utilization, network utilization, memory utilization, or any other computational performance metric, may implement the techniques described above with regard to <figref idref="DRAWINGS">FIG. <b>1</b></figref> and below with regard to <figref idref="DRAWINGS">FIGS. <b>8</b> and <b>9</b></figref>, in order to reconfigure the execution of processing functions at processing nodes <b>370</b> based on collected performance metrics. For instance, performance metrics may indicate that a processing node <b>370</b> is unable to keep up with the stream of data records received (e.g., by measuring result output rates, memory utilization, ingress buffers for network packets, etc.). Processing node management <b>320</b> may request another processing node <b>370</b> from processing node provisioning <b>330</b> in order to split the workload for the one processing node among 2 (or more) processing nodes. Various other management functions, such as migrating a stream processing function from process node to another, changing mappings for partitioned data streams, or any other real time changes in configuration to the execution of a stream processing query may be performed by processing node management <b>320</b>. In some embodiments, clients may submit reconfiguration requests to control plane <b>310</b> to change the execution configuration of data streams (e.g., change the number of processing nodes for a stream processing query).</p><p id="p-0042" num="0041">In some embodiments, control plane <b>310</b> may implement stream processing function performance monitoring <b>360</b>. Performance monitoring <b>360</b> may be implemented in order to provide feedback to processing node management <b>320</b> and/or clients of managed stream processing service <b>220</b>. For instance, a function performance report, may be generated and sent via interface <b>312</b> by performance monitoring <b>360</b>. In some embodiments, stream processing function performance monitoring may detect reconfiguration events for processing functions and notify processing node management <b>320</b> of the detected reconfiguration events.</p><p id="p-0043" num="0042">Managed stream processing service <b>220</b> may implement a pool of stream processing nodes <b>370</b><i>a </i>through <b>370</b><i>n </i>which may be implemented on dedicated hardware hosts (e.g., such as computing system <b>1000</b> in <figref idref="DRAWINGS">FIG. <b>9</b></figref> below) or may be implemented as virtual instances (e.g., by provisioning compute instances of computing service <b>230</b> in FIG. <b>2</b>). <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a logical block diagram of a stream processing node, according to at least some embodiments. Stream processing node <b>400</b> may retrieve data records for data streams in order to apply a stream processing function (or assigned portion/operation of stream processing function and deliver results generated by applying the stream processing function to a specified destination.</p><p id="p-0044" num="0043">Stream processing node <b>400</b> may implement stream data retrieval <b>410</b> in order to interface with a data stream source <b>460</b>. As noted above different types of data stream sources may be implemented. A data stream implemented by a managed stream interface may, for instance, have an interface that allows stream data retrieval to request data stream records <b>402</b> individually. Stream data retrieval <b>410</b> may periodically request <b>402</b> new data records in the stream (e.g., as part of a polling behavior). Throttling, buffer, and other processing rate controls may be implemented by stream data retrieval <b>410</b> in order to prevent stream processing node <b>400</b> from being overwhelmed. For example, a throttle threshold may be implemented that limits the number data records that may be queued or buffered for processing at stream processing node <b>400</b>. A timeout or other delay may be performed when the number of data records exceeds the throttle threshold so that stream processing node <b>400</b> does not drop or otherwise fail to process the data records received a stream processing node <b>400</b>. Stream data retrieval <b>410</b> may obtain or retrieve data records from data stream sources at different rates. In some embodiments, stream data retrieval <b>410</b> may be configured to register and listen for data stream records acting as a network endpoint for data stream source <b>460</b> to automatically send data stream records.</p><p id="p-0045" num="0044">Stream processing nodes <b>400</b> may implement function application engine(s) <b>420</b> to perform the operation(s) of the stream processing function on data records retrieved by stream data retrieval <b>410</b>. In some embodiments, function application engine(s) <b>420</b> may be implemented for a specific scheme or structure of data records. For example, in some embodiments data records may specify data records in a relational format with rows as different data records and columns as different attributes. Function application engine(s) <b>420</b> may act as a storage engine (e.g., SQL engine) that applies the specified operations (e.g., select, add, remove, modify, etc.) to data records according to the scheme of the data records. Thus if function application engine(s) <b>420</b> where a SQL storage engine, for instance, function application engine(s) <b>420</b> would treat a data record as a table and perform the specified operations upon attributes of a data records that mapped to different columns of the table. In some embodiments, function application engine(s) <b>420</b> may be execution platform(s) (e.g., for executables, workflows, or other instructions provided by control plane <b>310</b>) that parses data records, performs the specified operations, and generates the desired results. Note that the previous examples are not intended to be limiting as many different types of function application engine(s) <b>420</b> may be implemented to perform specified operations for a stream processing function. In some embodiments, operations may rely upon function specific data, such as function application data <b>440</b>, to perform operations (e.g., inserting various tags, flags, or other information to enrich a data record). Function application data <b>440</b> may be stored locally at stream processing node <b>400</b> or may be obtained from a remote data store or service (e.g., from storage service <b>240</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>).</p><p id="p-0046" num="0045">Stream processing node <b>400</b> may implement result reporting <b>430</b> to direct the sending of results <b>404</b> to specified destinations. In some embodiments, multiple destinations for results may be specified. As with stream data retrieval <b>410</b>, result reporting <b>430</b> may utilize different programmatic interfaces to register with and obtain access to the specified destinations. Result reporting <b>430</b> may, for example, reformat results <b>404</b> into the appropriate request, format, or scheme in order to ensure proper delivery of the reported results <b>404</b>. Result reporting <b>430</b> may buffer results <b>404</b> into fewer messages in order to reduce network traffic, in some embodiments. In some embodiments, results may be based on processing function (or operation) state that is updated each time a data records is processed, and only provided at certain times. For instance, a running average state for a window of data records may be updated each time a data record is received, but the running average value may only be provided periodically (e.g., every 30 minutes, 1 hour, etc.) In at least some embodiments, data records that do not conform to the data scheme (e.g., missing attributes or different types of attributes, such as when an attribute value is expected to be a string but is instead an integer), may be stored, directed, or otherwise reported to an error store, for reconciliation with the data stream (e.g., by a user).</p><p id="p-0047" num="0046">Result reporting <b>430</b> may track which function results <b>404</b> have been successfully delivered (e.g., by waiting for acknowledgements from the specified destinations) and update execution state for processing function <b>470</b> with identifications of processed data records <b>408</b>. For example, result reporting <b>430</b> may record a time stamp or data record sequence number that identifies the latest data record to be completely processed (including delivery). As multiple data streams (and/or partitions of data streams) may be processed by stream processing node <b>400</b>, execution state may be updated to describe processed data records for each data stream (and/or partition), including various information or metadata about the data stream (and/or partition), such as information that maps the execution state with respect to the individual data streams (and/or partitions). For instance, execution state may be updated to include a sequence number for a last data record that is mapped to data stream source A, a sequence number for a last data record that is mapped to data stream source B, and so on.</p><p id="p-0048" num="0047">In at least some embodiments, stream processing node <b>400</b> may implement performance reporting <b>450</b>. Performance reporting <b>450</b> may collect utilization, timing, and other performance related statistics for the execution of a stream processing function. Performance reporting <b>450</b> may periodically send these performance metrics <b>406</b> to stream processing function performance monitoring <b>360</b> for the various uses discussed above. In some embodiments, performance reporting <b>450</b> may track the performance metrics and provide them upon request from stream processing performance monitoring <b>360</b> (so that stream processing function performance monitoring <b>360</b> may implement a sweeper style metrics gathering in order to avoid being overwhelmed with metrics reporting across a fleet of stream processing nodes <b>400</b>).</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates interactions between a client and a stream processing service via a programmatic interface, according to at least some embodiments. Client <b>500</b> (which may be a client <b>210</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) or other client of managed stream processing service <b>220</b> may be configured to access or request actions via interface <b>312</b>. For instance, a request to enable automatic reconfiguration <b>510</b> may be sent via interface <b>510</b> to managed stream processing service <b>220</b>. The request may simply enable the automatic reconfiguration feature (which may not be performed with prior client enablement) or may include reconfiguration event threshold(s) or other reconfiguration event criteria that specifies how reconfiguration events may be triggered. In this way, a client can optimize reconfigurations to maximize different priorities, such as performance, efficiency, or cost.</p><p id="p-0050" num="0049">Managed stream processing service may, in some embodiments, provide notifications of detected reconfiguration events <b>520</b> via interface <b>312</b> to client <b>500</b>. For example, the notification may include various metadata describing the event (e.g., detection criteria, operation(s) involved, and/or current execution configuration. In at least some embodiments, a description of a new execution configuration for the processing function may be described (e.g., changes in the number or type of nodes). Client <b>500</b> may provide a response <b>530</b> that confirms, denies, or modifies the new execution configuration (e.g., changing node types to reduce cost or increase performance). As illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, client <b>500</b> may also send a request <b>540</b> to disable automatic reconfiguration.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> illustrates an example change in the execution configuration of a processing function. Processing function <b>602</b> may be applied at type A processing node <b>610</b>. A detected reconfiguration event for processing function <b>602</b> may indicate that a different type of processing node should be utilized to apply the processing function. Thus, as the changed execution configuration to the right of the arrow indicates that a different type of processing node has been substituted, type B processing node <b>612</b> (in place of type A processing node). As many different types of processing nodes can be employed to apply processing functions, such a change in execution configuration may be widely applicable to resolve many different performance concerns identified by a reconfiguration event.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> illustrates another example change in the execution configuration of a processing function. A group of processing nodes, processing nodes <b>632</b>, <b>634</b>, and <b>636</b> may be implemented to applying processing function <b>622</b> in parallel. A detected reconfiguration event for processing function <b>622</b> may indicate that a different number of processing nodes should be utilized to apply the processing function. Thus, as the changed execution configuration to the right of the arrow indicates, an additional node is added to the group of nodes, processing node <b>638</b> which also applies processing function <b>622</b>. Mapping information which directs different data records (e.g., from different data streams or partitions of a data stream) to different processing nodes may be updated to redistribute data records to include processing node <b>638</b>. Note that in various embodiments, processing nodes may be added or removed (not illustrated), and as such, a change in the number of nodes determined as part of a new execution configuration may be widely applicable to resolve many different performance concerns identified by a reconfiguration event.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>6</b>C</figref> illustrates another example change in the execution configuration of a processing function. A group of processing nodes, processing nodes <b>652</b> and <b>654</b> may be implemented to different operations in parallel (e.g., operation A for processing function <b>642</b> and operation B for processing function <b>642</b> respectively). However, a detected reconfiguration event for processing function <b>642</b> may indicate that a different number of processing nodes should be utilized to apply operation B for processing function <b>642</b> (e.g., as operation B may be a much more time consuming or resource intensive operation than operation A which may be outputting data faster than operation B can cope with). Thus, as the changed execution configuration to the right of the arrow indicates, additional nodes may be added to the group of nodes, processing nodes <b>656</b> and <b>658</b> which also applies operation B for processing function <b>642</b>. As with <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, note that in various embodiments, processing nodes may be added or removed (not illustrated) for performing specific operations, and as such, a change in the number of nodes performing specific operations determined as part of a new execution configuration may be widely applicable to resolve many different performance concerns identified by a reconfiguration event. Although not illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>C</figref>, a further operation may be added to recombine or aggregate the results of processing nodes <b>654</b>, <b>656</b>, and <b>658</b> into a single set of results that may be transmitted, in some embodiments.</p><p id="p-0054" num="0053">The examples of automated reconfiguration of real time data stream processing as discussed above with regard to <figref idref="DRAWINGS">FIGS. <b>2</b>-<b>6</b>C</figref> have been given in regard to a stream processing service and/or other network-based services. Various other types or configurations of distributed systems processing data from a data stream may implement these techniques. For example, large-scale distributed environments operated by a single business entity may implement managed function execution and automated reconfiguration for processing data streams in real time for its own applications. Moreover, different configurations of the various modules, components, systems, and or services described above that may implement automated reconfiguration of real time data stream processing. Thus the stream management service discussed above serves as one example context in which many of the stream management and processing techniques described herein may be implemented. However, the techniques discussed below with regard to <figref idref="DRAWINGS">FIGS. <b>7</b> and <b>8</b></figref> may be also implemented using the managed stream processing service as discussed above.</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a high-level flowchart illustrating various methods and techniques to provide automated reconfiguration of real time data stream processing, according to at least some embodiments. As noted above processing function may be executed on one or multiple stream processing nodes to perform various operations (e.g., operations to filter, aggregate, modify, transform, separate, or otherwise manipulate data records, including various analytical statistics which can be calculated or tracked for the data stream over time) upon data records of one or more data streams. The processing function may generate different results which may be sent to result destination(s) (e.g., providing data objects, data stores, network addresses, access information/credentials, data formats, multiple destinations, etc.). As the data records are received as part of a data stream, the processing function may be applied in streaming fashion, as data records are received at the processing nodes.</p><p id="p-0056" num="0055">Different performance metrics (e.g., metrics that indicate processor utilization, network utilization, memory utilization, or any other computational performance metric for processing nodes or hosts upon which the nodes are implement, metrics that indicate the behavior of the data stream, rate of data records received, average size of data records, number of data records in processing buffer or queue, or metrics that are specific to the performance of individual operations such as average time to perform a query operation, filter operation, aggregation operation, statistical analysis, etc.). These performance metrics may be reported by processing nodes (e.g., in response to requests for metrics or automatically). As indicated at <b>710</b>, the performance metrics that are collected may be monitored in order to detect a reconfiguration event for the data stream.</p><p id="p-0057" num="0056">A reconfiguration event, as noted above, may be detected when the performance of the processing function (including individual operations within the processing function) and/or processing nodes applying the processing function satisfy reconfiguration event trigger criteria. Reconfiguration event trigger criteria may be specified as thresholds, ranges, anomaly models, or any other conditions that may be determined based on the collected performance metrics. For example, a modeling operation that calculates a running average distribution of attribute values may trigger a reconfiguration event in the event that memory utilization on behalf of generating and maintaining the running average distribution exceeds a memory utilization threshold. In some embodiments, reconfiguration event criteria may be specified by a client. However, in some embodiments, reconfiguration event criteria may be determined by a stream processing system. Reconfiguration event criteria may be configured to optimize the performance of reconfiguration for different priorities, efficient resource utilization, cost (e.g., for service models where the number of nodes or type of nodes drivers the cost of the nodes), or any other operational priority.</p><p id="p-0058" num="0057">As indicated by the positive exit from <b>720</b>, when a reconfiguration event is detected, reconfiguring of the execution of the processing function may be performed. For example, as indicated at <b>730</b>, a different execution configuration may be determined for the processing function, in at least some embodiments. The execution configuration may include the number of processing nodes executing the processing function, the distribution operations of the processing function amongst processing node(s), the types of processing node(s) (e.g., number of processors, bandwidth of network connection, amount of memory, local persistent storage, etc.), increasing the number of nodes performing an operation (e.g., increasing parallelism) or the mapping of data records of the data stream(s) to different process node(s). Consider the example given above, a different execution configuration that may be determined for the processing node performing the running average distribution may include dividing the work of the operation amongst multiple nodes (e.g., increasing parallelization) or changing the processing node to a different type of processing node with a greater amount of memory available for performing the operation. In at least some embodiments, the different execution configuration may include at least one node that is different than the processing node(s) currently executing the processing function.</p><p id="p-0059" num="0058">As indicated at <b>740</b>, the different execution configuration may be initiated for the processing function. In at least some embodiments, the additional or different nodes may be provisioned (e.g., by sending a request to a virtual computing resource service for different compute instances or allocating different dedicated processing node hosts from a pool of processing node hosts to satisfy the different execution configuration (e.g., different node types, additional nodes, etc.). In some embodiments, processing of the data stream records may be suspended upon occurrence of the reconfiguration event so that various changes to update current processing nodes in accordance with the different execution configuration (e.g., changes to operations performed or changes to data stream record mapping). For those nodes that are no longer being utilized in the different execution configuration, the processing nodes may be shutdown, frozen, or otherwise released for performing other operations for other data streams. In some embodiments, a reboot migration operation may be performed to seamless transition the work being performed by one processing node to another by shutting down a current node and booting up a different node that is configured to perform the same operation (e.g., perhaps with different capabilities, such as greater processor speed, memory, or storage). In at least some embodiments, the processing nodes may be continually updating execution state for the processing function so that upon resumption of operations, the last processed data record may be used as the starting point for processing subsequent data records in the data stream(s).</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a high-level flowchart illustrating various methods and techniques to update execution state for a stream processing function in order to resume stream processing upon a reconfiguration event, according to at least some embodiments. As indicated at <b>810</b>, data records of data stream(s) being processed according to a stream processing function may be received at processing node(s), in some embodiments. In some embodiments, results of the operations may be transmitted to specified destinations, as discussed above. The processing node(s) may apply the processing function to the data record(s), as indicated at <b>820</b> (performing various operation(s) according to a current execution configuration). Upon completing the processing of the data records, an execution state for the processing function may be update to identify the data records as processed, as indicated at <b>830</b>. For example, a data record identifier (e.g., a sequence number or timestamp may be recorded as the latest data record to be processed). The execution state may be separately and/or durably stored from a processing node that updates the execution state. As noted above, data records may be processed from multiple different data streams (and/or partitions of data streams), and the execution state of the processing function may reflect the data records processed for each of the different data streams (and/or partitions thereof). Updating may continue until the detection of a reconfiguration event after which processing of data records may be paused or halted.</p><p id="p-0061" num="0060">As indicated by the positive exit from <b>840</b>, if a reconfiguration event is detected, then the execution state for the processing function may be accessed to determine a last record processed for the data stream(s), as indicated at <b>850</b>. For example, the highest sequence number or latest time stamp may be read from execution state, indicating that all data records prior to the sequence number or time stamp have been processed. Similar determinations may be performed for each data stream and/or partition of a data stream in those scenarios where multiple data streams are being processed by the same processing function. Once the last record processed for the data stream(s) is determined, then processing may be able resume at a processing node(s) performing according to a new execution configuration for the processing function, applying the processing function from the last record processed in the data stream (and/or last records for the multiple data streams and/or partitions thereof) before obtaining new data records for processing, as indicated at <b>860</b>. In this way, the processing function may be assured of its application to each data record in the data stream, even those data records that may be received close in time to a reconfiguration event. For those data records received, but not processed, or processed but not recorded as processed in the execution state, the applying function may be applied again in order to ensure that such data records are processed.</p><p id="p-0062" num="0061">The techniques described above may be useful in a number of scenarios. For example, large provider networks may comprise thousands of instance hosts implementing service instances of a number of different multi-tenant or single-tenant services for tens of thousands of clients simultaneously. Monitoring and/or billing agents installed on the various instances and hosts may rapidly generate thousands of metric records, which may need to be stored and analyzed to produce accurate billing records, to determine effective provisioning plans for the data centers of the provider network, to detect network attacks, and the like. The monitoring records may form an input stream to a managed stream processing service so that the techniques described may be implemented for the analysis of the collected records. Similarly, applications to collect and analyze large numbers of log records from numerous log sources (e.g., application logs from the nodes of a distributed application, or system logs from the hosts or compute instances at a data center) may also be able to utilize managed stream processing services. In at least some environments, the processing operations for data records may comprise a real-time ETL (Extract-Transform-Load) processing operation (i.e., an operation that transforms received data records in real time for loading into a destination, instead of doing the transformation offline), or a transformation of data records for insertion into a data warehouse. Using a data stream for loading data into a data warehouse in real time may avoid the delays that are typically required to clean and curate data from one or more data sources, before the data can be inserted into a warehouse for analysis.</p><p id="p-0063" num="0062">A number of different &#x201c;big data&#x201d; applications may also be built using the SMS and processing techniques. For example, the analysis of trends in various forms of social media interactions may be performed efficiently using streams. Data collected from mobile phones or tablet computers, such as location information of the users, may be managed as stream records. Audio or video information, collected for example from a fleet of monitoring cameras may represent another category of streaming data set that could be collected and processed in a scalable manner, potentially helping prevent attacks of various kinds. Scientific applications that require analysis of ever-growing data sets, collected for example from weather satellites, ocean-based sensors, forest-based sensors, astronomical telescopes, may also benefit from the stream management and processing capabilities described herein.</p><p id="p-0064" num="0063">The methods described herein may in various embodiments be implemented by any combination of hardware and software. For example, in one embodiment, the methods may be implemented by a computer system (e.g., a computer system as in <figref idref="DRAWINGS">FIG. <b>9</b></figref>) that includes one or more processors executing program instructions stored on a computer-readable storage medium coupled to the processors. The program instructions may be configured to implement the functionality described herein (e.g., the functionality of various servers, resource hosts, control planes, managers and/or other components, such as those that implement the block-based storage service described herein). The various methods as illustrated in the figures and described herein represent example embodiments of methods. The order of any method may be changed, and various elements may be added, reordered, combined, omitted, modified, etc.</p><p id="p-0065" num="0064">Embodiments of automated reconfiguration of real data stream processing as described herein may be executed on one or more computer systems, which may interact with various other devices. <figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram illustrating an example computer system, according to various embodiments. For example, computer system <b>1000</b> may be configured to implement storage and/or compute nodes of a compute cluster, a data stores, and/or a client, in different embodiments. Computer system <b>1000</b> may be any of various types of devices, including, but not limited to, a personal computer system, desktop computer, laptop or notebook computer, mainframe computer system, handheld computer, workstation, network computer, a consumer device, application server, storage device, telephone, mobile telephone, or in general any type of computing device.</p><p id="p-0066" num="0065">Computer system <b>1000</b> includes one or more processors <b>1010</b> (any of which may include multiple cores, which may be single or multi-threaded) coupled to a system memory <b>1020</b> via an input/output (I/O) interface <b>1030</b>. Computer system <b>1000</b> further includes a network interface <b>1040</b> coupled to I/O interface <b>1030</b>. In various embodiments, computer system <b>1000</b> may be a uniprocessor system including one processor <b>1010</b>, or a multiprocessor system including several processors <b>1010</b> (e.g., two, four, eight, or another suitable number). Processors <b>1010</b> may be any suitable processors capable of executing instructions. For example, in various embodiments, processors <b>1010</b> may be general-purpose or embedded processors implementing any of a variety of instruction set architectures (ISAs), such as the x86, PowerPC, SPARC, or MIPS ISAs, or any other suitable ISA. In multiprocessor systems, each of processors <b>1010</b> may commonly, but not necessarily, implement the same ISA. The computer system <b>1000</b> also includes one or more network communication devices (e.g., network interface <b>1040</b>) for communicating with other systems and/or components over a communications network (e.g. Internet, LAN, etc.).</p><p id="p-0067" num="0066">In the illustrated embodiment, computer system <b>1000</b> also includes one or more persistent storage devices <b>1060</b> and/or one or more I/O devices <b>1080</b>. In various embodiments, persistent storage devices <b>1060</b> may correspond to disk drives, tape drives, solid state memory, other mass storage devices, block-based storage devices, or any other persistent storage device. Computer system <b>1000</b> (or a distributed application or operating system operating thereon) may store instructions and/or data in persistent storage devices <b>1060</b>, as desired, and may retrieve the stored instruction and/or data as needed. For example, in some embodiments, computer system <b>1000</b> may host a storage system server node, and persistent storage <b>1060</b> may include the SSDs attached to that server node.</p><p id="p-0068" num="0067">Computer system <b>1000</b> includes one or more system memories <b>1020</b> that are configured to store instructions and data accessible by processor(s) <b>1010</b>. In various embodiments, system memories <b>1020</b> may be implemented using any suitable memory technology, (e.g., one or more of cache, static random access memory (SRAM), DRAM, RDRAM, EDO RAM, DDR 10 RAM, synchronous dynamic RAM (SDRAM), Rambus RAM, EEPROM, non-volatile/Flash-type memory, or any other type of memory). System memory <b>1020</b> may contain program instructions <b>1025</b> that are executable by processor(s) <b>1010</b> to implement the methods and techniques described herein. In various embodiments, program instructions <b>1025</b> may be encoded in platform native binary, any interpreted language such as Java&#x2122; byte-code, or in any other language such as C/C++, Java&#x2122;, etc., or in any combination thereof. For example, in the illustrated embodiment, program instructions <b>1025</b> include program instructions executable to implement the functionality of a resource host, in different embodiments. In some embodiments, program instructions <b>1025</b> may implement multiple separate clients, nodes, and/or other components.</p><p id="p-0069" num="0068">In some embodiments, program instructions <b>1025</b> may include instructions executable to implement an operating system (not shown), which may be any of various operating systems, such as UNIX, LINUX, Solaris&#x2122;, MacOS&#x2122;, Windows&#x2122;, etc. Any or all of program instructions <b>1025</b> may be provided as a computer program product, or software, that may include a non-transitory computer-readable storage medium having stored thereon instructions, which may be used to program a computer system (or other electronic devices) to perform a process according to various embodiments. A non-transitory computer-readable storage medium may include any mechanism for storing information in a form (e.g., software, processing application) readable by a machine (e.g., a computer). Generally speaking, a non-transitory computer-accessible medium may include computer-readable storage media or memory media such as magnetic or optical media, e.g., disk or DVD/CD-ROM coupled to computer system <b>1000</b> via I/O interface <b>1030</b>. A non-transitory computer-readable storage medium may also include any volatile or non-volatile media such as RAM (e.g. SDRAM, DDR SDRAM, RDRAM, SRAM, etc.), ROM, etc., that may be included in some embodiments of computer system <b>1000</b> as system memory <b>1020</b> or another type of memory. In other embodiments, program instructions may be communicated using optical, acoustical or other form of propagated signal (e.g., carrier waves, infrared signals, digital signals, etc.) conveyed via a communication medium such as a network and/or a wireless link, such as may be implemented via network interface <b>1040</b>.</p><p id="p-0070" num="0069">In some embodiments, system memory <b>1020</b> may include data store <b>1045</b>, which may be configured as described herein. In general, system memory <b>1020</b> (e.g., data store <b>1045</b> within system memory <b>1020</b>), persistent storage <b>1060</b>, and/or remote storage <b>1070</b> may store data blocks, replicas of data blocks, metadata associated with data blocks and/or their state, configuration information, and/or any other information usable in implementing the methods and techniques described herein.</p><p id="p-0071" num="0070">In one embodiment, I/O interface <b>1030</b> may be configured to coordinate I/O traffic between processor <b>1010</b>, system memory <b>1020</b> and any peripheral devices in the system, including through network interface <b>1040</b> or other peripheral interfaces. In some embodiments, I/O interface <b>1030</b> may perform any necessary protocol, timing or other data transformations to convert data signals from one component (e.g., system memory <b>1020</b>) into a format suitable for use by another component (e.g., processor <b>1010</b>). In some embodiments, I/O interface <b>1030</b> may include support for devices attached through various types of peripheral buses, such as a variant of the Peripheral Component Interconnect (PCI) bus standard or the Universal Serial Bus (USB) standard, for example. In some embodiments, the function of I/O interface <b>1030</b> may be split into two or more separate components, such as a north bridge and a south bridge, for example. Also, in some embodiments, some or all of the functionality of I/O interface <b>1030</b>, such as an interface to system memory <b>1020</b>, may be incorporated directly into processor <b>1010</b>.</p><p id="p-0072" num="0071">Network interface <b>1040</b> may be configured to allow data to be exchanged between computer system <b>1000</b> and other devices attached to a network, such as other computer systems <b>1090</b>, for example. In addition, network interface <b>1040</b> may be configured to allow communication between computer system <b>1000</b> and various I/O devices <b>1050</b> and/or remote storage <b>1070</b>. Input/output devices <b>1050</b> may, in some embodiments, include one or more display terminals, keyboards, keypads, touchpads, scanning devices, voice or optical recognition devices, or any other devices suitable for entering or retrieving data by one or more computer systems <b>1000</b>. Multiple input/output devices <b>1050</b> may be present in computer system <b>1000</b> or may be distributed on various nodes of a distributed system that includes computer system <b>1000</b>. In some embodiments, similar input/output devices may be separate from computer system <b>1000</b> and may interact with one or more nodes of a distributed system that includes computer system <b>1000</b> through a wired or wireless connection, such as over network interface <b>1040</b>. Network interface <b>1040</b> may commonly support one or more wireless networking protocols (e.g., Wi-Fi/IEEE 802.11, or another wireless networking standard). However, in various embodiments, network interface <b>1040</b> may support communication via any suitable wired or wireless general data networks, such as other types of Ethernet networks, for example. Additionally, network interface <b>1040</b> may support communication via telecommunications/telephony networks such as analog voice networks or digital fiber communications networks, via storage area networks such as Fibre Channel SANs, or via any other suitable type of network and/or protocol. In various embodiments, computer system <b>1000</b> may include more, fewer, or different components than those illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref> (e.g., displays, video cards, audio cards, peripheral devices, other network interfaces such as an ATM interface, an Ethernet interface, a Frame Relay interface, etc.)</p><p id="p-0073" num="0072">It is noted that any of the distributed system embodiments described herein, or any of their components, may be implemented as one or more network-based services. For example, a compute cluster within a computing service may present computing and/or storage services and/or other types of services that employ the distributed computing systems described herein to clients as network-based services. In some embodiments, a network-based service may be implemented by a software and/or hardware system designed to support interoperable machine-to-machine interaction over a network. A network-based service may have an interface described in a machine-processable format, such as the Web Services Description Language (WSDL). Other systems may interact with the network-based service in a manner prescribed by the description of the network-based service's interface. For example, the network-based service may define various operations that other systems may invoke, and may define a particular application programming interface (API) to which other systems may be expected to conform when requesting the various operations. though</p><p id="p-0074" num="0073">In various embodiments, a network-based service may be requested or invoked through the use of a message that includes parameters and/or data associated with the network-based services request. Such a message may be formatted according to a particular markup language such as Extensible Markup Language (XML), and/or may be encapsulated using a protocol such as Simple Object Access Protocol (SOAP). To perform a network-based services request, a network-based services client may assemble a message including the request and convey the message to an addressable endpoint (e.g., a Uniform Resource Locator (URL)) corresponding to the network-based service, using an Internet-based application layer transfer protocol such as Hypertext Transfer Protocol (HTTP).</p><p id="p-0075" num="0074">In some embodiments, network-based services may be implemented using Representational State Transfer (&#x201c;RESTful&#x201d;) techniques rather than message-based techniques. For example, a network-based service implemented according to a RESTful technique may be invoked through parameters included within an HTTP method such as PUT, GET, or DELETE, rather than encapsulated within a SOAP message.</p><p id="p-0076" num="0075">Various embodiments may further include receiving, sending or storing instructions and/or data implemented in accordance with the foregoing description upon a computer-accessible medium. Generally speaking, a computer-accessible medium may include storage media or memory media such as magnetic or optical media, e.g., disk or DVD/CD-ROM, volatile or non-volatile media such as RAM (e.g. SDRAM, DDR, RDRAM, SRAM, etc.), ROM, etc., as well as transmission media or signals such as electrical, electromagnetic, or digital signals, conveyed via a communication medium such as network and/or a wireless link.</p><p id="p-0077" num="0076">The various methods as illustrated in the Figures and described herein represent exemplary embodiments of methods. The methods may be implemented in software, hardware, or a combination thereof. The order of method may be changed, and various elements may be added, reordered, combined, omitted, modified, etc.</p><p id="p-0078" num="0077">Various modifications and changes may be made as would be obvious to a person skilled in the art having the benefit of this disclosure. It is intended to embrace all such modifications and changes and, accordingly, the above description to be regarded in an illustrative rather than a restrictive sense.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system, comprising:<claim-text>a plurality of compute nodes, respectively comprising at least one processor and a memory, wherein the plurality of compute nodes implement a managed stream processing system comprising a control plane and a plurality of stream processing nodes;</claim-text><claim-text>the control plane, configured to:<claim-text>collect performance metrics for one or more of the processing nodes that execute a processing function for a data stream that applies the processing function to data records of the data stream as they are received;</claim-text><claim-text>based, at least in part, on an analysis of the performance metrics, detect a reconfiguration event for the processing function;</claim-text><claim-text>in response to the detection of the reconfiguration event:<claim-text>determine a different execution configuration for the processing function such that at least one different processing node is executing the processing function; and</claim-text><claim-text>initiate the different execution configuration for the processing function.</claim-text></claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the control plane is further configured to perform the initiation of the different execution configuration in further response to receipt of a confirmation indication from a client of the managed stream processing system.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing function processes one or more different data streams in addition to the data stream, wherein the one or more processing nodes are configured to update an execution state in a durable data store for the processing function as the processing function is applied to data records of the data stream and the one or more different data streams, and wherein to initiate the different execution configuration for the processing function, the control plane is configured to determine respective last processed data records for the data stream and the one or more different data streams such that execution of the processing function resumes from the respective last processed data records of the data stream and the one or more different data streams.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the managed stream processing system is a network based service implemented as part of a provider network and wherein the one or more processing nodes are implemented as virtual computing resources hosted by a virtual computing service implemented as part of the provider network.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. A method, comprising:<claim-text>performing, by one or more computing devices:<claim-text>evaluating one or more performance metrics describing one or more processing nodes executing a processing function for a data stream that applies the processing function to data records of the data stream as they are received;</claim-text><claim-text>based, at least in part, on the evaluating, detecting an event to reconfigure the execution of the processing function;</claim-text><claim-text>in response to detecting the event, reconfiguring the execution of the processing function to reallocate execution of the processing function to include at least one different processing node.</claim-text></claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising requesting, from the one or more processing nodes, the one or more performance metrics describing the one or more processing nodes executing the processing function for the data stream.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the evaluating the one or more performance metrics and the detecting the event are performed in response to receiving a request to enable automatic reconfiguration for the execution of the processing function from a client via a programmatic interface.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the request to enable automatic reconfiguration comprises a reconfiguration event threshold and wherein detecting the event for the processing function comprises determining that the one or more performance metrics exceed the reconfiguration event threshold.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the at least one different processing node is a different type of processing node than the one or more processing nodes, and wherein reconfiguring the execution of the processing function comprises selecting the different type of processing node for the execution of the processing function based, at least in part, on the one or more performance metrics.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein reconfiguring the execution of the processing function comprises at least one of:<claim-text>adding one or more additional processing nodes including the at least one different node; or</claim-text><claim-text>removing at least one of the one or more processing nodes.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the data stream is one of a plurality of data streams upon which the processing function is executing, and wherein reconfiguring the execution of the processing function comprises determining a different data stream mapping for applying the processing function at a plurality of processing nodes including the at least one different processing node to reallocate processing of the plurality of data streams.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>,<claim-text>wherein the method further comprises updating, by the one or more processing nodes, an execution state for the processing function as the processing function is applied to the data records of the data stream; and</claim-text><claim-text>wherein reconfiguring the execution of the processing function comprises determining a last processed data record of the data stream such that the at least one different processing node resumes application of the processing function from the last processed data record in the data stream.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the processing function executes upon one or more other data streams in addition to the data stream, wherein updating the execution state for the processing function further comprises updating the execution state as other data records from the one or more other data streams are processed, and wherein reconfiguring the execution of the processing function further comprises determining respective last processed data records for the one or more other data streams so that execution of the processing function resumes from the respective last processed data records for the one or more data streams.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A non-transitory, computer-readable storage medium, storing program instructions that when executed by one or more computing devices cause the one or more computing devices to implement:<claim-text>monitoring performance metrics collected for one or more processing nodes executing a processing function for a data stream that applies the processing function to data records of the data stream as they are received;</claim-text><claim-text>based, at least in part, on the monitoring, detecting a reconfiguration event for the processing function;</claim-text><claim-text>in response to detecting the reconfiguration event:<claim-text>determining a different execution configuration for the processing function that reallocates execution of the processing function for least one processing node; and</claim-text><claim-text>initiating the different execution configuration for the processing function.</claim-text></claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The non-transitory, computer-readable storage medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the program instructions cause the one or more computing devices to implement performing the initiating the different execution configuration for the processing function in further response to receiving a confirmation of the different execution configuration from a client via a programmatic interface.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The non-transitory, computer-readable storage medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein monitoring the performance metrics and detecting the reconfiguration event are performed in response to receiving a request to enable automatic reconfiguration for the execution of the processing function from a client via a programmatic interface.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory, computer-readable storage medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein in response to receiving a request to disable automatic reconfiguration for the execution of the processing function from the client via the programmatic interface, the program instructions cause the one or more computing devices to implement halting the monitoring of the performance metrics.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory, computer-readable storage medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>,<claim-text>wherein the program instructions cause the one or more computing devices to further implement updating, by the one or more processing nodes, an execution state for the processing function as the processing function is applied to the data records of the data stream; and</claim-text><claim-text>wherein, in reconfiguring the execution of the processing function, the program instructions cause the one or more computing devices to implement determining a last processed data record of the data stream such that the at least one different processing node resumes application of the processing function from the last processed data record in the data stream.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory, computer-readable storage medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the processing function comprises a plurality of operations performed at different ones of the one or more processing nodes, and wherein in determining the different execution configuration for the processing function the program instructions cause the one or more computing devices to implement configuring the at least one processing node to perform one of the operations to increase a number of processing nodes performing the operation.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory, computer-readable storage medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the managed stream processing system is a network based service implemented as part of a provider network and wherein the data stream is produced by another network-based service implemented as part of the provider network.</claim-text></claim></claims></us-patent-application>
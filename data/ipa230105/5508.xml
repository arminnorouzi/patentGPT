<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005509A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005509</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17365101</doc-number><date>20210701</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>11</class><subclass>B</subclass><main-group>27</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>11</class><subclass>B</subclass><main-group>27</main-group><subgroup>036</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>11</class><subclass>B</subclass><main-group>27</main-group><subgroup>034</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>11</class><subclass>B</subclass><main-group>27</main-group><subgroup>36</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>783</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>11</class><subclass>B</subclass><main-group>27</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>11</class><subclass>B</subclass><main-group>27</main-group><subgroup>036</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>11</class><subclass>B</subclass><main-group>27</main-group><subgroup>034</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>11</class><subclass>B</subclass><main-group>27</main-group><subgroup>36</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>783</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEMS AND METHODS FOR PROCESSING VIDEO DATA</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant-inventor" designation="us-only" applicant-authority-category="inventor"><addressbook><last-name>MENDEL</last-name><first-name>Christopher Kyle</first-name><address><city>Houston</city><state>TX</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant><us-applicant sequence="01" app-type="applicant-inventor" designation="us-only" applicant-authority-category="inventor"><addressbook><last-name>COX</last-name><first-name>Jay Lawrence</first-name><address><city>Trenton</city><state>MI</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant><us-applicant sequence="02" app-type="applicant-inventor" designation="us-only" applicant-authority-category="inventor"><addressbook><last-name>KEIERLEBER</last-name><first-name>Peter</first-name><address><city>Sugar Land</city><state>TX</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant><us-applicant sequence="03" app-type="applicant" designation="us-only"><addressbook><last-name>REDDING, JR.</last-name><first-name>James Perry</first-name><address><city>Spring</city><state>TX</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MENDEL</last-name><first-name>Christopher Kyle</first-name><address><city>Houston</city><state>TX</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>COX</last-name><first-name>Jay Lawrence</first-name><address><city>Trenton</city><state>MI</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>KEIERLEBER</last-name><first-name>Peter</first-name><address><city>Sugar Land</city><state>TX</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>REDDING, JR.</last-name><first-name>James Perry</first-name><address><city>Spring</city><state>TX</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method includes obtaining video data for a first set of video files, generating processing job data for a first video processing job based on the video data, identifying a first processing server having a capacity for handling the first video processing job, sending, to the first processing server, the processing job data for the first video processing job and a first request to validate the video data, receiving, from the first processing server, validation testing results in connection with the first set of video files, determining first transcoding parameters for the first set of video files based on the validation testing results and output requirements data for the first video processing job, and sending, to the first processing server, a second request to generate an output video based on the first set of video files, the second request including an indication of the first transcoding parameters.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="172.30mm" wi="147.32mm" file="US20230005509A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="198.97mm" wi="149.35mm" file="US20230005509A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="200.15mm" wi="142.07mm" file="US20230005509A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="209.30mm" wi="96.18mm" file="US20230005509A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="185.50mm" wi="107.61mm" file="US20230005509A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="200.91mm" wi="153.84mm" file="US20230005509A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="217.34mm" wi="93.64mm" file="US20230005509A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present disclosure relates to data processing and, in particular, to systems and methods for automating video data processing for large quantities of video files.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">The statements in this section merely provide background information related to the present disclosure and may not constitute prior art.</p><p id="p-0004" num="0003">Advances in mobile and video technologies now enable capture of video data across many different devices, platforms, and file formats. Videos can be recorded using cameras on various different types of devices, and recorded videos can be saved (e.g., stored in memory) or streamed for consumption by viewers. Digital video files may vary in properties such as file format, frame rate, bit rate, video dimensions, file size, etc.</p><p id="p-0005" num="0004">Video files may sometimes be processed in bulk. By way of example, video editing software may be used to splice together multiple input video files of the same format (i.e., encoding format) to generate a single output video. When the input files all have the same or largely the same video properties, a standard batch processing solution may be sufficient for handling batch operations such as splicing, encoding, and the like. However, a standard batch solution is generally not suitable for video processing jobs involving input files that vary substantially in video properties and complex requirements for output videos.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0006" num="0005">This section provides a general summary of the disclosure and is not a comprehensive disclosure of its full scope or all of its features.</p><p id="p-0007" num="0006">In an aspect, a computing device is disclosed. The computing device includes a processor, a communications module coupled to the processor, and a memory coupled to the processor. The memory stores instructions that, when executed, configure the processor to: obtain video data for a first set of video files; generate processing job data for a first video processing job based on the video data for the first set of video files; identify a first processing server having a capacity for handling the first video processing job; send, to the first processing server, the processing job data for the first video processing job and a first request to validate the video data for the first set of video files; receive, from the first processing server, validation testing results in connection with the first set of video files; determine first transcoding parameters for the first set of video files based on the validation testing results and output requirements data for the first video processing job; and send, to the first processing server, a second request to generate an output video based on the first set of video files, the second request including an indication of the first transcoding parameters.</p><p id="p-0008" num="0007">In some implementations, the first transcoding parameters may comprise settings for use in performing at least one of: splicing together two or more of the video files of the first set; or converting at least one of the video files of the first set to a target format.</p><p id="p-0009" num="0008">In some implementations, when the processor is configured to obtain the video data for the first set of video files, the processor is further configured to: monitor one or more data stores configured for storing video files; detect a trigger event in connection with the one or more data stores; and in response to detecting the trigger event, retrieve video data associated with the first set of video files from the one or more data stores.</p><p id="p-0010" num="0009">In some implementations, when the processor is configured to detect the trigger event, the processor is further configured to detect start of an upload of at least one video file to the one or more data stores.</p><p id="p-0011" num="0010">In some implementations, when the processor is configured to detect the trigger event, the processor is further configured to detect completion of the upload based on determining that total size of uploaded files remains substantially constant for at least a defined length of time.</p><p id="p-0012" num="0011">In some implementations, the validation testing results may comprise, for each of one or more of the video files of the first set, at least one of: video display resolution; video codecs; audio codecs; or video compression settings.</p><p id="p-0013" num="0012">In some implementations, when the processor is configured to identify the first processing server, the processor is further configured to determine, for each of a plurality of remote computing systems, a current processing capacity of the remote computing system.</p><p id="p-0014" num="0013">In some implementations, when the processor is configured to determine the current processing capacity of the remote computing system, the processor is further configured to send, to the remote computing system, a query for obtaining at least one of processing power or available memory associated with the remote computing system.</p><p id="p-0015" num="0014">In some implementations, when the processor is configured to generate the processing job data, the processor is further configured to determine that the first set of video files is associated with a same processing job based on at least one of: metadata associated with the video files of the first set; file names of the video files of the first set; or an inventory list identifying constituent video files of a desired output video.</p><p id="p-0016" num="0015">In some implementations, the instructions, when executed, may further configure the processor to: determine, based on the validation testing results, that at least one of the video files of the first set is defective; and in response to determining that the at least one video file is defective, terminate the first video processing job.</p><p id="p-0017" num="0016">In another aspect, a computer-implemented method is disclosed. The method includes: obtaining video data for a first set of video files; generating processing job data for a first video processing job based on the video data for the first set of video files; identifying a first processing server having a capacity for handling the first video processing job; sending, to the first processing server, the processing job data for the first video processing job and a first request to validate the video data for the first set of video files; receiving, from the first processing server, validation testing results in connection with the first set of video files; determining first transcoding parameters for the first set of video files based on the validation testing results and output requirements data for the first video processing job; and sending, to the first processing server, a second request to generate an output video based on the first set of video files, the second request including an indication of the first transcoding parameters.</p><p id="p-0018" num="0017">In yet another aspect, a non-transitory computer readable storage medium is disclosed. The computer readable storage medium contains instructions thereon which, when executed by a processor, configure the processor to: obtain video data for a first set of video files; generate processing job data for a first video processing job based on the video data for the first set of video files; identify a first processing server having a capacity for handling the first video processing job; send, to the first processing server, the processing job data for the first video processing job and a first request to validate the video data for the first set of video files; receive, from the first processing server, validation testing results in connection with the first set of video files; determine first transcoding parameters for the first set of video files based on the validation testing results and output requirements data for the first video processing job; and send, to the first processing server, a second request to generate an output video based on the first set of video files, the second request including an indication of the first transcoding parameters.</p><p id="p-0019" num="0018">Further areas of applicability will become apparent from the description provided herein. It should be understood that the description and specific examples are intended for purposes of illustration only and are not intended to limit the scope of the present disclosure. Other example embodiments of the present disclosure will be apparent to those of ordinary skill in the art from a review of the following detailed descriptions in conjunction with the drawings.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0020" num="0019">Reference will now be made, by way of example, to the accompanying drawings which show example embodiments of the present application and in which:</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram illustrating an operating environment of an example embodiment;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> is a high-level schematic diagram of an example computing device;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> is a schematic block diagram showing an example organization of software components stored in memory of the example computing device of <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows, in flowchart form, an example method for managing video data processing of input video files associated with a video processing job;</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows, in flowchart form, an example method for generating processing job data for a video processing job;</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows, in flowchart form, an example method for determining transcoding parameters for input video files associated with a video processing job; and</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows, in flowchart form, an example method for processing and testing input video files associated with a video processing job.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0028" num="0027">Like reference numerals are used in the drawings to denote like elements and features. The drawings described herein are for illustration purposes only and are not intended to limit the scope of the present disclosure in any way.</p><heading id="h-0005" level="1">DETAILED DESCRIPTION OF EXAMPLE EMBODIMENTS</heading><p id="p-0029" num="0028">The following description is merely exemplary in nature and is not intended to limit the present disclosure, application, or uses. It should be understood that throughout the drawings, corresponding reference numerals indicate like or corresponding parts and features.</p><p id="p-0030" num="0029">In the present application, the term &#x201c;and/or&#x201d; is intended to cover all possible combinations and sub-combinations of the listed elements, including any one of the listed elements alone, any sub-combination, or all of the elements, and without necessarily excluding additional elements.</p><p id="p-0031" num="0030">In the present application, the phrase &#x201c;at least one of . . . or . . . &#x201d; is intended to cover any one or more of the listed elements, including any one of the listed elements alone, any sub-combination, or all of the elements, without necessarily excluding any additional elements, and without necessarily requiring all of the elements.</p><p id="p-0032" num="0031">The advances in mobile and video technologies have made video content creation readily accessible for the masses. Videos may be created using a wide range of device types (e.g., digital cameras, mobile phones, and the like). As a result, video files may vary in properties such as file format, frame rate, bit rate, video dimensions, file size, etc. In particular, videos that are generated on different devices or for different purposes may vary substantially in their video properties.</p><p id="p-0033" num="0032">Certain applications may require bulk processing of video files. As a specific example, court proceedings may have defined requirements for compression settings, video resolutions, and/or output formats for video files that are admissible as evidence. The requirements may need to be met in order for the video files to be used with courtroom-approved software and/or hardware for playing video to a jury. Video recordings of depositions, including remotely recorded testimonies, may be received from a wide range of different sources (e.g., different camera models). The recordings may thus vary in video properties such as video resolution, compression scheme, and the like. Further, the recordings may comprise one or more sets of video files that relate to the same subject matter (e.g., a single testimony). For example, a single testimony may result in creation of multiple video files due to storage limitations on the recording camera, etc. The video recordings may need to be spliced together to generate output videos that are suitable for presenting in courtrooms.</p><p id="p-0034" num="0033">Traditional video processing solutions are not properly equipped for handling batch operations for video files that vary in video properties. In particular, due to complexities relating to compression formats, requirements for proper splicing, and verification of input video quality and settings, standard encoding software is generally insufficient for batch processing of large collections of videos. Instead, the generation of output videos (e.g., for use in courtrooms) requires extensive manual intervention for collecting video recordings, splicing the videos together, determining compression formats and resolutions, and configuring a video transcoding device to operate according to parameters that align with the output video requirements.</p><p id="p-0035" num="0034">Various technical solutions for batch processing of video files that overcome the aforementioned challenges are described in the present disclosure.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an exemplary computing environment <b>100</b> consistent with certain disclosed embodiments. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the computing environment <b>100</b> may include one or more client devices <b>110</b>, a management server <b>150</b>, a database <b>151</b> associated with the management server <b>150</b>, one or more video processing servers <b>160</b>, an input videos data store <b>170</b>, a completed jobs data store <b>180</b>, and a communications network <b>120</b> connecting one or more of the components of computing environment <b>100</b>.</p><p id="p-0037" num="0036">As illustrated, a management server <b>150</b> (which may also be referred to as a server computing system) and client device <b>110</b> communicate via the network <b>120</b>. In at least some embodiments, the client device <b>110</b> is a computing device. The client device <b>110</b> may take a variety of forms including, for example, a mobile communication device such as a smartphone, a tablet computer, a wearable computer such as a head-mounted display or smartwatch, a laptop or desktop computer, or a computing device of another type. The client device <b>110</b> is associated with a specific entity, such as an individual or an organization. The client device <b>110</b> may store software instructions that cause the client device to establish communications with the management server <b>150</b> and, in some embodiments, one or more of the video processing servers <b>160</b>, the input videos data store <b>170</b>, or the completed jobs data store <b>180</b>.</p><p id="p-0038" num="0037">In one form, the management server <b>150</b> is a computing system. More specifically, the management server <b>150</b> implements a system for automatically handling video processing jobs. A video processing job refers to the production of custom work based on processing one or more video files. The custom work may, for example, be an output video that is produced based on one or more input video files. A processing job involves defined tasks (or operations) that are performed in order to produce an output (or &#x201c;complete&#x201d; the job).</p><p id="p-0039" num="0038">In one form, the management server <b>150</b> may receive requests to handle video processing jobs from multiple different entities and manage the operations for completing the requested video processing jobs. The requests may be received, for example, via a user interface associated with the management server <b>150</b>. That is, a user interface may be provided (e.g., on the client device <b>110</b>) for requesting and/or accessing video processing jobs to be handled by the management server <b>150</b>. A request may indicate various information about a video processing job. For example, a request may include identifying information about the requesting entity, description of the input video files, an indication of a location (e.g., a data store) where the input video files are stored/uploaded, and requirements data for output video products. The management server <b>150</b> may be configured to update the user interface based on information about the requested video processing jobs.</p><p id="p-0040" num="0039">In one form, the computing environment <b>100</b> includes at least one video processing server <b>160</b>. In one form, the video processing server <b>160</b> is a computing system. More specifically, the video processing server <b>160</b> is configured to perform various processing operations in connection with video files that are associated with one or more video processing jobs. The management server <b>150</b> interfaces with the one or more video processing servers <b>160</b>. In particular, the management server <b>150</b> may query a set of video processing servers <b>160</b> to identify a server that has available processing power and memory capacity to process a video processing job. Upon identifying a suitable one of the video processing servers <b>160</b> for a particular job, the management server <b>150</b> assigns the job to the identified server <b>160</b> for processing. The identified server <b>160</b> then performs one or more defined operations, such as video splicing, transcoding, etc., in connection with the assigned job based on the video files that are associated with the job.</p><p id="p-0041" num="0040">In addition to editing and converting video files, the video processing servers <b>160</b> may also be configured to perform validation testing of the video files. That is, the video processing servers <b>160</b> may be configured to test video assets (the terms &#x201c;video files&#x201d; and &#x201c;video assets&#x201d; are used interchangeably herein) for problems and/or errors. In performing validation testing, the video processing server <b>160</b> may obtain various information about the video files. In particular, the video processing server <b>160</b> may ascertain video properties, such as resolution, length, compression format, etc., of the video files. The results of the validation testing may be communicated, for example, to the management server <b>150</b>. Specifically, a video processing server <b>160</b> that is assigned a video processing job by the management server <b>150</b> may provide, to the management server <b>150</b>, validation testing results for the video files that are associated with the assigned job.</p><p id="p-0042" num="0041">The computing environment <b>100</b> includes an input videos data store <b>170</b>. In some embodiments, the input videos data store <b>170</b> may be a database where input video files for video processing jobs are stored. For example, the input videos data store <b>170</b> may be one of a set of designated locations that the management server <b>150</b> monitors to detect an upload of video files for new processing jobs.</p><p id="p-0043" num="0042">The computing environment <b>100</b> also includes a completed jobs data store <b>180</b>. In some embodiments, the completed jobs data store <b>180</b> may be a database that stores output videos associated with video processing jobs. In particular, a video processing server <b>160</b> that completes a job may store the output video(s) in the completed jobs data store <b>180</b>. The completed jobs data stores <b>180</b> may also store job description data associated with one or more video processing jobs. The job description data for a job may indicate, for example, number and identities of input video files, duration of the job, video splicing order, encoding format, and validation testing results for the input and/or output video files.</p><p id="p-0044" num="0043">The client device <b>110</b>, the management server <b>150</b>, the video processing servers <b>160</b>, the input videos data store <b>170</b> and the completed jobs data store <b>180</b> may be in geographically disparate locations. Put differently, the client device <b>110</b> may be remote from one or both of the management server <b>150</b>, the video processing servers <b>160</b>, the input videos data store <b>170</b> and the completed jobs data store <b>180</b>. As described above, client device <b>110</b>, the management server <b>150</b>, the video processing servers <b>160</b> may be computing systems.</p><p id="p-0045" num="0044">The network <b>120</b> is a computer network. In some embodiments, the network <b>120</b> may be an internetwork such as may be formed of one or more interconnected computer networks. For example, the network <b>120</b> may be or may include an Ethernet network, an asynchronous transfer mode (ATM) network, a wireless network, or the like.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> is a high-level operation diagram of an example computing device <b>105</b>. In some embodiments, the example computing device <b>105</b> may be exemplary of one or more of the client devices <b>110</b>, the management server <b>150</b>, or the video processing servers <b>160</b>. The example computing device <b>105</b> includes a variety of modules. For example, as illustrated, the example computing device <b>105</b>, may include a processor <b>200</b>, a memory <b>210</b>, an input interface module <b>220</b>, an output interface module <b>230</b>, and a communications module <b>240</b>. As illustrated, the foregoing example modules of the example computing device <b>105</b> are in communication over a bus <b>250</b>.</p><p id="p-0047" num="0046">In one form, the processor <b>200</b> is a hardware processor. The processor <b>200</b> may, for example, be one or more ARM, Intel x86, PowerPC processors or the like.</p><p id="p-0048" num="0047">In one form, the memory <b>210</b> is configured to store and retrieve data. The memory <b>210</b> may include, for example, random access memory, read-only memory, and persistent storage. Persistent storage may be, for example, flash memory, a solid-state drive or the like. Read-only memory and persistent storage are a computer-readable medium. A computer-readable medium may be organized using a file system and as such may be administered by an operating system governing overall operation of the example computing device <b>105</b>.</p><p id="p-0049" num="0048">In one form, the input interface module <b>220</b> is configured to receive input signals. Input signals may, for example, correspond to input received from a user. The input interface module <b>220</b> may serve to interconnect the example computing device <b>105</b> with one or more input devices. Input signals may be received from input devices by the input interface module <b>220</b>. Input devices may, for example, include one or more of a touchscreen input, keyboard, trackball or the like. In some embodiments, all or a portion of the input interface module <b>220</b> may be integrated with an input device. For example, the input interface module <b>220</b> may be integrated with one of the aforementioned example input devices.</p><p id="p-0050" num="0049">In one form, the output interface module <b>230</b> is configured to provide output signals. Some output signals may, for example, provide for a provision of output to a user. The output interface module <b>230</b> may serve to interconnect the example computing device <b>105</b> with one or more output devices. Output signals may be sent to output devices by output interface module <b>230</b>. Output devices may include, for example, a display screen such as, for example, a liquid crystal display (LCD), a touchscreen display. Additionally, or alternatively, output devices may include devices other than screens such as, for example, a speaker, indicator lamps (such as for, example, light-emitting diodes (LEDs)), and printers. In some embodiments, all or a portion of the output interface module <b>230</b> may be integrated with an output device. For example, the output interface module <b>230</b> may be integrated with one of the aforementioned example output devices.</p><p id="p-0051" num="0050">In one form, the communications module <b>240</b> is configured to communicate with other electronic devices and/or various communications networks. For example, the communications module <b>240</b> is configured to have the example computing device <b>105</b> to send or receive communications signals. Communications signals may be sent or received according to one or more protocols or according to one or more standards. For example, the communications module <b>240</b> may is configured to have the example computing device <b>105</b> to communicate via a cellular data network, such as for example, according to one or more standards such as, for example, Global System for Mobile Communications (GSM), Code Division Multiple Access (CDMA), Evolution Data Optimized (EVDO), Long-term Evolution (LTE) or the like. Additionally, or alternatively, the communications module <b>240</b> is configured to have the example computing device <b>105</b> to communicate using near-field communication (NFC), via Wi-Fi&#x2122;, using Bluetooth&#x2122; or via some combination of one or more networks or protocols. Contactless payments may be made using NFC. In some embodiments, all or a portion of the communications module <b>240</b> may be integrated into a component of the example computing device <b>105</b>. For example, the communications module <b>240</b> may be integrated into a communications chipset. The communications module <b>240</b> may include various transceivers, antennas, and other hardware for performing the functionality described herein.</p><p id="p-0052" num="0051">Software comprising instructions is executed by the processor <b>200</b> from a computer-readable medium. For example, software may be loaded into random-access memory from persistent storage of memory <b>210</b>. Additionally, or alternatively, instructions may be executed by the processor <b>200</b> directly from read-only memory of memory <b>210</b>.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> depicts an example organization of software components stored in memory <b>210</b> of the example computing device <b>105</b>. As illustrated these software components include an operating system <b>280</b> and application software <b>270</b>.</p><p id="p-0054" num="0053">In one form, the operating system <b>280</b> is software. The operating system <b>280</b> allows the application software <b>270</b> to access the processor <b>200</b>, the memory <b>210</b>, the input interface module <b>220</b>, the output interface module <b>230</b> and the communications module <b>240</b>. The operating system <b>280</b> may be, for example, Apple iOS&#x2122;, Google&#x2122; Android&#x2122;, Linux&#x2122;, Microsoft&#x2122; Windows&#x2122;, or the like.</p><p id="p-0055" num="0054">In one form, the application software <b>270</b> adapts the example computing device <b>105</b>, in combination with the operating system <b>280</b>, to operate as a device performing particular functions.</p><p id="p-0056" num="0055">Reference is made to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, which shows, in flowchart form, an example method <b>300</b> for managing video data processing of input video files associated with a video processing job. As a specific and non-limiting example, the method <b>300</b> may be implemented as part of an automated process for processing, splicing, and transcoding combinations of video files that are part of a collection of videos. An output video that is produced based on the method <b>300</b> may comply with requirements of videos for one or more specific applications (e.g., video depositions). For example, an output video may have video properties that are consistent with specific video resolution and compression requirements.</p><p id="p-0057" num="0056">Operations <b>302</b> and onward may be performed by one or more processors of a computing device such as, for example, the processor <b>200</b> (<figref idref="DRAWINGS">FIG. <b>2</b>A</figref>) of one or more suitably configured instances of the example computing device <b>105</b> (<figref idref="DRAWINGS">FIG. <b>2</b>A</figref>). In at least some embodiments, the method <b>300</b> may be performed by a computing system. In particular, a server (such as the management server <b>150</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in some embodiments) that is configured to manage a plurality of video processing jobs may perform all or part of the operations of method <b>300</b>.</p><p id="p-0058" num="0057">A computing system implementing a video processing management service may receive a request to process a collection of video files to generate a suitable output video. The request may be communicated to the computing system, for example, via a user interface (e.g., a graphical user interface) that is accessible on a client device. For example, the user interface may be associated with an application, such as a mobile or web application, for requesting batch video processing services. The request may indicate, at least, information about video files of a first set of videos and desired/required video settings, such as video display resolution, encoding format, naming convention, etc. for the output video upon completion of the batch processing.</p><p id="p-0059" num="0058">In operation <b>302</b>, the computing system obtains video data for the first set of video files. The video data may comprise information about the video files, such as file names, video properties, and the like. The computing system may obtain the video data from the request data associated with the request to process the first set of video files. Additionally, or alternatively, the computing system may determine a data store (e.g., a database) associated with the video files and query the data store to obtain the video data. For example, the computing system may determine one or more databases that are designated as being configured to store input video files for batch processing and query the databases to retrieve video data for the video files identified in a processing request.</p><p id="p-0060" num="0059">In operation <b>304</b>, the computing system generates processing job data for a first video processing job based on the video data for the first set of video files. In particular, the computing system internally assigns at least a subset of the video files of the first set to a new video processing job and determines relevant processing job data for the video processing job. The video files that are to be assigned to a same processing job may be determined by identifying indicators associated with the video files that suggest that the video files are related. For example, the computing system may obtain file names of the video files of the first set and determine which of the video files are related based on common features (e.g., common strings) associated with the file names. Additionally, or alternatively, the computing system may determine grouping of the video files for assigning to the new processing job based on metadata associated with the video files or a listing (e.g., an inventory list) that identifies constituent video files of a desired output video.</p><p id="p-0061" num="0060">In some embodiments, the computing system may generate display data associated with the new video processing job for presenting on a user interface. For example, display data including processing job data for the new job may be provided via a graphical user interface that is accessible on a client device. The display data may indicate, among others, job name, video category, total size of input video files, requesting entity, relevant timestamps (e.g., date created, last modified date, etc.) and current status of the job.</p><p id="p-0062" num="0061">Once the video files are assigned to a new video processing job, the computing system identifies a processing server having a capacity for handling the video processing job in operation <b>306</b>. The computing system determines various information about the video processing job, including number of files, maximum video size and total size, video content type, etc., and identifies a suitable server that can handle the video processing job. The video processing server may, in some embodiments, be one of a designated set of servers that are associated with the video processing management service. That is, the computing system may query only a defined set of video processing servers to determine suitability for the new video processing job.</p><p id="p-0063" num="0062">In at least some embodiments, the computing system selects a server for the new processing job based on determining, for each of one or more processing servers, a current processing capacity of the server. In particular, the computing system may send, to each of the processing servers, a query for obtaining at least one of processing power or available memory associated with the server. The processing server for the new job may be selected in a number of different ways. For example, the computing system may select the first one of the processing servers that is determined to have capacity for handling the new video processing job. That is, as the computing system queries one or more processing servers, if a processing server is determined to have the required capacity, said processing server may be selected. As another example, the computing system may select the processing server that has the most available current processing capacity (i.e., in terms of available memory and/or processing power).</p><p id="p-0064" num="0063">In operation <b>308</b>, the computing system sends, to the selected processing server, the processing job data for the new video processing job. The computing system also sends a first request to validate the video data for the video files. In at least some embodiments, the computing system may send instructions to the selected processing server to obtain the video files associated with the video processing job. For example, the processing server may be instructed to download copies of the video files of the new processing job from a database that stores the files.</p><p id="p-0065" num="0064">The first request may comprise instructions to perform validation testing of the video files for detecting any problems or errors associated with the files. The testing may be performed, for example, using specialized software that is locally available at the processing server or remotely located and accessible to the processing server. The processing server may obtain validation testing results based on the testing of the video files. The validation testing results indicate whether one or more of the video files have an associated problem/error. In particular, the validation testing results may identify any video files that are defective for containing errors that may adversely affect batch processing for the new processing job.</p><p id="p-0066" num="0065">In at least some embodiments, the validation testing results may indicate video properties of video files associated with the new processing job. By way of example, the validation testing results may include indications of one or more of the following for a video file: video display resolution; video codecs; audio codecs; or video compression settings.</p><p id="p-0067" num="0066">Upon completion of testing, the validation testing results are communicated to the computing system by the selected processing server. In operation <b>310</b>, the computing system receives, from the processing server, validation results in connection with the first set of video files. The computing system then determines first transcoding parameters for the video files of the new processing job in operation <b>312</b>. The first transcoding parameters broadly refer to settings that may be used for editing and/or converting video assets of a processing job. In at least some embodiments, the first transcoding parameters comprise settings for use in splicing together two or more video files of the processing job and/or converting at least one of the video files to a target format.</p><p id="p-0068" num="0067">The first transcoding parameters are determined based on the validation testing results received from the selected processing server and output requirements data for the new video processing job. In particular, the computing system may determine video properties of the video files associated with the processing job and obtain video output requirements for the processing job. The video output requirements may be obtained, for example, by database queries to determine, at least, a video output format and delivery type required for the video processing job (or a specific application associated with the video processing job). In at least some embodiments, the computing system may use guide templates that define preferred or optimal settings to use for various video processing operations, including splicing and transcoding operations, in different batch processing scenarios or contexts. The guide templates may, for example, be stored in memory of the computing system, and the determination of first transcoding parameters may depend on the validation testing results, the video output requirements, and settings identified in the guide templates.</p><p id="p-0069" num="0068">In operation <b>314</b>, the computing system sends, to the selected processing server, a second request to generate an output video based on the video files of the new processing job. The computing system also sends the first transcoding parameters to the processing server. In particular, the second request includes an indication of the first transcoding parameters for use in batch processing of the video files.</p><p id="p-0070" num="0069">Reference is made to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, which shows, in flowchart form, an example method <b>400</b> for generating processing job data for a video processing job. As a specific and non-limiting example, the method <b>400</b> may be implemented as part of an automated process for detecting an upload of video files, identifying a grouping of the uploaded video files for associating with a new video processing job, and assigning the new processing job to a suitable video processing server.</p><p id="p-0071" num="0070">Operations <b>402</b> and onward may be performed by one or more processors of a computing device such as, for example, the processor <b>200</b> (<figref idref="DRAWINGS">FIG. <b>2</b>A</figref>) of one or more suitably configured instances of the example computing device <b>105</b> (<figref idref="DRAWINGS">FIG. <b>2</b>A</figref>). In at least some embodiments, the method <b>400</b> may be performed by a computing system. In particular, a server (such as the management server <b>150</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in some embodiments) that is configured to manage a plurality of video processing jobs may perform all or part of the operations of method <b>400</b>. The operations of method <b>400</b> may be performed in addition to, or as alternatives of, one or more of the operations of method <b>300</b>.</p><p id="p-0072" num="0071">In operation <b>402</b>, the computing system monitors one or more data stores. The data stores may, for example, be databases storing a plurality of video files. The video files may be associated with one or more video processing jobs. In at least some embodiments, the data stores may be designated locations that are configured to receive uploads of video files for batch processing. For example, the data stores may correspond to online repositories to which video creators can upload video files of specific types or subject matter (e.g., video depositions). By monitoring the data stores for one or more defined trigger events, the computing system may automatically determine when video files associated with a new processing job have been uploaded for batch processing.</p><p id="p-0073" num="0072">Various different trigger events may be used for detecting an upload of video files. In operation <b>404</b>, the computing system detects the start of an upload of video files to at least one of the data stores. For example, the computing system may detect that the total size or number of video files in a data store has begun to increase. In order to detect completion of the video upload, the computing system may monitor one or more variables associated with the video files in the data store.</p><p id="p-0074" num="0073">The computing system tracks a total size of video files in the data store in operation <b>406</b>, and determines, in operation <b>408</b>, whether the total size of the video files is unchanged for a defined length of time. That is, a certain length of time may be defined, and the computing system may determine whether the total size of uploaded files remains substantially constant (or stable) for at least the defined length of time. If the amount of detected change in total size is less than a threshold amount, the computing system may determine that the total size has remained substantially constant. In a similar manner, the number of video files in the data store may be monitored to determine whether any change has occurred within a defined length of time.</p><p id="p-0075" num="0074">Additionally, or alternatively, completion of an upload of a group of video files may be detected by the presence of a single video asset. In operation <b>410</b>, the computing system performs check for a final video asset. In particular, the computing system may determine, based on file names, metadata, and/or accompanying inventory list for the video files, that a final video asset associated with the video upload is present in the data store. For example, the computing system may identify common parameters in the file names or metadata of the uploaded video files and determine that the files are related and/or components of a single video asset.</p><p id="p-0076" num="0075">In operation <b>412</b>, the computing system associates the video files with a video processing job. In particular, the computing system may internally associate the video files of the detected upload to a new batch video processing job. The new processing job and associated processing job data may then be communicated to a suitable processing server that may be identified in accordance with the techniques described above.</p><p id="p-0077" num="0076">Reference is made to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, which shows, in flowchart form, an example method <b>500</b> for determining transcoding parameters for input video files associated with a video processing job. As a specific and non-limiting example, the method <b>500</b> may be implemented as part of an automated process for processing, splicing, and transcoding combinations of video files that are part of a collection of videos. An output video that is produced based on the method <b>500</b> may comply with requirements of videos for one or more specific applications (e.g., video depositions). For example, an output video may have video properties that are consistent with specific video resolution and compression requirements.</p><p id="p-0078" num="0077">Operations <b>502</b> and onward may be performed by one or more processors of a computing device such as, for example, the processor <b>200</b> (<figref idref="DRAWINGS">FIG. <b>2</b>A</figref>) of one or more suitably configured instances of the example computing device <b>105</b> (<figref idref="DRAWINGS">FIG. <b>2</b>A</figref>). In at least some embodiments, the method <b>500</b> may be performed by a computing system. In particular, a server (such as the management server <b>150</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in some embodiments) that is configured to manage a plurality of video processing jobs may perform all or part of the operations of method <b>500</b>. The operations of method <b>500</b> may be performed in addition to, or as alternatives of, one or more operations of methods <b>300</b> and <b>400</b>.</p><p id="p-0079" num="0078">In operation <b>502</b>, the computing system sends, to a video processing server, instructions to test video assets associated with a video processing job. The video processing server may be a server that has been selected as being suitable for handling the video processing job. The instructions may be included in a request to the selected processing server to perform validation testing of the video files of the video processing job.</p><p id="p-0080" num="0079">In operation <b>504</b>, the computing system receives, from the video processing server, validation testing results for the video assets. The validation testing is performed by the video processing server to determine whether there are any errors or defects associated with one or more of the video files. The validation testing may be performed, for example, using designated software-based video examination tools that is accessible to the video processing server. In at least some embodiments, the validation testing results may include indications of video properties of the video files associated with the video processing job.</p><p id="p-0081" num="0080">In operation <b>506</b>, the computing system processes the validation testing results and in operation <b>508</b>, the computing system determines whether one or more of the video assets has failed validation testing. In particular, the computing system determines, based on the validation testing results, whether an error or defect has been detected for one or more of the video files of the video processing job.</p><p id="p-0082" num="0081">If at least one of the video assets fails validation testing, the computing system terminates the video processing job in operation <b>510</b>. That is, the computing system may determine, based on the validation testing results, that at least one of the video files is defective and in response, the computing system may terminate the video processing job. Various rules may be defined for determining when a video file is defective. For example, a video file may be determined to be defective if a threshold number of errors is detected during validation testing or if particular types of errors/defects are detected. The validation testing results may indicate the number and details of the detected errors/defects.</p><p id="p-0083" num="0082">In some embodiments, as an alternative to terminating a video processing job, the computing system may attempt to reprocess the job. For example, if one or more defective files are detected, the computing system may send an instruction message to the video processing server to obtain the video files of the video processing job again and perform operations for processing/testing the video files as described above.</p><p id="p-0084" num="0083">Upon termination due to defective file(s), the computing system generates a notification indicating one or more video file errors and job termination in operation <b>512</b>. The notification may be communicated to client devices for display thereon. In particular, the notification may be included in display data for presenting on a user interface associated with a video processing management service.</p><p id="p-0085" num="0084">If, on the other hand, all of the video assets are validated or determined to have passed the tests, the computing system generates notification of the validation of video assets in operation <b>514</b>. The notification may be communicated to client devices for display thereon. In particular, the notification may be included in display data for presenting on a user interface associated with a video processing management service.</p><p id="p-0086" num="0085">The computing system then obtains output requirements data for the video processing job in operation <b>516</b>, and the computing system determines transcoding parameters in operation <b>518</b>. Operations <b>516</b> and <b>518</b> may be performed according to techniques described above.</p><p id="p-0087" num="0086">Reference is made to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, which shows, in flowchart form, an example method <b>600</b> for processing and testing input video files associated with a video processing job. As a specific and non-limiting example, the method <b>600</b> may be implemented as part of an automated process for processing, splicing, and transcoding combinations of video files that are part of a collection of videos. An output video that is produced based on the method <b>600</b> may comply with requirements of videos for one or more specific applications (e.g., video depositions). For example, an output video may have video properties that are consistent with specific video resolution and compression requirements.</p><p id="p-0088" num="0087">Operations <b>602</b> and onward may be performed by one or more processors of a computing device such as, for example, the processor <b>200</b> (<figref idref="DRAWINGS">FIG. <b>2</b>A</figref>) of one or more suitably configured instances of the example computing device <b>105</b> (<figref idref="DRAWINGS">FIG. <b>2</b>A</figref>). In at least some embodiments, the method <b>600</b> may be performed by a computing system. In particular, a server (such as the video processing server <b>160</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in some embodiments) that is configured to process input video files of a video processing job in order to generate one or more output videos may perform all or part of the operations of method <b>600</b>.</p><p id="p-0089" num="0088">In operation <b>602</b>, the processing server obtains video files associated with a video processing job. In particular, the processing server may receive, from a video processing management entity, instructions to obtain one or more video files of a video processing job that has been assigned to the processing server. The processing server may access a database, such as an online repository, storing the video files and download copies of the files.</p><p id="p-0090" num="0089">In operation <b>604</b>, the processing server performs validation testing of the video files. The testing may be performed using designated software tools that are either locally available or remotely accessible by the processing server. The processing server generates validation testing results based on the testing of the video files, in operation <b>606</b>.</p><p id="p-0091" num="0090">In operation <b>608</b>, the processing server transmits the validation testing results to the video processing management entity (i.e., a management server). In operation <b>610</b>, the processing server receives, from the management server, transcoding parameters associated with the video processing job and a request to generate an output video file for the processing job based on the input video files obtained in operation <b>602</b>. In at least some embodiments, the processing server performs one or more video processing operations, such as video splicing and transcoding, for the input video files. The operations may be performed in accordance with the transcoding parameters received from the management server.</p><p id="p-0092" num="0091">By way of example, the processing server splices together the input video files in operation <b>612</b>. The processing server may seamlessly splice together all video files of the processing job according to a defined order. The order may be determined, for example, based on information, such as file names, metadata, or an inventory list, associated with the video files of the processing job.</p><p id="p-0093" num="0092">In operation <b>614</b>, the processing server transcodes the video assets in accordance with the transcoding parameters. That is, once the input video files have been spliced together as required, the processing server transcodes the newly created video assets using the transcoding parameters obtained from the management server. The transcoded video assets have the video/audio output formats, resolutions, and/or compression ratios that are required for the processing job.</p><p id="p-0094" num="0093">The management server may periodically query the processing server to determine whether the transcoding of the video assets has completed. Once the transcoding operations are completed, the processing server may be instructed (by the management server) to test the validity, quality and integrity of the output video assets. This testing may be performed using the same or other video examination software tools.</p><p id="p-0095" num="0094">Based on validation results, if one or more video assets fail the testing, the management server may terminate the video processing job and notify a user of the validation failure/termination (e.g., updating a user interface associated with the management server and/or for managing video processing jobs). If, on the other hand, all output video assets within the video processing job are determined to be valid, the management server may notify the user of validation success (e.g., indicating that the video assets are valid).</p><p id="p-0096" num="0095">In operation <b>616</b>, the processing server uploads the output video assets to a designated data store. The management server may, for example, send an instruction message to the processing server to upload the output video assets to a specific data store and upon receiving such message, the processing server may initiate upload of the video assets. Once the uploads are completed, the processing server may notify the management server of the completion and suitable notifications indicating completion of the video processing job may be generated and communicated to end users (e.g., client devices). In particular, push notifications (or similar messages) may be generated and transmitted to client devices via a user interface for managing video processing jobs. In some embodiments, the management server may be configured to move or copy the video assets of the video processing job from the designated data store to a particular archival-optimized storage solution.</p><p id="p-0097" num="0096">The various embodiments presented above are merely examples and are in no way meant to limit the scope of this application. Variations of the innovations described herein will be apparent to persons of ordinary skill in the art, such variations being within the intended scope of the present application. In particular, features from one or more of the above-described example embodiments may be selected to create alternative example embodiments including a sub-combination of features which may not be explicitly described above. In addition, features from one or more of the above-described example embodiments may be selected and combined to create alternative example embodiments including a combination of features which may not be explicitly described above. Features suitable for such combinations and sub-combinations would be readily apparent to persons skilled in the art upon review of the present application as a whole. The subject matter described herein and in the recited claims intends to cover and embrace all suitable changes in technology.</p><p id="p-0098" num="0097">Unless otherwise expressly indicated herein, all numerical values indicating mechanical/thermal properties, compositional percentages, dimensions and/or tolerances, or other characteristics are to be understood as modified by the word &#x201c;about&#x201d; or &#x201c;approximately&#x201d; in describing the scope of the present disclosure. This modification is desired for various reasons including industrial practice, material, manufacturing, and assembly tolerances, and testing capability.</p><p id="p-0099" num="0098">The apparatuses and methods described in this application may be partially or fully implemented by a special purpose computer created by configuring a general-purpose computer to execute one or more particular functions embodied in computer programs. The functional blocks, flowchart components, and other elements described above serve as software specifications, which can be translated into the computer programs by the routine work of a skilled technician or programmer.</p><p id="p-0100" num="0099">The description of the disclosure is merely exemplary in nature and, thus, variations that do not depart from the substance of the disclosure are intended to be within the scope of the disclosure. Such variations are not to be regarded as a departure from the spirit and scope of the disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computing device comprising:<claim-text>a processor;</claim-text><claim-text>a communications module coupled to the processor; and</claim-text><claim-text>a memory coupled to the processor, the memory storing instructions that, when executed, configure the processor to:<claim-text>obtain video data for a first set of video files;</claim-text><claim-text>generate processing job data for a first video processing job based on the video data for the first set of video files;</claim-text><claim-text>identify a first processing server having a capacity for handling the first video processing job;</claim-text><claim-text>send, to the first processing server, the processing job data for the first video processing job and a first request to validate the video data for the first set of video files;</claim-text><claim-text>receive, from the first processing server, validation testing results in connection with the first set of video files;</claim-text><claim-text>determine first transcoding parameters for the first set of video files based on the validation testing results and output requirements data for the first video processing job; and</claim-text><claim-text>send, to the first processing server, a second request to generate an output video based on the first set of video files, the second request including an indication of the first transcoding parameters.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first transcoding parameters comprise settings for use in performing at least one of:<claim-text>splicing together two or more of the video files of the first set; or</claim-text><claim-text>converting at least one of the video files of the first set to a target format.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein when the processor is configured to obtain the video data for the first set of video files, the processor is further configured to:<claim-text>monitor one or more data stores configured for storing video files;</claim-text><claim-text>detect a trigger event in connection with the one or more data stores; and</claim-text><claim-text>in response to detecting the trigger event, retrieve video data associated with the first set of video files from the one or more data stores.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computing device of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein when the processor is configured to detect the trigger event, the processor is further configured to detect start of an upload of at least one video file to the one or more data stores.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computing device of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein when the processor is configured to detect the trigger event, the processor is further configured to detect completion of the upload based on determining that total size of uploaded files remains substantially constant for at least a defined length of time.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the validation testing results comprise, for each of one or more of the video files of the first set, at least one of: video display resolution; video codecs; audio codecs; or video compression settings.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein when the processor is configured to identify the first processing server, the processor is further configured to determine, for each of a plurality of remote computing systems, a current processing capacity of the remote computing system.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The computing device of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein when the processor is configured to determine the current processing capacity of the remote computing system, the processor is further configured to send, to the remote computing system, a query for obtaining at least one of processing power or available memory associated with the remote computing system.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein when the processor is configured to generate the processing job data, the processor is further configured to determine that the first set of video files is associated with a same processing job based on at least one of:<claim-text>metadata associated with the video files of the first set;</claim-text><claim-text>file names of the video files of the first set; or</claim-text><claim-text>an inventory list identifying constituent video files of a desired output video.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions, when executed, further configure the processor to:<claim-text>determine, based on the validation testing results, that at least one of the video files of the first set is defective; and</claim-text><claim-text>in response to determining that the at least one video file is defective, terminate the first video processing job.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A computer-implemented method, comprising:<claim-text>obtaining video data for a first set of video files;</claim-text><claim-text>generating processing job data for a first video processing job based on the video data for the first set of video files;</claim-text><claim-text>identifying a first processing server having a capacity for handling the first video processing job;</claim-text><claim-text>sending, to the first processing server, the processing job data for the first video processing job and a first request to validate the video data for the first set of video files;</claim-text><claim-text>receiving, from the first processing server, validation testing results in connection with the first set of video files;</claim-text><claim-text>determining first transcoding parameters for the first set of video files based on the validation testing results and output requirements data for the first video processing job; and</claim-text><claim-text>sending, to the first processing server, a second request to generate an output video based on the first set of video files, the second request including an indication of the first transcoding parameters.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the first transcoding parameters comprise settings for use in performing at least one of:<claim-text>splicing together two or more of the video files of the first set; or</claim-text><claim-text>converting at least one of the video files of the first set to a target format.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein obtaining the video data for the first set of video files comprises:<claim-text>monitoring one or more data stores configured for storing video files;</claim-text><claim-text>detecting a trigger event in connection with the one or more data stores; and</claim-text><claim-text>in response to detecting the trigger event, retrieving video data associated with the first set of video files from the one or more data stores.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein detecting the trigger event comprises detecting a start of an upload of at least one video file to the one or more data stores.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein detecting the trigger event further comprises detecting completion of the upload based on determining that total size of uploaded files remains substantially constant for at least a defined length of time.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the validation testing results comprise, for each of one or more of the video files of the first set, at least one of: video display resolution; video codecs; audio codecs; or video compression settings.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein identifying the first processing server comprises determining, for each of a plurality of remote computing systems, a current processing capacity of the remote computing system.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein determining the current processing capacity of the remote computing system comprises sending, to the remote computing system, a query for obtaining at least one of processing power or available memory associated with the remote computing system.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein generating the processing job data comprises determining that the first set of video files is associated with a same processing job based on at least one of:<claim-text>metadata associated with the video files of the first set;</claim-text><claim-text>file names of the video files of the first set; or</claim-text><claim-text>an inventory list identifying constituent video files of a desired output video.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref> further comprising:<claim-text>determining, based on the validation testing results, that at least one of the video files of the first set is defective; and</claim-text><claim-text>in response to determining that the at least one video file is defective, terminating the first video processing job.</claim-text></claim-text></claim></claims></us-patent-application>
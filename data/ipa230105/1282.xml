<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230001283A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230001283</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17883057</doc-number><date>20220808</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>CN</country><doc-number>202110383654.7</doc-number><date>20210409</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>63</class><subclass>B</subclass><main-group>71</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>19</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>63</class><subclass>B</subclass><main-group>71</main-group><subgroup>0622</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>19</main-group><subgroup>006</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>63</class><subclass>B</subclass><main-group>2071</main-group><subgroup>0636</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>63</class><subclass>B</subclass><main-group>2071</main-group><subgroup>0638</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">SPORT TRAINING METHOD AND SYSTEM AND HEAD-MOUNTED VR DEVICE</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/CN2022/085321</doc-number><date>20210406</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17883057</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Qingdao Pico Technology Co., Ltd.</orgname><address><city>Qingdao</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>WU</last-name><first-name>Tao</first-name><address><city>Qingdao</city><country>CN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A sport training method and system and a head-mounted VR device are disclosed. The method is performed by a head-mounted VR device. The head-mounted VR device is wirelessly connected to a hand-motion tracker and a foot-motion tracker. The method comprises: displaying a virtual demonstrative action; acquiring 6DOF head-motion data, 6DOF hand-motion data and 6DOF foot-motion data of the user; fusing the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data; calculating motion data of different parts of a human body according to the data that have been fused; and comparing the motion data of the different parts of the human body obtained by the calculation with standard sport training data of the virtual demonstrative action, and if a degree of similarity is greater than a threshold, determining that an action of a human-body part meets a training standard, and if not, displaying a corresponding prompting message in a virtual reality scene to prompt a human-body part whose action is not standard.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="166.96mm" wi="121.41mm" file="US20230001283A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="180.00mm" wi="123.53mm" file="US20230001283A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="197.19mm" wi="155.19mm" file="US20230001283A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="186.69mm" wi="162.48mm" file="US20230001283A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="134.03mm" wi="93.64mm" file="US20230001283A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present application relates to the field of VR, in particular to a sport training method and system and a head-mounted VR device.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">With the advancement of society, people pay more and more attention to health. In the prior art, fitness activities (such as yoga) are usually carried out in a yoga club or gym. The participants are required to pay a certain fee, and a yoga instructor carries out on-site teaching and instructing. When there are a large number of participants, the yoga instructor cannot take care of every participant and instruct them individually. On the other hand, if the class size is small, the costs of the participants and the yoga club will be increased. Thus, the traditional ways of fitness have many problems, such as a low intelligence degree, a low efficiency, a high cost, and a poor fitness effect.</p><p id="p-0004" num="0003">In the prior art, users may also choose to practice at home by downloading some videos of training subjects and learning and practicing on the computer or TV. However, this video-instruction method is only a one-way instruction, and users cannot obtain the feedback on whether their own actions are correct or accurate, cannot determine whether their yoga actions are standard, cannot correct their own actions in time, and cannot evaluate the fitness effect, which results in a low efficiency and a poor fitness effect.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0005" num="0004">In view of the problems in the conventional fitness methods, such as low efficiency and effect, and the lack of systematic fitness evaluation and feedback mechanism, the present application is proposed to provide a sport training method, device and system to overcome the above problems or at least partially solve the above problems.</p><p id="p-0006" num="0005">According to an aspect of the present application, there is provided a sport training method. The sport training method is performed by a head-mounted VR device. The head-mounted VR device is wirelessly connected to a hand-motion tracker and a foot-motion tracker. The hand-motion tracker is used to track motion data of a hand of a user, and the foot-motion tracker is used to track motion data of a foot of the user. The method comprises:</p><p id="p-0007" num="0006">displaying a virtual demonstrative action;</p><p id="p-0008" num="0007">acquiring 6DOF head-motion data, 6DOF hand-motion data and 6DOF foot-motion data of the user;</p><p id="p-0009" num="0008">fusing the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data;</p><p id="p-0010" num="0009">calculating motion data of different parts of a human body according to the data that have been fused; and</p><p id="p-0011" num="0010">comparing the motion data of the different parts of the human body obtained by the calculation with standard sport training data of the virtual demonstrative action, and if a degree of similarity is greater than a threshold, determining that an action of a human-body part meets a training standard, and if not, displaying a corresponding prompting message in a virtual reality scene to prompt a human-body part whose action is not standard.</p><p id="p-0012" num="0011">According to another aspect of the present application, a head-mounted VR device is provided. The head-mounted VR device is wirelessly connected to a hand-motion tracker and a foot-motion tracker. The hand-motion tracker is used to track motion data of a hand of a user, and the foot-motion tracker is used to track motion data of a foot of the user. The head-mounted VR device comprises:</p><p id="p-0013" num="0012">a displaying unit configured for displaying a virtual demonstrative action;</p><p id="p-0014" num="0013">an acquiring unit configured for acquiring 6DOF head-motion data, 6DOF hand-motion data and 6DOF foot-motion data of the user;</p><p id="p-0015" num="0014">a fusing unit configured for fusing the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data;</p><p id="p-0016" num="0015">a calculating unit configured for calculating motion data of different parts of a human body according to the data that have been fused; and</p><p id="p-0017" num="0016">a comparing unit configured for comparing the motion data of the different parts of the human body obtained by the calculation with standard sport training data of the virtual demonstrative action, and if a degree of similarity is greater than a threshold, determining that an action of a human-body part meets a training standard, and if not, displaying a corresponding prompting message in a virtual reality scene to prompt a human-body part whose action is not standard.</p><p id="p-0018" num="0017">According to yet another aspect of the present application, there is provided a sport training system, which comprises: a server, and a plurality of head-mounted VR devices connected to the server via a network;</p><p id="p-0019" num="0018">each of the head-mounted VR devices is configured for sending motion data of different parts of a human body obtained by calculation to the server;</p><p id="p-0020" num="0019">the server is configured for receiving the motion data of the different parts of the human body sent by the plurality of head-mounted VR devices; in a virtual reality scene, according to the motion data, drawing a plurality of user avatars, and according to the plurality of user avatars, rendering to generate a multi-person interactive motion scene; and sending the multi-person interactive motion scene to each of the head-mounted VR devices in real time; and each of the head-mounted VR devices is further configured for displaying the multi-person interactive motion scene on a display screen, so as to realize remote interaction with another sport training user in the virtual reality scene.</p><p id="p-0021" num="0020">According to still another aspect of the present application, there is provided a computer-readable storage medium having one or more programs stored therein, wherein when executed by a processor, the one or more programs implement the above-described sport training method.</p><p id="p-0022" num="0021">By using the above technical solutions, the present application can achieve the following advantageous effects.</p><p id="p-0023" num="0022">By wearing the hand-motion tracker and the foot-motion tracker respectively at the specified parts of a hand and a foot of the user, and wearing the head-mounted VR device on the head of the user, the motion information of the key limbs of each of the sport training users can be tracked in real time, and the user is not required to wear a large number of sensors, which is very convenient for the user to wear. The head-mounted VR device acquires the 6DOF head-motion data collected in real time by itself, the 6DOF hand-motion data collected in real time by the hand-motion tracker and the 6DOF foot-motion data collected in real time by the foot-motion tracker, and fuses the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data to acquire high-precision high-frequency motion data, thereby increasing the tracking precision. The motion data of different parts of the human body are calculated according to the data that have been fused, the motion data of the different parts of the human body obtained by the calculation are compared with the standard sport training data, and if the degree of similarity is greater than a threshold, it is determined that the action of the human-body part meets the training standard, and if not, the prompting message is marked on the human-body part whose action is not standard in the head-mounted VR device for action standardizing correction. In this way, when the users are exercising at home, they can still judge whether the actions are standard or not, and correct non-demonstrative actions in time, thereby improving the fitness efficiency and effect, and solving the problems in the process of yoga and other fitness activities, such as the inability to determine whether the actions are standard or not, the inability to correct the actions in time, and the lack of systematic fitness evaluation and feedback mechanism. Moreover, the remote interaction among sport training users can be realized by using the server, which further improves the user experience.</p><p id="p-0024" num="0023">The above description is merely a summary of the technical solutions of the present application. In order to more clearly know the elements of the present application to enable the implementation according to the contents of the description, and in order to make the above and other purposes, features and advantages of the present application more apparent and understandable, the particular embodiments of the present application are provided below.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0025" num="0024">By reading the following detailed description of the preferable embodiments, various other advantages and benefits will become clear to a person skilled in the art. The drawings are merely intended to show the preferable embodiments, and are not to be considered as limiting the present application. Furthermore, throughout the drawings, the same reference signs denote the same elements. In the drawings:</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic flow chart of a sport training method according to an embodiment of the present application;</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram of multi-user VR remote interaction according to an embodiment of the present application;</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic structural diagram of a sport training device according to an embodiment of the present application;</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic diagram of a wearing effect according to an embodiment of the present application;</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic structural diagram of a sport training system according to an embodiment of the present application; and</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic structural diagram of a head-mounted VR device according to an embodiment of the present application.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0032" num="0031">The exemplary embodiments of the present application will be described in further detail below with reference to the drawings. Although the drawings illustrate the exemplary embodiments of the present application, it should be understood that the present application may be implemented in various forms, which should not be limited by the embodiments illustrated herein. In contrast, the purpose of providing those embodiments is to more clearly understand the present application, and to completely convey the scope of the present application to a person skilled in the art.</p><p id="p-0033" num="0032">The virtual reality (VR) technique provides people a sense of environmental immersion by simulating a virtual environment by using a computer. In the present application, the problems in the process of yoga and other fitness activities, such as the inability to determine whether the actions are standard, the inability to correct the actions in time, and the lack of systematic fitness evaluation and feedback mechanism, are solved by combining the VR device with sensors, thereby bringing the user a better fitness experience. In the technical solutions of the present application, before performing the sport training the user wears a hand-motion tracker and a foot-motion tracker respectively at specified parts of the hand and the foot, and wears a head-mounted VR device on the head. The hand-motion tracker and the foot-motion tracker are wirelessly connected to the head-mounted VR device. During the sport training, the user makes corresponding actions according to the virtual demonstrative actions displayed in the head-mounted VR device.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic flow chart of the sport training method according to an embodiment of the present application. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the method is performed by a head-mounted VR device, and comprises:</p><p id="p-0035" num="0034">Step S<b>100</b>: displaying a virtual demonstrative action.</p><p id="p-0036" num="0035">Step S<b>110</b>: acquiring 6DOF head-motion data, 6DOF hand-motion data and 6DOF foot-motion data of the user.</p><p id="p-0037" num="0036">6-DOF refers to that the information of 6 degrees of freedom (DOF) is used to represent the motion of an object, including the displacement information on X, Y and Z axes and the rotation information on the X, Y and Z axes. In the present embodiment, not only the change of the visual field angle caused by the rotation of the parts of the body can be detected, but also the change of up, down, front, back, left and right displacements caused by the movement of the parts of the body can be detected.</p><p id="p-0038" num="0037">In the present embodiment, the 6-DOF motion data of the head, the hand and the foot of the user are collected in real time to comprehensively monitor the motion data of the joints of the human body, which can more truly and accurately reflect the motion of the human body.</p><p id="p-0039" num="0038">Step S<b>120</b>: fusing the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data.</p><p id="p-0040" num="0039">In the present embodiment, the 6-DOF motion data of the head, the hand and the foot are acquired by using the head-mounted VR device, the hand-motion tracker and the foot-motion tracker respectively; in other words, each of the 6-DOF motion data has its own coordinate system. Therefore, it is necessary to fuse the motion data of the head, the hand and the foot, and particularly, to unify the 6-DOF motion data of the hand and the foot into the coordinate system of the head, so as to make the motion of the real human body consistent with the motion of the virtual human body in the head-mounted VR device.</p><p id="p-0041" num="0040">Step S<b>130</b>: calculating motion data of different parts of a human body according to the data that have been fused.</p><p id="p-0042" num="0041">In the present embodiment, the motion data of the head, the hand and the foot are fused, the 6-DOF motion data of the hand and the foot are unified into the coordinate system of the head, and the motion data of the 6-DOF motion data of the head, the hand and the foot in the head coordinate system are calculated.</p><p id="p-0043" num="0042">Step S<b>140</b>: comparing the motion data of the different parts of the human body obtained by the calculation with standard sport training data of the virtual demonstrative action, and if a degree of similarity is greater than a threshold, determining that an action of a human-body part meets a training standard, and if not, displaying a corresponding prompting message in a virtual reality scene to prompt a human-body part whose action is not standard.</p><p id="p-0044" num="0043">In the present embodiment, the standard sport training data are a standard action database established by collecting the data of the corresponding actions completed by senior sport trainers according to the above steps. For example, the threshold may be set to 95%.</p><p id="p-0045" num="0044">In sum, in the technical solution of the present embodiment, by wearing the hand-motion tracker and the foot-motion tracker respectively at the specified parts of a hand and a foot of the user, and wearing the head-mounted VR device on the head of the user, the motion information of the key limbs of each of the sport training users can be tracked in real time, and the user is not required to wear a large number of sensors, which is very convenient for the user to wear. The head-mounted VR device acquires the 6DOF head-motion data collected in real time by itself, the 6DOF hand-motion data collected in real time by the hand-motion tracker and the 6DOF foot-motion data collected in real time by the foot-motion tracker, and fuses the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data to acquire high-precision high-frequency motion data, thereby increasing the tracking precision. The motion data of different parts of the human body are calculated according to the data that have been fused, the motion data of the different parts of the human body obtained by the calculation are compared with the standard sport training data, and if the degree of similarity is greater than a threshold, it is determined that the action of the human-body part meets the training standard, and if not, the prompting message is marked on the human-body part whose action is not standard in the head-mounted VR device for action standardizing correction. In this way, when the users are exercising at home, they can still judge whether the actions are standard or not, and correct non-demonstrative actions in time, thereby improving the fitness efficiency and effect, and solving the problems in the process of yoga and other fitness activities, such as the inability to determine whether the actions are standard or not, the inability to correct the actions in time, and the lack of systematic fitness evaluation and feedback mechanism.</p><p id="p-0046" num="0045">In an embodiment of the present application, the head-mounted VR device is provided therein with a head-mounted tracking camera, an electromagnetic signal receiving module or an ultrasonic signal receiving module. The hand-motion tracker and the foot-motion tracker are both provided therein with an electromagnetic sensor and an electromagnetic signal emitting module, or both provided therein with an ultrasonic sensor and an ultrasonic signal emitting module.</p><p id="p-0047" num="0046">The head-mounted VR device acquires the 6DOF head-motion data collected in real time, the 6DOF hand-motion data collected in real time by the hand-motion tracker, and the 6DOF foot-motion data collected in real time by the foot-motion tracker, which further comprises:</p><p id="p-0048" num="0047">the head-mounted VR device collects the pose information of the head motion in real time by using the built-in head-mounted tracking camera;</p><p id="p-0049" num="0048">the hand-motion tracker and the foot-motion tracker collect the pose information of the hand motion and the pose information of the foot motion in real time respectively by using the built-in electromagnetic sensor, and wirelessly transmit them to the electromagnetic signal receiving module of the head-mounted VR device by using the electromagnetic signal emitting module; or, the hand-motion tracker and the foot-motion tracker collect the pose information of the hand motion and the pose information of the foot motion in real time respectively by using the built-in ultrasonic sensor, and wirelessly transmit them to the ultrasonic signal receiving module of the head-mounted VR device by using the ultrasonic signal emitting module.</p><p id="p-0050" num="0049">In the present embodiment, preferably, the head-mounted VR device is provided with built-in high-performance central processing unit (CPU) and graphics processing unit (GPU), which may be a high-performance mobile platform such as Qualcomm snapdragon 845 and Qualcomm snapdragon 865. The head-mounted VR device is further provided therein with 4 head-mounted tracking cameras, and each of the head-mounted tracking cameras is configured as follows: (1) frame rate: 30 Hz or higher; (2) angle of view (FOV): 130&#xb0; *80&#xb0; (H*V) or higher; (3) exposure mode: generally global shutter; and (4) light transmission band of lens: generally about 400-900. The head-mounted VR device collects the 6-DOF pose information of the user's head motion relative to the environment in real time by using the head-mounted tracking cameras.</p><p id="p-0051" num="0050">In an embodiment of the present application, the head-mounted VR device is further provided therein with a first wireless-communication module and a first IMU sensor, and the hand-motion tracker and the foot-motion tracker are both further provided therein with a second wireless-communication module and a second IMU sensor.</p><p id="p-0052" num="0051">The head-mounted VR device acquires the 6DOF head-motion data collected in real time, the 6DOF hand-motion data collected in real time by the hand-motion tracker, and the 6DOF foot-motion data collected in real time by the foot-motion tracker, which further comprises:</p><p id="p-0053" num="0052">the head-mounted VR device further collects the IMU information of the head motion in real time by using the built-in first IMU sensor, and fuses the IMU information of the head motion with the pose information of the head motion to obtain the 6DOF head-motion data;</p><p id="p-0054" num="0053">the hand-motion tracker and the foot-motion tracker further collect the IMU information of the hand motion and the IMU information of the foot motion in real time respectively by using the built-in second IMU sensor, and wirelessly transmit them to the first wireless-communication module of the head-mounted VR device by using the second wireless-communication module; and</p><p id="p-0055" num="0054">the head-mounted VR device fuses the pose information of the hand motion with the IMU information of the hand motion to obtain the 6DOF hand-motion data, and fuses the pose information of the foot motion with the IMU information of the foot motion to obtain the 6DOF foot-motion data.</p><p id="p-0056" num="0055">In addition to the 4 built-in head-mounted tracking cameras, in order to output the 6-DOF motion data with a high frequency (&#x3e;200 Hz), the head-mounted VR device generally requires to be provided with a built-in high-precision high-frequency IMU (Inertial Measurement Unit) inertial navigation sensor to measure the three-axis attitude angle (or angular velocity) and the acceleration of the head. High-frequency 6-DOF information of the motion state of the head-mounted VR device can be output by using the technique of simultaneous localization and mapping (SLAM) in combination with the IMU information.</p><p id="p-0057" num="0056">The hand-motion tracker can realize the hand motion tracking by using an electromagnetic sensor or an ultrasonic sensor. If an electromagnetic sensor is used, an electromagnetic signal emitting module is provided in the hand-motion tracker, and an electromagnetic signal receiving module is provided in the head-mounted VR device. If an ultrasonic sensor is used, an ultrasonic signal emitting module is provided in the hand-motion tracker, and an ultrasonic signal receiving module is provided in the head-mounted VR device. The hand-motion tracker is further provided therein with a wireless-communication module. In order to improve the tracking stability of the hand-motion tracker, it is further provided therein with an IMU sensor with a high precision and a high frequency to transmit the IMU inertial-navigation information in the hand-motion tracker to the head-mounted VR device by using the wireless-communication module. The electromagnetic signal receiving module or the ultrasonic signal receiving module at the head-mounted VR device receives the motion electromagnetic signal or the motion ultrasonic signal of the hand-motion tracker, combined with the IMU information of the hand motion tracking, the 6-DOF information of the hand-motion tracker is calculated in real time by using an electromagnetic-signal processing algorithm or an ultrasonic-signal processing algorithm. The built-in motion sensor of the foot-motion tracker is the same as that of the hand. If the hand-motion tracker is provided therein with an electromagnetic-wave sensor, the foot-motion tracker is also provided therein with an electromagnetic-wave sensor. If the hand-motion tracker is provided therein with an ultrasonic sensor, the foot-motion tracker is also provided therein with an ultrasonic sensor.</p><p id="p-0058" num="0057">In the present embodiment, the hand-motion tracker and the foot-motion tracker respectively acquire the 6DOF hand-motion data and the 6DOF foot-motion data by using the built-in electromagnetic sensor or ultrasonic sensor in combination with the second IMU sensor, and the head-mounted VR device acquires the 6DOF head-motion data by using the head-mounted tracking camera and the first IMU sensor, thereby overcoming the defects in the prior art that the acquirement of the user motion data by using the IMU sensor can only acquire the 3-DOF attitude data of the human joint points and cannot acquire the displacement data of the joint points, and that the IMU sensor will have a cumulative drift error over time. Thus, it acquires high-precision high-frequency 6-DOF motion data and increases the tracking precision, so that the position offset error can reach the order of millimeters, the rotation angle offset error can be controlled within 1.5&#xb0;, and the outputted frequency is greater than 200 Hz.</p><p id="p-0059" num="0058">In an embodiment of the present application, the head-mounted VR device fuses the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data, which comprises:</p><p id="p-0060" num="0059">the head-mounted VR device acquires a rotation matrix and a translation vector of the electromagnetic signal receiving module or ultrasonic signal receiving module relative to the first IMU sensor, performs coordinate system conversion on the 6DOF hand-motion data and 6DOF foot-motion data by using the rotation matrix and the translation vector, and converts them into 6-DOF motion data with the first IMU sensor as the origin.</p><p id="p-0061" num="0060">In the present embodiment, the hand-motion tracker and the foot-motion tracker are provided therein with the electromagnetic sensor or the ultrasonic sensor, and the VR head-mounted displaying all-in-one machine is provided therein with the electromagnetic signal receiving module or the ultrasonic signal receiving module. The coordinate systems of the 6-DOF motion data of the hand and the foot use the receiving-end sensors as the origin, while the coordinate system of the 6-DOF motion data of the head uses the first IMU sensor as the origin. Only by unifying the 6-DOF motion data of the hand, the foot and the head into the same coordinate system can the motion of the real human body be consistent with that of the virtual human body in the head-mounted VR device.</p><p id="p-0062" num="0061">Particularly, the 6-DOF motion data of the hand and the foot are unified into the head coordinate system, which comprises: acquiring respectively a rotation matrix R and a translation vector T of the electromagnetic signal receiving module or the ultrasonic signal receiving module in the head-mounted VR device relative to the first IMU sensor, performing coordinate system conversion on the 6-DOF motion data of the hand and the foot by using the rotation matrix R and the translation vector T, and converting them into 6-DOF tracking data with the first IMU sensor built in the head-mounted VR device as the origin. The formulas of the coordinate system conversion are:</p><p id="p-0063" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>6-DOF motion data with the first IMU sensor as the origin=<i>R*</i>6DOF hand-motion data+T&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0064" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>6-DOF motion data with the first IMU sensor as the origin=<i>R*</i>6DOF foot-motion data+T&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0065" num="0062">In order to accurately calculate the motion data of the different parts of the human body, in an embodiment of the present application, before sport training, the human-body motion data are calibrated according to the actions made by the user corresponding to the demonstrative actions. Particularly, when the user wears the hand-motion tracker, the foot-motion tracker and the head-mounted VR device, and makes corresponding actions according to the virtual calibration actions displayed in the head-mounted VR device, the motion speed and the motion angle of the different parts of the human body, the displacement information of each part, and the motion hold time of each key part of the human body are calculated according to the data that have been fused and the sport training calibration data by using an inverse kinematics algorithm.</p><p id="p-0066" num="0063">Taking yoga as an example, the operation of the system according to the present application is described below.</p><p id="p-0067" num="0064">(1) Before the exercise, the user firstly, according to a yoga training instruction manual, wears the motion tracking sensors on the specified parts of the hand and the foot and then wears the head-mounted VR device.</p><p id="p-0068" num="0065">(2) After the user has worn the sensors, the calibration of the human-body motion data is performed firstly in a &#x201c;yoga training instruction&#x201d; APP in the head-mounted VR device. The user, according to the demonstrative actions indicated by the APP, makes several corresponding actions, to perform the calibration of the human-body motion data, so as to make the motion tracking data of each sensor for the user's yoga actions more stable and precise. The human-body motion calibration data will be stored in the head-mounted VR device accordingly. The whole calibration process spends about 1-2 minutes. In order to make the motion tracking data of the yoga actions more stable and precise, it is recommended to calibrate the human-body motion data every time after wearing the motion tracking sensors.</p><p id="p-0069" num="0066">(3) After the above steps (1) and (2) have been completed, yoga training instruction may be provided. The user may select different yoga exercise actions in the APP. After selecting the yoga exercise actions, the user can see the virtual demonstrative action of each of the actions in the head-mounted VR device, and then the user makes the corresponding actions simultaneously. The system will calculate the motion speed and the motion angle of the different parts of the human body, the displacement information of each part, and the motion hold time of each key part of the human body according to the 6DOF head-motion data, the 6DOF hand-motion data, the 6DOF foot-motion data and the human-body motion calibration data at this moment in combination with the IK (inverse kinematics) algorithm, and compare them with the yoga training database in the head-mounted VR device. If the degree of similarity is greater than 95%, it is considered that the action of the human-body part meets the yoga training standard, and if not, the human-body part whose action is not standard is marked with a prompting message in the head-mounted VR device for action standardizing correction.</p><p id="p-0070" num="0067">(4) According to step (3), the actions in exercise courses are made in turn. The duration of each exercise course is about 30-40 minutes. After each exercise course has ended, the APP will count the quantity of wrong actions, the occurrence time of wrong actions, the average success rate of correct actions, and the quantity of actions completed in this course.</p><p id="p-0071" num="0068">In an embodiment of the present application, the head-mounted VR device further sends the motion data of the different parts of the human body obtained by the calculation to a server, and receives the multi-person interactive motion scene rendered and updated by the server by using a graphics processing unit (GPU), so as to realize remote interaction with another sport training user in the virtual reality scene.</p><p id="p-0072" num="0069">As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the present embodiment requires to construct a server. The user may determine the processing capacity, the application scene rendering capacity and other hardware configuration specifications of the server according to the quantity of the clients in the actual application (i.e. the head-mounted VR devices shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) and the rendering complexity of the VR content. In the present embodiment, the maximum quantity of the clients that the server can support is 100.</p><p id="p-0073" num="0070">In the present embodiment, the head-mounted VR device is provided therein with components such as a CPU, a GPU, and a wireless network module, collects the 6DOF head-motion data in real time, acquires the 6DOF hand-motion data collected in real time by the hand-motion tracker and the 6DOF foot-motion data collected in real time by the foot-motion tracker, fuses the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data, and calculates the motion data of different parts of the human body according to the data that have been fused, to obtain 150 Hz of the motion data of the different parts of the human body. Each of the clients is connected to a network via a wireless network processor such as a wireless router, and then is connected to the server via the network.</p><p id="p-0074" num="0071">The server receives the 150 Hz of the motion data of the different parts of the human body sent by each of the head-mounted VR devices via the network in real time, fuses the received motion data again, draws user avatars in the virtual reality scene, drives the virtual user avatars in real time by using the GPU for the user data of each of the head-mounted VR devices, renders and updates the information content of the multi-person interactive scene, and then transmits it to the head-mounted VR device of each of the clients in real time. Other sport training users may observe the motion states of the other sport training users in the multi-person interactive motion scene in real time on their own display screens from a third-party's perspective.</p><p id="p-0075" num="0072">The present embodiment further constructs a main controller. The main controller serves as the administrator in the sport training system and is configured to manage the head-mounted VR devices in the system. In the present embodiment, the physical structure of the main controller is the same as the physical structure of the head-mounted VR devices.</p><p id="p-0076" num="0073">Taking yoga as an example, the operation of the user interaction system according to the present application is described below.</p><p id="p-0077" num="0074">(1) Before the exercise, the user sends a &#x201c;request for joining multi-person fitness interaction&#x201d; to the server in the multi-person fitness APP of the head-mounted VR device.</p><p id="p-0078" num="0075">(2) The server quickly sends the instruction of &#x201c;request for joining multi-person fitness interaction&#x201d; sent by the user to the main controller.</p><p id="p-0079" num="0076">(3) The main controller confirms the user's joining request. If the user is allowed to join, the main controller sends a consent instruction to enable the user to join the multi-person fitness system.</p><p id="p-0080" num="0077">In the present embodiment, the main controller may be any senior fitness expert user who is responsible for inviting other fitness enthusiastic users to join the multi-person fitness system, and is also responsible for taking normative measures such as establishing fitness rules and punishment and reward mechanisms.</p><p id="p-0081" num="0078">In the process of the sport training, any sport training user may chat with the other sport training users by using a microphone on the head-mounted VR device, and may share the technical methods of fitness sports. Some senior fitness experts may help some junior sport training users correct their technical actions of fitness, and may share some interesting and active interactive topics conducive to fitness, such as diet precautions of fitness sports, to realize the remote interaction among the sport training users and improve the user experience.</p><p id="p-0082" num="0079"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic structural diagram of a sport training device according to an embodiment of the present application. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the sport training device <b>300</b> comprises: a head-mounted VR device <b>310</b>, a hand-motion tracker <b>320</b> and a foot-motion tracker <b>330</b>. The hand-motion tracker <b>320</b> and the foot-motion tracker <b>330</b> are wirelessly connected to the head-mounted VR device <b>310</b>. Before sport training, the hand-motion tracker <b>320</b> and the foot-motion tracker <b>330</b> are respectively worn on the specified parts of a hand and a foot of the user, and the head-mounted VR device <b>310</b> is worn on the head of the user. The wearing effect is shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. During the sport training, the user makes corresponding actions according to the virtual demonstrative actions displayed in the head-mounted VR device <b>310</b>.</p><p id="p-0083" num="0080">The hand-motion tracker <b>320</b> is used to collect 6DOF hand-motion data in real time and wirelessly transmit it to the head-mounted VR device <b>310</b>.</p><p id="p-0084" num="0081">The foot-motion tracker <b>330</b> is used to collect 6DOF foot-motion data in real time and wirelessly transmit it to the head-mounted VR device <b>130</b>.</p><p id="p-0085" num="0082">The head-mounted VR device <b>310</b> is used to, during the sport training, display virtual demonstrative actions, collect 6DOF head-motion data in real time, and acquire the 6DOF hand-motion data collected in real time by the hand-motion tracker <b>320</b> and the 6DOF foot-motion data collected in real time by the foot-motion tracker <b>330</b>; fuse the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data; calculate motion data of different parts of the human body according to the data that have been fused; and compare the motion data of the different parts of the human body obtained by the calculation with the standard sport training data, and if the degree of similarity is greater than a threshold, determine that the action of a human-body part meets a training standard, and if not, the head-mounted VR device <b>310</b> displays a corresponding prompting message in a virtual reality scene to prompt a human-body part whose action is not standard.</p><p id="p-0086" num="0083">In an embodiment of the present application, the head-mounted VR device <b>310</b> is provided therein with a head-mounted tracking camera, an electromagnetic signal receiving module or an ultrasonic signal receiving module; and the hand-motion tracker <b>320</b> and the foot-motion tracker <b>330</b> are both provided therein with an electromagnetic sensor and an electromagnetic signal emitting module, or are both provided therein with an ultrasonic sensor and an ultrasonic signal emitting module.</p><p id="p-0087" num="0084">The head-mounted VR device <b>310</b> is particularly used to collect the pose information of the head motion in real time by using the built-in head-mounted tracking camera.</p><p id="p-0088" num="0085">The hand-motion tracker <b>320</b> and the foot-motion tracker <b>330</b> are particularly used to collect the pose information of the hand motion and the pose information of the foot motion in real time respectively by using the built-in electromagnetic sensors, and wirelessly transmit them to the electromagnetic signal receiving module of the head-mounted VR device <b>310</b> by using the electromagnetic signal emitting modules.</p><p id="p-0089" num="0086">Alternatively, the hand-motion tracker <b>320</b> and the foot-motion tracker <b>330</b> collect the pose information of the hand motion and the pose information of the foot motion in real time respectively by using the built-in ultrasonic sensors, and wirelessly transmit them to the ultrasonic signal receiving module of the head-mounted VR device <b>310</b> by using the ultrasonic signal emitting modules.</p><p id="p-0090" num="0087">In an embodiment of the present application, the head-mounted VR device <b>310</b> is further provided therein with a first wireless-communication module and a first IMU sensor, and the hand-motion tracker <b>320</b> and foot-motion tracker <b>330</b> are both further provided therein with a second wireless-communication module and a second IMU sensor.</p><p id="p-0091" num="0088">The head-mounted VR device <b>310</b> is further particularly used to collect the IMU information of the head motion in real time by using the built-in first IMU sensor, and fuse the IMU information of the head motion with the pose information of the head motion to obtain the 6DOF head-motion data.</p><p id="p-0092" num="0089">The hand-motion tracker <b>320</b> and the foot-motion tracker <b>330</b> are further particularly used to collect the IMU information of the hand motion and the IMU information of the foot motion in real time respectively by using the built-in second IMU sensors, and wirelessly transmit them to the first wireless-communication module of the head-mounted VR device <b>310</b> by using the second wireless-communication modules. The head-mounted VR device <b>310</b> is further used to fuse the pose information of the hand motion with the IMU information of the hand motion to obtain the 6DOF hand-motion data, and fuse the pose information of the foot motion with the IMU information of the foot motion to obtain the 6DOF foot-motion data.</p><p id="p-0093" num="0090">In an embodiment of the present application, the head-mounted VR device <b>310</b> is particularly used to acquire a rotation matrix and a translation vector of the electromagnetic signal receiving module or ultrasonic signal receiving module relative to the first IMU sensor, perform coordinate system conversion on the 6DOF hand-motion data and the 6DOF foot-motion data by using the rotation matrix and the translation vector, and convert them into 6-DOF motion data with the first IMU sensor as the origin.</p><p id="p-0094" num="0091">In an embodiment of the present application, before sport training, after wearing the hand-motion tracker <b>320</b>, foot-motion tracker <b>330</b> and head-mounted VR device <b>310</b>, the user makes corresponding actions according to the virtual calibration action displayed in the head-mounted VR device. The head-mounted VR device <b>310</b> is further used to display the virtual calibration action before sport training and acquire sport training calibration data; and calculate the motion speed and the motion angle of the different parts of the human body, the displacement information of each part, and the motion hold time of each key part of the human body according to the data that have been fused and the sport training calibration data by using an inverse kinematics algorithm.</p><p id="p-0095" num="0092"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic structural diagram of a head-mounted VR device according to an embodiment of the present application. As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the head-mounted VR device <b>310</b> comprises:</p><p id="p-0096" num="0093">a displaying unit <b>3101</b> configured for displaying a virtual demonstrative action;</p><p id="p-0097" num="0094">an acquiring unit <b>3102</b> configured for acquiring 6DOF head-motion data, 6DOF hand-motion data and 6DOF foot-motion data of the user;</p><p id="p-0098" num="0095">a fusing unit <b>3103</b> configured for fusing the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data;</p><p id="p-0099" num="0096">a calculating unit <b>3104</b> configured for calculating motion data of different parts of a human body according to the data that have been fused; and</p><p id="p-0100" num="0097">a comparing unit <b>3105</b> configured for comparing the motion data of the different parts of the human body obtained by the calculation with standard sport training data of the virtual demonstrative action, and if a degree of similarity is greater than a threshold, determining that an action of a human-body part meets a training standard, and if not, displaying a corresponding prompting message in a virtual reality scene to prompt a human-body part whose action is not standard.</p><p id="p-0101" num="0098">When acquiring the 6DOF head-motion data of the user, the acquiring unit <b>3102</b> is particularly configured for:</p><p id="p-0102" num="0099">acquiring pose information of the head-mounted VR device by using a tracking camera of the head-mounted VR device;</p><p id="p-0103" num="0100">acquiring IMU information of the head-mounted VR device by using a first IMU sensor of the head-mounted VR device; and</p><p id="p-0104" num="0101">fusing the pose information of the head-mounted VR device with the IMU information of the head-mounted VR device to obtain the 6DOF head-motion data of the user.</p><p id="p-0105" num="0102">The hand-motion tracker and the foot-motion tracker collect the pose information of the hand motion and the pose information of the foot motion in real time respectively by using a built-in electromagnetic sensor/ultrasonic sensor, and wirelessly transmit to an electromagnetic signal receiving module/ultrasonic signal receiving module of the head-mounted VR device by using an electromagnetic signal emitting module/ultrasonic signal emitting module.</p><p id="p-0106" num="0103">The hand-motion tracker and the foot-motion tracker also collect IMU information of the hand motion and IMU information of the foot motion in real time respectively by using a built-in second IMU sensor, and wirelessly transmit to a first wireless-communication module of the head-mounted VR device by using a second wireless-communication module.</p><p id="p-0107" num="0104">When acquiring the 6DOF hand-motion data/6DOF foot-motion data of the user, the acquiring unit <b>3102</b> is particularly configured for:</p><p id="p-0108" num="0105">receiving hand pose information and hand IMU information sent by the hand-motion tracker, and fusing the hand pose information and the hand IMU information to obtain the 6DOF hand-motion data;</p><p id="p-0109" num="0106">and/or,</p><p id="p-0110" num="0107">receiving foot pose information and foot IMU information sent by the foot-motion tracker, fusing the foot pose information and the foot IMU information to obtain the 6DOF foot-motion data.</p><p id="p-0111" num="0108">In an embodiment, the fusing unit <b>3103</b> is particularly configured for: acquiring a rotation matrix and a translation vector of a built-in electromagnetic signal receiving module or ultrasonic signal receiving module of the head-mounted VR device relative to the first IMU sensor, and performing coordinate system conversion on the 6DOF hand-motion data and the 6DOF foot-motion data by using the rotation matrix and the translation vector, to convert the 6DOF hand-motion data and the 6DOF foot-motion data into 6-DOF motion data with the first IMU sensor as an origin.</p><p id="p-0112" num="0109"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic structural diagram of a sport training system according to an embodiment of the present application. As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the sport training system <b>500</b> comprises: a server <b>510</b>, and a plurality of above-mentioned head-mounted VR devices <b>310</b> connected to the server <b>510</b> via a network.</p><p id="p-0113" num="0110">Each of the head-mounted VR devices <b>310</b> is configured for sending the motion data of different parts of the human body of its own user obtained by calculation to the server <b>510</b>.</p><p id="p-0114" num="0111">The server <b>510</b> is configured for receiving the motion data of the different parts of the human bodies of a plurality of uses sent by the plurality of head-mounted VR devices <b>310</b>; in a virtual reality scene, drawing user avatars, driving the virtual user avatars in real time by using a graphics processing unit (GPU) on the received user data of each of the head-mounted VR devices, and rendering and updating to obtain a multi-person interactive motion scene; and sending the multi-person interactive motion scene to each of the head-mounted VR devices <b>310</b> in real time.</p><p id="p-0115" num="0112">Each of the head-mounted VR devices <b>310</b> is further configured for displaying the multi-person interactive motion scene on a display screen, so as to realize remote interaction with another sport training user in the virtual reality scene.</p><p id="p-0116" num="0113">The sport training system according to the present embodiment realizes the remote interaction among sport training users in the virtual reality scene via the server <b>510</b> and the plurality of head-mounted VR devices <b>310</b> connected to the server, so that the sport training users can interactively chat, and share fitness methods, diet precautions and other topics in the fitness process, thereby improving the interactivity and interest of fitness exercises, improving the user experience, and thus enhancing the fitness efficiency and effect.</p><p id="p-0117" num="0114">It should be noted that the particular embodiments of the above device and system embodiments can be carried out with reference to the particular embodiments of the above corresponding process embodiments, and will not be repeated here.</p><p id="p-0118" num="0115">In sum, the technical solutions of the present application can determine whether the user's actions are standard and whether the hold time is sufficient by using merely the hand-motion tracker, the foot-motion tracker and the head-mounted VR device, and send the feedback to the head-mounted VR device in time, and the user is not required to wear a large number of sensors, thereby improving the user experience. The cooperation of the head-mounted tracking camera, the electromagnetic sensor/ultrasonic sensor and the IMU sensor increases the tracking precision and frequency. The position offset error can reach the order of millimeters, the rotation angle offset error can be less than 1.5&#xb0;, the outputted frequency is greater than 200 Hz, and high-precision high-frequency motion data can be obtained. Further, by comparing the obtained motion data with the demonstrative actions and marking the prompting message on the human-body part whose action is not standard, the non-demonstrative actions can be corrected in time, and various exercise indicators such as the quantity of wrong actions, the occurrence time of wrong actions, the average success rate of correct actions and the quantity of completed actions can be counted and fed back to the user in time, which can enable the user to understand the completion of the actions and improve the fitness efficiency and effect. Moreover, the remote interaction among sport training users can be realized by using the server, which further improves the user experience.</p><p id="p-0119" num="0116">It should be noted that:</p><p id="p-0120" num="0117">The algorithms and displays provided herein are not inherently relevant to any specific computer, virtual device or other devices. Various general purpose devices can also be used together with the teaching herein. According to the above description, the structures that are required to construct this type of devices are apparent. Furthermore, the present application is not limited to any specific programming language. It should be understood that the contents of the present application described herein can be implemented by using various programming languages, and the description above for a specific language is intended to disclose the most preferable embodiments of the present application.</p><p id="p-0121" num="0118">The description provided herein describes many concrete details. However, it can be understood that the embodiments of the present application may be implemented without those concrete details. In some of the embodiments, well-known processes, structures and techniques are not described in detail, so as not to affect the understanding of the description.</p><p id="p-0122" num="0119">Similarly, it should be understood that, in order to simplify the present application and help understanding one or more of the aspects of the present application, in the above description of the exemplary embodiments of the present application, the features of the present application are sometimes grouped into individual embodiments, figures or the descriptions thereto. However, the method that is disclosed should not be interpreted as reflecting the intention that the present application, which is claimed, requires more feature than the features that are explicitly set forth in each of the claims. More exactly, as reflected by the following claims, the aspects of the present application are less than all of the features of the individual embodiments that are disclosed above. Therefore, the claims which follow a particular embodiment are thereby explicitly incorporated into the particular embodiment, and each of the claims itself serves as an separate embodiment of the present application.</p><p id="p-0123" num="0120">A person skilled in the art can understand that the modules in the device of an embodiment may be self-adaptively modified and be provided in one or more devices that are different from the embodiment. The modules or units or components in the embodiments may be combined into one module or unit or component, and may also be divided into multiple submodules or subunits or subcomponents. Unless at least some of such features and/or processes or units are mutually rejected, all of the features that are disclosed by the description (including the accompanying claims, the abstract and the drawings) and all of the processes or units of any method or device that is disclosed herein may be combined in any combination. Unless explicitly stated otherwise, each of the features that are disclosed by the description (including the accompanying claims, the abstract and the drawings) may be replaced by alternative features that provide the same, equivalent or similar objects.</p><p id="p-0124" num="0121">Furthermore, a person skilled in the art can understand that, although some embodiments described herein comprise a certain features that are included in other embodiments instead of other features, the combination of the features of different embodiments means maintaining within the scope of the present disclosure and forming different embodiments. For example, in the following claims, any one of the embodiments that the present disclosure seeks to protect can be used in any combination.</p><p id="p-0125" num="0122">Each component embodiment of the present application may be implemented by hardware, or by software modules that are operated on one or more processors, or by a combination thereof. A person skilled in the art should understand that some or all of the functions of some or all of the components of the sport training device according to the embodiments of the present application may be implemented by using a microprocessor or a digital signal processor (DSP) in practice. The present application may also be implemented as apparatus or device programs (for example, computer programs and computer program products) for implementing part of or the whole of the method described herein. Such programs for implementing the present application may be stored in a computer-readable medium, or may be in the form of one or more signals. Such signals may be downloaded from an Internet website, or provided on a carrier signal, or provided in any other forms.</p><p id="p-0126" num="0123">It should be noted that the above embodiments are for describing the present disclosure rather than limiting the present disclosure, and a person skilled in the art may design alternative embodiments without departing from the scope of the appended claims. In the claims, any reference signs between parentheses should not be construed as limiting the claims. The word &#x201c;comprise&#x201d; does not exclude elements or steps that are not listed in the claims. The word &#x201c;a&#x201d; or &#x201c;an&#x201d; preceding an element does not exclude the existing of a plurality of such elements. The present application may be implemented by means of hardware comprising several different elements and by means of a properly programmed computer. In unit claims that list several devices, some of those devices may be embodied by the same item of hardware. The words first, second, third and so on do not denote any order. Those words may be interpreted as names.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A sport training method, performed by a head-mounted VR device wirelessly connected to a hand-motion tracker for tracking motion data of a hand of a user and a foot-motion tracker for tracking motion data of a foot of the user, wherein the method comprises:<claim-text>displaying a virtual demonstrative action;</claim-text><claim-text>acquiring 6DOF head-motion data, 6DOF hand-motion data and 6DOF foot-motion data of the user;</claim-text><claim-text>fusing the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data;</claim-text><claim-text>calculating motion data of different parts of a human body according to the data that have been fused; and</claim-text><claim-text>comparing the motion data of the different parts of the human body obtained by the calculation with standard sport training data of the virtual demonstrative action, and if a degree of similarity is greater than a threshold, determining that an action of a human-body part meets a training standard, and if not, displaying a corresponding prompting message in a virtual reality scene to prompt a human-body part whose action is not standard.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of acquiring the 6DOF head-motion data of the user comprises:<claim-text>acquiring pose information of the head-mounted VR device by using a tracking camera of the head-mounted VR device;</claim-text><claim-text>acquiring IMU information of the head-mounted VR device by using a first IMU sensor of the head-mounted VR device; and</claim-text><claim-text>fusing the pose information of the head-mounted VR device with the IMU information of the head-mounted VR device to obtain the 6DOF head-motion data of the user.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the hand-motion tracker and the foot-motion tracker collect pose information of a hand motion and pose information of a foot motion in real time respectively by using a built-in electromagnetic sensor/ultrasonic sensor, and wirelessly transmit to an electromagnetic signal receiving module/ultrasonic signal receiving module of the head-mounted VR device by using an electromagnetic signal emitting module/ultrasonic signal emitting module;</claim-text><claim-text>the hand-motion tracker and the foot-motion tracker also collect IMU information of the hand motion and IMU information of the foot motion in real time respectively by using a built-in second IMU sensor, and wirelessly transmit to a first wireless-communication module of the head-mounted VR device by using a second wireless-communication module;</claim-text><claim-text>the step of acquiring the 6DOF hand-motion data/6DOF foot-motion data of the user comprises:</claim-text><claim-text>receiving hand pose information and hand IMU information sent by the hand-motion tracker, and fusing the hand pose information and the hand IMU information to obtain the 6DOF hand-motion data;</claim-text><claim-text>and/or,</claim-text><claim-text>receiving foot pose information and foot IMU information sent by the foot-motion tracker, fusing the foot pose information and the foot IMU information to obtain the 6DOF foot-motion data.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of fusing the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data comprises:<claim-text>acquiring a rotation matrix and a translation vector of a built-in electromagnetic signal receiving module or ultrasonic signal receiving module of the head-mounted VR device relative to the first IMU sensor, and performing coordinate system conversion on the 6DOF hand-motion data and the 6DOF foot-motion data by using the rotation matrix and the translation vector, to convert the 6DOF hand-motion data and the 6DOF foot-motion data into 6-DOF motion data with the first IMU sensor as an origin.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>sending the motion data of the different parts of the human body obtained by the calculation to a server, so that the server, in a virtual reality scene, according to the motion data, draws a plurality of user avatars, and according to the plurality of user avatars, renders to generate a multi-person interactive motion scene; and</claim-text><claim-text>receiving the multi-person interactive motion scene sent by the server and displaying the multi-person interactive motion scene on a display screen, so as to realize remote interaction with another sport training user in the virtual reality scene.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. A head-mounted VR device, wirelessly connected to a hand-motion tracker for tracking motion data of a hand of a user and a foot-motion tracker for tracking motion data of a foot of the user, wherein the head-mounted VR device comprises:<claim-text>a displaying unit configured for displaying a virtual demonstrative action;</claim-text><claim-text>an acquiring unit configured for acquiring 6DOF head-motion data, 6DOF hand-motion data and 6DOF foot-motion data of the user;</claim-text><claim-text>a fusing unit configured for fusing the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data;</claim-text><claim-text>a calculating unit configured for calculating motion data of different parts of a human body according to the data that have been fused; and</claim-text><claim-text>a comparing unit configured for comparing the motion data of the different parts of the human body obtained by the calculation with standard sport training data of the virtual demonstrative action, and if a degree of similarity is greater than a threshold, determining that an action of a human-body part meets a training standard, and if not, displaying a corresponding prompting message in a virtual reality scene to prompt a human-body part whose action is not standard.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The head-mounted VR device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein when acquiring the 6DOF head-motion data of the user, the acquiring unit is configured for:<claim-text>acquiring pose information of the head-mounted VR device by using a tracking camera of the head-mounted VR device;</claim-text><claim-text>acquiring IMU information of the head-mounted VR device by using a first IMU sensor of the head-mounted VR device; and</claim-text><claim-text>fusing the pose information of the head-mounted VR device with the IMU information of the head-mounted VR device to obtain the 6DOF head-motion data of the user.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The head-mounted VR device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein<claim-text>the hand-motion tracker and the foot-motion tracker collect pose information of a hand motion and pose information of a foot motion in real time respectively by using a built-in electromagnetic sensor/ultrasonic sensor, and wirelessly transmit to an electromagnetic signal receiving module/ultrasonic signal receiving module of the head-mounted VR device by using an electromagnetic signal emitting module/ultrasonic signal emitting module;</claim-text><claim-text>the hand-motion tracker and the foot-motion tracker also collect IMU information of the hand motion and IMU information of the foot motion in real time respectively by using a built-in second IMU sensor, and wirelessly transmit to a first wireless-communication module of the head-mounted VR device by using a second wireless-communication module; and</claim-text><claim-text>when acquiring the 6DOF hand-motion data/6DOF foot-motion data of the user, the acquiring unit is configured for:</claim-text><claim-text>receiving hand pose information and hand IMU information sent by the hand-motion tracker, and fusing the hand pose information and the hand IMU information to obtain the 6DOF hand-motion data;</claim-text><claim-text>and/or,</claim-text><claim-text>receiving foot pose information and foot IMU information sent by the foot-motion tracker, fusing the foot pose information and the foot IMU information to obtain the 6DOF foot-motion data.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The head-mounted VR device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the fusing unit is configured for:<claim-text>acquiring a rotation matrix and a translation vector of a built-in electromagnetic signal receiving module or ultrasonic signal receiving module of the head-mounted VR device relative to the first IMU sensor, and performing coordinate system conversion on the 6DOF hand-motion data and the 6DOF foot-motion data by using the rotation matrix and the translation vector, to convert the 6DOF hand-motion data and the 6DOF foot-motion data into 6-DOF motion data with the first IMU sensor as an origin.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A sport training system, comprising: a server, and a plurality of head-mounted VR devices connected to the server via a network;<claim-text>each of the head-mounted VR devices is configured for sending motion data of different parts of a human body obtained by calculation to the server;</claim-text><claim-text>the server is configured for receiving the motion data of the different parts of the human body sent by the plurality of head-mounted VR devices; in a virtual reality scene, according to the motion data, drawing a plurality of user avatars, and according to the plurality of user avatars, rendering to generate a multi-person interactive motion scene; and sending the multi-person interactive motion scene to each of the head-mounted VR devices in real time; and</claim-text><claim-text>each of the head-mounted VR devices is further configured for displaying the multi-person interactive motion scene on a display screen, so as to realize remote interaction with another sport training user in the virtual reality scene.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A computer-readable storage medium having one or more programs stored therein, wherein when executed by a processor, the one or more programs implement a sport training method, performed by a head-mounted VR device wirelessly connected to a hand-motion tracker for tracking motion data of a hand of a user and a foot-motion tracker for tracking motion data of a foot of the user, wherein the method comprises:<claim-text>displaying a virtual demonstrative action;</claim-text><claim-text>acquiring 6DOF head-motion data, 6DOF hand-motion data and 6DOF foot-motion data of the user;</claim-text><claim-text>fusing the 6DOF hand-motion data and the 6DOF foot-motion data with the 6DOF head-motion data;</claim-text><claim-text>calculating motion data of different parts of a human body according to the data that have been fused; and</claim-text><claim-text>comparing the motion data of the different parts of the human body obtained by the calculation with standard sport training data of the virtual demonstrative action, and if a degree of similarity is greater than a threshold, determining that an action of a human-body part meets a training standard, and if not, displaying a corresponding prompting message in a virtual reality scene to prompt a human-body part whose action is not standard.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The computer-readable storage medium according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the method further comprises:<claim-text>sending the motion data of the different parts of the human body obtained by the calculation to a server, so that the server, in a virtual reality scene, according to the motion data, draws a plurality of user avatars, and according to the plurality of user avatars, renders to generate a multi-person interactive motion scene; and</claim-text><claim-text>receiving the multi-person interactive motion scene sent by the server and displaying the multi-person interactive motion scene on a display screen, so as to realize remote interaction with another sport training user in the virtual reality scene.</claim-text></claim-text></claim></claims></us-patent-application>
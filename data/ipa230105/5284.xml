<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005285A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005285</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17940777</doc-number><date>20220908</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>413</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>174</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>226</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>416</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>413</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>174</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>226</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>416</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">MULTI-PAGE DOCUMENT RECOGNITION IN DOCUMENT CAPTURE</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16953561</doc-number><date>20201120</date></document-id><parent-status>ABANDONED</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17940777</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16290453</doc-number><date>20190301</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10860848</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16953561</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15221433</doc-number><date>20160727</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10248858</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16290453</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>13720671</doc-number><date>20121219</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>9430453</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>15221433</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Open Text Corporation</orgname><address><city>Waterloo</city><country>CA</country></address></addressbook><residence><country>CA</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Ho</last-name><first-name>Ming Fung</first-name><address><city>Fremont</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Techniques to capture document data are disclosed. It is determined that a sequence of pages in a stream of document page images comprise a single multi-page document. Data is extracted from two or more different pages included in the sequence. The data extracted from two or more different pages included in the sequence of pages is used to populate a data entry form associated with the multi-page document.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="143.09mm" wi="81.62mm" file="US20230005285A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="224.71mm" wi="83.14mm" file="US20230005285A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="216.41mm" wi="157.48mm" file="US20230005285A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="210.40mm" wi="130.89mm" file="US20230005285A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="215.14mm" wi="141.39mm" file="US20230005285A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="132.67mm" wi="156.80mm" file="US20230005285A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="218.10mm" wi="83.06mm" file="US20230005285A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="218.10mm" wi="142.32mm" file="US20230005285A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="215.14mm" wi="141.31mm" file="US20230005285A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="224.71mm" wi="83.14mm" file="US20230005285A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="224.71mm" wi="95.76mm" file="US20230005285A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="226.31mm" wi="142.49mm" file="US20230005285A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="211.75mm" wi="83.65mm" file="US20230005285A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="211.75mm" wi="83.65mm" file="US20230005285A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO OTHER APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 16/953,561, filed Nov. 20, 2020, entitled &#x201c;MULTI-PAGE DOCUMENT RECOGNITION IN DOCUMENT CAPTURE,&#x201d; which is a continuation of U.S. patent application Ser. No. 16/290,453, filed Mar. 1, 2019, entitled &#x201c;MULTI-PAGE DOCUMENT RECOGNITION IN DOCUMENT CAPTURE,&#x201d; issued as U.S. Pat. No. 10,860,848, which is a continuation of U.S. patent application Ser. No. 15/221,433, filed Jul. 27, 2016, entitled &#x201c;MULTI-PAGE DOCUMENT RECOGNITION IN DOCUMENT CAPTURE,&#x201d; issued as U.S. Pat. No. 10,248,858, which is a continuation of U.S. patent application Ser. No. 13/720,671, filed Dec. 19, 2012, entitled &#x201c;MULTI-PAGE DOCUMENT RECOGNITION IN DOCUMENT CAPTURE,&#x201d; issued as U.S. Pat. No. 9,430,453, all of which are incorporated herein by reference for all purposes.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading><p id="p-0003" num="0002">In document capture, typically pages are recognized and validated one at a time, in sequence. In the typical approach, each page is processed independently with its own data entry form, value extraction, and validation. In the case of a multi-page document, typically the metadata document generated through document capture for each page has to be mapped to a multi-page structure and data values reconciled across pages through additional processing.</p><p id="p-0004" num="0003">In practice, during data validation human operators typically must navigate through multiple pages and associated data entry forms, for example to compare and reconcile values that occur in different pages, etc. This approach depends on the knowledge of human operators of the location of data in different pages of a multiple page document, and in the worst case may require an operator to hunt through multiple independent pages and/or associated page-specific data entry forms to cross-validate data, for example. In addition, treating each page as a separate document results in suboptimal processing of structures such as tables, which may span multiple pages.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0005" num="0004">Various embodiments of the invention are disclosed in the following detailed description and the accompanying drawings.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a flow chart illustrating an embodiment of a process to capture data.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an embodiment of a document capture system and environment.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating an embodiment of a document capture system.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram illustrating an embodiment of a data validation user interface.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a screen shot illustrating an embodiment of a technique to minimize eye strain and/or fatigue in manual indexing.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow chart illustrating an embodiment of a process to facilitate manual indexing.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram illustrating an embodiment of a document capture system and process.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram illustrating an embodiment of an interface to validate a multi-page document.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>9</b>A</figref> is a flow chart illustrating an embodiment of a process to capture document data.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>9</b>B</figref> is a flow chart illustrating an embodiment of a process to capture document data.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flow chart illustrating an embodiment of a process to perform validation of data values extracted from a multi-page document.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flow chart illustrating an embodiment of a process to perform validation of data values extracted from a multi-page document.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flow chart illustrating an embodiment of a process to perform validation of data values extracted from a multi-page document.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0019" num="0018">The invention can be implemented in numerous ways, including as a process; an apparatus; a system; a composition of matter; a computer program product embodied on a computer readable storage medium; and/or a processor, such as a processor configured to execute instructions stored on and/or provided by a memory coupled to the processor. In this specification, these implementations, or any other form that the invention may take, may be referred to as techniques. In general, the order of the steps of disclosed processes may be altered within the scope of the invention. Unless stated otherwise, a component such as a processor or a memory described as being configured to perform a task may be implemented as a general component that is temporarily configured to perform the task at a given time or a specific component that is manufactured to perform the task. As used herein, the term &#x2018;processor&#x2019; refers to one or more devices, circuits, and/or processing cores configured to process data, such as computer program instructions.</p><p id="p-0020" num="0019">A detailed description of one or more embodiments of the invention is provided below along with accompanying figures that illustrate the principles of the invention. The invention is described in connection with such embodiments, but the invention is not limited to any embodiment. The scope of the invention is limited only by the claims and the invention encompasses numerous alternatives, modifications and equivalents. Numerous specific details are set forth in the following description in order to provide a thorough understanding of the invention. These details are provided for the purpose of example and the invention may be practiced according to the claims without some or all of these specific details. For the purpose of clarity, technical material that is known in the technical fields related to the invention has not been described in detail so that the invention is not unnecessarily obscured.</p><p id="p-0021" num="0020">Processing a multi-page document as a single entity, with a single corresponding data entry form, in an automated document capture context is disclosed. In various embodiments, the pages comprising a multi-page document are identified and associated with a multi-page document type. A corresponding data entry form is used to provide a structured representation of data extracted from the pages of the multi-page document. Structures that may span multiple pages, such as a table or list of values, are associated together in a single array or other structure of the data entry form. Validation of extracted values based on dependency fields that may occur on different pages is facilitated, both in automated processing and in human validation.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a flow chart illustrating an embodiment of a process to capture data. In the example shown, document content is captured into a digital format (<b>102</b>), e.g., by scanning the physical sheet(s) to create a scanned image. The document is classified (<b>104</b>). In some embodiments, classification includes detecting a document type corresponding to an associated data entry form. Data is extracted from the digital content (<b>106</b>), for example through optical character recognition (OCR) and/or optical mark recognition (OMR) techniques. Extracted data is validated (<b>108</b>). In various embodiments, validation may be performed at least in part by an automated process, for example by comparing multiple occurrences of the same value, by performing computations or other manipulations based on extracted data, etc. In various embodiments, all or a subset of extracted values, e.g., those for which less than a required degree of confidence is achieved through automated extraction and/or validation, may be validated manually, by a human indexer or other operator. Once all data has been validated, output is delivered (<b>110</b>), e.g., by storing the document image and associated data in an enterprise content management system or other repository.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an embodiment of a document capture system and environment. In the example shown, a client system <b>212</b> is attached to a scanner <b>204</b>. Documents are scanned by scanner <b>204</b> and the resulting document image is sent by the client system <b>212</b> to document capture system <b>202</b> for processing, e.g., using all or part of the process of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In the example shown, document capture system <b>202</b> uses a library of data entry forms <b>206</b> to create a structured representation of data extracted from a scanned document. For example, as in <figref idref="DRAWINGS">FIG. <b>1</b></figref> steps <b>104</b> and <b>106</b>, in some embodiments a document is classified by type and an instance of a corresponding data entry form is created and populated with data values extracted from the document image. In some embodiments, data validation may be performed, at least in part, by document capture system <b>202</b> by accessing external data <b>208</b> via a network <b>210</b>. For example, an external third party database that associates street addresses with correct postal zip codes may be used to validate a zip code value extracted from a document. In the example shown, validation may be performed at least in part by a plurality of manual indexers each using an associated client system <b>212</b> to communicate via network <b>210</b> with document capture system <b>202</b>. For example, document capture system <b>202</b> may be configured to queue human validation tasks and to serve tasks out to indexers using clients <b>212</b>. Each client system <b>212</b> may use a browser based and/or installed client software provided functionality to validate data as described herein. In some embodiments, once validation has been completed the resulting raw document image and/or form data are delivered as output, for example by storing the document image and associated form data in a repository <b>214</b>, such as an enterprise content management (ECM) or other repository.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating an embodiment of a document capture system. In the example shown, the document capture system <b>202</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref> is shown to receive document image data, e.g., via network <b>204</b> from a scanning client system <b>212</b>. Document image data is received in some embodiments in batches and is stored in an image store <b>308</b>. Document image data is provided to a data extraction module <b>310</b> which uses a data entry forms library <b>312</b> to classify each document by type and create an instance of a type-specific data entry form. Data extraction module <b>310</b> uses OCR, OMR, and/or other techniques to extract data values from the document image and uses the extracted values to populate the corresponding data entry form instance. In some embodiments, data extraction module <b>310</b> may provide a score or other indication of a degree of confidence with which an extracted value has been determined based on a corresponding portion of the document image. In some embodiments, for each data entry form field a corresponding location within the document image from which the data value entered by the extraction module in that form field was extracted, for example the portion that shows the text to which OCR or other techniques were applied to determine the text present in the image, is recorded. In the example shown, the data extraction module <b>310</b> provides the populated form to a validation module <b>314</b> configured to perform validation (automated and/or human as configured and/or required). In some embodiments, the validation module <b>314</b> applies one or more validation rules to identify fields that may require a human operator to validate. In the example shown, the validation module <b>314</b> may communicate via a communications interface <b>316</b>, for example a network interface card or other communications interface, to obtain external data to be used in validation and/or to generate and provide to human indexers via associated client systems, such as one or more of clients <b>212</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, tasks to perform human/manual validation of all or a subset of form fields. The validated data is provided to a delivery/output module <b>318</b> configured to provide output via communication interface <b>316</b>, for example by storing the document image and/or extracted data (structured data as capture using the corresponding data entry form) in an enterprise content management system or other repository.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram illustrating an embodiment of a data validation user interface. In the example shown, validation interface <b>400</b> includes a document image display area <b>402</b>, a data entry form interface <b>404</b>, and a navigation frame <b>406</b>. A document image <b>408</b> is displayed in document image display area <b>402</b>. In the example shown, portions of document image <b>408</b> that correspond to data entry form fields in the form shown in data entry form interface <b>404</b> are highlighted, as indicated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> by the cross-hatched rectangles in document image <b>408</b> as shown. In this example, thumbnails are shown in navigation pane <b>406</b>, each corresponding for example to an associated document and/or page from which data has been captured. In this example, the topmost thumbnail image as shown in navigation frame <b>406</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> is highlighted (thicker outer outline), indicating that document image <b>408</b> as displayed in document image display area <b>402</b> corresponds to the topmost thumbnail. In some embodiments, controls are provided (e.g., on screen controls, key stokes or combinations, etc.) to enable the operator to pan, scroll, and/or zoom in/out with respect to the document image <b>408</b>, for example to focus and zoom in on (magnify) a particular portion of the document image <b>408</b>. In some embodiments, as the operator validates each field a cursor advances to the next field and a corresponding portion of the document image <b>408</b> is highlighted.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a screen shot illustrating an embodiment of a technique to minimize eye strain and/or fatigue in manual indexing. In the example shown, partial screen shot <b>500</b> includes a portion of a manual data validation user interface that includes a data entry form field <b>502</b>, in this example with a current value of &#x201c;888-555-1348&#x201d; displayed, and nearby to the form field, as displayed in the data entry form portion of the data validation interface, a snippet <b>504</b> taken from a corresponding document image, which shows just the portion of the document image that contains the image of the text (in this case numerical values) extracted from the document to populate the form field <b>502</b>. In this example, a confirmation or other informational and/or error message <b>506</b> similarly is displayed near the form field <b>502</b>. As a result, the form field <b>502</b>, corresponding snippet <b>504</b>, and confirmation message <b>506</b> are all in the line of sight, or nearly so, at the same time, enabling all information required to validate the value entered in the form field <b>502</b>, including entering any correction that may be required, to be viewed at the same time and/or with minimal eye or head movement and without requiring the operator to scan back and forth between the document image frame and the data entry form, and/or to scroll, pan, or zoom in/out in the document image as viewed to locate and scale to a readable size the text to be validated. In some embodiments, the snippet <b>504</b> is scaled to ensure readability, for example by including in the snippet only (or mostly) the text to be validated and scaling the image to a readable size, for example until the image is of at least a prescribed minimum size and/or the displayed characters are of a prescribed minimum &#x201c;point&#x201d; or other size.</p><p id="p-0027" num="0026">In some embodiments, as an operator finishes validation of a field, indicated for example by pressing the &#x201c;enter&#x201d; key or selecting another key or on screen control, the system automatically pans to the next data entry form field, retrieves and displays near the form field a corresponding document image snippet. In this way, the operator can navigate through the form and corresponding portions of the document image without retargeting, i.e., without having to redirect their eyes to a different point or points on the screen.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow chart illustrating an embodiment of a process to facilitate manual indexing. In various embodiments, the process of <figref idref="DRAWINGS">FIG. <b>6</b></figref> is used to provide an interface such as the one shown and described above in connection with <figref idref="DRAWINGS">FIG. <b>5</b></figref>. In the example shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a snippet containing the text or other document image portion corresponding to a data entry form field to be validated is obtained, and an association between the snippet and/or the associated location in the document image, on the one hand, and the corresponding form field, on the other hand, is stored (<b>602</b>). The snippet is scaled as/if need for readability (<b>604</b>). The scaled (if applicable) snippet is displayed adjacent or otherwise near to the form field where corresponding extracted data to be validated is displayed and/or entered (<b>606</b>).</p><p id="p-0029" num="0028">Typically, as noted above pages comprising a multiple page document have been processed separately, each page having its own corresponding electronic data entry form associated with it. The per-page form approach has a number of shortcomings. For example, a value (e.g., an account number on the footer of each page in an invoice) may occur in several pages. An error on a single page results in work for the operator, because typically there is no framework to reconcile data across pages and to auto-correct data. In addition, in production, the operator will only become aware of the problem when he navigates to the page. If there are large discrepancies between values of many pages, then the operator must manually look at each page and that takes time.</p><p id="p-0030" num="0029">In semi-structured and unstructured documents, there can be any number of variations of pages. If the data-entry form is page-based, and a unique form per page is used, this results in an unmanageable number of forms. If a generic form that contains a union of possible fields is used, this results in forms with unused fields. This requires extra work to handle. Furthermore, if a value is copied from another page, its source value and location typically is not shown because only the current page, and not the page from which the copied value was extracted, is shown. If the page is changed, it would result in the data-entry form being changed. Changing the data-entry form then disrupts the sequence of work, resulting in lower operator efficiency.</p><p id="p-0031" num="0030">Under the form-per-page approach, when a table spans multiple pages, the technique of copying data between pages results in a large set of duplicate values. Extra effort is then needed to synchronize if the user makes any changes on any page. The navigation problem described above is compounded. For example, suppose the subtotals on a multi-page invoice line items table do not add up. It is more cumbersome for the operator to go through each page and then each table, and to work with duplicate row values.</p><p id="p-0032" num="0031">In content management systems, the metadata object is usually not defined per page. To export per-page forms, effort must be made to map values to their corresponding attributes of a metadata object used to represent the multi-page document in the content management system.</p><p id="p-0033" num="0032">In light of all the foregoing shortcomings of the per-page approach to document capture as applied to multi-page documents, automatic detection and processing of a multi-page document as a single document is disclosed. In various embodiments, automatic detection of the pages comprising a multiple page document is performed. Data values are extracted from the pages comprising the document and used to populate a single electronic data entry form for the multi-page document. The operator can then go through the electronic data entry form, for example to validate data fields as required, and the document capture and/or validation system shows the location in the captured document of the corresponding data, regardless of which page(s) it occurs in, rather than the operator having to find and/or choose each page, indexing each independently, and then reconcile later data that occurs in and/or spans multiple pages.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram illustrating an embodiment of a document capture system and process. In the example shown, scanned pages <b>702</b>, <b>704</b>, and <b>706</b> comprise a multi-page document. First page recognition and/or other techniques are applied in various embodiments to detect automatically the beginning and/or ending of a multi-page document such as document. The pages <b>702</b>, <b>704</b>, and <b>706</b> are identified through a process <b>708</b> as comprising a single multi-page document. A corresponding document type is determined and data values are extracted from pages <b>702</b>, <b>704</b>, and <b>706</b> to populate a single data entry form <b>710</b> configured to capture data values extracted from the multi-page document. In the example shown, the respective locations within the page images <b>702</b>, <b>704</b>, and <b>706</b> of data extracted to populate form <b>710</b> are shown as small cross-hatched rectangles. The rows at the bottom of page <b>702</b> and the top of page <b>704</b> in this example comprise a single table, list, or other array that spans pages <b>702</b> and <b>704</b>. The corresponding extracted data values are in some embodiments captured initially in page specific arrays, the rows of which are concatenated in the example shown to populate the single table at the bottom of form <b>710</b>.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram illustrating an embodiment of an interface to validate a multi-page document. In the example shown, the interface <b>800</b> includes a page image display area <b>802</b>, in which in the example shown an image of page <b>702</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref> is shown. The interface <b>800</b> further includes a data entry form area <b>804</b>, in this example corresponding to the form <b>710</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>. Thumbnails for the pages <b>702</b>, <b>704</b>, and <b>706</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref> (not numbered individually in <figref idref="DRAWINGS">FIG. <b>8</b></figref>) are displayed in navigation pane <b>806</b>. In the example shown, the topmost thumbnail as displayed in navigation pane <b>806</b> is highlighted as being currently &#x201c;selected&#x201d; for display in page image display area <b>802</b>. In various embodiments, selection by a human operator of a thumbnail in navigation pane <b>806</b> results in an image of the corresponding page being displayed in page image display area <b>802</b>. In some embodiments, as an operator navigates to different form fields in the form area <b>804</b> a corresponding portion or portions of the multi-page document, in one or more pages may be navigated to automatically. For example, navigation to a first row of the three column table at the bottom of the form in this example may in some embodiments cause the first page <b>702</b> to be displayed. Selection of a cell in one of the bottom three rows, either manually or automatically as the system advances to a next field to be validated, in various embodiments may cause the second page of the multi-page document, from which the corresponding data was extracted in this example, to be displayed in the page image display area <b>802</b>. In various embodiments, selection of a field in form area <b>804</b> results in a snippet of a corresponding portion of the page from which the data associated with that field was extracted is determined, retrieved, and displayed, for example in a location adjacent or nearly adjacent to the field, as described above.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>9</b>A</figref> is a flow chart illustrating an embodiment of a process to capture document data. In the example shown, the beginning and/or end of a multi-page document is/are detected (<b>902</b>). For example, known techniques to detect a first page may be used, and a multi-page document may be determined to have been encountered if one or more subsequent pages are scanned prior to a next &#x201c;first&#x201d; page is detected. A document type is determined and a corresponding data entry form instance is created (<b>904</b>). Scalar (single value) and array (tables, lists, or other two dimensional sets of data) data values are identified and extracted, for example using OCR, OMR, or other automated extraction techniques (<b>906</b>). Occurrences of the same and/or dependent values in multiple locations, including across page boundaries, may be used to perform automated and/or manual validation (<b>908</b>). For example, a name that appears at the beginning of a life insurance application and again in an attached report of a physical examination may be cross-checked to determine the accuracy of data extraction from one or both of the locations. Rows of arrays that span multiple pages are concatenated into a single form table (<b>910</b>). Array values may be validated using the full table, including across page boundaries (<b>912</b>). For example, quantity and unit price fields may be multiplied and the result compared to a line item subtotal, subtotals in all rows (including potentially across page boundaries) may be summed and compared to an extracted total, etc.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>9</b>B</figref> is a flow chart illustrating an embodiment of a process to capture document data. In the example shown, a library of metadata document types is defined, with each document type containing scalar fields and tables of array fields (<b>922</b>). Automatic page recognition is done as in prior art, with page types determined (<b>924</b>). Values are extracted into per-page scalar and array fields by name, and each field's location on the page is saved (<b>926</b>). The multi-page document type is determined from an analysis of the stream of page types (<b>928</b>). Data from the component pages is automatically combined into the document type (<b>930</b>). A given named scalar field may occur on any page, or in multiple pages. Data validation is performed (<b>932</b>).</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flow chart illustrating an embodiment of a process to perform validation of data values extracted from a multi-page document. In the example shown, an indication is received that an operator is done validating a currently displayed data (<b>1002</b>), e.g., the &#x201c;Date&#x201d; field in the example shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. If no more fields remain to be validated (<b>1004</b>), the process ends. Otherwise, if the next field to be validated is on the same page (<b>1006</b>) the next field in the data entry form is advanced to and displayed, and a corresponding snippet or other portion of the current page, from which the associated data value to be validated was extracted, is displayed adjacent to the form field (<b>1008</b>). If the next form field requiring validation is associated with data from a different page of the multi-page document (<b>1006</b>), the system automatically retrieves or otherwise accesses the other page and/or an applicable portion thereof (e.g., a corresponding snippet) (<b>1010</b>), transparently to the human operator, and the next form field and the corresponding snippet obtained from the other page of the multi-page document are displayed for validation (<b>1008</b>) transparently to and without requiring any further action by the human operator.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flow chart illustrating an embodiment of a process to perform validation of data values extracted from a multi-page document. In the example shown, a definition of a library of validation rules is received (<b>1102</b>). Examples include, without limitation, a rule requiring that a first value extracted from a named field A must match a second value extracted from a named field B. Another example is a rule requiring that a sum or other computation based on a specified set of fields must equal a value extracted from another named field, e.g., subtotals in an array must sum to equal a total. Document type definitions are received (<b>1104</b>). Each definition identifies validation rules to be applied, and as applicable a mapping to the document type fields to be used to apply each rule. An operator interface is provided that facilitates multi-field validation, including across page boundaries (<b>1106</b>). In some embodiments, for example, the interface enables an operator to iterate through just the dependent fields that require validation. As the operator corrects and/or confirms the entered value for a first dependent field, for example, and hits &#x201c;enter&#x201d;, the system advances automatically to display a next one of the dependent fields and its associate document image portion, from whichever page in which it may be located. The system iterates through the dependent fields until the operator enters data that clears the validation error and/or there are no more dependent fields to be displayed. In various embodiments, by combining data extracted from multiple page images of a multi-page documents into a single document type and associated data entry form, automated and manual validation of dependent data fields that occur on or across different pages is facilitated, without requiring software code and/or human action to navigate between data entry forms used to capture data extracted from individual pages.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flow chart illustrating an embodiment of a process to perform validation of data values extracted from a multi-page document. In the example shown, an instance of a multi-page document type is received (<b>1202</b>). Applicable validation rules are evaluated, e.g., sequentially, including those requiring the concurrent processing of data values extracted from different pages, and any dependent fields are marked as having an error if a rule fails (<b>1204</b>). If during validation by a human operator (see, e.g., <figref idref="DRAWINGS">FIG. <b>10</b></figref>) a data value as extracted is corrected, e.g., the human operator enters a corrected value in a form field, validation rules affected by the change are re-evaluated, for example to ensure a correction that satisfied a first rule did not introduce an inconsistency that caused a second rule to not be satisfied. If the value for a field is visually confirmed with the page image to be correct, then the field can be flagged so it is henceforth no longer marked as having an error when a rule is re-evaluated (<b>1204</b>). In this way, operators can be more efficient by navigating only to unconfirmed fields.</p><p id="p-0041" num="0040">In various embodiments, human operator validation of errors involving fields that have dependency relationships with other fields, such as a &#x201c;name&#x201d; value that occurs in more than one page of a multi-page document, is facilitated by displaying the fields together, in a single screen, along with each fields corresponding document image snippet, even if the snippets come from different pages. Likewise, as an operator iterates through error fields in a table or other two dimensional data structure, corresponding snippets are displayed, even if they come from multiple, different pages. The human operator need only navigate through fields in a single data entry form, and the system transparently retrieves and displays for each field its corresponding snippet or other partial image, without regard to page boundaries.</p><p id="p-0042" num="0041">Using techniques described herein, multi-page documents can be processed more efficiently in the document capture context. Values in the same document can be reconciled and either auto-corrected or flagged for manual confirmation without switching between documents or data entry forms, copying over data values from one form to the other, etc. This facilitates use of data redundancy found in many document images. In addition, the data entry form is abstracted from its page definition. The operator does not have to worry about where a value is, enable the operator to focus on validating data on the form. If there are variations in page versions, the operator does not have to worry about it. The location logic will find the right place. In addition, the developer and operator do not have to incur the cost and complexity of copying data back and forth between page forms. Array data is shown in one table, rather than in a table per page, thereby improving the user experience. Finally, it is easier to map content management metadata objects to new document types, since all of the extracted data values for and structure of a multi-page document are capture in one form.</p><p id="p-0043" num="0042">Although the foregoing embodiments have been described in some detail for purposes of clarity of understanding, the invention is not limited to the details provided. There are many alternative ways of implementing the invention. The disclosed embodiments are illustrative and not restrictive.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of capturing document data, comprising:<claim-text>obtaining a multi-page document;</claim-text><claim-text>determining a document type based at least in part on the multi-page document;</claim-text><claim-text>creating an instance of a selected one of a plurality of type-specific data entry forms in a forms library based at least in part on the document type, wherein the instance of the data entry form is associated with the multi-page document;</claim-text><claim-text>populating the instance of the data entry form associated with the multi-page document based at least in part on the data associated with the multi-page document;</claim-text><claim-text>identifying, according to one or more validation rules, one or more fields of the instance of the data entry form for which validation of the corresponding data by a user is required based at least in part on data extracted from a plurality of pages associated with the multi-page document, wherein data extracted from a first page of the plurality of pages is dependent on data extracted from a second page of the plurality of pages; and</claim-text><claim-text>providing, to the user, the one or more fields of the instance of the data entry form for which validation of the corresponding data is required.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising extracting data from two or more different pages included in the multi-page document.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the identifying of the one or more form fields for which validation of the corresponding data by a user is required comprises validating a dependent data value according to one or more data values on which the dependent data value depends, wherein the one or more data values on which the dependent data value depends are extracted from a page of the multi-page document that is different from a page of the multi-page document from which the dependent data value is extracted.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the one or more validation rules comprises confirming the dependent data value according to a defined dependency of the dependent data value on the one or more data values on which the dependent data value depends.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the identifying the one or more form fields for which validation of the corresponding data by the user is required comprises:<claim-text>determining whether the dependent data value matches another data value included in the multi-page document.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the dependent data value and the one or more data values on which the dependent data value depends are comprised in a table or array of the multi-page document.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, further comprising extracting data from two or more different pages included in the multi-page document, wherein the extracting data form two or more different pages included in the multi-page document comprises extracting the data values from pages comprising the multi-page document, and<claim-text>wherein the data values extracted from the pages comprising the multi-page document are used to populate a single electronic data entry form.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the providing of the one or more form fields to the user comprises:<claim-text>providing a data validation interface that enables form fields comprising the data entry form to be validated.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the validation interface enables an operator to iterate through the one or more form fields requiring validation.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein as each form field is displayed, a corresponding snippet or other partial image from a page from which a current data value associated with the form field was extracted is displayed adjacent to the field.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein as the operator iterates through fields associated with different pages, the corresponding snippet or other partial image is retrieved and displayed regardless of the source page within the multi-page document without requiring the operator to perform any other action to navigate to the corresponding page.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising determining that a sequence of pages comprise the multi-page document.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein determining that a sequence of pages in a stream of document page images comprise the single multi-page document includes processing each page individually to determine a corresponding page type; and processing the stream of page types to identify a sequence associated with a multi-page document type.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the document type contains one or more scalar fields and one or more tables of array fields.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising extracting values from each page into per-page scalar and array fields by name.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein for each extracted value a corresponding location on the page from which the value was extracted is saved.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising combining data extracted from the respective pages into a form associated with the document type.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein combining data extracted from the respective pages into a form associated with the document type includes forming an array that spans multiple pages concatenating a first set of rows of values extracted from a first page with a second set of rows of values extracted from a second page to create a combined set of rows to be included in the document type.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A document capture system, comprising:<claim-text>a communication or other interface configured to receive a multi-page document; and</claim-text><claim-text>one or more processors coupled to the interface and configured to:<claim-text>obtain the multi-page document;</claim-text><claim-text>determine a document type based at least in part on the multi-page document;</claim-text><claim-text>create an instance of a selected one of a plurality of type-specific data entry forms in a forms library based at least in part on the document type, wherein the instance of the data entry form is associated with the multi-page document;</claim-text><claim-text>populate the instance of the data entry form associated with the multi-page document based at least in part on the data associated with the multi-page document;</claim-text><claim-text>identify, according to one or more validation rules, one or more fields of the instance of the data entry form for which validation of the corresponding data by a user is required, wherein identifying of the one or more form fields for which validation of the corresponding data by a user is required comprises validating a dependent data value according to one or more data values on which the dependent data value depends based at least in part on data extracted from a plurality of pages associated with the multi-page document, wherein data extracted from a first page of the plurality of pages is dependent on data extracted from a second page of the plurality of pages; and</claim-text><claim-text>provide, to the user, the one or more fields of the instance of the data entry form for which validation of the corresponding data is required.</claim-text></claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A computer program product to capture document data, the computer program product being embodied in a non-transitory computer readable storage medium and comprising computer instructions for:<claim-text>obtaining a multi-page document;</claim-text><claim-text>determining a document type based at least in part on the multi-page document;</claim-text><claim-text>creating an instance of a selected one of a plurality of type-specific data entry forms in a forms library based at least in part on the document type, wherein the instance of the data entry form is associated with the multi-page document;</claim-text><claim-text>populating the instance of the data entry form associated with the multi-page document based at least in part on the data associated with the multi-page document;</claim-text><claim-text>identifying, according to one or more validation rules, one or more fields of the instance of the data entry form for which validation of the corresponding data by a user is required based at least in part on data extracted from a plurality of pages associated with the multi-page document, wherein data extracted from a first page of the plurality of pages is dependent on data extracted from a second page of the plurality of pages; and</claim-text><claim-text>providing, to the user, the one or more fields of the instance of the data entry form for which validation of the corresponding data is required.</claim-text></claim-text></claim></claims></us-patent-application>
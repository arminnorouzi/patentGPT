<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005271A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005271</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17781089</doc-number><date>20201119</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>219-222718</doc-number><date>20191210</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>20</main-group><subgroup>52</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>20</main-group><subgroup>53</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30196</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>2201</main-group><subgroup>07</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">MEASUREMENT METHOD</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>NEC SOLUTION INNOVATORS, LTD.</orgname><address><city>Koto-ku, Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>SAITOH</last-name><first-name>Takeshi</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>NEC SOLUTION INNOVATORS, LTD.</orgname><role>03</role><address><city>Koto-ku, Tokyo</city><country>JP</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/043206</doc-number><date>20201119</date></document-id><us-371c12-date><date>20220531</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A measurement apparatus detects a person and an umbrella based on acquired image data, and measures the number of persons based on a detected result.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="224.11mm" wi="113.20mm" file="US20230005271A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="122.34mm" wi="160.53mm" file="US20230005271A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="160.95mm" wi="162.64mm" file="US20230005271A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="118.96mm" wi="122.77mm" file="US20230005271A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="215.90mm" wi="156.72mm" file="US20230005271A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="122.77mm" wi="114.22mm" file="US20230005271A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="122.77mm" wi="114.22mm" file="US20230005271A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="243.42mm" wi="115.23mm" file="US20230005271A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="143.43mm" wi="113.11mm" file="US20230005271A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="115.06mm" wi="122.51mm" file="US20230005271A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="64.77mm" wi="107.70mm" file="US20230005271A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present invention relates to a measurement method, a measurement apparatus, and a recording medium.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">Detecting a person and the like based on image data acquired by a security camera and the like is known.</p><p id="p-0004" num="0003">An example of such a technique is shown in, for example, Patent Document 1. Patent Document 1 describes a surveillance information gathering system including an image capture unit for surveillance, a person detecting unit that detects a person from an image captured by the image capture unit, and a locus analyzing unit that analyzes a person detected by the person detecting unit to obtain a movement locus.</p><p id="p-0005" num="0004">Patent Document 1: Japanese Unexamined Patent Application Publication No. JP-A 2018-093283</p><p id="p-0006" num="0005">The number of persons visiting a specific area such as a shopping mall may be measured based on image data acquired by an image capture unit such as a security camera. In such measurement, when simply detecting a person as described in Patent Document 1, it is impossible to detect a person, for example, in a case where the person's face is hidden by an umbrella, and it is impossible consequently to perform accurate measurement.</p><p id="p-0007" num="0006">As described above, there is a problem that it is difficult to measure the number of persons based on image data in the case of bad weather such as rain.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0008" num="0007">Accordingly, an object of the present invention is to provide a measurement method, a measurement apparatus and a recording medium solving the problem that it is difficult to measure the number of persons based on image data in the case of bad weather such as rain.</p><p id="p-0009" num="0008">In order to achieve the object, a measurement method as an aspect of the present invention includes: detecting a person and an umbrella based on acquired image data; and measuring a number of persons based on a detected result.</p><p id="p-0010" num="0009">Further, a measurement apparatus as another aspect of the present invention includes: a detecting unit configured to detect a person and an umbrella based on acquired image data; and a measuring unit configured to measure a number of persons based on a result detected by the detecting unit.</p><p id="p-0011" num="0010">Further, a computer program as another aspect of the present invention is a computer program including instructions for causing a measurement apparatus to realize: a detecting unit configured to detect a person and an umbrella based on acquired image data; and a measuring unit configured to measure a number of persons based on a result detected by the detecting unit.</p><p id="p-0012" num="0011">With the configurations as described above, the present invention can provide a measurement method, a measurement apparatus and a computer-readable recording medium in which a program is recorded solving the problem that it is difficult to measure the number of persons based on image data in the case of bad weather such as rain.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a view showing an example of a configuration of an entire measurement system according to a first example embodiment of the present invention;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram showing an example of a configuration of a measurement apparatus shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a view for describing an example of processing at the time of performing association;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a view for describing an example of processing at the time of performing association;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a view for describing an example of processing at the time of performing association;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a view for describing an example of processing at the time of performing association;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a view for describing an example of a measurement process;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart showing an example of an overall operation of the measurement apparatus;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart showing an example of an operation when the measurement apparatus performs association; and</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram showing an example of a configuration of a measurement apparatus according to a second example embodiment of the present invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">EXAMPLE EMBODIMENTS</heading><heading id="h-0006" level="1">First Example Embodiment</heading><p id="p-0023" num="0022">A first example embodiment of the present invention will be described with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>9</b></figref>. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a view showing an example of a configuration of an entire measurement system <b>100</b>. <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram showing an example of a configuration of a measurement apparatus <b>200</b>. <figref idref="DRAWINGS">FIGS. <b>3</b> to <b>6</b></figref> are views for describing examples of processing at the time of performing association. <figref idref="DRAWINGS">FIG. <b>7</b></figref> is a view for describing an example of a measurement process. <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart showing an example of an overall operation of the measurement apparatus <b>200</b>. <figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart showing an example of an operation when the measurement apparatus <b>200</b> performs association.</p><p id="p-0024" num="0023">In the first example embodiment of the present invention, the measurement system <b>100</b>, which measures the number of persons based on image data, will be described. As will be described later, the measurement system <b>100</b> detects a person from image data and also detects an umbrella. Moreover, the measurement system <b>100</b> associates the detected person with the umbrella. Then, the measurement system <b>100</b> measures the number of persons based on the result of associating the person with the umbrella.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an example of a configuration of the entire measurement system <b>100</b>. Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the measurement system <b>100</b> includes, for example, the measurement apparatus <b>200</b> and a security camera <b>300</b>. For example, the security camera <b>300</b> is installed in a given location such as the entrance to a shopping mall or an event venue, and acquires image data including persons entering and exiting a predetermined area of the shopping mall, the event venue, and the like. The measurement apparatus <b>200</b> measures the number of persons based on the image data acquired by the security camera <b>300</b>. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the measurement apparatus <b>200</b> and the security camera <b>300</b> are connected so as to be able to communicate with each other via a network, for example.</p><p id="p-0026" num="0025">The numbers of the measurement apparatuses <b>200</b> and the security cameras <b>300</b> included by the measurement system <b>100</b> are not limited to one. The measurement system <b>100</b> may include a plurality of measurement apparatus <b>200</b> and a plurality of security cameras <b>300</b>, for example, include a plurality of security cameras <b>300</b> installed in different locations.</p><p id="p-0027" num="0026">The measurement apparatus <b>200</b> is an information processing apparatus that measures the number of persons based on image data acquired by the security camera <b>300</b>. As will be described later, when performing the abovementioned measurement, the measurement apparatus <b>200</b> detects an umbrella together with a person, and uses the result of associating the person with the umbrella.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an example of a configuration of the measurement apparatus <b>200</b>. Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the measurement apparatus <b>200</b> includes, as major components, a screen display unit <b>210</b>, a communication I/F unit <b>220</b>, a storing unit <b>230</b>, and an arithmetic processing unit <b>240</b>, for example.</p><p id="p-0029" num="0028">The screen display unit <b>210</b> includes a screen display device such as an LCD (Liquid Crystal Display). The screen display unit <b>210</b> displays, on a screen, image data included by image information <b>231</b>, a measurement result included by number-of-persons information <b>234</b>, and so on, in accordance with an instruction from the arithmetic processing unit <b>240</b>.</p><p id="p-0030" num="0029">The communication I/F unit <b>220</b> includes a data communication circuit. For example, the communication I/F unit <b>220</b> performs data communication with the security camera <b>300</b> or an external device connected via a communication line.</p><p id="p-0031" num="0030">The storing unit <b>230</b> is a storage device including a hard disk and a memory. The storing unit <b>230</b> stores processing information and a program <b>235</b> that are necessary for various processing in the arithmetic processing unit <b>240</b>. The program <b>235</b> is loaded to and executed by the arithmetic processing unit <b>240</b> to realize various processing units. The program <b>235</b> is previously loaded from an external device or a recording medium via a data input/output function such as the communication I/F unit <b>220</b> and is stored in the storing unit <b>230</b>. Major information stored by the storing unit <b>230</b> are, for example, the image information <b>231</b>, number-of-times information <b>232</b>, association information <b>233</b>, and the number-of-persons information <b>234</b>.</p><p id="p-0032" num="0031">The arithmetic processing unit <b>240</b> has a microprocessor such as an MPU (Micro-processing unit) and a peripheral circuit thereof. By loading the program <b>235</b> from the storing unit <b>230</b> and executing the program <b>235</b>, the arithmetic processing unit <b>240</b> causes the abovementioned hardware and the program <b>235</b> to cooperate and realizes various processing units. Major processing units realized by the arithmetic processing unit <b>240</b> are, for example, an image data acquiring unit <b>241</b>, a target detecting unit <b>242</b>, a target tracking unit <b>243</b>, an association measuring unit <b>244</b>, an associating unit <b>245</b>, a number-of-persons measuring unit <b>246</b>, and an output unit <b>247</b>.</p><p id="p-0033" num="0032">The processing units and the information described above will be described below in more detail.</p><p id="p-0034" num="0033">The image data acquiring unit <b>241</b> acquires image data acquired by the security camera <b>300</b> from the security camera <b>300</b> via the communication I/F unit <b>220</b>. Then, the image data acquiring unit <b>241</b> stores the acquired image data as the image information <b>231</b> into the storing unit <b>230</b>.</p><p id="p-0035" num="0034">As a result of the above process, image data of multiple frames is stored, for example, in chronological order in the image information <b>231</b>. The image data acquiring unit <b>241</b> may be configured to, for example, make attribute information representing the date and time when the security camera <b>300</b> has acquired image data correspond to image data and store into the storing unit <b>230</b>.</p><p id="p-0036" num="0035">The target detecting unit <b>242</b> detects a predetermined detection target from image data included by the image information <b>231</b>. For example, the target detecting unit <b>242</b> detects the head of a person and an umbrella that are detection targets from the image data. In other words, the target detecting unit <b>242</b> performs a process of detecting the head of a person and an umbrella for each frame so that discrimination of the type of a detection target having been detected between a person or an umbrella is possible. Moreover, the target detecting unit <b>242</b> generates a rectangle surrounding the detected head or umbrella. For example, how the rectangle generated by the target detecting unit <b>242</b> surrounds the head or the umbrella may be freely set.</p><p id="p-0037" num="0036">The target tracking unit <b>243</b> tracks a head (person) and an umbrella detected by the target detecting unit <b>242</b> based on the result of detection by the target detecting unit <b>242</b>. The target tracking unit <b>243</b> then generates a tracking line, which is a line connecting detection targets determined to be identical in the respective frames. In this example embodiment, a method used by the target tracking unit <b>243</b> when performing tracking is not particularly limited. The target tracking unit <b>243</b> can be configured to track a person and an umbrella by using a known method used at the time of tracking a person, for example. However, the target tracking unit <b>243</b> generates a tracking line so as to prevent a single tracking line from including both a spot where an umbrella is detected and a spot where a head is detected. That is to say, the target tracking unit <b>243</b> generates the tracking line of an umbrella and the tracking line of a person separately from each other.</p><p id="p-0038" num="0037">The association measuring unit <b>244</b> measures the number of association determinations representing a possibility of an associated relation between a person and an umbrella, based on the result of detection by the target detecting unit <b>242</b>, a tracking line generated by the target tracking unit <b>243</b>, and so on. For example, the association measuring unit <b>244</b> increments by 1 the number of association determinations included by the number-of-times information <b>232</b> for a combination of a person and an umbrella determined to be associated based on a condition to be described later.</p><p id="p-0039" num="0038">Further, the association measuring unit <b>244</b> performs measurement of the number of association determinations as described above on the respective frames. Consequently, the results of measurement performed on the respective frames by the association measuring unit <b>244</b> are accumulated in the number-of-times information <b>232</b>.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIGS. <b>3</b> to <b>6</b></figref> are views for describing conditions for measuring the number of association determinations. For example, the association measuring unit <b>244</b> determines that there is a possibility of association for a combination of a person and an umbrella satisfying all the conditions shown in <figref idref="DRAWINGS">FIGS. <b>3</b> to <b>6</b></figref>.</p><p id="p-0041" num="0040">For example, referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the association measuring unit <b>244</b> checks a positional relation between the rectangles of a person (head) and an umbrella detected by the target detecting unit <b>242</b>. Then, in a case where the upper side of the rectangle of the head is below the upper side of the rectangle of the umbrella, the association measuring unit <b>244</b> determines that a first condition is satisfied. For example, in the case of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the upper side of the rectangle of a person A is below the upper side of the rectangle of an umbrella A. Therefore, the association measuring unit <b>244</b> determines that a combination of the person A and the umbrella A satisfies the first condition. On the other hand, in the case of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the upper side of the rectangle of a person B is above the upper side of the rectangle of the umbrella A. Therefore, the association measuring unit <b>244</b> determines that a combination of the person B and the umbrella A does not satisfy the first condition.</p><p id="p-0042" num="0041">Further, referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the association measuring unit <b>244</b> checks the movement angle of the tracking line of an umbrella and the movement angle of the tracking line of a person. Then, in a case where the difference between the movement angle of the tracking line of the umbrella and the movement angle of the tracking line of the person is equal to or less than a predetermined angle threshold value, the association measuring unit <b>244</b> determines that a second condition is satisfied. The tracking lines of an umbrella and a person using the umbrella generally tend to be substantially parallel. Therefore, considering the second condition makes it possible to prevent erroneous association, for example, when persons pass each other.</p><p id="p-0043" num="0042">The movement angle of the tracking line of an umbrella and the movement angle of the tracking line of a person are, for example, as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a movement angle from a detection start position where generation of the tracking line is started to the latest position. The movement angle of the tracking line of an umbrella and the movement angle of the tracking line of a person may be other than that illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. For example, the movement angle of the tracking line of an umbrella and the movement angle of the tracking line of a person do not necessarily need to be a movement angle from the detection start position.</p><p id="p-0044" num="0043">Further, referring to <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref>, the association measuring unit <b>244</b> checks an IoU (Intersection over Union) value indicating the overlap of rectangles. For example, the association measuring unit <b>244</b> calculates IoU values for all the combinations of the rectangles of umbrellas and the rectangles of heads existing in a frame.</p><p id="p-0045" num="0044">The association measuring unit <b>244</b> can calculate an IoU value based on the result of deforming the rectangle of an umbrella as shown in <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref>. For example, the association measuring unit <b>244</b> multiplies an x-value and a y-value corresponding to the rectangle of an umbrella by a given value, respectively, to shift the position of the rectangle of the umbrella indicated by a dotted line in <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref> to a position closer to a position in which the user of the umbrella is supposed to be indicated by a solid line in <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref>. That is to say, the association measuring unit <b>244</b> moves the rectangle of the umbrella downward. Then, the association measuring unit <b>244</b> calculates IoU values for all the combinations of the shifted rectangles of umbrellas and the rectangles of heads. For example, as shown above, the association measuring unit <b>244</b> can shift the rectangle of an umbrella and then calculate the IoU value. It is generally assumed that the user of an umbrella is below the actual umbrella rectangle. Therefore, by moving the position of the rectangle of the umbrella closer to the user side, it is possible to increase the overlap rate of the rectangles and increase the accuracy of association.</p><p id="p-0046" num="0045">To be specific, for example, referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the association measuring unit <b>244</b> calculates an IoU value by calculating the areas of portions where the shifted rectangle of the umbrella and the rectangle of the head overlap, which are indicated by frames filled with diagonal lines in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. Then, the association measuring unit <b>224</b> determines that a third condition is satisfied for a combination that the calculated IoU value exceeds a predetermined IoU threshold value. For example, in the case of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the IoU value of the combination of the person A and the umbrella A exceeds the IoU threshold value. Therefore, the association measuring unit <b>244</b> determines that the third condition is satisfied for the combination of the person A and the umbrella A. On the other hand, in the case of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, either the IoU value of the combination of the person B and the umbrella A or the IoU value of the combination of the person C and the umbrella A does not exceed the IoU threshold value. Therefore, the association measuring unit <b>244</b> determines that either the combination of the person B or the umbrella A and the combination of the person C and the umbrella A does not satisfy the third condition.</p><p id="p-0047" num="0046">Although one umbrella may be used by a plurality of persons such as two persons in general, it is rare that one person holds a plurality of umbrellas. Therefore, association between a person and an umbrella can be such that a &#x201c;many to one&#x201d; state is allowed, but a &#x201c;one to many&#x201d; state is not allowed. From the above, for example, the association measuring unit <b>224</b> can handle a person already associated with an umbrella as not satisfy the third condition with respect to an umbrella other than the associated umbrella even if the IoU value exceeds the threshold value.</p><p id="p-0048" num="0047">For example, as described above, the association measuring unit <b>224</b> determines whether or not there is a possibility of association based on the positional relation between a person (head) and an umbrella, the relation between the movement angle of the person and the movement angle of the umbrella, the degree of overlap between the person and the umbrella, and the like. Specifically, for example, the association measuring unit <b>244</b> determines that there is a possibility of association for a combination of a person and an umbrella that satisfies all the first condition, the second condition and the third condition described above. Then, the association measuring unit <b>244</b> increments by 1 the number of association determinations stored in the number-of-times information for the combination satisfying all the conditions.</p><p id="p-0049" num="0048">The association measuring unit <b>244</b> may be configured to determine that there is a possibility of association when any one or two of the abovementioned first, second, and third conditions are satisfied. The association measuring unit <b>244</b> may determine that there is a possibility of association based on a condition other than illustrated above.</p><p id="p-0050" num="0049">The associating unit <b>245</b> performs association on a combination of a person and an umbrella based on the number of association determinations measured by the association measuring unit <b>244</b>. Then, the associating unit <b>245</b> stores information corresponding to the result of the association as the association information <b>233</b> into the storing unit <b>230</b>.</p><p id="p-0051" num="0050">For example, the associating unit <b>245</b> determines whether or not the number of association determinations included by the number-of-times information <b>232</b> exceeds a predetermined association threshold value. Then, in a case where the number of association determinations exceeds the association threshold value, the associating unit <b>245</b> performs association on a combination of a person and an umbrella exceeding the association threshold value. For example, the associating unit <b>245</b> performs association by making information for a person (for example, identification information) and information for an umbrella (for example, identification information) that are determined to be associated correspond to each other and storing into the association information <b>233</b>.</p><p id="p-0052" num="0051">As described above, at the time of associating a person and an umbrella, for example, a &#x201c;many to one&#x201d; state is allowed, but a &#x201c;one to many&#x201d; state is not allowed. Therefore, the associating unit <b>245</b> can be configured to, in a case where there are a plurality of combinations that the number of association determinations exceeds the association threshold value for a certain person, perform association on only a combination of the largest number of association determinations, for example.</p><p id="p-0053" num="0052">The number-of-persons measuring unit <b>246</b> measures the number of persons in image data by using the result of association by the associating unit <b>245</b>. Then, the number-of-persons measuring unit <b>246</b> stores the result of measurement as the number-of-persons information <b>234</b> into the storing unit <b>230</b>.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows an example of a process when the number-of-persons measuring unit <b>246</b> measures the number of persons by using the result of association by the associating unit <b>245</b>. For example, referring to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, in a case where the target detecting unit <b>242</b> has detected a person and an umbrella and the detected person and umbrella are associated one-to-one, the number-of-persons measuring unit <b>246</b> measures the number of persons as &#x201c;one person&#x201d; based on the result of detection of the person and the umbrella. Moreover, in a case where the target detecting unit <b>242</b> has detected an umbrella and no person is associated with the detected umbrella (that is, in the case of an umbrella that is not associated by the associating unit <b>245</b>), the number-of-persons measuring unit <b>246</b> measures the number of persons as &#x201c;one person&#x201d; based on the result of detection of the umbrella. Moreover, in a case where the target detecting unit <b>242</b> has detected a person and an umbrella and a plurality of persons are associated with the detected umbrella, the number-of-persons measuring unit <b>246</b> measures the number of persons as the number of persons associated with the umbrella based on the result of detection of the persons and the umbrella. For example, in a case where two persons are associated with the detected umbrella, the number-of-persons measuring unit <b>246</b> measures the number of persons as &#x201c;two persons&#x201d;. Moreover, in a case where the target detecting unit <b>242</b> has detected a person and no umbrella is associated with the detected person (that is, in the case of a person who is not associated by the associating unit <b>245</b>), the number-of-persons measuring unit <b>246</b> measures the number of persons as &#x201c;one person&#x201d; based on the result of detection of the person.</p><p id="p-0055" num="0054">For example, as described above, in a case where a person and an umbrella that are associated with each other are detected, the number-of-persons measuring unit <b>246</b> performs measurement according to the number of persons associated with the umbrella. Moreover, in a case where an umbrella that is not associated with a person is detected, the number-of-persons measuring unit <b>246</b> measures the number of persons based on the result of detection of the umbrella. That is to say, even when a person is not detected, the number-of-persons measuring unit <b>246</b> measures the number of persons based on the result of detection of an umbrella.</p><p id="p-0056" num="0055">The number-of-persons measuring unit <b>246</b> does not necessarily need to measure the number of all persons in image data. The number-of-persons measuring unit <b>246</b> may be configured to measure only the number of some persons (that is, the number of persons satisfying a condition) in image data, for example, measure the number of persons who are in a predetermined area in image data by using the result of association by the associating unit <b>245</b>.</p><p id="p-0057" num="0056">The output unit <b>247</b> outputs image data included by the image information <b>231</b>, the number-of-persons information <b>234</b> that is the result of measurement by the number-of-persons measuring unit <b>246</b>, and the like. For example, the output unit <b>247</b> makes the screen display unit <b>210</b> display the image data, the number-of-persons information <b>234</b>, and the like, or transmits to an external device via the communication I/F unit <b>220</b>.</p><p id="p-0058" num="0057">The above is an example of the configuration of the measurement apparatus <b>200</b>.</p><p id="p-0059" num="0058">The security camera <b>300</b> is installed in a given location such as the entrance to a shopping mall. The security camera <b>300</b> acquires image data including a person entering or exiting a predetermined area. Then, the security camera <b>300</b> transmits the acquired image data to the measurement apparatus <b>200</b>.</p><p id="p-0060" num="0059">In this example embodiment, the configuration of the security camera <b>300</b> is not particularly limited. For example, the security camera <b>300</b> can have a general function such as a function of acquiring image data and also acquiring information indicating the date and time when the image data is acquired.</p><p id="p-0061" num="0060">The above is an example of the configuration of the measurement system <b>100</b>. Subsequently, an example of an operation of the measurement apparatus <b>200</b> will be described with reference to <figref idref="DRAWINGS">FIGS. <b>8</b> and <b>9</b></figref>.</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows an example of an overall operation of the measurement apparatus <b>200</b>. Referring to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the target detecting unit <b>242</b> detects the head of a person and an umbrella that are predetermined detection targets from image data included by the image information <b>231</b> (step S<b>101</b>).</p><p id="p-0063" num="0062">The target tracking unit <b>243</b> tracks the head and the umbrella detected by the target detecting unit <b>242</b> based on the result of detection by the target detecting unit <b>242</b>. Consequently, the target tracking unit <b>243</b> generates a tracking line that is a line connecting identical detection targets detected by the target detecting unit <b>242</b> in the respective frames (step S<b>102</b>).</p><p id="p-0064" num="0063">The associating unit <b>245</b> performs association on a combination of a person and an umbrella based on the number of association determinations measured by the association measuring unit <b>244</b> (step S<b>103</b>). The details of processing by the associating unit <b>245</b> will be described later.</p><p id="p-0065" num="0064">The number-of-persons measuring unit <b>246</b> measures the number of persons in the image data based on the result of detection by the target detecting unit <b>242</b> and the result of association by the associating unit <b>245</b> (step S<b>104</b>).</p><p id="p-0066" num="0065">The output unit <b>247</b> outputs the result of measurement by the number-of-persons measuring unit <b>246</b>, and so on (step S<b>105</b>).</p><p id="p-0067" num="0066">The above is an example of the overall operation of the measurement apparatus <b>200</b>. Subsequently, referring to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, an example of an operation at the time of performing association will be described.</p><p id="p-0068" num="0067">Referring to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the association measuring unit <b>244</b> measures the number of association determinations indicating a possibility that a person and an umbrella are associated based on the result of detection by the processing at step S<b>101</b>, the tracking line generated by the processing at step S<b>102</b>, and so on (step S<b>201</b>). For example, in a case where the positional relation between a person (head) and an umbrella, the relation between the movement angle of the person and the movement angle of the umbrella, and the degree of overlap of the person and the umbrella satisfy predetermined conditions, the association measuring unit <b>244</b> increments by 1 the number of association determinations included by the number-of-times information <b>232</b>.</p><p id="p-0069" num="0068">The associating unit <b>245</b> performs association on a combination of a person and an umbrella based on the number of association determinations measured by the association measuring unit <b>244</b>. For example, the associating unit <b>245</b> checks whether or not the number of association determinations included in the number-of-times information <b>232</b> exceeds a predetermined association threshold value (step S<b>202</b>). Then, in a case where the number of association determinations exceeds the association threshold value (step S<b>202</b>, Yes), the associating unit <b>245</b> performs association on the combination of the person and the umbrella that exceeds the association threshold value (step S<b>203</b>). For example, the associating unit <b>245</b> performs association by making information for the person and information for the umbrella that are determined to be associated correspond to each other and storing into the association information <b>233</b>.</p><p id="p-0070" num="0069">The above is the operation at the time of performing association.</p><p id="p-0071" num="0070">Thus, the measurement apparatus <b>200</b> in this example embodiment includes the target detecting unit <b>242</b>, the associating unit <b>245</b>, and the number-of-persons measuring unit <b>246</b>. With such a configuration, the number-of-persons measuring unit <b>246</b> can measure the number of persons based on the result that the associating unit <b>245</b> associates a person and an umbrella detected by the target detecting unit <b>242</b> with each other. Consequently, for example, even when a person cannot be detected for a reason such that the head of the person is hidden by an umbrella, the number of persons having entered or exited the area can be accurately measured. Moreover, by performing association, it is possible to prevent the occurrence of double counting, such as double measurement of a person and an umbrella. As a result, even in the case of bad weather such as rain, it is possible to accurately measure the number of persons based on the image data.</p><p id="p-0072" num="0071">Further, in this example embodiment, the association measuring unit <b>244</b> is configured to measure the number of association determinations based on the positional relation between a person (head) and an umbrella, the relation between the movement angle of a person and the movement angle of an umbrella, the degree of overlap of a person and an umbrella, or the like. Moreover, the associating unit <b>245</b> is configured to perform association based on the result of measurement by the association measuring unit <b>244</b>. By thus performing association after the association measuring unit <b>244</b> considers various conditions, it is possible to prevent erroneous association from being performed. As a result, even in the case of bad weather such as rain, the number of persons can be measured more accurately based on the image data.</p><p id="p-0073" num="0072">After the tracking line of a person or an umbrella is interrupted once for a reason such that the head is hidden by the umbrella but reappears or the umbrella is folded once and then opened again, a new tracking line may be created. In such a case, the same person may be measured multiple times.</p><p id="p-0074" num="0073">Accordingly, the target tracking unit <b>243</b> can be configured to, in a case where the positional relation between a person and an umbrella satisfies a predetermined condition, consider a newly appearing tracking line to be identical to a previous tracking line and integrate the tracking lines. For example, in a case where the previous tracking line and e newly tracking line satisfy a condition such that the difference between the movement angle of the tracking line of a person and the movement angle of the tracking line of an umbrella is equal to or less than a movement angle threshold value, the target tracking unit <b>243</b> can integrate the tracking lines. Moreover, the target tracking unit <b>243</b> may be configured to determine the tracking lines, for example, based on attribute information indicating an attribute (gender, age, color of hair, color of cloths, color of umbrella) determined based on the image data.</p><p id="p-0075" num="0074">Further, in this example embodiment, a case where the measurement system <b>100</b> includes the measurement apparatus <b>200</b> and the security camera <b>300</b> has been described. However, the measurement apparatus <b>200</b> and the security camera <b>300</b> may be configured integrally. That is to say, the security camera <b>300</b> may have a function as the measurement apparatus <b>200</b> described in this example embodiment. In the case of thus configuring the security camera <b>300</b>, the measurement system <b>100</b> may include only the security camera <b>300</b>.</p><p id="p-0076" num="0075">Further, in this example embodiment, a case where one information processing apparatus a function as the measurement apparatus <b>200</b> has been illustrated. However, the function as the measurement apparatus <b>200</b> may be realized by a plurality of information processing apparatus connected by a network, for example.</p><heading id="h-0007" level="1">Second Example Embodiment</heading><p id="p-0077" num="0076">Next, a second example embodiment of the present invention will be described with reference to <figref idref="DRAWINGS">FIG. <b>14</b></figref>. In the second example embodiment, the overview of a configuration of a measurement apparatus <b>40</b> will be described.</p><p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. <b>14</b></figref> shows an example of the configuration of the measurement apparatus <b>40</b>. Referring to <figref idref="DRAWINGS">FIG. <b>14</b></figref>, the measurement apparatus <b>40</b> includes, for example, a detecting unit <b>41</b> and a measuring unit <b>42</b>. For example, the measurement apparatus <b>40</b> includes an arithmetic logic unit such as a CPU and a storage unit. For example, the measurement apparatus <b>40</b> realizes the abovementioned given processing units by the arithmetic logic unit executing a program stored in the storage device.</p><p id="p-0079" num="0078">The detecting unit <b>41</b> detects a person and an umbrella based on image data acquired from an external device such as an external camera, for example.</p><p id="p-0080" num="0079">The measuring unit <b>42</b> measures the number of persons based on the result of detection by the detecting unit <b>41</b>.</p><p id="p-0081" num="0080">Thus, the measurement apparatus <b>40</b> includes the detecting unit <b>41</b> and the measuring unit <b>42</b>. With such a configuration, the measuring unit <b>42</b> can measure the number of persons based on a person and an umbrella detected by the detecting unit <b>41</b>. Consequently, for example, even when a person cannot be detected for a reason such that the persons is hidden by an umbrella, it is possible to accurately measure the number of persons having entered or exited the area. As a result, even in the case of bad weather such as rain, it is possible to accurately measure the number of persons based on the image data.</p><p id="p-0082" num="0081">Further, the measurement apparatus <b>40</b> described above can be realized by installation of a given program into the measurement apparatus <b>40</b>. Specifically, a program as another aspect of the present invention is a program for causing the measurement apparatus <b>40</b> to realize the detecting unit <b>41</b> detecting a person and an umbrella based on acquired image data and the measuring unit <b>42</b> measuring the number of persons based on the result of detection by the detecting unit <b>41</b>.</p><p id="p-0083" num="0082">Further, a measurement method executed by the measurement apparatus <b>40</b> described above is a method of detecting a person and an umbrella based on acquired image data and measuring the number of persons based on the result of detection.</p><p id="p-0084" num="0083">The inventions of a program (or a recording medium) and a measurement method having the abovementioned configurations also have the same action and effect as the measurement apparatus <b>40</b>, and therefore, can also achieve the abovementioned object of the present invention.</p><heading id="h-0008" level="1">Supplementary Notes</heading><p id="p-0085" num="0084">The whole or part of the example embodiments disclosed above can be described as the following supplementary notes. Below, the outline of a measurement method and so on according to the present invention will be described. However, the present invention is not limited to the following configurations.</p><heading id="h-0009" level="1">Supplementary Note 1</heading><p id="p-0086" num="0085">A measurement method executed by a measurement apparatus, the measurement method comprising:</p><p id="p-0087" num="0086">detecting a person and an umbrella based on acquired image data; and</p><p id="p-0088" num="0087">measuring a number of persons based on a detected result.</p><heading id="h-0010" level="1">Supplementary Note 2</heading><p id="p-0089" num="0088">The measurement method according to Supplementary Note 1, comprising:</p><p id="p-0090" num="0089">associating the person and the umbrella based on the detected result; and</p><p id="p-0091" num="0090">measuring a number of persons based on a result of associating the person and the umbrella.</p><heading id="h-0011" level="1">Supplementary Note 3</heading><p id="p-0092" num="0091">The measurement method according to Supplementary Note 2, comprising</p><p id="p-0093" num="0092">associating the person and the umbrella based on a positional relation between the person and the umbrella.</p><heading id="h-0012" level="1">Supplementary Note 4</heading><p id="p-0094" num="0093">The measurement method according to Supplementary Note 2 or 3, comprising</p><p id="p-0095" num="0094">associating the person and the umbrella based on a relation between movement angles of the person and the umbrella.</p><heading id="h-0013" level="1">Supplementary Note 5</heading><p id="p-0096" num="0095">The measurement method according to any one of Supplementary Notes 2 to 4, comprising</p><p id="p-0097" num="0096">associating the person and the umbrella based on how the person and the umbrella overlap.</p><heading id="h-0014" level="1">Supplementary Note 6</heading><p id="p-0098" num="0097">The measurement method according to Supplementary Note 5, comprising</p><p id="p-0099" num="0098">associating the person and the umbrella based on how a rectangle enclosing a head of the person and a result of shifting a rectangle enclosing the umbrella by a predetermined method overlap.</p><heading id="h-0015" level="1">Supplementary Note 7</heading><p id="p-0100" num="0099">The measurement method according to any one of Supplementary Notes 1 to 6, comprising</p><p id="p-0101" num="0100">when detecting a person and an umbrella that are associated with each other, performing the measurement corresponding to a number of persons associated with the umbrella.</p><heading id="h-0016" level="1">Supplementary Note 8</heading><p id="p-0102" num="0101">The measurement method according to any one of Supplementary Notes 1 to 7, comprising</p><p id="p-0103" num="0102">when detecting an umbrella that is not associated with a person, measuring a number of persons based on a result of detecting the umbrella.</p><heading id="h-0017" level="1">Supplementary Note 9</heading><p id="p-0104" num="0103">A measurement apparatus comprising:</p><p id="p-0105" num="0104">a detecting unit configured to detect a person and an umbrella based on acquired image data; and</p><p id="p-0106" num="0105">a measuring unit configured to measure a number of persons based on a result detected by the detecting unit.</p><heading id="h-0018" level="1">Supplementary Note 10</heading><p id="p-0107" num="0106">A non-transitory computer-readable recording medium having a program recorded thereon, the program comprising instructions for causing a measurement apparatus to realize:</p><p id="p-0108" num="0107">a detecting unit configured to detect a person and an umbrella based on acquired image data; and</p><p id="p-0109" num="0108">a measuring unit configured to measure a number of persons based on a result detected by the detecting unit.</p><p id="p-0110" num="0109">The program described in the respective example embodiments and supplementary notes is stored in a storage device or recorded on a computer-readable recording medium. For example, the recording medium is a portable medium such as a flexible disk, an optical disk, a magnetooptical disk, and a semiconductor memory.</p><p id="p-0111" num="0110">Although the present invention has been described above with reference to the respective example embodiments, the present invention is not limited to the example embodiments. The configurations and details of the present invention can be changed in various manners that can be understood by one skilled in the art within the scope of the present invention.</p><p id="p-0112" num="0111">The present invention is based upon and claims the benefit of priority from Japanese patent application No. 2019-222718, filed on Dec. 10, 2019, the disclosure of which is incorporated herein in its entirety by reference.</p><heading id="h-0019" level="1">DESCRIPTION OF NUMERALS</heading><p id="p-0113" num="0112"><b>100</b> measurement system</p><p id="p-0114" num="0113"><b>200</b> measurement apparatus</p><p id="p-0115" num="0114"><b>210</b> screen display unit</p><p id="p-0116" num="0115"><b>220</b> communication I/F unit</p><p id="p-0117" num="0116"><b>230</b> storing unit</p><p id="p-0118" num="0117"><b>231</b> image information</p><p id="p-0119" num="0118"><b>232</b> number-of-times information</p><p id="p-0120" num="0119"><b>233</b> association information</p><p id="p-0121" num="0120"><b>234</b> number-of-persons information</p><p id="p-0122" num="0121"><b>235</b> program</p><p id="p-0123" num="0122"><b>240</b> arithmetic processing unit</p><p id="p-0124" num="0123"><b>241</b> image data acquiring unit</p><p id="p-0125" num="0124"><b>242</b> target detecting unit</p><p id="p-0126" num="0125"><b>243</b> target tracking unit</p><p id="p-0127" num="0126"><b>244</b> association measuring unit</p><p id="p-0128" num="0127"><b>245</b> associating unit</p><p id="p-0129" num="0128"><b>246</b> number-of-persons measuring unit</p><p id="p-0130" num="0129"><b>247</b> output unit</p><p id="p-0131" num="0130"><b>300</b> security camera</p><p id="p-0132" num="0131"><b>40</b> measurement apparatus</p><p id="p-0133" num="0132"><b>41</b> detecting unit</p><p id="p-0134" num="0133"><b>42</b> measuring unit</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A measurement method executed by a measurement apparatus, the measurement method comprising:<claim-text>detecting a person and an umbrella based on acquired image data; and</claim-text><claim-text>measuring a number of persons based on a detected result.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The measurement method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising:<claim-text>associating the person and the umbrella based on the detected result; and</claim-text><claim-text>measuring a number of persons based on a result of associating the person and the umbrella.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The measurement method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, comprising<claim-text>associating the person and the umbrella based on a positional relation between the person and the umbrella.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The measurement method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, comprising<claim-text>associating the person and the umbrella based on a relation between movement angles of the person and the umbrella.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The measurement method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, comprising<claim-text>associating the person and the umbrella based on how the person and the umbrella overlap.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The measurement method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, comprising<claim-text>associating the person and the umbrella based on how a rectangle enclosing a head of the person and a result of shifting a rectangle enclosing the umbrella by a predetermined method overlap.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The measurement method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising<claim-text>when detecting a person and an umbrella that are associated with each other, performing the measurement corresponding to a number of persons associated with the umbrella.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The measurement method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising<claim-text>when detecting an umbrella that is not associated with a person, measuring a number of persons based on a result of detecting the umbrella.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A measurement apparatus comprising:<claim-text>a detecting unit configured to detect a person and an umbrella based on acquired image data; and</claim-text><claim-text>a measuring unit configured to measure a number of persons based on a result detected by the detecting unit.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A non-transitory computer-readable recording medium having a program recorded thereon, the program comprising instructions for causing a measurement apparatus to realize:<claim-text>a detecting unit configured to detect a person and an umbrella based on acquired image data; and</claim-text><claim-text>a measuring unit configured to measure a number of persons based on a result detected by the detecting unit.</claim-text></claim-text></claim></claims></us-patent-application>
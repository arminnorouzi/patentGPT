<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004366A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004366</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17901128</doc-number><date>20220901</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>8</main-group><subgroup>41</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>8</main-group><subgroup>34</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>8</main-group><subgroup>36</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>8</main-group><subgroup>71</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>8</main-group><subgroup>447</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>8</main-group><subgroup>34</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>8</main-group><subgroup>36</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>8</main-group><subgroup>71</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>2425</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">ADAPTING EXISTING SOURCE CODE SNIPPETS TO NEW CONTEXTS</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17159524</doc-number><date>20210127</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11461081</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17901128</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>X Development LLC</orgname><address><city>Mountain View</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Zhang</last-name><first-name>Qianyu</first-name><address><city>Sunnyvale</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Ni</last-name><first-name>Bin</first-name><address><city>Fremont</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Singh</last-name><first-name>Rishabh</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Hatalsky</last-name><first-name>Olivia</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Implementations are described herein for adapting existing source code snippets to new contexts. In various implementations, a command may be detected to incorporate an existing source code snippet into destination source code. An embedding may be generated based on the existing source code snippet, e.g., by processing the existing source code snippet using an encoder. The destination source code may be processed to identify one or more decoder constraints. Subject to the one or more decoder constraints, the embedding may be processed using a decoder to generate a new version of the existing source code snippet that is adapted to the destination source code.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="185.25mm" wi="144.53mm" file="US20230004366A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="205.40mm" wi="146.56mm" file="US20230004366A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="216.75mm" wi="146.22mm" file="US20230004366A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="221.83mm" wi="133.94mm" file="US20230004366A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="216.07mm" wi="124.21mm" orientation="landscape" file="US20230004366A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="214.38mm" wi="100.33mm" orientation="landscape" file="US20230004366A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="223.01mm" wi="144.02mm" file="US20230004366A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="191.52mm" wi="147.32mm" file="US20230004366A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="157.73mm" wi="113.45mm" orientation="landscape" file="US20230004366A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">Much of the time and effort involved with modern computer programming tends to be skewed towards adapting existing source code to new contexts, rather than writing new source code from scratch. Given the myriad different languages, frameworks, and libraries that are available, adapting source code for new contexts comprises a significant portion of software developers' time.</p><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0003" num="0002">Implementations are described herein for adapting existing source code snippets to new contexts. In various implementations, a programmer may issue a command to incorporate/import an existing source code snippet, e.g., from one library, into destination source code that forms part of a different library or code base. This command may take various forms, such as a command to paste content of a clipboard into the destination source code, a command to drag-and-drop a graphical element representing a block of source code into a portion of a graphical user interface (GUI) corresponding to the destination source code, and so forth. Rather than requiring the programmer to manually adapt aspects of the existing source code snippet, such as variable and/or function names, to the destination source code's context, techniques described herein may perform this adaptation automatically, e.g., using various types of machine learning models and/or heuristics.</p><p id="p-0004" num="0003">In some implementations, one or both of the existing source code snippet and the destination source code may be processed using an encoder portion of an encoder-decoder machine learning model (also referred to as an &#x201c;autoencoder&#x201d; or &#x201c;neural language model&#x201d;). For example, the existing source code snippet may be inserted into the desired location of the destination source code, and then tokens/symbols of the resulting combination may be iteratively processed based on the encoder. Alternatively, in some implementations, embeddings generated from the existing source code snippet and the destination source code may be combined (e.g., concatenated, averaged, etc.) and processed based on the encoder to generate a new embedding.</p><p id="p-0005" num="0004">In various implementations, one or both of the encoder and decoder portions of the encoder-decoder model may take the form of a sequence-to-sequence machine learning model such as a recurrent neural network, a long short-term memory (LSTM) network, a gated recurrent unit (GRU) network, a Bidirectional Encoder Representations from Transformers (BERT)-based transformer, etc. An embedding (also referred to as a &#x201c;feature vector,&#x201d; a &#x201c;feature embedding,&#x201d; etc.) generated based on the encoder may include contextual information from one or both of the existing source code snippet and the destination source code, such as syntactic information, semantic information, structural information, etc. In some implementations, the embedding may represent a generalized (e.g., reduced dimension) form of the existing source code snippet that can more easily be adapted into different contexts. Alternatively, other types of machine learning models may be used to encode source code into embeddings. For example, in some implementations, source code may be first converted into a graph, e.g., an abstract syntax tree (AST), and then the graph may be processed using a graph-based machine learning model such as a graph neural network (GNN) to generate the embedding.</p><p id="p-0006" num="0005">However the embedding is generated, it may be applied as input across the decoder portion to generate output that includes the existing source code snippet, adapted to the context of the destination source code. In some such implementations, application of the decoder may be subject to decoder constraints. For example, the destination source code may be processed using various feature extraction techniques (machine learning or heuristic based) to identify decoder constraints that should be applied. These decoder constraints may take various forms, such as a dictionary of variable names and/or function names contained in the destination source code. In various implementations, the decoder may be biased towards and/or limited to the variable/function names in this dictionary. Thus, for instance, an embedding generated by the encoder portion, which may represent a more generalized form of the existing source code snippet, may be processed using a decoder that is biased towards variable/function names in the dictionary. The resulting output may comprise a new version of the existing source code snippet adapted to the destination source code.</p><p id="p-0007" num="0006">In some implementations, the decoder constraints may capture elements about source code beyond variable and function names, such as programming or coding style. For example, source code written by a highly-respected and/or prolific programmer may be used to train a machine learning model such as a neural language model. Later, that programmer's style may be &#x201c;detected&#x201d; in destination source code, e.g., as a context into which an existing source code snippet is to be incorporated. In the context of the present disclosure, the programmer's tendencies may be captured as stylistic and/or formatting constraints that may be employed as decoder constraints as described herein.</p><p id="p-0008" num="0007">Programming/coding styles may come in numerous forms, just as different programmers may tend to write source code in numerous ways. Some non-limiting examples of the types of elements that might contribute to programming/coding style are selection, placement, and/or formatting of symbols/tokens such as spaces, tabs, parenthesis, comments, and so forth. Suppose a company has a code base written by one or more particular programmers in a particular programming style. Suppose the company hires a new programmer who may or may not necessarily be familiar with that programming style. When the new hire attempts to copy existing source code from some other code base (e.g., publicly available) into the company's code base, the company's programming style/context may be captured via application of the machine learning model such that the to-be-copied existing source code is adapted to the same programming style when pasted.</p><p id="p-0009" num="0008">In some implementations, techniques described herein may be used to semantically &#x201c;wire&#x201d; source code snippets together. For example, the new version of the existing source code snippet that is adapted to the destination source code's context may include &#x201c;glue code&#x201d; that logically/semantically/syntactically couples the existing source code snippet with the destination source code. For example, if the existing source code snippet includes a function call, then glue code may be generated to adapt the function call to the destination source code. To this end, in various implementations, one or both of the encoder and decoder portions of the encoder-decoder machine learning model may be trained based on training data that includes glue code coupling the same or similar functions to other source code in different contexts.</p><p id="p-0010" num="0009">In some implementations, a method implemented using one or more processors may include: detecting a command to incorporate an existing source code snippet into destination source code; generating an embedding based on the existing source code snippet, wherein the generating includes processing the existing source code snippet using an encoder; processing the destination source code to identify one or more decoder constraints; subject to the one or more decoder constraints, processing the embedding using a decoder to generate a new version of the existing source code snippet that is adapted to the destination source code.</p><p id="p-0011" num="0010">In various implementations, the one or more decoder constraints may include a dictionary of variable names or function names extracted from the destination source code, and processing the embedding using the decoder may include biasing the decoder towards the variable names or function names in the dictionary. In various implementations, the one or more decoder constraints may include programming stylistic and formatting constraints, and processing the embedding using the decoder may include biasing the decoder towards the programming stylistic and formatting constraints.</p><p id="p-0012" num="0011">In various implementations, the existing source code snippet may include a function call, and processing the embedding using the decoder may include generating glue code to adapt the function call to the destination source code. In various implementations, the command may include a paste command. In various implementations, the command may include a command to drag-and-drop a graphical element that includes the existing source code snippet into the destination source code. In various implementations, the generating may include processing at least a portion of the destination source code using the encoder.</p><p id="p-0013" num="0012">In addition, some implementations include one or more processors of one or more computing devices, where the one or more processors are operable to execute instructions stored in associated memory, and where the instructions are configured to cause performance of any of the aforementioned methods. Some implementations also include one or more non-transitory computer readable storage media storing computer instructions executable by one or more processors to perform any of the aforementioned methods.</p><p id="p-0014" num="0013">It should be appreciated that all combinations of the foregoing concepts and additional concepts described in greater detail herein are contemplated as being part of the subject matter disclosed herein. For example, all combinations of claimed subject matter appearing at the end of this disclosure are contemplated as being part of the subject matter disclosed herein.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>1</b></figref> schematically depicts an example environment in which selected aspects of the present disclosure may be implemented, in accordance with various implementations.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>2</b></figref> schematically demonstrates an example of how various elements described herein may process data, in accordance with various implementations.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>3</b></figref> schematically demonstrates an example of how aspects of the present disclosure associated with inference may be implemented, in accordance with various implementations.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>4</b></figref> schematically demonstrates another example of how aspects of the present disclosure associated with inference may be implemented, in accordance with various implementations.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>5</b></figref> schematically demonstrates an example of how aspects of the present disclosure associated with training may be implemented, in accordance with various implementations.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>6</b>B</figref> depict an example graphical user interface (GUI) that may be presented in accordance with various implementations described herein.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts a flowchart illustrating an example method for practicing selected aspects of the present disclosure.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example architecture of a computing device.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>1</b></figref> schematically depicts an example environment in which selected aspects of the present disclosure may be implemented, in accordance with various implementations. Any computing devices depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref> or elsewhere in the figures may include logic such as one or more microprocessors (e.g., central processing units or &#x201c;CPUs&#x201d;, graphical processing units or &#x201c;GPUs,&#x201d; etc.) that execute computer-readable instructions stored in memory, or other types of logic such as application-specific integrated circuits (&#x201c;ASIC&#x201d;) (including &#x201c;tensor processing units&#x201d; or &#x201c;TPUs&#x201d;), field-programmable gate arrays (&#x201c;FPGA&#x201d;), and so forth. Some of the systems depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, such as a code knowledge system <b>102</b>, may be implemented using one or more server computing devices that form what is sometimes referred to as a &#x201c;cloud infrastructure&#x201d; or &#x201c;the cloud,&#x201d; although this is not required.</p><p id="p-0024" num="0023">A code knowledge system <b>102</b> may be provided for helping clients <b>118</b><sub>1-P </sub>manage their respective code bases <b>122</b><sub>1-P</sub>. In various implementations, code knowledge system <b>102</b> may be accessible, e.g., by clients <b>118</b><sub>1-P</sub>, via one or more networks <b>112</b>, such as the Internet or one or more local area networks.</p><p id="p-0025" num="0024">Code knowledge system <b>102</b> may include, among other things, a training module <b>104</b>, an inference module <b>106</b>, and an import module <b>108</b> that are configured to perform selected aspects of the present disclosure in order to help one or more clients <b>118</b><sub>1-P </sub>to make changes to one or more corresponding code bases <b>122</b><sub>1-P</sub>, particularly to adapt existing source code snippets to new contexts. Each client <b>118</b> may be, for example, an entity or organization such as a business (e.g., financial institute, bank, etc.), non-profit, club, university, government agency, or any other organization or individual that operates one or more software systems. For example, a bank may operate one or more software systems to manage the money under its control, including tracking deposits and withdrawals, tracking loans, tracking investments, and so forth. An airline may operate one or more software systems for booking/canceling/rebooking flight reservations, managing delays or cancelations of flight, managing people associated with flights, such as passengers, air crews, and ground crews, managing airport gates, and so forth. In some implementations, each client <b>118</b> may make changes to its code base <b>122</b> using one or more instances of an integrated development environment (IDE) <b>120</b> operating on one or more computing devices.</p><p id="p-0026" num="0025">Training module <b>104</b> and inference module <b>106</b> may have access to one or more machine learning model(s) <b>110</b>. These machine learning models <b>110</b> may take various forms, including but not limited to an encoder-decoder, various flavors of a recurrent neural network (RNN, e.g., long short-term memory, or &#x201c;LSTM&#x201d;, gate recurrent units, or &#x201c;GRU&#x201d;, etc.), a transformers (BERT)-based transformer model, a graph neural network (GNN) or other graph-based models, and any other type of machine learning model that may be applied to facilitate selected aspects of the present disclosure, particularly adapting existing source code snippets to new contexts.</p><p id="p-0027" num="0026">In various implementations, training module <b>104</b> may be configured to train machine learning model(s) <b>110</b> based on one or more corpuses of source code <b>116</b><sub>1-N</sub>. One or more corpuses of source code <b>116</b><sub>1-N </sub>may include source code files written in any number of programming languages, as well as in multiple versions of the same programming language (e.g., Python1 versus Python2 versus Python3, C versus C++, etc.). In some implementations, one or more corpuses <b>116</b><sub>1-N </sub>may also include natural language documentation on the subject of computer programming. This may include, for instance, computer programming textbooks, computer-programming HOWTO guides, inline comments contained in source code files, natural language comments stored in version control systems (VCS), e.g., during a &#x201c;commit&#x201d; of a recently-edited source code file, and so forth.</p><p id="p-0028" num="0027">In some implementations, training module <b>104</b> may train machine learning model(s) <b>110</b> based on corpuses <b>116</b><sub>1-N</sub>. For example, one or more machine learning models <b>110</b> may be sequence-to-sequence language models that are subjected to unsupervised training based on corpuses <b>116</b><sub>1-N</sub>. Once machine learning model(s) <b>110</b> are trained, they may be used by inference module <b>106</b>, e.g., at the behest of programmer associated with a client <b>118</b>, to adapt existing source code snippets extracted (e.g., copied, cut, dragged) from one context (e.g., one source code file) to another context (e.g., destination source code).</p><p id="p-0029" num="0028">This adapted source code snippet and/or the new combined source code that includes it may then be provided back to IDE <b>120</b> of client <b>118</b>, e.g., by import module <b>108</b> or inference module <b>106</b>. If the programmer was in the act of copying a source code snippet from one source code file for use in another, destination source code file, this may have the effect of the adapted source code snippet being &#x201c;pasted&#x201d; into the destination source code file. However, techniques described herein are not limited to inter-file transfers. In some implementations, techniques described herein may be used to copy/cut a source code snippet from one portion of a source code file and to paste it (in adapted form) into another portion of the same source code file.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>2</b></figref> schematically illustrates one example of how data may be processed by and flow between various components of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a programmer (not depicted) operates IDE <b>120</b> to import an existing source code snippet <b>224</b> into destination source code <b>226</b>. These commands are detected by import module <b>108</b>. Import module <b>108</b> obtains, e.g., from IDE <b>120</b> (e.g., via a plugin of IDE), data indicative of existing source code snippet <b>224</b> and destination source code <b>226</b>. This data may include, for instance, existing source code snippet <b>224</b> and destination source code <b>226</b> in raw form, embeddings generated therefrom, generalized templates generated therefrom, etc.</p><p id="p-0031" num="0030">Import module <b>108</b> may provide data indicative of some combination of <b>224</b>/<b>226</b> to inference module <b>106</b>. In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a call-out box is shown at right to demonstrate how constituent components of inference module <b>106</b> may process data <b>224</b>/<b>226</b> in some implementations. Assuming machine learning model <b>110</b> is an encoder-decoder model, an encoder portion <b>228</b> of machine learning model <b>110</b> may be used by inference module <b>106</b> to process data <b>224</b>/<b>226</b> to generate an embedding <b>230</b>. Embedding <b>230</b> may then be processed by inference module <b>106</b> based on a decoder portion <b>232</b>. Output generated based on decoder portion <b>232</b> may include adapted source code snippet <b>236</b>. In some implementations, adapted source code snippet <b>236</b> may be part of a larger combined source code that also includes the surrounding destination source code. In some such implementations, aspects of the surrounding destination source code <b>226</b> may also be adapted to receive adapted source code snippet <b>236</b>.</p><p id="p-0032" num="0031">Inference module <b>106</b> may process these data <b>224</b>/<b>226</b> in various ways. <figref idref="DRAWINGS">FIG. <b>3</b></figref> demonstrates one such example. For purposes of the following explanations, let existing source code snippet <b>224</b> be S and destination source code <b>226</b> be P. In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, existing source code snippet <b>224</b> (S) and destination source code (P) are first processed, e.g., by import module <b>108</b> or another component such as a compiler (not depicted), to generate respective abstract syntax trees (AST) <b>338</b>, <b>340</b>. Inference module <b>106</b> may then apply ASTs <b>338</b>, <b>340</b> as inputs across encoder portion <b>228</b> to generate respective vector representations, <b>230</b>A (S&#x2032;) and <b>230</b>B (P&#x2032;). These vector representations S&#x2032; and P&#x2032; may be concatenated or otherwise combined into a single embedding <b>230</b>. Combined embedding <b>230</b> may then be applied, e.g., by inference module <b>106</b>, across decoder portion <b>232</b> of machine learning model <b>110</b> to generate adapted source code snippet <b>236</b> (and in many cases, surrounding destination source code that may or may not also be adapted somewhat to receive adapted source code snippet <b>236</b>).</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts another way that inference module <b>106</b> may process data <b>224</b>/<b>226</b>. In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, machine learning model <b>110</b> is labeled &#x201c;E-D MODEL&#x201d; to indicate that in this example, machine learning model <b>110</b> once again takes the form of an encoder-decoder model. Machine learning model <b>110</b> is shown in a partially &#x201c;unfolded&#x201d; state to demonstrate one non-limiting example of how it can be operated for q (q being an integer) iterations. In this example, machine learning model <b>110</b> most resembles a recurrent neural network, but this is not meant to be limiting. As noted above, machine learning model <b>110</b> and/or its constituent components (e.g., encoder portion <b>228</b>, decoder portion <b>232</b>) may take various forms, such as an LSTM network, a GRU network, a transformer network, etc. In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, an input x<sub>i </sub>is applied across machine learning model <b>110</b> at each iteration i, along with a hidden state h<sub>i-1 </sub>from a previous iteration (acting as &#x201c;memory&#x201d;), to generate output y<sub>i</sub>.</p><p id="p-0034" num="0033">In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, an updated combined source code Q may be formed by pasting S in raw form into the desired location of P in raw form, such that Q=S+P. Q may then be processed to generate, e.g., as part of a new version of destination source code Q&#x2032;, adapted source code snippet <b>236</b>. In particular, inference module <b>106</b> (not depicted) first processes a token <b>430</b><sub>1 </sub>of destination source code <b>226</b> that precedes a target paste location for existing source code snippet <b>224</b>. This may at least partially &#x201c;condition&#x201d; or &#x201c;prime&#x201d; machine learning model <b>110</b> to the context of destination source code <b>226</b>. Next, inference module <b>106</b> may process tokens <b>430</b><sub>2 </sub>. . . <b>434</b><sub>q-1 </sub>of existing source code snippet <b>224</b> itself. Lastly, inference module <b>106</b> may process tokens <b>430</b><sub>q </sub>and onwards of destination source code <b>226</b> that is intended to follow the pasted (and adapted) source code snippet.</p><p id="p-0035" num="0034">As an alternative to the example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, in some implementations, the entirety of destination source code <b>226</b> (e.g., P from the previous example) may be applied by inference module <b>106</b> across machine learning model <b>110</b> first, to condition/prime machine learning model <b>110</b> to accurately adapt existing source code snippet <b>224</b> to its new context. Then, the entirety of existing source code snippet <b>224</b> (e.g., S from the previous example) may be applied by inference module <b>106</b> across the machine learning model to generate adapted source code snippet <b>236</b>.</p><p id="p-0036" num="0035">Referring back to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in some implementations, application of decoder portion <b>232</b> of machine learning model <b>110</b> by inference module <b>106</b> may be subject to one or more decoder constraints <b>234</b>. Decoder constraints <b>234</b> may be identified or otherwise ascertained, e.g., by import module <b>108</b> and/or inference module <b>106</b>, by processing destination source code <b>226</b>. For example, names of variables and functions in destination source code <b>226</b> may be extracted and used to form a dictionary. During application, decoder portion <b>232</b> may be biased towards terms in this dictionary, or to those dictionary terms and semantically similar terms (e.g., &#x201c;last name&#x201d; has a semantically similar meaning to &#x201c;surname&#x201d;). In some implementations, decoder constraints <b>234</b> may be formed as a number of word embeddings, or generalized forms of words, which may allow for additional flexibility when biasing decoder portion <b>232</b>.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts one example of how machine learning model <b>110</b> may be trained, e.g., by training module <b>104</b>. Many of the aspects of <figref idref="DRAWINGS">FIG. <b>5</b></figref> are similar to those of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, and therefore are labeled similarly. For example, machine learning model <b>110</b> once again takes the form of an encoder-decoder model depicted in an unfolded form. In this example, a sequence of tokens <b>530</b><sub>1-q </sub>of training source code are iteratively applied as input across machine learning model <b>110</b>, similar to <figref idref="DRAWINGS">FIG. <b>4</b></figref>. However, in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, noise is injected into the training source code so that machine learning model <b>110</b> can &#x201c;learn&#x201d; how to reassemble the original source code from noisy code. In particular, in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, some tokens such as <b>530</b><sub>1 </sub>and <b>530</b><sub>q </sub>are left unaltered. Other tokens corresponding to variable names or filenames, such as <b>530</b><sub>2 </sub>and <b>530</b><sub>q-1</sub>, are transformed. These unaltered and transformed tokens <b>530</b><sub>1-q </sub>may be encoded into embeddings and then decoded to generate output. The output may be compared to the original, unaltered training source code to determine error(s). These error(s) may be used to train machine learning model <b>110</b>, e.g., using techniques such as gradient descent and back propagation.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIGS. <b>6</b>A and <b>6</b>B</figref> depict an example graphical user interface (GUI) for a source code editor application (e.g., part of IDE <b>120</b> or standalone) that may be operated by a programmer (not depicted) to edit source code. In this example, the programmer has pasted the existing source code snippet &#x201c;resetPassword(employeeID)&#x201d; into destination source code that defines a function, fakeReachoutFunction. The pasted source code snippet is indicated in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref> by the bolded, italicized text.</p><p id="p-0039" num="0038">In <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, the existing source code snippet, unaltered, may not be proper syntactically and/or semantically in the context of fakeReachoutFunction. For example, prior to the pasting of the existing source code snippet, fakeReachoutFunction (when compiled and executed) would cycle through some number (employee_count) of employees, sending each a text message (via a hypothetical &#x201c;sendText&#x201d; function) that reminds the employee of a picnic that evening. At each iteration, the employee is identified by the long variable i (e.g., the employees may have consecutive employee identifiers starting at the first employee). However, the resetPassword function as pasted receives a variable called employeeID, which has not been defined in the context of fakeReachoutFunction. Moreover, it may also be the case that the resetPassword function is not available natively in fakeReachoutFunction, e.g., because a library to which the resetPassword function belongs has not been linked.</p><p id="p-0040" num="0039">Accordingly, in <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, the pasted source code snippet &#x201c;resetPassword(employeeID)&#x201d; has been adapted/transformed into the context of fakeReachoutFunction. For example, the argument employeeID has been replaced with the variable i that is already defined and used in fakeReachoutFunction. Additionally, the function name resetPassword has been transformed into a different, yet semantically similar, function called updateCredentials. It may be the case that, for the code base being edited, the updateCredentials function is linked and/or its use is mandated (e.g., by an entity in charge of the code base).</p><p id="p-0041" num="0040">Notably, resetPassword and updateCredentials are semantically similar to each other. In some implementations, machine learning model <b>110</b> may be trained to map semantically similar tokens to each other, e.g., based on distances between their embeddings in an embedding space. Additionally or alternatively, decoder constraints <b>234</b> may be defined to include embeddings generated from terms in source code. When decoder portion <b>232</b> is applied, it may be biased towards these embeddings and other nearby (and hence, semantically similar) embeddings.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart illustrating an example method <b>700</b> of practicing selected aspects of the present disclosure, in accordance with implementations disclosed herein. For convenience, the operations of the flow chart are described with reference to a system that performs the operations. This system may include various components of various computer systems, such as one or more components of code knowledge system <b>102</b>. Moreover, while operations of method <b>700</b> are shown in a particular order, this is not meant to be limiting. One or more operations may be reordered, omitted or added.</p><p id="p-0043" num="0042">At block <b>702</b>, the system may detect a command to incorporate an existing source code snippet into destination source code. For example, a programmer operating IDE <b>120</b> may copy/cut source code from one source code file and paste it into another, destination source code file. Alternatively, in some implementations, IDE <b>120</b> may present, e.g., as part of a GUI, graphical elements that represent source code snippets in raw form or in generalized/template form. These graphical elements may be dragged into destination source code files, e.g., in textual form and/or in a flowchart form that is common in visual IDEs. In yet other implementations, existing source code snippets may be imported into locations of destination source code in other ways, such as through an &#x201c;import&#x201d; menu.</p><p id="p-0044" num="0043">At block <b>704</b>, the system may generate an embedding (e.g., <b>230</b>) based on the existing source code snippet. In some implementations, and as indicated at block <b>706</b>, the generating of block <b>704</b> may include processing the existing source code snippet using an encoder (e.g., encoder portion <b>228</b>). These encoders may take various forms, such as sequence-to-sequence encoders (e.g., RNNs, LSTM, GRU, transformers), GNNs, and so forth.</p><p id="p-0045" num="0044">At block <b>708</b>, the system may process the destination source code to identify one or more decoder constraints. For example, the system may extract variable names, function names, and any other token name that may be custom or proprietary to the destination source code, and/or define a context of the destination source code. In some implementations, the destination source code may be converted to a data structure such as an AST to perform these extractions. These extracted names may be added to a dictionary, which may include the names themselves, grammatical variations of the names, and/or embeddings generated from the names.</p><p id="p-0046" num="0045">Subject to the one or more decoder constraints identified at block <b>708</b>, at block <b>710</b>, the system may process the embedding using a decoder (e.g., decoder portion <b>232</b>) to generate a new version of the existing source code snippet that is adapted to the destination source code. For example, at block <b>712</b>, the system may bias the decoder towards the dictionary generated from the destination source code at block <b>708</b>. For example, if at each iteration of its application, the machine learning model <b>110</b> provides probabilities for some number of candidate tokens to be output, then probabilities associated with those tokens that are in the dictionary or semantically similar to terms in the dictionary may have their probabilities increased relative to other tokens not in the dictionary.</p><p id="p-0047" num="0046">Depending on the nature of the existing source code snippet and the context of the destination source code, in some implementations, at block <b>714</b>, the system may generate glue code to adapt a to-be-imported function call contained in the existing source code snippet to the destination source code. For example, for neighboring (or at least logically proximate) application programming interface (API) calls, a programmer may provide output of a first API call to a next API call. In many cases the output of the first API call may need to be transformed or otherwise processed before being used as input for the second API call. Accordingly, machine learning model <b>110</b> may be trained, e.g., by training module <b>104</b>, to automatically &#x201c;wire&#x201d; output from one API call to input of another API call. In particular, machine learning model <b>110</b> may be trained on glue code that has been used previously to couple the same or similar API calls. If output of one function is always a second input of another function B, that can be learned.</p><p id="p-0048" num="0047">Referring back to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the new version of the existing source code snippet that is adapted to the destination source code may be presented, e.g., in IDE <b>120</b>, in various ways. In some implementations, when the existing source code is pasted or otherwise imported into destination source code, annotations (e.g., coloring, pop-up window, etc.) may be rendered showing how the source code snippet might be adapted to the destination source code. The programmer may be able to accept the changes, reject the changes, or modify the changes. In other implementations, the original source code snippet may be pasted and remain temporarily (e.g., for five seconds) before being transformed into the new version of the source code snippet that is adapted to the destination source code. In other implementations, the adaptation/transformation may occur immediately upon import, in which case the user may never see the original source code snippet pasted into the destination source code.</p><p id="p-0049" num="0048">In some implementations, the origin of the original source code snippet (e.g., a URL or other identifier of a code base, library, or API) may be captured, e.g., as part of a cut/copy command. This may allow attribution of the origin to be added to the destination source code, e.g., as a comment, commit comment, etc. Doing so may provide more flexibility to the programmer to visualize changes made to the original source code snippet during adaptation (which they can accept, reject, or modify, for instance). These attributions would also provide convenient documentation for future programmers. In some implementations, such attributions may contain additional information, such as commit comments about the original source code snippet, a developer identifier of the original source code snippet, standards to which the original source code snippet is compatible/incompatible, etc.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram of an example computing device <b>810</b> that may optionally be utilized to perform one or more aspects of techniques described herein. Computing device <b>810</b> typically includes at least one processor <b>814</b> which communicates with a number of peripheral devices via bus subsystem <b>812</b>. These peripheral devices may include a storage subsystem <b>824</b>, including, for example, a memory subsystem <b>825</b> and a file storage subsystem <b>826</b>, user interface output devices <b>820</b>, user interface input devices <b>822</b>, and a network interface subsystem <b>816</b>. The input and output devices allow user interaction with computing device <b>810</b>. Network interface subsystem <b>816</b> provides an interface to outside networks and is coupled to corresponding interface devices in other computing devices.</p><p id="p-0051" num="0050">User interface input devices <b>822</b> may include a keyboard, pointing devices such as a mouse, trackball, touchpad, or graphics tablet, a scanner, a touch screen incorporated into the display, audio input devices such as voice recognition systems, microphones, and/or other types of input devices. In general, use of the term &#x201c;input device&#x201d; is intended to include all possible types of devices and ways to input information into computing device <b>810</b> or onto a communication network.</p><p id="p-0052" num="0051">User interface output devices <b>820</b> may include a display subsystem, a printer, a fax machine, or non-visual displays such as audio output devices. The display subsystem may include a cathode ray tube (CRT), a flat-panel device such as a liquid crystal display (LCD), a projection device, or some other mechanism for creating a visible image. The display subsystem may also provide non-visual display such as via audio output devices. In general, use of the term &#x201c;output device&#x201d; is intended to include all possible types of devices and ways to output information from computing device <b>810</b> to the user or to another machine or computing device.</p><p id="p-0053" num="0052">Storage subsystem <b>824</b> stores programming and data constructs that provide the functionality of some or all of the modules described herein. For example, the storage subsystem <b>824</b> may include the logic to perform selected aspects of the method of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, as well as to implement various components depicted in <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>2</b></figref>.</p><p id="p-0054" num="0053">These software modules are generally executed by processor <b>814</b> alone or in combination with other processors. Memory <b>825</b> used in the storage subsystem <b>824</b> can include a number of memories including a main random access memory (RAM) <b>830</b> for storage of instructions and data during program execution and a read only memory (ROM) <b>832</b> in which fixed instructions are stored. A file storage subsystem <b>826</b> can provide persistent storage for program and data files, and may include a hard disk drive, a floppy disk drive along with associated removable media, a CD-ROM drive, an optical drive, or removable media cartridges. The modules implementing the functionality of certain implementations may be stored by file storage subsystem <b>826</b> in the storage subsystem <b>824</b>, or in other machines accessible by the processor(s) <b>814</b>.</p><p id="p-0055" num="0054">Bus subsystem <b>812</b> provides a mechanism for letting the various components and subsystems of computing device <b>810</b> communicate with each other as intended. Although bus subsystem <b>812</b> is shown schematically as a single bus, alternative implementations of the bus subsystem may use multiple busses.</p><p id="p-0056" num="0055">Computing device <b>810</b> can be of varying types including a workstation, server, computing cluster, blade server, server farm, or any other data processing system or computing device. Due to the ever-changing nature of computers and networks, the description of computing device <b>810</b> depicted in <figref idref="DRAWINGS">FIG. <b>8</b></figref> is intended only as a specific example for purposes of illustrating some implementations. Many other configurations of computing device <b>810</b> are possible having more or fewer components than the computing device depicted in <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0057" num="0056">Examples described herein have been related to adapting existing source code snippets to different contexts, but this is not meant to be limiting. In some implementations, techniques described herein may be usable to adapt snippets of other types of structured documents into new contexts. As one example, it is very common for lawyers to adapt legal language from one document (e.g., a contract) to another. Machine learning models such as neural language models that are trained on legal documents, rather than source code bases, may be used to adapt existing snippets of legal documents into destination legal documents having different contexts. For example, a contract clause used in a contract intended to be enforceable in a first state may be copied and pasted into another contract intended to be enforceable in a second state. If the neural language model is trained on contracts (and other sources, such as statutes, regulations, caselaw, etc.) from both states, it may be usable to automatically adapt the contract clause to the seconds state's laws and/or contractual norms. As another example, a contract clause could be copied from a first contract that involves a first set of parties to a second contract that involves a second set of parties. The clause may be adapted automatically to replace the first set of parties with the second set of parties. Other possibilities are contemplated.</p><p id="p-0058" num="0057">While several implementations have been described and illustrated herein, a variety of other means and/or structures for performing the function and/or obtaining the results and/or one or more of the advantages described herein may be utilized, and each of such variations and/or modifications is deemed to be within the scope of the implementations described herein. More generally, all parameters, dimensions, materials, and configurations described herein are meant to be exemplary and that the actual parameters, dimensions, materials, and/or configurations will depend upon the specific application or applications for which the teachings is/are used. Those skilled in the art will recognize, or be able to ascertain using no more than routine experimentation, many equivalents to the specific implementations described herein. It is, therefore, to be understood that the foregoing implementations are presented by way of example only and that, within the scope of the appended claims and equivalents thereto, implementations may be practiced otherwise than as specifically described and claimed. Implementations of the present disclosure are directed to each individual feature, system, article, material, kit, and/or method described herein. In addition, any combination of two or more such features, systems, articles, materials, kits, and/or methods, if such features, systems, articles, materials, kits, and/or methods are not mutually inconsistent, is included within the scope of the present disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method implemented using one or more processors, comprising:<claim-text>detecting a command to incorporate an existing source code snippet into destination source code;</claim-text><claim-text>generating an embedding based on the existing source code snippet, wherein the generating includes processing the existing source code snippet using an encoder;</claim-text><claim-text>processing the destination source code to identify one or more decoder constraints, wherein the one or more decoder constraints comprise a dictionary of variable names or function names extracted from the destination source code;</claim-text><claim-text>subject to the one or more decoder constraints, processing the embedding using a decoder to generate a new version of the existing source code snippet that is adapted to the destination source code, wherein processing the embedding using the decoder includes biasing the decoder towards the variable names or function names in the dictionary.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the existing source code snippet includes a function call, and processing the embedding using the decoder includes generating glue code to adapt the function call to the destination source code.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the command comprises a paste command.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the command comprises a command to drag-and-drop a graphical element that includes the existing source code snippet into the destination source code.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the generating includes processing at least a portion of the destination source code using the encoder.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. A method implemented using one or more processors, comprising:<claim-text>detecting a command to incorporate an existing source code snippet into destination source code;</claim-text><claim-text>generating a first embedding based on the existing source code snippet, wherein the generating includes processing data indicative of the existing source code snippet using one or more encoders;</claim-text><claim-text>generating a second embedding based on the destination source code snippet, wherein the generating includes processing data indicative of the destination source code snippet using one or more of the encoders;</claim-text><claim-text>combining the first and second embeddings into a combined embedding; and</claim-text><claim-text>processing the combined embedding using a decoder to generate a new version of the existing source code snippet that is adapted to the destination source code.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the combining comprises concatenating the first and second embeddings.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein generating the first and second embeddings include processing the existing and destination source code snippets to generate, respectively, first and second abstract syntax trees.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first and second abstract syntax trees are processed using one or more of the encoders to generate, respectively, the first and second embeddings.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the existing source code snippet includes a function call.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein processing the embedding using the decoder includes generating glue code to adapt the function call to the destination source code.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the command comprises a paste command.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the command comprises a command to drag-and-drop a graphical element that includes the existing source code snippet into the destination source code.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A system comprising one or more processors and memory storing instructions that, in response to execution by the one or more processors, cause the one or more processors to:<claim-text>detect a command to incorporate an existing source code snippet into destination source code;</claim-text><claim-text>generate a first embedding based on the existing source code snippet, wherein the generating includes processing data indicative of the existing source code snippet using one or more encoders;</claim-text><claim-text>generate a second embedding based on the destination source code snippet, wherein the instructions to generate include instructions to process data indicative of the destination source code snippet using one or more of the encoders;</claim-text><claim-text>combine the first and second embeddings into a combined embedding; and</claim-text><claim-text>process the combined embedding using a decoder to generate a new version of the existing source code snippet that is adapted to the destination source code.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions to combine include instructions to concatenate the first and second embeddings.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions to generate the first and second embeddings include instructions to process the existing and destination source code snippets to generate, respectively, first and second abstract syntax trees.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the first and second abstract syntax trees are processed using one or more of the encoders to generate, respectively, the first and second embeddings.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the existing source code snippet includes a function call, and the instructions to process include instructions to process the embedding using the decoder includes generating glue code to adapt the function call to the destination source code.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the command comprises a paste command.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the command comprises a command to drag-and-drop a graphical element that includes the existing source code snippet into the destination source code.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004389A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004389</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17358231</doc-number><date>20210625</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>30</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>30036</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>30123</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">VECTOR PROCESSOR UTILIZING MASSIVELY FUSED OPERATIONS</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Intel Corporation</orgname><address><city>Santa Clara</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Williams</last-name><first-name>Joseph</first-name><address><city>Holmdel</city><state>NJ</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Zivkovic</last-name><first-name>Zoran</first-name><address><city>Hertogenbosch</city><country>NL</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Chen</last-name><first-name>Jian-Guo</first-name><address><city>Basking Ridge</city><state>NJ</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Wan</last-name><first-name>Hong</first-name><address><city>Allentown</city><state>PA</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Dougherty</last-name><first-name>David</first-name><address><city>Allentown</city><state>PA</state><country>US</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>O'neill</last-name><first-name>Jay</first-name><address><city>Nesquehoning</city><state>PA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><orgname>Intel Corporation</orgname><role>02</role></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Techniques are disclosed for the use of fused vector processor instructions by a vector processor architecture. Each fused vector processor instruction may include a set of fields associated with individual vector processing instructions. The vector processor architecture may implement local buffers facilitating a single vector processor instruction to be used to execute each of the individual vector processing instructions without re-accessing vector registers between each executed individual vector processing instruction. The vector processor architecture enables less communication across the interconnection network, thereby increasing interconnection network bandwidth and the speed of computations, and decreasing power usage.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="112.61mm" wi="158.75mm" file="US20230004389A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="224.20mm" wi="164.25mm" orientation="landscape" file="US20230004389A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="232.07mm" wi="165.27mm" orientation="landscape" file="US20230004389A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="232.07mm" wi="165.27mm" orientation="landscape" file="US20230004389A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="253.15mm" wi="164.34mm" orientation="landscape" file="US20230004389A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="257.64mm" wi="141.82mm" file="US20230004389A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="256.29mm" wi="141.90mm" file="US20230004389A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="256.96mm" wi="164.34mm" orientation="landscape" file="US20230004389A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="256.20mm" wi="162.64mm" orientation="landscape" file="US20230004389A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="259.08mm" wi="123.78mm" file="US20230004389A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="259.08mm" wi="121.16mm" file="US20230004389A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The disclosure described herein generally relates to vector processor architectures and, in particular, to techniques for reducing the number of vector processing instructions using a fused vector processor instruction and local buffers accessed by execution units of the vector processor architecture.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">A vector processor or array processor is a central processing unit (CPU) that implements an instruction set containing instructions that operate on one-dimensional arrays of data referred to as &#x201c;vectors.&#x201d; This is in contrast to scalar processors having instructions that operate on single data items. Vector processors can greatly improve performance on certain workloads, notably numerical simulation and similar tasks, by utilizing a number of execution units that independently execute specific functions on incoming data streams to achieve a processing flow. However, current implementation of vector processors to achieve a processing flow presents various drawbacks.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS/FIGURES</heading><p id="p-0004" num="0003">The accompanying drawings, which are incorporated herein and form a part of the specification, illustrate the present disclosure and, together with the description, further serve to explain the principles and to enable a person skilled in the pertinent art to make and use the implementations as discussed herein.</p><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example of a conventional vector processor architecture.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates another example of a conventional vector processor architecture.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a vector processor architecture, in accordance with the disclosure.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates additional details of a local buffer configuration, in accordance with the disclosure.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a vector processing loop iteration implementing multiple separate vector processing instructions, in accordance with the disclosure.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a vector processing loop iteration implementing a fused vector processing instruction, in accordance with the disclosure.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> illustrates a configuration of a local buffer showing a rotator to compensate for misalignment of read vector data samples, in accordance with the disclosure.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> illustrates aligned and unaligned vector data sample access, in accordance with the disclosure.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example device, in accordance with the disclosure.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a process flow, in accordance with the disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0015" num="0014">The present disclosure will be described with reference to the accompanying drawings. The drawing in which an element first appears is typically indicated by the leftmost digit(s) in the corresponding reference number.</p><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0016" num="0015">In the following description, numerous specific details are set forth in order to provide a thorough understanding of the present disclosure. However, it will be apparent to those skilled in the art that the implementations of the disclosure, including structures, systems, and methods, may be practiced without these specific details. The description and representation herein are the common means used by those experienced or skilled in the art to most effectively convey the substance of their work to others skilled in the art. In other instances, well-known methods, procedures, components, and circuitry have not been described in detail to avoid unnecessarily obscuring the disclosure.</p><p id="p-0017" num="0016">Vector Processing Operation</p><p id="p-0018" num="0017">Generally speaking, conventional CPUs manipulate one or two pieces of data at a time. For instance, conventional CPUs may receive an instruction that essentially says &#x201c;add A to B and put the result in C,&#x201d; with &#x2018;C&#x2019; being an address in memory. Typically the data is rarely sent in raw form, and is instead &#x201c;pointed to&#x201d; via passing an address to a memory location that holds the actual data. Decoding this address and retrieving the data from that particular memory location takes some time, during which a conventional CPU sits idle waiting for the requested data to be retrieved. As CPU speeds have increased, this memory latency has historically become a large impediment to performance.</p><p id="p-0019" num="0018">Thus, to reduce the amount of time consumed by these steps, most modern CPUs use a technique known as instruction pipelining in which the instructions sequentially pass through several sub-units. The first sub-unit reads and decodes the address, the next sub-unit &#x201c;fetches&#x201d; the values at those addresses, while the next sub-unit performs the actual mathematical operations. Vector processors, which are otherwise known as array processors, take this concept even further. For instance, instead of pipelining just the instructions, vector processors also pipeline the data itself. For example, a vector processor may be fed instructions that indicate not to merely add A to B, but to add all numbers within a specified range of address locations in memory to all of the numbers at another set of address locations in memory. Thus, instead of constantly decoding the instructions and fetching the data needed to complete each one, a vector processor may read a single instruction from memory. This initial instruction is defined in a manner such that the instruction itself indicates that the instruction will repeatedly be executed on another item of data, at an address one increment larger than the last. This allows for significant savings in decoding time.</p><p id="p-0020" num="0019">Vector processors may be implemented in accordance with various architectures, and the various vector processor architectures as discussed throughout the disclosure as further described herein may be implemented in accordance with any of these architectures or combinations of these architectures. <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref> provide two different implementations of a vector processor architecture. <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an attached vector processor, which is attached to a general purpose computer, for instance, for the purpose of enhancing and improving the performance of that computer in numerical computational tasks. The attached vector processor achieves high performance by means of parallel processing with multiple functional units, which may be alternatively referred to herein as execution units or processing units.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>2</b></figref>, on the other hand, shows an example of a single instruction stream, multiple data streams (SIMD) vector processor. The vector processor architecture <b>200</b> as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> may have an architecture consisting of one or more execution units. Each execution unit is capable of executing one instruction. Each instruction can be a control, load/store, scalar or a vector instruction. Therefore, a processor with N execution units <b>204</b>.<b>1</b>-<b>204</b>.N as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> can issue as many as N instructions every clock cycle. The execution units <b>204</b>.<b>1</b>-<b>204</b>.N function under the control of a common control unit (such as processing circuitry), thus providing a single instruction stream to control each of the execution units <b>204</b>.<b>1</b>-<b>204</b>.N. The I/O data as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is typically identified with data communicated between the vector processor <b>200</b> and another data source or processor (which may be the common control unit or another processor) depending upon the particular application. The vector data memory <b>201</b> thus stores data received as input to be processed by the execution units <b>204</b>.<b>1</b>-<b>204</b>.N, and data that is output or read from the vector data memory <b>201</b> after the data is processed. The vector processor architecture <b>200</b> as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is an example of a load-store architecture used by vector processors, which is an instruction set architecture that divides instructions into two categories: memory access (loading and storing data between the vector data memory <b>201</b> and the vector registers <b>202</b>.<b>1</b>-<b>202</b>.N) and the vector processing operations performed by the execution units <b>204</b>.<b>1</b>-<b>204</b>.N using the data retrieved from and the results stored to the vector registers <b>202</b>.<b>1</b>-<b>202</b>.N.</p><p id="p-0022" num="0021">Thus, the load-store instruction architecture facilitates data stored in the vector data memory <b>201</b> that is to be processed to be loaded into the vector registers <b>202</b>.<b>1</b>-<b>202</b>.N using load operations, transferred to the execution units <b>204</b>.<b>1</b>-<b>204</b>.N, processed, written back to the vector registers <b>202</b>.<b>1</b>-<b>202</b>.N, and then written back to the vector data memory <b>201</b> using store operations. The location (address) of the data and the type of processing operation to be performed by each execution unit <b>204</b>.<b>1</b>-<b>204</b>.N is part of an instruction stored as part of the instruction set in the program memory <b>206</b>. The movement of data between these various components may be scheduled in accordance with a decoder that accesses the instructions sets from the program memory, which is not shown in further detail in <figref idref="DRAWINGS">FIG. <b>2</b></figref> for purposes of brevity. The interconnection network, which supports the transfer of data amongst the various components of the vector processor architecture <b>200</b> as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, is generally implemented as a collection of data buses and may be shared among a set of different components, ports, etc. In this way, several execution units <b>204</b>.<b>1</b>-<b>204</b>.N may write to a single vector register <b>202</b>, and the data loaded into several vector registers <b>202</b>.<b>1</b>-<b>202</b>.N may be read by and processed by several of the execution units <b>204</b>.<b>1</b>-<b>204</b>.N.</p><p id="p-0023" num="0022">The use of instruction sets in accordance with the vector processor architecture <b>200</b> is generally known, and therefore an additional description of this operation is not provided for purposes of brevity. Regardless of the particular implementation, vector processors can greatly improve performance on certain workloads but have various drawbacks. For instance, it is very common in many signal processing applications for a specific vector data sample to be used many times in the calculation of an expression. In one scenario, for the implementation of a finite impulse response (FIR) filter, each vector data sample is multiplied by every coefficient of the filter. Thus, if a filter has 127 coefficients, then each vector data sample will be used as the input to 127 multiply-accumulate operations. This property is referred to as &#x201c;data reuse.&#x201d; In conventional vector processors, such as the vector processor architecture <b>200</b> as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, data reuse is achieved by storing the data in the vector registers <b>202</b>.<b>1</b>-<b>202</b>.N, which has several drawbacks.</p><p id="p-0024" num="0023">One drawback of this scheme is that, to enable practical compiler design, the vector registers <b>202</b>.<b>1</b>-<b>202</b>.N must be implemented with aligned access. This is illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> with respect to a scenario in which the vector registers <b>202</b>.<b>1</b>-<b>202</b>.N store 4-entry 8-word register files in an aligned manner, which are then read from the vector registers <b>202</b>.<b>1</b>-<b>202</b>.N in an aligned manner to provide as 8-element (such as 8 vector data sample) result. In this scenario as shown in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, the resister file stored in the vector registers <b>202</b>.<b>1</b>-<b>202</b>.N is implemented as a 2D array of words. For such an approach, the vector data must reside entirely within the same entry of each element in the vector register file. However, it is common in many algorithms for the data to span across 2 or more entries of a register file as shown in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> and referred to as unaligned access. Conventional vector processors, such as the vector processor architecture <b>200</b> as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, perform unaligned access by reading two vectors of data from the register files although there is only one vector of useful data, which is inefficient in terms of both cost and power. Another drawback is that convention processor architectures do not exploit the properties of streaming data applications, which is discussed in further detail herein with respect to the vector processor architecture <b>300</b> as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0025" num="0024">Moreover, signal processing for wireless systems, particularly newer standards such as the 3rd Generation Partnership Project (3GPP) Release 16 5G Phase 2 specification, the most recent at the time of this writing, require a high throughput at low power levels beyond what is possible in a conventional programmable vector/VLIW DSP architectures such as those illustrated in <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>.</p><p id="p-0026" num="0025">The disclosure as further described herein addresses these issues by implementing a local buffer as part of each execution unit in conjunction with an instruction set that combines or fuses multiple vector processor instructions into a single vector processor instruction. This reduces the computational energy required to process vector data samples, which may be in accordance with wireless communication data processing. The disclosure as further described herein fuses multiple vector processor operations in a manner that maintains flexibility across various different wireless algorithm (or other suitable algorithm) workloads. A datapath is described that enables efficient fused instructions while maintaining such flexibility.</p><p id="p-0027" num="0026">Vector Processor Architecture</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a vector processor architecture in accordance with the disclosure. The vector processor architecture as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may be configured in accordance with any suitable type of vector processor application and implementation, which may utilize any suitable type of processor, CPU, etc. This may include standard, reduced instruction set computer (RISC), such as super scalar, very long instruction word (VLIW), graphics processing units (GPUs), etc. As noted above with reference to the vector processor architecture <b>200</b> as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the vector processor architecture <b>300</b> as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may also include any suitable number N of vector registers <b>302</b>.<b>1</b>-<b>302</b>.N and execution units <b>304</b>.<b>1</b>-<b>304</b>.N. The load-store machine architecture facilitates the vector processor architecture <b>300</b> moving data between the vector data memory <b>301</b>, the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N, and the execution units <b>304</b>.<b>1</b>-<b>304</b>.N. The vector registers <b>302</b>.<b>1</b>-<b>302</b>.N may alternatively be referred to as vector register files, and may represent any suitable type of storage such as volatile or non-volatile memory, and which may have any suitable size, addressable space, and address configuration depending upon the size of the data samples that are loaded into the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N, which may be stored as data vectors in one or more vector register files, which is typically a function of the particular instruction set and/or protocol such as vector size, word size, etc.</p><p id="p-0029" num="0028">Again, the vector processor architecture <b>300</b> may be implemented as part of or work in conjunction with a specialized component such as a digital signal processor (DSP) and/or a radio transceiver that implements digital signal processing to perform various operations that may be utilized as part of wireless signal processing applications associated with wireless data communications. Thus, and with respect to the vector processing operations, these operations may be any suitable type of function that operates on the vector data samples stored in each execution unit <b>304</b>'s respective local buffer <b>308</b>.<b>1</b>-<b>308</b>.N, which is retrieved by each respective execution unit <b>304</b> from one or more of the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N in accordance with a received fused vector processor instruction. Again, such vector processing operations may include digital signal processing operations that are associated with wireless data communications.</p><p id="p-0030" num="0029">The functions may be implemented as part of the particular application in which the vector processing architecture <b>300</b> is utilized, which may be digital signal processing operations for wireless communications. These may include the application and/or calculation of finite impulse response (FIR) filter contributions to a digital data stream, equalizer functions, the calculation of digital pre-distortion (DPD) coefficients or terms, the application or calculation of Fast Fourier Transforms (FFTs) and/or digital Fourier Transforms (DFTs), matrix operations, mixer and/or frequency correction calculations, peak detection and/or cancellation calculations, signal measurements, average signal measurement calculations over time, digital signal processing of signals transmitted or received via individual antenna data streams for multiple-input-multiple-output (MIMO) antenna systems, etc. Furthermore, the vector data samples as discussed herein may be part of an in-phase (I) quadrature-phase (Q) data stream, which may be processed prior to data transmission of wireless signals or after receiving the wireless signals. Additionally or alternatively, such functions may be implemented as part of graphics processing unit (GPU) to perform graphics processing and/or rendering.</p><p id="p-0031" num="0030">The vector processor architecture <b>300</b> may also include any suitable number of execution units <b>304</b>.<b>1</b>-<b>304</b>.N, which may implement any suitable type of vector processors, vector processing circuitry, etc., illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> as the processor circuitry <b>310</b>.<b>1</b>-<b>310</b>.N, and which may be implemented to perform specific types of vector data processing operations based upon respectively received commands or instructions. These commands or instructions may originate from a decoder or other suitable processor that functions to arbitrate or otherwise schedule the processing of I/O data that is stored in the vector data memory <b>301</b> and transferred from the vector data memory to the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N using the interconnection network. The execution units <b>304</b>.<b>1</b>-<b>304</b>.N may alternatively be referred to herein as vector units, vector processing units, or functional units, or further alternatively as execution unit circuitry, vector unit circuitry, vector processing unit circuitry, functional unit circuitry, or simply as one or more processors. The execution units <b>304</b>.<b>1</b>-<b>304</b>.N may be implemented in accordance with any suitable type of vector processor architecture and include any suitable number and/or type of vector processing circuitry, as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> as the processor circuitry <b>310</b>.<b>1</b>-<b>310</b>.N, and which may include known vector processor architectures and/or types, to perform their respective vector processing operations.</p><p id="p-0032" num="0031">Each of the execution units <b>304</b>.<b>1</b>-<b>304</b>.N is configured to perform a specific type of mathematical operation via bit manipulation such as multiplication, addition, etc. Each of the execution units <b>304</b>.<b>1</b>-<b>304</b>.N includes respective processor circuitry <b>310</b>.<b>1</b>-<b>310</b>.N and is configured to execute, for each clock cycle, a set of specific types of vector processor instructions in accordance with a fused vector processor instruction. Thus, in contrast to performing a single vector processor instruction per clock cycle, the vector processor architecture <b>300</b> may receive a fused or concatenated vector processor instruction that includes any suitable number of vector processor instructions, as further discussed herein. The set of vector processor instructions that are fused into a single vector processor instruction, which is received by one or more of the execution units <b>304</b>.<b>1</b>-<b>304</b>.N per clock cycle, may be encoded as various fields, each respecting a particular vector processor operation that is to be performed.</p><p id="p-0033" num="0032">Thus, the execution units <b>304</b>.<b>1</b>-<b>304</b>.N are configured to independently execute any suitable number of vector processor instructions each clock cycle in parallel with one another, as defined by each respectively received fused vector processor instruction (which may contain any suitable number of encoded vector processing instructions for respective vector processing operations). Because these instructions may be different than one another, the use of multiple execution units <b>304</b>.<b>1</b>-<b>304</b>.N means that the vector processor architecture <b>300</b> may execute N number of instructions in parallel each clock cycle. Thus, the vector processor architecture <b>300</b> as described herein may utilize a data format of vector processor instructions such that each vector processor instruction enables flexibility for the execution units <b>304</b>.<b>1</b>-<b>304</b>.N to perform any suitable number and type of sequential vector processor operations in accordance with a wide range of algorithms and applications.</p><p id="p-0034" num="0033">The vector processor architecture <b>300</b> may form part of or the entirety of a system on a chip (SoC), which may be part of a larger overall system in which the vector processor architecture <b>300</b> is implemented. That is, the vector processor architecture <b>300</b> may be instantiated as part of a broader SoC that may include several other processors, ports, I/O, etc. In such a scenario, the I/O data coupled to the vector data memory <b>301</b> as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may represent a SoC bus, which functions to write data to the vector data memory <b>301</b> and read data from the vector data memory <b>301</b>. The communication between the vector data memory <b>301</b> and another entity using the SoC bus may be via Direct Memory access (DMA) or other suitable means. Thus, and as noted above for the vector processor architecture <b>200</b>, the interconnection network may be a shared resource, and reducing the data transferred over the interconnection network thus reduces computational latency and power usage requirements.</p><p id="p-0035" num="0034">Therefore, in contrast to the vector processor architecture <b>200</b> as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, each of the execution units <b>304</b>.<b>1</b>-<b>304</b>.N as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> includes a buffer <b>308</b>.<b>1</b>-<b>308</b>.N, which may be implemented as any suitable type of memory having suitable size, addressable space, and address configuration. Each of the execution units <b>304</b>.<b>1</b>-<b>304</b>.N also includes respective processor circuitry <b>310</b>.<b>1</b>-<b>310</b>.N, which performs the aforementioned instructions and thus constitutes the portion of the execution units <b>304</b>.<b>1</b>-<b>304</b>.N that interfaces with the streaming buffers <b>308</b>.<b>1</b>-<b>308</b>.N, performs the requested vector processing operations each clock cycle, and then writes the result back to either a respective buffer <b>308</b>.<b>1</b>-<b>308</b>.N (if more vector processing operations are to be performed locally by the execution unknit <b>304</b>) or to the one or more of the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N (once the execution unit <b>304</b> has completed the necessary vector processing operations) as discussed in further detail below. The buffers <b>308</b>.<b>1</b>-<b>308</b>.N may be implemented as memory of a size smaller than each of the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N, which may include a size just large enough to hold vector data samples until the vector data samples are fully processed. The connections between the buffers <b>308</b>.<b>1</b>-<b>308</b>.N and each respective processor circuitry <b>310</b>.<b>1</b>-<b>310</b>.N are not shown in detail in <figref idref="DRAWINGS">FIG. <b>3</b></figref> for purposes of brevity. However, because each buffer <b>308</b>.<b>1</b>-<b>308</b>.N is local with respect to each execution unit <b>304</b>.<b>1</b>-<b>304</b>.N, the data bandwidth between each buffer <b>308</b>.<b>1</b>-<b>308</b>.N and its respective processor circuitry <b>310</b>.<b>1</b>-<b>310</b>.N may be increased beyond the data bandwidth that would be available using the interconnection network, which represents an arbitrated and complex combination of shared data lanes.</p><p id="p-0036" num="0035">The vector processor architecture <b>300</b> as described herein may be implemented in accordance with any suitable type of application that utilizes vector processing operations in accordance with any suitable type of vector processor instructions, which may be encoded into a fused vector processor instruction. The fused vector processor instructions may be generated by any suitable controller, processor component, etc., such as the decoder <b>320</b> as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, and include any suitable number of fields to facilitate the execution of various vector processor operations. The fused vector processor instructions may include fields representing various types of commands, pointers to address locations in the buffers <b>308</b>.<b>1</b>-<b>308</b>.N from which the processing circuitry <b>310</b>.<b>1</b>-<b>310</b>.N is to read and write data, the particular type of mathematical function or vector processing operation that should be performed by a respective execution unit <b>304</b> to which the vector instruction is sent, etc. Additional detail regarding the specific format and content of the fused vector processor instructions is discussed further below. Each execution unit <b>304</b>.<b>1</b>-<b>304</b>.N is configured to execute any suitable number of vector processing operations per each received fused vector processor instruction, which may be sent to the execution units <b>304</b>.<b>1</b>-<b>304</b>.N by the decoder <b>320</b> each clock cycle in accordance with a common system clock.</p><p id="p-0037" num="0036">It is noted that for streaming applications the data is processed in a sequential order. Thus, a natural memory structure for streaming data is a circular buffer. The buffers <b>308</b>.<b>1</b>-<b>308</b>.N may thus be implemented as circular buffers and be configured such that data is written into the end of the circular buffer and read from the beginning of the circular buffer in terms of the buffer's addressable space. Another advantage of using such a circular buffer configuration includes the ability to utilize simplified modulo addressing to read data from and write data to the circular buffer. As it is not practical for compilers to support circular addressing for the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N, the use of the local buffers <b>308</b>.<b>1</b>-<b>308</b>.N, which may locally implement such circular addressing, is particularly advantageous and overcomes this issue. Moreover, in many streaming applications such as FIR filters, mixers, and DPD actuators used in Digital Front-Ends (DFEs), the processing may be formulated as a single instruction that is repeatedly executed in a single execution unit <b>304</b>.<b>1</b>-<b>304</b>.N. Again, transferring data to and from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N over the shared interconnection network is expensive in terms of both cost and power due to the complex architecture of interconnection networks and their typical implementation to support &#x201c;many-to-many&#x201d; communication features in accordance with vector processor architecture and design.</p><p id="p-0038" num="0037">It is also noted that the use of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N differs from the use of a cache memory in various ways. A cache memory facilitates random access of the data stored therein. This feature requires cache memory to implement complex hardware that allows a check to be performed regarding whether the cache currently contains data that needs to be retrieved. Such features also result in processor stalls while waiting for the cached data to be retrieved. The complex hardware used for cache operation enables prefetch and predictive operations to be executed, which adds to their cost thereby limiting their practical implementation. The vector processor architecture <b>300</b> described herein may leverage the use of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N by exploiting the sequential nature of vector processing operations for certain applications, such as filter processor computations, that utilize streaming data. As discussed herein, the use of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N as part of the vector processor architecture <b>300</b> exploits the sequential and predictive nature of the computations performed for certain applications to eliminate the need for costly and complex data caches.</p><p id="p-0039" num="0038">The buffers <b>308</b>.<b>1</b>-<b>308</b>.N may each be further partitioned into any suitable number of additional buffers or &#x201c;sub-buffers,&#x201d; which may be referred to herein as virtual buffers or buffer partitions, or simply as buffers with the understanding that the smaller buffer partitions may form part of a larger buffer component. Additional detail regarding the organization of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N is shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, which illustrates a buffer <b>400</b>. The buffer <b>400</b> as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be identified with any one of (or each of) the buffers <b>308</b>.<b>1</b>-<b>308</b>.N as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, which is identified with a respective execution unit <b>304</b>.<b>1</b>-<b>304</b>.N. In this scenario, the buffer <b>400</b> has a total addressable range of 8 rows 0-7 and 16 columns 0-15. Alternatively, the rows as discussed herein may be alternatively referred to as words, with one word or more words occupying each row. Each address location of the buffer <b>400</b> is represented as an individual box of an intersecting row and column, and may store an individual vector data sample. The buffer <b>400</b> is partitioned into two virtual buffers <b>402</b>.<b>1</b> <b>402</b>.<b>2</b>, each having a predetermined address range, and which may be circular in nature such that the starting address range of each buffer <b>402</b>.<b>1</b>, <b>402</b>.<b>2</b> may be accessed and/or overwritten as the read and write pointers indicated by the vector processor instructions advance beyond the end of the address range, which advantageously maintains the size of the buffer <b>400</b> small and cost effective. The buffer <b>400</b> includes an input buffer <b>402</b>.<b>1</b>, which has an address range identified with rows 6-7 and columns 0-15, and is thus configured to store a total of four data vectors <b>404</b>.<b>1</b>, <b>404</b>.<b>2</b>, <b>404</b>.<b>3</b>, <b>404</b>.<b>4</b>, with each of these data vectors containing 8 vector data samples. The buffer <b>400</b> also includes an output buffer <b>402</b>.<b>2</b>, which has an address range identified with rows 2-3 and columns 0-15, and which has an address range configured to store a total of four data vectors <b>406</b>.<b>1</b>, <b>406</b>.<b>2</b>, <b>406</b>.<b>3</b>, <b>406</b>.<b>4</b>, with each of these data vectors also containing 8 vector data samples. Of course, and as discussed in further detail herein, the terms &#x201c;input&#x201d; and &#x201c;output&#x201d; in this context are with respect a current manner in which the buffers <b>402</b>.<b>1</b>, <b>402</b>.<b>2</b> are being utilized, and each of the buffers <b>402</b>.<b>1</b>, <b>402</b>.<b>2</b> may operate in a similar or identical manner but represent different ranges of addressable space within the buffer <b>400</b>.</p><p id="p-0040" num="0039">The data samples represented by one or more data vectors stored in the input buffer <b>402</b>.<b>1</b> and the output buffer <b>402</b>.<b>2</b> may be referred to herein as a set of vector data samples. The input buffer <b>402</b>.<b>1</b> and the output buffer <b>402</b>.<b>2</b> may have any suitable size and accompanying address range, and thus may be configured to store any suitable number and any suitable size of vector data samples and/or otherwise store any suitable number of sets of vector data samples. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the input buffer <b>402</b>.<b>1</b> is assumed to be initialized with zeros. Thus, each buffer or virtual buffer, as the case may be, which is identified with each respective buffer <b>308</b>.<b>1</b>-<b>308</b>.N, may have any suitable type of address organization and be identified with a range of addresses representing the overall capacity of that particular buffer or virtual buffer.</p><p id="p-0041" num="0040">Regardless of the particular address organization that is utilized, the buffers or virtual buffers may store sets of vector data samples over any suitable range of address locations. The use of the addressable space in the buffer <b>400</b> may be facilitated via the use of the aforementioned read pointers that are contained or otherwise encoded as part of each received fused vector processor instruction. The fused vector processor instructions may also include or otherwise encode write pointers, which specify the location within the buffer <b>400</b> (such as in the output buffer <b>402</b>.<b>2</b>) to store the results of the vector processing operations performed on the vector data samples stored in the input buffer <b>402</b>.<b>1</b>. Thus, and with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the read pointers may point to a starting address in the input buffer <b>402</b>.<b>1</b> from which the vector data samples are to be retrieved for a particular vector processing operation, whereas the write pointers point to a starting address in the output buffer <b>402</b>.<b>2</b> to which the results of a particular vector processing operation performed on the vector data samples is then stored.</p><p id="p-0042" num="0041">The address range that is incremented or offset between subsequent vector processing operations may advantageously be (but not necessarily be) a fixed or static offset value for both the read pointer and the write pointer. This value may be identified at compile time when the vector processor instructions and corresponding fields to be included in each fused vector processor instruction are initially generated. The use of a static increment or offset may be particularly useful, as the calculation of the next starting address identified by each subsequent read pointer and write pointer may be determined with a priori knowledge of the address range of each buffer and the data rate without performing additional complex processing tasks. The operation of the vector processing architecture <b>300</b> in accordance with a fixed I/O data rate may be leveraged to use of a static address increment between subsequent vector processing operations. In other words, because the buffers <b>308</b>.<b>1</b>-<b>308</b>.N may retrieve vector data samples from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N in accordance with a fixed or static data rate, this may be exploited to simplify the computation of the read and write pointer address offset calculations between subsequent vector processing operations, as the number of vector data samples to be processed each clock cycle may be fixed and thus a predetermined value that is related to the fixed data rate in terms of clock cycles.</p><p id="p-0043" num="0042">Moreover, each buffer or virtual buffer may be identified with a distinct vector data stream, with the vector processing operations being sequentially applied to vector data samples for each distinct data stream to calculate results in accordance with the type of vector processing operations that are performed. The vector processing operations may be sequentially executed over several respective clock cycles, with new vector data samples being retrieved from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N and, once no longer needed for further vector processing operations, the previous vector data samples stored in the buffer or virtual buffer may be overwritten with the new (i.e. more recently retrieved) vector data samples. In this way, the buffer or virtual buffers as described herein function in a circular manner by advancing, within each buffer, the next range of addresses used to store new vector data samples, and then returning to the original starting address over time as subsequent vector processing operations are performed and completed on older vector data samples.</p><p id="p-0044" num="0043">Again, the buffers <b>308</b>.<b>1</b>-<b>308</b>.N may store sets of vector data samples over any suitable range of address locations, which may be retrieved from one or more of the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N. This is enabled via the use of the aforementioned read pointers that are contained or otherwise encoded as part of each received fused vector processor instruction, with a single fused vector processor instruction encoding information for the read pointer increment to be performed after each one of the vector processing operations. The fused vector processor instruction may also include or otherwise encode write pointers, which specify the location within the buffer to store the results of the vector processing operations performed on the vector data samples. A single fused vector processor instruction may thus also encode information for the write pointer increment to be performed after each vector processing operation has been completed and data is to be written to the buffer, each vector processing operation being executed in response to receiving the same fused vector processor instruction.</p><p id="p-0045" num="0044">The vector processing operations may be sequentially executed over several respective clock cycles, although each of the vector processing operations may require a single fused vector processor instruction versus a sequential set of separate vector processor instructions. Further details of the nature of the fused vector processor instruction and how several vector processor instructions may be encoded into the fields of a single fused vector processor instruction are discussed below with respect to the illustrative implementations. Various implementations for vector processing operations performed by the execution units <b>304</b>.<b>1</b>-<b>304</b>.N of the vector processor architecture <b>300</b> in accordance with a data path are provided in further detail below, although these are non-limiting scenarios as the vector processing architecture <b>300</b> may be implemented in accordance with any suitable type of application and implementation, as noted above.</p><p id="p-0046" num="0045">Vector Processing Loop Iteration&#x2014;Multiple Separate Vector Processing Instructions</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a vector processing loop iteration implementing multiple separate vector processing instructions, in accordance with the disclosure. The conventional vector processing architecture <b>200</b> may execute one vector processing operation per each received vector processor instruction. In other words, several vector processing operations may be performed over a series of clock cycles, with each vector processor instruction defining the details regarding how each individual vector processing operation is to be performed. This may include the starting address of the vector data samples to be retrieved from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N, the type of vector processing operation to perform on the vector data samples, and a starting address of where to write the results back into the one or more of the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N.</p><p id="p-0048" num="0047">The conventional vector processor architecture <b>200</b> as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> may implement a number of vector processing iterations or loops, with one such iteration shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> which represents a conventional datapath used to execute vector processing operations on vector data samples retrieved form the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N. The sequence of vector processing operations constituting one loop iteration as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> may be repeated a number of times for additional sets of vector data samples as additional vector data samples are retrieved from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N, which requires use of the interconnection network each time vector data samples are transferred between the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N and the execution units <b>204</b>.<b>1</b>-<b>204</b>.N. Moreover, because the number of vector processing operations is limited to one per vector processor instruction, each vector operation in the sequence that is executed by an execution unit <b>204</b>.<b>1</b>-<b>204</b>.N may require one or more vector processing operations, each requiring a separate vector processor instruction.</p><p id="p-0049" num="0048">For instance, and with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the local data access and formatting vector processing operation(s) <b>502</b> includes rearranging the vector data samples retrieved from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N, copying the vector data samples, and aligning the vector data samples with the vector datapath utilized by the particular execution unit <b>204</b>.<b>1</b>-<b>204</b>.N. The non-linear (NL) processing vector processing operation(s) may include the computation of a non-linear function f(x) on an input x of the vector data samples. The vector processing operation(s) such as the inter-vector multiply-accumulate (MAC), arithmetic logic unit (ALU) operations, etc. may include a computation on each element or vector data sample of a data vector. The intra-vector MAC, ALU, etc. vector processing operation(s) may include a summation of all vector elements to find a vector data minimum or maximum. Post processing vector processing operation(s) may include normalization, type conversion, rounding, saturation, etc. Finally, data processing vector processing operation(s) may include combining vectors, packing vectors with partial results, etc. Each of these stages includes one or more vector operation, each requiring a separate vector processor instruction that may be received each clock cycle. Thus, the vector processing loop iteration as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> requires a significant number of vector processor instructions to be received to complete a single iteration of vector processing operations, which may span a number of clock cycles.</p><p id="p-0050" num="0049">Fused Vector Processing Instruction Pipeline</p><p id="p-0051" num="0050">It is noted that each of the vector processing operations as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> needs to be executed in accordance with several stages or phases. In other words, and with continued reference to the conventional vector processor architecture <b>200</b> as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, each of the vector processing operations <b>502</b>, <b>504</b>, <b>506</b>, <b>508</b>, <b>510</b>, and <b>512</b> includes reading the vector data from the vector registers <b>202</b>.<b>1</b>-<b>202</b>.N, transferring the vector data across the interconnection network, feeding the data to the execution units <b>204</b>.<b>1</b>-<b>204</b>.N, performing vector processing operations in each of the execution units <b>202</b>.<b>1</b>-<b>202</b>.N, moving the results of the computations performed in the execution nits <b>202</b>.<b>1</b>-<b>202</b>.N back across the interconnection network, and then writing these results back into the vector registers <b>202</b>.<b>1</b>-<b>202</b>.N. These phases are repeated for each of the processing operations <b>502</b>, <b>504</b>, <b>506</b>, <b>508</b>, <b>510</b>, and <b>512</b>, with each phase requiring one or more clock cycles depending upon the particular architecture of the vector processor, the size of the data being accessed and computed, etc. In other words, each of the vector processing operations <b>502</b>, <b>504</b>, <b>506</b>, <b>508</b>, <b>510</b>, and <b>512</b> as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> inherently includes several vector processing operations that require several vector processor instructions that occur over one or more clock cycles. Thus, each of the vector processing operations <b>502</b>, <b>504</b>, <b>506</b>, <b>508</b>, <b>510</b>, and <b>512</b> as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> repeatedly utilize the interconnection network to exchange data between the vector registers <b>202</b>.<b>1</b>-<b>202</b>.N and the execution units <b>204</b>.<b>1</b>-<b>204</b>.N.</p><p id="p-0052" num="0051">The repetitive nature of each of the processing operations <b>502</b>, <b>504</b>, <b>506</b>, <b>508</b>, <b>510</b>, and <b>512</b> using the interconnection network to transfer data in this manner expends a great deal of power and introduces latency into the system. In contrast, the use of a fused vector processor instruction that exploits the local buffers <b>308</b>.<b>1</b>-<b>308</b>.N, as discussed herein and in further detail below, advantageously reduces both system latency and power consumption. In particular, and as further noted below, once the vector data samples are retrieved from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N and loaded into the local buffers <b>308</b>.<b>1</b>-<b>308</b>.N, the vector data samples may be loaded directly into the vector datapath without the additional use of the interconnection network between vector processing operations. Thus, each of the vector processing operational stages as described in further below with respect to <figref idref="DRAWINGS">FIG. <b>6</b></figref> (i.e. <b>602</b>, <b>604</b>, <b>606</b>, <b>608</b>, <b>610</b>, <b>612</b>) may be executed such that only a single clock cycle is needed for each of the vector processing operations. However, the use of fused vector processing operations as discussed herein and with respect to <figref idref="DRAWINGS">FIG. <b>6</b></figref> in further detail below addresses these issues by providing a set of chained individual vector processing instructions that may be executed sequentially within an execution unit <b>304</b>.<b>1</b>-<b>304</b>.N. As a result, both the latency and power consumption of the vector processor architecture <b>300</b> may represent an improvement of several times better than the conventional vector processor architecture <b>200</b>.</p><p id="p-0053" num="0052">Moreover, the increased latency introduced into the vector processor architecture <b>200</b> as noted above further increases code complexity and size. That is, the system latency needs to be compensated for to ensure that the execution units <b>204</b>.<b>1</b>-<b>204</b>.N execute vector processing operations in parallel with one another to maintain the desired speed and efficiency of the system. The use of the fused vector processor instructions as noted herein further provide advantages with respect to reduced code size and complexity as a byproduct of reducing such latency.</p><p id="p-0054" num="0053">The vector processing operation pipeline as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a sequential series of vector processing operations that may be executed by one or more of the execution units <b>304</b>.<b>1</b>-<b>304</b>.N as discussed herein with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. Thus, the execution unit <b>600</b> as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> may be identified with one or more (or all) of the execution units <b>304</b>.<b>1</b>-<b>304</b>.N as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. In contrast to the vector processing operation pipeline as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, which is implemented via the execution unit <b>204</b>.<b>1</b>-<b>204</b>.N of the vector processor architecture <b>200</b>, the vector processing operation pipeline as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> may be implemented by an execution unit <b>304</b>.<b>1</b>-<b>304</b>.N of the vector processor architecture <b>300</b> as shown and discussed herein with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The vector processing operation pipeline as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> may, in contrast to the vector processing operation pipeline as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, perform several vector processing operations in response to receiving a single fused vector processor instruction. Thus, the various blocks as shown and described with respect to <figref idref="DRAWINGS">FIG. <b>6</b></figref> may represent the buffers <b>308</b>.<b>1</b>-<b>308</b>.N and the vector processing operations performed by the processor circuitry <b>310</b>.<b>1</b>-<b>310</b>.N via the execution units <b>304</b>.<b>1</b>-<b>304</b>.N, as further discussed below.</p><p id="p-0055" num="0054">To do so, the vector processor architecture <b>300</b> may utilize fused or concatenated vector processing instructions, which may be a single vector processor instruction having a number of fields that represent or otherwise encode individual vector processing instructions. In other words, for a single fused vector processor instruction, an execution unit <b>310</b>.<b>1</b>-<b>310</b>.N may (via the vector processor circuitry <b>304</b>.<b>1</b>-<b>304</b>.N) perform the plurality of vector processing operations in accordance with each of the individual vector processor instructions indicated by the fields contained within the fused vector processor instruction. Thus, the fused vector processor instruction may include any suitable type of machine-readable code, opcode, etc. that may be read by the execution units <b>304</b>.<b>1</b>-<b>304</b>.N and/or the processor circuitry <b>310</b>.<b>1</b>-<b>310</b>.N implemented by each of the execution units <b>304</b>.<b>1</b>-<b>304</b>.N, as discussed herein.</p><p id="p-0056" num="0055">The fused vector processing instruction, via the fields representing encoded individual vector processor instructions, may thus identify a number of individual vector processing instructions, which in turn indicate a number of computations to perform, a number and location (such as a read pointer address location) from which to retrieve vector data samples from the vector data registers <b>302</b>.<b>1</b>-<b>302</b>.N, a number of vector data samples to retrieve from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N, a location from which the vector data samples are stored or written to the buffers <b>308</b>.<b>1</b>-<b>308</b>.N (such as write pointer address starting locations), a location (such as a read pointer starting address location) of an address of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N to read the vector data samples, a number and/or type of vector processing operations to perform on vector data samples read from the buffers <b>308</b>.<b>1</b>-<b>308</b>.N, a location (such as a write pointer starting address location) in the buffers <b>308</b>.<b>1</b>-<b>308</b>.N to write the results of performing the vector processing operations, etc.</p><p id="p-0057" num="0056">Therefore, a single fused vector processing instruction may be received via an execution unit <b>304</b>.<b>1</b>-<b>304</b>.N during a single clock cycle, but may contain encoded data fields indicating a sequence of vector processing operations to be performed over several subsequent clock cycles. That is, an execution unit <b>304</b>.<b>1</b>-<b>304</b>.N may execute, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on a set of vector data samples that may be read from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N, written into a respective buffer <b>308</b>.<b>1</b>-<b>308</b>.N, and then initially read from the respective buffer <b>308</b>.<b>1</b>-<b>308</b>.N. Of course, the fused vector processor instruction may alternatively indicate that the vector processing operations be executed on vector data samples stored in a buffer <b>308</b>.<b>1</b>-<b>308</b>.N without the need to load the vector data samples from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N.</p><p id="p-0058" num="0057">In any event, the use of the fused vector processor instruction is enabled via the use of the local buffers <b>308</b>.<b>1</b>-<b>308</b>.N, which allow for each execution unit <b>304</b>.<b>1</b>-<b>304</b>.N to read vector data samples from the buffers <b>308</b>.<b>1</b>-<b>308</b>.N to initiate the vector processing operations and write the results of each vector processing operation to the local buffer <b>308</b>.<b>1</b>-<b>308</b>.N. These results may then be read from the local buffer <b>308</b>.<b>1</b>-<b>308</b>.N via the respective execution units <b>304</b>.<b>1</b>-<b>304</b>.N to execute the next vector processing operation, and so on. Thus, the circular nature of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N is particularly advantageous in this context, as the contents of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N may be rewritten over several vector processing operations without the need to retrieve vector data samples from, or load vector data samples into, the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N.</p><p id="p-0059" num="0058">With continued reference to the vector processing operation pipeline as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the local buffers <b>602</b>A may be identified with one or more different partitions of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N for one or more (or all) of the execution units <b>304</b>.<b>1</b>-<b>304</b>.N. The other blocks as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> may represent hardware, software, or any suitable combination thereof, each being configured to execute one or more specific types of functions in accordance with a particular vector processing operation. The various blocks as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> may be implemented as dedicated hardware configured to execute certain types of vector processing operations in accordance with the vector processor architecture <b>300</b> as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, which may include dedicated hardware configurations of known types to perform specific types of mathematical functions or other suitable vector processing operations. This may be one or more predetermined functions that the execution unit <b>600</b> is configured to execute upon receiving a fused vector processor instruction. The illustrated vector processing pipeline as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is provided for ease of explanation and not limitation, and may include any suitable number and/or type of blocks depending upon the particular application and the required number and/or type of vector processing operations that need to be executed for that application.</p><p id="p-0060" num="0059">Thus, the data formatting block <b>602</b>B may represent the functionality associated with a respective execution unit rearranges the vector data samples with respect to the data lanes utilized by the execution unit <b>600</b>, which may correspond to how the vector data samples are initially stored in the local buffers <b>602</b>A and/or how the vector data samples are rearranged once stored in the local buffers <b>602</b>A. This may vector data formatting, the generation of sliding windows for filters, DPD, etc. This may also include the replication of portions of vector data samples (i.e. cloning or broadcasting). Another scenario is alignment of the vector data samples with the datapath used by the vector processor architecture <b>300</b> (multipliers, ALUs, bit manipulation units, etc.). Once the data is formatted to be aligned with the datapath of the execution unit <b>600</b>, a number of vector processing operations are executed on the vector data samples in the blocks <b>604</b>, <b>606</b>, <b>608</b>, and <b>610</b>, each of which may be repeated for each vector data sample across each &#x201c;lane&#x201d; of the datapath a number of times depending upon size the data vectors being processed.</p><p id="p-0061" num="0060">Once the vector processing operations in blocks <b>604</b> and <b>606</b> have been completed (and additional vector processing operations if needed), then the vector data samples may need to be further rearranged with respect to bit order, merging previous results, combining various processing results with previous results, concatenating results, interleaving results, etc., which may be referred to as post-SIMD operations (assuming a SIMD vector processor architecture is used for the vector processor architecture <b>300</b>). Given the frequency of the data formatting as part of vector processing operations, the execution unit <b>600</b> as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> may include dedicated hardware, software, or combinations of both that is represented as the blocks <b>602</b>B, <b>612</b>A, which may perform such vector processing operations.</p><p id="p-0062" num="0061">With respect to the vector processing operations as shown in the blocks <b>604</b>, <b>606</b>, and further blocks and vector processing operations as applicable as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, these blocks function as part of the SIMD datapath (again assuming a SIMD vector processor architecture is used for the vector processor architecture <b>300</b>). In this context, one or more of the blocks as shown in or represented by the blocks <b>604</b>, <b>606</b>, <b>608</b>, <b>610</b>, etc. may represent dedicated hardware, software, or combinations of both configured to execute specific types of vector processing operations in a single clock cycle. This may include the calculation of vector non-linear (NL) function evaluation, which may be performed on vector data samples via the block <b>604</b>A, such as exponential functions e<sup>j&#x3b8;</sup>, square root functions &#x221a;{square root over (x)}, inverse functions</p><p id="p-0063" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <mfrac>   <mn>1</mn>   <mi>x</mi>  </mfrac>  <mo>,</mo> </mrow></math></maths></p><p id="p-0064" num="0000">inverse square root functions</p><p id="p-0065" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mrow>  <mfrac>   <mn>1</mn>   <msqrt>    <mi>x</mi>   </msqrt>  </mfrac>  <mo>,</mo> </mrow></math></maths></p><p id="p-0066" num="0000">etc. Although the block <b>604</b>A may function to compute any suitable type of function in accordance with a particular vector processing operation, the block <b>604</b>A may represent commonly-used functions for a particular application. The block <b>604</b>B may represent a quantized non-linear function stored in memory, which may be used to perform a linear interpolation between two vector data sample points and be used in conjunction with the block <b>604</b>A to evaluate more complex non-linear functions or when the vector NL block <b>604</b>A does not include dedicated hardware for a particular NL function to be evaluated.</p><p id="p-0067" num="0062">The next blocks <b>606</b>A and <b>606</b>B may be implemented to perform additional vector multiplication on the results of the previous block <b>604</b>. This may include a linear interpolation for the lookup tables, a vector multiplication on real and complex data, vector arithmetic, vector comparisons, Boolean operations, etc. The blocks <b>606</b>A, <b>606</b>B may be implemented as dedicated hardware, software, or combinations of both to facilitate such functions independently or in combination with one another based upon the particular vector processing operation that is received. The blocks <b>606</b>A, <b>606</b>B are shown as a non-limiting scenario, and the execution unit <b>600</b> may include any suitable number of such blocks, which may be repeated several times depending upon the particular type of vector processing operation that is being performed.</p><p id="p-0068" num="0063">Regardless of the number and type of vector processing operations performed in the blocks <b>604</b>, <b>606</b>, the vector processing operations result in a calculated result of vector data samples constituting a data vector. However, additional calculations within the data vector may be desired, and thus the vector reduction search block <b>608</b> functions to perform intra-vector summation and vector accumulation in block <b>608</b>A. This may include the identification of the maximum and/or minimum vector data sample within a data vector, the summation of all data vector samples within a data vector, calculate a final accumulation of multiplier/ALU results, etc. This may be referred to as reduction and may be performed via the block <b>608</b>A, which may also represent dedicated hardware to perform this functionality.</p><p id="p-0069" num="0064">Next, the execution unit <b>600</b> may perform vector normalization and/or scaling via the block <b>610</b>A, which again may be performed via dedicated hardware, software, or combinations of both. This may include shifting, rounding, and/or saturation of vector computations output by the previous block <b>608</b>A. This may include normalization vector processing operations to support pseudo floating point, removing leading zeroes, and/or fitting a calculated result output by the block <b>608</b>A to a particular data vector size. The data vector samples output by the block <b>610</b>A may then be further processed by the data block <b>612</b>A to provide the appropriate vector data formatting, and the block <b>612</b>B which facilitates vector data packing operations. The vector data packing operations may enable the calculated results of any suitable number of previous vector processing operations to be written to a data vector that may, once fully assembled or packed over a number of vector processing instructions, be transmitted by the execution unit <b>600</b> to one or more of the vector registers <b>304</b>.<b>1</b>-<b>302</b>.N. Again, although the vector data packing performed by the block <b>612</b>B may be executed in response to the completion of several vector processing operations, the received fused vector processor instruction may include encoded data fields that enable each of these vector processing operations to be performed.</p><p id="p-0070" num="0065">Again, conventionally the vector processing operations performed by each block of the execution unit <b>600</b> is executed separately per each received vector processor instruction, with one vector processing operation being performed for each received vector data processor instruction. The vector processor architecture <b>300</b> as described herein leverages the use of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N in conjunction with a fused vector processor instruction having multiple fields to perform any suitable number of vector processor instructions for each fused vector processor instruction that is received. That is, and with reference to Table 1 below, a number of vector processing operations may be performed as part of the vector processing operations executed via the SIMD datapath of the execution unit <b>600</b> as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, which may include the blocks <b>604</b> and <b>606</b>, although the vector processing operations may extend to any of the processing stages or blocks as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. As shown in Table 1 below, a conventional vector processor architecture requires a number of vector processor instructions as each operation is a mathematical calculation that requires a number of sequentially executed vector processing operation to be performed, which conventionally requires one instruction per vector processing operation. The use of the fused vector processing instruction enables such calculations to be performed using one fused vector processor instruction.</p><p id="p-0071" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="70pt" align="center"/><colspec colname="2" colwidth="49pt" align="center"/><colspec colname="3" colwidth="98pt" align="center"/><thead><row><entry namest="1" nameend="3" rowsep="1">TABLE 1</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row><row><entry/><entry>Fused datapath </entry><entry>Conventional datapath </entry></row><row><entry>Operation</entry><entry>instructions</entry><entry>instructions</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>ab + cd</entry><entry>1</entry><entry>2</entry></row><row><entry>abc</entry><entry>1</entry><entry>2</entry></row><row><entry> </entry></row><row><entry><maths id="MATH-US-00003" num="00003"><math overflow="scroll"> <mrow>  <mi>a</mi>  <mo>&#x2062;</mo>  <mfrac>   <mi>b</mi>   <msqrt>    <mi>c</mi>   </msqrt>  </mfrac> </mrow></math></maths></entry><entry>1</entry><entry>4</entry></row><row><entry> </entry></row><row><entry>(a + b)c &#x2212; d</entry><entry>1</entry><entry>2</entry></row><row><entry>af(b)</entry><entry>1</entry><entry>3</entry></row><row><entry> </entry></row><row><entry><maths id="MATH-US-00004" num="00004"><math overflow="scroll"> <mfrac>  <mrow>   <mi>f</mi>   <mo>&#x2061;</mo>   <mo>(</mo>   <mi>b</mi>   <mo>)</mo>  </mrow>  <mi>a</mi> </mfrac></math></maths></entry><entry>1</entry><entry>5</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0072" num="0066">Buffer Implementation to Facilitate Fused Vector Processor Instructions</p><p id="p-0073" num="0067">Again, the buffers <b>308</b>.<b>1</b>-<b>310</b>.N as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may be implemented to facilitate performing vector processing operations locally on each execution unit <b>304</b>.<b>1</b>-<b>304</b>.N without retrieving additional vector data samples from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the buffer <b>400</b>, which may be identified with one of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, may be partitioned or subdivided into several buffers of different addressable ranges. This may advantageously be leveraged to implement the fused vector processor operation as discussed herein. This may be particularly advantageous when each buffer partition is dedicated for a specific type of vector processing operation that may be executed as part of a pipeline of cascaded processing operations, as discussed herein with reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0074" num="0068">Thus, and as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the buffer <b>400</b> may be partitioned into any suitable number of virtual buffers <b>402</b>, with an input buffer <b>402</b>.<b>1</b> and an output buffer <b>402</b>.<b>2</b> being shown in FIG. <b>4</b>. Each of the virtual buffers <b>402</b> may function as an input buffer, an output buffer, or both, depending upon the particular vector processor operation that is being performed and whether a virtual buffer <b>402</b> is bead read from or written to during that vector processing operation. With reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a set of vector data samples may be retrieved from the one or more vector registers <b>302</b>.<b>1</b>-<b>302</b>.N and stored in the input buffer <b>402</b>.<b>1</b> as formatted vector data samples. Again, the buffers <b>308</b>.<b>1</b>-<b>308</b>.N may be identified with the local buffers <b>602</b>A as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. The vector data samples stored in the input buffer <b>402</b>.<b>1</b> may be read by the blocks <b>604</b>A, <b>604</b>B to perform any suitable type of vector processing operation, which may include the use of non-linear functions, lookup table and interpolation, etc. The results of the vector processing operations performed at block <b>604</b> may then be stored at any suitable location in the output buffer <b>402</b>.<b>2</b>. For the next vector processing operations at the block <b>606</b>, the output buffer <b>402</b>.<b>2</b> may then function as an input buffer such that the stored vector data sample results from the vector processing operation performed at block <b>604</b> are stored in the output buffer <b>402</b>.<b>1</b>, and then read as a result of the vector processing operations performed at the block <b>606</b>.</p><p id="p-0075" num="0069">Although only two buffers <b>402</b>.<b>1</b>, <b>402</b>.<b>2</b> are shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the buffer <b>400</b> may include any suitable number of buffers <b>402</b> spanning various ranges or addresses of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N. Thus, the buffer <b>400</b> may include additional buffers, with this process repeating for additional vector processing operations identified with the blocks <b>604</b>, <b>608</b> and/or additional vector processing operations performed by the blocks <b>608</b>, <b>610</b>, <b>612</b>, etc. Repeating the above scenario, the results of the vector processing operations being performed on the vector data samples read from the buffer <b>402</b>.<b>2</b> may then be stored in a further virtual buffer (not shown), which are accessed as a result of the vector processing operations performed at the block <b>608</b>, and so on. The circular nature of the buffer <b>400</b> is particularly advantageous in this context, as this enables each virtual buffer's addressable space to be re-used or overwritten as additional vector processing operations are performed locally by the execution unit <b>600</b> without retrieving additional vector data samples from the one or more vector registers.</p><p id="p-0076" num="0070">Moreover, the use of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N enables data access starting at any word and with no overhead. That is, once the vector processing operations have been completed, the results may be read from the buffers <b>308</b>.<b>1</b>-<b>308</b>.N in an unaligned manner and loaded into the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N using store operations. This is illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> via the use of the stored data vectors <b>752</b>, <b>754</b> being stored in the buffer <b>700</b> across different address ranges. The stored data vectors <b>752</b>, <b>754</b> may represent any suitable number of vector data samples, and may constitute one or more data vectors that are retrieved from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N. The buffer <b>700</b> as shown in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> may thus be identified with any one of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N as discussed herein with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0077" num="0071">To adapt to the unaligned manner in which the vector data samples are stored in the buffer <b>700</b>, the vector processor architecture <b>300</b> may include one or more data rotators such as the data rotator logic <b>456</b> as shown in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>. Thus, the buffers or virtual buffers may be referred to as &#x201c;circular,&#x201d; meaning that vector data samples may be stored in a manner that &#x201c;wraps&#x201d; across the rows and/or columns of addressable space in an unaligned manner and may span the end of a particular addressable range (such as a range of addresses for a row) and the beginning of another addressable range (such as another row), as shown in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> for the data vectors <b>752</b>, <b>754</b>.</p><p id="p-0078" num="0072">Although a single data rotator logic <b>756</b> is shown in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, this is for purposes of brevity, and the vector processor architecture <b>300</b> may include any suitable number of data rotators depending upon the particular application and implementation. The data rotator logic <b>756</b> is illustrated as having a specific size, but may be implemented having any suitable size depending upon a particular application. The data rotator logic <b>756</b> may be implemented using any suitable hardware components, software components, or combinations thereof. The data rotator logic <b>756</b> may be implemented as a Benes network or other suitable component using hardware. The data rotator logic <b>756</b> is not shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> for purposes of brevity, but functions to align the vector data samples that are written to the buffer <b>700</b> at the address indicated by a write pointer write_ptr as discussed herein, and read from the buffer <b>700</b> in an unaligned manner at starting address locations as indicated by the read pointers read_ptr0 and read_ptr1. The starting address location of the read pointers read_ptr0 and read_ptr1 may be part of a single fused vector processor instruction and constitute respective read pointers as discussed herein.</p><p id="p-0079" num="0073"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> illustrates a scenario in which 2 vectors <b>752</b>, <b>754</b> may be accessed from the buffer <b>700</b>. The two vectors <b>752</b>, <b>754</b> may be used in two input vector operations such as a vector add or a vector multiply. Again, the starting position of each vector is indicated by read pointers to the starting address position in the buffer <b>450</b> as indicated by read_ptr0 and read_ptr1, respectively. Thus, given a vector length of N elements (such as vector data samples), two sets of N sequential elements may be fetched starting from the respective read pointer positions and wrapping to the next consecutive row of the memory as needed. If a starting position of the read pointers point to word zero, then the vector access is aligned to the vector datapath as shown in the aligned access scenario <b>761</b> in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>. That is, element 0 of a vector is aligned with element 0 of a vector ALU or other suitable vector processor component in the vector datapath. However, if the position of the first element of a vector in the buffer <b>700</b> does not point to element 0, then the access is unaligned. This is illustrated in the unaligned scenario <b>762</b> in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, in which the first element of the vector is in position 3 of the buffer <b>700</b>. In such a case, once the vector is read from the buffer <b>700</b>, element 0 of the vector is in position 3 of the vector ALU, which would result in an incorrect computation. The vector thus needs to be rotated 3 positions as shown in the read result after rotation in the unaligned scenario in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>.</p><p id="p-0080" num="0074">Again, this alignment is achieved using the data rotator logic <b>756</b> as shown in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, which may include two or more data rotators. In this way, each of the 2 unaligned vectors <b>752</b>, <b>754</b> may be independently rotated by each respective data rotator logic <b>756</b> such that each vector becomes aligned to the arithmetic vector datapath. A similar approach may be used to write the resultant vector back to the buffer at any alignment. The following implementations as discussed herein may utilize such data rotation as needed, although this step may not explicitly be noted further herein for purposes of brevity.</p><p id="p-0081" num="0075">Thus, in contrast to the unaligned access from the 4-entry 8 word register file as shown in the unaligned access scenario <b>762</b> in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, which requires retrieving all vector data samples from rows 1 and 2, the circular nature of the local buffer <b>700</b> enables the execution units <b>304</b>.<b>1</b>-<b>304</b>.N to read the vector data samples over an address range that includes these vector data samples and no additional vector data samples. This increases efficiency and power savings, as noted herein. The data rotation may be performed at any suitable time to ensure correct computations, and once aligned may then be stored in the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N. In this way, the data rotator logic <b>756</b> re-aligns the vector data samples to ensure compatibility with standardized compilers and instruction sets that access the vector data samples from the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N in an aligned manner. The data rotator logic <b>756</b> may use information regarding the window offset and size of the stored data vectors to shift or realign the bits that are read from the buffer <b>700</b> using the read pointer address encoded into the fused vector processor instruction, and this may occur in a manner that is transparent to the compiler, the decoder <b>320</b>, or other component generating the vector processor instructions.</p><p id="p-0082" num="0076">Fused Vector Processor Instruction Format</p><p id="p-0083" num="0077">As noted herein, a fused vector processing instruction may include a number of fields that may represent encoded data, the encoded enabling the execution units <b>304</b>.<b>1</b>-<b>304</b>.N of the vector processor architecture <b>300</b> to perform any suitable number of vector processing operations. With reference to the scenario described above for the execution unit <b>600</b> utilizing the virtual buffers associated with the buffer <b>400</b>, this may include all information required to perform any suitable number of vector processing operations until the vector data samples are completely processed as provided by the block <b>612</b>B. Thus, the fields may include an address location within the vector registers <b>304</b>.<b>1</b>-<b>304</b>.N to initially retrieve the vector data samples for a particular set of vector processing operations. The fields may also include one or more read pointers indicating a starting address location within the buffer <b>400</b> from which the set of vector data samples are to be read to begin each respective one of the sequential vector processing operations. The fields may additionally include one or more write pointers indicating a starting address location in the buffer <b>400</b> where the results of each respective one of the sequential vector processing operations are to be stored in the buffer <b>400</b>.</p><p id="p-0084" num="0078">Moreover, the fields may include any suitable type of encoded data that functions to configured the blocks <b>602</b>B, <b>604</b>A, <b>604</b>B, <b>606</b>A, <b>606</b>B, <b>608</b>A, <b>610</b>A, and/or <b>612</b>A as discussed herein with reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>. This may include not only read and write pointers as noted above, but additionally the specific type of vector processing operations to be performed, the size of the vector data samples, how to format the vector data samples, the specific mathematical functions, the address locations of lookup tables, etc. Thus, the fused vector processor instruction may contain fields that have been predetermined such that when compiled and transmitted to the execution unit <b>600</b>, causes the execution unit <b>600</b> to perform a sequential number of vector processing operations on vector data samples retrieved from the one or more vector registers <b>302</b>.<b>1</b>-<b>302</b>.<b>2</b>. The fused vector processor instruction may advantageously encode fields for frequently-executed vector processor operations that may have predictable outcomes, which may be with respect to the advancement of the read and write pointers after each vector processing operation using knowledge of the size of the vector data samples to be processed and information regarding the address range of the buffers <b>308</b>.<b>1</b>-<b>308</b>.N. Moreover, the fused vector processor instruction may encode the fields to indicate vector processing operations that are typically repeated over a large number of vector data samples, which may be particularly useful for specific implementations as noted herein, such digital signal processing for wireless communications.</p><p id="p-0085" num="0079">As noted below, in one illustrative scenario, the fused vector processor instruction may include a number of fields with respect to the computation of a non-linear term used in digital pre-distortion (DPD). The fused vector processor instruction includes a number of fields that facilitates vector processor operations that function to read a partially computed DPD result from an accumulator, compute an additional term, and accumulate this newly computed term (r[i]=x[j]*f(|y[k]|) to the partial result, which is written back to the accumulator. The function f(x) is evaluated using lookup tables with interpolation. Once the entire expression is computed, the result is scaled, rounded, and saturated if necessary and written to the vector output via the output vector format blocks <b>612</b>A, <b>612</b>B. The operation is controlled by ctrl0/ctrl1 inputs.</p><p id="p-0086" num="0080">Thus, the fused vector processor instruction may have any suitable number of fields, with each field representing a number of corresponding bits that functions to instruct each corresponding block of the execution unit <b>600</b> that receives the fused vector processor instruction to perform specific tasks. Thus, the fused vector processor instruction may be executed by the processing circuitry <b>310</b>.<b>1</b>-<b>310</b>.N of a corresponding execution unit <b>304</b>.<b>1</b>-<b>304</b>.N in accordance with any suitable type of software language, machine code, opcode, etc. The various fields may have any suitable format depending upon the particular compiler and language used by the vector processor architecture <b>300</b>. The fields illustrated in Table 1 below may be generated using the instruction sets stored in the program memory <b>306</b>, which may be generated by the decoder <b>320</b> in accordance with a predetermined type of machine-readable code that is executed by the execution units <b>304</b>.<b>1</b>-<b>304</b>.N in accordance with a predetermined machine-readable and executable software instruction set. The specific arrangement of bits represented by each field of the fused vector processor instruction may cause the execution units <b>304</b>.<b>1</b>-<b>304</b>.N to execute specific vector processing operations. The first field of the vector processor instruction may include a control field such as ctrl:, which is indexed to the particular data vector being processed (such as 0, 1, 2, etc.)</p><p id="p-0087" num="0081">Thus, a fused vector processor instruction may contain any suitable number of operands or fields, each representing a number of bits that encode a specific instruction in accordance with the particular vector processing operations to be performed. The general syntax for such a fused vector processor instruction may be represented as follows:</p><p id="p-0088" num="0082">operation (&#x3c;FU&#x3e;, A, B, D, E, F, R, S, T);</p><p id="p-0089" num="0083">The fused vector processor instruction thus functions to instruct a corresponding execution unit <b>304</b>.<b>1</b>-<b>304</b>.N that receives the fused vector processor instruction to perform several vector processing operations. Thus, the fused vector processor instruction may be executed by the processing circuitry <b>310</b>.<b>1</b>-<b>310</b>.N of a corresponding execution unit <b>304</b>.<b>1</b>-<b>304</b>.N in accordance with any suitable type of software language, machine code, opcode, etc., which may be a set of predetermined software instructions, a hardware implementation, or combinations of both. The various fields on the fused vector processor instruction may have any suitable format depending upon the particular compiler and language used by the vector processor architecture <b>300</b>. The instructions illustrated in Table 1 below may form part of the instruction sets stored in the program memory <b>306</b>, which may be generated by the decoder <b>320</b> in accordance with a predetermined type of machine-readable code that is executed by the execution units <b>304</b>.<b>1</b>-<b>304</b>.N in accordance with a predetermined machine-readable and executable software instruction set. The specific arrangement of bits represented by each operand of the vector processor instruction may cause the execution units <b>304</b>.<b>1</b>-<b>304</b>.N to execute specific vector processing operations. The first operand of the fused vector processor instruction may include a control field such as ctrl:, which is indexed to the particular vector processor instruction (such as 0, 1, 2, etc.)</p><p id="p-0090" num="0084">As one scenario, a fused vector processor instruction may be expressed as follows:</p><p id="p-0091" num="0085">vec_inter_mac(ctrl0,ctrl1, vec_in0, vec_in1, vec_acc_in, vec_out, vec_acc_out);</p><p id="p-0092" num="0086">The vector processor architecture as discussed herein may implement any suitable number of fused vector processor instructions having any suitable number of fields, with a sample or subset of some fields being represented in Table 1 below, with additional operands and fields shown in Tables 2-4. Of course, the vector processor architecture <b>300</b> may include alternate, additional, and fewer instructions, fields, operands, etc., depending upon the particular operation being performed and the particular application.</p><p id="p-0093" num="0000"><tables id="TABLE-US-00002" num="00002"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="42pt" align="left"/><colspec colname="2" colwidth="175pt" align="left"/><thead><row><entry namest="1" nameend="2" rowsep="1">TABLE 1</entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row><row><entry>Instruction</entry><entry>Description</entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>ctrl0:</entry><entry>Instruction Control 0</entry></row><row><entry>ctrl1:</entry><entry>Instruction Control 1</entry></row><row><entry>vec_in0:</entry><entry>Input vector of complex samples</entry></row><row><entry>vec_in1:</entry><entry>Input vector of complex sample magnitudes</entry></row><row><entry>vec_acc_in:</entry><entry>Input vector of partially accumulated results</entry></row><row><entry>coef_in:</entry><entry>Subset of filter coefficients used in current stage</entry></row><row><entry>vec_out:</entry><entry>Vector of DPD results</entry></row><row><entry>vec_acc_out:</entry><entry>Output vector of partially accumulated results</entry></row><row><entry>ctrl0[0:7]:</entry><entry>input vector data 0 read address (read pointer for vector 0)</entry></row><row><entry>ctrl0[8:15]:</entry><entry>input vector data 1 read address (read pointer for vector 1)</entry></row><row><entry>ctrl0[23:16]:</entry><entry>output vector data write address (write pointer)</entry></row><row><entry>ctrl0[27:24]:</entry><entry>LUT selection</entry></row><row><entry>ctrl0[30:28]:</entry><entry>LUT size (16/32/64/128 . . . # of segments)</entry></row><row><entry>ctrl0[31]:</entry><entry>write enable for final scaled result</entry></row><row><entry>ctrl1[2:0]:</entry><entry>multiplier configuration</entry></row><row><entry/><entry>000 - multiply</entry></row><row><entry/><entry>001 - multiply accumulate</entry></row><row><entry/><entry>. . .</entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0094" num="0087">Again, a fused vector processor instruction may contain any suitable number of operands, each encoding a specific instruction in accordance with the particular vector processing operation and implementation. Thus, the syntax for a FIR filter vector processor instruction may be represented as follows:</p><p id="p-0095" num="0088">v_fir_filter (&#x3c;FU&#x3e;, A, B, D, E, F, R, S, T);</p><p id="p-0096" num="0089">with &#x3c;FU&#x3e; being a specific field with respect to the particular compiler used to generate the instruction. Table 2 below summarizes a set of such operands, which are explained in further detail below.</p><p id="p-0097" num="0000"><tables id="TABLE-US-00003" num="00003"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="6"><colspec colname="offset" colwidth="14pt" align="left"/><colspec colname="1" colwidth="35pt" align="left"/><colspec colname="2" colwidth="42pt" align="left"/><colspec colname="3" colwidth="49pt" align="left"/><colspec colname="4" colwidth="42pt" align="center"/><colspec colname="5" colwidth="35pt" align="center"/><thead><row><entry/><entry namest="offset" nameend="5" rowsep="1">TABLE 2</entry></row><row><entry/><entry namest="offset" nameend="5" align="center" rowsep="1"/></row><row><entry/><entry>Operand</entry><entry>Direction</entry><entry>C Type</entry><entry>Width (bits)</entry><entry>Cycle</entry></row><row><entry/><entry namest="offset" nameend="5" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="6"><colspec colname="offset" colwidth="14pt" align="left"/><colspec colname="1" colwidth="35pt" align="left"/><colspec colname="2" colwidth="42pt" align="left"/><colspec colname="3" colwidth="49pt" align="left"/><colspec colname="4" colwidth="42pt" align="char" char="."/><colspec colname="5" colwidth="35pt" align="center"/><tbody valign="top"><row><entry/><entry>A</entry><entry>Input</entry><entry>unsigned int</entry><entry>32</entry><entry>0</entry></row><row><entry/><entry>B</entry><entry>Input</entry><entry>unsigned int</entry><entry>32</entry><entry>0</entry></row><row><entry/><entry>D</entry><entry>Input</entry><entry>_int1024</entry><entry>1024</entry><entry>0</entry></row><row><entry/><entry>E</entry><entry>Input</entry><entry>_int1024</entry><entry>1024</entry><entry>0</entry></row><row><entry/><entry>F</entry><entry>Input</entry><entry>_int2560</entry><entry>2560</entry><entry>4</entry></row><row><entry/><entry>R</entry><entry>Output</entry><entry>_int1024</entry><entry>1024</entry><entry>6</entry></row><row><entry/><entry>S</entry><entry>Output</entry><entry>_int1024</entry><entry>1024</entry><entry>6</entry></row><row><entry/><entry>T</entry><entry>Output</entry><entry>_int2560</entry><entry>2560</entry><entry>4</entry></row><row><entry/><entry namest="offset" nameend="5" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0098" num="0090">Such a fused vector processing instruction may represent a vector FIR filter operation processor instruction and be utilized by one of the execution units <b>302</b>.<b>1</b>-<b>302</b>.N to implement various kinds of FIR filters, including non-symmetric, anti-symmetric, symmetric filter, half band interpolation and decimation filter, etc. For symmetric filters, including anti-symmetric filters, symmetry may be exploited to reduce the multiplication number. Thus, for this operation, it is assumed that filter coefficients are pre-arranged and stored in an on-chip lookup table (LUT). The on-chip LUT size may be any suitable size depending upon the particular application, such as 1024&#xd7;32 bits. The LUT may thus hold up to 2048 16-bit real coefficients in such a case.</p><p id="p-0099" num="0091">Tables 3 and 4 further include various fields and their accompanying description, which may be implemented to perform filter computations as noted herein or any other suitable type of vector processing operations. Thus, continuing the above scenario, the input vectors D, E may each contain 32 bit vector data samples for a total of 64 consecutive vector data samples. Thus, when enabled, these 64 vector data samples are written into one local buffer <b>308</b>.<b>1</b>-<b>308</b>.N (SBF) as a word (2048 bit wide), which is addressed by sbf_wr_ptr representing a write pointer as discussed herein. In this scenario, it is assumed that there are 8 such buffer words in the particular local buffer <b>308</b>.<b>1</b>-<b>308</b>.N. The write into the local buffer <b>308</b> is thus word aligned, and therefore sbf_wr_ptr is only 3 bits. The sbf_wr_ptr field may thus represent a write pointer that identifies the starting location in the local buffer <b>308</b>.<b>1</b>-<b>308</b>.N where data is to be written for further vector processing operations as discussed herein. The sbf_wr_enb field indicates, when enabled, that data is to be written into the local buffer <b>308</b>.<b>1</b>-<b>308</b>.N (such as from the vector registers <b>302</b>.<b>1</b>-<b>30</b>.N) as discussed herein. The fields sbf_rd_idx0, sbf_rd_idx1 may respectively represent read pointers identifying the starting location in the local buffer <b>308</b>.<b>1</b>-<b>308</b>.N from which data is to be read, as discussed herein.</p><p id="p-0100" num="0092">When enabled, the SBF read operation sbf_rd_enb results in an execution unit <b>304</b>.<b>1</b>-<b>304</b>.N reading out two unaligned buffer words independently from a local buffer <b>308</b>.<b>1</b>-<b>308</b>.N, which are indexed by sbf_r_idx0, sbf_r_idx1, respectively. These two 2048 bit words may be non-overlapped, partially overlapped, or completely-overlapped, depending on the values of sbf_r_idx0, sbf_r_idx1. To support such unaligned reads, both sbf_r_idx0 and sbf_r_idx1 are allocated 9 bits to be able to read from any 32 bit word position from the local buffer <b>308</b>.<b>1</b>-<b>308</b>.N. These two read out buffer words are then sent to two sliding window creation (SWC) blocks to go through rotation/interleave-and-rotation and sliding window generation based on the filter types. Each SWC block generates four 32 component vectors, one for each filter coefficient. Usually, one SWC generates 4 vectors for a main data path, whereas the other SWC generates the other 4 vectors for the symmetric data path. Two main path vectors and two symmetric data path vectors are thus sent to a first multiplication block (such as <b>606</b>A). The other two main path vectors and the other two symmetric data path vectors are sent to a second multiplication block.</p><p id="p-0101" num="0093">Continuing this scenario, one vector is then read out from the on-chip LUT. Four 16 bit real or two 32 bit complex coefficients from the read out vector are cloned into two coefficient vectors. Each coefficient vector is fed to one multiplication block. The products from both multiplication blocks and the accumulation input F are then added together. The results are carried out by T.</p><p id="p-0102" num="0094">Each execution of this operation may produce no filtered data sample (when only SBF write is enabled), <b>32</b>, or <b>16</b> filtered data samples (when SBF read is enabled), depending on the filter type that is being implemented. After all filter coefficients have been applied to one set of data samples, the accumulated results are then processed through a shift-round-saturate (SRS) block (such as S<b>610</b>A) to convert to a normal precision format. Again, SRS is a common function in DSP for scaling fixed point data after arithmetic operations that result in data that no longer fits in the vector. Then, the data is packed into a packing register to wait for more samples. After <b>64</b> data samples are collected, filtered data sample processing is carried out by R and S. A and B represent pre-generated headers to control each filter operation.</p><p id="p-0103" num="0095">The following dynamic fields are carried by A, B in each v_fir_filter operation:</p><p id="p-0104" num="0000"><tables id="TABLE-US-00004" num="00004"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="42pt" align="left"/><colspec colname="2" colwidth="35pt" align="center"/><colspec colname="3" colwidth="49pt" align="left"/><colspec colname="4" colwidth="91pt" align="left"/><thead><row><entry namest="1" nameend="4" rowsep="1">TABLE 3</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row><row><entry>Bit position</entry><entry>Size</entry><entry>Field Name</entry><entry>Definition</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/><entry>1</entry><entry>sbf_wr_enb</entry><entry>SBF write enable.</entry></row><row><entry/><entry/><entry/><entry>when set, data carried in D,</entry></row><row><entry/><entry/><entry/><entry>E is written into SBF.</entry></row><row><entry/><entry>1</entry><entry>sbf_rd_enb</entry><entry>SBF read enable.</entry></row><row><entry/><entry/><entry/><entry>When set, two SBF words</entry></row><row><entry/><entry/><entry/><entry>are read out, filter</entry></row><row><entry/><entry/><entry/><entry>operation is performed.</entry></row><row><entry/><entry>1</entry><entry>symm_enb</entry><entry>When set, symmetric path</entry></row><row><entry/><entry/><entry/><entry>is enabled.</entry></row><row><entry/><entry>9</entry><entry>sbf_rd_idx0</entry><entry>SBF read index 0 (read</entry></row><row><entry/><entry/><entry/><entry>pointer for vector 0)</entry></row><row><entry/><entry>9</entry><entry>sbf_rd_idx1</entry><entry>SBF read index 1 (read</entry></row><row><entry/><entry/><entry/><entry>pointe for vector 1)</entry></row><row><entry/><entry>1</entry><entry>pkr_enb</entry><entry>When set, on-chip packing</entry></row><row><entry/><entry/><entry/><entry>Register enabled.</entry></row><row><entry/><entry>1</entry><entry>pkr_we</entry><entry>When set and pkr_enb = 1,</entry></row><row><entry/><entry/><entry/><entry>one packing register is</entry></row><row><entry/><entry/><entry/><entry>written.</entry></row><row><entry/><entry>1</entry><entry>pkr_idx</entry><entry>Packing register Index.</entry></row><row><entry/><entry/><entry/><entry>May increase to 2 bits.</entry></row><row><entry/><entry>1</entry><entry>pkr_pos</entry><entry>Packing register position to</entry></row><row><entry/><entry/><entry/><entry>indicate first 16 or second</entry></row><row><entry/><entry/><entry/><entry>16 position. May increase</entry></row><row><entry/><entry/><entry/><entry>to 2 bits if 4-to-1 reduction</entry></row><row><entry/><entry/><entry/><entry>is needed.</entry></row><row><entry/><entry>2</entry><entry>mac_type</entry><entry>0&#x2014;No accumulation</entry></row><row><entry/><entry/><entry/><entry>1&#x2014;Add accumulation</entry></row><row><entry/><entry/><entry/><entry>input</entry></row><row><entry/><entry/><entry/><entry>2&#x2014;subtract accumulation</entry></row><row><entry/><entry/><entry/><entry>input</entry></row><row><entry/><entry/><entry/><entry>3&#x2014;un-supported</entry></row><row><entry/><entry>3</entry><entry>sbf_wr_ptr</entry><entry>SBF write index (write</entry></row><row><entry/><entry/><entry/><entry>pointer)</entry></row><row><entry/><entry>1</entry><entry>mem_w_enb</entry><entry>When set, data will be</entry></row><row><entry/><entry/><entry/><entry>written into VMEM</entry></row><row><entry/><entry>5</entry><entry>output_fmt</entry><entry>Specify the output format</entry></row><row><entry/><entry/><entry/><entry>operation</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0105" num="0096">The following fields are also used per-filter type, which may be loaded when no filter operation is performed (such as when sbf_wr_enb=1 and sbf_rd_enb=0).</p><p id="p-0106" num="0000"><tables id="TABLE-US-00005" num="00005"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="56pt" align="left"/><colspec colname="2" colwidth="35pt" align="center"/><colspec colname="3" colwidth="56pt" align="left"/><colspec colname="4" colwidth="70pt" align="left"/><thead><row><entry namest="1" nameend="4" rowsep="1">TABLE 4</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row><row><entry>Bit position</entry><entry>Size</entry><entry>Field Name</entry><entry>Definition</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/><entry>4</entry><entry>fir_type</entry><entry>FIR filter types</entry></row><row><entry/><entry>5</entry><entry>shift</entry><entry>scalar shift value for</entry></row><row><entry/><entry/><entry/><entry>SRS</entry></row><row><entry/><entry>1</entry><entry>sym_type</entry><entry>0&#x2014;symmetric</entry></row><row><entry/><entry/><entry/><entry>1&#x2014;anti-symmetric</entry></row><row><entry/><entry>2</entry><entry>mul_type</entry><entry>0&#x2014;MUL REAL,</entry></row><row><entry/><entry/><entry/><entry>real numbers</entry></row><row><entry/><entry/><entry/><entry>multiplication</entry></row><row><entry/><entry/><entry/><entry>1&#x2014;MUL CPX,</entry></row><row><entry/><entry/><entry/><entry>complex numbers</entry></row><row><entry/><entry/><entry/><entry>multiplication</entry></row><row><entry/><entry/><entry/><entry>2&#x2014;MUL SEMI, a</entry></row><row><entry/><entry/><entry/><entry>real number times a</entry></row><row><entry/><entry/><entry/><entry>complex number</entry></row><row><entry/><entry/><entry/><entry>3&#x2014;MUL MAGS,</entry></row><row><entry/><entry/><entry/><entry>complex number</entry></row><row><entry/><entry/><entry/><entry>magnitude square</entry></row><row><entry/><entry>1</entry><entry>mul_size</entry><entry>0&#x2014;16 bit mode</entry></row><row><entry/><entry/><entry/><entry>1&#x2014;32 bit mode</entry></row><row><entry/><entry>1</entry><entry>red_mode</entry><entry>0&#x2014;No reduction</entry></row><row><entry/><entry/><entry/><entry>1&#x2014;2-to-l</entry></row><row><entry/><entry/><entry/><entry>reduction</entry></row><row><entry/><entry/><entry/><entry>may need to increase</entry></row><row><entry/><entry/><entry/><entry>to 2 bits</entry></row><row><entry/><entry>4</entry><entry>coef_Lut_idx</entry><entry>Filter coefficient</entry></row><row><entry/><entry/><entry/><entry>LUT index</entry></row><row><entry/><entry>5</entry><entry>coef_idx</entry><entry>Filter coefficient</entry></row><row><entry/><entry/><entry/><entry>component start</entry></row><row><entry/><entry/><entry/><entry>index</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0107" num="0097">Thus, the vector processing operations as discussed herein may be implemented using a fused vector processor instruction that performs a for loop or other suitable control such that vector processing operations are iteratively executed, with the various fields for the individual vector processor instructions begin changed each pass through the for loop. Such fields thus dictate when data is to be written into the local buffers <b>308</b>.<b>1</b>-<b>308</b>.N by each respective execution unit <b>302</b>.<b>1</b>-<b>302</b>.N (sbf_wr_enb), the location within the local buffers <b>308</b>.<b>1</b>-<b>308</b>.N where the data is to be written (sbf_wr_ptr), when data is to be read from the local buffers <b>308</b>.<b>1</b>-<b>308</b>.N by each respective execution unit <b>302</b>.<b>1</b>-<b>302</b>.N (sbf_rd_enb), the location within the local buffers <b>308</b>.<b>1</b>-<b>308</b>.N from which the data is to be read (sbf_rd_idx0, sbf_rd_idx1, etc.), when data is to be written to the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N (mem_w_enb), etc.</p><p id="p-0108" num="0098">Example C-Code to Implement a DPD Loop</p><p id="p-0109" num="0099">The code snippet provided below is written in C, and all computations performed per for loop iteration (i.e. the number of vector processing operations executed for a particular fused vector processor instruction) are fused into a single V_INTRPL_MAC instruction.</p><p id="p-0110" num="0000"><tables id="TABLE-US-00006" num="00006"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="273pt" align="left"/><thead><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>// Loop to compute DPD on block of I/Q samples.</entry></row><row><entry>// Each iteration computes the contribution of one non-linear function to 2 vector outputs</entry></row><row><entry>// Hdr[0-3] stores all the precomputed control for each instruction call (pointers to data,</entry></row><row><entry>// pointers to LUT,</entry></row><row><entry>// multiplier configuration, etc.)</entry></row><row><entry>for (i=0; i&#x3c;(N_DATA_VECTORS/2)*N_FUNCTIONS+4; i++)</entry></row><row><entry>&#x2003;{</entry></row><row><entry>&#x2003;&#x2003;// load the control information for 2 fused instructions into integer variables</entry></row><row><entry>&#x2003;&#x2003;Hdr0 = *(hdr_ptr++);</entry></row><row><entry>&#x2003;&#x2003;Hdr1 = *(hdr_ptr++);</entry></row><row><entry>&#x2003;&#x2003;Hdr2 = *(hdr_ptr++);</entry></row><row><entry>&#x2003;&#x2003;Hdr3 = *(hdr_ptr++);</entry></row><row><entry>&#x2003;&#x2003;// load I/Q samples from memory at arbitrary offset</entry></row><row><entry>&#x2003;&#x2003;V_LDOI_2048_0(data_ptr, ofst_x, vecX0, vecX1, ofst_x);</entry></row><row><entry>&#x2003;&#x2003;// load magnitude of I/Q samples at arbitrary offset</entry></row><row><entry>&#x2003;&#x2003;V_LDOI_2048_0(xbar_ptr, ofst_a, vecA0, vecA1, ofst_a);</entry></row><row><entry>&#x2003;&#x2003;// read accumulator, compute an additional DPD term, add to accumulator, output scaled</entry></row><row><entry>&#x2003;&#x2003;//result for vector l</entry></row><row><entry>&#x2003;&#x2003;V_INTRPL_MAC(Hdr0, Hdr1, vecX0, vecX1, ACC0, vecR0, ACC0);</entry></row><row><entry>&#x2003;&#x2003;// read accumulator, compute an additional DPD term, add to accumulator, output scaled</entry></row><row><entry>&#x2003;&#x2003;//result for vector 2</entry></row><row><entry>&#x2003;&#x2003;V_INTRPL_MAC(Hdr2, Hdr3, vecA0, vecA1, ACC1, vecR1, ACC1);</entry></row><row><entry>&#x2003;&#x2003;// MEM_W_ENB(Hdr1) indicates that final term has accumulated and result can be</entry></row><row><entry>&#x2003;&#x2003;// written back to memory.</entry></row><row><entry>&#x2003;&#x2003;if (MEM_W_ENB(Hdr1))</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;V_STOI_2048_1(out_ptr, ofst_y, vecR0, vecR1, ofst_y);</entry></row><row><entry>}</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0111" num="0100">Device Implementing a Vector Processor Architecture</p><p id="p-0112" num="0101"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example device, in accordance with the present disclosure. The device <b>800</b> may be identified with one or more devices implementing a vector processor architecture to perform vector processing operations, such as the vector processor architecture <b>300</b> as shown and discussed herein with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The device <b>800</b> may be identified with a wireless device, a user equipment (UE) or other suitable device configured to perform wireless communications such as a mobile phone, a laptop computer, a cellular base station, a tablet, etc., which may include one or more components configured to transmit and receive radio signals, and to use vector processing operations as discussed herein to perform digital signal processing operations in accordance with wirelessly transmitted and/or received data, which may include filter processing, DFE processing, etc., as discussed herein. Alternatively, the device <b>800</b> may be identified with a graphics processing unit (GPU), which may perform graphic processing on streams of graphical data.</p><p id="p-0113" num="0102">As further discussed below, the device <b>800</b> may perform the functions as discussed herein with respect to the vector processor architecture <b>300</b> as shown and discussed with respect to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The device <b>800</b> may perform vector processing operations by receiving fused vector processor instructions having any suitable number of fields that result in the execution of several vector processing operations. These vector processing operations may be performed using locally-implemented or embedded buffers to store vector data samples and the output of performing vector data processing on the stored vector data samples. To do so, the device <b>800</b> may include processing circuitry <b>802</b>, a transceiver <b>804</b>, a vector processor architecture <b>806</b>, and a memory <b>808</b>. The components shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref> are provided for ease of explanation, and the device <b>800</b> may implement additional, less, or alternative components as those shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. In one scenario, the transceiver <b>804</b> may be omitted when the device <b>800</b> is implemented as a GPU.</p><p id="p-0114" num="0103">The processing circuitry <b>802</b> may be configured as any suitable number and/or type of computer processors, which may function to control the device <b>700</b> and/or other components of the device <b>800</b>. The processing circuitry <b>802</b> may be identified with one or more processors (or suitable portions thereof) implemented by the device <b>800</b>. The processing circuitry <b>802</b> may be identified with one or more processors such as a host processor, a digital signal processor, one or more microprocessors, graphics processors, baseband processors, microcontrollers, an application-specific integrated circuit (ASIC), part (or the entirety of) a field-programmable gate array (FPGA), etc.</p><p id="p-0115" num="0104">In any event, the processing circuitry <b>802</b> may be configured to carry out instructions to perform arithmetical, logical, and/or input/output (I/O) operations, and/or to control the operation of one or more components of device <b>800</b> to perform various functions as described herein. The processing circuitry <b>802</b> may include one or more microprocessor cores, memory registers, buffers, clocks, etc., and may generate electronic control signals associated with the components of the device <b>800</b> to control and/or modify the operation of these components. The processing circuitry <b>802</b> may communicate with and/or control functions associated with the transceiver <b>804</b>, the vector processor architecture <b>806</b>, and/or the memory <b>808</b>.</p><p id="p-0116" num="0105">The transceiver <b>804</b> (when present) may be implemented as any suitable number and/or type of components configured to transmit and/or receive data (such as data packets) and/or wireless signals in accordance with any suitable number and/or type of communication protocols. The transceiver <b>804</b> may include any suitable type of components to facilitate this functionality, including components associated with known transceiver, transmitter, and/or receiver operation, configurations, and implementations. Although depicted in <figref idref="DRAWINGS">FIG. <b>8</b></figref> as a transceiver, the transceiver <b>804</b> may include any suitable number of transmitters, receivers, or combinations of these that may be integrated into a single transceiver or as multiple transceivers or transceiver modules. The transceiver <b>804</b> may include components typically identified with an RF front end and include antennas, ports, power amplifiers (PAs), RF filters, mixers, local oscillators (LOs), low noise amplifiers (LNAs), upconverters, downconverters, channel tuners, etc. Thus, the transceiver <b>804</b> may be configured as any suitable number and/or type of components configured to facilitate receiving and/or transmitting data and/or signals in accordance with one or more communication protocols. The transceiver <b>804</b> may be implemented as any suitable number and/or type of components to support wireless communications such as analog-to-digital converters (ADCs), digital to analog converters, intermediate frequency (IF) amplifiers and/or filters, modulators, demodulators, baseband processors, etc. The data received via the transceiver <b>804</b> (e.g. wireless signal data streams), data provided to the transceiver <b>804</b> for transmission (e.g. data streams for transmission), and/or data used in conjunction with the transmission and/or reception of data via the transceiver <b>804</b> (e.g. digital filter coefficients, DPD terms, etc.) may be processed as data streams via the vector processor architecture <b>806</b>, as discussed herein. Thus, the vector processor architecture <b>806</b> may be identified with the vector processor architecture <b>300</b> as shown and described herein with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0117" num="0106">The memory <b>808</b> stores data and/or instructions such that, when the instructions are executed by the processing circuitry <b>802</b>, cause the device <b>800</b> to perform various functions as described herein with respect to the vector processor architecture <b>806</b>, such as controlling, monitoring, and/or regulating the flow of data through the vector processor architecture <b>806</b>. The memory <b>808</b> may be implemented as any well-known volatile and/or non-volatile memory, including read-only memory (ROM), random access memory (RAM), flash memory, a magnetic storage media, an optical disc, erasable programmable read only memory (EPROM), programmable read only memory (PROM), etc. The memory <b>808</b> may be non-removable, removable, or a combination of both. The memory <b>808</b> may be implemented as a non-transitory computer readable medium storing one or more executable instructions such as, for example, logic, algorithms, code, etc.</p><p id="p-0118" num="0107">As further discussed below, the instructions, logic, code, etc., stored in the memory <b>808</b> are represented by the various modules as shown, which may enable the functionality disclosed herein to be functionally realized. Alternatively, the modules as shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref> that are associated with the memory <b>808</b> may include instructions and/or code to facilitate control and/or monitor the operation of hardware components implemented via the device <b>800</b>. In other words, the modules shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref> are provided for ease of explanation regarding the functional association between hardware and software components. Thus, the processing circuitry <b>802</b> may execute the instructions stored in these respective modules in conjunction with one or more hardware components to perform the various functions as discussed herein.</p><p id="p-0119" num="0108">The vector processing control engine <b>810</b> may represent the functionality described herein as discussed with reference to controlling and/or monitoring the vector processor architecture <b>806</b>. The vector processing control engine <b>810</b> may represent the program memory <b>306</b> (and stored instruction sets), the decoder <b>320</b>, and/or the vector data memory <b>301</b> as discussed herein with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. Additionally or alternatively, one or more of the program memory <b>306</b>, the decoder <b>320</b>, and/or the vector data memory <b>301</b> may form part of the processing circuitry <b>802</b>, the memory <b>808</b>, or separate components not shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0120" num="0109">The executable instructions stored in the vector operation instruction management module <b>811</b> may facilitate, in conjunction with execution via the processing circuitry <b>802</b>, the device <b>800</b> receiving and decoding fused vector processor instructions (which may be sent via the processing circuitry <b>802</b> or other suitable component of the device <b>800</b> or a component external to the device <b>800</b>), and providing data streams to the vector processor architecture <b>806</b> (e.g. from a suitable data source as discussed herein). This may include a determination of each specific vector processor instruction to perform specific types of vector processing operations and/or any of the functionality as discussed herein with respect to the vector processor architecture <b>300</b> such as the retrieval of vector data samples from vector registers <b>302</b>.<b>1</b>-<b>302</b>.N, writing vector data samples to the local buffers <b>308</b>.<b>1</b>-<b>308</b>.N, reading vector data samples from the local buffers <b>308</b>.<b>1</b>-<b>308</b>.N, the calculations identified with various vector processing operations, writing the results of vector processing operation results to the local buffers <b>308</b>.<b>1</b>-<b>308</b>.N, etc.</p><p id="p-0121" num="0110">The executable instructions stored in the vector processing data management module <b>813</b> may facilitate, in conjunction with execution via the processing circuitry <b>802</b>, the determination of when the calculated results of vector processing operations are completed and stored in the appropriate buffer <b>308</b>.<b>1</b>-<b>308</b>.N of an execution unit <b>304</b>.<b>1</b>-<b>304</b>.N. This may include writing the results in one or more vector registers <b>302</b>.<b>1</b>-<b>302</b>.N and/or sending the vector data sample results to the vector data memory <b>301</b> and/or the I/O data to be utilized by the appropriate components of the device <b>800</b> or other suitable device.</p><p id="p-0122" num="0111">General Operation of a Vector Processor Architecture and a Wireless Device</p><p id="p-0123" num="0112">A vector processing unit is provided. With reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the vector processing unit includes a buffer configured to store a set of vector data samples that are retrieved from at least one vector register; and vector processing circuitry configured to perform, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on the set of vector data samples read from the buffer. The vector processing instruction is received during a single clock cycle, and at least one respective one of the plurality of fields is associated with an individual vector processor instruction, the vector processing circuitry being configured to perform the plurality of vector processing operations in accordance with each of the individual vector processor instructions. The plurality of fields includes a read pointer indicating a starting address location in the buffer from which the set of vector data samples are read to begin performing the plurality of vector processing operations. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, the buffer comprises an input buffer and an output buffer, the plurality of vector data samples retrieved from the at least one vector register are stored in the input buffer, and results of the vector processing circuitry performing one of the plurality of vector processing operations on the stored set of vector data samples are stored in the output buffer. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, one of the plurality of fields of the fused vector processor instruction is a write pointer indicating a starting address location in the output buffer where the results of the vector processing circuitry performing one of the vector processing operations on the set of vector data samples are stored. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, the buffer comprises a first buffer, a second buffer, and a third buffer, the plurality of vector data samples retrieved from the at least one vector register are stored in the first buffer, and the vector processing circuitry is configured to (i) perform a first one of the plurality of vector processing operations on the set of vector data samples stored in the first buffer and write the results of performing the first vector processing operation to the second buffer, and (ii) perform a second one of the plurality of vector processing operations on the set of vector data samples stored in the second buffer and write the results of performing the second vector processing operation to the third buffer. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, the vector processor circuitry is configured to perform the plurality of vector processing operations without retrieving additional vector data samples from the at least one vector register. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, the plurality of vector processing operations are digital signal processing operations that are associated with wireless data communications.</p><p id="p-0124" num="0113">A system on a chip (SoC) is provided. With reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the SoC includes a plurality of vector registers; and a plurality of vector processing units, each one of the plurality of vector processing units comprising: a buffer configured to store a set of vector data samples that are retrieved from at least one vector register; and vector processing circuitry configured to perform, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on the set of vector data samples read from the buffer, wherein the vector processing instruction is received during a single clock cycle, and wherein at least one respective one of the plurality of fields is associated with an individual vector processor instruction, the vector processing circuitry being configured to perform the plurality of vector processing operations in accordance with each of the individual vector processor instructions. The plurality of fields includes a read pointer indicating a starting address location in the buffer from which the set of vector data samples are read to begin performing the plurality of vector processing operations. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, the buffer comprises an input buffer and an output buffer, the plurality of vector data samples retrieved from the at least one vector register are stored in the input buffer, and results of the vector processing circuitry performing one of the plurality of vector processing operations on the stored set of vector data samples are stored in the output buffer. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, one of the plurality of fields of the fused vector processor instruction is a write pointer indicating a starting address location in the output buffer where the results of the vector processing circuitry performing one of the vector processing operations on the set of vector data samples are stored. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, the buffer comprises a first buffer, a second buffer, and a third buffer, the plurality of vector data samples retrieved from the at least one vector register are stored in the first buffer, and the vector processing circuitry is configured to (i) perform a first one of the plurality of vector processing operations on the set of vector data samples stored in the first buffer and write the results of performing the first vector processing operation to the second buffer, and (ii) perform a second one of the plurality of vector processing operations on the set of vector data samples stored in the second buffer and write the results of performing the second vector processing operation to the third buffer. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, the vector processor circuitry is configured to perform the plurality of vector processing operations without retrieving additional vector data samples from the at least one vector register. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, the plurality of vector processing operations are digital signal processing operations that are associated with wireless data communications.</p><p id="p-0125" num="0114">A wireless device is provided. With reference to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the wireless device includes a transceiver configured to wirelessly transmit and receive data; a plurality of vector registers; and a plurality of vector processing units, each one of the plurality of vector processing units comprising: a buffer configured to store a set of vector data samples that are retrieved from at least one vector register; and vector processing circuitry configured to perform, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on the set of vector data samples read from the buffer, wherein the vector processing instruction is received during a single clock cycle, wherein at least one respective one of the plurality of fields is associated with an individual vector processor instruction, the vector processing circuitry being configured to perform the plurality of vector processing operations in accordance with each of the individual vector processor instructions, and wherein the plurality of vector processing operations are digital signal processing operations performed in accordance with data wirelessly transmitted or received via the transceiver. The plurality of fields includes a read pointer indicating a starting address location in the buffer from which the set of vector data samples are read to begin performing the plurality of vector processing operations. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, the buffer comprises an input buffer and an output buffer, the plurality of vector data samples retrieved from the at least one vector register are stored in the input buffer, and results of the vector processing circuitry performing one of the plurality of vector processing operations on the stored set of vector data samples are stored in the output buffer. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, one of the plurality of fields of the fused vector processor instruction is a write pointer indicating a starting address location in the output buffer where the results of the vector processing circuitry performing one of the vector processing operations on the set of vector data samples are stored. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, the buffer comprises a first buffer, a second buffer, and a third buffer, the plurality of vector data samples retrieved from the at least one vector register are stored in the first buffer, and the vector processing circuitry is configured to (i) perform a first one of the plurality of vector processing operations on the set of vector data samples stored in the first buffer and write the results of performing the first vector processing operation to the second buffer, and (ii) perform a second one of the plurality of vector processing operations on the set of vector data samples stored in the second buffer and write the results of performing the second vector processing operation to the third buffer. In addition or in alternative to and in any combination with the optional features previously explained in this paragraph, the vector processor circuitry is configured to perform the plurality of vector processing operations without retrieving additional vector data samples from the at least one vector register.</p><p id="p-0126" num="0115">Process Flow</p><p id="p-0127" num="0116"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a process flow. With reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the process flow <b>900</b> may be a computer-implemented method executed by and/or otherwise associated with one or more processors (processing circuitry) and/or storage devices. These processors and/or storage devices may be associated with one or more components of the vector processor architecture <b>300</b> as discussed herein and/or one or more components of the device <b>800</b> as discussed herein. The processors and/or storage devices may be identified with the one or more execution units <b>304</b>.<b>1</b>-<b>304</b>.N and/or processor circuitry <b>310</b>.<b>1</b>-<b>310</b>.N executing vector processor instructions. The flow <b>900</b> may include alternate or additional steps that are not shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref> for purposes of brevity, and may be performed in a different order than the steps shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0128" num="0117">Flow <b>8900</b> may begin when one or more processors receive (block <b>902</b>) a fused vector processor instruction includes several fields that indicate several individual vector processing operations to be performed (i.e. executed). This fused vector processor instruction may be received from any suitable component that implements the vector processor architecture as discussed herein.</p><p id="p-0129" num="0118">Flow <b>900</b> may include one or more processors, in response to receiving the fused vector processor instruction, retrieving (block <b>904</b>) vector data samples from one or more of the vector registers <b>302</b>.<b>1</b>-<b>302</b>.N and writing (block <b>902</b>) the retrieved vector data samples to a local buffer (such as one of buffers <b>308</b>.<b>1</b>-<b>308</b>.N) associated with an execution unit <b>304</b>.<b>1</b>-<b>304</b>.N. These vector processing operations may be executed in accordance with the encoded data fields included in the fused vector processor instruction as noted herein.</p><p id="p-0130" num="0119">Flow <b>900</b> may include one or more processors performing (block <b>906</b>) vector processing operations on vector data samples read from a local buffer. This may include the use of the encoded data fields included in the fused vector processor instruction as noted herein, which may include a read pointer identifying the starting address location in the buffer from which the vector data samples are to be read. This may also include the one or more processors writing (block <b>908</b>) the results of performing the vector processing operations on the read vector data samples to the buffer. This may include the encoded data fields included in the fused vector processor instruction as noted herein, which may include a write pointer identifying the starting address location in the buffer to which the vector data samples are to be written. Again, any suitable number of vector processing operations may be performed via the use of subsequent vector processor instructions, as discussed herein, such that several vector processing operations may be executed for a single fused vector processor instruction using the local execution unit buffers <b>308</b>.<b>1</b>-<b>308</b>.N as discussed herein.</p><heading id="h-0005" level="1">Examples</heading><p id="p-0131" num="0120">The following examples pertain to various techniques of the present disclosure.</p><p id="p-0132" num="0121">An example (e.g. example 1) relates to a vector processing unit. The vector processing unit includes a buffer configured to store a set of vector data samples that are retrieved from at least one vector register; and vector processing circuitry configured to perform, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on the set of vector data samples read from the buffer. The vector processing instruction is received during a single clock cycle, and at least one respective one of the plurality of fields is associated with an individual vector processor instruction, the vector processing circuitry being configured to perform the plurality of vector processing operations in accordance with each of the individual vector processor instructions.</p><p id="p-0133" num="0122">Another example (e.g. example 2) relates to a previously-described example (e.g. example 1), wherein the plurality of fields includes a read pointer indicating a starting address location in the buffer from which the set of vector data samples are read to begin performing the plurality of vector processing operations.</p><p id="p-0134" num="0123">Another example (e.g. example 3) relates to a previously-described example (e.g. one or more of examples 1-2), wherein the buffer comprises an input buffer and an output buffer, the plurality of vector data samples retrieved from the at least one vector register are stored in the input buffer, and results of the vector processing circuitry performing one of the plurality of vector processing operations on the stored set of vector data samples are stored in the output buffer.</p><p id="p-0135" num="0124">Another example (e.g. example 4) relates to a previously-described example (e.g. one or more of examples 1-3), wherein one of the plurality of fields of the fused vector processor instruction is a write pointer indicating a starting address location in the output buffer where the results of the vector processing circuitry performing one of the vector processing operations on the set of vector data samples are stored.</p><p id="p-0136" num="0125">Another example (e.g. example 5) relates to a previously-described example (e.g. one or more of examples 1-4), wherein the buffer comprises a first buffer, a second buffer, and a third buffer, the plurality of vector data samples retrieved from the at least one vector register are stored in the first buffer, and the vector processing circuitry is configured to (i) perform a first one of the plurality of vector processing operations on the set of vector data samples stored in the first buffer and write the results of performing the first vector processing operation to the second buffer, and (ii) perform a second one of the plurality of vector processing operations on the set of vector data samples stored in the second buffer and write the results of performing the second vector processing operation to the third buffer.</p><p id="p-0137" num="0126">Another example (e.g. example 6) relates to a previously-described example (e.g. one or more of examples 1-5), wherein the vector processor circuitry is configured to perform the plurality of vector processing operations without retrieving additional vector data samples from the at least one vector register.</p><p id="p-0138" num="0127">Another example (e.g. example 7) relates to a previously-described example (e.g. one or more of examples 1-6), wherein the plurality of vector processing operations are digital signal processing operations that are associated with wireless data communications.</p><p id="p-0139" num="0128">An example (e.g. example 8) relates to a system on a chip (SoC). The SoC includes a plurality of vector registers; and a plurality of vector processing units, each one of the plurality of vector processing units comprising: a buffer configured to store a set of vector data samples that are retrieved from at least one vector register; and vector processing circuitry configured to perform, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on the set of vector data samples read from the buffer, wherein the vector processing instruction is received during a single clock cycle, and wherein at least one respective one of the plurality of fields is associated with an individual vector processor instruction, the vector processing circuitry being configured to perform the plurality of vector processing operations in accordance with each of the individual vector processor instructions.</p><p id="p-0140" num="0129">Another example (e.g. example 9) relates to a previously-described example (e.g. example 8), wherein the plurality of fields includes a read pointer indicating a starting address location in the buffer from which the set of vector data samples are read to begin performing the plurality of vector processing operations.</p><p id="p-0141" num="0130">Another example (e.g. example 10) relates to a previously-described example (e.g. one or more of examples 8-9), wherein: the buffer comprises an input buffer and an output buffer, the plurality of vector data samples retrieved from the at least one vector register are stored in the input buffer, and results of the vector processing circuitry performing one of the plurality of vector processing operations on the stored set of vector data samples are stored in the output buffer.</p><p id="p-0142" num="0131">Another example (e.g. example 11) relates to a previously-described example (e.g. one or more of examples 8-10), wherein one of the plurality of fields of the fused vector processor instruction is a write pointer indicating a starting address location in the output buffer where the results of the vector processing circuitry performing one of the vector processing operations on the set of vector data samples are stored.</p><p id="p-0143" num="0132">Another example (e.g. example 12) relates to a previously-described example (e.g. one or more of examples 8-11), wherein: the buffer comprises a first buffer, a second buffer, and a third buffer, the plurality of vector data samples retrieved from the at least one vector register are stored in the first buffer, and the vector processing circuitry is configured to (i) perform a first one of the plurality of vector processing operations on the set of vector data samples stored in the first buffer and write the results of performing the first vector processing operation to the second buffer, and (ii) perform a second one of the plurality of vector processing operations on the set of vector data samples stored in the second buffer and write the results of performing the second vector processing operation to the third buffer.</p><p id="p-0144" num="0133">Another example (e.g. example 13) relates to a previously-described example (e.g. one or more of examples 8-12), wherein the vector processor circuitry is configured to perform the plurality of vector processing operations without retrieving additional vector data samples from the at least one vector register.</p><p id="p-0145" num="0134">Another example (e.g. example 14) relates to a previously-described example (e.g. one or more of examples 8-13), wherein the plurality of vector processing operations are digital signal processing operations that are associated with wireless data communications.</p><p id="p-0146" num="0135">An example (e.g. example 15) relates to wireless device. The wireless device includes a transceiver configured to wirelessly transmit and receive data; a plurality of vector registers; and a plurality of vector processing units, each one of the plurality of vector processing units comprising: a buffer configured to store a set of vector data samples that are retrieved from at least one vector register; and vector processing circuitry configured to perform, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on the set of vector data samples read from the buffer, wherein the vector processing instruction is received during a single clock cycle, wherein at least one respective one of the plurality of fields is associated with an individual vector processor instruction, the vector processing circuitry being configured to perform the plurality of vector processing operations in accordance with each of the individual vector processor instructions, and wherein the plurality of vector processing operations are digital signal processing operations performed in accordance with data wirelessly transmitted or received via the transceiver.</p><p id="p-0147" num="0136">Another example (e.g. example 16) relates to a previously-described example (e.g. example 15), wherein the plurality of fields includes a read pointer indicating a starting address location in the buffer from which the set of vector data samples are read to begin performing the plurality of vector processing operations.</p><p id="p-0148" num="0137">Another example (e.g. example 17) relates to a previously-described example (e.g. one or more of examples 15-16), wherein: the buffer comprises an input buffer and an output buffer, the plurality of vector data samples retrieved from the at least one vector register are stored in the input buffer, and results of the vector processing circuitry performing one of the plurality of vector processing operations on the stored set of vector data samples are stored in the output buffer.</p><p id="p-0149" num="0138">Another example (e.g. example 18) relates to a previously-described example (e.g. one or more of examples 15-17), wherein one of the plurality of fields of the fused vector processor instruction is a write pointer indicating a starting address location in the output buffer where the results of the vector processing circuitry performing one of the vector processing operations on the set of vector data samples are stored.</p><p id="p-0150" num="0139">Another example (e.g. example 19) relates to a previously-described example (e.g. one or more of examples 15-18), wherein: the buffer comprises a first buffer, a second buffer, and a third buffer, the plurality of vector data samples retrieved from the at least one vector register are stored in the first buffer, and the vector processing circuitry is configured to (i) perform a first one of the plurality of vector processing operations on the set of vector data samples stored in the first buffer and write the results of performing the first vector processing operation to the second buffer, and (ii) perform a second one of the plurality of vector processing operations on the set of vector data samples stored in the second buffer and write the results of performing the second vector processing operation to the third buffer.</p><p id="p-0151" num="0140">Another example (e.g. example 20) relates to a previously-described example (e.g. one or more of examples 15-19), wherein the vector processor circuitry is configured to perform the plurality of vector processing operations without retrieving additional vector data samples from the at least one vector register.</p><p id="p-0152" num="0141">An example (e.g. example 21) relates to a vector processing unit. The vector processing unit includes a buffer means for storing a set of vector data samples that are retrieved from at least one vector register means; and vector processing means for performing, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on the set of vector data samples read from the buffer means. The vector processing instruction is received during a single clock cycle, and at least one respective one of the plurality of fields is associated with an individual vector processor instruction, the vector processing means performing the plurality of vector processing operations in accordance with each of the individual vector processor instructions.</p><p id="p-0153" num="0142">Another example (e.g. example 22) relates to a previously-described example (e.g. example 21), wherein the plurality of fields includes a read pointer indicating a starting address location in the buffer means from which the set of vector data samples are read to begin performing the plurality of vector processing operations.</p><p id="p-0154" num="0143">Another example (e.g. example 23) relates to a previously-described example (e.g. one or more of examples 21-22), wherein the buffer means comprises an input buffer and an output buffer, the plurality of vector data samples retrieved from the at least one vector register means are stored in the input buffer, and results of the vector processing means performing one of the plurality of vector processing operations on the stored set of vector data samples are stored in the output buffer.</p><p id="p-0155" num="0144">Another example (e.g. example 24) relates to a previously-described example (e.g. one or more of examples 21-23), wherein one of the plurality of fields of the fused vector processor instruction is a write pointer indicating a starting address location in the output buffer where the results of the vector processing means performing one of the vector processing operations on the set of vector data samples are stored.</p><p id="p-0156" num="0145">Another example (e.g. example 25) relates to a previously-described example (e.g. one or more of examples 21-24), wherein the buffer means comprises a first buffer, a second buffer, and a third buffer, the plurality of vector data samples retrieved from the at least one vector register means are stored in the first buffer, and the vector processing means (i) performs a first one of the plurality of vector processing operations on the set of vector data samples stored in the first buffer and writes the results of performing the first vector processing operation to the second buffer, and (ii) performs a second one of the plurality of vector processing operations on the set of vector data samples stored in the second buffer and writes the results of performing the second vector processing operation to the third buffer.</p><p id="p-0157" num="0146">Another example (e.g. example 26) relates to a previously-described example (e.g. one or more of examples 21-25), wherein the vector processor means performs the plurality of vector processing operations without retrieving additional vector data samples from the at least one vector register means.</p><p id="p-0158" num="0147">Another example (e.g. example 27) relates to a previously-described example (e.g. one or more of examples 21-26), wherein the plurality of vector processing operations are digital signal processing operations that are associated with wireless data communications.</p><p id="p-0159" num="0148">An example (e.g. example 28) relates to a system on a chip (SoC). The SoC includes a plurality of vector register means; and a plurality of vector processing units, each one of the plurality of vector processing units comprising: a buffer means for storing a set of vector data samples that are retrieved from at least one vector register means; and vector processing means for performing, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on the set of vector data samples read from the buffer means, wherein the vector processing instruction is received during a single clock cycle, and wherein at least one respective one of the plurality of fields is associated with an individual vector processor instruction, the vector processing means performing the plurality of vector processing operations in accordance with each of the individual vector processor instructions.</p><p id="p-0160" num="0149">Another example (e.g. example 29) relates to a previously-described example (e.g. example 28), wherein the plurality of fields includes a read pointer indicating a starting address location in the buffer means from which the set of vector data samples are read to begin performing the plurality of vector processing operations.</p><p id="p-0161" num="0150">Another example (e.g. example 30) relates to a previously-described example (e.g. one or more of examples 28-29), wherein: the buffer means comprises an input buffer and an output buffer, the plurality of vector data samples retrieved from the at least one vector register means are stored in the input buffer, and results of the vector processing means performing one of the plurality of vector processing operations on the stored set of vector data samples are stored in the output buffer.</p><p id="p-0162" num="0151">Another example (e.g. example 31) relates to a previously-described example (e.g. one or more of examples 28-30), wherein one of the plurality of fields of the fused vector processor instruction is a write pointer indicating a starting address location in the output buffer where the results of the vector processing means performing one of the vector processing operations on the set of vector data samples are stored.</p><p id="p-0163" num="0152">Another example (e.g. example 32) relates to a previously-described example (e.g. one or more of examples 28-31), wherein: the buffer means comprises a first buffer, a second buffer, and a third buffer, the plurality of vector data samples retrieved from the at least one vector register means are stored in the first buffer, and the vector processing means (i) performs a first one of the plurality of vector processing operations on the set of vector data samples stored in the first buffer and writes the results of performing the first vector processing operation to the second buffer, and (ii) performs a second one of the plurality of vector processing operations on the set of vector data samples stored in the second buffer and writes the results of performing the second vector processing operation to the third buffer.</p><p id="p-0164" num="0153">Another example (e.g. example 33) relates to a previously-described example (e.g. one or more of examples 28-32), wherein the vector processor means performs the plurality of vector processing operations without retrieving additional vector data samples from the at least one vector register means.</p><p id="p-0165" num="0154">Another example (e.g. example 34) relates to a previously-described example (e.g. one or more of examples 28-33), wherein the plurality of vector processing operations are digital signal processing operations that are associated with wireless data communications.</p><p id="p-0166" num="0155">An example (e.g. example 35) relates to wireless device. The wireless device includes a transceiver means for wirelessly transmitting and receiving data; a plurality of vector register means; and a plurality of vector processing units, each one of the plurality of vector processing units comprising: a buffer means for storing a set of vector data samples that are retrieved from at least one vector register; and vector processing means for performing, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on the set of vector data samples read from the buffer, wherein the vector processing instruction is received during a single clock cycle, wherein at least one respective one of the plurality of fields is associated with an individual vector processor instruction, the vector processing means performing the plurality of vector processing operations in accordance with each of the individual vector processor instructions, and wherein the plurality of vector processing operations are digital signal processing operations performed in accordance with data wirelessly transmitted or received via the transceiver means.</p><p id="p-0167" num="0156">Another example (e.g. example 36) relates to a previously-described example (e.g. example 35), wherein the plurality of fields includes a read pointer indicating a starting address location in the buffer from which the set of vector data samples are read to begin performing the plurality of vector processing operations.</p><p id="p-0168" num="0157">Another example (e.g. example 37) relates to a previously-described example (e.g. one or more of examples 35-36), wherein: the buffer means comprises an input buffer and an output buffer, the plurality of vector data samples retrieved from the at least one vector register means are stored in the input buffer, and results of the vector processing means performing one of the plurality of vector processing operations on the stored set of vector data samples are stored in the output buffer.</p><p id="p-0169" num="0158">Another example (e.g. example 38) relates to a previously-described example (e.g. one or more of examples 35-37), wherein one of the plurality of fields of the fused vector processor instruction is a write pointer indicating a starting address location in the output buffer where the results of the vector processing means performing one of the vector processing operations on the set of vector data samples are stored.</p><p id="p-0170" num="0159">Another example (e.g. example 39) relates to a previously-described example (e.g. one or more of examples 35-38), wherein: the buffer means comprises a first buffer, a second buffer, and a third buffer, the plurality of vector data samples retrieved from the at least one vector register means are stored in the first buffer, and the vector processing means (i) performs a first one of the plurality of vector processing operations on the set of vector data samples stored in the first buffer and writes the results of performing the first vector processing operation to the second buffer, and (ii) performs a second one of the plurality of vector processing operations on the set of vector data samples stored in the second buffer and writes the results of performing the second vector processing operation to the third buffer.</p><p id="p-0171" num="0160">Another example (e.g. example 40) relates to a previously-described example (e.g. one or more of examples 35-39), wherein the vector processor means performs the plurality of vector processing operations without retrieving additional vector data samples from the at least one vector register means.</p><p id="p-0172" num="0161">An apparatus as shown and described.</p><p id="p-0173" num="0162">A method as shown and described.</p><heading id="h-0006" level="1">CONCLUSION</heading><p id="p-0174" num="0163">The aforementioned description will so fully reveal the general nature of the disclosure that others can, by applying knowledge within the skill of the art, readily modify and/or adapt for various applications without undue experimentation, and without departing from the general concept of the present disclosure. Therefore, such adaptations and modifications are intended to be within the meaning and range of equivalents of the disclosed implementations, based on the teaching and guidance presented herein. It is to be understood that the phraseology or terminology herein is for the purpose of description and not of limitation, such that the terminology or phraseology of the present specification is to be interpreted by the skilled artisan in light of the teachings and guidance.</p><p id="p-0175" num="0164">References in the specification to &#x201c;one implementation,&#x201d; &#x201c;an implementation,&#x201d; &#x201c;an exemplary implementation,&#x201d; etc., indicate that the implementation described may include a particular feature, structure, or characteristic, but every implementation may not necessarily include the particular feature, structure, or characteristic. Moreover, such phrases are not necessarily referring to the same implementation. Further, when a particular feature, structure, or characteristic is described in connection with an implementation, it is submitted that it is within the knowledge of one skilled in the art to affect such feature, structure, or characteristic in connection with other implementations whether or not explicitly described.</p><p id="p-0176" num="0165">The implementation described herein are provided for illustrative purposes, and are not limiting. Other implementation are possible, and modifications may be made to the described implementations. Therefore, the specification is not meant to limit the disclosure. Rather, the scope of the disclosure is defined only in accordance with the following claims and their equivalents.</p><p id="p-0177" num="0166">The implementations described herein may be facilitated in hardware (e.g., circuits), firmware, software, or any combination thereof. Implementations may also be implemented as instructions stored on a machine-readable medium, which may be read and executed by one or more processors. A machine-readable medium may include any mechanism for storing or transmitting information in a form readable by a machine (e.g., a computing device). For example, a machine-readable medium may include read only memory (ROM); random access memory (RAM); magnetic disk storage media; optical storage media; flash memory devices; electrical, optical, acoustical or other forms of propagated signals (e.g., carrier waves, infrared signals, digital signals, etc.), and others. Further, firmware, software, routines, instructions may be described herein as performing certain actions. However, it should be appreciated that such descriptions are merely for convenience and that such actions in fact results from computing devices, processors, controllers, or other devices executing the firmware, software, routines, instructions, etc. Further, any of the implementation variations may be carried out by a general purpose computer.</p><p id="p-0178" num="0167">For the purposes of this discussion, the term &#x201c;processing circuitry&#x201d; or &#x201c;processor circuitry&#x201d; shall be understood to be circuit(s), processor(s), logic, or a combination thereof. For example, a circuit can include an analog circuit, a digital circuit, state machine logic, other structural electronic hardware, or a combination thereof. A processor can include a microprocessor, a digital signal processor (DSP), or other hardware processor. The processor can be &#x201c;hard-coded&#x201d; with instructions to perform corresponding function(s) according to implementations described herein. Alternatively, the processor can access an internal and/or external memory to retrieve instructions stored in the memory, which when executed by the processor, perform the corresponding function(s) associated with the processor, and/or one or more functions and/or operations related to the operation of a component having the processor included therein.</p><p id="p-0179" num="0168">In one or more of the implementations described herein, processing circuitry can include memory that stores data and/or instructions. The memory can be any well-known volatile and/or non-volatile memory, including, for example, read-only memory (ROM), random access memory (RAM), flash memory, a magnetic storage media, an optical disc, erasable programmable read only memory (EPROM), and programmable read only memory (PROM). The memory can be non-removable, removable, or a combination of both.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230004389A1-20230105-M00001.NB"><img id="EMI-M00001" he="5.67mm" wi="76.20mm" file="US20230004389A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230004389A1-20230105-M00002.NB"><img id="EMI-M00002" he="6.35mm" wi="76.20mm" file="US20230004389A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00003" nb-file="US20230004389A1-20230105-M00003.NB"><img id="EMI-M00003" he="6.69mm" wi="5.67mm" file="US20230004389A1-20230105-M00003.TIF" alt="embedded image " img-content="table" img-format="tif"/></us-math><us-math idrefs="MATH-US-00004" nb-file="US20230004389A1-20230105-M00004.NB"><img id="EMI-M00004" he="5.67mm" wi="5.25mm" file="US20230004389A1-20230105-M00004.TIF" alt="embedded image " img-content="table" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A vector processing unit, comprising:<claim-text>a buffer configured to store a set of vector data samples that are retrieved from at least one vector register; and</claim-text><claim-text>vector processing circuitry configured to perform, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on the set of vector data samples read from the buffer,</claim-text><claim-text>wherein the vector processing instruction is received during a single clock cycle, and</claim-text><claim-text>wherein at least one respective one of the plurality of fields is associated with an individual vector processor instruction, the vector processing circuitry being configured to perform the plurality of vector processing operations in accordance with each of the individual vector processor instructions.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The vector processing unit of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of fields includes a read pointer indicating a starting address location in the buffer from which the set of vector data samples are read to begin performing the plurality of vector processing operations.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The vector processing unit of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the buffer comprises an input buffer and an output buffer,</claim-text><claim-text>the plurality of vector data samples retrieved from the at least one vector register are stored in the input buffer, and</claim-text><claim-text>results of the vector processing circuitry performing one of the plurality of vector processing operations on the stored set of vector data samples are stored in the output buffer.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The vector processing unit of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein one of the plurality of fields of the fused vector processor instruction is a write pointer indicating a starting address location in the output buffer where the results of the vector processing circuitry performing one of the vector processing operations on the set of vector data samples are stored.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The vector processing unit of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the buffer comprises a first buffer, a second buffer, and a third buffer,</claim-text><claim-text>the plurality of vector data samples retrieved from the at least one vector register are stored in the first buffer, and</claim-text><claim-text>the vector processing circuitry is configured to (i) perform a first one of the plurality of vector processing operations on the set of vector data samples stored in the first buffer and write the results of performing the first vector processing operation to the second buffer, and (ii) perform a second one of the plurality of vector processing operations on the set of vector data samples stored in the second buffer and write the results of performing the second vector processing operation to the third buffer.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The vector processing unit of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the vector processor circuitry is configured to perform the plurality of vector processing operations without retrieving additional vector data samples from the at least one vector register.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The vector processing unit of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of vector processing operations are digital signal processing operations that are associated with wireless data communications.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A system on a chip (SoC), comprising:<claim-text>a plurality of vector registers; and</claim-text><claim-text>a plurality of vector processing units, each one of the plurality of vector processing units comprising:<claim-text>a buffer configured to store a set of vector data samples that are retrieved from at least one vector register; and</claim-text><claim-text>vector processing circuitry configured to perform, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on the set of vector data samples read from the buffer,</claim-text></claim-text><claim-text>wherein the vector processing instruction is received during a single clock cycle, and</claim-text><claim-text>wherein at least one respective one of the plurality of fields is associated with an individual vector processor instruction, the vector processing circuitry being configured to perform the plurality of vector processing operations in accordance with each of the individual vector processor instructions.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The SoC of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the plurality of fields includes a read pointer indicating a starting address location in the buffer from which the set of vector data samples are read to begin performing the plurality of vector processing operations.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The SoC of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein:<claim-text>the buffer comprises an input buffer and an output buffer,</claim-text><claim-text>the plurality of vector data samples retrieved from the at least one vector register are stored in the input buffer, and</claim-text><claim-text>results of the vector processing circuitry performing one of the plurality of vector processing operations on the stored set of vector data samples are stored in the output buffer.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The SoC of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein one of the plurality of fields of the fused vector processor instruction is a write pointer indicating a starting address location in the output buffer where the results of the vector processing circuitry performing one of the vector processing operations on the set of vector data samples are stored.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The SoC of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein:<claim-text>the buffer comprises a first buffer, a second buffer, and a third buffer,</claim-text><claim-text>the plurality of vector data samples retrieved from the at least one vector register are stored in the first buffer, and</claim-text><claim-text>the vector processing circuitry is configured to (i) perform a first one of the plurality of vector processing operations on the set of vector data samples stored in the first buffer and write the results of performing the first vector processing operation to the second buffer, and (ii) perform a second one of the plurality of vector processing operations on the set of vector data samples stored in the second buffer and write the results of performing the second vector processing operation to the third buffer.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The SoC of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the vector processor circuitry is configured to perform the plurality of vector processing operations without retrieving additional vector data samples from the at least one vector register.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The SoC of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the plurality of vector processing operations are digital signal processing operations that are associated with wireless data communications.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A wireless device, comprising:<claim-text>a transceiver configured to wirelessly transmit and receive data;</claim-text><claim-text>a plurality of vector registers; and</claim-text><claim-text>a plurality of vector processing units, each one of the plurality of vector processing units comprising:<claim-text>a buffer configured to store a set of vector data samples that are retrieved from at least one vector register; and</claim-text><claim-text>vector processing circuitry configured to perform, in response to receiving a fused vector processor instruction having a plurality of fields, a plurality of vector processing operations on the set of vector data samples read from the buffer,</claim-text></claim-text><claim-text>wherein the vector processing instruction is received during a single clock cycle,</claim-text><claim-text>wherein at least one respective one of the plurality of fields is associated with an individual vector processor instruction, the vector processing circuitry being configured to perform the plurality of vector processing operations in accordance with each of the individual vector processor instructions, and</claim-text><claim-text>wherein the plurality of vector processing operations are digital signal processing operations performed in accordance with data wirelessly transmitted or received via the transceiver.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The wireless device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the plurality of fields includes a read pointer indicating a starting address location in the buffer from which the set of vector data samples are read to begin performing the plurality of vector processing operations.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The wireless device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein:<claim-text>the buffer comprises an input buffer and an output buffer,</claim-text><claim-text>the plurality of vector data samples retrieved from the at least one vector register are stored in the input buffer, and</claim-text><claim-text>results of the vector processing circuitry performing one of the plurality of vector processing operations on the stored set of vector data samples are stored in the output buffer.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The wireless device of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein one of the plurality of fields of the fused vector processor instruction is a write pointer indicating a starting address location in the output buffer where the results of the vector processing circuitry performing one of the vector processing operations on the set of vector data samples are stored.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The wireless device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein:<claim-text>the buffer comprises a first buffer, a second buffer, and a third buffer,</claim-text><claim-text>the plurality of vector data samples retrieved from the at least one vector register are stored in the first buffer, and</claim-text><claim-text>the vector processing circuitry is configured to (i) perform a first one of the plurality of vector processing operations on the set of vector data samples stored in the first buffer and write the results of performing the first vector processing operation to the second buffer, and (ii) perform a second one of the plurality of vector processing operations on the set of vector data samples stored in the second buffer and write the results of performing the second vector processing operation to the third buffer.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The wireless device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the vector processor circuitry is configured to perform the plurality of vector processing operations without retrieving additional vector data samples from the at least one vector register.</claim-text></claim></claims></us-patent-application>
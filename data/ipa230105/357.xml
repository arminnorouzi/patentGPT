<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000358A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000358</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17931463</doc-number><date>20220912</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>55</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>024</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>1455</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>0077</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>55</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>02427</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>0806</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>14552</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>742</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>746</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>0012</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10024</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10028</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10048</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30196</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">ATTACHED SENSOR ACTIVATION OF ADDITIONALLY-STREAMED PHYSIOLOGICAL PARAMETERS FROM NON-CONTACT MONITORING SYSTEMS AND ASSOCIATED DEVICES, SYSTEMS, AND METHODS</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16778312</doc-number><date>20200131</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11484208</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17931463</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Covidien LP</orgname><address><city>Mansfield</city><state>MA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>ADDISON</last-name><first-name>Paul S.</first-name><address><city>Edinburgh</city><country>GB</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present technology relates to the field of medical monitoring. Patient monitoring systems and associated devices, methods, and computer readable media are described. In some embodiments, a patient monitoring system includes one or more sensors configured to capture first data related to a patient and a monitoring device configured to receive the first data. In these and other embodiments, the patient monitoring system can include an image capture device configured to capture second data related to the patient. In these and still other embodiments, the one or more sensors can be configured to instruct the patient monitoring system to display the second data.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="129.46mm" wi="158.75mm" file="US20230000358A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="181.02mm" wi="158.75mm" file="US20230000358A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="167.13mm" wi="147.83mm" orientation="landscape" file="US20230000358A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="198.54mm" wi="161.80mm" file="US20230000358A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="189.99mm" wi="96.94mm" file="US20230000358A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="224.54mm" wi="159.43mm" file="US20230000358A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application is a continuation application of U.S. application Ser. No. 16/778,312 filed Jan. 31, 2000, entitled &#x201c;Attached Sensor Activation of Additionally-Streamed Physiological Parameters from Noncontact Monitoring Systems and Associated Devices, Systems, and Methods&#x201d;, which is specifically incorporated by reference herein for all that it discloses or teaches.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">The present technology is generally related to non-contact monitoring systems for patients, used in conjunction with attached patient sensors.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Many conventional medical monitors require attachment of a sensor to a patient in order to detect physiologic signals from the patient and to transmit detected signals through a cable to the monitor. These monitors process the received signals and determine vital signs such as the patient's pulse rate, respiration rate, and arterial oxygen saturation. For example, a pulse oximeter is a finger sensor that can include two light emitters and a photodetector. The sensor emits light into the patient's finger and transmits the detected light signal to a monitor. The monitor includes a processor that processes the signal, determines vital signs (e.g., pulse rate, respiration rate, arterial oxygen saturation), and displays the vital signs on a display.</p><p id="p-0005" num="0004">Other monitoring systems include other types of monitors and sensors, such as electroencephalogram (EEG) sensors, blood pressure cuffs, temperature probes, air flow measurement devices (e.g., spirometer), and others. Some wireless, wearable sensors have been developed, such as wireless EEG patches and wireless pulse oximetry sensors.</p><p id="p-0006" num="0005">Video-based monitoring is a field of patient monitoring that uses one or more remote video cameras to detect physical attributes of the patient. This type of monitoring can also be called &#x201c;non-contact&#x201d; monitoring in reference to the remote video sensor(s), which does/do not contact the patient. The remainder of this disclosure offers solutions and improvements in this field.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0007" num="0006">The techniques of this disclosure generally relate to a patient monitoring system including a non-contact monitoring component, used in conjunction with one or more attached patient sensors, with the sensor(s) activating additionally streamed physiological parameters from the non-contact monitoring system.</p><p id="p-0008" num="0007">In one aspect, a first sensor in contact with a patient provides first data to determine one or more patient parameters. A non-contact video monitoring system including an image capture device is programmed to capture second data related to the patient. A monitoring device is configured to receive and display said first data; and either said first sensor or an associated first sensor device is configured to provide instructions to the monitoring device to display said second data.</p><p id="p-0009" num="0008">In another aspect, an additional connecting element is associated with the first sensor, the additional connecting element configured to receive the first data from the one or more sensors and to transmit the first data to the monitoring device.</p><p id="p-0010" num="0009">In another aspect, the first sensor or associated first sensor device is configured to provide instruction as an encrypted key.</p><p id="p-0011" num="0010">In another aspect, the non-contact video monitoring system is programmed to define one or more regions of interest (ROI's) on a patient, capture the second data related to the patient, wherein the second data includes two or more images of the ROI's, and to measure changes in depths of the ROI's across the two or more images of the ROI's.</p><p id="p-0012" num="0011">In another aspect, the image capture device includes a depth sensing camera, an RGB camera, and/or an infrared camera.</p><p id="p-0013" num="0012">In another aspect, instructions to the monitoring device are configured to: allow the monitoring device to include the second data directly onto a current display screen; allow the monitoring device to reconfigure a current screen to display the second data; and/or allow for separate pages to be accessible on the monitoring device for display of the second data.</p><p id="p-0014" num="0013">In other aspects, the first and second data are combined at a monitoring device or are combined prior to receipt at a monitoring device.</p><p id="p-0015" num="0014">The details of one or more aspects of the disclosure are set forth in the accompanying drawings and the description below. Other features, objects, and advantages of the techniques described in this disclosure will be apparent from the description and drawings, and from the claims.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0016" num="0015">Many aspects of the present disclosure can be better understood with reference to the following drawings. The components in the drawings are not necessarily to scale. Instead, emphasis is placed on illustrating clearly the principles of the present disclosure. The drawings should not be taken to limit the disclosure to the specific embodiments depicted, but are for explanation and understanding only.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic view of a patient monitoring system configured with both attached and non-contact monitoring components, in accordance with various embodiments of the present technology;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic view of a patient monitoring system having a probe with an additional connecting element, configured in accordance with various embodiments of the present technology;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic view of patient monitoring systems configured in accordance with various embodiments of the present technology;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram illustrating a patient monitoring system having a computing device, a server, and one or more image capture devices, and configured in accordance with various embodiments of the present technology;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flow diagram illustrating a patient monitoring method for instructing a monitoring device to display attached sensor and NCM data;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic view of a patient monitoring system combining first and second data streams at a monitoring device, configured in accordance with various embodiments of the present technology; and</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a schematic view of a patient monitoring system combining first and second data streams prior to a monitoring device, configured in accordance with various embodiments of the present technology.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0024" num="0023">The following disclosure describes patient monitoring devices, systems, and associated methods for detecting and/or monitoring one or more patient parameters, such as tidal volume, respiratory rate, minute volume, patient movement, temperature, blood pressure, heart rate, arterial oxygen saturation, and/or others. As described in greater detail below, devices, systems, and/or methods configured in accordance with embodiments of the present technology are configured to capture one or more images (e.g., a video sequence) of a patient or a portion of a patient (e.g., a patient's torso) within a field of view of a non-contact detector (e.g., an image capture device). The devices, systems, and/or methods can measure changes in depths of regions (e.g., one or more pixels or groups of pixels) in the captured images over time. Based, at least in part, on these measurements, the devices, systems, and/or methods can determine various respiratory parameters of a patient, including tidal volume, minute volume, and respiratory rate, among others. In these and other embodiments, the device, systems, and/or methods can analyze the respiratory parameters and can trigger alerts and/or alarms when the devices, systems, and/or methods detect one or more breathing abnormalities.</p><p id="p-0025" num="0024">Additionally, devices, systems, and/or methods configured in accordance with embodiments of the present technology can include one or more sensors or probes associated with (e.g., contacting) a patient that can be configured to capture data (e.g., temperature, blood pressure, heart rate, arterial oxygen saturation, etc.) related to a patient. The devices, systems, and/or methods can transmit the captured data to a monitoring device, hub, mobile patient management system (MPM), or the like. In some embodiments, the devices, systems, and/or methods can analyze the captured data to determine and/or monitor one or more patient parameters. In these and other embodiments, the devices, systems, and/or methods can use the data captured by the one or more sensors or probes in conjunction with data captured using a non-contact detector. In these and still other embodiments, the devices, systems, and/or methods can trigger alerts and/or alarms when the devices, systems, and/or methods detect one or more patient parameter abnormalities.</p><p id="p-0026" num="0025">In some embodiments, one or more sensors or probes associated with (e.g., contacting) a patient can be configured to capture data related to a patient and can be configured to activate additionally streamed physiological parameters from non-contact monitoring (NCM) devices. In such cases, one or more sensors or probes and/or one or more associated intermediary devices (e.g., an additional connecting element (ACE)) can be configured to communicate with and instruct a monitoring device, such as a hub, mobile patient management system (MPM), or the like (note that a monitoring device could also be a clinician's data tablet, a central data collection and display system, etc.), to start receiving physiological data from an NCM camera and/or allow such data to be displayed on the screen.</p><p id="p-0027" num="0026">In exemplary embodiments such instruction by a sensor, probe or associated device comprises a key that is transmitted to (either via a wired or wireless connection) and read by the monitoring device. The key can be configured to: allow the monitoring device to include the additional physiological information directly onto a current display screen; allow the device or system to reconfigure a current screen to display the additional physiological information; and/or allow for separate pages to be accessible on the device or system for display of the additional physiological information.</p><p id="p-0028" num="0027">In some exemplary embodiments, sensors or probes that are configured to provide such instruction are provided with marking, for example different color coding, packaging, labeling, etc., to distinguish from standard sensors or probes. In some embodiments, such sensors or probes are configured with a unique or different connector shape and/or connector pin configuration relative to standard sensors or probes.</p><p id="p-0029" num="0028">In some exemplary embodiments, a wireless receiver or additional connecting element (ACE) can collect or pass through the patient sensor or probe information (e.g., pulse oximeter information, or a combination of different types of information from plural patient sensors or probes) as well as receive the additional (NCM) physiological information, passing all of this information on to a monitoring device. Additionally, different wireless receivers or ACE components may be configured to switch on different physiological parameters, for example with one configured only to include respiratory parameters (e.g., respiratory rate, tidal volume, minute volume and central and obstructive apnea detection), whereas others could be configured to only include patient activity and posture information, etc. Accordingly, one or more ACE components may be configured to simultaneously provide information to a monitoring device.</p><p id="p-0030" num="0029">In some embodiments, one or more ACE components may be configured only to when an appropriate/compatible probe is attached. Additionally, it should be recognized that various additional types of sensors and probes are contemplated, including without limitation regional saturation probes, depth of anesthesia (EEG) probes, capnography sidestream probes, etc. Further, the present disclosure contemplates other sources of additional physiological information (in addition to or instead of NCM), including temperature, ETCO2, rSO2 monitors, etc. Also as has been noted above, in some embodiments, a wireless (for example, electromagnetic, LiFi, sonar, etc.) system can be used for one or more transmission paths.</p><p id="p-0031" num="0030">In some exemplary embodiments, data streams are combined and/or switched on prior to sending the streams to the monitoring device.</p><p id="p-0032" num="0031">Specific details of several embodiments of the present technology are described herein with reference to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>6</b></figref>. Although many of the embodiments are described with respect to devices, systems, and methods for detection and/or monitoring of one or more parameters of a human patient, other applications and other embodiments in addition to those described herein are within the scope of the present technology. For example, at least some embodiments of the present technology can be useful for detection and/or monitoring of one or more parameters of other animals and/or in non-patients (e.g., elderly or neonatal individuals within their homes, individuals in a search and rescue or stranded context, etc.). It should be noted that other embodiments in addition to those disclosed herein are within the scope of the present technology. Further, embodiments of the present technology can have different configurations, components, and/or procedures than those shown or described herein. Moreover, a person of ordinary skill in the art will understand that embodiments of the present technology can have configurations, components, and/or procedures in addition to those shown or described herein and that these and other embodiments can be without several of the configurations, components, and/or procedures shown or described herein without deviating from the present technology.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic view of an exemplary monitoring system, shown generally at <b>100</b>, including a non-contact monitoring (NCM) system, shown generally at <b>102</b> and a patient attached probe system, shown generally at <b>104</b>. An exemplary NCM camera <b>106</b> is illustrated in an out-of-contact position with optional wired <b>108</b> and wireless <b>110</b> transmission paths. The patient attached probe system <b>104</b> shows an exemplary finger probe <b>112</b>, attached to a patient <b>114</b>, and an exemplary mobile patient monitoring (MPM) device <b>116</b>, connected to the probe/sensor <b>112</b> via a cable <b>118</b> and a connector <b>120</b>. An optional wireless pathway to/from the device is shown generally at <b>122</b>. <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic view of an exemplary connected probe <b>112</b> and MPM <b>116</b>, with the cable <b>118</b> and connector <b>120</b> first connecting to an additional connecting element (ACE) <b>202</b>.</p><p id="p-0034" num="0033">In some embodiments, the monitoring device can be a monitor with a screen <b>134</b> (e.g., to display various information, such as a power on/off button, one or more patient parameters, one or more alerts and/or alarms, etc.). The monitoring device can be attached to, be worn, and/or otherwise be carried by a patient <b>114</b>. For example, the monitoring device can be attached to and/or worn by the patient <b>114</b> at the patient's upper arm, at the patient's belt, on the patient's wrist (e.g., as a watch and/or using a band), etc. In some embodiments, the monitoring device can be sewn into the patient's clothing. In these and other embodiments, the monitoring device can be a mobile device, such as a mobile phone, tablet, or laptop.</p><p id="p-0035" num="0034">In the embodiments illustrated in <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>, one or more probes/sensors <b>112</b> include a pulse oximeter attached to a finger of the patient. In these and other embodiments, the one or more sensors <b>112</b> can include other sensors in addition to or in lieu of the pulse oximeter, such as electrodes, temperature sensors, blood pressure cuffs, etc. The one or more sensors <b>112</b> can be used to perform various tests and/or to capture various information and data relating to the patient <b>114</b>. For example, the one or more sensors <b>112</b> can be used to capture an electrocardiogram (ECG) signal and/or an electroencephalogram (EEG) signal of the patient. In these and other embodiments, the one or more sensors <b>112</b> can capture the patient's arterial oxygen saturation, temperature, blood pressure, and/or other patient parameters (e.g., systolic and diastolic pressure, heart rate, respiratory rate, average temperature, etc.).</p><p id="p-0036" num="0035">Information captured by the one or more sensors <b>112</b> can be stored and/or processed by the one or more sensors <b>112</b> and/or by the monitoring device. For example, the one or more sensors <b>112</b> can store captured information and/or can locally process the captured information (e.g., to determine one or more patient parameters). In these and other embodiments, the one or more sensors <b>112</b> can transmit the raw, captured information and/or the locally processed data to the monitoring device. For example, the one or more sensors <b>112</b> can include a wireless transmitter (not shown) to transfer the data directly to the monitoring device via a wired or wireless connection (not shown). In turn, the monitoring device can store and/or process the information received from the one or more sensors <b>112</b> (e.g., to determine one or more patient parameters). In these and other embodiments, the monitoring device can transfer the raw, captured information and/or processed data to a central unit (not shown), such as a central hospital station, via a wired or wireless connection (not shown).</p><p id="p-0037" num="0036">Additionally or alternatively, the one or more sensors <b>112</b> can transmit the captured information and/or the locally processed data to a relay (not shown) (e.g., a band attached to the patient) via one or more wired and/or wireless connections. In some embodiments, a relay can store and/or process data received from the one or more sensors. In these and other embodiments, the relay can include a wireless transmitter that can be used to transmit the captured information and/or the processed data to the monitoring device via a wireless connection.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic view of a patient <b>114</b> and a video-based patient monitoring system <b>300</b> configured in accordance with various embodiments of the present technology. The system <b>300</b> includes a non-contact detector <b>310</b> and a computing device <b>315</b>. In some embodiments, the detector <b>310</b> can include one or more image capture devices <b>314</b>, such as one or more video cameras. The non-contact detector <b>310</b> of the system <b>300</b> is placed remote from the patient <b>114</b>. More specifically, the image capture device <b>314</b> of the non-contact detector <b>310</b> is positioned remote from the patient <b>114</b> in that it is spaced apart from and does not contact the patient <b>114</b>. The image capture device <b>314</b> includes a detector exposed to a field of view (FOV) <b>316</b> that encompasses at least a portion of the patient <b>114</b>.</p><p id="p-0039" num="0038">The image capture device <b>314</b> can capture a sequence of images over time. The image capture device <b>314</b> can be a depth sensing camera, such as a Kinect camera from Microsoft Corp. (Redmond, Wash.). A depth sensing camera can detect a distance between the camera and objects within its field of view. Such information can be used, as disclosed herein, to determine that a patient <b>114</b> is within the FOV <b>316</b> of the image capture device <b>314</b> and/or to determine one or more ROI's to monitor on the patient <b>114</b>. Once an ROI is identified, the ROI can be monitored over time, and the changes in depths of regions (e.g., pixels) within the ROI can represent movements of the patient <b>114</b> (e.g., associated with breathing). As described in greater detail in U.S. patent application Ser. No. 16/219,360, U.S. Provisional Patent Application Ser. No. 62/779,964 and U.S. Provisional Patent Application Ser. No. 62/797,519, those movements, or changes of regions within the ROI, can be used to determine various patient parameters, such as various breathing parameters, including tidal volume, minute volume, respiratory rate, etc. Those movements, or changes of regions within the ROI, can also be used to detect various patient parameter abnormalities, as discussed in greater detail in U.S. Provisional Patent Application Ser. Nos. 62/716,724 and 62/779,964. The various patient parameter abnormalities can include, for example, apnea, rapid breathing (tachypnea), slow breathing, intermittent or irregular breathing, shallow breathing, obstructed and/or impaired breathing, and others. The entire disclosures of U.S. patent application Ser. No. 16/219,360 and U.S. Provisional Patent Application Ser. Nos. 62/716,724, 62/779,964 and 62/797,519 are incorporated herein by reference.</p><p id="p-0040" num="0039">In these and other embodiments, the image capture device can be an RGB (red green blue) camera or an infrared camera. An RGB camera can detect slight color changes within its field of view. Such information can be used, as disclosed herein, to determine that a patient <b>114</b> is within the FOV <b>316</b> of the image capture device <b>314</b> and/or to determine one or more ROI's to monitor on the patient <b>114</b>. Once an ROI is identified, the ROI can be monitored over time, and the changes in color of regions (e.g., pixels) within the ROI can represent various information related to the patient <b>114</b>. As described in greater detail in U.S. patent application Ser. No. 16/188,969 those color changes can be used to detect optical signals associated with one or more medical devices, such as a pulse oximeter attached to the patient. Those color changes can also be used to determine and/or monitor various vital signs of the patient, including pulse rate, respiration rate, and arterial oxygen saturation, as discussed in greater detail in U.S. patent application Ser. Nos. 15/432,057, 15/432,063 and 62/797,519. Additionally, or alternatively, as discussed in greater detail in U.S. Provisional Patent Application Ser. Nos. 62/685,485 and 62/695,244, those color changes can also be used in a surgical setting to monitor and/or assess blood flow in the ROI by detecting occlusions and/or monitoring pulsation, pulsation strength, and/or perfusion. The entire disclosures of U.S. patent application Ser. Nos. 16/188,969, 15/432,057, and 15/432,063 and U.S. Provisional Patent Application Ser. Nos. 62/685,485 and 62/695,244 are incorporated herein by reference.</p><p id="p-0041" num="0040">In some embodiments, the system <b>300</b> can receive user input to identify a starting point for defining a ROI. For example, an image can be reproduced on a display <b>322</b> of the system <b>300</b> (or on the display of the monitoring device <b>116</b>), allowing a user of the system <b>300</b> to select a patient <b>114</b> for monitoring (which can be helpful where multiple objects are within the FOV <b>316</b> of the image capture device <b>314</b>) and/or allowing the user to select a point on the patient <b>114</b> from which a ROI can be determined (such as the point <b>303</b> on the chest of the patient <b>114</b>). In other embodiments, other methods for identifying a patient <b>114</b>, for identifying points on the patient <b>114</b>, and/or for defining one or more ROI's can be used. For example, a user can select a patient <b>114</b> for monitoring and a point on a patient bed <b>308</b> (which can be helpful in defining one or more ranges of depths to be used in measurements taken by a non-contact detector).</p><p id="p-0042" num="0041">The images detected by the image capture device <b>314</b> can be sent to the computing device <b>315</b> through a wired or wireless connection <b>320</b>. The computing device <b>315</b> can include a processor <b>318</b> (e.g., a microprocessor), the display <b>322</b>, and/or hardware memory <b>326</b> for storing software and computer instructions. Sequential image frames of the patient <b>114</b> are recorded by the image capture device <b>314</b> and sent to the processor <b>318</b> for analysis. The display <b>322</b> can be remote from the image capture device <b>314</b>, such as a video screen positioned separately from the processor <b>318</b> and the memory <b>326</b>. Other embodiments of the computing device <b>315</b> can have different, fewer, or additional components than shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. In some embodiments, the computing device <b>315</b> can be a server. In other embodiments, the computing device <b>315</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref> can be additionally connected to a server (e.g., as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> and discussed in greater detail below). The captured images/video can be processed or analyzed at the computing device <b>315</b> and/or a server to determine a variety of parameters (e.g., tidal volume, minute volume, respiratory rate, etc.) of a patient.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram illustrating a patient monitoring system <b>400</b> (e.g., the patient monitoring system <b>100</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> and the video-based patient monitoring system <b>300</b> shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, having a computing device <b>410</b>, a server <b>425</b>, and one or more image capture devices <b>485</b>, and configured in accordance with various embodiments of the present technology. In various embodiments, fewer, additional, and/or different components can be used in the system <b>400</b>. The computing device <b>410</b> includes a processor <b>415</b> that is coupled to a memory <b>405</b>. The processor <b>415</b> can store and recall data and applications in the memory <b>405</b>, including applications that process information and send commands/signals according to any of the methods disclosed herein. The processor <b>415</b> can also (i) display objects, applications, data, etc. on an interface/display <b>407</b> and/or (ii) receive inputs through the interface/display <b>407</b>. As shown, the processor <b>415</b> is also coupled to a transceiver <b>420</b>.</p><p id="p-0044" num="0043">The computing device <b>410</b> can communicate with other devices, such as the server <b>425</b> and/or the image capture device(s) <b>485</b> via (e.g., wired or wireless) connections <b>470</b> and/or <b>480</b>, respectively. For example, the computing device <b>410</b> can send to the server <b>425</b> information determined about a patient from images and/or other data captured by the image capture device(s) <b>485</b> and/or one or more other sensors or probes. The computing device <b>410</b> can be located remotely from the image capture device(s) <b>485</b>, or it can be local and close to the image capture device(s) <b>485</b> (e.g., in the same room). In various embodiments disclosed herein, the processor <b>415</b> of the computing device <b>410</b> can perform the steps disclosed herein.</p><p id="p-0045" num="0044">In other embodiments, the steps can be performed on a processor <b>435</b> of the server <b>425</b>. In some embodiments, the various steps and methods disclosed herein can be performed by both of the processors <b>415</b> and <b>435</b>. In some embodiments, certain steps can be performed by the processor <b>415</b> while others are performed by the processor <b>435</b>. In some embodiments, information determined by the processor <b>415</b> can be sent to the server <b>425</b> for storage and/or further processing.</p><p id="p-0046" num="0045">In some embodiments, the image capture device(s) <b>485</b> are remote sensing device(s), such as depth sensing video camera(s) In some embodiments, the image capture device(s) <b>485</b> can be or include some other type(s) of device(s), such as proximity sensors or proximity sensor arrays, heat or infrared sensors/cameras, sound/acoustic or radio wave emitters/detectors, or other devices that include a field of view and can be used to monitor the location and/or characteristics of a patient or a region of interest (ROI) on the patient. Body imaging technology can also be utilized according to the methods disclosed herein. For example, backscatter x-ray or millimeter wave scanning technology can be utilized to scan a patient, which can be used to define and/or monitor a ROI. Advantageously, such technologies can be able to &#x201c;see&#x201d; through clothing, bedding, or other materials while giving an accurate representation of the patient's skin facet. This can allow for more accurate measurements, particularly if the patient is wearing baggy clothing or is under bedding. The image capture device(s) <b>485</b> can be described as local because they are relatively close in proximity to a patient such that at least a part of a patient is within the field of view of the image capture device(s) <b>485</b>. In some embodiments, the image capture device(s) <b>485</b> can be adjustable to ensure that the patient is captured in the field of view. For example, the image capture device(s) <b>485</b> can be physically movable, can have a changeable orientation (such as by rotating or panning), and/or can be capable of changing a focus, zoom, or other characteristic to allow the image capture device(s) <b>485</b> to adequately capture images of a patient and/or a ROI of the patient. In various embodiments, for example, the image capture device(s) <b>485</b> can focus on a ROI, zoom in on the ROI, center the ROI within a field of view by moving the image capture device(s) <b>485</b>, or otherwise adjust the field of view to allow for better and/or more accurate tracking/measurement of the ROI.</p><p id="p-0047" num="0046">The server <b>425</b> includes a processor <b>435</b> that is coupled to a memory <b>430</b>. The processor <b>435</b> can store and recall data and applications in the memory <b>430</b>. The processor <b>435</b> is also coupled to a transceiver <b>440</b>. In some embodiments, the processor <b>435</b>, and subsequently the server <b>425</b>, can communicate with other devices, such as the computing device <b>410</b> through the connection <b>470</b>.</p><p id="p-0048" num="0047">The devices shown in the illustrative embodiment can be utilized in various ways. For example, either the connections <b>470</b> and <b>480</b> can be varied. Either of the connections <b>470</b> and <b>480</b> can be a hard-wired connection. A hard-wired connection can involve connecting the devices through a USB (universal serial bus) port, serial port, parallel port, or other type of wired connection that can facilitate the transfer of data and information between a processor of a device and a second processor of a second device. In another embodiment, either of the connections <b>470</b> and <b>480</b> can be a dock where one device can plug into another device. In other embodiments, either of the connections <b>470</b> and <b>480</b> can be a wireless connection. These connections can take the form of any sort of wireless connection, including, but not limited to, Bluetooth connectivity, Wi-Fi connectivity, infrared, visible light, radio frequency (RF) signals, or other wireless protocols/methods. Other possible modes of wireless communication can include near-field communications, such as passive radio-frequency identification (RFID) and active RFID technologies. RFID and similar near-field communications can allow the various devices to communicate in short range when they are placed proximate to one another. In some embodiments, two or more devices in the patient monitoring system <b>400</b> can together create a dynamic mesh network that includes connections <b>470</b> and/or <b>480</b>. In these and other embodiments, data captured by and/or received at one device of the system <b>400</b> may be sent to and/or through other devices of the system <b>400</b> (e.g., to reach the server(s)), hence improving wireless coverage. In these and still other embodiments, the various devices can connect through an internet (or other network) connection. That is, either of the connections <b>470</b> and <b>480</b> can represent several different computing devices and network components that allow the various devices to communicate through the internet, either through a hard-wired or wireless connection. Either of the connections <b>470</b> and <b>480</b> can also be a combination of several modes of connection.</p><p id="p-0049" num="0048">The configuration of the devices in <figref idref="DRAWINGS">FIG. <b>4</b></figref> is merely one physical system <b>400</b> on which the disclosed embodiments can be executed. Other configurations of the devices shown can exist to practice the disclosed embodiments. Further, configurations of additional or fewer devices than the devices shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> can exist to practice the disclosed embodiments. Additionally, the devices shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> can be combined to allow for fewer devices than shown or can be separated such that more than the three devices exist in a system. It will be appreciated that many various combinations of computing devices can execute the methods and systems disclosed herein. Examples of such computing devices can include other types of medical devices and sensors, infrared cameras/detectors, night vision cameras/detectors, other types of cameras, augmented reality goggles, virtual reality goggles, mixed reality goggle, radio frequency transmitters/receivers, smart phones, personal computers, servers, laptop computers, tablets, blackberries, RFID enabled devices, smart watch or wearables, or any combinations of such devices.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flow diagram illustrating a patient monitoring routine <b>500</b> for determining and monitoring one or more patient parameters in accordance with various embodiments of the present technology. All or a subset of the steps of the routine <b>500</b> can be executed by various components or devices of one or more patient monitoring systems (e.g., the wearable and/or video-based patient monitoring systems described above) and/or users of the system(s) (e.g., a caregiver, a clinician, a patient, etc.).</p><p id="p-0051" num="0050">The routine <b>500</b> can begin at block <b>502</b> by sensing a data via a patient attached probe (e.g., <b>112</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>). At block <b>504</b>, the routine <b>500</b> can capture first patient data from a sensor in contact with the patient. In some embodiments, the routine <b>500</b> can capture patient data using one or more sensors or probes associated with (e.g., contacting) the patient. For example, the routine <b>500</b> can use one or more sensors or probes to capture an ECG signal, an EEG signal, a temperature signal, a heart rate signal, a respiratory rate signal, an average temperature signal, and/or one or more other physiological signals relating to the patient. In these and other embodiments, the routine <b>500</b> can capture patient data using one or more image capture devices. For example, the routine <b>500</b> can use an image capture device to detect a location of the patient, movement of the patient, whether the patient is awake or sleeping, and/or other data relating to the patient.</p><p id="p-0052" num="0051">At block <b>506</b>, the patient attached sensor or associated device can transmit instructions (e.g., a key) to the monitoring device to instruct the monitoring device to display not just the first patient data from the attached sensor/probe, but also second patient data from the non- contact monitoring (NCM) system. At block <b>508</b>, the monitoring device receives and reads the key (which may be encrypted) from the patient attached sensor or associated device. As has been discussed above, the instruction can prompt the monitoring device to start receiving data from the NCM system. Such instructions can also activate the NCM system, as well as: allow the monitoring device to include the additional physiological information directly onto a current display screen; allow the device or system to reconfigure a current screen to display the additional physiological information; and/or allow for separate pages to be accessible on the device or system for display of the additional physiological information.</p><p id="p-0053" num="0052">At block <b>510</b>, the routine <b>500</b> can sense/capture second patient data from the video system. For example, the routine <b>510</b> can recognize a patient within a field of view (FOV) of one or more image capture devices and/or define one or more regions of interest (ROI's) on the patient. In some embodiments, the routine <b>510</b> can recognize the patient by identifying the patient using facial recognition hardware and/or software of the image capture device(s). In these embodiments, the routine <b>510</b> can display the name of the patient on a display screen once the routine <b>510</b> has identified the patient.</p><p id="p-0054" num="0053">At block <b>512</b>, the monitoring device (e.g., a MPM device, clinician's tablet, etc.) displays data from both the attached sensor as well as second patient data from the noncontact monitoring system.</p><p id="p-0055" num="0054">Although the steps of the routine <b>500</b> are discussed and illustrated in a particular order, the routine <b>500</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> is not so limited. In other embodiments, the routine <b>500</b> can be performed in a different order. In these and other embodiments, any of the steps of the routine <b>500</b> can be performed before, during, and/or after any of the other steps of the routine <b>500</b>. A person of ordinary skill in the relevant art will readily recognize that the illustrated method can be altered and still remain within these and other embodiments of the present technology.</p><p id="p-0056" num="0055">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, optional combination of data streams on a monitoring device, prior to display on a monitoring device screen is illustrated generally at <b>600</b>. <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a schematic view of a mobile patient monitoring device <b>116</b>, a probe <b>112</b>, a wired connector cable <b>118</b>, a connector <b>120</b>, a wireless transmission path <b>122</b> and a wireless dongle <b>602</b>. Data combination (shown in the flow portion of the diagram at <b>604</b>) may occur prior to display on the screen of the MPM <b>116</b>.</p><p id="p-0057" num="0056">Referring still to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, in some embodiments, data streams are switched on and/or combined before display (or before sending to) a monitoring device. <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates combination of streams on the monitoring device.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a schematic view of a system (shown generally at <b>700</b>), including a monitoring device <b>116</b>, in combination with a wireless receiving unit <b>702</b>, with associated wireless transmission path <b>122</b>, receiving NCM data <b>704</b>. A physically attached probe, e.g., a pulse oximeter, <b>112</b> (though the present disclosure contemplates wireless communication of this data as well) communicates with the wireless receiving unit <b>702</b> to transmit pulse oximeter data <b>706</b> via a cable <b>118</b>. <figref idref="DRAWINGS">FIG. <b>7</b></figref> shows a system configured to send a combined stream of digital information to the monitoring device. The wireless receiving unit <b>702</b> combines the first (in this case pulse oximeter data) data with the second, NCM data and sends a revised data stream to the monitoring device. In some exemplary embodiments, the revised data stream is formatted, such that existing hardware can use the information without additional hardware or software modifications, while still being able to extract information such as respiration rate, for example, accurately and quickly.</p><p id="p-0059" num="0058">In exemplary embodiments, the wireless receiving unit <b>702</b> only sends NCM data if the probe <b>112</b> is connected to it, and/or if the probe provides the correct key instructing the wireless receiving unit to use NCM data. Further, in some embodiments, the wireless receiving unit <b>702</b> can be configured to only send a subset of the wireless (e.g., NCM data) streamed to it. For example, the wireless receiving unit could be configured only to send out respiratory rate, combined with pulse oximeter parameters. In other embodiments, it could only stream out apnea detection flags with pulse oximetry parameters, only stream out patient posture information, etc. Accordingly, some embodiments provide customized or customizable wireless receiving units according to different possible desired parameters handled by the wireless receiving units.</p><p id="p-0060" num="0059">In some embodiments, the data streams referred to above may include numerical values of a physiological parameter (e.g., heart rate, respiratory rate), a flag indicating a state (e.g., an apnea flag, a sensor-off flag, etc.), a physiological waveform (e.g., PPG, ECG, EEG, CO2), a video stream (e.g. from an RGB or depth camera), etc.+</p><p id="p-0061" num="0060">The above detailed descriptions of embodiments of the technology are not intended to be exhaustive or to limit the technology to the precise form disclosed above. Although specific embodiments of, and examples for, the technology are described above for illustrative purposes, various equivalent modifications are possible within the scope of the technology, as those skilled in the relevant art will recognize. For example, while steps are presented in a given order, alternative embodiments can perform steps in a different order. Furthermore, the various embodiments described herein can also be combined to provide further embodiments.</p><p id="p-0062" num="0061">The systems and methods described herein can be provided in the form of tangible and non-transitory machine-readable medium or media (such as a hard disk drive, hardware memory, etc.) having instructions recorded thereon for execution by a processor or computer. The set of instructions can include various commands that instruct the computer or processor to perform specific operations such as the methods and processes of the various embodiments described here. The set of instructions can be in the form of a software program or application. The computer storage media can include volatile and non-volatile media, and removable and non-removable media, for storage of information such as computer-readable instructions, data structures, program modules or other data. The computer storage media can include, but are not limited to, RAM, ROM, EPROM, EEPROM, flash memory or other solid-state memory technology, CD-ROM, DVD, or other optical storage, magnetic disk storage, or any other hardware medium which can be used to store desired information and that can be accessed by components of the system. Components of the system can communicate with each other via wired or wireless communication. The components can be separate from each other, or various combinations of components can be integrated together into a monitor or processor or contained within a workstation with standard computer hardware (for example, processors, circuitry, logic circuits, memory, and the like). The system can include processing devices such as microprocessors, microcontrollers, integrated circuits, control units, storage media, and other hardware.</p><p id="p-0063" num="0062">From the foregoing, it will be appreciated that specific embodiments of the technology have been described herein for purposes of illustration, but well-known structures and functions have not been shown or described in detail to avoid unnecessarily obscuring the description of the embodiments of the technology. To the extent any materials incorporated herein by reference conflict with the present disclosure, the present disclosure controls. Where the context permits, singular or plural terms can also include the plural or singular term, respectively. Moreover, unless the word &#x201c;or&#x201d; is expressly limited to mean only a single item exclusive from the other items in reference to a list of two or more items, then the use of &#x201c;or&#x201d; in such a list is to be interpreted as including (a) any single item in the list, (b) all of the items in the list, or (c) any combination of the items in the list. Where the context permits, singular or plural terms can also include the plural or singular term, respectively. Additionally, the terms &#x201c;comprising,&#x201d; &#x201c;including,&#x201d; &#x201c;having&#x201d; and &#x201c;with&#x201d; are used throughout to mean including at least the recited feature(s) such that any greater number of the same feature and/or additional types of other features are not precluded.</p><p id="p-0064" num="0063">From the foregoing, it will also be appreciated that various modifications can be made without deviating from the technology. For example, various components of the technology can be further divided into subcomponents, or various components and functions of the technology can be combined and/or integrated. Furthermore, although advantages associated with certain embodiments of the technology have been described in the context of those embodiments, other embodiments can also exhibit such advantages, and not all embodiments need necessarily exhibit such advantages to fall within the scope of the technology. Accordingly, the disclosure and associated technology can encompass other embodiments not expressly shown or described herein.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A patient monitoring system, comprising:<claim-text>a sensor in contact with a patient, the sensor configured to capture first physiological data related to the patient;</claim-text><claim-text>a non-contact video monitoring system configured to capture second physiological data related to the patient, wherein the non-contact video monitoring system includes a camera; and</claim-text><claim-text>a monitoring device configured to:<claim-text>receive the first physiological data;</claim-text><claim-text>wirelessly receive the second physiological data; and</claim-text><claim-text>based on instructions transmitted from the sensor to the monitoring device, wirelessly transmit activation instructions to the non-contact video monitoring system such that the non-contact video monitoring system begins to capture the second physiological data and wirelessly transmit the second physiological data to the monitoring device.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The patient monitoring system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the monitoring device is further configured to combine the first and second physiological data.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The patient monitoring system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions transmitted from the sensor to the monitoring device to activate the non-contact video monitoring system are based at least in part on the first physiological data.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The patient monitoring system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions transmitted from the sensor to the monitoring device comprise an encrypted key.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The patient monitoring system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the camera includes a depth sensing camera, an RGB camera, and/or an infrared camera.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The patient monitoring system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensor is further configured to transmit instructions to the monitoring device to:<claim-text>display on a display screen the first physiological data;</claim-text><claim-text>display on the display screen the second physiological data; or</claim-text><claim-text>display on the display screen the first physiological data and the second physiological data.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. A method for patient monitoring, comprising:<claim-text>obtaining, from a sensor in contact with a patient, first physiological data related to the patient;</claim-text><claim-text>transmitting the first physiological data and first instructions from the sensor to a monitoring device;</claim-text><claim-text>based on the first instructions, transmitting second instructions from the monitoring device to a non-contact video monitoring system, the second instructions instructing the non-contact video monitoring system to begin obtaining second physiological data related to the patient; and</claim-text><claim-text>wirelessly transmitting the second physiological data from the non-contact monitoring system to the monitoring device.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, further comprising:<claim-text>at the monitoring device, combining the first physiological data and the second physiological data.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the second instructions instructing the non-contact video monitoring system to begin obtaining second physiological data related to the patient are based at least in part on the first physiological data.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, further comprising:<claim-text>displaying on a display screen the first physiological data, the second physiological data, or the first physiological data and the second physiological data.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, further comprising:<claim-text>transmitting instructions from the first sensor to the monitoring device to display on a display screen the first physiological data, the second physiological data, or the first physiological data and the second physiological data.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the first instructions comprise an encrypted key.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein obtaining second physiological data related to the patient comprises:<claim-text>defining one or more regions of interest (ROI's) on a patient;</claim-text><claim-text>capturing the second physiological data related to the patient, wherein the second physiological data includes two or more images of the ROI's; and</claim-text><claim-text>measuring changes in depths of the ROI's across the two or more images of the ROI's.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A method for patient monitoring, comprising:<claim-text>obtaining, from a sensor in contact with a patient, first physiological data related to the patient;</claim-text><claim-text>obtaining, from a non-contact video monitoring system, second physiological data related to the patient;</claim-text><claim-text>transmitting the first physiological data from the sensor to a wireless receiver;</claim-text><claim-text>transmitting the second physiological data from the non-contact monitoring system to the wireless receiver;</claim-text><claim-text>combining, via the wireless receiver, the first and second physiological data to thereby create combined data;</claim-text><claim-text>transmitting the combined data to a monitoring device; and</claim-text><claim-text>displaying the first and second physiological data on the monitoring device.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005601A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005601</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17901829</doc-number><date>20220901</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-051707</doc-number><date>20200323</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>30</main-group><subgroup>40</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>56</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>30</main-group><subgroup>40</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>56</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">DOCUMENT CREATION SUPPORT APPARATUS, METHOD, AND PROGRAM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/011744</doc-number><date>20210322</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17901829</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>FUJIFILM Corporation</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>NAKAMURA</last-name><first-name>Keigo</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>FUJIFILM Corporation</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A document creation support apparatus includes at least one processor, and the processor generates a sentence related to a property of at least one structure of interest included in an image. The processor determines whether or not a sentence amount of the sentence is a prescribed amount. The processor adjusts the sentence amount such that the sentence amount is the prescribed amount based on a result of the determination.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="101.26mm" wi="113.96mm" file="US20230005601A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="249.77mm" wi="159.34mm" file="US20230005601A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="217.34mm" wi="84.07mm" file="US20230005601A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="105.16mm" wi="113.62mm" file="US20230005601A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="244.26mm" wi="130.47mm" orientation="landscape" file="US20230005601A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="246.80mm" wi="138.35mm" file="US20230005601A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="139.53mm" wi="138.35mm" file="US20230005601A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="231.39mm" wi="145.12mm" file="US20230005601A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="159.94mm" wi="138.35mm" file="US20230005601A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="206.59mm" wi="161.04mm" orientation="landscape" file="US20230005601A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="241.98mm" wi="162.39mm" file="US20230005601A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="205.74mm" wi="161.04mm" orientation="landscape" file="US20230005601A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="208.36mm" wi="161.04mm" orientation="landscape" file="US20230005601A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application is a Continuation of PCT International Application No. PCT/JP2021/011744, filed on Mar. 22, 2021, which claims priority to Japanese Patent Application No. 2020-051707, filed on Mar. 23, 2020. Each application above is hereby expressly incorporated by reference, in its entirety, into the present application.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Technical Field</heading><p id="p-0003" num="0002">The present disclosure relates to a document creation support apparatus, method, and program that support creation of documents such as medical documents.</p><heading id="h-0004" level="1">Related Art</heading><p id="p-0004" num="0003">In recent years, advances in medical devices, such as computed tomography (CT) apparatuses and magnetic resonance imaging (MRI) apparatuses, have enabled image diagnosis using high-resolution medical images with higher quality. In particular, since a region of a lesion can be accurately specified by image diagnosis using CT images, MRI images, and the like, appropriate treatment is being performed based on the specified result.</p><p id="p-0005" num="0004">In addition, image diagnosis is also made by analyzing a medical image via computer-aided diagnosis (CAD) using a learning model in which machine learning is performed by deep learning or the like, discriminating properties such as the shape, density, position, and size of structures of interest such as abnormal shadows included in the medical images, and acquiring them as an analysis result. The analysis result acquired by CAD is associated with examination information such as a patient name, gender, age, and a modality that has acquired the medical image, and is saved in a database. The medical image and the analysis result are transmitted to a terminal of a radiologist who interprets the medical images. The radiologist interprets the medical image by referring to the transmitted medical image and analysis result and creates an interpretation report, in his or her own terminal.</p><p id="p-0006" num="0005">Meanwhile, with the improvement of the performance of the CT apparatus and the MRI apparatus described above, the number of medical images to be interpreted is also increasing. However, since the number of radiologists has not kept up with the number of medical images, it is desired to reduce the burden of the image interpretation work of the radiologists. Therefore, various methods have been proposed to support the creation of medical documents such as interpretation reports. For example, JP2019-153250A proposes various methods for generating a sentence to be included in an interpretation report based on keywords input by a radiologist and on information indicating a property of a structure of interest (hereinafter referred to as property information) included in an analysis result of a medical image. In the methods described in JP2019-153250A, a sentence relating to medical care (hereinafter referred to as a medical sentence) is created by using a learning model in which machine learning is performed, such as a recurrent neural network trained to generate a sentence from characters representing the input property information. By automatically generating the medical sentence as in the method described in JP2019-153250A, it is possible to reduce a burden on a radiologist at the time of creating a medical document such as an interpretation report.</p><p id="p-0007" num="0006">Incidentally, as described above, if the sentence generated by the learning model is too long, the burden on a reader such as an attending physician who reads the sentence becomes large. Conversely, if the medical sentence is too short, the reader is worried whether the medical sentence includes necessary information about the structure of interest included in the medical image.</p><heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0008" num="0007">The present disclosure has been made in consideration of the above circumstances, and an object thereof is to enable the generation of sentences with an appropriate amount of information.</p><p id="p-0009" num="0008">According to an aspect of the present disclosure, there is provided a document creation support apparatus comprising at least one processor, in which the processor is configured to generate a sentence related to a property of at least one structure of interest included in an image, determine whether or not a sentence amount of the sentence is a prescribed amount, and adjust the sentence amount such that the sentence amount is the prescribed amount based on a result of the determination.</p><p id="p-0010" num="0009">For the &#x201c;sentence amount&#x201d;, for example, the number of characters, the number of lines, the number of paragraphs, and the like of the sentence can be used.</p><p id="p-0011" num="0010">The &#x201c;prescribed amount&#x201d; may be a constant value or a value having a range. The range may have only an upper limit value, may have only a lower limit value, or may have both an upper limit value and a lower limit value.</p><p id="p-0012" num="0011">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to adjust the sentence amount by selecting a property to be described in the sentence from among one or more properties of the structure of interest.</p><p id="p-0013" num="0012">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to generate the sentence including a description regarding each of one or more properties specified for the structure of interest, and adjust the sentence amount by deleting, from the sentence, a description regarding a negative property among descriptions regarding each of a plurality of properties included in the sentence.</p><p id="p-0014" num="0013">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to generate, for a plurality of structures of interest included in the image, a plurality of sentences describing properties of each of the structures of interest, and adjust the sentence amount of the sentence for at least one of the plurality of structures of interest such that a total amount of the sentence generated for each of the plurality of structures of interest is the prescribed amount.</p><p id="p-0015" num="0014">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to adjust the sentence amount by integrating common descriptions among the descriptions regarding each of the plurality of structures of interest included in the sentence.</p><p id="p-0016" num="0015">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to generate, for a plurality of structures of interest included in the image, a plurality of candidate sentences describing properties of each of the structures of interest, and adjust, for each of the plurality of structures of interest, the sentence amount by selecting a combination in which a sentence amount of a sentence including a selected candidate sentence is the prescribed amount from combinations of selecting one candidate sentence from among the plurality of candidate sentences.</p><p id="p-0017" num="0016">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to display the sentence on a display.</p><p id="p-0018" num="0017">In the document creation support apparatus according to the aspect of the present disclosure, the image may be a medical image, and the sentence may be a medical sentence related to the structure of interest included in the medical image.</p><p id="p-0019" num="0018">According to another aspect of the present disclosure, there is provided a document creation support method comprising: generating a sentence related to a property of at least one structure of interest included in an image; determining whether or not a sentence amount of the sentence is a prescribed amount; and adjusting the sentence amount such that the sentence amount is the prescribed amount based on a result of the determination.</p><p id="p-0020" num="0019">In addition, a program for causing a computer to execute the document creation support method according to the aspect of the present disclosure may be provided.</p><p id="p-0021" num="0020">According to the aspects of the present disclosure, it is possible to generate medical sentences with an appropriate amount of information.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram showing a schematic configuration of a medical information system to which a document creation support apparatus according to an embodiment of the present disclosure is applied.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram showing a schematic configuration of the document creation support apparatus according to the present embodiment.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a functional configuration diagram of the document creation support apparatus according to the present embodiment.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram for describing property information derived by an image analysis unit.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram schematically showing a configuration of a recurrent neural network.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram showing an example of medical sentences and medical sentences in which a sentence amount is adjusted.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram showing an example of medical sentences and medical sentences in which a sentence amount is adjusted.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram showing an example of medical sentences and medical sentences in which a sentence amount is adjusted.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram showing an example of medical sentences and medical sentences in which a sentence amount is adjusted.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram showing an example of medical sentences and medical sentences in which a sentence amount is adjusted.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram showing an example of a display screen of a medical sentence.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart showing a process performed in the present embodiment.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram showing another example of a display screen of a medical sentence.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram showing another example of a display screen of a medical sentence.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0036" num="0035">Hereinafter, embodiments of the present disclosure will be described with reference to the drawings. First, a configuration of a medical information system <b>1</b> to which a document creation support apparatus according to the present embodiment is applied will be described. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram showing a schematic configuration of the medical information system <b>1</b>. The medical information system <b>1</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is, based on an examination order from a doctor in a medical department using a known ordering system, a system for imaging an examination target part of a subject, storing a medical image acquired by the imaging, interpreting the medical image by a radiologist and creating an interpretation report, and viewing the interpretation report and observing the medical image to be interpreted in detail by the doctor in the medical department that is a request source.</p><p id="p-0037" num="0036">As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in the medical information system <b>1</b>, a plurality of imaging apparatuses <b>2</b>, a plurality of interpretation workstations (WSs) <b>3</b> that are interpretation terminals, a medical care WS <b>4</b>, an image server <b>5</b>, an image database (hereinafter referred to as an image DB) <b>6</b>, a report server <b>7</b>, and a report database (hereinafter referred to as a report DB) <b>8</b> are communicably connected to each other through a wired or wireless network <b>10</b>.</p><p id="p-0038" num="0037">Each apparatus is a computer on which an application program for causing each apparatus to function as a component of the medical information system <b>1</b> is installed. The application program is stored in a storage apparatus of a server computer connected to the network <b>10</b> or in a network storage in a state in which it can be accessed from the outside, and is downloaded to and installed on the computer in response to a request. Alternatively, the application program is recorded on a recording medium, such as a digital versatile disc (DVD) and a compact disc read only memory (CD-ROM), and distributed, and is installed on the computer from the recording medium.</p><p id="p-0039" num="0038">The imaging apparatus <b>2</b> is an apparatus (modality) that generates a medical image showing a diagnosis target part of the subject by imaging the diagnosis target part. Specifically, examples of the modality include a simple X-ray imaging apparatus, a CT apparatus, an MRI apparatus, a positron emission tomography (PET) apparatus, and the like. The medical image generated by the imaging apparatus <b>2</b> is transmitted to the image server <b>5</b> and is saved in the image DB <b>6</b>.</p><p id="p-0040" num="0039">The interpretation WS <b>3</b> is a computer used by, for example, a radiologist of a radiology department to interpret a medical image and to create an interpretation report, and encompasses a document creation support apparatus <b>20</b> according to the present embodiment. In the interpretation WS <b>3</b>, a viewing request for a medical image to the image server <b>5</b>, various image processing for the medical image received from the image server <b>5</b>, display of the medical image, input reception of comments on findings regarding the medical image, and the like are performed. In the interpretation WS <b>3</b>, an analysis process for medical images and input comments on findings, support for creating an interpretation report based on the analysis result, a registration request and a viewing request for the interpretation report to the report server <b>7</b>, and display of the interpretation report received from the report server <b>7</b> are performed. The above processes are performed by the interpretation WS <b>3</b> executing software programs for respective processes.</p><p id="p-0041" num="0040">The medical care WS <b>4</b> is a computer used by a doctor in a medical department to observe an image in detail, view an interpretation report, create an electronic medical record, and the like, and is configured to include a processing apparatus, a display apparatus such as a display, and an input apparatus such as a keyboard and a mouse. In the medical care WS <b>4</b>, a viewing request for the image to the image server <b>5</b>, display of the image received from the image server <b>5</b>, a viewing request for the interpretation report to the report server <b>7</b>, and display of the interpretation report received from the report server <b>7</b> are performed. The above processes are performed by the medical care WS <b>4</b> executing software programs for respective processes.</p><p id="p-0042" num="0041">The image server <b>5</b> is a general-purpose computer on which a software program that provides a function of a database management system (DBMS) is installed. The image server <b>5</b> comprises a storage in which the image DB <b>6</b> is configured. This storage may be a hard disk apparatus connected to the image server <b>5</b> by a data bus, or may be a disk apparatus connected to a storage area network (SAN) or a network attached storage (NAS) connected to the network <b>10</b>. In a case where the image server <b>5</b> receives a request to register a medical image from the imaging apparatus <b>2</b>, the image server <b>5</b> prepares the medical image in a format for a database and registers the medical image in the image DB <b>6</b>.</p><p id="p-0043" num="0042">Image data of the medical image acquired by the imaging apparatus <b>2</b> and accessory information are registered in the image DB <b>6</b>. The accessory information includes, for example, an image identification (ID) for identifying each medical image, a patient ID for identifying a subject, an examination ID for identifying an examination, a unique ID (unique identification (UID)) allocated for each medical image, examination date and examination time at which a medical image is generated, the type of imaging apparatus used in an examination for acquiring a medical image, patient information such as the name, age, and gender of a patient, an examination part (an imaging part), imaging information (an imaging protocol, an imaging sequence, an imaging method, imaging conditions, the use of a contrast medium, and the like), and information such as a series number or a collection number in a case where a plurality of medical images are acquired in one examination.</p><p id="p-0044" num="0043">In addition, in a case where the viewing request from the interpretation WS <b>3</b> and the medical care WS <b>4</b> is received through the network <b>10</b>, the image server <b>5</b> searches for a medical image registered in the image DB <b>6</b> and transmits the searched for medical image to the interpretation WS <b>3</b> and to the medical care WS <b>4</b> that are request sources.</p><p id="p-0045" num="0044">The report server <b>7</b> incorporates a software program for providing a function of a database management system to a general-purpose computer. In a case where the report server <b>7</b> receives a request to register the interpretation report from the interpretation WS <b>3</b>, the report server <b>7</b> prepares the interpretation report in a format for a database and registers the interpretation report in the report DB <b>8</b>.</p><p id="p-0046" num="0045">In the report DB <b>8</b>, an interpretation report including at least the comments on findings created in the interpretation WS <b>3</b> is registered. The interpretation report may include, for example, information such as a medical image to be interpreted, an image ID for identifying the medical image, a radiologist ID for identifying the radiologist who performed the interpretation, a lesion name, lesion position information, information for accessing a medical image including a specific region, and property information.</p><p id="p-0047" num="0046">Further, in a case where the report server <b>7</b> receives the viewing request for the interpretation report from the interpretation WS <b>3</b> and the medical care WS <b>4</b> through the network <b>10</b>, the report server <b>7</b> searches for the interpretation report registered in the report DB <b>8</b>, and transmits the searched for interpretation report to the interpretation WS <b>3</b> and to the medical care WS <b>4</b> that are request sources.</p><p id="p-0048" num="0047">In the present embodiment, it is assumed that the medical image is a three-dimensional CT image consisting of a plurality of tomographic images with a lung as a diagnosis target, and an interpretation report including, as comments on findings, a medical sentence on a structure of interest such as an abnormal shadow included in the lung is created by interpreting the CT image. The medical image is not limited to the CT image, and any medical image such as an MRI image and a simple two-dimensional image acquired by a simple X-ray imaging apparatus can be used.</p><p id="p-0049" num="0048">The network <b>10</b> is a wired or wireless local area network that connects various apparatuses in a hospital to each other. In a case where the interpretation WS <b>3</b> is installed in another hospital or clinic, the network <b>10</b> may be configured to connect local area networks of respective hospitals through the Internet or a dedicated line.</p><p id="p-0050" num="0049">Next, the document creation support apparatus according to the present embodiment will be described. <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a hardware configuration of the document creation support apparatus according to the present embodiment. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the document creation support apparatus <b>20</b> includes a central processing unit (CPU) <b>11</b>, a non-volatile storage <b>13</b>, and a memory <b>16</b> as a temporary storage area. Further, the document creation support apparatus <b>20</b> includes a display <b>14</b> such as a liquid crystal display, an input device <b>15</b> such as a keyboard and a mouse, and a network interface (I/F) <b>17</b> connected to the network <b>10</b>. The CPU <b>11</b>, the storage <b>13</b>, the display <b>14</b>, the input device <b>15</b>, the memory <b>16</b>, and the network I/F <b>17</b> are connected to a bus <b>18</b>. The CPU <b>11</b> is an example of a processor in the present disclosure.</p><p id="p-0051" num="0050">The storage <b>13</b> is realized by a hard disk drive (HDD), a solid state drive (SSD), a flash memory, and the like. A document creation support program is stored in the storage <b>13</b> as a storage medium. The CPU <b>11</b> reads a document creation support program <b>12</b> from the storage <b>13</b>, loads the read document creation support program <b>12</b> into the memory <b>16</b>, and executes the loaded document creation support program <b>12</b>.</p><p id="p-0052" num="0051">Next, a functional configuration of the document creation support apparatus according to the present embodiment will be described. <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram showing a functional configuration of the document creation support apparatus according to the present embodiment. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the document creation support apparatus <b>20</b> comprises an image acquisition unit <b>21</b>, an image analysis unit <b>22</b>, a sentence generation unit <b>23</b>, a determination unit <b>24</b>, a display control unit <b>25</b>, a save control unit <b>26</b>, and a communication unit <b>27</b>. Then, in a case where the CPU <b>11</b> executes the document creation support program <b>12</b>, the CPU <b>11</b> functions as the image acquisition unit <b>21</b>, the image analysis unit <b>22</b>, the sentence generation unit <b>23</b>, the determination unit <b>24</b>, the display control unit <b>25</b>, the save control unit <b>26</b>, and the communication unit <b>27</b>.</p><p id="p-0053" num="0052">The image acquisition unit <b>21</b> acquires a medical image for creating an interpretation report from the image server <b>5</b> according to an instruction from the input device <b>15</b> by the radiologist who is an operator.</p><p id="p-0054" num="0053">The image analysis unit <b>22</b> analyzes the medical image to derive property information indicating the property of the structure of interest included in the medical image. To this end, the image analysis unit <b>22</b> has a learning model <b>22</b>A in which machine learning is performed to detect an abnormal shadow included in the medical image as a structure of interest and to discriminate properties of the detected abnormal shadow for each of a plurality of predetermined property items.</p><p id="p-0055" num="0054">Here, examples of the property item specified for the abnormal shadow include the location of the abnormal shadow, the size of the abnormal shadow, the shape of the boundary (clear and irregular), the type of absorption value (solid type and frosted glass type), the presence or absence of spicula, whether it is a tumor or a nodule, the presence or absence of pleural contact, the presence or absence of pleural invagination, the presence or absence of pleural infiltration, the presence or absence of a cavity, and the presence or absence of calcification. Note that, the examples of property items are not limited to these.</p><p id="p-0056" num="0055">In the present embodiment, the learning model <b>22</b>A consists of a convolutional neural network in which machine learning is performed through deep learning or the like using supervised training data so as to discriminate the properties of abnormal shadows in medical images.</p><p id="p-0057" num="0056">The learning model <b>22</b>A is constructed by machine learning using, for example, a plurality of combinations of a medical image including an abnormal shadow and a property item representing the property of the abnormal shadow as supervised training data. In a case where a medical image is input, the learning model <b>22</b>A outputs a property score derived for each property item in the abnormal shadow included in the medical image. The property score is a score indicating the prominence of the property for each property item. The property score takes a value of 0 or more and 1 or less, for example, and the larger the value of the property score is, the more pronounced the property is.</p><p id="p-0058" num="0057">For example, in a case where the property score for &#x201c;the presence or absence of spicula&#x201d;, which is one of the property items of an abnormal shadow, is, for example, 0.5 or more, it is specified that the property for &#x201c;the presence or absence of spicula&#x201d; of the abnormal shadow is &#x201c;with spicula (positive)&#x201d;, and in a case where the property score for &#x201c;the presence or absence of spicula&#x201d; is less than, for example, 0.5, it is specified that the property for the presence or absence of spicula of the abnormal shadow is &#x201c;no spicula (negative)&#x201d;. The threshold value 0.5 used for property determination is merely an example, and is set to an appropriate value for each property item.</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram for describing an example of property information specified by the image analysis unit <b>22</b>. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, in property information <b>30</b> specified by the image analysis unit <b>22</b>, the properties for each property item are &#x201c;under left lung pleura&#x201d;, &#x201c;4.2 cm&#x201d;, &#x201c;irregular&#x201d;, &#x201c;solid&#x201d;, &#x201c;with spicula&#x201d;, &#x201c;tumor&#x201d;, &#x201c;with pleural contact&#x201d;, &#x201c;with pleural invagination&#x201d;, &#x201c;no pleural infiltration&#x201d;, &#x201c;no cavity&#x201d;, and &#x201c;no calcification&#x201d;. In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, + is given in the case of &#x201c;yes&#x201d;, that is, positive, and&#x2014;is given in the case of &#x201c;no&#x201d;, that is, negative.</p><p id="p-0060" num="0059">As the learning model <b>22</b>A, any learning model such as, for example, a support vector machine (SVM) can be used in addition to the convolutional neural network.</p><p id="p-0061" num="0060">Further, the learning model for detecting the abnormal shadow from the medical image and the learning model for discriminating the property of the abnormal shadow may be constructed separately.</p><p id="p-0062" num="0061">The sentence generation unit <b>23</b> generates a sentence related to a property of the abnormal shadow included in the medical image by using the property information derived by the image analysis unit <b>22</b>. Further, as will be described later, a sentence amount of the generated medical sentence is adjusted according to a result of the determination performed by the determination unit <b>24</b>. In the present embodiment, the sentence generation unit <b>23</b> generates a medical sentence as a sentence. The sentence generation unit <b>23</b> consists of a learning model <b>23</b>A that has been trained to generate a sentence from the input information. As the learning model <b>23</b>A, for example, a recurrent neural network can be used. <figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram schematically showing a configuration of a recurrent neural network. As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, a recurrent neural network <b>40</b> consists of an encoder <b>41</b> and a decoder <b>42</b>. The property information derived by the image analysis unit <b>22</b> is input to the encoder <b>41</b>. For example, property information indicating &#x201c;under left lung pleura&#x201d;, &#x201c;4.2 cm&#x201d;, &#x201c;spicula+&#x201d; and &#x201c;tumor&#x201d; is input to the encoder <b>41</b>. The decoder <b>42</b> is trained to document character information, and generates a sentence from the input property information. Specifically, from the above-mentioned property information indicating &#x201c;under left lung pleura&#x201d;, &#x201c;4.2 cm&#x201d;, &#x201c;spicula+&#x201d; and &#x201c;tumor&#x201d;, a medical sentence &#x201c;A 4.2 cm diameter tumor having spicula is found under the left lung pleura&#x201d; is generated. In <figref idref="DRAWINGS">FIG. <b>5</b></figref>, &#x201c;EOS&#x201d; indicates the end of the sentence (end of sentence).</p><p id="p-0063" num="0062">In this way, in order to output the medical sentence by inputting the property information, the recurrent neural network <b>40</b> is constructed by training the encoder <b>41</b> and the decoder <b>42</b> using a large amount of supervised training data consisting of a combination of the property information and the medical sentence.</p><p id="p-0064" num="0063">The sentence generation unit <b>23</b> adjusts a sentence amount such that a sentence amount of the medical sentence is a prescribed amount based on the result of the determination performed by the determination unit <b>24</b>, which will be described later. The adjustment of the sentence amount will be described later.</p><p id="p-0065" num="0064">The determination unit <b>24</b> determines whether or not the sentence amount of the medical sentence generated by the sentence generation unit <b>23</b> is a prescribed amount. Specifically, the determination unit <b>24</b> determines the sentence amount by determining whether or not the number of characters, the number of lines, or the number of paragraphs of the sentence is a prescribed amount Th<b>1</b>. The prescribed amount Th<b>1</b> may be a constant value or a value having a range. In a case where the prescribed amount is a value having a range, the range may have only an upper limit value, may have only a lower limit value, or may have both an upper limit value and a lower limit value. Specifically, in a case of the number of characters, the prescribed amount Th<b>1</b> may be 100 characters, 100 characters or more, 100 characters or less, or 90 characters or more and 110 characters or less. In the present embodiment, the prescribed amount Th<b>1</b> will be described as a value having an upper limit value and a lower limit value. In addition, the prescribed amount Th<b>1</b> may be changed according to the preference of the radiologist.</p><p id="p-0066" num="0065">Then, in a case where the sentence amount of the medical sentence generated by the sentence generation unit <b>23</b> is not the prescribed amount Th<b>1</b>, the determination unit <b>24</b> gives an instruction according to the determination result to the sentence generation unit <b>23</b>. That is, in a case where the sentence amount is less than the prescribed amount Th<b>1</b>, an instruction to increase the sentence amount is given, and in a case where the sentence amount is larger than the prescribed amount Th<b>1</b>, an instruction to reduce the sentence amount is given. In a case where the sentence amount of the medical sentence generated by the sentence generation unit <b>23</b> is the prescribed amount Th<b>1</b>, the determination unit <b>24</b> does nothing.</p><p id="p-0067" num="0066">The sentence generation unit <b>23</b> adjusts the sentence amount of the medical sentence according to the instruction from the determination unit <b>24</b>. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram showing an example of medical sentences and medical sentences in which a sentence amount is adjusted. As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, it is assumed that medical sentences <b>51</b> before adjustment are &#x201c;A 21 mm-sized irregular solid nodule is found in the left lower lobe S<b>6</b>. It is lobular and has a clear boundary. Calcification is found inside, but cavities and air bronchograms are not included. The nodule is in contact with the pleura.&#x201d; In a case where the determination unit <b>24</b> gives an instruction to reduce the sentence amount with respect to the medical sentences <b>51</b>, the sentence generation unit <b>23</b> adjusts the sentence amount by selecting the property to be described in the medical sentence. For example, the sentence amount is adjusted by selecting only the shape-related properties from among the plurality of properties included in the medical sentences <b>51</b>, and a medical sentence <b>52</b> of &#x201c;A 21 mm-sized irregular solid nodule is found in the left lower lobe S<b>6</b>&#x201d; is generated. Alternatively, properties other than the properties related to the inside such as calcification, cavities, and air bronchograms in the medical sentences <b>51</b>, and the properties related to contact with other tissues such as pleural contact may be selected. In this case, the sentence generation unit <b>23</b> adjusts the sentence amount of the medical sentences <b>51</b> to generate medical sentences <b>53</b> of &#x201c;A 21 mm-sized irregular solid nodule is found in the left lower lobe S<b>6</b>. It is lobular and has a clear boundary.&#x201d;</p><p id="p-0068" num="0067">Further, the sentence generation unit <b>23</b> may adjust the sentence amount by selecting only the positive properties in the medical sentences <b>51</b>. In this case, the sentence generation unit <b>23</b> adjusts the sentence amount of the medical sentences <b>51</b> to generate medical sentences <b>54</b> of &#x201c;A 21 mm-sized irregular solid nodule is found in the left lower lobe S<b>6</b>. It is lobular and has a clear boundary. Calcification is found inside. The nodule is in contact with the pleura.&#x201d;</p><p id="p-0069" num="0068">In a case where the medical sentence is too short, the sentence generation unit <b>23</b> adjusts the sentence amount of the medical sentence so as to increase the sentence amount. For example, as shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, in a case where a medical sentence <b>61</b> before adjustment is &#x201c;A 21 mm-sized irregular solid nodule is found in the left lower lobe S<b>6</b>&#x201d;, the sentence amount of the medical sentence <b>61</b> is adjusted by selecting all the positive property items derived by the image analysis unit <b>22</b>. For example, the sentence generation unit <b>23</b> adjusts the sentence amount of the medical sentence <b>61</b> to generate medical sentences <b>62</b> of &#x201c;A 21 mm-sized irregular solid nodule is found in the left lower lobe S<b>6</b>. It is lobular and has a clear boundary. Calcification is found inside. The nodule is in contact with the pleura.&#x201d; In addition, the sentence generation unit <b>23</b> may adjust the sentence amount of the medical sentence <b>61</b> so as to select all of the negative property item and the positive property item. For example, the sentence generation unit <b>23</b> adjusts the sentence amount of the medical sentence <b>61</b> to generate medical sentences <b>63</b> of &#x201c;A 21 mm-sized irregular solid nodule is found in the left lower lobe S<b>6</b>. It is lobular and has a clear boundary. Calcification is found inside, but cavities and air bronchograms are not included. The nodule is in contact with the pleura.&#x201d;</p><p id="p-0070" num="0069">Here, in a case where the medical image includes a plurality of abnormal shadows, the sentence generation unit <b>23</b> generates a medical sentence including a description regarding each of the properties specified for the plurality of abnormal shadows. In such a case, in a case where the determination unit <b>24</b> gives an instruction to reduce the sentence amount, the sentence generation unit <b>23</b> may adjust the sentence amount by integrating the common descriptions among the descriptions regarding each of the properties specified for the plurality of abnormal shadows. For example, as shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, it is assumed that medical sentences <b>65</b> before adjustment are &#x201c;There is a solid nodule with irregularities in the left lung S<b>3</b>. It is accompanied by spicula. In addition, there is a solid nodule with irregularities in the right lung S<b>7</b>&#x201d;, and descriptions regarding two abnormal shadows are included. In this case, the description regarding the solid nodule is common to the two abnormal shadows. Therefore, the sentence generation unit <b>23</b> adjusts the sentence amount by integrating the descriptions regarding the solid nodules common to the two abnormal shadows to generate a medical sentence <b>66</b> of &#x201c;There are solid nodules with irregularities in the left lung S<b>3</b> and the right lung S<b>7</b>.&#x201d;</p><p id="p-0071" num="0070">Further, in a case where the medical image includes a plurality of abnormal shadows, the sentence generation unit <b>23</b> may generate a plurality of candidate sentences describing properties of each of abnormal shadows, and adjust, for each of the plurality of abnormal shadows, the sentence amount by selecting a combination in which a sentence amount of a sentence including a selected candidate sentence is the prescribed amount from combinations of selecting one candidate sentence from among the plurality of candidate sentences.</p><p id="p-0072" num="0071">For example, in a case where the medical image includes two abnormal shadows A and B, as shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the sentence generation unit <b>23</b> generates candidate sentences <b>71</b>A to <b>71</b>C for the abnormal shadow A and candidate sentences <b>72</b>A to <b>72</b>C for the abnormal shadow B, respectively. Then, the sentence generation unit <b>23</b> selects one candidate sentence from each of the candidate sentences <b>71</b>A to <b>71</b>C for the abnormal shadow A and the candidate sentences <b>72</b>A to <b>72</b>C for the abnormal shadow B to generate a medical sentence. For example, the candidate sentence <b>71</b>C for the abnormal shadow A and the candidate sentence <b>72</b>C for the abnormal shadow B are selected to generate medical sentences <b>73</b> shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>.</p><p id="p-0073" num="0072">In a case where the sentence amount of the medical sentences <b>73</b> is larger than a prescribed amount, the determination unit <b>24</b> gives an instruction to shorten the sentence amount. Thereby, the sentence generation unit <b>23</b> performs adjustment so as to reduce the sentence amount of the medical sentences <b>73</b>, and generates medical sentences <b>74</b>. At this time, the sentence generation unit <b>23</b> may select the candidate sentence such that the description regarding the abnormal shadow having a higher degree of malignancy among the abnormal shadows A and B becomes longer. For example, in the abnormal shadow A and the abnormal shadow B, the abnormal shadow A has a higher degree of malignancy. Therefore, the medical sentences <b>74</b> are generated by changing the description regarding the abnormal shadow B included in the medical sentences <b>73</b> to the candidate sentence <b>72</b>A shorter than the candidate sentence <b>72</b>C.</p><p id="p-0074" num="0073">Further, as described above, the sentence amount of the medical sentences <b>73</b> may be adjusted by selecting only the negative properties from among the descriptions included in the medical sentences <b>73</b> or by integrating the descriptions of the common properties.</p><p id="p-0075" num="0074">In addition, the medical image and the interpretation report acquired in the past for the same patient may be acquired, it may be determined whether the abnormal shadow included in the medical image to be interpreted at the present is a continuation of the past medical image or a newly appearing abnormal shadow, and the description of the newly appearing abnormal shadow may be lengthened.</p><p id="p-0076" num="0075">The display control unit <b>25</b> displays the generated medical sentence on the display <b>14</b>. <figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram showing a display screen of a medical sentence. As shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, a display screen <b>80</b> includes an image display region <b>81</b> and a sentence display region <b>82</b>. In the image display region <b>81</b>, a slice image SL<b>1</b> that is most likely to specify the abnormal shadow detected by the image analysis unit <b>22</b> is displayed. The slice image SL<b>1</b> includes an abnormal shadow <b>83</b>, and the abnormal shadow <b>83</b> is surrounded by a rectangular region <b>84</b>.</p><p id="p-0077" num="0076">In the sentence display region <b>82</b>, a medical sentence <b>85</b> which is generated by the sentence generation unit <b>23</b> or in which a sentence amount is adjusted is displayed. The medical sentence <b>85</b> is the same as the medical sentence <b>52</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, &#x201c;A 21 mm-sized irregular solid nodule is found in the left lower lobe S<b>6</b>.&#x201d;</p><p id="p-0078" num="0077">Below the image display region <b>81</b>, a correction button <b>88</b>A and a confirmation button <b>88</b>B are displayed.</p><p id="p-0079" num="0078">The radiologist interprets the slice image SL<b>1</b> displayed in the image display region <b>81</b> and included in the medical image, and determines the suitability of the medical sentence <b>85</b> displayed in the sentence display region <b>82</b>. By selecting the correction button <b>88</b>A, the radiologist can manually correct the medical sentence <b>85</b> displayed in the sentence display region <b>82</b> by input from the input device <b>15</b>. Further, by selecting the confirmation button <b>88</b>B, the medical sentence <b>85</b> displayed in the sentence display region <b>82</b> can be confirmed with its contents.</p><p id="p-0080" num="0079">By the selection of the confirmation button <b>88</b>B performed by the operator, the save control unit <b>26</b> transcribes the medical sentence <b>85</b> described in the sentence display region <b>82</b> to the interpretation report, and saves the interpretation report and the slice image referred to in the case of generating the interpretation report together in the storage <b>13</b>.</p><p id="p-0081" num="0080">The communication unit <b>27</b> transfers the interpretation report to which the medical sentence <b>85</b> described in the sentence display region <b>82</b> is transcribed and the slice image referred to in the case of generating the interpretation report together to the report server <b>7</b> via the network I/F<b>17</b>. The report server <b>7</b> saves the interpretation report and the slice image together.</p><p id="p-0082" num="0081">Next, a process performed in the present embodiment will be described. <figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart showing a process performed in the present embodiment. It is assumed that the medical image to be interpreted is acquired from the image server <b>5</b> by the image acquisition unit <b>21</b> and is saved in the storage <b>13</b>. The process is started in a case where an instruction to create an interpretation report is given by the radiologist, and the image analysis unit <b>22</b> analyzes the medical image to derive property information indicating the property of the structure of interest such as an abnormal shadow included in the medical image (Step ST<b>1</b>). Next, the sentence generation unit <b>23</b> generates a medical sentence related to the medical image based on the property information (Step ST<b>2</b>). Subsequently, the determination unit <b>24</b> determines whether or not the sentence amount of the generated medical sentence is a prescribed amount (Step ST<b>3</b>).</p><p id="p-0083" num="0082">In a case where Step ST<b>3</b> is negative, the sentence generation unit <b>23</b> adjusts the sentence amount such that the sentence amount of the medical sentence is the prescribed amount based on a result of the determination (Step ST<b>4</b>), and returns to Step ST<b>3</b>. In a case where Step ST<b>3</b> is affirmative, the display control unit <b>25</b> displays the medical image and the medical sentence generated by the sentence generation unit <b>23</b> on the display <b>14</b> (Step ST<b>5</b>).</p><p id="p-0084" num="0083">Next, the display control unit <b>25</b> determines whether or not the correction button <b>88</b>A displayed on the display screen is selected (Step ST<b>6</b>). In a case where Step ST<b>6</b> is affirmative, the display control unit <b>25</b> receives the correction of the medical sentence displayed in the sentence display region <b>82</b> using the input device <b>15</b>, and the sentence generation unit <b>23</b> corrects the medical sentence displayed in the sentence display region <b>82</b> by input from the input device <b>15</b> (Step ST<b>7</b>). Subsequently, the display control unit <b>25</b> determines whether or not the confirmation button <b>88</b>B is selected (Step ST<b>8</b>). In a case where Step ST<b>8</b> is negative, the process returns to Step ST<b>6</b>.</p><p id="p-0085" num="0084">In a case where Step ST<b>8</b> is affirmative, the save control unit <b>26</b> transcribes the medical sentence to the interpretation report for the medical image, and saves the interpretation report and the medical image together in the storage <b>13</b> (saving the interpretation report or the like; Step ST<b>9</b>). Then, the communication unit <b>27</b> transfers the interpretation report and the medical image together to the report server <b>7</b> via the network I/F<b>17</b> (transfer of the interpretation report or the like; Step ST<b>10</b>), and ends the process.</p><p id="p-0086" num="0085">In this way, in the present embodiment, it is determined whether or not the sentence amount of the sentence is the prescribed amount, and the sentence amount is adjusted such that the sentence amount is the prescribed amount based on the determination result. Therefore, it is possible to generate medical sentences with an appropriate amount of information.</p><p id="p-0087" num="0086">In the above embodiment, one medical sentence in which the sentence amount is adjusted to the prescribed amount is displayed in the sentence display region <b>82</b> of the display screen <b>80</b>, but the present disclosure is not limited thereto. For example, as shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, three medical sentences <b>52</b> to <b>53</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> may be displayed in the sentence display region <b>82</b>, and from among the displayed medical sentences <b>52</b> to <b>53</b>, the medical sentence desired by the radiologist may be selected by using the input device <b>15</b>. In <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the medical sentences <b>52</b> to <b>54</b> are displayed in ascending order of the sentence amount from the top. Further, since the medical sentence generated by the sentence generation unit <b>23</b> is short, in a case where the sentence amount of the medical sentence is adjusted to increase, a plurality of medical sentences may be displayed in descending order of the sentence amount. For example, as shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, the medical sentences <b>62</b> and <b>63</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref> may be displayed in the order of the medical sentences <b>63</b> and <b>62</b> from the top.</p><p id="p-0088" num="0087">Further, in the above embodiment, the technique of the present disclosure is applied in the case of creating an interpretation report using a medical image with the lung as the diagnosis target, but the diagnosis target is not limited to the lung. In addition to the lung, any part of a human body such as a heart, liver, brain, and limbs can be diagnosed.</p><p id="p-0089" num="0088">Further, in the above embodiment, for example, as hardware structures of processing units that execute various kinds of processing, such as the image acquisition unit <b>21</b>, the image analysis unit <b>22</b>, the sentence generation unit <b>23</b>, the determination unit <b>24</b>, the display control unit <b>25</b>, the save control unit <b>26</b>, and the communication unit <b>27</b>, various processors shown below can be used. As described above, the various processors include a programmable logic device (PLD) as a processor of which the circuit configuration can be changed after manufacture, such as a field programmable gate array (FPGA), a dedicated electrical circuit as a processor having a dedicated circuit configuration for executing specific processing such as an application specific integrated circuit (ASIC), and the like, in addition to the CPU as a general-purpose processor that functions as various processing units by executing software (programs).</p><p id="p-0090" num="0089">One processing unit may be configured by one of the various processors, or may be configured by a combination of the same or different kinds of two or more processors (for example, a combination of a plurality of FPGAs or a combination of the CPU and the FPGA). In addition, a plurality of processing units may be configured by one processor.</p><p id="p-0091" num="0090">As an example where a plurality of processing units are configured by one processor, first, there is a form in which one processor is configured by a combination of one or more CPUs and software as typified by a computer, such as a client or a server, and this processor functions as a plurality of processing units. Second, there is a form in which a processor for realizing the function of the entire system including a plurality of processing units via one integrated circuit (IC) chip as typified by a system on chip (SoC) or the like is used. In this way, various processing units are configured by one or more of the above-described various processors as hardware structures.</p><p id="p-0092" num="0091">Furthermore, as the hardware structure of the various processors, more specifically, an electrical circuit (circuitry) in which circuit elements such as semiconductor elements are combined can be used.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A document creation support apparatus comprising at least one processor,<claim-text>wherein the processor is configured to:</claim-text><claim-text>generate a sentence related to a property of at least one structure of interest included in an image,</claim-text><claim-text>determine whether or not a sentence amount of the sentence is a prescribed amount, and</claim-text><claim-text>adjust the sentence amount such that the sentence amount is the prescribed amount based on a result of the determination.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The document creation support apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to adjust the sentence amount by selecting a property to be described in the sentence from among one or more properties of the structure of interest.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The document creation support apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to generate the sentence including a description regarding each of one or more properties specified for the structure of interest, and adjust the sentence amount by deleting, from the sentence, a description regarding a negative property among descriptions regarding each of a plurality of properties included in the sentence.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The document creation support apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to<claim-text>generate, for a plurality of structures of interest included in the image, a plurality of sentences describing properties of each of the structures of interest, and</claim-text><claim-text>adjust the sentence amount of the sentence for at least one of the plurality of structures of interest such that a total amount of the sentence generated for each of the plurality of structures of interest is the prescribed amount.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The document creation support apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the processor is configured to adjust the sentence amount by integrating common descriptions among the descriptions regarding each of the plurality of structures of interest included in the sentence.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The document creation support apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to<claim-text>generate, for a plurality of structures of interest included in the image, a plurality of candidate sentences describing properties of each of the structures of interest, and</claim-text><claim-text>adjust, for each of the plurality of structures of interest, the sentence amount by selecting a combination in which a sentence amount of a sentence including a selected candidate sentence is the prescribed amount from combinations of selecting one candidate sentence from among the plurality of candidate sentences.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The document creation support apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to display the sentence on a display.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The document creation support apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the image is a medical image, and the sentence is a medical sentence related to the structure of interest included in the medical image.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A document creation support method comprising:<claim-text>generating a sentence related to a property of at least one structure of interest included in an image;</claim-text><claim-text>determining whether or not a sentence amount of the sentence is a prescribed amount; and</claim-text><claim-text>adjusting the sentence amount such that the sentence amount is the prescribed amount based on a result of the determination.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A non-transitory computer-readable storage medium that stores a document creation support program causing a computer to execute a procedure comprising:<claim-text>generating a sentence related to a property of at least one structure of interest included in an image;</claim-text><claim-text>determining whether or not a sentence amount of the sentence is a prescribed amount; and</claim-text><claim-text>adjusting the sentence amount such that the sentence amount is the prescribed amount based on a result of the determination.</claim-text></claim-text></claim></claims></us-patent-application>
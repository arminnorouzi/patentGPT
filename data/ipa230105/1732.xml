<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230001733A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230001733</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17809764</doc-number><date>20220629</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>42</class><subclass>D</subclass><main-group>25</main-group><subgroup>20</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>42</class><subclass>D</subclass><main-group>25</main-group><subgroup>378</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20141001</date></cpc-version-indicator><section>B</section><class>42</class><subclass>D</subclass><main-group>25</main-group><subgroup>20</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20141001</date></cpc-version-indicator><section>B</section><class>42</class><subclass>D</subclass><main-group>25</main-group><subgroup>378</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SECURITY ARTICLE AUTHENTICATION</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63217956</doc-number><date>20210702</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>VIAVI Solutions Inc.</orgname><address><city>Chandler</city><state>AZ</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>HOUCK</last-name><first-name>William D.</first-name><address><city>Santa Rosa</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>SCHEER</last-name><first-name>Adam</first-name><address><city>Princeton</city><state>NJ</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>BILGER</last-name><first-name>Markus</first-name><address><city>Santa Rosa</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A user device may cause light to be emitted at a security article by one or more light emission devices of the user device. The user device may obtain from a first set of one or more optical sensor devices of the user device first sensor data associated with the security article, and may obtain from a second set of one or more optical sensor devices of the user device second sensor data associated with the security article. The user device may determine, based on the first sensor data and the second sensor data, one or more characteristics of a security feature of the security article. The user device may determine, based on the one or more characteristics of the security feature, whether the security article is authentic. The user device may cause, based on determining whether the security article is authentic, one or more actions to be performed.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="222.42mm" wi="152.57mm" file="US20230001733A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="217.85mm" wi="172.21mm" orientation="landscape" file="US20230001733A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="217.42mm" wi="172.21mm" orientation="landscape" file="US20230001733A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="211.92mm" wi="172.21mm" orientation="landscape" file="US20230001733A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="209.55mm" wi="172.21mm" orientation="landscape" file="US20230001733A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="223.86mm" wi="172.21mm" orientation="landscape" file="US20230001733A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="202.27mm" wi="172.21mm" orientation="landscape" file="US20230001733A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="205.49mm" wi="172.21mm" orientation="landscape" file="US20230001733A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="235.71mm" wi="154.60mm" file="US20230001733A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">RELATED APPLICATION</heading><p id="p-0002" num="0001">This application claims priority to U.S. Provisional Patent Application No. 63/217,956, filed on Jul. 2, 2021, and entitled &#x201c;SECURITY ARTICLE AUTHENTICATION,&#x201d; the content of which is incorporated by reference herein in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Some documents, such as monetary instruments, identity documents, and other documents of value, may include one or more security or authentication features to combat counterfeiting. For example, a surface of a document may include an application of magnetic ink that includes magnetically aligned magnetic flakes to create an optical feature (e.g., a color-shifting feature or a reflectivity feature).</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">Some implementations described herein relate to a method. The method may include causing, by a user device, light to be emitted at a security article by one or more light emission devices of the user device. The method may include obtaining, by the user device, from a first set of one or more optical sensor devices of a plurality of optical sensor devices of the user device, and based on causing the light to be emitted, first sensor data associated with the security article. The method may include obtaining, by the user device, from a second set of one or more optical sensor devices of the plurality of optical sensor devices of the user device, and based on causing the light to be emitted, second sensor data associated with the security article. The method may include determining, by the user device and based on the first sensor data and the second sensor data, identification information associated with the security article. The method may include identifying, by the user device and based on the first sensor data and the second sensor data, a security feature of the security article. The method may include determining, by the user device and based on identifying the security feature of the security article, one or more characteristics of the security feature. The method may include determining, by the user device and based on the identification information associated with the security article and the one or more characteristics of the security feature, whether the security article is authentic. The method may include causing, based on determining whether the security article is authentic, one or more actions to be performed.</p><p id="p-0005" num="0004">Some implementations described herein relate to a user device. The user device may include one or more memories and one or more processors coupled to the one or more memories. The user device may be configured to cause light to be emitted at a security article by one or more light emission devices of the user device. The user device may be configured to obtain from a first set of one or more optical sensor devices of a plurality of optical sensor devices of the user device, and based on causing the light to be emitted, first sensor data associated with the security article. The user device may be configured to obtain from a second set of one or more optical sensor devices of the plurality of optical sensor devices of the user device, and based on causing the light to be emitted, second sensor data associated with the security article. The user device may be configured to determine, based on the first sensor data and the second sensor data, one or more characteristics of a security feature of the security article. The user device may be configured to determine, based on the one or more characteristics of the security feature, whether the security article is authentic. The user device may be configured to cause, based on determining whether the security article is authentic, one or more actions to be performed.</p><p id="p-0006" num="0005">Some implementations described herein relate to a non-transitory computer-readable medium that stores a set of instructions for a user device. The set of instructions, when executed by one or more processors of the user device, may cause the user device to cause light to be emitted at a security article by one or more light emission devices of the user device. The set of instructions, when executed by one or more processors of the user device, may cause the user device to obtain, from a plurality of optical sensor devices of the user device, and based on causing the light to be emitted, sensor data associated with the security article. The set of instructions, when executed by one or more processors of the user device, may cause the user device to determine, based on the sensor data, one or more characteristics of a security feature of the security article. The set of instructions, when executed by one or more processors of the user device, may cause the user device to determine, based on the one or more characteristics of the security feature, whether the security article is authentic. The set of instructions, when executed by one or more processors of the user device, may cause the user device to cause, based on determining whether the security article is authentic, one or more actions to be performed.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref> are diagrams of an example implementation described herein.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIGS. <b>2</b>A-<b>2</b>C</figref> are diagrams of an example implementation described herein.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram of an example environment in which systems and/or methods described herein may be implemented.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram of example components of a device associated with security article authentication.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart of an example process associated with security article authentication.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0012" num="0011">The following detailed description of example implementations refers to the accompanying drawings. The same reference numbers in different drawings may identify the same or similar elements.</p><p id="p-0013" num="0012">In some cases, a document, such as paper currency, may include one or more security or authentication features, such as a watermark or a pattern printed with color shifting ink, on a region of the document. A person may directly inspect, or may use an authentication device, to analyze the document to determine that the one or more optical security features are present in the document. Based on identifying the one or more optical security features, the person, or the authentication device, may determine that the document is genuine. For example, a person may view a watermark in a dollar bill and may conclude that the dollar bill is not counterfeit. However, as advanced printing technology becomes more widely available (e.g., beyond government organizations or security-providing companies), a security feature may be able to be reproduced (or a facsimile security feature that appears to be similar to the security feature may be produced), which enables counterfeiting of the document and increases a likelihood that the counterfeit document is deemed legitimate.</p><p id="p-0014" num="0013">Some implementations described herein provide a user device that includes one or more light emission devices and a plurality of optical sensor devices (e.g., camera devices). The user device may cause the one or more light emission devices to emit light at a security article that includes a security feature. The light may be associated with one or more spectral ranges (e.g., an ultraviolet (UV) spectral range, a visual spectral range, and/or an infrared (IR) spectral range). A first set of one or more optical sensor devices and a second set of one or more optical sensor devices, of the plurality of optical sensor devices, may be configured to respectively detect light associated with a first spectral range and a second spectral range. Accordingly, the user device may obtain (e.g., based on causing the light to be emitted), from the first set of one or more optical sensor devices, first sensor data associated with the security article (e.g., in association with the first spectral range), and, from the second set of one or more optical sensor devices, second sensor data associated with the security article (e.g., in association with the second spectral range). Accordingly, the user device may process the first sensor data and the second sensor data to identify the security feature of the security article and to determine one or more characteristics of the security feature. The user device may therefore determine, based on the one or more characteristics of the security feature, whether the security article is authentic.</p><p id="p-0015" num="0014">In this way, the user device assists a user of the user device in authenticating the security article, without using a separate authentication device. This makes it easier to authenticate security articles, which increases a likelihood that fraudulent security articles will be discovered (and therefore removed from circulation). Accordingly, use of technical resources, such as computing resources (e.g., processing resources, memory resources, communication resources, and/or power resources, among other examples) to investigate counterfeiting, scan potentially counterfeit security articles, identify counterfeit security articles, and/or analyze security articles, among other examples, may be reduced.</p><p id="p-0016" num="0015">Further, some implementations described herein enable use of security features that include characteristics that are detectable outside a visual spectral range, and are therefore &#x201c;invisible&#x201d; to a human user. In this way a security feature may be &#x201c;hidden&#x201d; on a security article, by including characteristics that only the user device is able to detect and identify. This reduces a likelihood that the security feature can be fraudulently reproduced, which decreases a likelihood of counterfeiting of the security article.</p><p id="p-0017" num="0016">Additionally, some implementations described herein include providing visual, audible, and/or haptic information for enabling the user device to perform an authentication process of the security article. This assists visually impaired users, who may not otherwise be able to authenticate the security article.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref> are diagrams of an example implementation <b>100</b> described herein. As shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>B</figref>, example implementation <b>100</b> includes a user device <b>102</b>. <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> shows a front view of the user device <b>102</b> and <figref idref="DRAWINGS">FIG. <b>1</b>B</figref> shows a back view of the user device <b>102</b>. The user device <b>102</b> may include a plurality of optical sensor devices <b>104</b>, one or more light emission devices <b>106</b>, a display screen <b>108</b>, an audio component <b>110</b>, and/or a haptic component <b>112</b>.</p><p id="p-0019" num="0018">Each optical sensor device <b>104</b>, of the plurality of optical sensor devices <b>104</b>, may include, for example, an image sensor (e.g., an imaging &#x201c;camera&#x201d;), an ambient light sensor, a spectral sensor, a proximity sensor, a time-of-flight sensor, and/or one or more arrays of any of the preceding optical sensor devices. Each optical sensor device <b>104</b> may include a silicon (Si) based sensor, an indium-gallium-arsenide (InGaAs) based sensor, a lead-sulfide (PbS) based sensor, or a germanium (Ge) based sensor, and/or may utilize one or more sensor technologies, such as a complementary metal-oxide-semiconductor (CMOS) technology, or a charge-coupled device (CCD) technology, among other examples. In some implementations, optical sensor device <b>104</b> may include a front-side illumination (FSI) sensor, a back-side illumination (BSI) sensor, and/or the like.</p><p id="p-0020" num="0019">Each optical sensor device <b>104</b> may be configured to detect light associated with a spectral range (e.g., a light wavelength range). For example, an optical sensor device <b>104</b> may be configured to detect light associated with an ultraviolet (UV) spectral range (e.g., a range within 100 nanometers (nm) to 379 nm), a visible spectral range (e.g., a range within 380 nm to 779 nm), a near-infrared (NIR) spectral range (e.g., a range within 780 nm to 1399 nm), a short-wavelength infrared (SWIR) spectral range (e.g., a range within 1400 nm to 2999 nm), a mid-wavelength infrared (MWIR) spectral range (e.g., a range within 3000 nm to 7999 nm), and/or a long-wavelength infrared (LWIR) spectral range (e.g., a range within 8000 nm to 15000 nm), among other examples. In some implementations, a first optical sensor device <b>104</b> may be configured to detect light associated with a first spectral range and a second optical sensor device <b>104</b> may be configured to detect light associated with a second spectral range, wherein the first spectral range and the second spectral range are different (e.g., a minimum of the first spectral range is not equal to a minimum of the second spectral range and/or a maximum of the first spectral range is not equal to a maximum of the second spectral range), or, alternatively, the first spectral range and the second spectral range are the same (e.g., respective minimums and maximums of the first spectral range and the second spectral range are equal to each other). Upon detecting light associated with a particular spectral range, each optical sensor device <b>104</b> may generate sensor data associated with the particular spectral range. The sensor data may indicate an intensity of light associated with the particular spectral range that is incident on the optical sensor device <b>104</b> (e.g., active/inactive or a more granular indication of intensity). For example, the first optical sensor device <b>104</b> may generate sensor data associated with the first spectral range and the second optical sensor device <b>104</b> may generate sensor data associated with the second spectral range.</p><p id="p-0021" num="0020">Each light emission device <b>106</b>, of the one or more light emission devices <b>106</b> may include, for example, a halogen light, an incandescent light, a compact fluorescent (CFL) light, a laser, a light emitting diode (LED), a fluorescent light, a neon light, and/or one or more arrays of any of the above-mentioned light emission devices. Each light emission device <b>106</b> may be configured to emit light associated with a spectral range (e.g., a light wavelength range). For example, an emission device <b>106</b> may be configured to emit light associated with a UV spectral range, a visible spectral range, an NIR spectral range, an SWIR spectral range, an MWIR spectral range, and/or an LWIR spectral range, among other examples. In some implementations, a light emission device <b>106</b> may be configured to emit light associated with a broad spectral range, such as a range within 200 nm to 2000 nm. Additionally, or alternatively, a first light emission device <b>106</b> may be configured to emit light associated with a first spectral range and a second light emission device <b>106</b> may be configured to emit light associated with a second spectral range, wherein the first spectral range and the second spectral range are different (e.g., a minimum of the first spectral range is not equal to a minimum of the second spectral range and/or a maximum of the first spectral range is not equal to a maximum of the second spectral range), or, alternatively, the first spectral and the second spectral range are the same (e.g., respective minimums and maximums of the first spectral range and the second spectral range are equal to each other).</p><p id="p-0022" num="0021">The display screen <b>108</b> may be a liquid crystal display (LCD) display screen, a light emitting diode (LED) display screen, or an organic light emitting diode (OLED) display screen, among other examples. The display screen <b>108</b> may be configured to emit light associated with a spectral range, such as a visible spectral range (e.g., to present visual information to a user of the user device <b>102</b>). In some implementations, the display screen <b>108</b> may be configured to be a light emission device <b>106</b> of the one or more light emission devices <b>106</b>. The audio component <b>110</b> may be, for example, a speaker and/or a buzzer (e.g., that are configured to present audible information to the user of the user device <b>102</b>). The haptic component <b>112</b> may be, for example, a vibrator and/or an actuator (e.g., that are configured to present haptic information to the user of the user device <b>102</b>).</p><p id="p-0023" num="0022">In some implementations, the plurality of optical sensor devices <b>104</b> and the one or more light emission devices <b>106</b> may be disposed on an external surface of a side of the user device <b>102</b>. For example, as shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, the plurality of optical sensor devices <b>104</b> and the one or more light emission devices <b>106</b> may be disposed in a component cluster <b>114</b> on an external surface of the front side of the user device <b>102</b>, upon which the display screen <b>108</b> is also disposed. As another example, as shown in <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>, the plurality of optical sensor devices <b>104</b> and the one or more light emission devices <b>106</b> may be disposed in a component cluster <b>116</b> on an external surface of a back side of the user device. In some implementations, the plurality of optical sensor devices <b>104</b> may be arranged within a component cluster (component cluster <b>114</b> or component cluster <b>116</b>), such that two optical sensor devices <b>104</b> are separated by a particular distance (e.g., that is indicated by configuration information that is accessible to the user device <b>102</b>, as further described herein). As further shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, the haptic component <b>112</b> may be included in (e.g., integrated in) an internal environment of the user device <b>102</b>.</p><p id="p-0024" num="0023">As shown in <figref idref="DRAWINGS">FIG. <b>1</b>C</figref>, the example implementation <b>100</b> may include a security article <b>118</b>. The security article <b>118</b> may include currency, a bank note, a government issued identification card, a private organization identification card, a transaction card, an indication document (e.g., that indicates an author of the indication document; an originator, producer, or owner of a product or service associated with the indication document; and/or other information). As shown in <figref idref="DRAWINGS">FIG. <b>1</b>C</figref>, the security article <b>118</b> may include a security feature <b>120</b>. The security feature <b>120</b> may include, for example, a raised ink feature, a color-shifting ink feature, a fluorescent ink feature, a security thread feature, a watermark feature, a microprinting feature, a reflective feature, a refractive feature, a diffractive feature, a foil feature, a hologram feature, a window feature, an image feature, a graphic feature, a micro-optics feature, and/or a pattern feature. While <figref idref="DRAWINGS">FIG. <b>1</b>C</figref> shows a single security feature <b>120</b> included in the security article <b>118</b>, the security article may include multiple security features <b>120</b>. In some implementations, a security feature <b>120</b> may be associated with one or more regions of a surface (or surfaces) of the security article <b>118</b> (e.g., the security feature <b>120</b> may span the one or more regions of the surface of the security article <b>118</b>).</p><p id="p-0025" num="0024">In some implementations, the security article <b>118</b> may be authentic (e.g., may be an authentic security article). For example, the security article <b>118</b> may be what the security article <b>118</b> purports to be (e.g., based on labeling or other indicators on the security article <b>118</b>), such as currency, a bank note, a government issued identification card, a private organization identification card, a transaction card, and/or an indication document. Accordingly, the security feature <b>120</b> may include one or more characteristics (e.g., one or more optical characteristics and/or one or more composition characteristics, described herein) that indicate that the security article <b>118</b> is authentic (e.g., the one or more characteristics match expected characteristics of an authentic security article). Alternatively, in some implementations, the security article <b>118</b> may not be authentic (e.g., may be a fraudulent security article). For example, the security article <b>118</b> may not be what the security article <b>118</b> purports to be (e.g., based on labeling or other indicators on the security article <b>118</b>). For example, the security article <b>118</b> may be counterfeit currency, a counterfeit bank note, a counterfeit government issued identification card, a counterfeit private organization identification card, a counterfeit transaction card, and/or a counterfeit indication document. Accordingly, the security feature <b>120</b> may include one or more characteristics (e.g., one or more optical characteristics and/or one or more composition characteristics, described herein) that indicate that the security article <b>118</b> is not authentic (e.g., the one or more characteristics do not match expected characteristics of an authentic security article).</p><p id="p-0026" num="0025">As indicated above, <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref> are provided as examples. Other examples may differ from what is described with regard to <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>C</figref>.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIGS. <b>2</b>A-<b>2</b>C</figref> are diagrams of an example implementation <b>200</b> described herein. As shown in <figref idref="DRAWINGS">FIGS. <b>2</b>A-<b>2</b>C</figref>, the user device <b>102</b> may perform one or more processing steps related to authenticating the security article <b>118</b> (e.g., determining whether the security article is an authentic security article or a fraudulent security article).</p><p id="p-0028" num="0027">As shown in <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, and by reference number <b>202</b>, the user device <b>102</b> may initiate a process for authenticating the security article <b>118</b>. For example, a user of the user device <b>102</b> may interact with a user interface of the user device <b>102</b> to cause an application (e.g., that is configured to facilitate authenticating security articles) to run on the user device <b>102</b>. The user device <b>102</b>, when running the application, may provide, to the user of the user device <b>102</b>, one or more prompts, such as one or more visual prompts (e.g., via the display screen <b>108</b>), one or more audible prompts (e.g., via the audio component <b>110</b>), and/or one or more haptic prompts (e.g., via the haptic component <b>112</b>), to present the security article <b>118</b> to the user device <b>102</b>. For example, the user device <b>102</b> may instruct the user to position the security article <b>118</b> within respective fields of view of the plurality of optical sensor devices <b>104</b> (e.g., such that a particular surface, such as a front surface or a back surface, of the security article <b>118</b> is within the respective fields of view of the plurality of optical sensor devices <b>104</b>). Accordingly, the user of the user device <b>102</b> may present the security article <b>118</b> to the user device <b>102</b> (e.g., by positioning the security article <b>118</b> to be within the respective fields of view of the plurality of optical sensor devices <b>104</b>).</p><p id="p-0029" num="0028">As further shown in <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, and by reference number <b>204</b>, the user device <b>102</b> (e.g., when running the application) may cause light to be emitted at the security article <b>118</b> by the one or more light emission devices <b>106</b> of the user device <b>102</b>. For example, the user device <b>102</b> may send one or more signals to the one or more light emission devices <b>106</b> to cause the one or more light emission devices <b>106</b> of the user device <b>102</b> to emit the light at the security article <b>118</b>. In some implementations, the user device <b>102</b> may cause the one or more light emission devices <b>106</b> of the user device <b>102</b> to emit light associated with one or more spectral ranges at the security article <b>118</b>. For example, the user device <b>102</b> may send a first signal to the one or more light emission devices <b>106</b> to cause at least one light emission device <b>106</b> to emit light associated with a UV spectral range, a second signal to the one or more light emission devices <b>106</b> to cause at least one light emission device <b>106</b> to emit light associated with a visible spectral range, a third signal to the one or more light emission devices <b>106</b> to cause at least one light emission device <b>106</b> to emit light associated with an NIR spectral range, a fourth signal to the one or more light emission devices <b>106</b> to cause at least one light emission device <b>106</b> to emit light associated with an SWIR spectral range, a fifth signal to the one or more light emission devices <b>106</b> to cause at least one light emission device <b>106</b> to emit light associated with an MWIR spectral range, and/or a sixth signal to the one or more light emission devices <b>106</b> to cause at least one light emission device <b>106</b> to emit light associated with an LWIR spectral range. In some implementations, the user device <b>102</b> may cause the one or more light emission devices <b>106</b> of the user device <b>102</b> to emit light associated with the one or more spectral ranges at the security article <b>118</b> at the same time (e.g., during a same time range, or during two or more time ranges that at least partially overlap), or, alternatively at different times (e.g., at two or more time ranges that do not overlap).</p><p id="p-0030" num="0029">As further shown in <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, and by reference number <b>206</b>, the user device <b>102</b> (e.g., when running the application) may obtain, from the plurality of optical sensor devices <b>104</b>, sensor data associated with the security article <b>118</b> (e.g., based on causing light to be emitted at the security article <b>118</b> by the one or more light emission devices <b>106</b>). For example, the user device <b>102</b> may obtain, from a first set of one or more optical sensor devices <b>104</b>, of the plurality of optical sensor devices <b>104</b>, first sensor data associated with the security article <b>118</b>; the user device <b>102</b> may obtain, from a second set of one or more optical sensor devices <b>104</b>, of the plurality of optical sensor devices <b>104</b>, second sensor data associated with the security article <b>118</b>; the user device <b>102</b> may obtain, from a third set of one or more optical sensor devices <b>104</b>, of the plurality of optical sensor devices <b>104</b>, third sensor data associated the security article <b>118</b>; and/or so on. When the first set of one or more optical sensor devices <b>104</b> is configured to detect light associated with a first spectral range, the first sensor data may be associated with the first spectral range; when the second set of one or more optical sensor devices <b>104</b> is configured to detect light associated with a second spectral range, the second sensor data may be associated with the second spectral range; when the third set of one or more optical sensor devices <b>104</b> is configured to detect light associated with a third spectral range, the third sensor data may be associated with the third spectral range; and/or so on. In this way, the user device <b>102</b> may obtain sensor data (e.g., discrete sensor data) associated with the security article <b>118</b> for each spectral range, of one or more spectral ranges, that the plurality of optical sensor devices <b>104</b> are configured to detect.</p><p id="p-0031" num="0030">In some implementations, the user device <b>102</b> may cause the plurality of optical sensor devices <b>104</b> to generate sensor data at a same time. For example, the user device <b>102</b> may send one or more signals to the plurality of optical sensor devices <b>104</b> to cause the plurality of optical sensor devices <b>104</b> to generate the sensor data during a same time range. In some implementations, the user device <b>102</b> may cause the plurality of optical sensor devices <b>104</b> to generate sensor data at different times. For example, the user device <b>102</b> may send a first signal to the first set of one or more optical sensor devices <b>104</b> to cause the first set of one or more optical sensor devices <b>104</b> to generate the first sensor data during a first time range; may send a second signal to the second set of one or more optical sensor devices <b>104</b> to cause the second set of one or more optical sensor devices <b>104</b> to generate the second sensor data during a second time range (e.g., that does not overlap with the first time range); may send a third signal to the third set of one or more optical sensor devices <b>104</b> to cause the third set of one or more optical sensor devices <b>104</b> to generate the third sensor data during a third time range (e.g., that does not overlap with the first time range and does not overlap with the second time range); and/or so on.</p><p id="p-0032" num="0031">In some implementations, the user device <b>102</b> may cause the one or more light emission devices <b>106</b> of the user device <b>102</b> to emit light associated with a spectral range at a same time that the user device <b>102</b> causes a set of one or more optical sensor devices <b>104</b>, that are configured to detect the spectral range, to generate sensor data associated with the spectral range. For example, the user device <b>102</b> may send respective control signals to the one or more light emission devices <b>106</b> and the first set of one or more optical sensor devices <b>104</b> to cause at least one light emission device <b>106</b> to emit light associated with a first spectral range during a first time range and to cause the first set of one or more optical sensor devices <b>104</b> to generate first sensor data associated with the first spectral range during the first time range; may send respective control signals to the one or more light emission devices <b>106</b> and the second set of one or more optical sensor devices <b>104</b> to cause at least one light emission device <b>106</b> to emit light associated with a second spectral range during a second time range and to cause the second set of one or more optical sensor devices <b>104</b> to generate second sensor data associated with the second spectral range during the second time range; may send respective control signals to the one or more light emission devices <b>106</b> and the third set of one or more optical sensor devices <b>104</b> to cause at least one light emission device <b>106</b> to emit light associated with a third spectral range during a third time range and to cause the third set of one or more optical sensor devices <b>104</b> to generate third sensor data associated with the third spectral range during the third time range; and/or so on. In this way, the user device <b>102</b> increases a likelihood that the security article <b>118</b> and the security feature <b>120</b> are illuminated with light associated with a particular spectral range when a set of one or more optical sensor devices <b>104</b> is to generate sensor data associated with the spectral range. Further, the set of one or more optical sensor devices <b>104</b> may generate more accurate sensor data associated with the spectral range than would be generated otherwise (e.g., because the light associated with the particular spectral range is not affected by interference or other optical issues that would result from other light associated with one or more other spectral ranges being emitted at the same time).</p><p id="p-0033" num="0032">In some implementations, the user device <b>102</b> may cause the one or more light emission devices <b>106</b> of the user device <b>102</b> to emit light associated with a spectral range at a same time that the user device <b>102</b> causes a set of one or more optical sensor devices <b>104</b>, that are configured to detect a different spectral range, to generate sensor data associated with the different spectral range. In this way, the set of one or more optical sensor devices <b>104</b> may generate sensor data related to a fluorescence effect associated with the security article <b>118</b> (e.g., when the security feature <b>120</b> of the security article <b>118</b> includes a fluorescent ink feature). In an example, the user device <b>102</b> may cause at least one light emission device <b>106</b> to emit light associated with a third spectral range (e.g., a UV spectral range) during a time range, and may cause the first set of one or more optical sensor devices <b>104</b> to generate first sensor data associated with a first spectral range (e.g., a visual spectral range) during the time range and the second set of one or more optical sensor devices <b>104</b> to generate second sensor data associated with a second spectral range (e.g., an NIR spectral range) during the time range. The third spectral range may be different than the first spectral range and the second spectral range.</p><p id="p-0034" num="0033">As shown in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, and by reference number <b>208</b>, the user device <b>102</b> (e.g., when running the application) may determine identification information associated with the security article <b>118</b> (e.g., based on the sensor data obtained by the user device <b>102</b>). In some implementations, the user device <b>102</b> may process the sensor data (e.g., using one or more machine vision techniques, such as an object detection technique, an optical character recognition technique, and/or another machine vision technique) to determine the identification information. For example, the user device <b>102</b> may process first sensor data (e.g., that is associated with a first spectral range), second sensor data (e.g., that is associated with a second spectral range), third sensor data (e.g., that is associated with a third spectral range), and/or so on, that was obtained by the user device <b>102</b> (e.g., as described herein) to determine the identification information associated with the security article <b>118</b>. The identification information associated with the security article <b>118</b> may include an identifier (e.g., a universally unique identifier (UUID), a text string, a number string, and/or an alphanumeric string, among other examples) associated with the security article <b>118</b>, and the identifier may correspond to printed, displayed, and/or other information that is otherwise included in the security article <b>118</b>.</p><p id="p-0035" num="0034">As further shown in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, and by reference number <b>210</b>, the user device <b>102</b> (e.g., when running the application) may identify the security feature <b>120</b> of the security article <b>118</b> (e.g., based on the sensor data obtained by the user device <b>102</b>). In some implementations, the user device <b>102</b> may process the sensor data (e.g., using one or more machine vision techniques) to identify the security feature <b>120</b>. For example, the user device <b>102</b> may process first sensor data (e.g., that is associated with a first spectral range), second sensor data (e.g., that is associated with a second spectral range), third sensor data (e.g., that is associated with a third spectral range), and/or so on, that was obtained by the user device <b>102</b> (e.g., as described herein) to identify the security feature <b>120</b>. Additionally, or alternatively, the user device <b>102</b> may process the sensor data to identify at least one portion of the sensor data that is associated with the security feature <b>120</b> (e.g., at least one portion of the sensor data that is associated with one or more regions of a surface (or surfaces) of the security article <b>118</b> upon which the security feature <b>120</b> is disposed). For example, the user device <b>102</b> may process the first sensor data to identify at least one portion of the first sensor data that is associated with the security feature <b>120</b>, the second sensor data to identify at least one portion of the second sensor data that is associated with the security feature <b>120</b>, the third sensor data to identify at least one portion of the third sensor data that is associated with the security feature <b>120</b>, and/or so on.</p><p id="p-0036" num="0035">As further shown in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, and by reference number <b>212</b>, the user device <b>102</b> (e.g., when running the application) may determine one or more characteristics of the security feature <b>120</b> (e.g., based on identifying the security feature <b>120</b>). The one or more characteristics may include, for example, one or more optical characteristics of the security feature <b>120</b> (e.g., one or more colors, such as of one or more inks of the security feature <b>120</b>; one or more dimensions, such as respective heights, widths, and/or thicknesses of one or more inks, security threads, and/or other features of the security feature <b>120</b>; one or more reflective characteristics; one or more refractive characteristics; one or more diffractive characteristics; and/or one or more fluorescent characteristics) and/or one or more composition characteristics of the security feature <b>120</b> (e.g., one or more chemical compositions, such as of one or more inks, security threads, and/or other features of the security feature; one or more composition ratios, such as composition ratios of one or more colors, materials, or other components of the security feature <b>120</b>), among other examples. As a first specific example, when the security feature <b>120</b> includes a color-shifting ink feature, the one or more characteristics may include respective colors of the color-shifting ink feature at one or more different viewing angles. As a second specific example, when the security feature <b>120</b> includes a reflective feature, the one or more characteristics may include respective reflectivity values of the reflective feature for one or more spectral ranges.</p><p id="p-0037" num="0036">In some implementations, the user device <b>102</b> may process the sensor data (e.g., using one or more machine learning models) to identify the one or more characteristics of the security feature <b>120</b>. For example, the user device <b>102</b> may process the first sensor data (e.g., that is associated with a first spectral range), the second sensor data (e.g., that is associated with a second spectral range), the third sensor data (e.g., that is associated with a third spectral range), and/or so on, to identify the one or more characteristics of the security feature <b>120</b>. With regard to the first specific example above, the user device <b>102</b> may process the first sensor data (e.g., in association with configuration information that indicates a distance between the first set of one or more optical sensor devices <b>104</b> and the second set of one or more optical sensor devices <b>104</b>) to determine a first color of the security feature <b>120</b> at a first viewing angle, may process the second sensor data (e.g., in association with the configuration information) to determine a second color of the security feature <b>120</b> at a second viewing angle, and/or so on. With regard to the second specific example above, the user device <b>102</b> may process the first sensor data to determine a first reflectivity value of the reflective feature for the first spectral range, may process the second sensor data to determine a second reflectivity value of the reflective feature for the second spectral range, and/or so on.</p><p id="p-0038" num="0037">Additionally, or alternatively, the user device <b>102</b> may process the at least one portion of the sensor data that is associated with the security feature <b>120</b> (e.g., using the one or more machine learning models) to identify the one or more characteristics of the security feature <b>120</b>. For example, the user device <b>102</b> may process the at least one portion of the first sensor data, the at least one portion of the second sensor data, the at least one portion of the third sensor data, and/or so on, to identify the one or more characteristics of the security feature <b>120</b>. In this way, when processing the at least one portion of the sensor data, rather than all of the sensor data, to identify the one or more characteristics of the security feature <b>120</b>, the user device <b>102</b> may use fewer computing resources (e.g., processing resources, memory resources, communication resources, and/or power resources, among other examples) of the user device <b>102</b>, which improves a performance of the user device <b>102</b>.</p><p id="p-0039" num="0038">As shown in <figref idref="DRAWINGS">FIG. <b>2</b>C</figref>, and by reference number <b>214</b>, the user device <b>102</b> (e.g., when running the application) may determine whether the security article <b>118</b> is authentic (e.g., based on determining the identification information associated with the security article, based on identifying the security feature <b>120</b>, and/or based on identifying the one or more characteristics of the security feature <b>120</b>). For example, the user device <b>102</b> may process (e.g., using one or more machine learning models) the identification information associated with the security article <b>118</b>, information identifying the security feature <b>120</b>, and/or information identifying the one or more characteristics of the security feature <b>120</b> to determine whether the security article <b>118</b> is authentic.</p><p id="p-0040" num="0039">As another example, the user device <b>102</b> may search, based on the identification information associated with the security article <b>118</b>, a data structure (e.g., a database, an electronic folder, an electronic table, or another data structure) that stores security article authentication information for an entry associated with the security article <b>118</b>. The entry may include characteristic information associated with the security feature <b>120</b> of the security article <b>118</b>. The user device <b>102</b> may compare the characteristic information and the one or more characteristics of the security feature <b>120</b> (e.g., identified by the user device <b>102</b>, as described elsewhere herein) to determine whether the security article <b>118</b> is authentic. In some implementations, to make a comparison, the user device <b>102</b> may determine whether the characteristic information matches the one or more characteristics (e.g., is the same as, or is similar to, the one or more characteristics). With regard to the first specific example above, when the security feature <b>120</b> includes a color-shifting ink feature, the user device <b>102</b> may determine whether the characteristic information (e.g., that indicates a color-shift property of the color-shifting ink feature at one or more different viewing angles) matches the one or more characteristics (e.g., that includes respective colors of the color-shifting ink feature at one or more different viewing angles). With regard to the second specific example above, when the security feature <b>120</b> includes a reflective feature, the user device <b>102</b> may determine whether the characteristic information (e.g., that indicates a reflectivity of the reflective feature for one or more spectral ranges) matches the one or more characteristics (e.g., that includes respective reflectivity values of the reflective feature for one or more spectral ranges). The user device <b>102</b> may determine that the security article <b>118</b> is authentic when the user device <b>102</b> determines that the characteristic information matches the one or more characteristics. Alternatively, the user device <b>102</b> may determine that the security article <b>118</b> is not authentic when the user device <b>102</b> determines that the characteristic information does not match the one or more characteristics.</p><p id="p-0041" num="0040">In some implementations, the user device <b>102</b> (e.g., when running the application) may cause (e.g., based on determining whether the security article <b>118</b> is authentic) one or more actions to be performed. For example, as shown by reference number <b>216</b>, the user device <b>102</b> may cause authentication information indicating whether the security article <b>118</b> is authentic to be presented to the user of the user device <b>102</b>. For example, the user device <b>102</b> may cause the authentication information to be visually displayed via the display screen <b>108</b>, audibly presented via the audio component <b>110</b>, and/or haptically presented via the haptic component <b>112</b>. The information may indicate whether the security article <b>118</b> is or is not fraudulent, whether the security article <b>118</b> can be or cannot be used for a transaction, whether a holder of the security article <b>118</b> can or cannot access a restricted area, and/or whether a locked resource is to be unlocked or to remain locked, among other examples.</p><p id="p-0042" num="0041">In some implementations, the user device <b>102</b> may cause (e.g., based on determining whether the security article <b>118</b> is authentic) granting or denying access to a resource (e.g., a prescription drug, a hazardous material, and/or a restricted area, among other examples). For example, as shown by reference number <b>218</b>, when the user device <b>102</b> determines that the security article <b>118</b> is authentic, the user device <b>102</b> may send a signal to a remote device <b>220</b> associated with the resource to cause the remote device <b>220</b> to release the resource or otherwise allow a holder of the security article <b>118</b> access to the resource. As another example, when the user device <b>102</b> determines that the security article <b>118</b> is not authentic, the user device <b>102</b> may send a signal to the remote device <b>220</b> associated with the resource to cause the remote device <b>220</b> to lock the resource (or to maintain a lock on the resource) or otherwise prevent a holder of the security article <b>118</b> from accessing the resource.</p><p id="p-0043" num="0042">As indicated above, <figref idref="DRAWINGS">FIGS. <b>2</b>A-<b>2</b>C</figref> are provided as examples. Other examples may differ from what is described with regard to <figref idref="DRAWINGS">FIGS. <b>2</b>A-<b>2</b>C</figref>.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram of an example environment <b>300</b> in which systems and/or methods described herein may be implemented. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, environment <b>300</b> may include the user device <b>102</b>, the remote device <b>220</b>, and a network <b>310</b>. Devices of environment <b>300</b> may interconnect via wired connections, wireless connections, or a combination of wired and wireless connections.</p><p id="p-0045" num="0044">The user device <b>102</b> includes one or more devices capable of receiving, generating, storing, processing, and/or providing information associated with security article authentication, as described elsewhere herein. The user device <b>102</b> may include a communication device and/or a computing device. For example, the user device <b>102</b> may include a wireless communication device, a mobile phone, a user equipment, a laptop computer, a tablet computer, a desktop computer, a wearable communication device (e.g., a smart wristwatch, a pair of smart eyeglasses, a head mounted display, or a virtual reality headset), or a similar type of device. In some implementations, the user device <b>102</b> may receive information from and/or transmit information to another device in environment <b>300</b>, such as the remote device <b>220</b>.</p><p id="p-0046" num="0045">The remote device <b>220</b> includes one or more devices capable of receiving, generating, storing, processing, and/or providing security article authentication, as described elsewhere herein. The remote device <b>220</b> may include a communication device and/or a computing device. For example, the remote device <b>220</b> may include a wireless communication device, a mobile phone, a user equipment, a laptop computer, a tablet computer, a desktop computer, a server, such as an application server, a client server, a web server, a database server, a host server, a proxy server, a virtual server (e.g., executing on computing hardware), a server in a cloud computing system, a device that computing hardware used in a cloud computing environment, or a similar type of device.</p><p id="p-0047" num="0046">The network <b>310</b> includes one or more wired and/or wireless networks. For example, the network <b>310</b> may include a wireless wide area network (e.g., a cellular network or a public land mobile network), a local area network (e.g., a wired local area network or a wireless local area network (WLAN), such as a Wi-Fi network), a personal area network (e.g., a Bluetooth network), a near-field communication network, a telephone network, a private network, the Internet, and/or a combination of these or other types of networks. The network <b>310</b> enables communication among the devices of environment <b>300</b>.</p><p id="p-0048" num="0047">The number and arrangement of devices and networks shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> are provided as an example. In practice, there may be additional devices and/or networks, fewer devices and/or networks, different devices and/or networks, or differently arranged devices and/or networks than those shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. Furthermore, two or more devices shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may be implemented within a single device, or a single device shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may be implemented as multiple, distributed devices. Additionally, or alternatively, a set of devices (e.g., one or more devices) of environment <b>300</b> may perform one or more functions described as being performed by another set of devices of environment <b>300</b>.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram of example components of a device <b>400</b> associated with security article authentication. Device <b>400</b> may correspond to the user device <b>102</b> and/or the remote device <b>220</b>. In some implementations, the user device <b>102</b> and/or the remote device <b>220</b> include one or more devices <b>400</b> and/or one or more components of device <b>400</b>. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, device <b>400</b> may include a bus <b>410</b>, a processor <b>420</b>, a memory <b>430</b>, an input component <b>440</b>, an output component <b>450</b>, and a communication component <b>460</b>.</p><p id="p-0050" num="0049">Bus <b>410</b> includes one or more components that enable wired and/or wireless communication among the components of device <b>400</b>. Bus <b>410</b> may couple together two or more components of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, such as via operative coupling, communicative coupling, electronic coupling, and/or electric coupling. Processor <b>420</b> includes a central processing unit, a graphics processing unit, a microprocessor, a controller, a microcontroller, a digital signal processor, a field-programmable gate array, an application-specific integrated circuit, and/or another type of processing component. Processor <b>420</b> is implemented in hardware, firmware, or a combination of hardware and software. In some implementations, processor <b>420</b> includes one or more processors capable of being programmed to perform one or more operations or processes described elsewhere herein.</p><p id="p-0051" num="0050">Memory <b>430</b> includes volatile and/or nonvolatile memory. For example, memory <b>430</b> may include random access memory (RAM), read only memory (ROM), a hard disk drive, and/or another type of memory (e.g., a flash memory, a magnetic memory, and/or an optical memory). Memory <b>430</b> may include internal memory (e.g., RAM, ROM, or a hard disk drive) and/or removable memory (e.g., removable via a universal serial bus connection). Memory <b>430</b> may be a non-transitory computer-readable medium. Memory <b>430</b> stores information, instructions, and/or software (e.g., one or more software applications) related to the operation of device <b>400</b>. In some implementations, memory <b>430</b> includes one or more memories that are coupled to one or more processors (e.g., processor <b>420</b>), such as via bus <b>410</b>.</p><p id="p-0052" num="0051">Input component <b>440</b> enables device <b>400</b> to receive input, such as user input and/or sensed input. For example, input component <b>440</b> may include a touch screen, a keyboard, a keypad, a mouse, a button, a microphone, a switch, a sensor, a global positioning system sensor, an accelerometer, a gyroscope, and/or an actuator. Output component <b>450</b> enables device <b>400</b> to provide output, such as via a display, a speaker, and/or a light-emitting diode. Communication component <b>460</b> enables device <b>400</b> to communicate with other devices via a wired connection and/or a wireless connection. For example, communication component <b>460</b> may include a receiver, a transmitter, a transceiver, a modem, a network interface card, and/or an antenna.</p><p id="p-0053" num="0052">Device <b>400</b> may perform one or more operations or processes described herein. For example, a non-transitory computer-readable medium (e.g., memory <b>430</b>) may store a set of instructions (e.g., one or more instructions or code) for execution by processor <b>420</b>. Processor <b>420</b> may execute the set of instructions to perform one or more operations or processes described herein. In some implementations, execution of the set of instructions, by one or more processors <b>420</b>, causes the one or more processors <b>420</b> and/or the device <b>400</b> to perform one or more operations or processes described herein. In some implementations, hardwired circuitry is used instead of or in combination with the instructions to perform one or more operations or processes described herein. Additionally, or alternatively, processor <b>420</b> may be configured to perform one or more operations or processes described herein. Thus, implementations described herein are not limited to any specific combination of hardware circuitry and software.</p><p id="p-0054" num="0053">The number and arrangement of components shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> are provided as an example. Device <b>400</b> may include additional components, fewer components, different components, or differently arranged components than those shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. Additionally, or alternatively, a set of components (e.g., one or more components) of device <b>400</b> may perform one or more functions described as being performed by another set of components of device <b>400</b>.</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart of an example process <b>500</b> associated with security article authentication. In some implementations, one or more process blocks of <figref idref="DRAWINGS">FIG. <b>5</b></figref> are performed by a user device (e.g., user device <b>102</b>). In some implementations, one or more process blocks of <figref idref="DRAWINGS">FIG. <b>5</b></figref> are performed by another device or a group of devices separate from or including the user device, such as a remote device (e.g., remote device <b>220</b>). Additionally, or alternatively, one or more process blocks of <figref idref="DRAWINGS">FIG. <b>5</b></figref> may be performed by one or more components of device <b>400</b>, such as processor <b>420</b>, memory <b>430</b>, input component <b>440</b>, output component <b>450</b>, and/or communication component <b>460</b>.</p><p id="p-0056" num="0055">As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, process <b>500</b> may include causing light to be emitted at a security article by one or more light emission devices of the user device (block <b>510</b>). For example, the user device may cause light to be emitted at a security article by one or more light emission devices of the user device, as described above.</p><p id="p-0057" num="0056">As further shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, process <b>500</b> may include obtaining from a first set of one or more optical sensor devices of a plurality of optical sensor devices of the user device, and based on causing the light to be emitted, first sensor data associated with the security article (block <b>520</b>). For example, the user device may obtain from a first set of one or more optical sensor devices of a plurality of optical sensor devices of the user device, and based on causing the light to be emitted, first sensor data associated with the security article, as described above.</p><p id="p-0058" num="0057">As further shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, process <b>500</b> may include obtaining from a second set of one or more optical sensor devices of the plurality of optical sensor devices of the user device, and based on causing the light to be emitted, second sensor data associated with the security article (block <b>530</b>). For example, the user device may obtain from a second set of one or more optical sensor devices of the plurality of optical sensor devices of the user device, and based on causing the light to be emitted, second sensor data associated with the security article, as described above.</p><p id="p-0059" num="0058">As further shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, process <b>500</b> may include determining, based on the first sensor data and the second sensor data, identification information associated with the security article (block <b>540</b>). For example, the user device may determine, based on the first sensor data and the second sensor data, identification information associated with the security article, as described above.</p><p id="p-0060" num="0059">As further shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, process <b>500</b> may include identifying, based on the first sensor data and the second sensor data, a security feature of the security article (block <b>550</b>). For example, the user device may identify, based on the first sensor data and the second sensor data, a security feature of the security article, as described above.</p><p id="p-0061" num="0060">As further shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, process <b>500</b> may include determining, based on identifying the security feature of the security article, one or more characteristics of the security feature (block <b>560</b>). For example, the user device may determine, based on identifying the security feature of the security article, one or more characteristics of the security feature, as described above.</p><p id="p-0062" num="0061">As further shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, process <b>500</b> may include determining, based on the identification information associated with the security article and the one or more characteristics of the security feature, whether the security article is authentic (block <b>570</b>). For example, the user device may determine, based on the identification information associated with the security article and the one or more characteristics of the security feature, whether the security article is authentic, as described above.</p><p id="p-0063" num="0062">As further shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, process <b>500</b> may include causing, based on determining whether the security article is authentic, one or more actions to be performed (block <b>580</b>). For example, the user device may cause, based on determining whether the security article is authentic, one or more actions to be performed, as described above.</p><p id="p-0064" num="0063">Process <b>500</b> may include additional implementations, such as any single implementation or any combination of implementations described below and/or in connection with one or more other processes described elsewhere herein.</p><p id="p-0065" num="0064">In a first implementation, the security feature includes at least one of a raised ink feature, a color-shifting ink feature, a fluorescent ink feature, a security thread feature, a watermark feature, a microprinting feature, a reflective feature, a refractive feature, a diffractive feature, a foil feature, a hologram feature, a window feature, an image feature, a graphic feature, or a pattern feature.</p><p id="p-0066" num="0065">In a second implementation, alone or in combination with the first implementation, the first sensor data is associated with a first spectral range and the second sensor data is associated with a second spectral range, wherein the first spectral range and the second spectral range are different (e.g., the first sensor data and the second sensor data are associated with different spectral ranges).</p><p id="p-0067" num="0066">In a third implementation, alone or in combination with one or more of the first and second implementations, the light is associated with the first spectral range and the second spectral range.</p><p id="p-0068" num="0067">In a fourth implementation, alone or in combination with one or more of the first through third implementations, the light is associated with a third spectral range, and the third spectral range is different than the first spectral range and the second spectral range.</p><p id="p-0069" num="0068">In a fifth implementation, alone or in combination with one or more of the first through fourth implementations, the first set of one or more optical sensor devices generates the first sensor data during a first time range, the second set of one or more optical sensor devices generates the second sensor data during a second time range, and the first time range and the second time range at least partially overlap.</p><p id="p-0070" num="0069">In a sixth implementation, alone or in combination with one or more of the first through fifth implementations, the first set of one or more optical sensor devices generates the first sensor data during a first time range, the second set of one or more optical sensor devices generates the second sensor data during a second time range, and the first time range and the second time range do not overlap.</p><p id="p-0071" num="0070">In a seventh implementation, alone or in combination with one or more of the first through sixth implementations, determining the one or more characteristics of the security feature comprises processing at least one portion of the first sensor data associated with the security feature of the security article and at least one portion of the second sensor data associated with the security feature of the security article to determine the one or more characteristics of the security feature.</p><p id="p-0072" num="0071">In an eighth implementation, alone or in combination with one or more of the first through seventh implementations, causing the one or more actions to be performed comprises causing at least one of: causing authentication information indicating whether the security article is authentic to be visually displayed via a display screen of the user device, causing the authentication information to be audibly presented via an audio component of the user device, or causing the authentication information to be haptically presented via a haptic component of the user device.</p><p id="p-0073" num="0072">In an ninth implementation, alone or in combination with one or more of the first through eighth implementations, causing the one or more actions to be performed comprises granting or denying access to a resource based on determining whether the security article is authentic.</p><p id="p-0074" num="0073">Although <figref idref="DRAWINGS">FIG. <b>5</b></figref> shows example blocks of process <b>500</b>, in some implementations, process <b>500</b> includes additional blocks, fewer blocks, different blocks, or differently arranged blocks than those depicted in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. Additionally, or alternatively, two or more of the blocks of process <b>500</b> may be performed in parallel.</p><p id="p-0075" num="0074">The foregoing disclosure provides illustration and description, but is not intended to be exhaustive or to limit the implementations to the precise forms disclosed. Modifications and variations may be made in light of the above disclosure or may be acquired from practice of the implementations.</p><p id="p-0076" num="0075">As used herein, the term &#x201c;component&#x201d; is intended to be broadly construed as hardware, firmware, or a combination of hardware and software. It will be apparent that systems and/or methods described herein may be implemented in different forms of hardware, firmware, and/or a combination of hardware and software. The actual specialized control hardware or software code used to implement these systems and/or methods is not limiting of the implementations. Thus, the operation and behavior of the systems and/or methods are described herein without reference to specific software code&#x2014;it being understood that software and hardware can be used to implement the systems and/or methods based on the description herein.</p><p id="p-0077" num="0076">Even though particular combinations of features are recited in the claims and/or disclosed in the specification, these combinations are not intended to limit the disclosure of various implementations. In fact, many of these features may be combined in ways not specifically recited in the claims and/or disclosed in the specification. Although each dependent claim listed below may directly depend on only one claim, the disclosure of various implementations includes each dependent claim in combination with every other claim in the claim set. As used herein, a phrase referring to &#x201c;at least one of&#x201d; a list of items refers to any combination of those items, including single members. As an example, &#x201c;at least one of: a, b, or c&#x201d; is intended to cover a, b, c, a-b, a-c, b-c, and a-b-c, as well as any combination with multiple of the same item.</p><p id="p-0078" num="0077">No element, act, or instruction used herein should be construed as critical or essential unless explicitly described as such. Also, as used herein, the articles &#x201c;a&#x201d; and &#x201c;an&#x201d; are intended to include one or more items, and may be used interchangeably with &#x201c;one or more.&#x201d; Further, as used herein, the article &#x201c;the&#x201d; is intended to include one or more items referenced in connection with the article &#x201c;the&#x201d; and may be used interchangeably with &#x201c;the one or more.&#x201d; Furthermore, as used herein, the term &#x201c;set&#x201d; is intended to include one or more items (e.g., related items, unrelated items, or a combination of related and unrelated items), and may be used interchangeably with &#x201c;one or more.&#x201d; Where only one item is intended, the phrase &#x201c;only one&#x201d; or similar language is used. Also, as used herein, the terms &#x201c;has,&#x201d; &#x201c;have,&#x201d; &#x201c;having,&#x201d; or the like are intended to be open-ended terms. Further, the phrase &#x201c;based on&#x201d; is intended to mean &#x201c;based, at least in part, on&#x201d; unless explicitly stated otherwise. Also, as used herein, the term &#x201c;or&#x201d; is intended to be inclusive when used in a series and may be used interchangeably with &#x201c;and/or,&#x201d; unless explicitly stated otherwise (e.g., if used in combination with &#x201c;either&#x201d; or &#x201c;only one of&#x201d;).</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method, comprising:<claim-text>causing, by a user device, light to be emitted at a security article by one or more light emission devices of the user device;</claim-text><claim-text>obtaining, by the user device, from a first set of one or more optical sensor devices of a plurality of optical sensor devices of the user device, and based on causing the light to be emitted, first sensor data associated with the security article;</claim-text><claim-text>obtaining, by the user device, from a second set of one or more optical sensor devices of the plurality of optical sensor devices of the user device, and based on causing the light to be emitted, second sensor data associated with the security article;</claim-text><claim-text>determining, by the user device and based on the first sensor data and the second sensor data, identification information associated with the security article;</claim-text><claim-text>identifying, by the user device and based on the first sensor data and the second sensor data, a security feature of the security article;</claim-text><claim-text>determining, by the user device and based on identifying the security feature of the security article, one or more characteristics of the security feature;</claim-text><claim-text>determining, by the user device and based on the identification information associated with the security article and the one or more characteristics of the security feature, whether the security article is authentic; and</claim-text><claim-text>causing, based on determining whether the security article is authentic, one or more actions to be performed.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the security feature includes at least one of:<claim-text>a raised ink feature,</claim-text><claim-text>a color-shifting ink feature,</claim-text><claim-text>a fluorescent ink feature,</claim-text><claim-text>a security thread feature,</claim-text><claim-text>a watermark feature,</claim-text><claim-text>a microprinting feature,</claim-text><claim-text>a reflective feature,</claim-text><claim-text>a refractive feature,</claim-text><claim-text>a diffractive feature,</claim-text><claim-text>a foil feature,</claim-text><claim-text>a hologram feature,</claim-text><claim-text>a window feature,</claim-text><claim-text>an image feature,</claim-text><claim-text>a graphic feature,</claim-text><claim-text>a micro-optic feature, or</claim-text><claim-text>a pattern feature.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first sensor data is associated with a first spectral range and the second sensor data is associated with a second spectral range,<claim-text>wherein the first spectral range and the second spectral range are different.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the light is associated with the first spectral range and the second spectral range.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the light is associated with a third spectral range, and<claim-text>wherein the third spectral range is different than the first spectral range and the second spectral range.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the first set of one or more optical sensor devices generates the first sensor data during a first time range;</claim-text><claim-text>the second set of one or more optical sensor devices generates the second sensor data during a second time range; and</claim-text><claim-text>the first time range and the second time range at least partially overlap.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the first set of one or more optical sensor devices generates the first sensor data during a first time range;</claim-text><claim-text>the second set of one or more optical sensor devices generates the second sensor data during a second time range; and</claim-text><claim-text>the first time range and the second time range do not overlap.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the one or more characteristics of the security feature comprises:<claim-text>processing at least one portion of the first sensor data associated with the security feature of the security article and at least one portion of the second sensor data associated with the security feature of the security article to determine the one or more characteristics of the security feature.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein causing the one or more actions to be performed comprises causing at least one of:<claim-text>causing authentication information indicating whether the security article is authentic to be visually displayed via a display screen of the user device;</claim-text><claim-text>causing the authentication information to be audibly presented via an audio component of the user device; or</claim-text><claim-text>causing the authentication information to be haptically presented via a haptic component of the user device.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A user device, comprising:<claim-text>one or more memories; and</claim-text><claim-text>one or more processors, coupled to the one or more memories, configured to:<claim-text>cause light to be emitted at a security article by one or more light emission devices of the user device;</claim-text><claim-text>obtain from a first set of one or more optical sensor devices of a plurality of optical sensor devices of the user device, and based on causing the light to be emitted, first sensor data associated with the security article;</claim-text><claim-text>obtain from a second set of one or more optical sensor devices of the plurality of optical sensor devices of the user device, and based on causing the light to be emitted, second sensor data associated with the security article;</claim-text><claim-text>determine, based on the first sensor data and the second sensor data, one or more characteristics of a security feature of the security article;</claim-text><claim-text>determine, based on the one or more characteristics of the security feature, whether the security article is authentic; and</claim-text><claim-text>cause, based on determining whether the security article is authentic, one or more actions to be performed.</claim-text></claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The user device of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the first sensor data and the second sensor data are associated with different spectral ranges.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The user device of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein:<claim-text>the first set of one or more optical sensor devices generates the first sensor data during a first time range;</claim-text><claim-text>the second set of one or more optical sensor devices generates the second sensor data during a second time range; and</claim-text><claim-text>the first time range and the second time range at least partially overlap.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The user device of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein:<claim-text>the first set of one or more optical sensor devices generates the first sensor data during a first time range;</claim-text><claim-text>the second set of one or more optical sensor devices generates the second sensor data during a second time range; and</claim-text><claim-text>the first time range and the second time range do not overlap.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The user device of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the one or more processors, to determine the one or more characteristics of the security feature, are configured to:<claim-text>process at least one portion of the first sensor data associated with the security feature of the security article and at least one portion of the second sensor data associated with the security feature of the security article to determine the one or more characteristics of the security feature.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The user device of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the one or more processors, to cause the one or more actions to be performed, are configured to:<claim-text>grant or deny access to a resource based on determining whether the security article is authentic.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A non-transitory computer-readable medium storing a set of instructions, the set of instructions comprising:<claim-text>one or more instructions that, when executed by one or more processors of a user device, cause the user device to:<claim-text>cause light to be emitted at a security article by one or more light emission devices of the user device;</claim-text><claim-text>obtain, from a plurality of optical sensor devices of the user device, and based on causing the light to be emitted, sensor data associated with the security article;</claim-text><claim-text>determine, based on the sensor data, one or more characteristics of a security feature of the security article;</claim-text><claim-text>determine, based on the one or more characteristics of the security feature, whether the security article is authentic; and</claim-text><claim-text>cause, based on determining whether the security article is authentic, one or more actions to be performed.</claim-text></claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the sensor data is associated with a plurality of spectral ranges.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein:<claim-text>the plurality of optical sensor devices generates a first portion of the sensor data during a first time range;</claim-text><claim-text>the plurality of optical sensor devices generates a second portion of the sensor data during a second time range; and</claim-text><claim-text>the first time range and the second time range at least partially overlap.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein:<claim-text>the plurality of optical sensor devices generates a first portion of the sensor data during a first time range;</claim-text><claim-text>the plurality of optical sensor devices generates a second portion of the sensor data during a second time range; and</claim-text><claim-text>the first time range and the second time range do not overlap.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the one or more instructions, that cause the user device to determine the one or more characteristics of the security feature, cause the user device to:<claim-text>process at least one portion of the sensor data associated with the security feature of the security article to determine the one or more characteristics of the security feature.</claim-text></claim-text></claim></claims></us-patent-application>
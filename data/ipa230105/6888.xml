<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230006889A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230006889</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17900653</doc-number><date>20220831</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>41</main-group><subgroup>122</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>41</main-group><subgroup>5025</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>41</main-group><subgroup>122</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>41</main-group><subgroup>5025</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">FLOW-SPECIFIC NETWORK SLICING</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only"><addressbook><last-name>Thyagaturu</last-name><first-name>Akhilesh S.</first-name><address><city>Tempe</city><state>AZ</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant><us-applicant sequence="01" app-type="applicant" designation="us-only"><addressbook><last-name>Guim Bernat</last-name><first-name>Francesc</first-name><address><city>Barcelona</city><country>ES</country></address></addressbook><residence><country>ES</country></residence></us-applicant><us-applicant sequence="02" app-type="applicant" designation="us-only"><addressbook><last-name>Zhuang</last-name><first-name>Xiangyang</first-name><address><city>Santa Clara</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant><us-applicant sequence="03" app-type="applicant" designation="us-only"><addressbook><last-name>Kumar</last-name><first-name>Karthik</first-name><address><city>Chandler</city><state>AZ</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant><us-applicant sequence="04" app-type="applicant" designation="us-only"><addressbook><last-name>Torre</last-name><first-name>Petar</first-name><address><city>Feldkirchen</city><country>DE</country></address></addressbook><residence><country>DE</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Thyagaturu</last-name><first-name>Akhilesh S.</first-name><address><city>Tempe</city><state>AZ</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Guim Bernat</last-name><first-name>Francesc</first-name><address><city>Barcelona</city><country>ES</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Zhuang</last-name><first-name>Xiangyang</first-name><address><city>Santa Clara</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Kumar</last-name><first-name>Karthik</first-name><address><city>Chandler</city><state>AZ</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Torre</last-name><first-name>Petar</first-name><address><city>Feldkirchen</city><country>DE</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present disclosure is generally related to edge computing technologies (ECTs), communications networking, network slicing, and in particular, to techniques and technologies for providing flow-specific network slices. In particular, the present disclosure describes mechanisms that expand existing end-to-end architectures in order to include quality of service and monitoring mechanisms that connect network slicing technologies with infrastructure and/or network data center quality of service provider domains. The described mechanisms provide data center bridging to enable network, edge computing, and cloud computing domains.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="118.96mm" wi="158.75mm" file="US20230006889A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="254.42mm" wi="173.65mm" orientation="landscape" file="US20230006889A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="216.92mm" wi="174.84mm" orientation="landscape" file="US20230006889A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="218.44mm" wi="169.50mm" orientation="landscape" file="US20230006889A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="215.05mm" wi="164.17mm" orientation="landscape" file="US20230006889A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="214.71mm" wi="164.17mm" orientation="landscape" file="US20230006889A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="245.28mm" wi="170.52mm" orientation="landscape" file="US20230006889A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="248.58mm" wi="166.45mm" orientation="landscape" file="US20230006889A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="239.35mm" wi="170.52mm" orientation="landscape" file="US20230006889A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="256.20mm" wi="173.40mm" file="US20230006889A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="252.39mm" wi="168.23mm" orientation="landscape" file="US20230006889A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="249.77mm" wi="173.82mm" orientation="landscape" file="US20230006889A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="263.57mm" wi="164.76mm" file="US20230006889A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="235.97mm" wi="161.97mm" file="US20230006889A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present disclosure is generally related to edge computing technologies (ECTs), communications networking, network slicing, and in particular, to techniques and technologies for providing flow-specific network slices.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">3GPP Fifth Generation (5G) networking technologies have emerged as a catalyst for applications requiring relatively high data rates. In order to operate at a level acceptable to most end user, these applications require a certain level of performance in terms of, for example, response times, latency, among many other performance metrics. These performance requirements are needs in the cellular network domain, edge computing domain, and the cloud domain. While each of these domains provides some level of quality of service (QoS) at an individual level, there is a gap in interfacing and/or interworking mechanisms to facilitate QoS across these domains in a manner that is meaningful to the end user at the service or microservice level. Additionally, mechanisms to propagate service level agreements between these domains is also lacking and/or missing.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0004" num="0003">In the drawings, which are not necessarily drawn to scale, like numerals may describe similar components in different views. Like numerals having different letter suffixes may represent different instances of similar components. Some embodiments are illustrated by way of example, and not limitation, in the figures of the accompanying drawings in which:</p><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts example environment employing network slicing. <figref idref="DRAWINGS">FIGS. <b>2</b>, <b>3</b>, and <b>6</b></figref> depict example end-to-end (e2e) quality of service (QoS) architectures. <figref idref="DRAWINGS">FIGS. <b>4</b> and <b>5</b></figref> depict example data packet formats for flow-specific slicing. <figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts an example e2e QoS procedure. <figref idref="DRAWINGS">FIG. <b>8</b></figref> depicts an example service mesh architecture.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an example edge computing environment. <figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates an overview of an edge cloud configuration for edge computing. <figref idref="DRAWINGS">FIG. <b>11</b></figref> depicts a virtual edge configuration in an edge computing system. <figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates various compute arrangements deploying containers in an edge computing system. <figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates an example software distribution platform. <figref idref="DRAWINGS">FIG. <b>14</b></figref> depict example components of a compute node, which may be deployed in an edge computing system(s).</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><heading id="h-0005" level="1">1. Flow-Specific Network Slicing</heading><p id="p-0007" num="0006">1.1. Slicing Architecture Configurations and Arrangements</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an example environment <b>100</b> including multiple network slices wherein different network slices isolate burstiness and interference from applications in different slices. 3GPP Fifth Generation (5G) networking technologies have emerged as a catalyst for applications requiring high data rates. Network slicing offers a means to ensure that different applications (e.g., Internet of Things (IoT), autonomous or semi-autonomous vehicles or drones, ultra-high definition (UHD), and/or other like applications) do not interfere with one another.</p><p id="p-0009" num="0008">A network slice is a logical and/or virtual network that includes a set of network functions (NFs), and corresponding resources such as, for example, compute, storage, and networking resources. Network slices can span and can be deployed across multiple network domains and/or network operator (NOP) domains, including access network (AN) <b>130</b>&#x2032;, edge network (e.g., edge cloud <b>110</b>), core network (e.g., core cloud <b>115</b>), and transport networks (TNs). Network slices are &#x201c;sliced out&#x201d; from a physical network in order to provide specific capabilities and characteristics required for applications running within the network slice. A network slice could also be seen as a unique profile for an application, defined as a set of services within the network, or as an NF chain built to support a given use case, traffic type, subscriber or customer (e.g., a &#x201c;CSC&#x201d; which may refer to a &#x201c;communication service customer&#x201d; or a &#x201c;cloud service customer&#x201d;), and/or the like.</p><p id="p-0010" num="0009">Network slicing at least in some examples includes means for creating logical and/or virtualized networks over a common multi-domain infrastructure using technologies such as software defined networking (SDN), network functions virtualization (NFV), orchestration, analytics, telemetry, and automation technologies. Network slicing allows NOPs to create network slices that can support a specific purpose (e.g., an application, service, set of users, a network, and/or the like). In particular, a network slice includes a set of NF instances, with their supporting resources (e.g. virtualized resources and/or non-virtualized resources), to provide a service for certain purpose (e.g. to support a certain set of communication services, provide public network integrated non-public networks (PNI-NPNs), and/or the like in a Network Slice as a Service (NSaaS) model), for operational efficiencies (e.g. to optimize operator internal O&#x26;M procedures in network slice as NOP internals model), and/or to satisfy an associated SLA and/or SLS. As discussed in more detail infra, network slicing is enhanced to allow NOPs to create network slices that can support individual data flows associated with specific applications, services, set of users, and/or networks.</p><p id="p-0011" num="0010">Each of the NFs in a network slice may be a virtual NF (VNF) or a physical NF (PNF). The NFs may be implemented using virtual machines (VMs), virtualization containers, and/or some other network function virtualization (NFV) technology. The NFs can also be deployed using virtualization infrastructure (VI) <b>140</b> and/or AN equipment <b>130</b>, <b>130</b>&#x2032;, which allows various NFs to operate in or as an edge cloud <b>110</b> and/or core cloud <b>160</b>. In some implementations, commercial-of-the-shelf (COTS) equipment can be used for the VI <b>140</b> and/or AN equipment <b>130</b>, <b>130</b>&#x2032;. Connectivity among the NFs located in the edge cloud <b>110</b> and the core cloud <b>160</b> are provisioned using SDN <b>143</b> (e.g., SDN controllers and/or the like) and/or other virtual and/or physical network appliances. As examples, the SDN <b>143</b> can include technologies and/or protocols such as OpenFlow, Border Gateway Protocol Link-State (BGP-LS), Path Computation Element Communication Protocol (PCEP), Network Configuration Protocol (NETCONF), YANG, and/or the like. Additionally, end point devices <b>160</b> can access the edge cloud <b>110</b> and the core cloud <b>160</b> using one or more ANs <b>130</b>&#x2032;, where each AN <b>130</b>&#x2032; includes one or more network access nodes (NANs) <b>130</b>. In some implementations, the NAN(s) <b>130</b> and AN(s) <b>130</b>&#x2032; may support multi-access networks, or networks involving multiple access technologies (or RATs).</p><p id="p-0012" num="0011">In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, network slices are created for different network slice types (or service types) including an ultra-high definition (UHD) slice <b>121</b>, an enhanced Mobile Broadband (eMBB) slice <b>122</b>, a massive IoT (mIoT) slice <b>123</b> (also referred to as &#x201c;massive Machine Type Communications slice <b>123</b>&#x201d; or &#x201c;mMTC slice <b>123</b>&#x201d;), and a mission-critical (MC) slice <b>124</b> (also referred to as an &#x201c;URLLC slice <b>124</b>&#x201d;). Applications dedicated for each service are virtualized and operate within their respective slices <b>121</b>, <b>122</b>, <b>123</b>, <b>124</b>. Each network slice is created for different services that have different service requirements. In some examples, the different service requirements for each network slice may be specified by respective service level agreements (SLAs). Additionally, NFs are deployed, disposed, or otherwise placed at different locations in each slice (e.g., within the edge cloud <b>110</b> or the core cloud <b>115</b>) depending on the services provided by each network slice. Some NFs such as, for example, access management (mgt) functions <b>171</b>, session mgt functions <b>172</b>, mobility mgt functions <b>173</b>, charging functions <b>174</b>, policy control, and the like, can be deployed in one slice, while being omitted from other slices.</p><p id="p-0013" num="0012">In this example, the UHD slice <b>121</b> includes a RAN function (RANF) <b>131</b>, user plane (UP) core network (CN) <b>142</b><i>u</i>, and edge compute function (ECF) <b>136</b> in the edge cloud <b>110</b>, and control plane (CP) CN <b>142</b><i>c </i>and Mobile Video Optimization (MVO) server(s) <b>150</b> in the core cloud <b>115</b>. In one example implementation, the ECF <b>136</b> is, or operates as, a cache server, a CDN node, or the like. The eMBB slice <b>122</b> includes a RANF <b>131</b> in the edge cloud <b>110</b>, and the core cloud <b>115</b> includes a UP and CP 5G CN <b>142</b> with full mobility features, as well as virtualized IP Multimedia Subsystem (IMS) server(s) <b>151</b> and TN optimizer (TN-Opt) <b>152</b>. The TN includes links and/or network elements that connect a RAN and the CN, including fronthaul, midhaul, and backhaul interfaces. Examples of network elements in a TN include access routers, metro edge gateways (mEGs), metro aggregation edge gateway (mAEG), metro backbone router (mBB), and/or backbone routers (BB). Examples of TNs that can be used include TCP networks, 5G transport networks (e.g., including Wavelength Division Multiplexing (WDM), Pulse Amplitude Modulation 4-level (PAM4), MPLS, EVPN, Virtual Extensible LAN (VXLAN), Segment Routing MPLS (SR-MPLS), SR-IPv6 (SRv6), among many other technologies), optical transport networks (OTNs), Synchronous Digital Hierarchy (SDH) TNs, xHaul TN, ITU IMT 2020/5G TNs, and/or the like.</p><p id="p-0014" num="0013">The massive IoT slice <b>123</b> includes a RANF <b>131</b> in the edge cloud <b>110</b> and a set of IoT servers <b>153</b> and a lightweight 5G CN <b>142</b>&#x2032; in the core cloud <b>115</b>. This CN <b>142</b>&#x2032; may be made lightweight by not including mobility management features of other 5G core networks. In some examples, the massive IoT slice <b>123</b> can include one or more sensor networks and/or IoT networks. The MC slice <b>124</b> includes a RANF <b>131</b>, a UP 5G CN <b>142</b><i>u</i>, and associated MC servers <b>154</b> (e.g., V2X servers, and the like) in the edge cloud <b>110</b> to minimize transmission delay. The MC slice <b>124</b> can include some less critical MC servers/services <b>154</b>&#x2032; in the core cloud <b>115</b>. In some examples, the MC slice <b>124</b> can be used for autonomous and/or semi-autonomous vehicle applications/services, amusement ride (e.g., roller coasters, and the like) telemetry, smart city applications/services, smart factory applications/services, remote healthcare services, time-sensitive networks (see e.g., <i>IEEE Standard for Local and Metropolitan Area Networks&#x2014;Timing and Synchronization for Time</i>-<i>Sensitive Applications</i>, IEEE Std 802.1AS-2020, pp. 1-421 (19 Jun. 2020) (&#x201c;[IEEE802.1AS]&#x201d;)), and/or the like. Although the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref> shows different types of devices <b>160</b> corresponding to different slices, this example is meant to illustrate the main services represented by different types of devices <b>160</b>. In other implementations, some or all of the network slices can be genericized as a logically separated, self-contained, independent, and secured part of a network, targeting different services with different requirements such as, for example, speed, latency, jitter, reliability, and/or other requirements. These requirements may be defined or specified by resource model information (e.g., including a service profile and/or a network slice profile), management model information, and/or capability model information (see e.g., discussion infra with respect to <figref idref="DRAWINGS">FIG. <b>6</b></figref>). Moreover, different network slices can encompass the use or multiple device types and/or some device types can be served by or within multiple network slices.</p><p id="p-0015" num="0014">In some examples, the end point devices <b>160</b> may be the same or similar as the UEs <b>910</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref> and/or the end point devices <b>1060</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>, and the NANs <b>130</b> may be the same or similar as the NANs <b>930</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref> and/or the NAN <b>1040</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>. Additionally or alternatively, the NANs <b>131</b> and/or the RANFs <b>131</b> may have a CU/DU split-architecture deployment and/or a next generation fronthaul (NGF) deployment (see e.g., 3GPP TS 38.401 v17.1.1 (2022 Jul. 5) (&#x201c;[TS38401]&#x201d;) and U.S. application Ser. No. 17/704,658 filed on 25 Mar. 2022 (&#x201c;['658]&#x201d;), the contents of each which are hereby incorporated by reference in their entireties and for all purposes). Additionally or alternatively, the ECF <b>136</b> may be the same or similar as the edge compute nodes <b>936</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref> and/or the local processing hubs <b>1050</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>. In some examples, the ECF <b>136</b> may be implemented in a same or similar manner as discussed in [<b>658</b>]. Additionally or alternatively, the CN <b>142</b><i>u</i>, CN <b>142</b><i>c</i>, CN <b>142</b>, and/or CN <b>142</b>&#x2032; may be the same or similar as the <b>942</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref> (discussed infra). Additionally or alternatively, the edge cloud <b>110</b> may be the same or similar as the edge layer <b>937</b> and/or ECT <b>935</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref> and/or the edge cloud <b>1010</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>. Additionally or alternatively, the core cloud <b>115</b> may be the same or similar as the cloud <b>944</b> and/or server(s) <b>950</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref> and/or the cloud data center <b>1030</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>.</p><p id="p-0016" num="0015">In some implementations, the communications among the NFs in the edge cloud <b>110</b> and the core cloud <b>115</b> takes place using internet protocol (IP) and/or multi-protocol label switching (MPLS) according to known techniques. Additionally or alternatively, the communications in the AN(s) <b>130</b>&#x2032; and/or the SDN <b>143</b> may be based on NGFI (also referred to as &#x201c;xHaul&#x201d; or the like) as discussed in ['658]. In some implementations, different slice types may be instantiated or created based on the interface between the edge cloud <b>110</b> to core cloud <b>115</b>. For example, a first type of edge-to-cloud interface may be selected for a UHD slice <b>121</b>, a second type of edge-to-cloud interface may be selected for an eMBB slice <b>122</b>, a third type of edge-to-cloud interface may be selected for a massive IoT slice <b>123</b>, a fourth type of edge-to-cloud interface may be selected for MC slice <b>124</b>, and so forth. Furthermore, different flow-specific slices may be instantiated or created for different flows based at least in part on a selected edge-to-cloud interface.</p><p id="p-0017" num="0016">3GPP 5G provides network slicing for isolation and dedicated computing capabilities. 3GPP has defined the processes and interfaces for 5G network slicing to provide dedicated QoS among 5G network slices. In 5G networks, a network slice instance (NSI) is defined within a public land mobile network (PLMN) or within a standalone non-public network (SNPN), and includes CN CP functions (e.g., CN <b>142</b><i>c </i>discussed previously) and UP functions (e.g., CN <b>142</b><i>u </i>discussed previously), and in the serving PLMN, at least one of the following: an next generation (NG)-RAN; a Non-3GPP Inter-Working Function (N3IWF) or Trusted Non-3GPP Gateway Function (TNGF) to the non-3GPP Access Network described in clause 4.2.8.2 of [TS23501], or a Trusted WLAN Interworking Function (TWIF) to the trusted WLAN in the case of support of NSCW devices described in clause 4.2.8.5 of [TS23501]; or a Wireline Access Gateway Function (W-AGF) to the Wireline Access Network described in clause 4.2.8.4 of [TS23501].</p><p id="p-0018" num="0017">Network slices may differ for supported features and/or NF optimizations, in which case such network slices may have, for example, different single network slice selection assistance information (S-NSSAIs) with different slice/service types (SSTs) (see e.g., clause 5.15.2.1 of [TS23501]). An operator can deploy multiple network slices delivering exactly the same features but for different groups of UEs, for example, as they deliver a different committed service and/or because they are dedicated to a customer, in which case such network slices may have different S-NSSAIs with the same SST, but different slice differentiators (SDs) (see e.g., clause 5.15.2.1 of [TS23501]). An S-NSSAI identifies a network slice, and includes an SST and an SD. The SST refers to the expected network slice behavior in terms of features and services. The SD includes information that complements the SST(s) to differentiate amongst multiple network slices of the same SST. In some implementations, an S-NSSAI may not include an SD. Additionally, an S-NNSAI may be among a set of S-NSSAIs in a network slice selection assistance information (NSSAI) field/data structure. An NSSAI provided by a UE to a serving PLMN during registration is referred to as a &#x201c;requested NSSAI&#x201d;, and the S-NSSAI values a UE could use in a serving PLMN in the UE's current registration area is referred to as an &#x201c;allowed NSSAI&#x201d;. Based on the operator's operational or deployment needs, an NSI can be associated with one or more S-NSSAIs, and an S-NSSAI can be associated with one or more NSIs. Additional information about S-NSSAIs are discussed in [TS23501].</p><p id="p-0019" num="0018">Various performance metrics span the AN domain (e.g., AN(s) <b>130</b>&#x2032; in <figref idref="DRAWINGS">FIG. <b>1</b></figref>), edge computing domain (e.g., edge cloud <b>110</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>), and the cloud domain (e.g., core cloud <b>115</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>). While these domains provide Quality of Service (QoS) and/or QoS-like constructs at an individual level, there is a gap in interfacing and/or interworking to facilitate QoS across these domains in a manner that is meaningful to the end user at the service or microservice level. For example, having QoS successfully enforced at in the AN domain is meaningless if the cloud or edge domains are congested or overloaded. Additionally, telemetry hooks and handshaking capabilities to facilitate QoS interfacing and/or interworking are lacking. Likewise, mechanisms to propagate SLAs between these domains are also lacking. Various metrics need to be covered by these SLAs such as, for example, bandwidth, latency, security, and reliability metrics. Various aspects of these metrics are statistical in nature as observed by user devices and/or application, including statistical observations regarding 99th percentile, average, deviations, and the like, which can be beneficial if exchanged between the AN, edge, and cloud domains, in addition to just an upper or lower bounds. As an example, [TS23501] discusses various QoS characteristics associated with a QoS flow (or 5G QoS Identifier (5QI), as shown by Table 5.7.3.1.</p><p id="p-0020" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="336pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 5.7.3.1</entry></row></thead><tbody valign="top"><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>QoS Flow Performance Characteristics</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="119pt" align="left"/><colspec colname="2" colwidth="217pt" align="left"/><tbody valign="top"><row><entry>Performance Characteristics</entry><entry>Description</entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row><row><entry>Resource Type</entry><entry>Guaranteed Bit Rate (GBR), Delay Critical GBR or Non-GBR; determines</entry></row><row><entry/><entry>if dedicated network resources related to a QoS Flow-level Guaranteed</entry></row><row><entry/><entry>Flow Bit Rate (GFBR) value are permanently allocated (e.g. by an</entry></row><row><entry/><entry>admission control function in a radio base station). See [TS23501],</entry></row><row><entry/><entry>section 5.7.3.2.</entry></row><row><entry>Priority Level</entry><entry>The priority level associated with 5G QoS characteristics indicates a</entry></row><row><entry/><entry>priority in scheduling resources (e.g., radio resources) among QoS flows.</entry></row><row><entry/><entry>See also, [TS23501], section 5.7.3.3.</entry></row><row><entry>Packet Delay Budget (PDB)</entry><entry>defined as the upper bound for packet delivery between UE/device and</entry></row><row><entry/><entry>N6 termination point at a User Plane Function (UPF) (e.g., between Data</entry></row><row><entry/><entry>Network (DN) and UPF in the 5G core network (5GC)).</entry></row><row><entry/><entry>PDB can also include Core Network PDB (CN PDB) (see e.g., [TS23501],</entry></row><row><entry/><entry>section 5.7.3.4) and/or 5G-AN PDB.</entry></row><row><entry>Packet Error Rate (PER)</entry><entry>defines an upper bound for the rate of PDUs (e.g., IP packets) that have</entry></row><row><entry/><entry>been processed by the sender of a link layer protocol (e.g., RLC in RAN</entry></row><row><entry/><entry>of a 3GPP access) but that are not successfully delivered by the</entry></row><row><entry/><entry>corresponding receiver to the upper layer (e.g., PDCP in RAN of a 3GPP</entry></row><row><entry/><entry>access). Thus, the PER defines an upper bound for a rate of non-</entry></row><row><entry/><entry>congestion related packet losses. See [TS23501], section 5.7.3.5.</entry></row><row><entry>Averaging window</entry><entry>Used for GBR and Delay-critical GBR resource type only; used for</entry></row><row><entry/><entry>calculating the bit rate. The Averaging window represents the duration</entry></row><row><entry/><entry>over which the GFBR and MFBR shall be calculated (e.g. in the (R)AN,</entry></row><row><entry/><entry>UPF, UE) See [TS23501], section 5.7.3.6.</entry></row><row><entry>Maximum Data Burst Volume (MDBV)</entry><entry>Used for Delay-critical GBR resource type only; MDBV denotes the</entry></row><row><entry/><entry>largest amount of data that the 5G-AN is required to serve within a period</entry></row><row><entry/><entry>of 5G-AN PDB. See [TS235011], section 5.7.3.7.</entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0021" num="0019">3GPP 5G defines network slice types at a relatively high level, which may be viewed as highly abstracted summary of the service characteristics from multiple QoS flows provided in a slice. The operator can deploy multiple network slices delivering the same QoS features and for different groups of UEs. Table 5.15.2.2-1 shows example standardized SST values (e.g., out of a total 127 allowed values), which provide a way for establishing global interoperability for slicing so that PLMNs can support roaming use cases more efficiently for the most commonly used SSTs.</p><p id="p-0022" num="0000"><tables id="TABLE-US-00002" num="00002"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="315pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 5.15.2.2-1</entry></row></thead><tbody valign="top"><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>Standardized SST values</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="56pt" align="left"/><colspec colname="2" colwidth="35pt" align="center"/><colspec colname="3" colwidth="224pt" align="left"/><tbody valign="top"><row><entry>Slice/Service type</entry><entry>SST value</entry><entry>Characteristics</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row><row><entry>eMBB</entry><entry>1</entry><entry>Slice suitable for the handling of 5G enhanced Mobile Broadband.</entry></row><row><entry>URLLC</entry><entry>2</entry><entry>Slice suitable for the handling of ultra-reliable low latency communications.</entry></row><row><entry>MIoT</entry><entry>3</entry><entry>Slice suitable for the handling of massive IoT.</entry></row><row><entry>V2X</entry><entry>4</entry><entry>Slice suitable for the handling of V2X services.</entry></row><row><entry>HMTC</entry><entry>5</entry><entry>Slice suitable for the handling of High-Performance Machine-Type</entry></row><row><entry/><entry/><entry>Communications.</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0023" num="0020">Since the 5G slice is the origin point for the request (e.g., a requested NSSAI), the slice needs to embed the QoS information and exchange the same with the other layers. Unfortunately, there is no current means for handshake of SLAs, QoS settings, and telemetry between 5G, edge and cloud domains. The present disclosure provides mechanisms to solves these problems. Specifically, the present disclosure expands current device-to-cloud e2e architectures in order to include QoS (or performance metric) and monitoring mechanisms that connect network slicing aspects with infrastructure and/or network data center QoS domain (e.g., data center bridging (DCB); see e.g., clause 38 of [IEEE802.1Q]).</p><p id="p-0024" num="0021">Current solutions involve aligning and calibrating individual QoS settings to the lowest common denominator by the end user. However, these localized monitoring solutions are inefficient and cannot scale. Additionally, QoS granularity is not currently enforced at the cloud and edge infrastructure. Hence, the notion of e2e QoS is decoupled between 3GPP 5G networks, edge networks, and cloud services. Furthermore, existing solutions do not provide flow-specific resolution of network slicing in NG-RAN and/or cloud/edge infrastructure that is combined and adaptive. For example, although current 3GPP 5G standards specify QoS parameters for QoS flows and allow network slices to be deployed for individual subscribers (e.g., individual enterprises or subscribers to an NOP), current 3GPP 5G standards do not allow for network slices to be provisioned individual data flows that may be application-specific and/or service-specific.</p><p id="p-0025" num="0022">The present disclosure describes an end-to-end (e2e) framework for providing flow-specific network slices across multiple domains including the network/cellular domain, the edge computing domain, and the cloud computing domain. In particular, the present disclosure discusses coordinated e2e QoS policy setup between 5G networks and cloud services, as well as edge networks. As discussed infra, existing device to cloud e2e architectures are expanded in order to include QoS and monitoring mechanisms that connect network slicing with infrastructure and/or network data center QoS domains (e.g., DCB). In various implementations, network slices are allocated, provisioned, or otherwise provided at flow-specific resolutions or flow-specific granularities. In some implementations, a flow-specific resolution/granularity can be expressed in terms of tuple data such as a five tuple data structure including source network address, destination network address, source port, destination port, and network type (e.g., where the network addresses may be IP address or some other type of network address such as any of those discussed herein).</p><p id="p-0026" num="0023"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an example flow-specific slicing architecture <b>200</b> for providing e2e automatic QoS creation. The slicing architecture <b>200</b> includes one or more data producers <b>272</b>, NANs <b>240</b>-<b>1</b> and <b>240</b>-<b>2</b>, a service provider environment <b>236</b>, and NOP domains <b>220</b>-<b>1</b> and <b>220</b>-<b>2</b> (also referred to as &#x201c;NOPs <b>220</b>&#x201d;, &#x201c;mobile network operator domains <b>220</b>&#x201d;, &#x201c;MNOs <b>220</b>&#x201d;, &#x201c;telco domains <b>220</b>&#x201d;, and/or the like). The NOP domains <b>220</b>-<b>1</b> and <b>220</b>-<b>2</b> may represent different NOPs, which can include a cellular network and/or public land mobile network (PLMN) (where the cellular network/PLMN includes one or more radio access networks (RANs) and at least one core network), WLAN networks (e.g., including one or more WLAN access networks (ANs) and at least one backbone network), and/or any other type of wired or wireless network including any of those discussed herein), which may or may not implement different access technologies from one another.</p><p id="p-0027" num="0024">The NOP domains <b>220</b> can also include respective data center networks (DCNs) (e.g., DCN <b>640</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>), which can be used to implement the cloud ANs, CNs, and/or cloud computing services. In other implementations, cloud computing services can be provided by a data center service provider (DCSP) that is separate from the NOPs <b>220</b>. For example, NOP <b>220</b> can lease DCN infrastructure and/or other resources that are owned/operated by a DCSP to host CN and/or cloud RAN elements. The DCSP designs, builds, and operates one or more data centers and/or DCNs. In some examples, the DCSP can be a virtualization infrastructure service provider (VISP), a platform as a service (PaaS) provider, an Infrastructure as a Service (IaaS) provider, a cloud service provider (CSP), and/or an edge network service provider. Any of the aforementioned implementations can be combined, for example, where an NOP <b>220</b> owns or operates its own DCN to host CN and/or cloud RAN elements and a DCSP owns/operates a separate DCN to provide cloud computing services to the NOP <b>220</b>. Additionally or alternatively, the DCSP in the aforementioned implementations may own, operate, or otherwise provide the service provider environment <b>236</b>.</p><p id="p-0028" num="0025">In the example of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, each of the NOP domains <b>220</b>-<b>1</b> and <b>220</b>-<b>2</b> may represent a set of NOP infrastructure elements, which can include, for example, NANs, switches, hubs, routers, gateways, network appliances, physical and/or virtual NFs, fronthaul links, midhaul links, backhaul links, and/or any other type of network element such as any of those discussed herein. Each NOPs <b>220</b> may include one or more NANs <b>240</b> (e.g., base stations, access points, and/or the like) that convey data between the data producers <b>272</b> and the NOP domains <b>220</b>. The NANs <b>240</b> may be the same or similar as NANs <b>130</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, NANs <b>930</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, and/or the NAN <b>1040</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>. For example, NAN <b>240</b>-<b>1</b> may be owned by, operated by, or otherwise associated with a first NOP <b>220</b>-<b>1</b> and NAN <b>240</b>-<b>2</b> may be owned by, operated by, or otherwise associated with a second NOP <b>220</b>-<b>2</b>. In some examples, multi-access use cases may be supported wherein NANs <b>240</b> implement one or more access technologies (or radio access technologies (RATs)), which may be different than one another. For example, NAN <b>240</b>-<b>1</b> may implement or otherwise service user devices according to a first RAT and/or a first communication protocol (e.g., 3GPP 5G) and NAN <b>240</b>-<b>2</b> <b>1</b> may implement or otherwise service user devices according to a second RAT and/or a second communication protocol (e.g., WiFi).</p><p id="p-0029" num="0026">The NANs <b>240</b> interact with NOPs <b>220</b> via (edge/cloud) provider submission interfaces <b>250</b>, which can include one or more APIs, web services (WS), reference points, service-based interfaces, and/or other connection/communication mechanisms. In some implementations, the provider submission interfaces <b>250</b> can include transformation functions and exposure gateways, which are used to expose various functionalities between the multiple domains <b>220</b> and allows network slices to be created for a given flow. In these implementations, interoperability among the NOP domains <b>220</b> is provided via the exposure gateways, and the transformation functions are communicatively coupled with different NOP domains <b>220</b> via one or more network APIs, which can be used to set QoS parameters. Additionally, various capabilities are exposed to individual networks (e.g., telecos) and/or NOP domains <b>220</b> via the network APIs. The capabilities can include, for example, slicing capabilities, positioning capabilities, managed QoS capabilities, and/or other capabilities, configurations, parameters, and/or characteristics such as any of those discussed herein. The transformation functions are logical entities (e.g., business logic) that call southbound APIs, transform data, and provide functionality for one or more service APIs. The transformation functions may also provide an abstraction of internal APIs to the service APIs. Additionally, individual transformation functions are connected to one or more exposure gateways, and the exposure gateways expose service functions via the service APIs. The service APIs can be used for access control, billing/charging, cross-operator federation, and the like. In some implementations, the service APIs include mapping tables for various attributes to southbound APIs. Furthermore, the service APIs connect the exposure gateways with one or more aggregation functions (or aggregators). Technical aggregation may be used for the enrichment of the service APIs (e.g., cloud, edge, and/or platform providers). Enriched service APIs are also used to connect the aggregators to capability (service) consumers (e.g., end user devices), and may be used for premium streaming and/or the like.</p><p id="p-0030" num="0027">The service provider environment <b>236</b> configures flow-specific parameters to the NOPs <b>220</b> (or specified/selected NOP infrastructure elements). This configuration may be done by the orchestrator <b>236</b><i>a</i>, the observation element <b>236</b><i>b</i>, and/or the service <b>236</b><i>c </i>itself. The configuration may be done through a suitable API(s), web service(s), connector(s), reference point(s), interfaces, protocols, and/or any other suitable means. The infrastructure elements of the NOPs <b>220</b> also provide responses/replies to the service provider environment <b>236</b> based on the configuration.</p><p id="p-0031" num="0028">The service provider environment <b>236</b> operates or otherwise provides one or more services <b>236</b>, and also includes an orchestrator <b>236</b><i>a </i>and an observation element <b>236</b><i>b</i>. In some examples, the orchestrator <b>236</b><i>a </i>includes the observation element <b>236</b><i>b</i>. The orchestrator <b>236</b><i>a </i>and/or observation element <b>236</b><i>b </i>collect network performance measurements/metrics and update network configurations (e.g., &#x201c;slicing configurations&#x201d;) according to app/service requirements for network slices based on the observation of network performance. In some implementations, the orchestrator <b>236</b><i>a </i>allocates resources to individual flow-specific slices according to respective slice requirements and/or predetermined or negotiated SLAs. To serve multiple service consumers and/or multiple flow-specific slices, the orchestrator <b>236</b><i>a </i>includes or operates one or more sophisticated scheduling functions to meet competing and conflicting needs of different slice consumers, subscribers, deployment scenarios, use cases, and/or flows such as, for example, UHD, eMBB, ultra-reliable low latency communications slice (URLLC), industrial Internet of Things (IIoT), mIoT, and/or the like. In one example, the orchestrator <b>236</b><i>a </i>may provide differentiated handling of data traffic or traffic flows by creating or instantiating different user plane and/or control plane functions to serve individual flow-specific slices in a dedicated fashion. In some examples, the orchestrator <b>236</b><i>a </i>includes corresponds to one or more of the orchestrators <b>625</b>, <b>645</b>, <b>725</b>, <b>736</b><i>a</i>, <b>1160</b>, <b>1231</b> and/or container managers <b>1211</b>, <b>1221</b> discussed infra. In some implementations, the service provider environment <b>236</b> is an edge computing network/framework (e.g., edge cloud <b>110</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>; edge layer <b>937</b> and/or ECT <b>935</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>; and/or edge cloud <b>1010</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>), a cloud computing service or cloud network (e.g., core cloud <b>115</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>; cloud <b>944</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>; and/or cloud data center <b>1030</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>), a backbone or core network (e.g., core cloud <b>115</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>; CN <b>942</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>), or a service provider platform (e.g., one or more application servers, web servers, and/or data storage servers such as server(s) <b>950</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref> and/or the like). In some implementations, the service provider environment <b>236</b> is a combination of edge computing network/framework, cloud computing service, backbone/core network, and/or service provider platform, or various aspects thereof.</p><p id="p-0032" num="0029">The data producers (sensors) <b>272</b> collect data (e.g., sensor data, telemetry data, and/or the like) and stream or otherwise provide the data to the service <b>236</b><i>c </i>via the NANs <b>240</b>. In some examples, data streams may be handed over between NOP domains <b>220</b>. The collected data is provided to the respective NOPs <b>220</b> from the NANs <b>240</b> (e.g., NAN <b>240</b>-<b>1</b> provides (sensor) data to NOP <b>220</b>-<b>1</b> and NAN <b>240</b>-<b>2</b> provides (sensor) data to NOP <b>220</b>-<b>2</b>) via (edge/cloud) provider submission interfaces <b>250</b>. The NOP domains <b>220</b> each include various elements to provide network slices (e.g., network slices <b>622</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>). These elements include, for example, NOP infrastructure <b>221</b> (e.g., NFV infrastructure (NFVI) and/or other virtualization infrastructure), management (mgmt) functions <b>222</b> (e.g., orchestration, QoS provisioning, slice management, and/or the like), telemetry functions <b>223</b>, and a set of NFVs <b>224</b>. Each NFV <b>224</b> includes one or more processing elements (cores) <b>225</b>, information technology (IT) functions <b>226</b>, and/or other elements/entities including use case or application-specific functions (not shown by <figref idref="DRAWINGS">FIG. <b>2</b></figref>).</p><p id="p-0033" num="0030">The data producers <b>272</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref> are depicted as cameras or other image sensors (also referred to as &#x201c;sensors <b>272</b>&#x201d;), which may be used for security and/or video analytics service <b>236</b><i>c</i>. In one example use case, the sensors <b>272</b> can be visible-light cameras, infrared cameras, and/or LiDAR sensors mounted on or (semi-)autonomous vehicles, drones, robots, unmanned aerial vehicles (UAVs), unmanned underwater vehicles (UUVs) or other unmanned watercraft, (semi-) autonomous sensors, IoT devices, machine-type communications (MTC) devices, roller coaster trains or individual roller coaster cars, and/or the like (collectively referred to herein as &#x201c;(semi-) autonomous systems&#x201d;). In other examples, the data producers <b>272</b> can be any other type of sensors, actuators, or other type of devices such as any of those discussed herein (see e.g., discussion of sensors <b>1472</b>, actuators <b>1474</b>, and positioning circuitry <b>1475</b> of <figref idref="DRAWINGS">FIG. <b>14</b></figref>).</p><p id="p-0034" num="0031">Once a service <b>236</b><i>c </i>is deployed in the service provider environment <b>236</b>, it is attached in one hand into the NOP domain <b>220</b> to a specific network slice. The network slice (or NSI) includes a set of properties for a corresponding service <b>236</b><i>c</i>, which may be defined or specified by a service profile (or &#x201c;service configuration&#x201d;) and/or a slice profile (or slice configuration) As examples, the service/slice profile/configuration includes parameters, characteristics, properties, and/or requirements such as latency, bandwidth (BW), security, and/or other like metrics such as any of those discussed herein, which may be based on SLAs, KPIs, and the like. Once the slice is configured, the slice is mapped to an e2e QoS construct (or channel) that may be created for the service <b>236</b><i>c </i>(e.g., DCB virtual lanes) on or in the NOP domain <b>220</b> and/or the service provider environment <b>236</b>. Once the e2e QoS construct/channel (e.g., virtual channel/lane) is/are created, data producers <b>272</b> (e.g., end users, devices, and the like) that are also mapped to that slice start injecting traffic into the NOP domain <b>220</b> (e.g., via NANs <b>240</b> and 5G/core architecture and the like). The traffic from the producers <b>272</b> is translated from the AN traffic (e.g., 5G traffic and/or the like) into network layer traffic (e.g., IP traffic and/or the like). Once the traffic is translated, the NOP domain <b>220</b> (or core network) is responsible for automatically adding metadata into the network packets (e.g., IP packets) a that will be used by the next level/layer (e.g., data center or infrastructure layers) to map those packets into appropriate virtual channel (e.g., DCB virtual lane or the like).</p><p id="p-0035" num="0032">In some cases, it may not be efficient to always allocate e2e resources for all slices and NANs of an NOP domain <b>220</b>. For example, if the e2e resources only involve radio resources, then a MAC scheduler at a NAN <b>240</b> may handle the allocation of radio resources as needed. In another example, if the e2e resources only involve dedicated spectrum for slices, the dedicated spectrum may be preset and static. In various implementations, telemetry and/or metrics/measurements of individual slices that are provided by different NANs <b>240</b> are scaled-out so that flow-specific slices can be allocated in an efficient manner. In these implementations, the NOP and/or DCN infrastructure adaptively schedules and prioritizes resources to the virtual lanes (e.g., a virtual lane <b>652</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>). that are mapped to a particular slice (e.g., a slice <b>622</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>). Additionally or alternatively, the NOP and/or DCN infrastructure can provide hints, feedback, metrics, or other data to the NOP domain <b>220</b> (e.g., edge user case/service to 5G-as-a-service) to perform certain actions (e.g., perform compression due to congestion on the backhaul and/or the like). In some implementations, temporal QoS channels are dynamically created when a request for a particular network slice and NOP crosses a domain that has not been setup with the e2e QoS path.</p><p id="p-0036" num="0033">In contrast to 3GPP 5G network slicing, which creates dedicated resources for a particular service type (e.g., UHD, eMBB, URLLC, mMTC, mIoT, and the like), the present disclosure provides flow-based network slicing in an e2e perspective such that a cloud/edge application (app) can request a (flow) dedicated slice that is specific to an individual application or service. For instance, if a media streaming platform (e.g., Netflix&#xae;, Hulu&#xae;, and the like) wants to deliver media content, the media streaming platform's cloud or edge orchestrator can coordinate with a RAN orchestrator and management framework to create an e2e network slice that is specific to particular user and/or specific to a particular application, which can be specified to an individual data flow, which is from an end user/consumer (e.g., application, device, and/or the like) to a cloud/edge application. The data flow can be specified using tuple data. In one example, a 5-tuple can be used to identify a flow, where the 5-tuple can include a source network address (e.g., IP address and/or the like), destination network address (e.g., IP address and/or the like), source port, destination port, and/or network/transport protocol/type (e.g., IP type and/or the like). In another example, a 3-tuple can be used to identify a flow, where the 3-tuple can include a source network address (e.g., IP address and/or the like), destination network address (e.g., IP address and/or the like), and ICMP identifier (e.g., identifying an ICMP query session or the like). Other implementations can use other data to identify data flows for flow-specific slices such as, for example, flow identifiers (e.g., 5G QoS IDs (5QI) and/or the like) hash-based identifiers, session and/or application identifiers, and/or any other suitable network address with or without any other suitable information/data.</p><p id="p-0037" num="0034">The slicing architecture <b>200</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref> aims to achieve e2e QoS mechanisms from the access (e.g., NANs <b>240</b>) to the service provider environment <b>236</b> (e.g., edge or cloud) where the services <b>236</b><i>c </i>may be hosted, with enhanced interface and coordination mechanism among domains <b>220</b>. As alluded to previously, there are three domains that are included as part of the slicing architecture <b>200</b> including: access network (including NANs <b>240</b>), NOP domains <b>220</b> (including NOP-specific infrastructure), and the service provider environment <b>236</b> (e.g., edge and/or cloud networks and related infrastructure elements). The NOP domains <b>220</b> (including access network elements such as NANs <b>240</b>) and core (inter)work with infrastructure and data center QoS schemes to provide e2e monitoring and QoS enforcement schemes, which can include (a) mapping devices into specific slices; (b) inserting or injecting slice identifiers (IDs) and/or slice characteristics into traffic/packets for routing to appropriate slices (e.g., virtual lanes assigned to a slice); and (c) monitoring metrics of individual slices. With respect to (b), when traffic from a network slice (e.g., a 3GPP 5G network slice) is translated into network traffic (e.g., IP traffic and/or the like), a slice ID and/or slice characteristics are included in the network traffic (e.g., IP traffic and/or the like) so the infrastructure and date center can route the network traffic through the proper virtual lanes associated with the flow-specific slice. In 3GPP 5G systems, an NSSAI field including an 8-bit SST is present when a UE sends a registration request to the 5G core network (5GC). The SST and/or other contents of the NSSAI data structure can be one example of information that is also conveyed to the infrastructure and data center domains in network traffic/packets. With respect to (c), the NANs <b>240</b> that provide network access/connectivity for network slices continue monitoring and collecting slice-related metrics (e.g., latency, BW, jitter, and/or other like metrics such as any of those discussed herein) that each of the slices is demanding. The collected data (telemetry data) is then aggregated by various intermediate points (e.g., network elements and/or NFs) and provided to the corresponding infrastructure and/or data centers elements (e.g., routers, switches, fabrics, network appliances, DPUs and/or IPUs, and/or the like) that are targets or otherwise associated with the slice (e.g., telemetry access from outside of a 5G domain). Additionally or alternatively, a network slice (e.g., 5G slice or the like) may receive requests from specific end points to perform certain optimizations for a particular slice based on the current status of the virtual lanes where they are being mapped.</p><p id="p-0038" num="0035">In some implementations, the NOP and/or DCN infrastructure are expanded to implement QoS mechanisms based on network slice identifiers. In these implementations, network and data center infrastructure are expanded to be capable of instantiating data center virtual lanes mapped into the specific network slices. If the NOP and/or DCN infrastructure implements differentiated QoS (e.g., using the DSCP field of an IP header), the labeling and corresponding QoS policy should be aligned with that for the access network (e.g., 5G or the like). Additionally or alternatively, the infrastructure and data center may proactively allocate or de-allocate resources to a particular virtual lane mapped into a particular slice and NOP domain <b>220</b> based on the amount of load that is seen at the end of the network slicing. Additionally or alternatively, the infrastructure and data center may require to a particular NOP to perform certain optimizations (if possible) for certain slices depending on the current backhaul utilization. Examples could be implemented using certain traffic shaping schemes, traffic splitting schemes, compression schemes, and/or the like. This may depend on the functionalities available on the hardware (e.g., CPUs, accelerators, DPUs/IPUs, and/or the like).</p><p id="p-0039" num="0036"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows an example flow-specific configuration <b>300</b> based on the slicing architecture <b>200</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The example of <figref idref="DRAWINGS">FIG. <b>3</b></figref> includes an NOP domain <b>320</b>, which may represent one or more of the NOP domains <b>220</b>-<b>1</b> and/or <b>220</b>-<b>2</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, or may represent one or more infrastructure (network) elements in either of the NOP domains <b>220</b>-<b>1</b> or <b>220</b>-<b>2</b>. Additionally, the NOP infrastructure <b>321</b> may be the same or similar as the NOP infrastructure <b>221</b>-<b>1</b>, <b>221</b>-<b>2</b>, mgmt <b>322</b> may be the same or similar as the mgmt <b>222</b>-<b>1</b>, <b>222</b>-<b>2</b>, telemetry function <b>323</b> may be the same or similar as the telemetry function <b>223</b>, the NFV <b>324</b> may be the same or similar as the NFV <b>224</b>-<b>1</b>, <b>224</b>-<b>2</b>, core <b>325</b> may be the same or similar as the core <b>225</b>-<b>1</b>, <b>225</b>-<b>2</b>, and IT <b>326</b> may be the same or similar as the IT <b>226</b>-<b>1</b>, <b>226</b>-<b>2</b>.</p><p id="p-0040" num="0037">In this example, at step <b>3</b>.<b>1</b> a service <b>236</b><i>c </i>is deployed in the service provider environment <b>236</b>. In an example, the service <b>236</b><i>c </i>may be a video analytics service, and the commands/instructions to setup the service <b>236</b><i>c </i>may be in the form shown by example instruction [0].</p><p id="p-0041" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Instantiate(Video_Analytics,SRC=(<i>A, . . . ,N</i>),QoS={(<i>bw,+/&#x2212;</i>%),(<i>lat,+/&#x2212;</i>%), . . . })&#x2003;&#x2003;[0]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0042" num="0038">In example instruction [<b>0</b>], Instantiate( ) is a function, method, API call, or other means for instructing the service provider environment <b>236</b> to instantiate a service <b>236</b><i>c</i>; Video_Analytics is an identifier or namespace of the service <b>236</b><i>c </i>to be instantiated; SRC=(A, . . . , N) is a source of a service provider and/or service consumer of the service <b>236</b><i>c </i>wherein A, . . . , N is a set of source service consumer/producer parameters; QoS={ } is a set of QoS parameters for the service <b>236</b><i>c</i>; (bw,+/&#x2212;%) is a bandwidth QoS parameter wherein the &#x201c;bw&#x201d; is an initial bandwidth value for the service <b>236</b><i>c </i>and the &#x201c;+/&#x2212;%&#x201d; represents a permitted or desired percentage range (or standard deviation) from the initial bandwidth value; (lat, +/&#x2212;%) is a latency QoS parameter wherein the &#x201c;lat&#x201d; is an initial latency value for the service <b>236</b><i>c </i>and the &#x201c;+/&#x2212;%&#x201d; represents a permitted or desired percentage range (or standard deviation) from the initial latency value; and the ellipsis ( . . . ) indicates that the set of QoS parameters can include zero or more additional QoS parameters and/or QoS characteristics for the service <b>236</b><i>c </i>such as, for example, acceptable jitter value, minimum arrival time, acceptable execution time, acceptable blocking time or other responsiveness metric, acceptable packet drop rate, queue information (e.g., number of jobs per unit of time, residency times, and/or the like), 5G QoS parameters (e.g., 5QI, ARP, RQA, notification control, flow bit rates, aggregate bit rates, default values, maximum packet loss rate, wireline access networks (W-SGAN)-specific QoS parameters (see e.g., 3GPP TS 23.316 v17.3.0 (2022 Jun. 15)), 5G QoS characteristics (see e.g., Table 5.7.3.1 supra), QoS forwarding treatment parameters (e.g. scheduling weights, admission thresholds, queue management thresholds, link layer protocol configuration, and/or the like). Additionally or alternatively, any other performance indicators, metrics, and/or measures such as any of those discussed herein can be used as QoS parameters. In various implementations, the service <b>236</b><i>c </i>can be deployed in the service provider environment <b>236</b> at step <b>3</b>.<b>1</b> according to the example service mesh of <figref idref="DRAWINGS">FIG. <b>8</b></figref> (discussed infra).</p><p id="p-0043" num="0039">At step <b>3</b>.<b>2</b>, the service provider environment <b>236</b> configures itself and/or a set of service compute nodes of the service provider environment <b>236</b> (e.g., edge compute node(s), cloud compute node(s), CN compute nodes and/or NFs, and/or application/web/DB server(s)). In some implementations, step <b>3</b>.<b>2</b> can include selecting a set of service compute nodes of the service provider environment <b>236</b> based on service API telemetry, instantiating the service <b>236</b><i>c</i>, and setting up QoS parameters via the service API (e.g., the service API and/or enriched service API discussed previously). In one example, the service <b>236</b><i>c </i>is a video analytics service, and the service API is a camera/sensor API.</p><p id="p-0044" num="0040">At step <b>3</b>.<b>3</b>, the service provider environment <b>236</b> configures flow-specific (QoS) parameters to the NOP domain <b>320</b>. The flow-specific (QoS) configuration may be done by the orchestrator <b>236</b><i>a</i>, observation element <b>236</b><i>b</i>, or the service <b>236</b><i>c </i>itself. This configuration may be done using the network APIs, service APIs, and/or enriched service APIs discussed previously with respect to the provider submission interfaces <b>250</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. An example API method/function is shown by example instruction [<b>1</b>].</p><p id="p-0045" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>API_QOS_SETUP{SRC,QoS,DST, . . . }&#x2003;&#x2003;[1]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0046" num="0041">In example instruction [1], API_QOS_SETUP( ) is a function, method, API call, or other means for configuring the NOP infrastructure element(s) <b>320</b> with the flow-specific (QoS) parameters; SRC is a source address for the flow-specific network slice, QoS is/are the QoS parameters for the flow-specific network slice (e.g., including those in example instruction [0]), DST is a destination address for the flow-specific network slice, and the ellipsis ( . . . ) indicates that zero or more additional flow-specific (QoS) parameters can be included in the configuration. In various implementations, the flow-specific (QoS) parameters provisioned at step <b>3</b>.<b>3</b> according to the example service mesh of <figref idref="DRAWINGS">FIG. <b>8</b></figref> (discussed infra).</p><p id="p-0047" num="0042">At step <b>3</b>.<b>4</b>, the NOP <b>320</b> configures QoS parameters for the core <b>324</b> (which may be the same or similar as the core <b>225</b>-<b>1</b> or <b>225</b>-<b>2</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>), configures access QoS parameters, and configure infrastructure QoS parameters. At step <b>3</b>.<b>5</b>, the NOP <b>320</b> provides results of the configuration operations to the service provider environment <b>236</b>.</p><p id="p-0048" num="0043">At step <b>3</b>.<b>6</b>, streams from the data providers <b>272</b> are provided for service <b>236</b><i>c </i>via the NAN <b>340</b> and the (edge/cloud) provider submission interface(s) <b>250</b>. The NAN <b>340</b> may be the same or similar to either of the NANs <b>240</b>-<b>1</b> and <b>240</b>-<b>2</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. At step <b>3</b>.<b>7</b>, the service provider environment <b>236</b> (or the set of service compute nodes selected at step <b>3</b>.<b>2</b>) monitors SLAs, KPIs, measurements, and/or metrics of the service <b>236</b><i>c </i>and notifies service consumers (not shown by <figref idref="DRAWINGS">FIG. <b>3</b></figref>) if one or more SLAs cannot be met anymore, or is predicted to fall below one or more thresholds defined by the SLAs.</p><p id="p-0049" num="0044">In the example of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, once the service <b>236</b><i>c </i>is deployed in the service provider environment <b>236</b> (see e.g., step <b>3</b>.<b>1</b>), it is attached into an NOP domain <b>220</b> (e.g., including NOP infrastructure elements <b>221</b>) to a specific network slice (e.g., a slice <b>622</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>). The network slice includes a set of properties (see e.g., steps <b>3</b>.<b>2</b> and <b>3</b>.<b>3</b>) based on the service's <b>236</b><i>c </i>SLAs, KPIs, and/or the like (e.g., bandwidth, latency, security, reliability, and/or any other SLAs, KPIs, metrics and/or the like such as any of those discussed herein). In some implementations, the SLAs and/or KPIs can be mapped to statistical estimators such as, for example, jitter, median, and/or any other statistical estimators/measures such as any of those discussed herein. When the slice is configured (see e.g., step <b>3</b>.<b>3</b>), the slice is mapped into an e2e QoS construct (e.g., a virtual lane <b>652</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>) that is created for the service <b>236</b><i>c</i>. The NOP infrastructure <b>221</b> and/or DCN infrastructure may store a mapping or other data structure that associates a virtual lane (e.g., a virtual lane <b>652</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>), slice ID (e.g., slice ID <b>422</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>) of the corresponding network slice (e.g., a slice <b>622</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>), and an NOP ID (e.g., NOP ID <b>421</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>) of the NOP <b>220</b> providing the network slice. In some implementations, multiple NOPs can be subscribers to the same or different CSPs.</p><p id="p-0050" num="0045">After the e2e QoS channel/construct is created, the devices that are mapped into the slice start communicating traffic to/from the NOP architecture (e.g., (R)AN and CN infrastructure and/or the like). In 3GPP 5G implementations, network traffic (e.g., IP, Ethernet, and/or the like) is directly carried by the N6 interface between a data network (DN) and a user plane function (UPF) (see e.g., [TS23501]). Based on the requested service type, the 5GC will assign/change various QoS flows during PDU session establishment for a specific UE/application. The 5GC may also add some amount of metadata into the network packets (e.g., IP packets, Ethernet packets, and/or the like) directly (e.g., at the packet level) so that slicing can be used. Example packets and the metadata added to the packets is shown by <figref idref="DRAWINGS">FIGS. <b>4</b> and <b>5</b></figref>.</p><p id="p-0051" num="0046"><figref idref="DRAWINGS">FIGS. <b>4</b> and <b>5</b></figref> show example packets <b>400</b> and <b>500</b>, respectively, that are enhanced to support flow-specific slicing. The example packet <b>400</b> is based on an IP version 4 (IPv4) packet format and example packet <b>500</b> is based on an IP version 6 (IPv6) packet format, but the examples herein are not limited thereto, and any type of packet format can be used such as, for example, Internet Control Message Protocol (ICMP) packets, Flexilink packets, TCP packets, non-access stratum (NAS) packets, Ethernet packets, and/or any other type of packet or data unit such as any of those discussed herein.</p><p id="p-0052" num="0047">The packet <b>400</b> includes a payload (data) section <b>402</b> that carries data and a header section <b>401</b> that includes various header fields shown by Table IPv4.</p><p id="p-0053" num="0000"><tables id="TABLE-US-00003" num="00003"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="91pt" align="left"/><colspec colname="2" colwidth="35pt" align="center"/><colspec colname="3" colwidth="196pt" align="left"/><thead><row><entry namest="1" nameend="3" rowsep="1">TABLE IPv4</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row><row><entry>Header Field</entry><entry>Length</entry><entry>Description</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="91pt" align="left"/><colspec colname="2" colwidth="14pt" align="right"/><colspec colname="3" colwidth="21pt" align="left"/><colspec colname="4" colwidth="196pt" align="left"/><tbody valign="top"><row><entry>Version</entry><entry>4</entry><entry>bits</entry><entry>includes a version field to indicate a version of the network</entry></row><row><entry/><entry/><entry/><entry>protocol (e.g., for IPv4 the value in this field is always &#x2018;4&#x2019;)</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="91pt" align="left"/><colspec colname="2" colwidth="35pt" align="center"/><colspec colname="3" colwidth="196pt" align="left"/><tbody valign="top"><row><entry>Internet Header Length (IHL)</entry><entry>variable</entry><entry>contains the size of the IPv4 header; it has 4 bits that specify the</entry></row><row><entry/><entry/><entry>number of 32-bit words in the header.</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="91pt" align="left"/><colspec colname="2" colwidth="14pt" align="right"/><colspec colname="3" colwidth="21pt" align="left"/><colspec colname="4" colwidth="196pt" align="left"/><tbody valign="top"><row><entry>Differentiated Services Code</entry><entry>8</entry><entry>bits</entry><entry>DSCP: specifies differentiated services (DiffServ) per RFC</entry></row><row><entry>Point (DSCP)/type of service</entry><entry/><entry/><entry>2474. Real-time data streaming makes use of the DSCP field;</entry></row><row><entry>(ToS)</entry><entry/><entry/><entry>can also include Explicit Congestion Notification (ECN) to</entry></row><row><entry/><entry/><entry/><entry>indicate network congestion.</entry></row><row><entry/><entry/><entry/><entry>ToS: specifies a priority and request a route for low-latency, high-</entry></row><row><entry/><entry/><entry/><entry>throughput, or highly-reliable service.</entry></row><row><entry>Total Length</entry><entry>16</entry><entry>bits</entry><entry>defines the entire packet size in bytes, including header and data</entry></row><row><entry>Identification</entry><entry>16</entry><entry>bits</entry><entry>used for uniquely identifying a group of fragments of a single</entry></row><row><entry/><entry/><entry/><entry>datagram to which the packet belongs</entry></row><row><entry>Flag(s)</entry><entry>3</entry><entry>bits</entry><entry>used to control or identify fragments including:</entry></row><row><entry/><entry/><entry/><entry>bit 0: reserved</entry></row><row><entry/><entry/><entry/><entry>bit 1: don't fragment (DF)</entry></row><row><entry/><entry/><entry/><entry>bit 2: more fragments (MF)</entry></row><row><entry>Fragment Offset</entry><entry>13</entry><entry>bits</entry><entry>specifies the offset of a particular fragment relative to the</entry></row><row><entry/><entry/><entry/><entry>beginning of the original unfragmented datagram in units of</entry></row><row><entry/><entry/><entry/><entry>eight-byte blocks.</entry></row><row><entry>Time-to-live (TTL)</entry><entry>8</entry><entry>bits</entry><entry>Indicates an expiration or lifetime of the packet</entry></row><row><entry>Protocol</entry><entry>8</entry><entry>bits</entry><entry>defines the protocol used in the data portion of the packet/</entry></row><row><entry/><entry/><entry/><entry>datagram</entry></row><row><entry>Header Checksum</entry><entry>16</entry><entry>bits</entry><entry>used for error-checking of the header.</entry></row><row><entry>Source Address</entry><entry>32</entry><entry>bits</entry><entry>Network address (e.g., IPv4 address) of the sender of the packet</entry></row><row><entry>Destination Address</entry><entry>32</entry><entry>bits</entry><entry>Network address (e.g., IPv4 address) of the receiver/destination</entry></row><row><entry/><entry/><entry/><entry>of the packet</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="91pt" align="left"/><colspec colname="2" colwidth="35pt" align="center"/><colspec colname="3" colwidth="196pt" align="left"/><tbody valign="top"><row><entry>Options</entry><entry>variable</entry><entry>Fields and/or parameters used to configure a number of optional</entry></row><row><entry/><entry/><entry>parameters or behaviors</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0054" num="0048">The payload (data) section <b>402</b> includes an NOP ID field <b>421</b> and a slice ID field <b>422</b>. The NOP ID field <b>421</b> is used to carry an NOP ID (also referred to as an &#x201c;NOP ID <b>421</b>&#x201d;) of the NOP <b>220</b> in which the flow-specific slice is configured. As examples, the NOP ID <b>421</b> can be a universally unique ID (UUID) assigned to the NOP <b>220</b>, a PLMN ID of the NOP <b>220</b>, a random number (or pseudorandom number), a hash value, a digital signature of the NOP <b>220</b>, a digital certificate of the NOP <b>220</b>, and/or some other identifier and/or credentials associated with the NOP <b>220</b> such as any of those discussed herein or combinations thereof. The slice ID field <b>422</b> carries an ID of the flow-specific slice (also referred to as a &#x201c;slice ID <b>422</b>&#x201d;). As examples, the slice ID <b>422</b> can be a UUID assigned to the flow-specific slice, an NSI ID, a configured NSSAI, an S-NSSAI, a 5QI, a hash value, a random number (or pseudorandom number), and/or some other data or identifier such as any of those discussed herein or combinations thereof. The NOP ID <b>421</b> and/or slice ID <b>422</b> can be generated and/or assigned by any suitable entity such as a subscriber to an NOP and/or CSP, the NOP <b>220</b> itself, a CSP, a certificate authority, and/or some other entity.</p><p id="p-0055" num="0049">The size of the NOP ID field <b>421</b> and the slice ID field <b>422</b> may be variable in length based on the type of IDs used and/or the size of such IDs. In this example, the NOP ID field <b>421</b> and the slice ID field <b>422</b> are located in the first byte (bits <b>0</b>-<b>16</b>) of the payload (data) section <b>402</b> of the packet <b>400</b>. However, in other implementations, the NOP ID field <b>421</b> and the slice ID field <b>422</b> can be located in other parts/sections of the payload (data) section <b>402</b>. Additionally or alternatively, the NOP ID field <b>421</b> and the slice ID field <b>422</b> can be located in the options section, wherein a new or existing options classes can be configured to carry the NOP ID field <b>421</b> and the slice ID field <b>422</b>.</p><p id="p-0056" num="0050">The packet <b>500</b> includes a payload (data) section <b>502</b> that carries data and a header section <b>501</b> that includes various header fields shown by Table IPv6.</p><p id="p-0057" num="0000"><tables id="TABLE-US-00004" num="00004"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="63pt" align="left"/><colspec colname="2" colwidth="42pt" align="center"/><colspec colname="3" colwidth="203pt" align="left"/><thead><row><entry namest="1" nameend="3" rowsep="1">TABLE IPv6</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row><row><entry>Header Field</entry><entry>Length</entry><entry>Description</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="63pt" align="left"/><colspec colname="2" colwidth="21pt" align="right"/><colspec colname="3" colwidth="21pt" align="left"/><colspec colname="4" colwidth="203pt" align="left"/><tbody valign="top"><row><entry>Version</entry><entry>4</entry><entry>bits</entry><entry>includes a version field to indicate a version of the network</entry></row><row><entry/><entry/><entry/><entry>protocol (e.g., for IPv6 the value in this field is always &#x2018;6&#x2019;)</entry></row><row><entry>Traffic Class</entry><entry>8</entry><entry>bits</entry><entry>Six most significant bits hold a DSCP value and remaining two</entry></row><row><entry/><entry/><entry/><entry>bits contain ECN value (see Table IPv4)</entry></row><row><entry>Flow Label</entry><entry>20</entry><entry>bits</entry><entry>A high-entropy identifier of a flow of packets between a source</entry></row><row><entry/><entry/><entry/><entry>and destination.</entry></row><row><entry>Payload Length</entry><entry>16</entry><entry>bits</entry><entry>Includes size of the payload in octets, including any extension</entry></row><row><entry/><entry/><entry/><entry>headers</entry></row><row><entry>Next Header</entry><entry>8</entry><entry>bits</entry><entry>Specifies the type of the next header.</entry></row><row><entry>Hop Limit</entry><entry>8</entry><entry>bits</entry><entry>Replaces the TTL field in IPv4. This value is decremented by one</entry></row><row><entry/><entry/><entry/><entry>at each forwarding node and the packet is discarded if it becomes 0.</entry></row><row><entry>Source Address</entry><entry>128</entry><entry>bits</entry><entry>Network address (e.g., IPv6 address) of the sending node</entry></row><row><entry>Destination Address</entry><entry>128</entry><entry>bits</entry><entry>Network address (e.g., IPv6 address) of the destination node</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0058" num="0051">The payload (data) section <b>502</b> includes zero or more extension headers, an NOP ID field <b>421</b> and the slice ID field <b>422</b>. The extension header(s) carry optional internet layer information and are placed between the fixed header <b>501</b> and an upper-layer protocol header. The NOP ID field and the slice ID field may be the same or similar as the NOP ID field <b>421</b> and the slice ID field <b>422</b> discussed previously. In this example, the NOP ID field <b>421</b> and the slice ID field <b>422</b> are located in the first byte (bits <b>0</b>-<b>16</b>) of the payload (data) section <b>502</b> of the packet <b>500</b>. In other implementations, the NOP ID field <b>421</b> and the slice ID field <b>422</b> can be located in other parts/sections of the payload (data) section <b>502</b>. In other implementations, the NOP ID field <b>421</b> and the slice ID field <b>422</b> can be included in an extension header such as, for example, a routing extension header (e.g., next header field value of 43), a mobility extension header (e.g., next header field value of 135), or a new extension header specifically designed for flow-specific slices (e.g., next header field value of 253 or 254 used for experimentation/testing).</p><p id="p-0059" num="0052">Referring back to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the declaration of a service type and QoS characteristics are done by the initiating service/application (see step <b>3</b>.<b>1</b>). The addition of metadata (e.g., the NOP ID <b>421</b> and the slice ID <b>422</b>) at the backbone or 5GC can be performed by an NF or application function (AF) using a mapping or other correspondence of ingress packets (e.g., packets <b>400</b>, <b>500</b>) to a corresponding set of QoS parameters/characteristics. The NF/AF can use information in the packets to match the packets to QoS parameters/characteristics, which can include, for example, destination address, port number, DSCP value, flow label, and/or the like. The particular fields to used can be predefined or configured by an NOP, service provider, or service consumer. If the values/data in the predefined or configured fields match for two different QoS levels, the NF/AF may sniff the payload deeper for other information to use. If not possible due to encryption (e.g., IPsec or the like), some kind of traffic classification may be used.</p><p id="p-0060" num="0053">Once the traffic is translated from the access network format into a higher-layer traffic packet format (e.g., 5G traffic translated into network packets (e.g., IP packets), transport packets, and/or the like), the backbone/core (or NF or AF within the backbone or core network) automatically inserts or adds the metadata into the packets so that the packets can be used by the next level (e.g., an DCN) to map the packets into the appropriate virtual channel (e.g., a virtual lane <b>652</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>). This can be useful if, for example, the QoS parameters/characteristics of the egress packets are not already known. The packets may include 2.b/c. For example, the network building block may not have any specific resource allocated for a slice (e.g., a slice <b>622</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>). In this case it will reach to an DCN management entity (e.g., orchestrator or infrastructure element) in order to retrieve the properties of that slice. In some implementations, it may let the packet continue, but it may also create some resource allocation or use a default/temporal virtual lane definition for that slice and/or NOP <b>220</b> if more packets are coming. In some implementations, it may remove the temporal virtual lane after some time of not being used (e.g., a predefined or configured idle time). The information may be stored in any case.</p><p id="p-0061" num="0054">In the example of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a static circumstance is assumed wherein the devices are statically bound to a particular access network. However, in many cases, devices may move or have a certain mobility pattern/characteristic, or the service type and/or QoS characteristics/parameters may change. The example of <figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an example where device mobility, services, and/or traffic patterns/characteristics may be dynamic.</p><p id="p-0062" num="0055">Referring back to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, flow-specific slicing in a dynamic environment can operate as follows. The NOP infrastructure <b>221</b> within each NOP domain <b>220</b> and/or DCN infrastructure with a DCN (e.g., DCN <b>640</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>) is/are responsible for gathering telemetry data (e.g., system information and/or other data) of their various cores <b>225</b>, IT infrastructure <b>226</b>, and/or other hardware and/or software (sub)systems. In this regard, each NOP domain <b>220</b> includes a telemetry function <b>223</b> (also referred to as &#x201c;statistics function <b>223</b>&#x201d; or the like), which collects the telemetry data and provides it to the DCN (see e.g., telemetry processor <b>656</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>). The telemetry data is then used to determine or identify slices that have similar e2e QoS treatment, QoS characteristics, and/or QoS parameters. The way in which the telemetry data is collected may be based on the implementation and/or deployment model being used. For example, 5G systems can include one or a combination of the following implementations/deployment models: 5G standalone UPF cores <b>225</b>, distributed UPFs, small cell NANs generating network traffic (e.g., IP traffic) directly, CU/DU split architectures, IAB architectures, and/or the like. The NOP infrastructure <b>221</b> (or telemetry functions <b>223</b>) provide the collected telemetry data to a network management entity (e.g., telemetry processor <b>656</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref> and/or QoS mgmt <b>642</b>, slicing management function <b>635</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the orchestration element <b>221</b>, NW orchestrator <b>725</b>, and/or the NSM <b>743</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>). The management entity is responsible for abstracting and/or aggregating the telemetry data including indications of one or more targets (e.g., specific clouds/CSPs, NOPs, and/or DCNs), and provides the telemetry data to the various intermediate tiers such as, for example, different infrastructure connections (e.g., MPLS, DCB, and/or the like), cloud infrastructure, and data center infrastructure (e.g., DCN <b>640</b>). In some implementations, the telemetry data can be provided to the various intermediate tiers via a UPF for the user plane traffic. In some cases, various end points and intermediate tiers of the e2e path may require information for the various slices or QoS parameters/characteristics on the NOP-side to perform the traffic optimizations discussed previously.</p><p id="p-0063" num="0056"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an example reference architecture <b>600</b> that includes a set of architectural building blocks for the e2e QoS and/or flow-specific slicing services discussed herein. This set of building blocks can be used by or for the slicing network architectures <b>200</b> and/or <b>300</b>. The e2e system network building blocks <b>600</b> include a network (NWs) <b>620</b> and a DCN <b>640</b>. The NW <b>620</b> includes one or more (radio) access networks ((R)ANs) and at least one CN. Each (R)AN includes a set of NANs which may be the same or similar as the NAN <b>340</b> in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, either of the NANs <b>240</b>-<b>1</b> and <b>240</b>-<b>2</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref> NANs <b>930</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, and/or the NAN <b>1040</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>) and the CN may be the same or similar as the CN the CNs <b>142</b><i>u</i>, <b>142</b><i>c</i>, <b>142</b>, and/or <b>142</b>&#x2032; of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the CN <b>942</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, and/or the CN <b>1020</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>. Additionally or alternatively, the NW <b>620</b> may correspond to either of the NOP domains <b>220</b>.</p><p id="p-0064" num="0057">The UE <b>610</b> operates one or more of N applications (apps) <b>611</b> (including app <b>611</b>-<b>1</b>, app <b>611</b>-<b>2</b>, . . . app <b>611</b>-N, where N is a number) to access and/or consume one or more of N services <b>610</b> (including service <b>612</b>-<b>1</b>, service <b>612</b>-<b>2</b>, . . . service <b>612</b>-N, where N is a number). Although the example of <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a same number of apps <b>611</b> and services <b>612</b>, in various implementations, there may be a different number of apps <b>611</b> and services <b>612</b>, for example, where an app <b>611</b> can be used to access multiple services <b>612</b> and/or multiple apps <b>611</b> can be used to access the same service <b>612</b>. The UE <b>610</b> may be the same or similar as the UEs <b>910</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref> and/or any other device/system discussed herein. In some implementations, some or all of the apps <b>611</b> can be operated by other devices such as servers and/or other computing devices. Additionally, although the example of <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the services <b>612</b> are shown as being in the DCN <b>640</b>, in other implementations, some or all of the services <b>612</b> may be implemented or operated outside of the DCN <b>640</b>. In some examples, the services <b>610</b> may be provided by a service provider environment (e.g., service provider environment <b>236</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref> and/or service provider domain <b>736</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>).</p><p id="p-0065" num="0058">The NW <b>620</b> provides individual network slices <b>622</b> for respective services <b>612</b>. For example, network slice <b>622</b>-<b>1</b> corresponds to service <b>612</b>-<b>1</b>, network slice <b>622</b>-<b>2</b> corresponds to service <b>612</b>-<b>2</b>, and so forth to network slice <b>622</b>-N which corresponds to service <b>612</b>-N. As mentioned previously, each network slice <b>622</b> can include a set of NFs and supporting resources. In some implementations, the NFs in a network slice <b>622</b> can be grouped into one or more network slice subnets. The network slices <b>622</b> depicted in <figref idref="DRAWINGS">FIG. <b>6</b></figref> may also represent one or more NSIs and/or one or more network slice subnets. A network slice subnet represents a group of NFs (including their corresponding resources) that form part or complete constituents of a network slice <b>622</b>. The grouping of the NF(s) allows the management of each group of NFs to be conducted independently of the network slice. A network slice subnet constituent may include one or more NF(s) and/or one or more other constituent network slice subnet(s). A network slice subnet may be shared by one or more network slice subnet(s), or not shared with any other network slice subnet. The NFs in a network slice subnet may be instance(s) of CN NF(s), instance(s) of AN NF(s), or any combination thereof. Additionally, a network slice subnet may have information representing a set of links with capacities to provide connection between NFs (e.g., TN requirements of the network slice subnet) and/or information of the physical, logical, and/or virtualized resources used.</p><p id="p-0066" num="0059">A network slice <b>622</b> and/or network slice subnet also has an associated network slice profile, which defines, specifies, or otherwise includes set of requirements (e.g. those derived from SLAs, SLSs, and/or the like) that are applicable to the network slice <b>622</b> and/or subnet constituents. The network slice profile may be common (e.g., applicable to all network slice subnet constituents, regardless of their types) or specific (e.g., applicable to only (R)AN NF(s) or only to CN NF(s) network slice subnet constituents). In one example, TN requirements (e.g. set of QoS attributes/characteristics/parameters for links interconnecting the network slice subnet constituent NFs) may be included in a network slice profile. In some implementations, the network slice profile can include mappings of a network slice <b>622</b> (or network slice subnet constituents) to one or more virtual lanes <b>652</b> outside of the NW <b>620</b> and/or a mapping of the network slice <b>622</b> (or network slice subnet constituents) to one or more services <b>612</b> (which may or may not be outside of the NW <b>620</b>).</p><p id="p-0067" num="0060">Additionally or alternatively, a network slice <b>622</b> and/or network slice subnet has one or more service profiles, which represents SLAs and/or SLSs of a network slice <b>622</b> and/or network slice subnet. In some implementations, an individual service profile corresponds to a specific service (e.g., an individual service <b>236</b><i>c</i>). The requirements of the network slice profile may be industry requirements, NOP requirements, and/or service provider environment <b>236</b> requirements (e.g., requirements of service <b>236</b><i>c</i>). In one example, a service profile is used to capture a set of requirements for service/use case (e.g., requirements for UHD slice <b>121</b>, requirements for eMBB slice <b>122</b>, requirements for MIoT slice <b>123</b>, and/or requirements for URLLC slice <b>124</b>). In another example, a service profile is used to capture a set of specific industry requirements for creation of network slice <b>622</b> such as V2X, smart grid, remote healthcare, and/or the like. In another example, a service profile is used to capture a set of flow-specific requirements for creation of flow-specific slice <b>662</b> such any of those discussed herein.</p><p id="p-0068" num="0061">The NW <b>620</b> includes a slicing orchestrator <b>625</b> that provides e2e QoS slicing services for various user/application services <b>612</b>. The slicing orchestrator <b>625</b> may also be referred to as &#x201c;orchestrator <b>625</b>&#x201d;, &#x201c;slice controller <b>625</b>&#x201d;, &#x201c;slicing function <b>625</b>&#x201d;, &#x201c;slicer <b>625</b>&#x201d;, and/or the like. In some examples, the orchestrator <b>625</b> may be the same or similar as the orchestrators <b>236</b><i>a</i>, <b>645</b>, <b>725</b>, <b>736</b><i>a</i>, <b>1160</b>, <b>1231</b> and/or container managers <b>1211</b>, <b>1221</b> discussed herein. The orchestrator <b>625</b> includes a monitoring function (&#x201c;monitor&#x201d;) <b>631</b>, one or more transformation function(s) (&#x201c;transformer(s)&#x201d;) <b>632</b>, QoS configurations <b>633</b>, one or more interfaces <b>634</b>, and a slicing management function (&#x201c;slicing mgmt&#x201d;) <b>635</b>. The QoS configurations <b>633</b> may include the QoS parameters, characteristics, and/or requirements of individual network slices <b>622</b> as discussed previously. The interfaces <b>634</b> may include front haul interfaces (e.g., between the UEs <b>610</b> and ANs or individual NANs), midhaul interfaces (e.g., between different ANs and/or NFs in an NW <b>620</b>), and/or backhaul interfaces (e.g., between the NW <b>620</b> and the DCN <b>640</b>).</p><p id="p-0069" num="0062">The monitor <b>631</b> monitors or otherwise gathers metrics, measurements, KPIs, and/or other aspects of individual network slices <b>612</b>, which may be based on one or more SLAs. Additionally or alternatively, the monitor <b>631</b> monitors or otherwise gathers metrics/measurements (e.g., KPIs, radio condition data, and/or any other network-related data such as any of those discussed herein) and telemetry data (e.g., system information and/or other data) of various cores <b>225</b>, IT infrastructure <b>226</b>, and/or other hardware and/or software (sub)systems as discussed previously (see e.g., <figref idref="DRAWINGS">FIG. <b>2</b></figref>). The transformer(s) <b>632</b> can include functions that translate or transform access network traffic into higher-layer traffic (e.g., network packets, and/or the like). Additionally or alternatively, the transformer(s) <b>632</b> may include the transformation functions and exposure gateways discussed previously with respect to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0070" num="0063">The slicing mgmt <b>635</b> provides slicing management services within a slicing management framework. The slicing management framework includes, for example, standardized management service interfaces (e.g., including interface(s) <b>634</b>) for the network slicing management services and NF management services; and a set of slicing management functions to manage NF(s) in individual network slices <b>612</b>. In some implementations, a CSP and/or NOP can provide an NSaaS to its subscribers or CSCs, which allows the subscribers/CSCs to use the network slice as the end user or optionally allows CSC to manage the network slice as manager via management interface exposed by the CSP. The network slicing management services are capable of supporting various NOP deployment options to support diverse use cases, applications, and/or use cases, as well as various management services applicable to various NFs.</p><p id="p-0071" num="0064">The provisioning of network slicing and/or slicing management services can include multiple phases, such as a preparation phase, a commissioning phase, an operation phase, and a decommissioning phase. In the preparation phase, the NSI does not exist. The preparation phase includes network slice design, network slice capacity planning, on-boarding and evaluation of NFs in the network slice <b>612</b>, preparing the network environment, and/or other necessary preparations required to be done before the creation of an NSI. During an NSI lifecycle stage, which includes the commissioning, operation, and decommissioning phases, the NSI provisioning operations include creating an NSI (commissioning phase); activating an NSI (operation phase); de-activating an NSI (operation phase); modifying an NSI (operation phase); and terminate an NSI (decommissioning phase). Similarly, provisioning for network slice subnet instance includes the following operations: NSSI creation; NSSI activation and associating it with certain NSI to be used by the NSI; disassociating the NSSI with certain NSI and de-active the NSSI if it's not associated with any NSI; NSSI modification; and NSSI termination.</p><p id="p-0072" num="0065">The commissioning phase includes creation of an NSI. During NSI creation all resources allocated for the NSI have been created and configured to satisfy the network slice requirements. NSI creation may trigger NSSI(s) creation or using existing NSSI(s) and setting up the corresponding associations.</p><p id="p-0073" num="0066">The operation phase includes the activation, supervision, performance reporting (e.g. for SLAs and/or KPI monitoring by the monitor <b>631</b>), resource capacity planning, modification, and de-activation of a NSI. For example, during the operation phase, the slicing mgmt <b>635</b> can adjust the resources allocated to individual slices <b>622</b> (e.g., allocate more or fewer resources) based on monitored/collected telemetry data (e.g., from telemetry function(s) <b>223</b>, <b>333</b>) and/or metrics/measurements and/or KPIs of the individual network slices <b>622</b>. NSI activation includes any actions that make the NSI active to provide communication services. NSI activation may trigger NSSI activation. NSI modification in operation phase could map to several workflows, e.g. changes of NSI capacity, changes of NSI topology, NSI reconfiguration. NSI modification can be triggered by receiving new network slice related requirements, new communication service requirements, or the result of NSI supervision automatically. NSI modification may trigger NSSI modification. The NSI deactivation operation may be needed before NSI modification operation and the NSI activation operation may be needed after the NSI modification operation. NSI deactivation includes any actions that make the NSI inactive and not providing any communication services. NSI deactivation trigger NSSI deactivation to deactivate constituent NSSI(s) which is not used by other NSI(s). Operator may decide to keep the NSI without termination after deactivation and reactivate it when receives new communication service request.</p><p id="p-0074" num="0067">The decommissioning phase includes terminating the NSI, which includes any action that makes the NSI not exist anymore and releasing resources that are not used by other NSI(s). NSI termination can involve decommissioning of non-shared constituents/elements (if required) and removing the NSI specific configuration from the shared constituents/elements. After the decommissioning phase, the NSI is terminated. NSI termination may trigger NSSI termination to terminate constituent NSSI(s) which is not used by other NSI(s).</p><p id="p-0075" num="0068">The information that can be used to describe an NSI may include resource model information, management model information, and capability model information. The resource model information describes static parameters and functional components of a network slice <b>622</b> such as, for example, a service profile, a network slice type (e.g. UHD, eMBB, URLLC, mMTC, mIoT, and/or the like), additional system features (e.g. multicast, edge computing, and/or the like), and priority information. In some implementations, the resource model information may be enhanced to include QoS parameters/requirements for a corresponding service-specific flow <b>662</b>. The management model information includes information that is used for network slice lifecycle management such as configuration profiles (e.g., application configuration parameters). The capability model information describes slice capabilities including, for example, supported communication service characteristic information (e.g., service type, UE mobility level, density of users, traffic density), QoS attributes (e.g., bandwidth, latency, throughput, and the like), capacity (e.g., maximum number of UEs), and/or other capabilities of an NSI and/or capabilities that can be exposed to a CSC and/or can be used for provisioning a service-specific flow <b>662</b>.</p><p id="p-0076" num="0069">The information that can be used to describe a network slice subnet instance may include resource model information, management model information, and capability model information. The resource model information of a network slice subnet describes the static parameters and functional component(s) of the network slice subnet such as, for example, slice profile, network slice subnet type (e.g. RAN eMBB, CN eMBB, and so forth), additional system features (e.g., multicast, edge computing, and the like), priority, QoS attributes (e.g., bandwidth, latency, number of subscribers and soon), Network Service Descriptor (NSD) ID, and/or the like. The management model information describes the information model that is used for network slice subnet lifecycle management such as, for example, configuration profile (e.g., application configuration parameters) and the like. The capability model information describes the capabilities of the network slice subnet such as, for example, supported communication service characteristic information (e.g. service type, UE mobility level, density of users, traffic density, and the like), QoS attributes (e.g., bandwidth, latency, throughput and so on) and capacity (e.g., maximum number of UEs), and/or other capabilities of the network slice subnet.</p><p id="p-0077" num="0070">Additionally or alternatively, the slicing mgmt <b>635</b> also manages AN and CN instances within the NW <b>620</b>, and coordinates with other management systems/functions outside of the NW <b>620</b> to manage non-NW <b>620</b> functions/elements. The non-NW <b>620</b> functions/elements include, for example, TN and/or data center (e.g., DCN <b>640</b>) elements. The slicing mgmt <b>635</b> provides network slice requirements to the corresponding management systems/functions of the non-NW <b>620</b> functions/elements. Examples of the network slice requirements include topology requirements, QoS configurations <b>633</b> (e.g., QoS attributes, characteristics, parameters, and/or requirements for individual TN links, fronthaul links, and/or backhaul links), SLAs, SLSs, and/or other relevant information. Additionally or alternatively, the slicing mgmt <b>635</b> operates and/or manages the slicing technology used to create and manage the NSIs. Examples of the slicing technologies can include 3GPP 5G network slicing technologies; OTN with Optical Channel Data Unit-k (ODUk) and/or Optical Channel Payload Unit-k; hierarchical QoS (HQoS); Ethernet channelized sub-interface; Flexible Ethernet (FlexE); generic network slice templates (see e.g., <i>Generic Network Slice Template</i>, GSMA Permanent Reference Document (PRD) NG.116 v7.0 (17 Jun. 2022), the contents of which are hereby incorporated by reference in its entirety), and/or the like.</p><p id="p-0078" num="0071">In various implementations, the slicing mgmt <b>635</b> is responsible for abstracting and/or aggregating the monitored/collected telemetry data, and provides the telemetry data to identified service provider environments <b>236</b> (e.g., specific clouds and/or edge networks hosting the services <b>236</b><i>c</i>). After a service <b>236</b><i>c </i>is deployed in the service provider environment <b>236</b>, the slicing mgmt <b>635</b> may attach, map, assign, or otherwise associate that service <b>236</b><i>c </i>with a network slice <b>622</b> or multiple network slices <b>622</b> in the NW <b>620</b>. Here, the service provider environment <b>236</b> may be part of the NW <b>620</b>, the DCN <b>640</b>, or a separate platform (e.g., an edge network such as any of those discussed herein). Before, after, or concurrently with the service <b>236</b><i>c </i>being matched to the network slice <b>622</b>, the network slice <b>622</b> is attached, mapped, assigned, or otherwise associated with a virtual lane <b>652</b> or multiple virtual lanes <b>652</b>. The slicing mgmt <b>635</b> may also provide the telemetry data to various intermediate tiers such as, for example, different infrastructure connections (e.g., interfaces <b>634</b> and/or <b>643</b>), cloud infrastructure, DCN <b>640</b>, and/or the like.</p><p id="p-0079" num="0072">The DCN <b>640</b> includes infrastructure/equipment such as, for example, servers (e.g., rack mount, blade mount, and/or the like), data processing units (DPUs) and/or infrastructure processing units (IPUs), hardware accelerators and/or accelerator pools, NICs and/or smartNICs, routers, bridges, switches, relays, network fabrics, network appliances, gateways devices, cooling plant, and/or the like. Additionally or alternatively, the infrastructure/equipment in the DCN <b>640</b> may be arranged in any suitable topology such as, for example, basic tree, fat-tree, Leaf-Spine, clos network, VL2, JellyFish, DCell, BCube, Xpander, FiConn, Scafida, and/or the like. In some examples, the DCN <b>640</b> is owned or operated by a DCSP. The DCSP may be a CSP that provides cloud computing services. Additionally or alternatively, the DCSP may be an edge computing service provider and the DCN <b>640</b> may be an edge data center or represent an edge computing network (see e.g., edge layer <b>937</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>) that is deployed at or near one or more NANs (e.g., NANs <b>930</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>). For example, the DCN <b>640</b> may be a containerized data center housed within one or more shipping containers or other like enclosure(s) that can be deployed at various locations. In any of these examples, at least some of the DCN resources and/or infrastructure/equipment in DCN <b>640</b> may be or host the service provider environment <b>236</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0080" num="0073">The DCN <b>640</b> provides individual virtual lanes <b>652</b> for respective network slices <b>622</b>. For example, virtual lane <b>652</b>-<b>1</b> corresponds to network slice <b>622</b>-<b>1</b>, virtual lane <b>652</b>-<b>2</b> corresponds to network slice <b>622</b>-<b>2</b>, and so forth to virtual lane <b>652</b>-N which corresponds to network slice <b>622</b>-N. As examples, the virtual lanes <b>652</b> can be DCB virtual lanes, priority-based flow control (PFC) priority groups (see e.g., [IEEE802.1Q]), Fibre Channel (FC) virtual links, virtual LAN (VLAN) channels, and/or the like and/or combinations thereof.</p><p id="p-0081" num="0074">In various implementations, a virtual lane <b>652</b> and a network slice <b>622</b> are combined, attached, merged, mapped, assigned, or otherwise associated with one another to provide a corresponding flow-specific slice <b>662</b> and/or e2e QoS enhancements discussed herein for one or more services <b>612</b>. For example, flow-specific slice <b>662</b>-<b>1</b> comprises network slice <b>622</b>-<b>1</b> and virtual lane <b>652</b>-<b>1</b>, flow-specific slice <b>662</b>-<b>2</b> comprises network slice <b>622</b>-<b>2</b> and virtual lane <b>652</b>-<b>2</b>, and so forth to flow-specific slice <b>662</b>-N comprising network slice <b>622</b>-N and virtual lane <b>652</b>-N. In some examples, flow-specific slice <b>662</b> may be referred to as a &#x201c;flow-based slice <b>662</b>&#x201d;, an &#x201c;e2e QoS construct <b>662</b>&#x201d;, an &#x201c;e2e QoS path <b>662</b>&#x201d;, and/or the like. In some examples, each flow-based slice <b>662</b> includes one network slice <b>622</b> and one virtual lane <b>652</b>. In other examples, a flow-based slice <b>662</b> can include a set of one or more network slices <b>622</b> and a set of one or more virtual lanes <b>652</b>. Additionally or alternatively, a flow-based slice <b>662</b> can include virtual lanes <b>652</b> in different NWs and/or NOP domains (e.g., a first set of network slices <b>622</b> of in a flow-based slice <b>662</b> can be in NOP domain <b>220</b>-<b>1</b> and a second set of network slices <b>622</b> of in the flow-based slice <b>662</b> can be in NOP domain <b>220</b>-<b>2</b>). In various implementations, the network slice(s) <b>622</b> and virtual lane(s) <b>652</b> can be set up when for a flow-specific slice <b>662</b> is requested by a subscriber or service consumer. Additionally or alternatively, newly instantiated virtual lane(s) <b>652</b> can be mapped or assigned to existing (or already instantiated) network slice(s) <b>622</b> to form or otherwise create a flow-specific slice <b>662</b> when flow-specific slice <b>662</b> creation is requested. Additionally or alternatively, newly instantiated network slice(s) <b>622</b> can be mapped or assigned to existing (or already instantiated) virtual lane(s) <b>652</b> to form or otherwise create a flow-specific slice <b>662</b> when flow-specific slice <b>662</b> creation is requested. Additionally or alternatively, existing (or already instantiated) network slice(s) <b>622</b> can be mapped or assigned to existing (or already instantiated) virtual lane(s) <b>652</b> to form or otherwise create a flow-specific slice <b>662</b> when flow-specific slice <b>662</b> creation is requested. Additionally or alternatively, existing and/or already instantiated network slice(s) <b>622</b> can be merged together and mapped to one or more virtual lane(s) <b>652</b> for a flow-specific slice <b>662</b>. Additionally or alternatively, existing and/or already instantiated virtual lane(s) <b>652</b> can be merged together and mapped to one or more network slice(s) <b>622</b> for a flow-specific slice <b>662</b>. In these ways, network slice(s) <b>622</b> and virtual lane(s) <b>652</b> can be &#x201c;cobbled together&#x201d; in various ways to form or create flow-specific slices <b>662</b> on an as-needed basis.</p><p id="p-0082" num="0075">The DCN <b>640</b> includes a DCN orchestrator <b>645</b> that assists in providing e2e QoS slicing for various services <b>612</b>. The DCN orchestrator <b>645</b> may also be referred to as &#x201c;orchestrator <b>645</b>&#x201d;, &#x201c;virtual lane controller <b>645</b>&#x201d;, &#x201c;DCB controller <b>645</b>&#x201d;, &#x201c;DCB function <b>645</b>&#x201d;, &#x201c;DCN management function <b>645</b>&#x201d;, and/or the like. In some examples, the orchestrator <b>645</b> may be the same or similar as any one or more of the orchestrators <b>236</b><i>a</i>, <b>625</b>, <b>725</b>, <b>736</b><i>a</i>, <b>1160</b>, <b>1231</b> and/or container managers <b>1211</b>, <b>1221</b> discussed herein. The DCN orchestrator <b>645</b> manages NF and virtual lane aspects, and provides various management services including, for example, provisioning, fault supervision; performance assurance; trace management; file management; application management; communication monitoring; startup, registration, and/or termination/tear-down of PNFs; instantiation and termination/tear-down of VNFs; scaling management services for PNFs and/or VNFs; among many other management services. The DCN orchestrator <b>645</b> manages the provisioning, maintenance, (resource) scaling, and termination of individual virtual lanes <b>652</b>. In various implementations, the DCN orchestrator <b>645</b> also handles the mapping or association of network slices <b>622</b> and virtual lanes <b>652</b> that make up one or more flow-based slices <b>662</b>.</p><p id="p-0083" num="0076">The DCN orchestrator <b>645</b> includes a QoS management function (&#x201c;QoS mgmt&#x201d;) <b>642</b>, one or more interfaces <b>643</b>, feedback generator <b>644</b>, packet processor <b>655</b>, and telemetry processor <b>656</b>. The interfaces <b>643</b> may include various backhaul interfaces (e.g., between the NW <b>620</b> and the DCN <b>640</b>, and/or interfaces between various DCN infrastructure elements).</p><p id="p-0084" num="0077">The QoS mgmt <b>642</b> configures and manages QoS aspects of flow-based slices <b>662</b> and/or virtual lanes <b>652</b>. This can include scheduling, assigning, and/or prioritizing resources for individual virtual lanes <b>652</b> that are mapped to a particular slice <b>622</b>. The QoS mgmt <b>642</b> is configured to implement various QoS mechanisms based on network slice identifiers/identities. For example, the QoS mgmt <b>642</b> is capable of instantiating the virtual lanes <b>652</b>, and mapping, attaching, assigning, or otherwise associating the instantiated virtual lanes <b>652</b> with one or more network slices <b>622</b> in the NW <b>6</b>. Additionally or alternatively, the QoS mgmt <b>642</b> can dynamically create and manage temporal or temporary virtual lanes <b>652</b> when a network slice <b>622</b> crosses into an NOP domain that has not been setup with the virtual lane <b>662</b>. In some implementations, the QoS mgmt <b>642</b> labels and/or configures QoS policies/configurations to be aligned with QoS policies/QoS configurations <b>633</b> in the NW <b>620</b>. In some implementations, this may be done when the DCN <b>640</b> and/or the QoS mgmt <b>642</b> implements differentiated QoS (e.g., based on the DSCP field as shown by <figref idref="DRAWINGS">FIGS. <b>4</b> and <b>5</b></figref>). Additionally or alternatively, the QoS mgmt <b>642</b> can proactively allocate or de-allocate resources to/from a virtual lane <b>652</b> based on various factors such as, for example, the amount of load that is seen at the network slicing <b>662</b>, metrics and/or measurement indicating that SLAs/SLSs are not being met (or are predicted to not be met), and/or other factors.</p><p id="p-0085" num="0078">In some implementations, the QoS mgmt <b>642</b> provides an interface for clients/subscribers to query and set network policies for the flow-based slices <b>662</b>. The network policies define a set of conditions and actions such as allowing specific types of network traffic to be assigned to traffic classes (e.g., DCB traffic classes, PFC priorities, and/or the like) for ingress packets, egress packets, packet processing, and/or prioritized delivery. For example, a condition may define or specify QoS parameters and/or characteristics, and ingress and/or egress packet that match the specified condition are assigned to corresponding action(s). The policy actions can specify a QoS class, priority level, and/or traffic class to which the packets should be assigned, destination ports or addresses, and/or other actions.</p><p id="p-0086" num="0079">The feedback generator <b>644</b> generates, measures, and/or collects metrics, measurements, and/or telemetry data of individual slices <b>622</b>, virtual lanes <b>652</b>, and/or flow-specific slices <b>662</b>, and generates feedback based on the metrics, measurements, and/or telemetry data. The feedback generator <b>644</b> provides the feedback to the NW <b>620</b> to perform various actions to support the flow-specific slices <b>662</b>. The feedback can include the collected metrics/measurements, hints, status updates, instructions, QoS configuration data, and/or other suitable data that can be used to support flow-specific slices <b>662</b>. For example, the feedback generator <b>644</b> and/or the QoS mgmt <b>642</b> may determine that the NW <b>620</b> (or a specific NF or (R)AN function) to perform certain optimizations (if possible) for one or more slices <b>622</b> depending on various factors (e.g., a current or predicted utilization of one or more interfaces <b>634</b> and/or interfaces <b>643</b>). In this example, the generated feedback can include instructions or indicators to perform the optimizations for the one or more slices <b>622</b>. This allows the telemetry and/or metrics/measurements of individual slices <b>622</b> to be scaled-up or scaled down so that the flow-specific slices <b>662</b> can be allocated and/or managed in an efficient manner. Additionally or alternatively, the feedback generator <b>644</b> and/or the QoS mgmt <b>642</b> may implement various traffic shaping schemes, traffic splitting schemes, traffic switching schemes, traffic steering schemes, compression schemes, and/or the like. This may depend on the functionalities available on the hardware (e.g., CPUs, accelerators, DPUs/IPUs, and/or the like) in the NW <b>620</b> and/or in the DCN <b>640</b>.</p><p id="p-0087" num="0080">The packet processor <b>655</b> performs various packet processing functions and/or operates one or more packet processing pipelines. Examples of packet processing functions include packetization; assembly; application of filters, rules, policies, and/or classifiers to data and/or ingress and/or egress packets; checking cycling redundancy codes (CRCs) and/or CRC re-generation; framing; encapsulation; encryption and/or decryption; packet reordering; routing-related tasks; and/or other packet processing functions or tasks. In some examples, the packet processor <b>655</b> extracts metadata (e.g., NOP ID <b>421</b> and/or slice ID <b>422</b>) from individual packets as the individual packets enter or exit the DCN <b>640</b>, and the packet processor <b>655</b> applies classifiers, rules, policies, and/or matching criteria can be applied to each packet entering or exiting the DCN <b>640</b> to map or assign the individual packets to a flow-specific slice <b>662</b>. Additionally or alternatively, the packet processor <b>655</b> can insert, inject, append, or otherwise add metadata (e.g., NOP ID <b>421</b> and/or slice ID <b>422</b>).</p><p id="p-0088" num="0081">The telemetry processor <b>656</b> can store packets/data and/or performance data (e.g., measurements, metrics, statistics, key performance indicators (KPIs), and/or the like), and/or other like data generated and/or otherwise associated with NSIs and/or virtual lane instances <b>652</b>. In some examples, the NW <b>620</b> may include statistics functions and/or telemetry functions (e.g., telemetry function <b>223</b>, <b>323</b>) that provide various metrics/measurements and/or telemetry data to the telemetry processor <b>656</b>. The manner in which the telemetry data, statistics, metrics/measurements, and/or KPIs is collected may be based on the implementation and/or deployment model and/or topology of the NW <b>620</b> and/or DCN <b>640</b>. To store the telemetry data and/or metrics/measurements, the DCN <b>640</b> and/or telemetry processor <b>656</b> can include any suitable combination of statistics collection elements (and memory/storage circuitry such as any of those discussed herein. Additionally, the telemetry processor <b>656</b> can store various sets of telemetry data, statistics, metrics/measurements, and/or KPIs in suitable databases, time-series databases, key-value stores, and/or other data structures. In some implementations, the telemetry processor <b>656</b> provides the collected and/or stored telemetry data, statistics, metrics/measurements, and/or KPIs to the QoS mgmt <b>642</b>, and the QoS mgmt <b>642</b> abstracts and/or aggregates the data and provides the abstracted/aggregated data to various intermediate tiers such as, for example, different NW infrastructure nodes, cloud infrastructure, and/or other compute nodes in the DCN <b>640</b> via the interfaces <b>643</b> and/or the like.</p><p id="p-0089" num="0082">In some implementations, the feedback generator <b>644</b>, the packet processor <b>655</b>, and/or the telemetry processor <b>656</b> are embodied as one or more stream processors. The stream processor(s) process data directly as it is produced or received, and detect conditions from the data streams within a relatively small time period (e.g., measured in terms of microseconds to minutes). The stream processor(s) can be implemented as software components (e.g., software engines, software agents, artificial intelligence (AI) agents, modules, objects, or other like logical units), as individual hardware elements (e.g., general-purpose processing elements and/or special-purpose processing elements), or a combination thereof. In an example software-based implementation, the stream processor(s) are developed using a suitable programming language(s) and/or development tools/environments, which are executed by one or more processors of one or more computing systems (see e.g., processor circuitry <b>1452</b> of <figref idref="DRAWINGS">FIG. <b>14</b></figref>). In this example, logic and/or program code of the stream processor(s) may be executed by a single processor or by multiple processing devices. In an example hardware-based implementation, the stream processor(s) are implemented by respective hardware elements, such as GPUs (or floating point units within one or more GPUs), hardware accelerators (e.g., FPGAs, ASICs, DSPs, SoCs, digital signal controllers (DSCs), etc.) that are configured with appropriate logic blocks, bit stream(s), etc. to perform their respective functions, AI accelerating co-processor(s), tensor processing units (TPUs), and/or the like. In some embodiments, the stream processor(s) may be implemented using stream processor(s), which are systems and/or applications that send or receive data streams and execute the applications or analytics logic in response to detecting events or triggers from the data streams. The stream processor(s) process data directly as it is produced or received and detect conditions from the data streams within a relatively small time period (e.g., measured in terms of milliseconds to minutes). The stream processor(s) may be implemented using any stream/event processing engines or stream analytics engines such as, for example, Apache&#xae; Kafka&#xae;, Apache&#xae; Storm&#xae;, Apache&#xae; Flink&#xae;, Apache&#xae; Apex&#xae;, Apache&#xae; Spark&#xae;, IBM&#xae; Spade, Nvidia&#xae; CUDA&#x2122;, Intel&#xae; Ct&#x2122;, Ampa&#x2122; provided by Software AGO, StreamC&#x2122; from Stream Processors, Inc., and/or the like. In some implementations, the stream processor(s) may implement or operate virtual machines (VMs), virtualization containers, or other suitable runtime environment(s) in which various packet processing applications, telemetry analysis applications, and/or other applications may be executed.</p><p id="p-0090" num="0083">Additionally or alternatively, the various elements in orchestrator <b>625</b> and/or orchestrator <b>645</b> can be implemented as separate virtualization containers, which may be deployed and managed using a suitable containerization technology/framework. Examples of the virtualization/containerization frameworks that can be used include Docker&#xae;, Kubernetes&#xae;, containerd, Google&#xae; Container Engine, and/or any of the other container and/or virtualization technologies discussed herein, or combination(s) thereof. Other combinations of container and orchestration technologies can be used in other implementations. Any of these example implementations can be combined with any of the aforementioned example implementations, and/or any other example implementations discussed herein.</p><p id="p-0091" num="0084">1.2. Flow-Specific Slicing Procedures</p><p id="p-0092" num="0085"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows an example flow-specific slicing procedure <b>700</b>, which allows for the creation/termination of flow-specific slicing as opposed to service based QoS in 5G systems. The procedure <b>700</b> takes place between a UE <b>710</b>, a NW domain <b>720</b>, and a service provider domain <b>736</b>. The NW domain <b>720</b> includes a RAN <b>721</b> which may include one or more NANs and/or other network elements/functions, an NW orchestrator <b>725</b>, and a CN <b>742</b> which includes a network slice manager (NSM) <b>743</b> or some other NF that handles network slicing, among many other NFs such as those discussed in [TS23501]. The service provider domain <b>736</b> includes a service orchestrator <b>736</b><i>a </i>and implemented/provisioned service(s) <b>736</b><i>c </i>which may be based on one or more applications (apps). Additionally, the UE <b>710</b> operates a user/client app <b>711</b> that corresponds to the service provider app <b>736</b><i>d </i>in the service provider domain <b>736</b>. Procedure <b>700</b> may operate as follows.</p><p id="p-0093" num="0086">At operation <b>7</b>.<b>1</b>, the service orchestrator <b>736</b><i>a </i>sends a request or indicator for a flow-specific slice <b>662</b> to the NW orchestrator <b>725</b>. In some implementations, the request/indicator includes an e2e QoS configuration and/or QoS/slice requirements. For example, the request/indicator can be in the form shown by example instruction [2].</p><p id="p-0094" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>FlowSlice_create(user_info,QoS_info,app_info,duration, . . . }&#x2003;&#x2003;[2]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0095" num="0087">In example instruction [2], &#x201c;user info&#x201d; includes various information related to user <b>710</b>, &#x201c;QoS_info&#x201d; includes the QoS configuration/requirements for the flow-specific slice <b>662</b>, &#x201c;app_info&#x201d; includes information about the service <b>736</b><i>c </i>and/or service provider app <b>736</b><i>d</i>, and/or the corresponding user/client app <b>711</b> related to the flow and/or the flow-specific slice <b>662</b>, &#x201c;duration&#x201d; is a length of time and/or a set of time periods that the flow-specific slice <b>662</b> and/or the network slice <b>622</b> should be active, and the ellipsis ( . . . ) indicates that additional information may be provided (e.g., thresholds, conditions, variables, filter rules, and/or other parameters). In one example, example instruction [2] can additionally or alternatively include &#x201c;flow_info&#x201d;, which is or includes a flow configuration and/or a set of parameters/characteristics of a flow to which the flow-specific slice <b>662</b> belongs. In some implementations, the QoS and/or flow characteristics can be configured by an NOP or user/subscriber. In some implementations, the service orchestrator <b>736</b><i>a </i>or the orchestrator <b>725</b> extract flow properties/characteristics of an individual flow. In these ways, a dynamic resolution for the flow-specific slice <b>662</b> can be specified. In one example, the QoS configuration and/or flow configuration may indicate that packets belonging to the flow will be sent at 30 millisecond (ms) intervals, and therefore, the network slice <b>622</b> and/or the flow-specific slice <b>662</b> should be activated every 30 ms. In another example, the QoS configuration and/or flow configuration may specify or define an application-specific or user-specific traffic classification for packets belonging to the flow, and how to identify packets belonging to different classes of the application-specific or user-specific traffic classification. Other configuration options are also possible in various implementations.</p><p id="p-0096" num="0088">Additionally or alternatively, the orchestrator <b>725</b> can operate or use one or more machine learning models to derive the QoS/flow characteristics for individual flows. In one example, packets belonging to individual flows may be marked or labeled to instruct or notify the orchestrator <b>725</b> to use those packets for training or inference determinations. Additionally, the orchestrator <b>725</b> can also send the inferences/predictions to the service orchestrator <b>736</b><i>a </i>or other edge/cloud functions, which can then use the inferences/predictions to update or adjust parameters/characteristics of the flow-specific slice <b>662</b> and/or update parameters/characteristics of the QoS/flow configurations.</p><p id="p-0097" num="0089">At operation <b>7</b>.<b>2</b>, the NW orchestrator <b>725</b> sends an instruction or indicator to the RAN <b>721</b> to create a network slice <b>622</b> for the flow-specific slice <b>662</b>, and at operation <b>7</b>.<b>3</b> the orchestrator <b>725</b> sends an instruction or indicator to the CN <b>742</b> (or NSM <b>743</b>) to create the network slice <b>622</b> for the flow-specific slice <b>622</b>. The instruction/indicator at operation <b>7</b>.<b>2</b> may be in the form shown by example instruction [3], and the instruction/indicator at operation <b>7</b>.<b>3</b> may be in the form shown by example instruction [4], where the parameters in the instructions/indicators may be the same or similar to those discussed previously with respect to example instruction [2].</p><p id="p-0098" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>RanSlice_create{user_info,QoS_info,app_info,duration, . . . }&#x2003;&#x2003;[3]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0099" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Core_net_Slice_create{user_info,QoS_info,app_info,duration, . . . }&#x2003;&#x2003;[4]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0100" num="0090">In some implementations, at operation <b>7</b>.<b>2</b> the NW orchestrator <b>725</b> sends an instruction or indicator to the RAN <b>721</b> to allocate one or more existing or already instantiated network slices <b>622</b> to the flow-specific slice <b>662</b>. Additionally or alternatively, at operation <b>7</b>.<b>3</b> the NW orchestrator <b>725</b> sends an instruction or indicator to the CN <b>742</b> (or NSM <b>743</b>) to allocate one or more existing or already instantiated network slices <b>622</b> to the flow-specific slice <b>662</b>.</p><p id="p-0101" num="0091">At operation <b>7</b>.<b>4</b>, the RAN <b>721</b> performs various operations/tasks to set up a network slice <b>622</b> (or allocate existing network slice(s) <b>622</b>) for the flow-specific slice <b>662</b>, and sends RAN slice information to the NW orchestrator <b>725</b>. Similarly, at operation <b>7</b>.<b>5</b>, the CN <b>742</b> (or NSM <b>743</b>) performs various operations/tasks to set up the network slice <b>622</b> (or allocate existing network slice(s) <b>622</b>) for the flow-specific slice <b>662</b>, and sends CN slice information to the NW orchestrator <b>725</b>. The RAN slice information may be in the form shown by example instruction [5], and the CN slice information may be in the form shown by example instruction [6].</p><p id="p-0102" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>RAN_slice{Slice_id,QoS_info,duration, . . . }&#x2003;&#x2003;[5]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0103" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Core_net_slice{Slice_id,QoS_info,duration, . . . }&#x2003;&#x2003;[6]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0104" num="0092">In instructions [5] and [6], the &#x201c;Slice_id&#x201d; is an identifier or identity of the network slice <b>622</b> (e.g., NSSAI, S-NSSAI, slice ID <b>422</b>, and/or the like). The &#x201c;QoS_info&#x201d; is the QoS flow configuration/characteristics of the network slice <b>622</b> (e.g., in a 5G system, this may include a QoS profile provided to the NAN by an SMF, one or more QoS rule(s) and/or QoS Flow level QoS parameters provided by the SMF and intended for the UE <b>710</b>, and/or one or more uplink and/or downlink packet detection rules (PDRs) provided by the SMF and intended for a UPF). The &#x201c;duration&#x201d; indicates a time period or set of intervals during which the network slice <b>622</b> will be active or inactive. In some implementations, the RAN slice information and/or the CN slice information can include a service profile and/or a network slice profile of the network slice <b>622</b>, and/or may include resource model information, management model information, and/or capability information of the network slice <b>622</b>, an NSI, and/or constituent network slice subnets of the network slice <b>622</b>.</p><p id="p-0105" num="0093">At operation <b>7</b>.<b>6</b>, the NW orchestrator <b>725</b> compiles, aggregates, or otherwise processes the slice information obtained from the RAN <b>721</b> and the CN <b>742</b> (or NSM <b>743</b>), and sends the network slice information to the NW orchestrator <b>725</b>. The network slice information may be in the form shown by example instruction [7], which may include the same or similar parameters discussed previously with respect to instructions [2], [3], [4], [5], and/or [6].</p><p id="p-0106" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Slice_info{user_info,app_info,QoS_info,duration, . . . }&#x2003;&#x2003;[7]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0107" num="0094">In this example, the Slice_info may represent or indicate the resources and/or other network slice aspects that the RAN <b>721</b> can reserve for the network slice <b>622</b>. Sending the Slice_info to the service orchestrator <b>736</b><i>a </i>allows the service orchestrator <b>736</b><i>a </i>to know which slice parameters can be adjusted or altered. Additionally or alternatively, the example instruction [7] can include the Slice_id received from the NW orchestrator <b>725</b>. Furthermore, various operations/tasks may be performed by the RAN <b>721</b> and/or CN <b>742</b> (or NSM <b>743</b>) to set up network slice <b>622</b> before, during, or after performance of operations <b>7</b>.<b>2</b>, <b>7</b>.<b>3</b>, <b>7</b>.<b>4</b>, and/or <b>7</b>.<b>5</b>.</p><p id="p-0108" num="0095">At operation <b>7</b>.<b>7</b>, the service orchestrator <b>736</b><i>a </i>provisions the various slice information into the service <b>736</b><i>c </i>and/or app <b>736</b><i>d</i>. The provisioning information may be in the form shown by example instruction [8], which may include the same or similar parameters discussed previously with respect to instructions [2], [3], [4], [5], [6], and/or [7].</p><p id="p-0109" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>ServiceApp_provision{user_info,app_info,QoS_info,duration, . . . }&#x2003;&#x2003;[8]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0110" num="0096">In some examples, the example instruction [8] can also include the Slice_id received from the NW orchestrator <b>725</b>. Additionally or alternatively, the service orchestrator <b>736</b><i>a </i>may update a mapping or other data structure to include a mapping or association between the network slice(s) <b>622</b> and one or more virtual lanes <b>652</b> created for the flow-specific slice <b>662</b>. The way in which services <b>736</b><i>c </i>and/or apps <b>736</b><i>d </i>are provisioned with the slicing information may be implementation-specific, use case-specific, application-specific, and/or based on design choice, and may vary from implementation to implementation. In some examples, a service mesh is employed for provisioning the services <b>736</b><i>c </i>and/or apps <b>736</b><i>d </i>with flow/QoS parameters/configuration data. Examples of the service mesh technologies that can be used include Istio (see e.g., <figref idref="DRAWINGS">FIG. <b>8</b></figref>), Linkerd, Consul, and/or some other suitable service mesh technology.</p><p id="p-0111" num="0097">After the e2e dedicated resources (e.g., flow-specific slice resources) have been set up at operation <b>7</b>.<b>7</b>, an e2e connection (e.g., flow-specific slice <b>662</b>) is established between app <b>711</b> and app <b>736</b><i>d </i>at operation <b>7</b>.<b>8</b>. In various implementations, the e2e connection (e.g., flow-specific slice <b>662</b>) may flow between app <b>711</b> and app <b>736</b><i>d </i>through the NW domain <b>720</b> and the service provider domain <b>736</b>. At operation <b>7</b>.<b>9</b>, an e2e flow with dedicated QoS takes place using the established e2e connection (or through the flow-specific slice <b>662</b>) where packets belonging to the flow are conveyed or communicated between app <b>711</b> and app <b>736</b><i>d</i>. In various implementations, there can be loopbacks and/or feedback of various statistics, metrics, measurements, KPIs, and/or the like related to the flow-specific slice <b>662</b>, which can be fed to the service orchestrator <b>736</b><i>a </i>and are used to update or adjust the QoS/flow parameters of the flow-specific slice <b>662</b> during the e2e flow with dedicated QoS. In these ways, the QoS/flow parameters of the flow-specific slice <b>662</b> are more adaptive and rapidly deployable in comparison to existing slicing technologies, which allows the flow-specific slice <b>662</b> to be expanded or otherwise scaled in a more efficient manner than existing slicing technologies, and beyond the traditional latency and throughput calculations used by existing slicing technologies. In particular, the flow-specific slice <b>662</b> can be heterogeneous and/or multidimensional, which is not possible for existing slicing technologies.</p><p id="p-0112" num="0098">When the e2e flow with dedicated QoS is completed, the e2e connection (or flow-specific slice <b>662</b>) can be terminated by performing operations <b>7</b>.<b>10</b>, <b>7</b>.<b>11</b>, and <b>7</b>.<b>12</b>. At operation <b>7</b>.<b>10</b>, the service orchestrator <b>736</b><i>a </i>sends an instruction, command, or indicator to the NW orchestrator <b>725</b> to destroy or terminate the e2e connection (or flow-specific slice <b>662</b>). The termination instruction, command, or indicator sent at operation <b>7</b>.<b>10</b> may be in the form shown by example instruction [9], which may include the slice ID discussed previously with respect to instructions [5], [6], [7], and/or [8].</p><p id="p-0113" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>FlowSpecificSlice_destroy{Slice_id}&#x2003;&#x2003;[9]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0114" num="0099">The NW orchestrator <b>725</b> sends respective termination instructions, commands, or indicators with the slice ID to the RAN <b>730</b> and/or the CN <b>742</b> (or NSM <b>743</b>). The termination instructions, commands, or indicators with the slice ID to the RAN <b>730</b> and/or the CN <b>742</b> (or NSM <b>743</b>) may be in the form shown by example instructions [10] and [11], respectively, which include the slice ID discussed previously with respect to instructions [5], [6], [7], [8], and/or [9].</p><p id="p-0115" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>RanSlice_destroy{Slice_id}&#x2003;&#x2003;[10]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0116" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Core_net_Slice_destroy{Slice_id}&#x2003;&#x2003;[11]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0117" num="0100">In <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the instructions [2], [3], [4], [5], [6], [7], [8], [9], [10], and/or [11] may be conveyed using any suitable APIs, web services, and/or interfaces between the NW domain <b>720</b> and the service provider domain <b>736</b>, and/or using various APIs, web services, and/or interfaces between the elements within the NW domain <b>720</b> and among elements in the service provider domain <b>736</b>. Additionally, in some examples, the NW orchestrator <b>725</b> may be a RAN orchestrator, a CN orchestrator, or some other NF that handles orchestration functions. Additionally or alternatively, the service provider domain <b>736</b> may be, or may be implemented in or by a cloud computing environment and/or an edge computing network, and the service provider orchestrator <b>736</b><i>a </i>may be a cloud orchestrator, an edge computing orchestrator, a container orchestrator, and/or one or more virtualization technologies. Additionally or alternatively, the service provider app <b>736</b><i>d </i>may be a cloud native application. Additionally or alternatively, the UE <b>710</b> may be the same or similar as the end point devices <b>160</b>, <b>1060</b> and/or UEs <b>910</b>, the NW orchestrator <b>725</b> may be the same or similar as the orchestrator <b>625</b>, container manager <b>1211</b>, <b>1221</b>, and/or container orchestrator <b>1231</b>, and the service provider orchestrator <b>736</b><i>a </i>may be the same or similar as the orchestrator <b>236</b><i>a</i>, container manager <b>1211</b>, <b>1221</b>, and/or container orchestrator <b>1231</b>.</p><p id="p-0118" num="0101">In any of the examples discussed herein, any of the orchestrators <b>236</b><i>a</i>, <b>625</b>, <b>645</b>, <b>725</b>, <b>736</b><i>a </i>may be embodied as one or more (or a collection of) network functions (NFs) that provide slicing functionality such as, for example, a Network Slice Admission Control Function (NSACF), Network Slice-specific and SNPN Authentication and Authorization Function (NSSAAF), Network Slice Selection Function (NSSF), Network Slice Management Function (NSMF), Network Slice Subnet Management Function (NSSMF), and/or other NFs such as those discussed in relevant 3GPP standards/specifications such as [TS23501], [TS28533], 3GPP TS 28.530 v17.2.0 (2021 Dec. 23) (&#x201c;[TS28530]&#x201d;), 3GPP TS 28.531 v17.42.0 (2022 Jun. 16) (&#x201c;[TS28531]&#x201d;), and/or the like. Additionally or alternatively, any of the orchestrators <b>236</b><i>a</i>, <b>625</b>, <b>645</b>, <b>725</b>, <b>736</b><i>a </i>may encompass one or more (or a collection of) other network slice functions such as an IETF Network Slice service provider and/or IETF Network Slice Controller (NSC), and/or an IETF 5G E2E Network Slice Orchestrator as discussed in Geng et al., 5<i>G End</i>-<i>to</i>-<i>end Network Slice Mapping from the view of Transport Network</i>, IETF Network Working Group, draft-geng-teas-network-slice-mapping-05 (7 Mar. 2022), https://www.ietf.org/archive/id/draft-geng-teas-network-slice-mapping-05.html (&#x201c;[IETF-Geng]&#x201d;) and Farrel et al., <i>Framework for IETF Network Slices</i>, IETF Network Working Group, draft-ietf-teas-ietf-network-slices-14 (3 Aug. 2022), https://www.ietf.org/archive/id/draft-ietf-teasetf-network-slices-14.html (&#x201c;[IETF-Farrel]&#x201d;), the contents of each of which are hereby incorporated by reference in their entireties. Additionally or alternatively, the NW orchestrator <b>725</b> and/or service orchestrator <b>736</b><i>a </i>may be the same or similar as the Intelligent Network Slice Manager (INSM) discussed in Int'l App. No. PCT/US2022/035759 filed on Jun. 30, 2022 (&#x201c;['759pct]&#x201d;), the contents of which is hereby incorporated by reference in its entirety and for all purposes.</p><p id="p-0119" num="0102">Additionally or alternatively, one or more of the orchestrators <b>236</b><i>a</i>, <b>625</b>, <b>645</b>, <b>725</b>, <b>736</b><i>a </i>can be deployed at or in a RAN such as in or by a central unit (CU) of a CU/DU split architecture (see e.g., [TS38401] and ['658]), in a network access node (NAN) such as at or co-located with a DU of a CU/DU split architecture (see e.g., [TS38401] and ['658]), and/or the like. Additionally or alternatively, one or more of the orchestrators <b>236</b><i>a</i>, <b>625</b>, <b>645</b>, <b>725</b>, <b>736</b><i>a </i>may be implemented as a service management and orchestration (SMO) entity, a RAN Intelligent Controller (RIC) (see e.g., [O-RAN]), and/or some other like entity/element. For example, some or all of the functionalities of one or more of the orchestrators <b>236</b><i>a</i>, <b>625</b>, <b>645</b>, <b>725</b>, <b>736</b><i>a </i>can be implemented as one or multiple xApps located at Near-Real-Time (RT) RAN Intelligent Controller (RIC) and/or one or multiple rApps at Non-RT RIC in O-RAN framework (see e.g., [O-RAN]). In one example implementation, the NW orchestrator <b>725</b> can be implemented as a near-RT RIC and the service orchestrator <b>736</b><i>a </i>can be implemented as an O-RAN SMO. In another example implementation, the NW orchestrator <b>725</b> can be implemented as a near-RT RIC and the service orchestrator <b>736</b><i>a </i>can be implemented as a non-RT RIC. In another example implementation, the NW orchestrator <b>725</b> can be implemented as a non-RT RIC and the service orchestrator <b>736</b><i>a </i>can be implemented as an O-RAN SMO.</p><p id="p-0120" num="0103">Additionally or alternatively, one or more of the orchestrators <b>236</b><i>a</i>, <b>625</b>, <b>645</b>, <b>725</b>, <b>736</b><i>a </i>is/are deployed at an edge compute node (e.g., edge compute node <b>936</b> in <figref idref="DRAWINGS">FIG. <b>9</b></figref>). For example, one or more of the orchestrators <b>236</b><i>a</i>, <b>625</b>, <b>645</b>, <b>725</b>, <b>736</b><i>a </i>can be implemented as an edge application (app) such as a MEC app operating in a MEC host (see e.g., [MEC]), an Edge Application Server (EAS) and/or Edge Configuration Server (ECS) in a 3GPP edge computing framework (see e.g., [SA6Edge]), or as a management function based on Zero-touch System Management (ZSM) architecture (see e.g., ETSI GS ZSM 001 V1.1.1 (2019 October), ETSI GS ZSM 002 v1.1.1 (2019 August), ETSI GS ZSM 003 v1.1.1 (2021 June) ETSI GS ZSM 009-1 V1.1.1 (2021 June), ETSI GS ZSM 009-2 V1.1.1 (2022 June), ETSI GS ZSM 007 V1.1.1 (2019 August) (collectively referred to as &#x201c;[ZSM]&#x201d;), the contents of each of which are hereby incorporated by reference in their entireties). Additionally or alternatively, one or more of the orchestrators <b>236</b><i>a</i>, <b>625</b>, <b>645</b>, <b>725</b>, <b>736</b><i>a </i>can be implemented as, or embodied as, an ONAP module in the Linux Foundation&#xae; Open Network Automation Platform (ONAP) (see e.g., ONAP Architecture, Rev. 9e77fad2 (updated 7 Jun. 2022), https://docs.onap.org/en/latest/guides/onap-developer/architecture/index.html, the contents of which are hereby incorporated by reference in its entirety). The various orchestration concepts described in the present disclosure can be applied to any or all of the aforementioned frameworks.</p><p id="p-0121" num="0104"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows an example service mesh architecture <b>800</b>, which may be used in various implementations discussed herein. The service mesh architecture <b>800</b> is based on the Istio architecture discussed in the <i>Istio documentation</i>, version 1.14.3 (2022), https://istio.io/v1.14.3/docs/, the contents of which is hereby incorporated by reference in its entirety and for all purposes. However, other service mesh technologies can be used such as any of those discussed herein.</p><p id="p-0122" num="0105">The service mesh architecture <b>800</b> includes a service mesh <b>801</b>. The service mesh <b>801</b> (also referred to as Istio mesh <b>801</b> or mesh <b>801</b>) is an infrastructure layer that enables managed, observable and secure communication between workload instances. A workload instance, at least in some examples, is a single instantiation of a workload's binary, and a workload is a binary deployed by one or more operators to deliver some function of a service mesh application. Workloads have names, namespaces, and unique IDs. In some examples, operators are methods of packaging, deploying, and managing a containerized application (e.g., a Kubernetes&#xae; application and/or the like). In some examples, the service <b>236</b><i>c </i>and/or service <b>736</b><i>c </i>discussed previously may be workload instances.</p><p id="p-0123" num="0106">A workload instance can expose zero or more service endpoints, and can consume zero or more services (e.g., services <b>821</b>-A and services <b>821</b>-B in <figref idref="DRAWINGS">FIG. <b>8</b></figref>). At least in some examples, a service <b>821</b> is, or includes, a delineated group of related behaviors within the service mesh <b>801</b>. Services <b>821</b> are identified using a service name, which are used to apply Istio policies such as, for example, load balancing and routing. A service <b>821</b> can be materialized by one or more service endpoints (e.g., a network-reachable manifestation of a service <b>821</b>), and may include one or multiple service versions (e.g., a distinct variant of a service <b>821</b>, which can be backed by different versions of a workload binary). In this example, each service <b>821</b> is deployed within a respective container <b>820</b> (including container <b>820</b><i>a </i>and <b>820</b><i>b </i>in <figref idref="DRAWINGS">FIG. <b>8</b></figref>). As an example, at least one of the services <b>821</b> may correspond to the service <b>236</b><i>c </i>and/or service <b>736</b><i>c </i>discussed previously. The containers <b>820</b> may be implemented using any suitable containerization technology such as, for example, Kubernetes&#x2122;, Docker&#x2122;, Linux Containers (LXC), Solaris containers, Microsoft&#xae; Hyper-V containers, and/or any other suitable containerization technology such as any of those discussed herein. Additionally, each container <b>820</b> may use the same or different containerization technologies from one another. Workload instances have a number of properties including, for example, a name and namespace; unique ID; network address (e.g., IP address and/or the like); labels; principal.</p><p id="p-0124" num="0107">The service mesh <b>801</b> is logically split into a data plane <b>802</b> and a control plane <b>803</b>. The data plane <b>802</b> is the part of a mesh <b>801</b> that directly controls communication between workload instances. The control plane <b>803</b> includes a set of system services that configure the mesh <b>801</b> or a subset of the mesh <b>801</b> to manage the communication between the workload instances within the mesh <b>801</b>. The control plane <b>803</b> manages and configures the intelligent proxies <b>822</b> to route traffic appropriately.</p><p id="p-0125" num="0108">The data plane <b>802</b> includes a set of intelligent proxies <b>822</b> (including proxies <b>822</b>-A and <b>822</b>-B in <figref idref="DRAWINGS">FIG. <b>8</b></figref>) deployed as sidecars to mediate and control traffic that the mesh services send and receive. The intelligent proxies <b>822</b> mediate and/or control some or all network communication between services <b>821</b> and/or microservices (also referred to as &#x201c;microservices <b>821</b>&#x201d;) (e.g., the mesh traffic <b>852</b> between proxies <b>822</b>-A and <b>822</b>-B). The intelligent proxies <b>822</b> also collect and report telemetry on some or all mesh traffic <b>852</b>. In this example, each proxy <b>822</b> is deployed within a respective container <b>823</b> (including container <b>823</b><i>a </i>and <b>823</b><i>b </i>in <figref idref="DRAWINGS">FIG. <b>8</b></figref>). The containers <b>823</b> may be implemented using the same or different containerization technology as the containers <b>820</b> and/or may use the same or different containerization technologies from one another.</p><p id="p-0126" num="0109">In some examples, the intelligent proxies <b>822</b> are implemented as envoy proxies (also referred to herein as &#x201c;envoys <b>822</b>&#x201d;) (see e.g., Envoy documentation, version 1.23 (15 Jul. 2022), https://www.envoyproxy.io/docs/envoy/v1.23.0/(&#x201c;[Envoy]&#x201d;), the contents of which is hereby incorporated by reference in its entirety and for all purposes). Envoy is a high level (e.g., L7) proxy and communication bus designed for relatively large modern service oriented architectures (SOAs). Envoy can be used to mediate inbound traffic (e.g., ingress traffic <b>851</b>) and outbound traffic (e.g., egress traffic <b>853</b>) for various services <b>821</b> in the service mesh <b>801</b>. In some implementations, envoy proxies <b>822</b> are the only components that interact with data plane traffic.</p><p id="p-0127" num="0110">In some implementations, envoy proxies <b>822</b> are deployed as sidecars to services <b>821</b>, logically augmenting the services <b>821</b> with other features such as, for example, dynamic service discovery, load balancing, transport layer security (TLS) termination, HTTP/2 and gRPC proxies, health checks, staged rollouts with percentage-based traffic split, rich metrics, traffic control features (e.g., enforcement of fine-grained traffic control with rich routing rules for HTTP, gRPC, WebSocket, and TCP traffic), network resiliency features (e.g., setup retries, failovers, circuit breakers, and fault injection), security and authentication features (e.g., enforcement of security policies and enforcement of access control and rate limiting defined through the configuration API(s)), and/or pluggable extensions model based on WebAssembly that allows for custom policy enforcement and telemetry generation for mesh traffic <b>852</b>. The sidecars may be sidecar containers, which extend and enhance a main container and share resources like pod storage, storage volumes, network interfaces, and the like. The main and sidecar containers also share a pod network, allowing them to communicate with each other on the same network using localhost or the pod's network address thereby reducing latency between the two containers. This sidecar deployment allows Istio to enforce policy decisions and extract rich telemetry which can be sent to monitoring systems to provide information about the behavior of the entire mesh <b>801</b>. The sidecar proxy model also allows Istio capabilities to be added to an existing deployment without requiring re-architecting or code rewrites.</p><p id="p-0128" num="0111">The control plane <b>803</b> includes an Istiod component <b>830</b>. The Istiod <b>830</b> provides service discovery, configuration, and certificate management. In some implementations, the Istiod <b>830</b> converts high level routing rules that control traffic behavior into envoy-specific configurations, and propagates them to the sidecars at runtime. In this example, the Istiod component <b>830</b> is a consolidated control plane binary that encapsulates the following functions (or microservices): pilot <b>831</b>, a citadel <b>832</b>, and a galley <b>833</b>.</p><p id="p-0129" num="0112">The pilot <b>831</b> provides service discovery for the Envoy sidecars, traffic management capabilities for intelligent routing (e.g., A/B tests, canary rollouts, and/or the like), and resiliency (timeouts, retries, circuit breakers, and/or the like). The pilot <b>831</b> programs the envoy proxies <b>822</b>, which are responsible for service discovery, load balancing, and routing. The pilot <b>831</b> converts high level routing rules that control traffic behavior into Envoy-specific configurations, and propagates them to the sidecars at runtime. The pilot <b>831</b> abstracts platform-specific service discovery mechanisms and synthesizes them into a standard format that a sidecar can consume. Istio can support discovery for multiple environments such as containers (e.g., Kubernetes containers and/or the like) and/or virtual machines (VMs). The pilot <b>831</b> can be configured to refine the envoy configurations to exercise more granular control over the traffic in the service mesh <b>801</b> via the Istio traffic management API.</p><p id="p-0130" num="0113">The citadel <b>832</b> enables service-to-service and end-user authentication with built-in identity and credential management. The citadel <b>832</b> can be used to upgrade unencrypted traffic in the service mesh <b>801</b>. Using the citadel <b>832</b>, operators can enforce policies based on service identity rather than on relatively unstable layer 3 or layer 4 network identifiers. The citadel <b>832</b> is also responsible for certificate generation. The citadel <b>832</b> acts as a certificate authority (CA) and generates certificates to allow secure mutual TLS (mTLS) communication in the data plane <b>802</b>.</p><p id="p-0131" num="0114">The galley <b>833</b> is a component that is responsible for configuration management, which can include, for example configuration validation, ingestion, processing and distribution. The galley <b>833</b> is responsible for insulating the rest of the Istio components from the details of obtaining user configuration from the underlying platform (e.g., Kubemetes&#xae;, Docker&#xae;, and/or the like). The control plane <b>803</b> can also include a mixer function/microservice (not shown by <figref idref="DRAWINGS">FIG. <b>8</b></figref>), which provides extensibility and/or acts as a policy and telemetry hub. The mixer is a platform-independent component that enforces access control and usage policies across the service mesh <b>801</b>, and collects telemetry data from the envoy proxies <b>822</b> and/or other services <b>821</b>. The proxies <b>822</b> extract request level attributes (e.g., data that describes a property of a specific service request and/or the environment for the request) and sends them to the mixer for evaluation. In some implementations, the mixer may be, or may be replaced with a Proxy WebAssembly (Wasm) plugins.</p><p id="p-0132" num="0115">Traffic management in the service mesh <b>801</b> may be based on Istio traffic management services. The Istio traffic management includes virtual services, destination rules, gateways, service entities, and sidecars. A virtual service allows users to configure how requests are routed to a &#x201c;real&#x201d; service <b>821</b> within the service mesh <b>801</b>. Each virtual service includes a set of routing rules (also referred to as &#x201c;traffic rules&#x201d;) that are evaluated in order, which allows a proxy <b>822</b> to match each given request to the virtual service to a specific destination within the mesh <b>801</b>. The routing rules in a virtual service specify how a proxy <b>822</b> is to send the virtual service's traffic to appropriate destination(s). Route destinations can be versions of the same service <b>822</b> or entirely different services <b>822</b>. The routing/traffic rules can be configured in combination with gateways (e.g., envoy gateways and/or gateway APIs) to control ingress traffic <b>851</b> and egress traffic <b>853</b>. The destination rules specify conditions and/or actions for traffic for a particular destination. Destination rules are applied after virtual service routing rules are evaluated, and apply to the traffic's &#x201c;real&#x201d; destination (e.g., a desired service <b>821</b>).</p><p id="p-0133" num="0116">The gateways (e.g., envoy gateways and/or gateway APIs) manage inbound and outbound traffic (e.g., ingress traffic <b>851</b>, mesh traffic <b>852</b>, and/or egress traffic <b>853</b>) and can be configured to control the traffic that remains inside the mesh <b>801</b> and/or leaves the mesh <b>801</b>. For example, gateway configurations are applied to standalone envoy proxies that run at the edge of the mesh <b>801</b>, rather than sidecar envoy proxies <b>822</b> running alongside a service <b>821</b>. A service entry allows entries to be added to a service registry, which allows traffic to be sent to/from external services as if it was that service were inside the mesh <b>801</b>. Configuring service entries allows you to manage traffic for services running outside of the mesh, including redirect and forward traffic for external destinations, such as APIs consumed from the web, or traffic to services in legacy infrastructure; defining retry, timeout, and fault injection policies for external destinations; and running a mesh service <b>821</b> in a VM and/or adding VMs to the mesh <b>801</b>. Moreover, sidecar configurations allow for the definition of ports and protocols to be permitted by envoy proxies <b>822</b> and limiting the set of services that individual envoy proxies <b>822</b> can reach.</p><p id="p-0134" num="0117">Based on the example of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the flow-specific slicing information/configuration (see e.g., operation <b>7</b>.<b>7</b> in <figref idref="DRAWINGS">FIG. <b>7</b></figref>) is provided to the control plane function <b>830</b>, and then the various parameters, properties, and/or data of the flow-specific slicing information/configuration is applied to a proxy <b>822</b> associated with the service <b>821</b> associated with the flow-specific slice <b>662</b>. The control plane function <b>830</b> configures the virtual services, destination rules, gateways, service entities, and/or sidecars for the proxies <b>822</b> based on the received flow-specific slicing information/configuration data. The proxies <b>822</b> use these configurations to control packets for individual flow-specific slices <b>662</b>. Here, received packets (e.g., ingress traffic <b>851</b>) may enter an ingress gateway (not shown by <figref idref="DRAWINGS">FIG. <b>8</b></figref>), and then be passed to a proxy <b>822</b> that is a sidecar of a service <b>82</b> corresponding to a flow-specific slice <b>662</b>. As packets (e.g., ingress traffic <b>851</b>) flow through the proxy <b>822</b>, the proxy <b>822</b> will compare data included in the packets (e.g., NOP ID <b>421</b> and/or slice ID <b>422</b>) with the configured traffic routing rules and/or destination rules for the flow-specific slice <b>662</b>. When the data included in the packets matches the traffic routing rules and/or destination rules, the packets are provided to the service <b>821</b>. The service <b>821</b> processes the data, and the data/packets can be routed through the mesh <b>801</b> (e.g., as mesh traffic <b>852</b>) and/or exits the mesh <b>801</b> (e.g., egress traffic <b>853</b>) through an egress gateway (not shown by <figref idref="DRAWINGS">FIG. <b>8</b></figref>).</p><p id="p-0135" num="0118">1.3. Example Use Case</p><p id="p-0136" num="0119">As alluded to previously, with the current network slicing paradigms, such as the 3GPP 5G network slicing (see e.g., [TS23501] and [TS38300]), a network slice can be provisioned that has a specified QoS treatment (e.g., specified or configured QoS parameters and QoS characteristics). However, these network slices are logical or virtual versions of an entire 5G system including a 5G access network (5G-AN) and 5G Core Network (5GC). However, these network slices may still be too broad for certain applications, services, and/or use cases. For example, some services, applications, and/or use cases may not need to use some 5GC NFs and/or RAN NFs, which would automatically be provisioned in conventional network slices. In another example, some services, applications, and/or use cases may only need to be active for a certain period of time, or for certain time intervals, and therefore, resources allocated to a conventional network slice for those periods/intervals may not be used and are not allocated for other purposes. The present disclosure provides mechanisms for provisioning or otherwise providing flow-specific slices <b>662</b>, which are more granular than the network slices provided by existing network slicing paradigms.</p><p id="p-0137" num="0120">An example use case for utilizing the flow-specific slices involves control systems, such as those that utilize programmable logic controllers (PLCs) to monitor aspects of one or more amusement rides in an amusement park (or theme park). Examples of such amusement rides include roller coasters, vertical rides (e.g., Ferris wheels), pendulum rides, among many others. The amusement rides include various components such as gondolas or cars that carry passengers (where two or more cars hooked together are referred to as a &#x201c;train&#x201d;) and ride-dependent components. For example, roller coasters include ride-dependent components such as railroad tracks, launch equipment/systems (e.g., electromagnet, hydraulic, pneumatic, flywheel-based, catapults, and/or friction wheels), chain lifts, braking systems (e.g., block brakes, trim brakes, and the like), mechanical and/or hydraulic car safety systems, and embedded computer system(s). The computer system(s) ensure that there is adequate space between individual cars and/or individual trains to avoid potential accidents, and also control mechanical equipment, especially components of the launch system. In some cases, some amusement rides can incorporate virtual reality (VR) and/or augmented reality (AR) applications into the rides wherein riders/passengers wear VR/AR headsets that consume and display VR/AR images, video, animations, holograms, and the like during the ride.</p><p id="p-0138" num="0121">In this example use case, various PLCs are disposed on or in individual cars and/or on different parts of amusement rides (e.g., along roller coaster tracks, at the arms and/or axels of a pendulum ride, and so forth). In some examples, some or all PLCs are connected to the embedded computer system(s) and/or an electronic system(s) disposed on or in individual amusement ride components. In these examples, a PLC is able to access hardware/system state information, and/or other data generated by the computer and/or the electronic system. Additionally, the PLCs collect data on the amusement ride components to which they are attached/connected, generate status information (e.g., alerts, and/or other data) based on the collected data, and communicate the status information to a centralized control center (also referred to as an &#x201c;operations center&#x201d;) at the amusement park. The control center includes various compute nodes that monitor the status information received from individual PLCs, and can control the operation of individual amusement rides and/or perform other suitable functions based on the status information. Individuals in the control center monitor the amusement rides based on the status information to ensure that the amusement rides are operating properly and to identify potential failures in the amusement rides.</p><p id="p-0139" num="0122">The compute nodes in the control center operate various applications that evaluate the operational health and/or system diagnostics of the component/parts of amusement rides, and the amusement rides as a whole, to ensure that the amusement rides are safe or otherwise operating as intended. The control center applications and applications/logic operated by individual PLCs are developed in such a way that they generate data/traffic in a known traffic pattern, which could be specific to a particular amusement ride and/or based on other conditions or characteristics of the amusement rides, PLCs, and/or control center compute nodes. The traffic pattern and/or the communication interfaces between the PLCs and the control center may be based on the Common Industrial Protocol (CIP&#x2122;) or the like.</p><p id="p-0140" num="0123">For example, the traffic pattern may involve each PLC generating and transmitting a safety packet to the control center every 30 ms. Additionally, the safety packets may be assigned a highest QoS class, traffic class, or priority in comparison to packets having other QoS classes, traffic classes, and/or priorities. Furthermore, the safety packets may traverse multiple intermediate nodes and/or take different paths from individual PLCs to the control center.</p><p id="p-0141" num="0124">Here, the safety packets generated and transmitted by one or more PLCs may be assigned to a safety data flow that is mapped to a particular flow-specific slice <b>662</b>, and the control center applications that evaluate the operational health and/or system diagnostics of the component/parts of amusement rides may be associated with a safety monitoring service <b>236</b><i>c</i>, <b>736</b><i>c</i>. Additionally, the amusement park owner/operator may be a network slice customer/subscriber to a 3GPP 5G NOP and an edge computing service provider or CSP, and the 3GPP 5G NOP may provision a network slice <b>622</b> to the amusement park owner/operator for use by the control center and PLCs. In this example, the amusement park owner/operator may configure or otherwise specify that the safety flow-specific slice <b>662</b> should be active at 30 ms intervals such that the safety packets can be communicated throughout the amusement park with little or no interference from other packets associated with other services <b>236</b><i>c</i>, <b>736</b><i>c</i>. Additionally or alternatively, the amusement park owner/operator may configure or otherwise specify that other packets (e.g., non-safety packets) may be communicated throughout the amusement packet outside of the 30 ms safety intervals with higher latencies (e.g., 210 ms or the like). For example, the flow-specific slice <b>662</b> may specify a 30 ms latency requirement for safety packets at 30 ms time intervals, and may prioritize VR and/or AR packets outside of the 30 ms time intervals.</p><heading id="h-0006" level="1">2. Edge Computing System Configurations and Arrangements</heading><p id="p-0142" num="0125">Edge computing refers to the implementation, coordination, and use of computing and resources at locations closer to the &#x201c;edge&#x201d; or collection of &#x201c;edges&#x201d; of a network. Deploying computing resources at the network's edge may reduce application and network latency, reduce network backhaul traffic and associated energy consumption, improve service capabilities, improve compliance with security or data privacy requirements (especially as compared to conventional cloud computing), and improve total cost of ownership.</p><p id="p-0143" num="0126">Individual compute platforms or other components that can perform edge computing operations (referred to as &#x201c;edge compute nodes,&#x201d; &#x201c;edge nodes,&#x201d; or the like) can reside in whatever location needed by the system architecture or ad hoc service. In many edge computing architectures, edge nodes are deployed at NANs, gateways, network routers, and/or other devices that are closer to endpoint devices (e.g., UEs, IoT devices, etc.) producing and consuming data. As examples, edge nodes may be implemented in a high performance compute data center or cloud installation; a designated edge node server, an enterprise server, a roadside server, a telecom central office; or a local or peer at-the-edge device being served consuming edge services.</p><p id="p-0144" num="0127">Edge compute nodes may partition resources (e.g., memory, CPU, GPU, interrupt controller, I/O controller, memory controller, bus controller, network connections or sessions, etc.) where respective partitionings may contain security and/or integrity protection capabilities. Edge nodes may also provide orchestration of multiple applications through isolated user-space instances such as containers, partitions, virtual environments (VEs), virtual machines (VMs), Function-as-a-Service (FaaS) engines, Servlets, servers, and/or other like computation abstractions. Containers are contained, deployable units of software that provide code and needed dependencies. Various edge system arrangements/architecture treats VMs, containers, and functions equally in terms of application composition. The edge nodes are coordinated based on edge provisioning functions, while the operation of the various applications are coordinated with orchestration functions (e.g., VM or container engine, etc.). The orchestration functions may be used to deploy the isolated user-space instances, identifying and scheduling use of specific HW, security related functions (e.g., key management, trust anchor management, etc.), and other tasks related to the provisioning and lifecycle of isolated user spaces.</p><p id="p-0145" num="0128">Applications that have been adapted for edge computing include but are not limited to virtualization of traditional network functions including include, for example, Software-Defined Networking (SDN), NFV, distributed RAN units and/or RAN clouds, and the like. Additional example use cases for edge computing include computational offloading, Content Data Network (CDN) services (e.g., video on demand, content streaming, security surveillance, alarm system monitoring, building access, data/content caching, etc.), gaming services (e.g., AR/VR, etc.), accelerated browsing, IoT and industry applications (e.g., factory automation), media analytics, live streaming/transcoding, and V2X applications (e.g., driving assistance and/or autonomous driving applications).</p><p id="p-0146" num="0129">The present disclosure provides specific examples relevant to various edge computing configurations provided within and various access/network implementations. Any suitable standards and network implementations are applicable to the edge computing concepts discussed herein. For example, many edge computing/networking technologies may be applicable to the present disclosure in various combinations and layouts of devices located at the edge of a network. Examples of such edge computing/networking technologies include [MEC]; [O-RAN]; [ISEO]; [SA6Edge]; Content Delivery Networks (CDNs) (also referred to as &#x201c;Content Distribution Networks&#x201d; or the like); Mobility Service Provider (MSP) edge computing and/or Mobility as a Service (MaaS) provider systems (e.g., used in AECC architectures); Nebula edge-cloud systems; Fog computing systems; Cloudlet edge-cloud systems; Mobile Cloud Computing (MCC) systems; Central Office Re-architected as a Datacenter (CORD), mobile CORD (M-CORD) and/or Converged Multi-Access and Core (COMAC) systems; and/or the like. Further, the techniques disclosed herein may relate to other IoT edge network systems and configurations, and other intermediate processing entities and architectures may also be used for purposes of the present disclosure.</p><p id="p-0147" num="0130"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an example edge computing environment <b>900</b> including different layers of communication, starting from an endpoint layer <b>910</b><i>a </i>(also referred to as &#x201c;sensor layer <b>910</b><i>a</i>&#x201d;, &#x201c;things layer <b>910</b><i>a</i>&#x201d;, or the like) including one or more IoT devices <b>911</b> (also referred to as &#x201c;endpoints <b>910</b><i>a</i>&#x201d; or the like) (e.g., in an Internet of Things (IoT) network, wireless sensor network (WSN), fog, and/or mesh network topology); increasing in sophistication to intermediate layer <b>910</b><i>b </i>(also referred to as &#x201c;client layer <b>910</b><i>b</i>&#x201d;, &#x201c;gateway layer <b>910</b><i>b</i>&#x201d;, or the like) including various user equipment (UEs) <b>912</b><i>a</i>, <b>912</b><i>b</i>, and <b>912</b><i>c </i>(also referred to as &#x201c;intermediate nodes <b>910</b><i>b</i>&#x201d; or the like), which may facilitate the collection and processing of data from endpoints <b>910</b><i>a</i>; increasing in processing and connectivity sophistication to access layer <b>930</b> including a set of network access nodes (NANs) <b>931</b>, <b>932</b>, and <b>933</b> (collectively referred to as &#x201c;NANs <b>930</b>&#x201d; or the like); increasing in processing and connectivity sophistication to edge layer <b>937</b> including a set of edge compute nodes <b>936</b><i>a</i>-<i>c </i>(collectively referred to as &#x201c;edge compute nodes <b>936</b>&#x201d; or the like) within an edge computing framework <b>935</b> (also referred to as &#x201c;ECT <b>935</b>&#x201d; or the like); and increasing in connectivity and processing sophistication to a backend layer <b>940</b> including core network (CN) <b>942</b>, cloud <b>944</b>, and server(s) <b>950</b>. The processing at the backend layer <b>940</b> may be enhanced by network services as performed by one or more remote servers <b>950</b>, which may be, or include, one or more CN functions, cloud compute nodes or clusters, application (app) servers, and/or other like systems and/or devices. Some or all of these elements may be equipped with or otherwise implement some or all features and/or functionality discussed herein.</p><p id="p-0148" num="0131">The environment <b>900</b> is shown to include end-user devices such as intermediate nodes <b>910</b><i>b </i>and endpoint nodes <b>910</b><i>a </i>(collectively referred to as &#x201c;nodes <b>910</b>&#x201d;, &#x201c;UEs <b>910</b>&#x201d;, or the like), which are configured to connect to (or communicatively couple with) one or more communication networks (also referred to as &#x201c;access networks,&#x201d; &#x201c;radio access networks,&#x201d; or the like) based on different access technologies (or &#x201c;radio access technologies&#x201d;) for accessing application, edge, and/or cloud services. These access networks may include one or more NANs <b>930</b>, which are arranged to provide network connectivity to the UEs <b>910</b> via respective links <b>903</b><i>a </i>and/or <b>903</b><i>b </i>(collectively referred to as &#x201c;channels <b>903</b>&#x201d;, &#x201c;links <b>903</b>&#x201d;, &#x201c;connections <b>903</b>&#x201d;, and/or the like) between individual NANs <b>930</b> and respective UEs <b>910</b>.</p><p id="p-0149" num="0132">As examples, the communication networks and/or access technologies may include cellular technology such as LTE, MuLTEfire, and/or NR/5G (e.g., as provided by Radio Access Network (RAN) node <b>931</b> and/or RAN nodes <b>932</b>), WiFi or wireless local area network (WLAN) technologies (e.g., as provided by access point (AP) <b>933</b> and/or RAN nodes <b>932</b>), and/or the like. Different technologies exhibit benefits and limitations in different scenarios, and application performance in different scenarios becomes dependent on the choice of the access networks (e.g., WiFi, LTE, etc.) and the used network and transport protocols (e.g., Transfer Control Protocol (TCP), Virtual Private Network (VPN), Multi-Path TCP (MPTCP), Generic Routing Encapsulation (GRE), etc.).</p><p id="p-0150" num="0133">The intermediate nodes <b>910</b><i>b </i>include UE <b>912</b><i>a</i>, UE <b>912</b><i>b</i>, and UE <b>912</b><i>c </i>(collectively referred to as &#x201c;UE <b>912</b>&#x201d; or &#x201c;UEs <b>912</b>&#x201d;). In this example, the UE <b>912</b><i>a </i>is illustrated as a vehicle system (also referred to as a vehicle UE or vehicle station), UE <b>912</b><i>b </i>is illustrated as a smartphone (e.g., handheld touchscreen mobile computing device connectable to one or more cellular networks), and UE <b>912</b><i>c </i>is illustrated as a flying drone or unmanned aerial vehicle (UAV). However, the UEs <b>912</b> may be any mobile or non-mobile computing device, such as desktop computers, workstations, laptop computers, tablets, wearable devices, PDAs, pagers, wireless handsets smart appliances, single-board computers (SBCs) (e.g., Raspberry Pi, Arduino, Intel Edison, etc.), plug computers, and/or any type of computing device such as any of those discussed herein.</p><p id="p-0151" num="0134">The endpoints <b>910</b> include UEs <b>911</b>, which may be IoT devices (also referred to as &#x201c;IoT devices <b>911</b>&#x201d;), which are uniquely identifiable embedded computing devices (e.g., within the Internet infrastructure) that comprise a network access layer designed for low-power IoT applications utilizing short-lived UE connections. The IoT devices <b>911</b> are any physical or virtualized, devices, sensors, or &#x201c;things&#x201d; that are embedded with HW and/or SW components that enable the objects, devices, sensors, or &#x201c;things&#x201d; capable of capturing and/or recording data associated with an event, and capable of communicating such data with one or more other devices over a network with little or no user intervention. As examples, IoT devices <b>911</b> may be abiotic devices such as autonomous sensors, gauges, meters, image capture devices, microphones, light emitting devices, audio emitting devices, audio and/or video playback devices, electro-mechanical devices (e.g., switch, actuator, etc.), EEMS, ECUs, ECMs, embedded systems, microcontrollers, control modules, networked or &#x201c;smart&#x201d; appliances, MTC devices, M2M devices, and/or the like. The IoT devices <b>911</b> can utilize technologies such as M2M or MTC for exchanging data with an MTC server (e.g., a server <b>950</b>), an edge server <b>936</b> and/or ECT <b>935</b>, or device via a PLMN, ProSe or D2D communication, sensor networks, or IoT networks. The M2M or MTC exchange of data may be a machine-initiated exchange of data.</p><p id="p-0152" num="0135">The IoT devices <b>911</b> may execute background applications (e.g., keep-alive messages, status updates, etc.) to facilitate the connections of the IoT network. Where the IoT devices <b>911</b> are, or are embedded in, sensor devices, the IoT network may be a WSN. An IoT network describes an interconnecting IoT UEs, such as the IoT devices <b>911</b> being connected to one another over respective direct links <b>905</b>. The IoT devices may include any number of different types of devices, grouped in various combinations (referred to as an &#x201c;IoT group&#x201d;) that may include IoT devices that provide one or more services for a particular user, customer, organizations, etc. A service provider (e.g., an owner/operator of server(s) <b>950</b>, CN <b>942</b>, and/or cloud <b>944</b>) may deploy the IoT devices in the IoT group to a particular area (e.g., a geolocation, building, etc.) in order to provide the one or more services. In some implementations, the IoT network may be a mesh network of IoT devices <b>911</b>, which may be termed a fog device, fog system, or fog, operating at the edge of the cloud <b>944</b>. The fog involves mechanisms for bringing cloud computing functionality closer to data generators and consumers wherein various network devices run cloud application logic on their native architecture. Fog computing is a system-level horizontal architecture that distributes resources and services of computing, storage, control, and networking anywhere along the continuum from cloud <b>944</b> to Things (e.g., IoT devices <b>911</b>). The fog may be established in accordance with specifications released by the OFC, the OCF, among others. Additionally or alternatively, the fog may be a tangle as defined by the IOTA foundation.</p><p id="p-0153" num="0136">The fog may be used to perform low-latency computation/aggregation on the data while routing it to an edge cloud computing service (e.g., edge nodes <b>930</b>) and/or a central cloud computing service (e.g., cloud <b>944</b>) for performing heavy computations or computationally burdensome tasks. On the other hand, edge cloud computing consolidates human-operated, voluntary resources, as a cloud. These voluntary resource may include, inter-alia, intermediate nodes <b>920</b> and/or endpoints <b>910</b>, desktop PCs, tablets, smartphones, nano data centers, and the like. In various implementations, resources in the edge cloud may be in one to two-hop proximity to the IoT devices <b>911</b>, which may result in reducing overhead related to processing data and may reduce network delay.</p><p id="p-0154" num="0137">Additionally or alternatively, the fog may be a consolidation of IoT devices <b>911</b> and/or networking devices, such as routers and switches, with high computing capabilities and the ability to run cloud application logic on their native architecture. Fog resources may be manufactured, managed, and deployed by cloud vendors, and may be interconnected with high speed, reliable links. Moreover, fog resources reside farther from the edge of the network when compared to edge systems but closer than a central cloud infrastructure. Fog devices are used to effectively handle computationally intensive tasks or workloads offloaded by edge resources.</p><p id="p-0155" num="0138">Additionally or alternatively, the fog may operate at the edge of the cloud <b>944</b>. The fog operating at the edge of the cloud <b>944</b> may overlap or be subsumed into an edge network <b>930</b> of the cloud <b>944</b>. The edge network of the cloud <b>944</b> may overlap with the fog, or become a part of the fog. Furthermore, the fog may be an edge-fog network that includes an edge layer and a fog layer. The edge layer of the edge-fog network includes a collection of loosely coupled, voluntary and human-operated resources (e.g., the aforementioned edge compute nodes <b>936</b> or edge devices). The Fog layer resides on top of the edge layer and is a consolidation of networking devices such as the intermediate nodes <b>920</b> and/or endpoints <b>910</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0156" num="0139">Data may be captured, stored/recorded, and communicated among the IoT devices <b>911</b> or, for example, among the intermediate nodes <b>920</b> and/or endpoints <b>910</b> that have direct links <b>905</b> with one another as shown by <figref idref="DRAWINGS">FIG. <b>9</b></figref>. Analysis of the traffic flow and control schemes may be implemented by aggregators that are in communication with the IoT devices <b>911</b> and each other through a mesh network. The aggregators may be a type of IoT device <b>911</b> and/or network appliance. In the example of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the aggregators may be edge nodes <b>930</b>, or one or more designated intermediate nodes <b>920</b> and/or endpoints <b>910</b>. Data may be uploaded to the cloud <b>944</b> via the aggregator, and commands can be received from the cloud <b>944</b> through gateway devices that are in communication with the IoT devices <b>911</b> and the aggregators through the mesh network. Unlike the traditional cloud computing model, in some implementations, the cloud <b>944</b> may have little or no computational capabilities and only serves as a repository for archiving data recorded and processed by the fog. In these implementations, the cloud <b>944</b> centralized data storage system and provides reliability and access to data by the computing resources in the fog and/or edge devices. Being at the core of the architecture, the Data Store of the cloud <b>944</b> is accessible by both Edge and Fog layers of the aforementioned edge-fog network.</p><p id="p-0157" num="0140">As mentioned previously, the access networks provide network connectivity to the end-user devices <b>920</b>, <b>910</b> via respective NANs <b>930</b>. The access networks may be Radio Access Networks (RANs) such as an NG RAN or a 5G RAN for a RAN that operates in a 5G/NR cellular network, an E-UTRAN for a RAN that operates in an LTE or 4G cellular network, or a legacy RAN such as a UTRAN or GERAN for GSM or CDMA cellular networks. The access network or RAN may be referred to as an Access Service Network for WiMAX implementations. Additionally or alternatively, all or parts of the RAN may be implemented as one or more software entities running on server computers as part of a virtual network, which may be referred to as a cloud RAN (CRAN), Cognitive Radio (CR), a virtual baseband unit pool (vBBUP), and/or the like. Additionally or alternatively, the CRAN, CR, or vBBUP may implement a RANF split, wherein one or more communication protocol layers are operated by the CRAN/CR/vBBUP and other communication protocol entities are operated by individual RAN nodes <b>931</b>, <b>932</b>. This virtualized framework allows the freed-up processor cores of the NANs <b>931</b>, <b>932</b> to perform other virtualized applications, such as virtualized applications for various elements discussed herein. Furthermore, the NANs <b>930</b> may each be, or may include one or more RANFs such as those discussed herein.</p><p id="p-0158" num="0141">The UEs <b>910</b> may utilize respective connections (or channels) <b>903</b><i>a</i>, each of which comprises a physical communications interface or layer. The connections <b>903</b><i>a </i>are illustrated as an air interface to enable communicative coupling consistent with cellular communications protocols, such as 3GPP LTE, 5G/NR, Push-to-Talk (PTT) and/or PTT over cellular (POC), UMTS, GSM, CDMA, and/or any of the other communications protocols discussed herein. Additionally or alternatively, the UEs <b>910</b> and the NANs <b>930</b> communicate data (e.g., transmit and receive) data over a licensed medium (also referred to as the &#x201c;licensed spectrum&#x201d; and/or the &#x201c;licensed band&#x201d;) and an unlicensed shared medium (also referred to as the &#x201c;unlicensed spectrum&#x201d; and/or the &#x201c;unlicensed band&#x201d;). To operate in the unlicensed spectrum, the UEs <b>910</b> and NANs <b>930</b> may operate using LAA, enhanced LAA (eLAA), and/or further eLAA (feLAA) mechanisms. The UEs <b>910</b> may further directly exchange communication data via respective direct links <b>905</b>, which may be LTE/NR Proximity Services (ProSe) link or PC5 interfaces/links, or WiFi based links or a personal area network (PAN) based links (e.g., [IEEE802154] based protocols including ZigBee, IPv6 over Low power Wireless Personal Area Networks (6LoWPAN), WirelessHART, MiWi, Thread, etc.; WiFi-direct; Bluetooth/Bluetooth Low Energy (BLE) protocols).</p><p id="p-0159" num="0142">Additionally or alternatively, individual UEs <b>910</b> provide radio information to one or more NANs <b>930</b> and/or one or more edge compute nodes <b>936</b> (e.g., edge servers/hosts, etc.). The radio information may be in the form of one or more measurement reports, and/or may include, for example, signal strength measurements, signal quality measurements, and/or the like. Each measurement report is tagged with a timestamp and the location of the measurement (e.g., the UEs <b>910</b> current location). As examples, the measurements collected by the UEs <b>910</b> and/or included in the measurement reports may include one or more of the following: bandwidth (BW), network or cell load, latency, jitter, round trip time (RTT), number of interrupts, out-of-order delivery of data packets, transmission power, bit error rate, bit error ratio (BER), Block Error Rate (BLER), packet error ratio (PER), packet loss rate, packet reception rate (PRR), data rate, peak data rate, end-to-end (e2e) delay, signal-to-noise ratio (SNR), signal-to-noise and interference ratio (SINR), signal-plus-noise-plus-distortion to noise-plus-distortion (SINAD) ratio, carrier-to-interference plus noise ratio (CINR), Additive White Gaussian Noise (AWGN), energy per bit to noise power density ratio (Eb/NO), energy per chip to interference power density ratio (Ec/IOT), energy per chip to noise power density ratio (Ec/NO), peak-to-average power ratio (PAPR), reference signal received power (RSRP), reference signal received quality (RSRQ), received signal strength indicator (RSSI), received channel power indicator (RCPI), received signal to noise indicator (RSNI), Received Signal Code Power (RSCP), average noise plus interference (ANPI), GNSS timing of cell frames for UE positioning for E-UTRAN or 5G/NR (e.g., a timing between an AP or RAN node reference time and a GNSS-specific reference time for a given GNSS), GNSS code measurements (e.g., the GNSS code phase (integer and fractional parts) of the spreading code of the ith GNSS satellite signal), GNSS carrier phase measurements (e.g., the number of carrier-phase cycles (integer and fractional parts) of the ith GNSS satellite signal, measured since locking onto the signal; also called Accumulated Delta Range (ADR)), channel interference measurements, thermal noise power measurements, received interference power measurements, power histogram measurements, channel load measurements, STA statistics, and/or other like measurements. The RSRP, RSSI, and/or RSRQ measurements may include RSRP, RSSI, and/or RSRQ measurements of cell-specific reference signals, channel state information reference signals (CSI-RS), and/or synchronization signals (SS) or SS blocks for 3GPP networks (e.g., LTE or 5G/NR), and RSRP, RSSI, RSRQ, RCPI, RSNI, and/or ANPI measurements of various beacon, Fast Initial Link Setup (FILS) discovery frames, or probe response frames for WLAN/WiFi (e.g., [IEEE80211]) networks. Other measurements may be additionally or alternatively used, such as those discussed in 3GPP TS 36.214 v17.0.0 (2022 Mar. 31) (&#x201c;[TS36214]&#x201d;), 3GPP TS 38.215 v17.1.0 (2022 Apr. 1) (&#x201c;[TS38215]&#x201d;), 3GPP TS 38.314 v17.1.0 (2022 Jul. 17) (&#x201c;[TS38314]&#x201d;), [IEEE80211], and/or the like. Additionally or alternatively, any of the aforementioned measurements (or combination of measurements) may be collected by one or more NANs <b>930</b> and provided to the edge compute node(s) <b>936</b>.</p><p id="p-0160" num="0143">Additionally or alternatively, the measurements can include one or more of the following measurements: measurements related to Data Radio Bearer (DRB) (e.g., number of DRBs attempted to setup, number of DRBs successfully setup, number of released active DRBs, in-session activity time for DRB, number of DRBs attempted to be resumed, number of DRBs successfully resumed, etc.); measurements related to Radio Resource Control (RRC) (e.g., mean number of RRC connections, maximum number of RRC connections, mean number of stored inactive RRC connections, maximum number of stored inactive RRC connections, number of attempted, successful, and/or failed RRC connection establishments, etc.); measurements related to UE Context (UECNTX); measurements related to Radio Resource Utilization (RRU) (e.g., DL total PRB usage, UL total PRB usage, distribution of DL total PRB usage, distribution of UL total PRB usage, DL PRB used for data traffic, UL PRB used for data traffic, DL total available PRBs, UL total available PRBs, etc.); measurements related to Registration Management (RM); measurements related to Session Management (SM) (e.g., number of PDU sessions requested to setup; number of PDU sessions successfully setup; number of PDU sessions failed to setup, etc.); measurements related to GTP Management (GTP); measurements related to IP Management (IP); measurements related to Policy Association (PA); measurements related to Mobility Management (MM) (e.g., for inter-RAT, intra-RAT, and/or Intra/Inter-frequency handovers and/or conditional handovers: number of requested, successful, and/or failed handover preparations; number of requested, successful, and/or failed handover resource allocations; number of requested, successful, and/or failed handover executions; mean and/or maximum time of requested handover executions; number of successful and/or failed handover executions per beam pair, etc.); measurements related to Virtualized Resource(s) (VR); measurements related to Carrier (CARR); measurements related to QoS Flows (QF) (e.g., number of released active QoS flows, number of QoS flows attempted to release, in-session activity time for QoS flow, in-session activity time for a UE <b>910</b>, number of QoS flows attempted to setup, number of QoS flows successfully established, number of QoS flows failed to setup, number of initial QoS flows attempted to setup, number of initial QoS flows successfully established, number of initial QoS flows failed to setup, number of QoS flows attempted to modify, number of QoS flows successfully modified, number of QoS flows failed to modify, etc.); measurements related to Application Triggering (AT); measurements related to Short Message Service (SMS); measurements related to Power, Energy and Environment (PEE); measurements related to network service(s) and/or NF service (NFS); measurements related to Packet Flow Description (PFD); measurements related to Random Access Channel (RACH); measurements related to Measurement Report (MR); measurements related to Layer 1 Measurement (L1M); measurements related to Network Slice Selection (NSS); measurements related to Paging (PAG); measurements related to Non-IP Data Delivery (NIDD); measurements related to external parameter provisioning (EPP); measurements related to traffic influence (TI); measurements related to Connection Establishment (CE); measurements related to Service Parameter Provisioning (SPP); measurements related to Background Data Transfer Policy (BDTP); measurements related to Data Management (DM); and/or any other performance measurements such as those discussed in 3GPP TS 28.552 v17.7.1 (2022 Jun. 17) (&#x201c;[TS28552]&#x201d;), 3GPP TS 32.425 v17.1.0 (2021 Jun. 24) (&#x201c;[TS32425]&#x201d;), the contents of each of which are hereby incorporated by reference in their entireties.</p><p id="p-0161" num="0144">The radio information may be reported in response to a trigger event and/or on a periodic basis. Additionally or alternatively, individual UEs <b>910</b> report radio information either at a low periodicity or a high periodicity depending on a data transfer that is to take place, and/or other information about the data transfer. Additionally or alternatively, the edge compute node(s) <b>936</b> may request the measurements from the NANs <b>930</b> at low or high periodicity, or the NANs <b>930</b> may provide the measurements to the edge compute node(s) <b>936</b> at low or high periodicity. Additionally or alternatively, the edge compute node(s) <b>936</b> may obtain other relevant data from other edge compute node(s) <b>936</b>, core network functions (NFs), application functions (AFs), and/or other UEs <b>910</b> such as Key Performance Indicators (KPIs), with the measurement reports or separately from the measurement reports.</p><p id="p-0162" num="0145">Additionally or alternatively, in cases where is discrepancy in the observation data from one or more UEs, one or more RAN nodes, and/or core network NFs (e.g., missing reports, erroneous data, etc.) simple imputations may be performed to supplement the obtained observation data such as, for example, substituting values from previous reports and/or historical data, apply an extrapolation filter, and/or the like. Additionally or alternatively, acceptable bounds for the observation data may be predetermined or configured. For example, CQI and MCS measurements may be configured to only be within ranges defined by suitable 3GPP standards. In cases where a reported data value does not make sense (e.g., the value exceeds an acceptable range/bounds, or the like), such values may be dropped for the current learning/training episode or epoch. For example, on packet delivery delay bounds may be defined or configured, and packets determined to have been received after the packet delivery delay bound may be dropped.</p><p id="p-0163" num="0146">In any of the embodiments discussed herein, any suitable data collection and/or measurement mechanism(s) may be used to collect the observation data. For example, data marking (e.g., sequence numbering, etc.), packet tracing, signal measurement, data sampling, and/or timestamping techniques may be used to determine any of the aforementioned metrics/observations. The collection of data may be based on occurrence of events that trigger collection of the data. Additionally or alternatively, data collection may take place at the initiation or termination of an event. The data collection can be continuous, discontinuous, and/or have start and stop times. The data collection techniques/mechanisms may be specific to a HW configuration/implementation or non-HW-specific, or may be based on various software parameters (e.g., OS type and version, etc.). Various configurations may be used to define any of the aforementioned data collection parameters. Such configurations may be defined by suitable specifications/standards, such as 3GPP (e.g., [SA6Edge]), ETSI (e.g., [MEC]), O-RAN (e.g., [0-RAN]), Intel&#xae; Smart Edge Open (formerly OpenNESS) (e.g., [ISEO]), IETF (e.g., [MAMS]), IEEE/WiFi (e.g., [IEEE80211], [WiMAX], [IEEE16090], etc.), and/or any other like standards such as those discussed herein.</p><p id="p-0164" num="0147">The UE <b>912</b><i>b </i>is shown as being capable of accessing access point (AP) <b>933</b> via a connection <b>903</b><i>b</i>. In this example, the AP <b>933</b> is shown to be connected to the Internet without connecting to the CN <b>942</b> of the wireless system. The connection <b>903</b><i>b </i>can comprise a local wireless connection, such as a connection consistent with any [IEEE802] protocol (e.g., [IEEE80211] and variants thereof), wherein the AP <b>933</b> would comprise a WiFi router. Additionally or alternatively, the UEs <b>910</b> can be configured to communicate using suitable communication signals with each other or with any of the AP <b>933</b> over a single or multicarrier communication channel in accordance with various communication techniques, such as, but not limited to, an OFDM communication technique, a single-carrier frequency division multiple access (SC-FDMA) communication technique, and/or the like, although the scope of the present disclosure is not limited in this respect. The communication technique may include a suitable modulation scheme such as Complementary Code Keying (CCK); Phase-Shift Keying (PSK) such as Binary PSK (BPSK), Quadrature PSK (QPSK), Differential PSK (DPSK), etc.; or Quadrature Amplitude Modulation (QAM) such as M-QAM; and/or the like.</p><p id="p-0165" num="0148">The one or more NANs <b>931</b> and <b>932</b> that enable the connections <b>903</b><i>a </i>may be referred to as &#x201c;RAN nodes&#x201d; or the like. The RAN nodes <b>931</b>, <b>932</b> may comprise ground stations (e.g., terrestrial access points) or satellite stations providing coverage within a geographic area (e.g., a cell). The RAN nodes <b>931</b>, <b>932</b> may be implemented as one or more of a dedicated physical device such as a macrocell base station, and/or a low power base station for providing femtocells, picocells or other like cells having smaller coverage areas, smaller user capacity, or higher bandwidth compared to macrocells. In this example, the RAN node <b>931</b> is embodied as a NodeB, evolved NodeB (eNB), or a next generation NodeB (gNB), and the RAN nodes <b>932</b> are embodied as relay nodes, distributed units, or Road Side Unites (RSUs). Any other type of NANs can be used.</p><p id="p-0166" num="0149">Any of the RAN nodes <b>931</b>, <b>932</b> can terminate the air interface protocol and can be the first point of contact for the UEs <b>912</b> and IoT devices <b>911</b>. Additionally or alternatively, any of the RAN nodes <b>931</b>, <b>932</b> can fulfill various logical functions for the RAN including, but not limited to, RANF(s) (e.g., radio network controller (RNC) functions and/or NG-RANFs) for radio resource management, admission control, UL and DL dynamic resource allocation, radio bearer management, data packet scheduling, etc. Additionally or alternatively, the UEs <b>910</b> can be configured to communicate using OFDM communication signals with each other or with any of the NANs <b>931</b>, <b>932</b> over a multicarrier communication channel in accordance with various communication techniques, such as, but not limited to, an OFDMA communication technique (e.g., for DL communications) and/or an SC-FDMA communication technique (e.g., for UL and ProSe or sidelink communications), although the scope of the present disclosure is not limited in this respect.</p><p id="p-0167" num="0150">For most cellular communication systems, the RANF(s) operated by the RAN or individual NANs <b>931</b>-<b>932</b> organize DL transmissions (e.g., from any of the RAN nodes <b>931</b>, <b>932</b> to the UEs <b>910</b>) and UL transmissions (e.g., from the UEs <b>910</b> to RAN nodes <b>931</b>, <b>932</b>) into radio frames (or simply &#x201c;frames&#x201d;) with 10 millisecond (ms) durations, where each frame includes ten 1 ms subframes. Each transmission direction has its own resource grid that indicate physical resource in each slot, where each column and each row of a resource grid corresponds to one symbol and one subcarrier, respectively. The duration of the resource grid in the time domain corresponds to one slot in a radio frame. The resource grids comprises a number of resource blocks (RBs), which describe the mapping of certain physical channels to resource elements (REs). Each RB may be a physical RB (PRB) or a virtual RB (VRB) and comprises a collection of REs. An RE is the smallest time-frequency unit in a resource grid. The RNC function(s) dynamically allocate resources (e.g., PRBs and modulation and coding schemes (MCS)) to each UE <b>910</b> at each transmission time interval (TTI). A TTI is the duration of a transmission on a radio link <b>903</b><i>a</i>, <b>905</b>, and is related to the size of the data blocks passed to the radio link layer from higher network layers.</p><p id="p-0168" num="0151">The NANs <b>931</b>, <b>932</b> may be configured to communicate with one another via respective interfaces or links (not shown), such as an X2 interface for LTE implementations (e.g., when CN <b>942</b> is an Evolved Packet Core (EPC)), an Xn interface for 5G or NR implementations (e.g., when CN <b>942</b> is an Fifth Generation Core (5GC)), or the like. The NANs <b>931</b> and <b>932</b> are also communicatively coupled to CN <b>942</b>. Additionally or alternatively, the CN <b>942</b> may be an evolved packet core (EPC) network, a NextGen Packet Core (NPC) network, a 5G core (5GC), or some other type of CN. The CN <b>942</b> is a network of network elements and/or network functions (NFs) relating to a part of a communications network that is independent of the connection technology used by a terminal or user device. The CN <b>942</b> comprises a plurality of network elements/NFs configured to offer various data and telecommunications services to customers/subscribers (e.g., users of UEs <b>912</b> and IoT devices <b>911</b>) who are connected to the CN <b>942</b> via a RAN. The components of the CN <b>942</b> may be implemented in one physical node or separate physical nodes including components to read and execute instructions from a machine-readable or computer-readable medium (e.g., a non-transitory machine-readable storage medium). Additionally or alternatively, NFV may be utilized to virtualize any or all of the above-described network node functions via executable instructions stored in one or more computer-readable storage mediums (described in further detail infra). A logical instantiation of the CN <b>942</b> may be referred to as a network slice, and a logical instantiation of a portion of the CN <b>942</b> may be referred to as a network sub-slice. NFV architectures and infrastructures may be used to virtualize one or more network functions, alternatively performed by proprietary hardware, onto physical resources comprising a combination of industry-standard server hardware, storage hardware, or switches. In other words, NFV systems can be used to execute virtual or reconfigurable implementations of one or more CN <b>942</b> components/functions.</p><p id="p-0169" num="0152">The CN <b>942</b> is shown to be communicatively coupled to an application server <b>950</b> and a network <b>950</b> via an IP communications interface <b>955</b>. the one or more server(s) <b>950</b> comprise one or more physical and/or virtualized systems for providing functionality (or services) to one or more clients (e.g., UEs <b>912</b> and IoT devices <b>911</b>) over a network. The server(s) <b>950</b> may include various computer devices with rack computing architecture component(s), tower computing architecture component(s), blade computing architecture component(s), and/or the like. The server(s) <b>950</b> may represent a cluster of servers, a server farm, a cloud computing service, or other grouping or pool of servers, which may be located in one or more datacenters. The server(s) <b>950</b> may also be connected to, or otherwise associated with one or more data storage devices (not shown). Moreover, the server(s) <b>950</b> may include an operating system (OS) that provides executable program instructions for the general administration and operation of the individual server computer devices, and may include a computer-readable medium storing instructions that, when executed by a processor of the servers, may allow the servers to perform their intended functions. Suitable implementations for the OS and general functionality of servers are known or commercially available, and are readily implemented by persons having ordinary skill in the art. Generally, the server(s) <b>950</b> offer applications or services that use IP/network resources. As examples, the server(s) <b>950</b> may provide traffic management services, cloud analytics, content streaming services, immersive gaming experiences, social networking and/or microblogging services, and/or other like services. In addition, the various services provided by the server(s) <b>950</b> may include initiating and controlling software and/or firmware updates for applications or individual components implemented by the UEs <b>912</b> and IoT devices <b>911</b>. The server(s) <b>950</b> can also be configured to support one or more communication services (e.g., Voice-over-Internet Protocol (VoIP) sessions, PTT sessions, group communication sessions, social networking services, etc.) for the UEs <b>912</b> and IoT devices <b>911</b> via the CN <b>942</b>.</p><p id="p-0170" num="0153">The Radio Access Technologies (RATs) employed by the NANs <b>930</b>, the UEs <b>910</b>, and the other elements in <figref idref="DRAWINGS">FIG. <b>9</b></figref> may include, for example, any of the communication protocols and/or RATs discussed herein. Different technologies exhibit benefits and limitations in different scenarios, and application performance in different scenarios becomes dependent on the choice of the access networks (e.g., WiFi, LTE, etc.) and the used network and transport protocols (e.g., Transfer Control Protocol (TCP), Virtual Private Network (VPN), Multi-Path TCP (MPTCP), Generic Routing Encapsulation (GRE), etc.). These RATs may include one or more V2X RATs, which allow these elements to communicate directly with one another, with infrastructure equipment (e.g., NANs <b>930</b>), and other devices. In some implementations, at least two distinct V2X RATs may be used including WLAN V2X (W-V2X) RAT based on IEEE V2X technologies (e.g., DSRC for the U.S. and ITS-G5 for Europe) and 3GPP C-V2X RAT (e.g., LTE, 5G/NR, and beyond). In one example, the C-V2X RAT may utilize a C-V2X air interface and the WLAN V2X RAT may utilize an W-V2X air interface.</p><p id="p-0171" num="0154">The W-V2X RATs include, for example, <i>IEEE Guide for Wireless Access in Vehicular Environments </i>(<i>WAVE</i>) <i>Architecture</i>, IEEE 1609.0-2019 (10 Apr. 2019) (&#x201c;[IEEE16090]&#x201d;), V2X <i>Communications Message Set Dictionary</i>, SAE I<smallcaps>NT'L </smallcaps>(23 Jul. 2020) (&#x201c;[J2735_202007]&#x201d;), Intelligent Transport Systems in the 5 GHz frequency band (ITS-G5), the [IEEE80211p] (which is the layer 1 (L1) and layer 2 (L2) part of WAVE, DSRC, and ITS-G5), and/or [WiMAX]. The term &#x201c;DSRC&#x201d; refers to vehicular communications in the 5.9 GHz frequency band that is generally used in the United States, while &#x201c;ITS-G5&#x201d; refers to vehicular communications in the 5.9 GHz frequency band in Europe. Since any number of different RATs are applicable (including [IEEE80211p] RATs) that may be used in any geographic or political region, the terms &#x201c;DSRC&#x201d; (used, among other regions, in the U.S.) and &#x201c;ITS-G5&#x201d; (used, among other regions, in Europe) may be used interchangeably throughout this disclosure. The access layer for the ITS-G5 interface is outlined in ETSI EN 302 663 V1.3.1 (2020 January) (hereinafter &#x201c;[EN302663]&#x201d;) and describes the access layer of the ITS-S reference architecture. The ITS-G5 access layer comprises [IEEE80211] (which now incorporates [IEEE80211p]), as well as features for Decentralized Congestion Control (DCC) methods discussed in ETSI TS 102 687 V1.2.1 (2018 April) (&#x201c;[TS102687]&#x201d;). The access layer for 3GPP LTE-V2X based interface(s) is outlined in, inter alia, ETSI EN 303 613 V1.1.1 (2020-01), 3GPP TS 23.285 v16.2.0 (2019-12); and 3GPP 5G/NR-V2X is outlined in, inter alia, 3GPP TR 23.786 v16.1.0 (2019-06) and 3GPP TS 23.287 v16.2.0 (2020 March).</p><p id="p-0172" num="0155">The cloud <b>944</b> may represent a cloud computing architecture/platform that provides one or more cloud computing services. Cloud computing refers to a paradigm for enabling network access to a scalable and elastic pool of shareable computing resources with self-service provisioning and administration on-demand and without active management by users. Computing resources (or simply &#x201c;resources&#x201d;) are any physical or virtual component, or usage of such components, of limited availability within a computer system or network. Examples of resources include usage/access to, for a period of time, servers, processor(s), storage equipment, memory devices, memory areas, networks, electrical power, input/output (peripheral) devices, mechanical devices, network connections (e.g., channels/links, ports, network sockets, etc.), operating systems, virtual machines (VMs), software/applications, computer files, and/or the like. Cloud computing provides cloud computing services (or cloud services), which are one or more capabilities offered via cloud computing that are invoked using a defined interface (e.g., an API or the like). Some capabilities of cloud <b>944</b> include application capabilities type, infrastructure capabilities type, and platform capabilities type. A cloud capabilities type is a classification of the functionality provided by a cloud service to a cloud service customer (e.g., a user of cloud <b>944</b>), based on the resources used. The application capabilities type is a cloud capabilities type in which the cloud service customer can use the cloud service provider's applications; the infrastructure capabilities type is a cloud capabilities type in which the cloud service customer can provision and use processing, storage or networking resources; and platform capabilities type is a cloud capabilities type in which the cloud service customer can deploy, manage and run customer-created or customer-acquired applications using one or more programming languages and one or more execution environments supported by the cloud service provider. Cloud services may be grouped into categories that possess some common set of qualities. Some cloud service categories that the cloud <b>944</b> may provide include, for example, Communications as a Service (CaaS), which is a cloud service category involving real-time interaction and collaboration services; Compute as a Service (CompaaS), which is a cloud service category involving the provision and use of processing resources needed to deploy and run software; Database as a Service (DaaS), which is a cloud service category involving the provision and use of database system management services; Data Storage as a Service (DSaaS), which is a cloud service category involving the provision and use of data storage and related capabilities; Firewall as a Service (FaaS), which is a cloud service category involving providing firewall and network traffic management services; Infrastructure as a Service (IaaS), which is a cloud service category involving infrastructure capabilities type; Network as a Service (NaaS), which is a cloud service category involving transport connectivity and related network capabilities; NSaaS; Platform as a Service (PaaS), which is a cloud service category involving the platform capabilities type; Software as a Service (SaaS), which is a cloud service category involving the application capabilities type; Security as a Service, which is a cloud service category involving providing network and information security (infosec) services; and/or other like cloud services.</p><p id="p-0173" num="0156">Additionally or alternatively, the cloud <b>944</b> may represent one or more cloud servers, application servers, web servers, and/or some other remote infrastructure. The remote/cloud servers may include any one of a number of services and capabilities such as, for example, any of those discussed herein. Additionally or alternatively, the cloud <b>944</b> may represent a network such as the Internet, a local area network (LAN), a wide area network (WAN), a wireless local area network (WLAN), or a wireless wide area network (WWAN) including proprietary and/or enterprise networks for a company or organization, or combinations thereof. The cloud <b>944</b> may be a network that comprises computers, network connections among the computers, and software routines to enable communication between the computers over network connections. In this regard, the cloud <b>944</b> comprises one or more network elements that may include one or more processors, communications systems (e.g., including network interface controllers, one or more transmitters/receivers connected to one or more antennas, etc.), and computer readable media. Examples of such network elements may include wireless access points (WAPs), home/business servers (with or without RF communications circuitry), routers, switches, hubs, radio beacons, base stations, picocell or small cell base stations, backbone gateways, and/or any other like network device. Connection to the cloud <b>944</b> may be via a wired or a wireless connection using the various communication protocols discussed infra. More than one network may be involved in a communication session between the illustrated devices. Connection to the cloud <b>944</b> may require that the computers execute software routines which enable, for example, the seven layers of the OSI model of computer networking or equivalent in a wireless (cellular) phone network. Cloud <b>944</b> may be used to enable relatively long-range communication such as, for example, between the one or more server(s) <b>950</b> and one or more UEs <b>910</b>. Additionally or alternatively, the cloud <b>944</b> may represent the Internet, one or more cellular networks, local area networks, or wide area networks including proprietary and/or enterprise networks, TCP/Internet Protocol (IP)-based network, or combinations thereof. In these implementations, the cloud <b>944</b> may be associated with network operator who owns or controls equipment and other elements necessary to provide network-related services, such as one or more base stations or access points, one or more servers for routing digital data or telephone calls (e.g., a core network or backbone network), etc. The backbone links <b>955</b> may include any number of wired or wireless technologies, and may be part of a LAN, a WAN, or the Internet. In one example, the backbone links <b>955</b> are fiber backbone links that couple lower levels of service providers to the Internet, such as the CN <b>912</b> and cloud <b>944</b>.</p><p id="p-0174" num="0157">As shown by <figref idref="DRAWINGS">FIG. <b>9</b></figref>, each of the NANs <b>931</b>, <b>932</b>, and <b>933</b> are co-located with edge compute nodes (or &#x201c;edge servers&#x201d;) <b>936</b><i>a</i>, <b>936</b><i>b</i>, and <b>936</b><i>c</i>, respectively. These implementations may be small-cell clouds (SCCs) where an edge compute node <b>936</b> is co-located with a small cell (e.g., pico-cell, femto-cell, etc.), or may be mobile micro clouds (MCCs) where an edge compute node <b>936</b> is co-located with a macro-cell (e.g., an eNB, gNB, etc.). The edge compute node <b>936</b> may be deployed in a multitude of arrangements other than as shown by <figref idref="DRAWINGS">FIG. <b>9</b></figref>. In a first example, multiple NANs <b>930</b> are co-located or otherwise communicatively coupled with one edge compute node <b>936</b>. In a second example, the edge servers <b>936</b> may be co-located or operated by RNCs, which may be the case for legacy network deployments, such as 3G networks. In a third example, the edge servers <b>936</b> may be deployed at cell aggregation sites or at multi-RAT aggregation points that can be located either within an enterprise or used in public coverage areas. In a fourth example, the edge servers <b>936</b> may be deployed at the edge of CN <b>942</b>. These implementations may be used in follow-me clouds (FMC), where cloud services running at distributed data centers follow the UEs <b>910</b> as they roam throughout the network.</p><p id="p-0175" num="0158">In any of the implementations discussed herein, the edge servers <b>936</b> provide a distributed computing environment for application and service hosting, and also provide storage and processing resources so that data and/or content can be processed in close proximity to subscribers (e.g., users of UEs <b>910</b>) for faster response times The edge servers <b>936</b> also support multitenancy run-time and hosting environment(s) for applications, including virtual appliance applications that may be delivered as packaged virtual machine (VM) images, middleware application and infrastructure services, content delivery services including content caching, mobile big data analytics, and computational offloading, among others. Computational offloading involves offloading computational tasks, workloads, applications, and/or services to the edge servers <b>936</b> from the UEs <b>910</b>, CN <b>942</b>, cloud <b>944</b>, and/or server(s) <b>950</b>, or vice versa. For example, a device application or client application operating in a UE <b>910</b> may offload application tasks or workloads to one or more edge servers <b>936</b>. In another example, an edge server <b>936</b> may offload application tasks or workloads to one or more UE <b>910</b> (e.g., for distributed ML computation or the like).</p><p id="p-0176" num="0159">The edge compute nodes <b>936</b> may include or be part of an edge system <b>935</b> that employs one or more ECTs <b>935</b>. The edge compute nodes <b>936</b> may also be referred to as &#x201c;edge hosts <b>936</b>&#x201d; or &#x201c;edge servers <b>936</b>.&#x201d; The edge system <b>935</b> includes a collection of edge servers <b>936</b> and edge management systems (not shown by <figref idref="DRAWINGS">FIG. <b>9</b></figref>) necessary to run edge computing applications within an operator network or a subset of an operator network. The edge servers <b>936</b> are physical computer systems that may include an edge platform and/or virtualization infrastructure, and provide compute, storage, and network resources to edge computing applications. Each of the edge servers <b>936</b> are disposed at an edge of a corresponding access network, and are arranged to provide computing resources and/or various services (e.g., computational task and/or workload offloading, cloud-computing capabilities, IT services, and other like resources and/or services as discussed herein) in relatively close proximity to UEs <b>910</b>. The VI of the edge servers <b>936</b> provide virtualized environments and virtualized resources for the edge hosts, and the edge computing applications may run as VMs and/or application containers on top of the VI.</p><p id="p-0177" num="0160">In one example implementation, the ECT <b>935</b> operates according to the MEC framework, as discussed in ETSI GS MEC 003 V3.1.1 (2022 March), ETSI GS MEC 009 V3.1.1 (2021 June), ETSI GS MEC 010-1 v1.1.1 (2017 October), ETSI GS MEC 010-2 v2.2.1 (2022 February), ETSI GS MEC 011 v2.2.1 (2020 December), ETSI GS MEC 012 V2.2.1 (2022 February), ETSI GS MEC 013 v2.2.1 (2022 January), ETSI GS MEC 014 V1.1.1 (2021 February), ETSI GS MEC 015 v2.1.1 (2020 June), ETSI GS MEC 016 v2.2.1 (2020 April), ETSI GS MEC 021 v2.2.1 (2022 February), ETSI GS MEC 028 v2.2.1 (2021 July), ETSI GS MEC 029 v2.2.1 (2022 January), ETSI MEC GS 030 v2.2.1 (2022 May), ETSI GS NFV-MAN 001 v1.1.1 (2014 December), U.S. Provisional App. No. 63/003,834 filed Apr. 1, 2020 (&#x201c;['834]&#x201d;), and Int'l App. No. PCT/US2020/066969 filed on Dec. 23, 2020 (&#x201c;['969]&#x201d;) (collectively referred to herein as &#x201c;[MEC]&#x201d;), the contents of each of which are hereby incorporated by reference in their entireties. This example implementation (and/or in any other example implementation discussed herein) may also include NFV and/or other like virtualization technologies such as those discussed in ETSI GR NFV 001 V1.3.1 (2021 March), ETSI GS NFV 002 V1.2.1 (2014 December), ETSI GR NFV 003 V1.6.1 (2021 March), ETSI GS NFV 006 V2.1.1 (2021 January), ETSI GS NFV-INF 001 V1.1.1 (2015 January), ETSI GS NFV-INF 003 V1.1.1 (2014 December), ETSI GS NFV-INF 004 V1.1.1 (2015 January), ETSI GS NFV-MAN 001 v1.1.1 (2014 December), and/or Open Source MANO documentation, version 12 (June 2022), https://osm.etsi.org/docs/user-guide/v12/index.html (&#x201c;[OSM]&#x201d;) (collectively referred to as &#x201c;[ETSINFV]&#x201d;), the contents of each of which are hereby incorporated by reference in their entireties. Other virtualization technologies and/or service orchestration and automation platforms may be used such as, for example, those discussed in <i>E</i>2<i>E Network Slicing Architecture</i>, GSMA, Official Doc. NG.127, v1.0 (3 Jun. 2021), https://www.gsma.com/newsroom/wp-content/uploads//NG.127-v1.0-2.pdf, <i>Open Network Automation Platform </i>(<i>ONAP</i>) <i>documentation</i>, Release Istanbul, v9.0.1 (17 Feb. 2022), https://docs.onap.org/en/latest/index.html (&#x201c;[ONAP]&#x201d;), 3GPP Service Based Management Architecture (SBMA) as discussed in 3GPP TS 28.533 v17.2.0 (2022 Mar. 22) (&#x201c;[TS28533]&#x201d;), the contents of each of which are hereby incorporated by reference in their entireties.</p><p id="p-0178" num="0161">In another example implementation, the ECT <b>935</b> operates according to the O-RAN framework. Typically, front-end and back-end device vendors and carriers have worked closely to ensure compatibility. The flip-side of such a working model is that it becomes quite difficult to plug-and-play with other devices and this can hamper innovation. To combat this, and to promote openness and inter-operability at every level, several key players interested in the wireless domain (e.g., carriers, device manufacturers, academic institutions, and/or the like) formed the Open RAN alliance (&#x201c;O-RAN&#x201d;) in 2018. The O-RAN network architecture is a building block for designing virtualized RAN on programmable hardware with radio access control powered by AI. Various aspects of the O-RAN architecture are described in <i>O</i>-<i>RAN Architecture Description </i>v06.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG1 (March 2022); <i>O</i>-<i>RAN Operations and Maintenance Architecture Specification </i>v04.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG1 (February 2021); <i>O</i>-<i>RAN Operations and Maintenance Interface Specification </i>v04.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG1 (February 2021) <i>O</i>-<i>RAN Information Model and Data Models Specification </i>v01.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG1 (February 2021); <i>O</i>-<i>RAN Working Group </i>1 <i>Slicing Architecture </i>v06.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG1 (March 2022); <i>O</i>-<i>RAN Working Group </i>2 (<i>Non</i>-<i>RT RIC and A</i>1 <i>interface WG</i>) <i>A</i>1 <i>interface: Application Protocol </i>v03.01, O-RAN A<smallcaps>LLIANCE </smallcaps>WG2 (June 2021); <i>O</i>-<i>RAN Working Group </i>2 (<i>Non</i>-<i>RT RIC and A</i>1 <i>interface WG</i>) <i>A</i>1 <i>interface: Type Definitions </i>v02.03, O-RAN A<smallcaps>LLIANCE </smallcaps>WG2 (October 2021); <i>O</i>-<i>RAN Working Group </i>2 (<i>Non</i>-<i>RT RIC and A</i>1 <i>interface WG</i>) <i>A</i>1 <i>interface: Transport Protocol </i>v01.01, O-RAN A<smallcaps>LLIANCE </smallcaps>WG2 (June 2021); <i>O</i>-<i>RAN Working Group </i>2 <i>AI/ML workflow description and requirements </i>v01.03 O-RAN A<smallcaps>LLIANCE </smallcaps>WG2 (October 2021); <i>O</i>-<i>RAN Working Group </i>2 <i>Non</i>-<i>RT RIC Architecture </i>v01.00 O-RAN A<smallcaps>LLIANCE </smallcaps>WG2 (October 2021); <i>O</i>-<i>RAN Working Group </i>2 <i>Non</i>-<i>RT RIC: Functional Architecture </i>v01.01, O-RAN A<smallcaps>LLIANCE </smallcaps>WG2 (July 2021); <i>O</i>-<i>RAN Working Group </i>2 (<i>Non</i>-<i>RT RIC and A</i>1 <i>interface WG</i>): <i>R</i>1 <i>interface: General Aspects and Principles </i>v01.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG2 (March 2022); <i>O</i>-<i>RAN Working Group </i>3 <i>Near</i>-<i>Real</i>-<i>time Intelligent Controller Architecture </i>&#x26; <i>E</i>2 <i>General Aspects and Principles </i>v02.01, O-RAN A<smallcaps>LLIANCE </smallcaps>WG3 (March 2022); <i>O</i>-<i>RAN Working Group </i>3 <i>Near</i>-<i>Real</i>-<i>time Intelligent Controller E</i>2 <i>Service Model </i>(<i>E</i>2<i>SM</i>) v02.01, O-RAN A<smallcaps>LLIANCE </smallcaps>WG3 (March 2022); <i>O</i>-<i>RAN Working Group </i>3 <i>Near</i>-<i>Real</i>-<i>time Intelligent Controller E</i>2 <i>Service Model </i>(<i>E</i>2<i>SM</i>) <i>RAN Function Network Interface </i>(<i>NI</i>) v01.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG3 (February 2020); <i>O</i>-<i>RAN Working Group </i>3 <i>Near</i>-<i>Real</i>-<i>time Intelligent Controller E</i>2 <i>Service Model </i>(<i>E</i>2<i>SM</i>) <i>KPM </i>v02.01, O-RAN A<smallcaps>LLIANCE </smallcaps>WG3 (March 2022); <i>O</i>-<i>RAN Working Group </i>3 <i>Near</i>-<i>Real</i>-<i>time Intelligent Controller E</i>2 <i>Service Model </i>(<i>E</i>2<i>SM</i>) <i>RAN Control </i>v01.01, O-RAN A<smallcaps>LLIANCE </smallcaps>WG3 (March 2022); <i>O</i>-<i>RAN Working Group </i>3<i>, Near</i>-<i>Real</i>-<i>time Intelligent Controller, E</i>2 <i>Application Protocol </i>(<i>E</i>2<i>AP</i>) v02.01, O-RAN A<smallcaps>LLIANCE </smallcaps>WG3 (March 2022); <i>O</i>-<i>RAN Working Group </i>3 <i>Near</i>-<i>Real</i>-<i>time Intelligent Controller Near</i>-<i>RT RIC Architecture </i>v02.01, O-RAN A<smallcaps>LLIANCE </smallcaps>WG3 (March 2022); <i>O</i>-<i>RAN Working Group </i>4 (<i>Open Fronthaul Interfaces WG</i>) <i>Control, User and Synchronization Plane Specification </i>v08.01, O-RAN A<smallcaps>LLIANCE </smallcaps>WG4 (May 2022); and <i>O</i>-<i>RAN Working Group </i>4 (<i>Open Fronthaul Interfaces WG</i>) <i>Control, User and Synchronization Plane Specification </i>v07.02, O-RAN A<smallcaps>LLIANCE </smallcaps>WG4 (May 2022); <i>O</i>-<i>RAN Fronthaul Working Group </i>4 <i>Cooperative Transport Interface Transport Control Plane Specification </i>v02.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG4 (June 2021); <i>O</i>-<i>RAN Fronthaul Working Group </i>4 <i>Cooperative Transport Interface Transport Management Plane Specification </i>v02.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG4 (June 2021); <i>O</i>-<i>RAN Fronthaul Working Group </i>4 <i>Management Plane Specification </i>v08.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG4 (March 2022); <i>O</i>-<i>RAN Fronthaul Working Group </i>4 <i>Management Plane Specification </i>v07.01, O-RAN A<smallcaps>LLIANCE </smallcaps>WG4 (April 2022); <i>O</i>-<i>RAN Alliance Working Group </i>5 <i>O</i>1 <i>Interface specification for O</i>-<i>DU </i>v03.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG5 (March 2022); <i>O</i>-<i>RAN Open F</i>1<i>/W</i>1<i>/E</i>1<i>/X</i>2<i>/Xn Interfaces Working Group Transport Specification </i>v01.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG5 (April 2020); <i>Cloud Architecture and Deployment Scenarios for O</i>-<i>RAN Virtualized RAN </i>v02.02, O-RAN A<smallcaps>LLIANCE </smallcaps>WG6 (October 2021); <i>Cloud Platform Reference Designs </i>v02.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG6 (February 2021); <i>O</i>-<i>RAN O</i>2 <i>Interface General Aspects and Principles </i>v01.02, O-RAN A<smallcaps>LLIANCE </smallcaps>WG6 (March 2022); <i>O</i>-<i>RAN Acceleration Abstraction Layer General Aspects and Principles </i>v02.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG6 (March 2022); <i>O</i>-<i>RAN White Box Hardware Working Group Hardware Reference Design Specification for Indoor Pico Cell with Fronthaul Split Option </i>6 v02.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG7 (October 2021); <i>O</i>-<i>RAN WG</i>7 <i>Hardware Reference Design Specification for Indoor Picocell </i>(<i>FR</i>1) <i>with Split Option </i>7-2 v03.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG7 (October 2021); <i>O</i>-<i>RAN White Box Hardware Working Group Hardware Reference Design Specification for Outdoor Micro Cell with Split Architecture Option </i>7.2 v02.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG7 (October 2021); <i>O</i>-<i>RAN WG</i>7 <i>Hardware Reference Design Specification for Indoor Picocell </i>(<i>FR</i>1) <i>with Split Option </i>8 v03.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG7 (October 2021); <i>O</i>-<i>RAN Open X</i>- <i>haul Transport Working Group Management interfaces for Transport Network Elements </i>v03.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG9 (March 2022); <i>O</i>-<i>RAN Open X</i>-<i>haul Transport Working Group Synchronization Architecture and Solution Specification</i>, O-RAN A<smallcaps>LLIANCE </smallcaps>WG9 (March 2022); <i>O</i>-<i>RAN Open Xhaul Transport WG</i>9 <i>WDM</i>-<i>based Fronthaul Transport</i>, O-RAN A<smallcaps>LLIANCE </smallcaps>WG9 (March 2022); <i>O</i>-<i>RAN Open Transport Working Group </i>9 <i>Xhaul Packet Switched Architectures and Solutions </i>v02.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG9 (October 2021); <i>O</i>-<i>RAN Operations and Maintenance Architecture </i>v06.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG10 (March 2022); <i>O</i>-<i>RAN Operations and Maintenance Interface Specification </i>v06.00, O-RAN A<smallcaps>LLIANCE </smallcaps>WG10 (March 2022); <i>O</i>-<i>RAN: Towards an Open and Smart RAN</i>, O-RAN A<smallcaps>LLIANCE</smallcaps>, White Paper (October 2018); and U.S. application Ser. No. 17/484,743 filed on 24 Sep. 2021 (collectively referred to as &#x201c;[O-RAN]&#x201d;) the contents of each of which are hereby incorporated by reference in their entireties.</p><p id="p-0179" num="0162">In another example implementation, the ECT <b>935</b> operates according to the 3<sup>rd </sup>Generation Partnership Project (3GPP) System Aspects Working Group 6 (SA6) Architecture for enabling Edge Applications (referred to as &#x201c;3GPP edge computing&#x201d;, &#x201c;3GPP EdgeApp&#x201d;, or the like) as discussed in 3GPP TS 23.558 v17.4.0 (2022 Jun. 13) (&#x201c;[TS23558]&#x201d;), 3GPP TS 23.501 v17.5.0 (2022 Jun. 15) (&#x201c;[TS23501]&#x201d;), and U.S. application Ser. No. 17/484,719 filed on 24 Sep. 2021 (&#x201c;['719]&#x201d;) (collectively referred to as &#x201c;[SA6Edge]&#x201d;), the contents of each of which is hereby incorporated by reference in their entireties.</p><p id="p-0180" num="0163">In another example implementation, the ECT <b>935</b> operates according to the Intel&#xae; Smart Edge Open framework (formerly known as OpenNESS) as discussed in Intel&#xae; Smart Edge Open Developer Guide, version 21.09 (30 Sep. 2021), available at: &#x3c;https://smart-edge-open.github.io/&#x3e; (&#x201c;[ISEO]&#x201d;), the contents of which are hereby incorporated by reference in its entirety.</p><p id="p-0181" num="0164">In another example implementation, the ECT <b>935</b> operates according to the Multi-Access Management Services (MAMS) framework as discussed in Kanugovi et al., <i>Multi</i>-<i>Access Management Services </i>(<i>MAMS</i>), I<smallcaps>NTERNET </smallcaps>E<smallcaps>NGINEERING </smallcaps>T<smallcaps>ASK </smallcaps>F<smallcaps>ORCE </smallcaps>(IETF), Request for Comments (RFC) 8743 (March 2020), Ford et al., <i>TCP Extensions for Multipath Operation with Multiple Addresses</i>, IETF RFC 8684, (March 2020), De Coninck et al., <i>Multipath Extensions for QUIC </i>(<i>MP</i>-<i>QUIC</i>), IETF <smallcaps>DRAFT</smallcaps>-<smallcaps>DECONINCK</smallcaps>-<smallcaps>QUIC</smallcaps>-<smallcaps>MULTIPATH</smallcaps>-07, IETA, QUIC Working Group (3 May 2021), Zhu et al., <i>User Plane Protocols for Multiple Access Management Service</i>, IETF <smallcaps>DRAFT</smallcaps>-<smallcaps>ZHU</smallcaps>-<smallcaps>INTAREA</smallcaps>-<smallcaps>MAMS</smallcaps>-<smallcaps>USER</smallcaps>-<smallcaps>PROTOCOL</smallcaps>-09, IETA, INTAREA (4 Mar. 2020), and Zhu et al., <i>Generic Multi</i>-<i>Access </i>(<i>GMA</i>) <i>Convergence Encapsulation Protocols</i>, IETF <smallcaps>DRAFT</smallcaps>-<smallcaps>ZHU</smallcaps>-<smallcaps>INTAREA</smallcaps>-<smallcaps>GMA</smallcaps>-14, IETA, INTAREA/Network Working Group (24 Nov. 2021) (collectively referred to as &#x201c;[MAMS]&#x201d;), the contents of each of which are hereby incorporated by reference in their entireties. In these implementations, an edge compute node and/or one or more cloud computing nodes/clusters may be one or more MAMS servers that includes or operates a Network Connection Manager (NCM) for downstream/DL traffic, and the client include or operate a Client Connection Manager (CCM) for upstream/UL traffic. An NCM is a functional entity that handles MAMS control messages from clients (e.g., a client that configures the distribution of data packets over available access paths and (core) network paths, and manages user-plane treatment (e.g., tunneling, encryption, and/or the like) of the traffic flows (see e.g., [MAMS]). The CCM is the peer functional element in a client (e.g., a client that handles MAMS control-plane procedures, exchanges MAMS signaling messages with the NCM, and configures the network paths at the client for the transport of user data (e.g., network packets, and/or the like) (see e.g., [MAMS]).</p><p id="p-0182" num="0165">It should be understood that the aforementioned edge computing frameworks and services deployment examples are only one illustrative example of edge computing systems/networks <b>935</b>, and that the present disclosure may be applicable to many other edge computing/networking technologies in various combinations and layouts of devices located at the edge of a network including the various edge computing networks/systems described herein. Further, the techniques disclosed herein may relate to other IoT edge network systems and configurations, and other intermediate processing entities and architectures may also be applicable to the present disclosure.</p><p id="p-0183" num="0166"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram <b>1000</b> showing an overview of a configuration for edge computing, which includes a layer of processing referred to in many of the following examples as an &#x201c;edge cloud&#x201d;. As shown, the edge cloud <b>1010</b> is co-located at an edge location, such as a NAN <b>1040</b> (e.g., access point, base station, or the like), a local processing hub <b>1050</b>, or a central office <b>1020</b>, and thus, may include multiple entities, devices, and equipment instances. The edge cloud <b>1010</b> is located much closer to the endpoint (consumer and producer) data sources <b>1060</b> (e.g., autonomous vehicles <b>1061</b>, user equipment <b>1062</b>, business and industrial equipment <b>1063</b>, video capture devices <b>1064</b>, drones <b>1065</b>, smart cities and building devices <b>1066</b>, sensors and IoT devices <b>1067</b>, and/or the like) than the cloud data center <b>1030</b>. Compute, memory, and storage resources which are offered at the edges in the edge cloud <b>1010</b> are critical to providing ultra-low latency response times for services and functions used by the endpoint data sources <b>1060</b> as well as reduce network backhaul traffic from the edge cloud <b>1010</b> toward cloud data center <b>1030</b> thus improving energy consumption and overall network usages among other benefits.</p><p id="p-0184" num="0167">Compute, memory, and storage are scarce resources, and generally decrease depending on the edge location (e.g., fewer processing resources being available at consumer endpoint devices, than at a base station, than at a central office <b>1020</b>). However, the closer that the edge location is to the endpoint <b>1060</b>, the more that space and power is often constrained. Thus, edge computing attempts to reduce the amount of resources needed for network services, through the distribution of more resources which are located closer both geographically and in network access time. In this manner, edge computing attempts to bring the compute resources to the workload data where appropriate, or, bring the workload data to the compute resources.</p><p id="p-0185" num="0168">The edge cloud <b>1010</b> architecture that covers multiple potential deployments and addresses restrictions that some network operators or service providers may have in their own infrastructures. These include, variation of configurations based on the edge location because edges at a NAN level, for instance, may have more constrained performance and capabilities in a multi-tenant scenario; configurations based on the type of compute, memory, storage, fabric, acceleration, or like resources available to edge locations, tiers of locations, or groups of locations; the service, security, and management and orchestration capabilities; and related objectives to achieve usability and performance of end services. These deployments may accomplish processing in network layers that may be considered as &#x201c;near edge&#x201d;, &#x201c;close edge&#x201d;, &#x201c;local edge&#x201d;, &#x201c;middle edge&#x201d;, or &#x201c;far edge&#x201d; layers, depending on latency, distance, and timing characteristics.</p><p id="p-0186" num="0169">Edge computing is a paradigm where computing is performed at or closer to the &#x201c;edge&#x201d; of a network, typically through the use of an appropriately arranged compute platform (e.g., x86, ARM, Nvidia, and/or other CPU/GPU based compute hardware architecture) implemented at NANs <b>1040</b>, gateways, network routers, and/or other devices which are much closer to endpoint devices <b>1060</b> producing and consuming the data. For example, edge gateway servers (e.g., local processing hub <b>1050</b>) may be equipped with pools of memory and storage resources to perform computation in real-time for low latency use-cases (e.g., autonomous driving or video surveillance) for connected client devices <b>1060</b>. In another example, NANs <b>1040</b> may be augmented with compute and acceleration resources to directly process service workloads for connected UEs <b>1060</b>, without further communicating data via backhaul networks. In another example, central office network management hardware <b>1020</b> may be replaced with standardized compute HW (e.g., COTS HW) that performs virtualized network functions and offers compute resources for the execution of services and consumer functions for connected devices <b>1060</b>. Additionally or alternatively, an arrangement with HW combined with virtualized functions, commonly referred to as a hybrid arrangement, may also be implemented. Within edge computing networks, there may be scenarios in services which the compute resource will be &#x201c;moved&#x201d; to the data, as well as scenarios in which the data will be &#x201c;moved&#x201d; to the compute resource. In an example, NAN <b>1040</b> compute, acceleration, and network resources can provide services in order to scale to workload demands on an as-needed basis by activating dormant capacity (e.g., subscription, capacity on-demand, and so forth) in order to manage corner cases, emergencies, and/or to provide longevity for deployed resources over a significantly longer implemented lifecycle.</p><p id="p-0187" num="0170"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates deployment and orchestration for virtualized and container-based edge configurations across an edge computing system <b>1100</b> operated among multiple edge nodes and/or multiple tenants (e.g., users, providers, subscribers, and the like) which use such edge nodes. The edge computing system <b>1100</b> includes a first edge node <b>1122</b> and a second edge node <b>1124</b> that are coordinated to fulfill requests and responses for various endpoint devices <b>1110</b> (e.g., smart cities, building systems, mobile devices, computing devices, business/logistics systems, industrial systems, and/or the like), which access various virtual edge instances <b>1132</b>, <b>1134</b>. Additionally or alternatively, the endpoint devices <b>1110</b> can be the same or similar as the end point devices <b>160</b>, end point devices <b>1060</b>, and/or any other device discussed herein. Here, the virtual edge instances <b>1132</b>, <b>1134</b> provide edge compute capabilities and processing in an edge cloud, with access to a cloud/data center <b>1140</b> for higher-latency requests for websites, applications, database servers, and/or the like. However, the edge cloud <b>1010</b> enables coordination of processing among multiple edge nodes for multiple tenants or entities.</p><p id="p-0188" num="0171">The virtual edge instances include a first virtual edge <b>1132</b> offered to a first tenant (Tenant 1), which offers a first combination of edge storage, computing, and services; and a second virtual edge <b>1134</b> offering a second combination of edge storage, computing, and services. The virtual edge instances <b>1132</b>, <b>1134</b> are distributed among the edge nodes <b>1122</b>, <b>1124</b>, and may include scenarios in which a request and response are fulfilled from the same or different edge nodes. The configuration of the edge nodes <b>1122</b>, <b>1124</b> to operate in a distributed yet coordinated fashion occurs based on edge provisioning functions <b>1150</b>. The functionality of the edge nodes <b>1122</b>, <b>1124</b> to provide coordinated operation for applications and services, among multiple tenants, occurs based on orchestration functions <b>1160</b>.</p><p id="p-0189" num="0172">Some of the devices in <b>1110</b> are multi-tenant devices where tenant 1 may function within a tenant1 &#x2018;slice&#x2019; while a tenant 2 may function within a tenant2 slice (and, in further examples, additional or sub-tenants may exist; and each tenant may even be specifically entitled and transactionally tied to a specific set of features all the way day to specific hardware features). A trusted multi-tenant device may further contain a tenant specific cryptographic key such that the combination of key and slice may be considered a &#x201c;root of trust&#x201d; (RoT) or tenant specific RoT. A RoT may further be computed dynamically composed using a device identity composition engine (DICE) architecture such that a single DICE hardware building block may be used to construct layered trusted computing base contexts for layering of device capabilities (such as a Field Programmable Gate Array (FPGA)). The RoT may further be used for a trusted computing context to enable a &#x201c;fan-out&#x201d; that is useful for supporting multi-tenancy. Within a multi-tenant environment, the respective edge nodes <b>1122</b>, <b>1124</b> may operate as security feature enforcement points for local resources allocated to multiple tenants per node. Additionally, tenant runtime and application execution (e.g., in instances <b>1132</b>, <b>1134</b>) may serve as an enforcement point for a security feature that creates a virtual edge abstraction of resources spanning potentially multiple physical hosting platforms. Finally, the orchestration functions <b>1160</b> at an orchestration entity may operate as a security feature enforcement point for marshalling resources along tenant boundaries.</p><p id="p-0190" num="0173">Edge compute nodes may partition resources (e.g., memory, central processing unit (CPU), graphics processing unit (GPU), interrupt controller, input/output (I/O) controller, memory controller, bus controller, and/or the like) where respective partitionings may contain a RoT capability and where fan-out and layering according to a DICE model may further be applied to Edge Nodes. Cloud computing nodes often use containers, FaaS engines, Servlets, servers, or other computation abstraction that may be partitioned according to a DICE layering and fan-out structure to support a RoT context for each. Accordingly, the respective RoTs spanning devices <b>1110</b>, <b>1122</b>, and <b>1140</b> may coordinate the establishment of a distributed trusted computing base (DTCB) such that a tenant-specific virtual trusted secure channel linking all elements end to end can be established.</p><p id="p-0191" num="0174">In some cases, a container may have data or workload specific keys protecting its content from a previous edge node. As part of migration of a container, a pod controller at a source edge node may obtain a migration key from a target edge node pod controller where the migration key is used to wrap the container-specific keys. When the container/pod is migrated to the target edge node, the unwrapping key is exposed to the pod controller that then decrypts the wrapped keys. The keys may now be used to perform operations on container specific data. The migration functions may be gated by properly attested edge nodes and pod managers (as described above).</p><p id="p-0192" num="0175">In further examples, an edge computing system is extended to provide for orchestration of multiple applications through the use of containers (a contained, deployable unit of software that provides code and needed dependencies) in a multi-owner, multi-tenant environment. A multi-tenant orchestrator may be used to perform key management, trust anchor management, and other security functions related to the provisioning and lifecycle of the trusted &#x2018;slice&#x2019; concept in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. For instance, an edge computing system may be configured to fulfill requests and responses for various client endpoints from multiple virtual edge instances (and, from a cloud or remote data center). The use of these virtual edge instances may support multiple tenants and multiple applications (e.g., augmented reality (AR)/virtual reality (VR), enterprise applications, content delivery, gaming, compute offload) simultaneously. Further, there may be multiple types of applications within the virtual edge instances (e.g., normal applications; latency sensitive applications; latency-critical applications; user plane applications; networking applications; and/or the like). The virtual edge instances may also be spanned across systems of multiple owners at different geographic locations (or, respective computing systems and resources which are co-owned or co-managed by multiple owners).</p><p id="p-0193" num="0176">For instance, each edge node <b>1122</b>, <b>1124</b> may implement the use of containers, such as with the use of a container pod <b>1126</b>, <b>1128</b> providing a group of one or more containers. In a setting that uses one or more container pods, a pod controller or orchestrator <b>1160</b> is responsible for local control and orchestration of the containers in the pod <b>1126</b>, <b>1128</b>. Various edge node resources (e.g., storage, compute, services, depicted with hexagons in <figref idref="DRAWINGS">FIG. <b>11</b></figref>) are provided for the respective edge slices <b>1132</b>, <b>1134</b>, and are partitioned according to the needs of each container. Here, each container pod <b>1126</b>, <b>1128</b> can host a service instance <b>236</b><i>c</i>, slice instance <b>622</b> and/or virtual lane instance <b>652</b> that provide e2e QoS constructs/channels/lanes according to the various example implementations discussed herein, and the pod controller/orchestrator <b>1160</b> may be the same or similar as the controller/orchestrators <b>236</b><i>a</i>, <b>625</b>, <b>645</b>, <b>725</b>, <b>736</b><i>a </i>discussed previously. With the use of container pods, a pod controller oversees the partitioning and allocation of containers and resources. The pod controller receives instructions from an orchestrator <b>1160</b> that instructs the controller on how best to partition physical resources and for what duration, such as by receiving key performance indicator (KPI) targets based on SLA contracts. The pod controller determines which container requires which resources and for how long in order to complete the workload and satisfy the SLA. The pod controller also manages container lifecycle operations such as: creating the container, provisioning it with resources and applications, coordinating intermediate results between multiple containers working on a distributed application together, dismantling containers when workload completes, and the like. Additionally, a pod controller may serve a security role that prevents assignment of resources until the right tenant authenticates or prevents provisioning of data or a workload to a container until an attestation result is satisfied.</p><p id="p-0194" num="0177">Also, with the use of container pods, tenant boundaries can still exist but in the context of each pod of containers. If each tenant specific pod has a tenant specific pod controller, there will be a shared pod controller that consolidates resource allocation requests to avoid typical resource starvation situations. Further controls may be provided to ensure attestation and trustworthiness of the pod and pod controller. For instance, the orchestrator <b>1160</b> may provision an attestation verification policy to local pod controllers that perform attestation verification. If an attestation satisfies a policy for a first tenant pod controller but not a second tenant pod controller, then the second pod could be migrated to a different edge node that does satisfy it. Alternatively, the first pod may be allowed to execute and a different shared pod controller is installed and invoked prior to the second pod executing.</p><p id="p-0195" num="0178"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates additional compute arrangements deploying containers in an edge computing system <b>1200</b>. As an example, system arrangements <b>1210</b>, <b>1220</b> depict settings in which a pod controller (e.g., container managers <b>1211</b>, <b>1221</b>, and container orchestrator <b>1231</b>) is adapted to launch containerized pods, functions, and FaaS instances through execution via compute nodes <b>1215</b> in arrangement <b>1210</b>, and/or to separately execute containerized VNFs through execution via compute nodes <b>1223</b> in arrangement <b>1220</b>. This arrangement is adapted for use of multiple tenants in arrangement <b>1230</b> using compute nodes <b>1237</b>, where containerized pods <b>1212</b>, functions <b>1213</b>, VNFs <b>1222</b>, <b>1236</b>, and FaaS instances <b>1214</b> are launched within VMs <b>1234</b>, <b>1235</b> for tenants <b>1232</b>, <b>1233</b> specific to respective tenants (aside from the execution of VNFs). This arrangement is further adapted for use in arrangement <b>1240</b>, which provides containers <b>1242</b>, <b>1243</b> and/or execution of the VNFs, applications, and functions on compute nodes <b>1244</b>, as coordinated by a container-based orchestration system <b>1241</b>.</p><p id="p-0196" num="0179">In an example implementation, compute nodes <b>1215</b>, <b>1223</b>, <b>1237</b>, <b>1244</b> may be or include infrastructure in the service provider environment <b>236</b>, infrastructure in the NOP domain <b>220</b>, <b>320</b>, and/or infrastructure in the DCN <b>640</b>; the pods <b>1212</b>, functions <b>1213</b>, VNFs <b>1222</b>, <b>1236</b>, FaaS instances <b>1214</b>, and/or containers <b>1242</b>, <b>1243</b> correspond to one or more service instances <b>236</b><i>c</i>, slice instances <b>622</b>, and/or virtual lane instances <b>652</b>; and the container managers <b>1211</b>, <b>1221</b>, container orchestrator <b>1231</b>, and/or container-based orchestration system <b>1241</b> correspond to the orchestrators <b>236</b><i>a</i>, <b>625</b>, <b>645</b>, <b>725</b>, <b>736</b><i>a</i>, <b>1160</b>, discussed previously.</p><p id="p-0197" num="0180">The system arrangements in <figref idref="DRAWINGS">FIG. <b>12</b></figref> provide an architecture that treats VMs, containers, and functions equally in terms of application composition, and resulting applications are combinations of these three ingredients. Each ingredient may involve use of one or more accelerator components (e.g., FPGAs, ASICs, and the like) as a local backend. In this manner, applications can be split across multiple edge owners, coordinated by an orchestrator. In the context of <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the pod controller/container manager, container orchestrator, and individual nodes may provide a security enforcement point. However, tenant isolation may be orchestrated where the resources allocated to a tenant are distinct from resources allocated to a second tenant, but edge owners cooperate to ensure resource allocations are not shared across tenant boundaries. Or, resource allocations could be isolated across tenant boundaries, as tenants could allow &#x201c;use&#x201d; via a subscription or transaction/contract basis. In these contexts, virtualization, containerization, enclaves and hardware partitioning schemes may be used by edge owners to enforce tenancy. Other isolation environments may include: bare metal (dedicated) equipment, virtual machines, containers, virtual machines on containers, or combinations thereof.</p><p id="p-0198" num="0181">In further examples, aspects of software-defined or controlled silicon hardware, and other configurable hardware, may integrate with the applications, functions, and services an edge computing system. Software defined silicon (SDSi) may be used to ensure the ability for some resource or hardware ingredient to fulfill a contract or service level agreement, based on the ingredient's ability to remediate a portion of itself or the workload (e.g., by an upgrade, reconfiguration, or provision of new features within the hardware configuration itself).</p><heading id="h-0007" level="1">3. Hardware Components, Configurations, and Arrangements</heading><p id="p-0199" num="0182"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates an example software (SW) distribution platform (SDP) <b>1305</b> to distribute software <b>1360</b>, such as the example computer readable instructions <b>1481</b>, <b>1482</b>, <b>1483</b> of <figref idref="DRAWINGS">FIG. <b>14</b></figref>, to one or more devices, such as example processor platform(s) (pp) <b>1300</b>, connected edge devices <b>1462</b> (see e.g., <figref idref="DRAWINGS">FIG. <b>14</b></figref>), and/or any of the other computing systems/devices discussed herein. The SDP <b>1305</b> (or components thereof) may be implemented by any computer server, data facility, cloud service, CDN, edge computing framework, etc., capable of storing and transmitting software (e.g., code, scripts, executable binaries, containers, packages, compressed files, and/or derivatives thereof) to other computing devices (e.g., third parties, the example connected edge devices <b>1462</b> of <figref idref="DRAWINGS">FIG. <b>14</b></figref>). The SDP <b>1305</b> (or components thereof) may be located in a cloud (e.g., data center, etc.), a local area network, an edge network, a wide area network, on the Internet, and/or any other location communicatively coupled with the pp <b>1300</b>.</p><p id="p-0200" num="0183">The pp <b>1300</b> and/or connected edge devices <b>1462</b> connected edge devices <b>1462</b> may include customers, clients, managing devices (e.g., servers), third parties (e.g., customers of an entity owning and/or operating the SDP <b>1305</b>), IoT devices, and the like. The pp <b>1300</b>/connected edge devices <b>1462</b> may operate in commercial and/or home automation environments. In some examples, a third party is a developer, a seller, and/or a licensor of software such as the example computer readable media <b>1481</b>, <b>1482</b>, <b>1483</b> of <figref idref="DRAWINGS">FIG. <b>14</b></figref>. The third parties may be consumers, users, retailers, OEMs, etc. that purchase and/or license the software for use and/or re-sale and/or sub-licensing. In some examples, distributed software causes display of one or more user interfaces (UIs) and/or graphical user interfaces (GUIs) to identify the one or more devices (e.g., connected edge devices) geographically and/or logically separated from each other (e.g., physically separated IoT devices chartered with the responsibility of water distribution control (e.g., pumps), electricity distribution control (e.g., relays), etc.). In some examples, the pp <b>1300</b>/connected edge devices <b>1462</b> can be physically located in different geographic locations, legal jurisdictions, etc.</p><p id="p-0201" num="0184">In <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the SDP <b>1305</b> includes one or more servers (referred to as &#x201c;servers <b>1305</b>&#x201d;) and one or more storage devices (referred to as &#x201c;storage <b>1305</b>&#x201d;). The storage <b>1305</b> store the computer readable instructions <b>1360</b>, which may correspond to the instructions <b>1481</b>, <b>1482</b>, <b>1483</b> of <figref idref="DRAWINGS">FIG. <b>14</b></figref>. The servers <b>1305</b> are in communication with a network <b>1310</b>, which may correspond to any one or more of the Internet and/or any of the example networks as described herein. The servers <b>1305</b> are responsive to requests to transmit the software to a requesting party as part of a commercial transaction. Payment for the delivery, sale and/or license of the software may be handled by the servers <b>1305</b> and/or via a third-party payment entity. The servers <b>1305</b> enable purchasers and/or licensors to download the computer readable instructions <b>1360</b> from the SDP <b>1305</b>.</p><p id="p-0202" num="0185">The servers <b>1305</b> are communicatively connected to one or more security domains and/or security devices through which requests and transmissions of the example computer readable instructions <b>1360</b> must pass. Additionally or alternatively, the servers <b>1305</b> periodically offer, transmit, and/or force updates to the software <b>1360</b> to ensure improvements, patches, updates, etc. are distributed and applied to the software at the end user devices. The computer readable instructions <b>1360</b> are stored on storage <b>1305</b> in a particular format. A format of computer readable instructions includes, but is not limited to a particular code language (e.g., Java, JavaScript, Python, C, C#, SQL, HTML, etc.), and/or a particular code state (e.g., uncompiled code (e.g., ASCII), interpreted code, linked code, executable code (e.g., a binary), etc.), and/or any other format such as those discussed herein. In some examples, the computer readable instructions <b>1360</b> stored in the SDP <b>1305</b> are in a first format when transmitted to the pp <b>1300</b>. Additionally or alternatively, the first format is an executable binary in which particular types of the pp <b>1300</b> can execute. Additionally or alternatively, the first format is uncompiled code that requires one or more preparation tasks to transform the first format to a second format to enable execution on the pp <b>1300</b>. For example, the receiving pp <b>1300</b> may need to compile the computer readable instructions <b>1360</b> in the first format to generate executable code in a second format that is capable of being executed on the pp <b>1300</b>. Additionally or alternatively, the first format is interpreted code that, upon reaching the pp <b>1300</b>, is interpreted by an interpreter to facilitate execution of instructions. Additionally or alternatively, different components of the computer readable instructions <b>1482</b> can be distributed from different sources and/or to different processor platforms; for example, different libraries, plug-ins, components, and other types of compute modules, whether compiled or interpreted, can be distributed from different sources and/or to different processor platforms. For example, a portion of the software instructions (e.g., a script that is not, in itself, executable) may be distributed from a first source while an interpreter (capable of executing the script) may be distributed from a second source.</p><p id="p-0203" num="0186"><figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates an example of components that may be present in a computing node <b>1450</b> for implementing the techniques (e.g., operations, processes, methods, and methodologies) described herein. The compute node <b>1450</b> provides a closer view of the respective components of node <b>1400</b> when implemented as or as part of a computing device (e.g., as a mobile device, a base station, server, gateway, and/or the like). The compute node <b>1450</b> may include any combinations of the hardware or logical components referenced herein, and it may include or couple with any device usable with an edge communication network or a combination of such networks. The components may be implemented as integrated circuitry (ICs), a System on Chip (SoC), portions thereof, discrete electronic devices, or other modules, instruction sets, programmable logic or algorithms, hardware, hardware accelerators, software, firmware, or a combination thereof adapted in the compute node <b>1450</b>, or as components otherwise incorporated within a chassis of a larger system.</p><p id="p-0204" num="0187">In some embodiments, the compute node <b>1450</b> may correspond to the end point devices <b>160</b>, AN <b>130</b>&#x2032;, NAN <b>130</b>, and/or other elements shown and described with respect to <figref idref="DRAWINGS">FIG. <b>1</b></figref>; data producers <b>272</b>, NANs <b>240</b>, service provider environment <b>236</b>, and/or NOP domains <b>220</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>; NOP domain <b>320</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>; UE <b>610</b>, NW <b>620</b>, NW orchestrator <b>625</b>, DCN <b>640</b>, and/or DCN orchestrator <b>645</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>; UE <b>710</b>, NW domain <b>720</b>, RAN <b>721</b>, NW orchestrator <b>725</b>, CN <b>742</b>, NSM <b>743</b>, service provider domain <b>736</b>, and/or service orchestrator <b>736</b><i>a </i>of <figref idref="DRAWINGS">FIG. <b>7</b></figref>; service mesh <b>801</b> of <figref idref="DRAWINGS">FIG. <b>8</b></figref> and/or components therein; UEs <b>910</b>, NANs <b>930</b>, edge compute node(s) <b>936</b>, CN <b>942</b> (or compute node(s) therein), cloud <b>944</b> (or compute node(s) therein), and/or server(s) <b>950</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>; end point devices <b>1060</b>, a local processing hub <b>1050</b>, NAN <b>1040</b>, and/or edge cloud <b>1010</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>; software distribution platform <b>1305</b> and/or processor platform(s) <b>1300</b> of <figref idref="DRAWINGS">FIG. <b>13</b></figref>; and/or any other component, device, and/or system discussed herein. The compute node <b>1450</b> may be embodied as a type of device, appliance, computer, or other &#x201c;thing&#x201d; capable of communicating with other edge, networking, or endpoint components. For example, compute node <b>1450</b> may be embodied as a smartphone, a mobile compute device, a smart appliance, an in-vehicle compute system (e.g., a navigation system), an edge compute node, a NAN, switch, router, bridge, hub, and/or other device or system capable of performing the described functions.</p><p id="p-0205" num="0188">The compute node <b>1450</b> includes processing circuitry in the form of one or more processors <b>1452</b>. The processor circuitry <b>1452</b> includes circuitry such as, but not limited to one or more processor cores and one or more of cache memory, low drop-out voltage regulators (LDOs), interrupt controllers, serial interfaces such as SPI, I<sup>2</sup>C or universal programmable serial interface circuit, real-time clock (RTC), timer-counters including interval and watchdog timers, general purpose I/O, memory card controllers such as secure digital/multi-media card (SD/MMC) or similar, interfaces, mobile industry processor interface (MIPI) interfaces and Joint Test Access Group (JTAG) test access ports. In some implementations, the processor circuitry <b>1452</b> may include one or more hardware accelerators (e.g., same or similar to acceleration circuitry <b>1464</b>), which may be microprocessors, programmable processing devices (e.g., FPGA, ASIC, etc.), or the like. The one or more accelerators may include, for example, computer vision and/or deep learning accelerators. In some implementations, the processor circuitry <b>1452</b> may include on-chip memory circuitry, which may include any suitable volatile and/or non-volatile memory, such as DRAM, SRAM, EPROM, EEPROM, Flash memory, solid-state memory, and/or any other type of memory device technology, such as those discussed herein.</p><p id="p-0206" num="0189">The processor circuitry <b>1452</b> may be, for example, one or more processor cores (CPUs), application processors and/or application processing units (APUs), graphics processing units (GPUs), RISC processors, Acorn RISC Machine (ARM) processors, CISC processors, one or more DSPs, one or more FPGAs, one or more PLDs, one or more ASICs, one or more baseband processors, one or more radio-frequency integrated circuits (RFIC), one or more microprocessors or controllers, a multi-core processor, a multithreaded processor, an ultra-low voltage processor, an embedded processor, a special purpose processing unit and/or specialized processing unit, or any other known processing elements, or any suitable combination thereof. In some implementations, the processor circuitry <b>1452</b> may be embodied as a specialized x-processing unit (xPU) also known as a data processing unit (DPU), infrastructure processing unit (IPU), or network processing unit (NPU). An xPU may be embodied as a standalone circuit or circuit package, integrated within an SoC, or integrated with networking circuitry (e.g., in a SmartNIC, or enhanced SmartNIC), acceleration circuitry, storage devices, storage disks, and/or AI hardware (e.g., GPUs or programmed FPGAs). The xPU may be designed to receive programming to process one or more data streams and perform specific tasks and actions for the data streams (e.g., hosting microservices, performing service management or orchestration, organizing or managing server or data center hardware, managing service meshes, or collecting and distributing telemetry), outside of a CPU or general purpose processing hardware. However, an xPU, a SoC, a CPU, and other variations of the processor circuitry <b>1452</b> may work in coordination with each other to execute many types of operations and instructions within and on behalf of the compute node <b>1450</b>.</p><p id="p-0207" num="0190">The processors (or cores) <b>1452</b> may be coupled with or may include memory/storage and may be configured to execute instructions stored in the memory/storage to enable various applications or operating systems to run on the platform <b>1450</b>. The processors (or cores) <b>1452</b> is configured to operate application software to provide a specific service to a user of the platform <b>1450</b>. Additionally or alternatively, the processor(s) <b>1452</b> may be a special-purpose processor(s)/controller(s) configured (or configurable) to operate according to the elements, features, and implementations discussed herein.</p><p id="p-0208" num="0191">As examples, the processor(s) <b>1452</b> may include an Intel&#xae; Architecture Core&#x2122; based processor such as an i3, an i5, an i7, an i9 based processor; an Intel&#xae; microcontroller-based processor such as a Quark&#x2122;, an Atom&#x2122;, or other MCU-based processor; Pentium&#xae; processor(s), Xeon&#xae; processor(s), or another such processor available from Intel&#xae; Corporation, Santa Clara, Calif. However, any number other processors may be used, such as one or more of Advanced Micro Devices (AMD) Zen&#xae; Architecture such as Ryzen&#xae; or EPYC&#xae; processor(s), Accelerated Processing Units (APUs), MxGPUs, Epyc&#xae; processor(s), or the like; A5-A12 and/or S1-S4 processor(s) from Apple&#xae; Inc., Snapdragon&#x2122; or Centrig&#x2122; processor(s) from Qualcomm&#xae; Technologies, Inc., Texas Instruments, Inc.&#xae; Open Multimedia Applications Platform (OMAP)&#x2122; processor(s); a MIPS-based design from MIPS Technologies, Inc. such as MIPS Warrior M-class, Warrior I-class, and Warrior P-class processors; an ARM-based design licensed from ARM Holdings, Ltd., such as the ARM Cortex-A, Cortex-R, and Cortex-M family of processors; the ThunderX2&#xae; provided by Cavium&#x2122;, Inc.; or the like. In some implementations, the processor(s) <b>1452</b> may be a part of a system on a chip (SoC), System-in-Package (SiP), a multi-chip package (MCP), and/or the like, in which the processor(s) <b>1452</b> and other components are formed into a single integrated circuit, or a single package, such as the Edison&#x2122; or Galileo&#x2122; SoC boards from Intel&#xae; Corporation. Other examples of the processor(s) <b>1452</b> are mentioned elsewhere in the present disclosure.</p><p id="p-0209" num="0192">The processor(s) <b>1452</b> may communicate with system memory <b>1454</b> over an interconnect (IX) <b>1456</b>. Any number of memory devices may be used to provide for a given amount of system memory. As examples, the memory may be random access memory (RAM) in accordance with a Joint Electron Devices Engineering Council (JEDEC) design such as the DDR or mobile DDR standards (e.g., LPDDR, LPDDR2, LPDDR3, or LPDDR4). In particular examples, a memory component may comply with a DRAM standard promulgated by JEDEC, such as JESD79F for DDR SDRAM, JESD79-2F for DDR2 SDRAM, JESD79-3F for DDR3 SDRAM, JESD79-4A for DDR4 SDRAM, JESD209 for Low Power DDR (LPDDR), JESD209-2 for LPDDR2, JESD209-3 for LPDDR3, and JESD209-4 for LPDDR4. Other types of RAM, such as dynamic RAM (DRAM), synchronous DRAM (SDRAM), and/or the like may also be included. Such standards (and similar standards) may be referred to as DDR-based standards and communication interfaces of the storage devices that implement such standards may be referred to as DDR-based interfaces. In various implementations, the individual memory devices may be of any number of different package types such as single die package (SDP), dual die package (DDP) or quad die package (Q17P). These devices, in some examples, may be directly soldered onto a motherboard to provide a lower profile solution, while in other examples the devices are configured as one or more memory modules that in turn couple to the motherboard by a given connector. Any number of other memory implementations may be used, such as other types of memory modules, e.g., dual inline memory modules (DIMMs) of different varieties including but not limited to microDIMMs or MiniDIMMs.</p><p id="p-0210" num="0193">To provide for persistent storage of information such as data, applications, operating systems and so forth, a storage <b>1458</b> may also couple to the processor <b>1452</b> via the IX <b>1456</b>. In an example, the storage <b>1458</b> may be implemented via a solid-state disk drive (SSDD) and/or high-speed electrically erasable memory (commonly referred to as &#x201c;flash memory&#x201d;). Other devices that may be used for the storage <b>1458</b> include flash memory cards, such as SD cards, microSD cards, eXtreme Digital (XD) picture cards, and the like, and USB flash drives. In an example, the memory device may be or may include memory devices that use chalcogenide glass, multi-threshold level NAND flash memory, NOR flash memory, single or multi-level Phase Change Memory (PCM), a resistive memory, nanowire memory, ferroelectric transistor random access memory (FeTRAM), anti-ferroelectric memory, magnetoresistive random access memory (MRAM) memory that incorporates memristor technology, phase change RAM (PRAM), resistive memory including the metal oxide base, the oxygen vacancy base and the conductive bridge Random Access Memory (CB-RAM), or spin transfer torque (STT)-MRAM, a spintronic magnetic junction memory based device, a magnetic tunneling junction (MTJ) based device, a Domain Wall (DW) and Spin Orbit Transfer (SOT) based device, a thyristor based memory device, or a combination of any of the above, or other memory. The memory circuitry <b>1454</b> and/or storage circuitry <b>1458</b> may also incorporate three-dimensional (3D) cross-point (XPOINT) memories from Intel&#xae; and Micron&#xae;.</p><p id="p-0211" num="0194">In low power implementations, the storage <b>1458</b> may be on-die memory or registers associated with the processor <b>1452</b>. However, in some examples, the storage <b>1458</b> may be implemented using a micro hard disk drive (HDD). Further, any number of new technologies may be used for the storage <b>1458</b> in addition to, or instead of, the technologies described, such resistance change memories, phase change memories, holographic memories, or chemical memories, among others.</p><p id="p-0212" num="0195">The components of edge computing device <b>1450</b> may communicate over an interconnect (IX) <b>1456</b>. The IX <b>1456</b> may represent any suitable type of connection or interface such as, for example, metal or metal alloys (e.g., copper, aluminum, etc.), fiber, and/or the like. The IX <b>1456</b> may include any number of IX, fabric, and/or interface technologies, including instruction set architecture (ISA), extended ISA (eISA), Inter-Integrated Circuit (I2C), serial peripheral interface (SPI), point-to-point interfaces, power management bus (PMBus), peripheral component interconnect (PCI), PCI express (PCIe), PCI extended (PCIx), Intel&#xae; Ultra Path Interconnect (UPI), Intel&#xae; Accelerator Link, Intel&#xae; QuickPath Interconnect (QPI), Intel&#xae; Omni-Path Architecture (OPA), Compute Express Link&#x2122; (CXL&#x2122;) IX technology, RapidIO&#x2122; IX, Coherent Accelerator Processor Interface (CAPI), OpenCAPI, cache coherent interconnect for accelerators (CCIX), Gen-Z Consortium IXs, HyperTransport IXs, NVLink provided by NVIDIA&#xae;, a Time-Trigger Protocol (TTP) system, a FlexRay system, PROFIBUS, ARM&#xae; Advanced eXtensible Interface (AXI), ARM&#xae; Advanced Microcontroller Bus Architecture (AMBA) IX, HyperTransport, Infinity Fabric (IF), and/or any number of other IX technologies. The IX <b>1456</b> may be a proprietary bus, for example, used in a SoC based system.</p><p id="p-0213" num="0196">The IX <b>1456</b> couples the processor <b>1452</b> to communication circuitry <b>1466</b> for communications with other devices, such as a remote server (not shown) and/or the connected edge devices <b>1462</b>. The communication circuitry <b>1466</b> is a hardware element, or collection of hardware elements, used to communicate over one or more networks (e.g., cloud <b>1463</b>) and/or with other devices (e.g., edge devices <b>1462</b>).</p><p id="p-0214" num="0197">The transceiver <b>1466</b> may use any number of frequencies and protocols, such as 2.4 Gigahertz (GHz) transmissions under [IEEE802154], using the Bluetooth&#xae; low energy (BLE) standard, as defined by the Bluetooth&#xae; Special Interest Group, or the ZigBee&#xae; standard, among others. Any number of radios, configured for a particular wireless communication protocol, may be used for the connections to the connected edge devices <b>1462</b>. For example, a wireless local area network (WLAN) unit may be used to implement WiFi&#xae; communications in accordance with [IEEE80211]. In addition, wireless wide area communications, e.g., according to a cellular or other wireless wide area protocol, may occur via a wireless wide area network (WWAN) unit.</p><p id="p-0215" num="0198">The wireless network transceiver <b>1466</b> (or multiple transceivers) may communicate using multiple standards or radios for communications at a different range. For example, the compute node <b>1450</b> may communicate with close devices, e.g., within about 10 meters, using a local transceiver based on BLE, or another low power radio, to save power. More distant connected edge devices <b>1462</b>, e.g., within about 50 meters, may be reached over ZigBee&#xae; or other intermediate power radios. Both communications techniques may take place over a single radio at different power levels or may take place over separate transceivers, for example, a local transceiver using BLE and a separate mesh transceiver using ZigBee&#xae;.</p><p id="p-0216" num="0199">A wireless network transceiver <b>1466</b> (e.g., a radio transceiver) may be included to communicate with devices or services in the edge cloud <b>1463</b> via local or wide area network protocols. The wireless network transceiver <b>1466</b> may be an LPWA transceiver that follows [IEEE802154] (or variants thereof), among others. The compute node <b>1463</b> may communicate over a wide area using LoRaWAN&#x2122; (Long Range Wide Area Network) developed by Semtech and the LoRa Alliance. The techniques described herein are not limited to these technologies but may be used with any number of other cloud transceivers that implement long range, low bandwidth communications, such as Sigfox, and other technologies. Further, other communications techniques, such as time-slotted channel hopping, described in [IEEE802154] may be used.</p><p id="p-0217" num="0200">Any number of other radio communications and protocols may be used in addition to the systems mentioned for the wireless network transceiver <b>1466</b>, as described herein. For example, the transceiver <b>1466</b> may include a cellular transceiver that uses spread spectrum (SPA/SAS) communications for implementing high-speed communications. Further, any number of other protocols may be used, such as Wi-Fi&#xae; networks for medium speed communications and provision of network communications. The transceiver <b>1466</b> may include radios that are compatible with any number of 3GPP specifications, such as LTE and 5G/NR communication systems, discussed in further detail at the end of the present disclosure. A network interface controller (NIC) <b>1468</b> may be included to provide a wired communication to nodes of the edge cloud <b>1463</b> or to other devices, such as the connected edge devices <b>1462</b> (e.g., operating in a mesh). The wired communication may provide an Ethernet connection or may be based on other types of networks, such as Fiber Channel (FC), FC over Ethernet (FCoE), or FCoE Initiator Protocol (FIP), iSCSI, Controller Area Network (CAN), Local Interconnect Network (LIN), DeviceNet, ControlNet, Data Highway+, or PROFINET, among many others. An additional NIC <b>1468</b> may be included to enable connecting to a second network, for example, a first NIC <b>1468</b> providing communications to the cloud over Ethernet, and a second NIC <b>1468</b> providing communications to other devices over another type of network.</p><p id="p-0218" num="0201">Given the variety of types of applicable communications from the device to another component or network, applicable communications circuitry used by the device may include or be embodied by any one or more of components <b>1464</b>, <b>1466</b>, <b>1468</b>, or <b>1470</b>. Accordingly, in various examples, applicable means for communicating (e.g., receiving, transmitting, etc.) may be embodied by such communications circuitry.</p><p id="p-0219" num="0202">The compute node <b>1450</b> may include or be coupled to acceleration circuitry <b>1464</b>, which may be embodied by one or more AI accelerators, a neural compute stick, neuromorphic hardware, an FPGA, an arrangement of GPUs, one or more SoCs (including programmable SoCs), one or more CPUs, one or more digital signal processors, dedicated ASICs (including programmable ASICs), PLDs such as CPLDs or HCPLDs, and/or other forms of specialized processors or circuitry designed to accomplish one or more specialized tasks. These tasks may include AI processing (including machine learning, training, inferencing, and classification operations), visual data processing, network data processing, object detection, rule analysis, or the like. In FPGA-based implementations, the acceleration circuitry <b>1464</b> may comprise logic blocks or logic fabric and other interconnected resources that may be programmed (configured) to perform various functions, such as the procedures, methods, functions, etc. discussed herein. In such implementations, the acceleration circuitry <b>1464</b> may also include memory cells (e.g., EPROM, EEPROM, flash memory, static memory (e.g., SRAM, anti-fuses, etc.) used to store logic blocks, logic fabric, data, etc. in LUTs and the like.</p><p id="p-0220" num="0203">The IX <b>1456</b> also couples the processor <b>1452</b> to a sensor hub or external interface <b>1470</b> that is used to connect additional devices or subsystems. The additional/external devices may include sensors <b>1472</b>, actuators <b>1474</b>, and positioning circuitry <b>1475</b>. The sensor circuitry <b>1472</b> includes devices, modules, or subsystems whose purpose is to detect events or changes in its environment and send the information (sensor data) about the detected events to some other a device, module, subsystem, etc. Examples of such sensors <b>1472</b> include, inter alia, inertia measurement units (IMU) comprising accelerometers, gyroscopes, and/or magnetometers; microelectromechanical systems (MEMS) or nanoelectromechanical systems (NEMS) comprising 3-axis accelerometers, 3-axis gyroscopes, and/or magnetometers; level sensors; flow sensors; temperature sensors (e.g., thermistors, including sensors for measuring the temperature of internal components and sensors for measuring temperature external to the compute node <b>1450</b>); pressure sensors; barometric pressure sensors; gravimeters; altimeters; image capture devices (e.g., cameras); light detection and ranging (LiDAR) sensors; proximity sensors (e.g., infrared radiation detector and the like); depth sensors, ambient light sensors; optical light sensors; ultrasonic transceivers; microphones; and/or the like.</p><p id="p-0221" num="0204">The actuators <b>1474</b>, allow platform <b>1450</b> to change its state, position, and/or orientation, or move or control a mechanism or system. The actuators <b>1474</b> comprise electrical and/or mechanical devices for moving or controlling a mechanism or system, and converts energy (e.g., electric current or moving air and/or liquid) into some kind of motion. The actuators <b>1474</b> may include one or more electronic (or electrochemical) devices, such as piezoelectric biomorphs, solid state actuators, solid state relays (SSRs), shape-memory alloy-based actuators, electroactive polymer-based actuators, relay driver integrated circuits (ICs), and/or the like. The actuators <b>1474</b> may include one or more electromechanical devices such as pneumatic actuators, hydraulic actuators, electromechanical switches including electromechanical relays (EMRs), motors (e.g., DC motors, stepper motors, servomechanisms, etc.), power switches, valve actuators, wheels, thrusters, propellers, claws, clamps, hooks, audible sound generators, visual warning devices, and/or other like electromechanical components. The platform <b>1450</b> may be configured to operate one or more actuators <b>1474</b> based on one or more captured events and/or instructions or control signals received from a service provider and/or various client systems.</p><p id="p-0222" num="0205">The positioning circuitry <b>1475</b> includes circuitry to receive and decode signals transmitted/broadcasted by a positioning network of a global navigation satellite system (GNSS). Examples of navigation satellite constellations (or GNSS) include United States' Global Positioning System (GPS), Russia's Global Navigation System (GLONASS), the European Union's Galileo system, China's BeiDou Navigation Satellite System, a regional navigation system or GNSS augmentation system (e.g., Navigation with Indian Constellation (NAVIC), Japan's Quasi-Zenith Satellite System (QZSS), France's Doppler Orbitography and Radio-positioning Integrated by Satellite (DORIS), etc.), or the like. The positioning circuitry <b>1475</b> comprises various hardware elements (e.g., including hardware devices such as switches, filters, amplifiers, antenna elements, and the like to facilitate OTA communications) to communicate with components of a positioning network, such as navigation satellite constellation nodes. Additionally or alternatively, the positioning circuitry <b>1475</b> may include a Micro-Technology for Positioning, Navigation, and Timing (Micro-PNT) IC that uses a master timing clock to perform position tracking/estimation without GNSS assistance. The positioning circuitry <b>1475</b> may also be part of, or interact with, the communication circuitry <b>1466</b> to communicate with the nodes and components of the positioning network. The positioning circuitry <b>1475</b> may also provide position data and/or time data to the application circuitry, which may use the data to synchronize operations with various infrastructure (e.g., radio base stations), for turn-by-turn navigation, or the like. When a GNSS signal is not available or when GNSS position accuracy is not sufficient for a particular application or service, a positioning augmentation technology can be used to provide augmented positioning information and data to the application or service. Such a positioning augmentation technology may include, for example, satellite based positioning augmentation (e.g., EGNOS) and/or ground based positioning augmentation (e.g., DGPS). In some implementations, the positioning circuitry <b>1475</b> is, or includes an INS, which is a system or device that uses sensor circuitry <b>1472</b> (e.g., motion sensors such as accelerometers, rotation sensors such as gyroscopes, and altimeters, magnetic sensors, and/or the like to continuously calculate (e.g., using dead by dead reckoning, triangulation, or the like) a position, orientation, and/or velocity (including direction and speed of movement) of the platform <b>1450</b> without the need for external references.</p><p id="p-0223" num="0206">In some optional examples, various input/output (I/O) devices may be present within or connected to, the compute node <b>1450</b>, which are referred to as input circuitry <b>1486</b> and output circuitry <b>1484</b> in <figref idref="DRAWINGS">FIG. <b>14</b></figref>. The input circuitry <b>1486</b> and output circuitry <b>1484</b> include one or more user interfaces designed to enable user interaction with the platform <b>1450</b> and/or peripheral component interfaces designed to enable peripheral component interaction with the platform <b>1450</b>. Input circuitry <b>1486</b> may include any physical or virtual means for accepting an input including, inter alia, one or more physical or virtual buttons (e.g., a reset button), a physical keyboard, keypad, mouse, touchpad, touchscreen, microphones, scanner, headset, and/or the like. The output circuitry <b>1484</b> may be included to show information or otherwise convey information, such as sensor readings, actuator position(s), or other like information. Data and/or graphics may be displayed on one or more user interface components of the output circuitry <b>1484</b>. Output circuitry <b>1484</b> may include any number and/or combinations of audio or visual display, including, inter alia, one or more simple visual outputs/indicators (e.g., binary status indicators (e.g., light emitting diodes (LEDs)) and multi-character visual outputs, or more complex outputs such as display devices or touchscreens (e.g., Liquid Chrystal Displays (LCD), LED displays, quantum dot displays, projectors, etc.), with the output of characters, graphics, multimedia objects, and the like being generated or produced from the operation of the platform <b>1450</b>. The output circuitry <b>1484</b> may also include speakers or other audio emitting devices, printer(s), and/or the like. Additionally or alternatively, the sensor circuitry <b>1472</b> may be used as the input circuitry <b>1484</b> (e.g., an image capture device, motion capture device, or the like) and one or more actuators <b>1474</b> may be used as the output device circuitry <b>1484</b> (e.g., an actuator to provide haptic feedback or the like). In another example, near-field communication (NFC) circuitry comprising an NFC controller coupled with an antenna element and a processing device may be included to read electronic tags and/or connect with another NFC-enabled device. Peripheral component interfaces may include, but are not limited to, a non-volatile memory port, a USB port, an audio jack, a power supply interface, etc. A display or console hardware, in the context of the present system, may be used to provide output and receive input of an edge computing system; to manage components or services of an edge computing system; identify a state of an edge computing component or service; or to conduct any other number of management or administration functions or service use cases.</p><p id="p-0224" num="0207">A battery <b>1476</b> may power the compute node <b>1450</b>, although, in examples in which the compute node <b>1450</b> is mounted in a fixed location, it may have a power supply coupled to an electrical grid, or the battery may be used as a backup or for temporary capabilities. The battery <b>1476</b> may be a lithium ion battery, or a metal-air battery, such as a zinc-air battery, an aluminum-air battery, a lithium-air battery, and the like.</p><p id="p-0225" num="0208">A battery monitor/charger <b>1478</b> may be included in the compute node <b>1450</b> to track the state of charge (SoCh) of the battery <b>1476</b>, if included. The battery monitor/charger <b>1478</b> may be used to monitor other parameters of the battery <b>1476</b> to provide failure predictions, such as the state of health (SoH) and the state of function (SoF) of the battery <b>1476</b>. The battery monitor/charger <b>1478</b> may include a battery monitoring integrated circuit, such as an LTC4020 or an LTC2990 from Linear Technologies, an ADT7488A from ON Semiconductor of Phoenix Ariz., or an IC from the UCD90xxx family from Texas Instruments of Dallas, Tex. The battery monitor/charger <b>1478</b> may communicate the information on the battery <b>1476</b> to the processor <b>1452</b> over the IX <b>1456</b>. The battery monitor/charger <b>1478</b> may also include an analog-to-digital (ADC) converter that enables the processor <b>1452</b> to directly monitor the voltage of the battery <b>1476</b> or the current flow from the battery <b>1476</b>. The battery parameters may be used to determine actions that the compute node <b>1450</b> may perform, such as transmission frequency, mesh network operation, sensing frequency, and the like.</p><p id="p-0226" num="0209">A power block <b>1480</b>, or other power supply coupled to a grid, may be coupled with the battery monitor/charger <b>1478</b> to charge the battery <b>1476</b>. In some examples, the power block <b>1480</b> may be replaced with a wireless power receiver to obtain the power wirelessly, for example, through a loop antenna in the compute node <b>1450</b>. A wireless battery charging circuit, such as an LTC4020 chip from Linear Technologies of Milpitas, Calif., among others, may be included in the battery monitor/charger <b>1478</b>. The specific charging circuits may be selected based on the size of the battery <b>1476</b>, and thus, the current required. The charging may be performed using the Airfuel standard promulgated by the Airfuel Alliance, the Qi wireless charging standard promulgated by the Wireless Power Consortium, or the Rezence charging standard, promulgated by the Alliance for Wireless Power, among others.</p><p id="p-0227" num="0210">The storage <b>1458</b> may include instructions <b>1483</b> in the form of software, firmware, or hardware commands to implement the techniques described herein. Although such instructions <b>1482</b>, <b>1483</b> are shown as code blocks included in the memory <b>1454</b> and the storage <b>1458</b>, any of the code blocks <b>1482</b>, <b>1483</b> may be replaced with hardwired circuits, for example, built into an application specific integrated circuit (ASIC) or programmed into an FPGA, or the like.</p><p id="p-0228" num="0211">In an example, the instructions <b>1481</b>, <b>1482</b>, <b>1483</b> provided via the memory <b>1454</b>, the storage <b>1458</b>, or the processor <b>1452</b> may be embodied as a non-transitory machine-readable medium (NTMRM) <b>1460</b> including code to direct the processor <b>1452</b> to perform electronic operations in the compute node <b>1450</b>. The processor <b>1452</b> may access the NTMRM <b>1460</b> over the IX <b>1456</b>. For instance, the NTMRM <b>1460</b> may be embodied by devices described for the storage <b>1458</b> or may include specific storage units such as storage devices and/or storage disks that include optical disks (e.g., digital versatile disk (DVD), compact disk (CD), CD-ROM, Blu-ray disk), flash drives, floppy disks, hard drives (e.g., SSDs), or any number of other hardware devices in which information is stored for any duration (e.g., for extended time periods, permanently, for brief instances, for temporarily buffering, and/or caching). The NTMRM <b>1460</b> may include instructions to direct the processor <b>1452</b> to perform a specific sequence or flow of actions, for example, as described with respect to the flowchart(s) and block diagram(s) of operations and functionality depicted above. As used herein, the terms &#x201c;machine-readable medium&#x201d; and &#x201c;computer-readable medium&#x201d; are interchangeable. As used herein, the term &#x201c;non-transitory computer-readable medium&#x201d; is expressly defined to include any type of computer readable storage device and/or storage disk and to exclude propagating signals and to exclude transmission media.</p><p id="p-0229" num="0212">Computer program code for carrying out operations of the present disclosure (e.g., computational logic and/or instructions <b>1481</b>, <b>1482</b>, <b>1483</b>) may be written in any combination of one or more programming languages, including an object oriented programming language such as Python, Ruby, Scala, Smalltalk, Java&#x2122;, C++, C#, or the like; a procedural programming languages, such as the &#x201c;C&#x201d; programming language, the Go (or &#x201c;Golang&#x201d;) programming language, or the like; a scripting language such as JavaScript, Server-Side JavaScript (SSJS), JQuery, PHP, Pearl, Python, Ruby on Rails, Accelerated Mobile Pages Script (AMPscript), Mustache Template Language, Handlebars Template Language, Guide Template Language (GTL), PHP, Java and/or Java Server Pages (JSP), Node.js, ASP.NET, JAMscript, and/or the like; a markup language such as Hypertext Markup Language (HTML), Extensible Markup Language (XML), Java Script Object Notion (JSON), Apex&#xae;, Cascading Stylesheets (CSS), JavaServer Pages (JSP), MessagePack&#x2122;, Apache&#xae; Thrift, Abstract Syntax Notation One (ASN.1), Google&#xae; Protocol Buffers (protobuf), or the like; some other suitable programming languages including proprietary programming languages and/or development tools, or any other languages tools. The computer program code <b>1481</b>, <b>1482</b>, <b>1483</b> for carrying out operations of the present disclosure may also be written in any combination of the programming languages discussed herein. The program code may execute entirely on the system <b>1450</b>, partly on the system <b>1450</b>, as a stand-alone software package, partly on the system <b>1450</b> and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the system <b>1450</b> through any type of network, including a LAN or WAN, or the connection may be made to an external computer (e.g., through the Internet using an Internet Service Provider (ISP)).</p><p id="p-0230" num="0213">In an example, the instructions <b>1481</b>, <b>1482</b>, <b>1483</b> on the processor circuitry <b>1452</b> (separately, or in combination with the instructions <b>1481</b>, <b>1482</b>, <b>1483</b>) may configure execution or operation of a trusted execution environment (TEE) <b>1490</b>. The TEE <b>1490</b> operates as a protected area accessible to the processor circuitry <b>1402</b> to enable secure access to data and secure execution of instructions. In some embodiments, the TEE <b>1490</b> may be a physical hardware device that is separate from other components of the system <b>1450</b> such as a secure-embedded controller, a dedicated SoC, or a tamper-resistant chipset or microcontroller with embedded processing devices and memory devices. Examples of such embodiments include a Desktop and mobile Architecture Hardware (DASH) compliant Network Interface Card (NIC), Intel&#xae; Management/Manageability Engine, Intel&#xae; Converged Security Engine (CSE) or a Converged Security Management/Manageability Engine (CSME), Trusted Execution Engine (TXE) provided by Intel&#xae; each of which may operate in conjunction with Intel&#xae; Active Management Technology (AMT) and/or Intel&#xae; vPro&#x2122; Technology; AMD&#xae; Platform Security coProcessor (PSP), AMD&#xae; PRO A-Series Accelerated Processing Unit (APU) with DASH manageability, Apple&#xae; Secure Enclave coprocessor; IBM&#xae; Crypto Express3&#xae;, IBM&#xae; 4807, 4808, 4809, and/or 4765 Cryptographic Coprocessors, IBM&#xae; Baseboard Management Controller (BMC) with Intelligent Platform Management Interface (IPMI), Dell&#x2122; Remote Assistant Card II (DRAC II), integrated Dell&#x2122; Remote Assistant Card (iDRAC), and the like.</p><p id="p-0231" num="0214">Additionally or alternatively, the TEE <b>1490</b> may be implemented as secure enclaves, which are isolated regions of code and/or data within the processor and/or memory/storage circuitry of the system <b>1450</b>. Only code executed within a secure enclave may access data within the same secure enclave, and the secure enclave may only be accessible using the secure application (which may be implemented by an application processor or a tamper-resistant microcontroller). Various implementations of the TEE <b>1490</b>, and an accompanying secure area in the processor circuitry <b>1452</b> or the memory circuitry <b>1454</b> and/or storage circuitry <b>1458</b> may be provided, for instance, through use of Intel&#xae; Software Guard Extensions (SGX), ARM&#xae; TrustZone&#xae; hardware security extensions, Keystone Enclaves provided by Oasis Labs&#x2122;, and/or the like. Other aspects of security hardening, hardware roots-of-trust, and trusted or protected operations may be implemented in the device <b>1400</b> through the TEE <b>1490</b> and the processor circuitry <b>1452</b>. Additionally or alternatively, the memory circuitry <b>1454</b> and/or storage circuitry <b>1458</b> may be divided into isolated user-space instances such as containers, partitions, virtual environments (VEs), etc. The isolated user-space instances may be implemented using a suitable OS-level virtualization technology such as Docker&#xae; containers, Kubernetes&#xae; containers, Solaris&#xae; containers and/or zones, OpenVZ&#xae; virtual private servers, DragonFly BSD&#xae; virtual kernels and/or jails, chroot jails, and/or the like. Virtual machines could also be used in some implementations. In some embodiments, the memory circuitry <b>1404</b> and/or storage circuitry <b>1408</b> may be divided into one or more trusted memory regions for storing applications or software modules of the TEE <b>1490</b>.</p><p id="p-0232" num="0215">In further examples, a machine-readable medium also includes any tangible medium that is capable of storing, encoding or carrying instructions for execution by a machine and that cause the machine to perform any one or more of the methodologies of the present disclosure or that is capable of storing, encoding or carrying data structures utilized by or associated with such instructions. A &#x201c;machine-readable medium&#x201d; thus may include but is not limited to, solid-state memories, and optical and magnetic media. Specific examples of machine-readable media include non-volatile memory, including but not limited to, by way of example, semiconductor memory devices (e.g., electrically programmable read-only memory (EPROM), electrically erasable programmable read-only memory (EEPROM)) and flash memory devices; magnetic disks such as internal hard disks and removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The instructions embodied by a machine-readable medium may further be transmitted or received over a communications network using a transmission medium via a network interface device utilizing any one of a number of transfer protocols (e.g., HTTP).</p><p id="p-0233" num="0216">A machine-readable medium may be provided by a storage device or other apparatus which is capable of hosting data in a non-transitory format. In an example, information stored or otherwise provided on a machine-readable medium may be representative of instructions, such as instructions themselves or a format from which the instructions may be derived. This format from which the instructions may be derived may include source code, encoded instructions (e.g., in compressed or encrypted form), packaged instructions (e.g., split into multiple packages), or the like. The information representative of the instructions in the machine-readable medium may be processed by processing circuitry into the instructions to implement any of the operations discussed herein. For example, deriving the instructions from the information (e.g., processing by the processing circuitry) may include: compiling (e.g., from source code, object code, etc.), interpreting, loading, organizing (e.g., dynamically or statically linking), encoding, decoding, encrypting, unencrypting, packaging, unpackaging, or otherwise manipulating the information into the instructions.</p><p id="p-0234" num="0217">In an example, the derivation of the instructions may include assembly, compilation, or interpretation of the information (e.g., by the processing circuitry) to create the instructions from some intermediate or preprocessed format provided by the machine-readable medium. The information, when provided in multiple parts, may be combined, unpacked, and modified to create the instructions. For example, the information may be in multiple compressed source code packages (or object code, or binary executable code, etc.) on one or several remote servers. The source code packages may be encrypted when in transit over a network and decrypted, uncompressed, assembled (e.g., linked) if necessary, and compiled or interpreted (e.g., into a library, stand-alone executable, etc.) at a local machine, and executed by the local machine.</p><p id="p-0235" num="0218"><figref idref="DRAWINGS">FIG. <b>14</b></figref> depicts a high-level view of components of a varying device, subsystem, or arrangement of a compute node. However, some of the components shown may be omitted, additional components may be present, and a different arrangement of the components shown may occur in other implementations. Further, these arrangements are usable in a variety of use cases and environments, including those discussed below (e.g., a mobile UE in industrial compute for smart city or smart factory, among many other examples).</p><p id="p-0236" num="0219">The components of the device <b>1450</b> and/or any of the devices and/or systems discussed herein may be servers, appliances, network infrastructure, machines, robots, drones, and/or any other type of computing devices. For example, an edge cloud may include an appliance computing device that is a self-contained electronic device including a housing, a chassis, a case or a shell. In some circumstances, the housing may be dimensioned for portability such that it can be carried by a human and/or shipped. Alternatively, it may be a smaller module suitable for installation in a vehicle for example. Example housings may include materials that form one or more exterior surfaces that partially or fully protect contents of the appliance, in which protection may include weather protection, hazardous environment protection (e.g., electromagnetic interference (EMI), and/or radio-frequency interference (RFI), electromagnetic radiation, vibration, relatively extreme temperatures, and the like), and/or enable submergibility. Example housings may include power circuitry to provide power for stationary and/or portable implementations, such as AC power inputs, DC power inputs, AC/DC or DC/AC converter(s), power regulators, transformers, charging circuitry, batteries, wired inputs and/or wireless power inputs. Smaller, modular implementations may also include an extendible or embedded antenna arrangement for wireless communications. Example housings and/or surfaces thereof may include or connect to mounting hardware to enable attachment to structures such as buildings, telecommunication structures (e.g., poles, antenna structures, etc.) and/or racks (e.g., server racks, blade mounts, etc.). Example housings and/or surfaces thereof may support one or more sensors (e.g., temperature sensors, vibration sensors, light sensors, acoustic sensors, capacitive sensors, proximity sensors, etc.). One or more such sensors may be contained in, carried by, or otherwise embedded in the surface and/or mounted to the surface of the appliance. Example housings and/or surfaces thereof may support mechanical connectivity, such as propulsion hardware (e.g., wheels, propellers, etc.) and/or articulating hardware (e.g., robot arms, pivotable appendages, etc.). In some circumstances, the sensors may include any type of input devices such as user interface hardware (e.g., buttons, switches, dials, sliders, etc.). In some circumstances, example housings include output devices contained in, carried by, embedded therein and/or attached thereto. Output devices may include displays, touchscreens, lights, LEDs, speakers, I/O ports (e.g., USB), etc. In some circumstances, edge devices are devices presented in the network for a specific purpose (e.g., a traffic light), but may have processing and/or other capacities that may be utilized for other purposes. Such edge devices may be independent from other networked devices and may be provided with a housing having a form factor suitable for its primary purpose; yet be available for other compute tasks that do not interfere with its primary task. Edge devices include Internet of Things devices. The appliance computing device may include hardware and software components to manage local issues such as device temperature, vibration, resource utilization, updates, power issues, physical and network security, etc. Example hardware for implementing an appliance computing device is described in conjunction with <figref idref="DRAWINGS">FIG. <b>14</b></figref>. The edge cloud may also include one or more servers and/or one or more multi-tenant servers. Such a server may include an operating system and implement a virtual computing environment. A virtual computing environment may include a hypervisor managing (e.g., spawning, deploying, destroying, etc.) one or more virtual machines, one or more containers, etc. Such virtual computing environments provide an execution environment in which one or more applications and/or other software, code or scripts may execute while being isolated from one or more other applications, software, code or scripts.</p><heading id="h-0008" level="1">4. Example Implementations</heading><p id="p-0237" num="0220">Additional examples of the presently described methods, devices, systems, and networks discussed herein include the following, non-limiting implementations. Each of the following non-limiting examples may stand on its own or may be combined in any permutation or combination with any one or more of the other examples provided below or throughout the present disclosure.</p><p id="p-0238" num="0221">Example 1 includes a method for providing flow-specific slicing, the method comprising: causing instantiation of a virtual lane in a data center network (DCN) to be used for a flow-specific slice for a service hosted by a service provider environment; mapping a network slice instance (NSI) in a communication network (NW) to the instantiated virtual lane; and causing an end-to-end (e2e) connection to be established for the flow-specific slice, wherein the e2e connection is established between a user application operated by a user device and a service provider application operated by the service provider environment, and the flow-specific slice includes the instantiated virtual lane and the NSI based on the mapping.</p><p id="p-0239" num="0222">Example 2 includes the method of example 1 and/or any other example(s) herein, wherein the method includes: sending a request for network slice creation to an NW orchestrator in the NW, wherein the request is to cause the NW orchestrator to create the NSI.</p><p id="p-0240" num="0223">Example 3 includes the method of example 2 and/or any other example(s) herein, wherein the request is to cause the NW orchestrator to instruct a radio access network (RAN) to provision resources for the network slice.</p><p id="p-0241" num="0224">Example 4 includes the method of examples 2-3 and/or any other example(s) herein, wherein the request is to cause the NW orchestrator to instruct a core network (CN) to provision resources for the network slice.</p><p id="p-0242" num="0225">Example 5 includes the method of examples 2-4 and/or any other example(s) herein, wherein the request includes quality of service (QoS) parameters for the flow-specific slice or the NSI.</p><p id="p-0243" num="0226">Example 6 includes the method of example 5 and/or any other example(s) herein, wherein the QoS parameters are based on a service level agreement (SLA) defined for the flow-specific slice.</p><p id="p-0244" num="0227">Example 7 includes the method of examples 2-6 and/or any other example(s) herein, wherein the request includes user information related to the user device.</p><p id="p-0245" num="0228">Example 8 includes the method of examples 2-7 and/or any other example(s) herein, wherein the request includes a length of time or a set of time periods during which the flow-specific slice is to be active or inactive.</p><p id="p-0246" num="0229">Example 9 includes the method of examples 2-8 and/or any other example(s) herein, wherein the method includes: receiving, from the NW orchestrator, a response based on the request for network slice creation, wherein the response includes network slice configuration information for the NSI.</p><p id="p-0247" num="0230">Example 10 includes the method of example 9 and/or any other example(s) herein, wherein the response includes a network slice identifier (ID) assigned to the NSI.</p><p id="p-0248" num="0231">Example 11 includes the method of examples 9-10 and/or any other example(s) herein, wherein the method includes: provisioning the service provider application with a flow-specific slice configuration based on the network slice configuration information.</p><p id="p-0249" num="0232">Example 12 includes the method of example 11 and/or any other example(s) herein, wherein the method includes: receiving network slice feedback from the NW, wherein the feedback includes metrics related to operation of the network slice in the NW; updating the flow-specific slice configuration based on the received feedback; and provisioning the service provider application with the updated flow-specific slice configuration, wherein the updated flow-specific slice configuration is to cause changes to QoS parameters of the flow-specific slice or cause changes to resources allocated to the flow-specific slice.</p><p id="p-0250" num="0233">Example 13 includes the method of examples 1-12 and/or any other example(s) herein, wherein the flow-specific slice belongs to a data flow, and flow-specific packets belonging to the data flow are communicated between the user application and the service provider application in the flow-specific slice.</p><p id="p-0251" num="0234">Example 14 includes the method of example 13 and/or any other example(s) herein, wherein the method includes: determining whether received packets belong to the data flow based on metadata included in the received packets.</p><p id="p-0252" num="0235">Example 15 includes the method of example 14 and/or any other example(s) herein, wherein the determining whether received packets belong to the data flow includes: extracting the metadata from the received packets; comparing the extracted metadata with flow-specific slice information of the flow-specific slice; and routing the received packets to be sent over the flow-specific slice when the extracted metadata matches the flow-specific slice information.</p><p id="p-0253" num="0236">Example 16 includes the method of example 15 and/or any other example(s) herein, wherein a service mesh is used to route the received packets to the service provider application, and route packets processed by the service provider application to the flow-specific slice.</p><p id="p-0254" num="0237">Example 17 includes the method of example 13 and/or any other example(s) herein, wherein the method includes: receiving packets from the service provider application that belong to the data flow; and inserting metadata into the received packets, wherein the inserted metadata is to cause the received packets to be routed through the flow-specific slice to the user application.</p><p id="p-0255" num="0238">Example 18 includes the method of examples 14-17 and/or any other example(s) herein, wherein the metadata includes a flow-specific slice ID assigned to the flow-specific slice.</p><p id="p-0256" num="0239">Example 19 includes the method of examples 14-18 and/or any other example(s) herein, wherein the metadata includes a network operator ID assigned to the NW.</p><p id="p-0257" num="0240">Example 20 includes the method of examples 18-19 and/or any other example(s) herein, wherein the metadata is included in a header section of the received packets or included in a payload section of the received packets.</p><p id="p-0258" num="0241">Example 21 includes the method of examples 2-20 and/or any other example(s) herein, wherein the NW orchestrator is one or more of an RAN intelligent controller (RIC) in an Open RAN Alliance (O-RAN) framework; a Network Slice Management Function (NSMF) in a Third Generation Partnership Project (3GPP) Fifth Generation (5G) system, a 3GPP 5G Network Slice Orchestrator, a Zero-touch System Management (ZSM) function in a ZSM framework, an Open Network Automation Platform (ONAP) module in an ONAP framework, a Network Slice Controller in an IETF Network Slice framework, a Network Slice Orchestrator in an IETF Network Slice framework, and a container orchestration engine in a containerization framework.</p><p id="p-0259" num="0242">Example 22 includes the method of examples 1-21 and/or any other example(s) herein, wherein the NW is a cellular network or a wireless local area network (WLAN).</p><p id="p-0260" num="0243">Example 23 includes the method of example 22 and/or any other example(s) herein, wherein the cellular network is a 3GPP 5G network or a 3GPP LTE network, and the WLAN network is a WiFi network.</p><p id="p-0261" num="0244">Example 24 includes the method of examples 1-23 and/or any other example(s) herein, wherein the DCN includes a cloud computing service or an edge computing network.</p><p id="p-0262" num="0245">Example 25 includes the method of examples 1-24 and/or any other example(s) herein, wherein the method is performed by a service provider orchestrator in the service provider environment or a DCN orchestrator in the DCN.</p><p id="p-0263" num="0246">Example 26 includes the method of example 25 and/or any other example(s) herein, wherein the service provider orchestrator is one or more of a RIC in an O-RAN framework; an NSMF in a 3GPP 5G system, a Network Slice Orchestrator in a 3GPP 5G system, a ZSM function in a ZSM framework, an ONAP module in an ONAP framework, a Network Slice Controller in an IETF Network Slice framework, a Network Slice Orchestrator in an IETF Network Slice framework, and a container orchestration engine in a containerization framework.</p><p id="p-0264" num="0247">Example 27 includes the method of examples 25-26 and/or any other example(s) herein, wherein the DCN orchestrator is one or more of a RIC in an O-RAN framework; an NSMF in a 3GPP 5G system, a Network Slice Orchestrator in a 3GPP 5G system, a ZSM function in a ZSM framework, an ONAP module in an ONAP framework, a Network Slice Controller in an IETF Network Slice framework, a Network Slice Orchestrator in an IETF Network Slice framework, and a container orchestration engine in a containerization framework.</p><p id="p-0265" num="0248">Example 28 includes the method of examples 1-27 and/or any other example(s) herein, wherein a first end of the e2e connection is the user application and a second end of the e2e connection is the service provider application.</p><p id="p-0266" num="0249">Example 29 includes the method of example 28 and/or any other example(s) herein, wherein the service provider application is a cloud computing service or an application operated by one or more cloud compute nodes.</p><p id="p-0267" num="0250">Example 30 includes the method of example 28 and/or any other example(s) herein, wherein the service provider application is an edge computing application operated by one or more edge compute nodes.</p><p id="p-0268" num="0251">Example 31 includes the method of example 28 and/or any other example(s) herein, wherein the service provider application is a radio access network (RAN) function operated by one or more RAN nodes in a RAN.</p><p id="p-0269" num="0252">Example 32 includes the method of example 31 and/or any other example(s) herein, wherein the RAN belongs to the NW.</p><p id="p-0270" num="0253">Example 33 includes the method of example 28 and/or any other example(s) herein, wherein the service provider application is a network function within a core network of the NW.</p><p id="p-0271" num="0254">Example 34 includes the method of example 28 and/or any other example(s) herein, wherein the service provider application is a network function within a core network of the NW.</p><p id="p-0272" num="0255">Example 35 includes the method of examples 1-34 and/or any other example(s) herein, wherein the service provider environment is an edge computing network including at least one edge compute node.</p><p id="p-0273" num="0256">Example 36 includes the method of example 35 and/or any other example(s) herein, wherein the edge compute node is co-located with a RAN node.</p><p id="p-0274" num="0257">Example 37 includes the method of examples 1-34 and/or any other example(s) herein, wherein the service provider environment is a cloud computing service or a cluster of cloud compute nodes in the cloud computing service.</p><p id="p-0275" num="0258">Example 38 includes the method of examples 1-34 and/or any other example(s) herein, wherein the service provider environment includes a cluster of cloud compute nodes of a cloud computing service and a set of edge compute nodes in an edge computing network.</p><p id="p-0276" num="0259">Example 39 includes the method of examples 1-34 and/or any other example(s) herein, wherein the service provider environment is an edge cloud including a set of edge compute nodes and a cloud data center.</p><p id="p-0277" num="0260">Example 40 includes the method of examples 1-34 and/or any other example(s) herein, wherein the service provider environment is a RAN.</p><p id="p-0278" num="0261">Example 41 includes the method of examples 1-40 and/or any other example(s) herein, wherein the service provider environment includes a set of servers within the DCN, wherein zero or more servers of the set of servers within the DCN are virtual machines.</p><p id="p-0279" num="0262">Example 42 includes the method of example 41 and/or any other example(s) herein, wherein the DCN is an edge data center implemented by one or more edge compute nodes.</p><p id="p-0280" num="0263">Example 43 includes the method of examples 41-42 and/or any other example(s) herein, wherein the DCN is part of a cloud computing service.</p><p id="p-0281" num="0264">Example 44 includes one or more computer readable media comprising instructions, wherein execution of the instructions by processor circuitry is to cause the processor circuitry to perform the method of any of examples 1-43 and/or any other example(s) herein. Example 45 includes a computer program comprising the instructions of example 44 and/or any other example(s) herein. Example 46 includes an Application Programming Interface defining functions, methods, variables, data structures, and/or protocols for the computer program of example 45 and/or any other example(s) herein. Example 47 includes an apparatus comprising circuitry loaded with the instructions of example 44 and/or any other example(s) herein. Example 48 includes an apparatus comprising circuitry operable to run the instructions of example 44 and/or any other example(s) herein. Example 49 includes an integrated circuit comprising one or more of the processor circuitry and the one or more computer readable media of example 44 and/or any other example(s) herein. Example 50 includes a computing system comprising the one or more computer readable media and the processor circuitry of example 44 and/or any other example(s) herein. Example 51 includes an apparatus comprising means for executing the instructions of example 44 and/or any other example(s) herein. Example 52 includes a signal generated as a result of executing the instructions of example 44 and/or any other example(s) herein. Example 53 includes a data unit generated as a result of executing the instructions of example 44 and/or any other example(s) herein, wherein the data unit is a datagram, network packet, data frame, data segment, a Protocol Data Unit (PDU), a Service Data Unit (SDU), a message, or a database object. Example 54 includes a signal encoded with the data unit of example 53 and/or any other example(s) herein. Example 55 includes an electromagnetic signal carrying the instructions of example 44 and/or any other example(s) herein. Example 56 includes an apparatus comprising means for performing the method of any of examples 1-43 and/or any other example(s) herein.</p><heading id="h-0009" level="1">5. Terminology</heading><p id="p-0282" num="0265">As used herein, the singular forms &#x201c;a,&#x201d; &#x201c;an&#x201d; and &#x201c;the&#x201d; are intended to include plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms &#x201c;comprises&#x201d; and/or &#x201c;comprising,&#x201d; when used in this specification, specific the presence of stated features, integers, steps, operations, elements, and/or components, but do not preclude the presence or addition of one or more other features, integers, steps, operation, elements, components, and/or groups thereof. The phrase &#x201c;A and/or B&#x201d; means (A), (B), or (A and B). For the purposes of the present disclosure, the phrase &#x201c;A, B, and/or C&#x201d; means (A), (B), (C), (A and B), (A and C), (B and C), or (A, B and C). The description may use the phrases &#x201c;in an embodiment,&#x201d; or &#x201c;In some embodiments,&#x201d; each of which may refer to one or more of the same or different embodiments. Furthermore, the terms &#x201c;comprising,&#x201d; &#x201c;including,&#x201d; &#x201c;having,&#x201d; and the like, as used with respect to the present disclosure, are synonymous.</p><p id="p-0283" num="0266">The terms &#x201c;coupled,&#x201d; &#x201c;communicatively coupled,&#x201d; along with derivatives thereof are used herein. The term &#x201c;coupled&#x201d; at least in some examples refers to two or more elements are in direct physical or electrical contact with one another, may mean that two or more elements indirectly contact each other but still cooperate or interact with each other, and/or may mean that one or more other elements are coupled or connected between the elements that are said to be coupled with each other. The term &#x201c;directly coupled&#x201d; may mean that two or more elements are in direct contact with one another. The term &#x201c;communicatively coupled&#x201d; may mean that two or more elements may be in contact with one another by a means of communication including through a wire or other interconnect connection, through a wireless communication channel or ink, and/or the like.</p><p id="p-0284" num="0267">The term &#x201c;colocated&#x201d; or &#x201c;co-located&#x201d; at least in some examples refers to two or more elements being in the same place or location, or relatively close to one another (e.g., within some predetermined distance from one another). Additionally or alternatively, the term &#x201c;colocated&#x201d; or &#x201c;co-located&#x201d; at least in some examples refers to the placement or deployment of two or more compute elements or compute nodes together in a secure dedicated storage facility, or within a same enclosure or housing.</p><p id="p-0285" num="0268">The term &#x201c;establish&#x201d; or &#x201c;establishment&#x201d; at least in some examples refers to (partial or in full) acts, tasks, operations, etc., related to bringing or the readying the bringing of something into existence either actively or passively (e.g., exposing a device identity or entity identity). Additionally or alternatively, the term &#x201c;establish&#x201d; or &#x201c;establishment&#x201d; at least in some examples refers to (partial or in full) acts, tasks, operations, etc., related to initiating, starting, or warming communication or initiating, starting, or warming a relationship between two entities or elements (e.g., establish a session, establish a session, etc.). Additionally or alternatively, the term &#x201c;establish&#x201d; or &#x201c;establishment&#x201d; at least in some examples refers to initiating something to a state of working readiness. The term &#x201c;established&#x201d; at least in some examples refers to a state of being operational or ready for use (e.g., full establishment). Furthermore, any definition for the term &#x201c;establish&#x201d; or &#x201c;establishment&#x201d; defined in any specification or standard can be used for purposes of the present disclosure and such definitions are not disavowed by any of the aforementioned definitions.</p><p id="p-0286" num="0269">The term &#x201c;obtain&#x201d; at least in some examples refers to (partial or in full) acts, tasks, operations, etc., of intercepting, movement, copying, retrieval, or acquisition (e.g., from a memory, an interface, or a buffer), on the original packet stream or on a copy (e.g., a new instance) of the packet stream. Other aspects of obtaining or receiving may involving instantiating, enabling, or controlling the ability to obtain or receive the stream of packets (or the following parameters and templates or template values).</p><p id="p-0287" num="0270">The term &#x201c;receipt&#x201d; at least in some examples refers to any action (or set of actions) involved with receiving or obtaining an object, data, data unit, etc., and/or the fact of the object, data, data unit, etc. being received. The term &#x201c;receipt&#x201d; at least in some examples refers to an object, data, data unit, and the like, being pushed to a device, system, element, etc. (e.g., often referred to as a push model), pulled by a device, system, element, etc. (e.g., often referred to as a pull model), and/or the like.</p><p id="p-0288" num="0271">The term &#x201c;element&#x201d; at least in some examples refers to a unit that is indivisible at a given level of abstraction and has a clearly defined boundary, wherein an element may be any type of entity including, for example, one or more devices, systems, controllers, network elements, modules, etc., or combinations thereof.</p><p id="p-0289" num="0272">The term &#x201c;measurement&#x201d; at least in some examples refers to the observation and/or quantification of attributes of an object, event, or phenomenon. Additionally or alternatively, the term &#x201c;measurement&#x201d; at least in some examples refers to a set of operations having the object of determining a measured value or measurement result, and/or the actual instance or execution of operations leading to a measured value.</p><p id="p-0290" num="0273">The term &#x201c;signal&#x201d; at least in some examples refers to an observable change in a quality and/or quantity. Additionally or alternatively, the term &#x201c;signal&#x201d; at least in some examples refers to a function that conveys information about of an object, event, or phenomenon. Additionally or alternatively, the term &#x201c;signal&#x201d; at least in some examples refers to any time varying voltage, current, or electromagnetic wave that may or may not carry information. The term &#x201c;digital signal&#x201d; at least in some examples refers to a signal that is constructed from a discrete set of waveforms of a physical quantity so as to represent a sequence of discrete values.</p><p id="p-0291" num="0274">The term &#x201c;lightweight&#x201d; or &#x201c;lite&#x201d; at least in some examples refers to an application or computer program designed to use a relatively small amount of resources such as having a relatively small memory footprint, low processor usage, and/or overall low usage of system resources. The term &#x201c;lightweight protocol&#x201d; at least in some examples refers to a communication protocol that is characterized by a relatively small overhead. Additionally or alternatively, the term &#x201c;lightweight protocol&#x201d; at least in some examples refers to a protocol that provides the same or enhanced services as a standard protocol, but performs faster than standard protocols, has lesser overall size in terms of memory footprint, uses data compression techniques for processing and/or transferring data, drops or eliminates data deemed to be nonessential or unnecessary, and/or uses other mechanisms to reduce overall overheard and/or footprint.</p><p id="p-0292" num="0275">The term &#x201c;identifier&#x201d; at least in some examples refers to a value, or a set of values, that uniquely identify an identity in a certain scope. Additionally or alternatively, the term &#x201c;identifier&#x201d; at least in some examples refers to a sequence of characters that identifies or otherwise indicates the identity of a unique object, element, or entity, or a unique class of objects, elements, or entities. Additionally or alternatively, the term &#x201c;identifier&#x201d; at least in some examples refers to a sequence of characters used to identify or refer to an application, program, session, object, element, entity, variable, set of data, and/or the like. The &#x201c;sequence of characters&#x201d; mentioned previously at least in some examples refers to one or more names, labels, words, numbers, letters, symbols, and/or any combination thereof. Additionally or alternatively, the term &#x201c;identifier&#x201d; at least in some examples refers to a name, address, label, distinguishing index, and/or attribute. Additionally or alternatively, the term &#x201c;identifier&#x201d; at least in some examples refers to an instance of identification. The term &#x201c;persistent identifier&#x201d; at least in some examples refers to an identifier that is reused by a device or by another device associated with the same person or group of persons for an indefinite period.</p><p id="p-0293" num="0276">The term &#x201c;identification&#x201d; at least in some examples refers to a process of recognizing an identity as distinct from other identities in a particular scope or context, which may involve processing identifiers to reference an identity in an identity database.</p><p id="p-0294" num="0277">The terms &#x201c;ego&#x201d; (as in, e.g., &#x201c;ego device&#x201d;) and &#x201c;subject&#x201d; (as in, e.g., &#x201c;data subject&#x201d;) at least in some examples refers to an entity, element, device, system, etc., that is under consideration or being considered. The terms &#x201c;neighbor&#x201d; and &#x201c;proximate&#x201d; (as in, e.g., &#x201c;proximate device&#x201d;) at least in some examples refers to an entity, element, device, system, etc., other than an ego device or subject device.</p><p id="p-0295" num="0278">The term &#x201c;network path&#x201d; or &#x201c;path&#x201d; at least in some examples refers to a data communications feature of a communication system describing the sequence and identity of system components visited by one or more packets, where the components of the path may be either logical or physical. The term &#x201c;network forwarding path&#x201d; at least in some examples refers to an ordered list of connection points forming a chain of NFs and/or nodes, along with policies associated to the list.</p><p id="p-0296" num="0279">The term &#x201c;circuitry&#x201d; at least in some examples refers to a circuit or system of multiple circuits configured to perform a particular function in an electronic device. The circuit or system of circuits may be part of, or include one or more hardware components, such as a logic circuit, a processor (shared, dedicated, or group) and/or memory (shared, dedicated, or group), an application-specific integrated circuit (ASIC), field-programmable gate array (FPGA), programmable logic controller (PLC), system on chip (SoC), system in package (SiP), multi-chip package (MCP), digital signal processor (DSP), etc., that are configured to provide the described functionality. In addition, the term &#x201c;circuitry&#x201d; may also refer to a combination of one or more hardware elements with the program code used to carry out the functionality of that program code. Some types of circuitry may execute one or more software or firmware programs to provide at least some of the described functionality. Such a combination of hardware elements and program code may be referred to as a particular type of circuitry.</p><p id="p-0297" num="0280">The term &#x201c;processor circuitry&#x201d; at least in some examples refers to, is part of, or includes circuitry capable of sequentially and automatically carrying out a sequence of arithmetic or logical operations, or recording, storing, and/or transferring digital data. The term &#x201c;processor circuitry&#x201d; at least in some examples refers to one or more application processors, one or more baseband processors, a physical CPU, a single-core processor, a dual-core processor, a triple-core processor, a quad-core processor, and/or any other device capable of executing or otherwise operating computer-executable instructions, such as program code, software modules, and/or functional processes. The terms &#x201c;application circuitry&#x201d; and/or &#x201c;baseband circuitry&#x201d; may be considered synonymous to, and may be referred to as, &#x201c;processor circuitry.&#x201d;</p><p id="p-0298" num="0281">The term &#x201c;memory&#x201d; and/or &#x201c;memory circuitry&#x201d; at least in some examples refers to one or more hardware devices for storing data, including RAM, MRAM, PRAM, DRAM, and/or SDRAM, core memory, ROM, magnetic disk storage mediums, optical storage mediums, flash memory devices or other machine readable mediums for storing data. The term &#x201c;computer-readable medium&#x201d; may include, but is not limited to, memory, portable or fixed storage devices, optical storage devices, and various other mediums capable of storing, containing or carrying instructions or data. The term &#x201c;memory footprint&#x201d; at least in some examples refers to the amount of memory that a program, application, or other unit of software or program code uses or references while running.</p><p id="p-0299" num="0282">The term &#x201c;interface circuitry&#x201d; at least in some examples refers to, is part of, or includes circuitry that enables the exchange of information between two or more components or devices. The term &#x201c;interface circuitry&#x201d; at least in some examples refers to one or more hardware interfaces, for example, buses, I/O interfaces, peripheral component interfaces, network interface cards, and/or the like.</p><p id="p-0300" num="0283">The term &#x201c;device&#x201d; at least in some examples refers to a physical entity embedded inside, or attached to, another physical entity in its vicinity, with capabilities to convey digital information from or to that physical entity.</p><p id="p-0301" num="0284">The term &#x201c;entity&#x201d; at least in some examples refers to a distinct component of an architecture or device, or information transferred as a payload.</p><p id="p-0302" num="0285">The term &#x201c;controller&#x201d; at least in some examples refers to an element or entity that has the capability to affect a physical entity, such as by changing its state or causing the physical entity to move.</p><p id="p-0303" num="0286">The term &#x201c;terminal&#x201d; at least in some examples refers to point at which a conductor from a component, device, or network comes to an end. Additionally or alternatively, the term &#x201c;terminal&#x201d; at least in some examples refers to an electrical connector acting as an interface to a conductor and creating a point where external circuits can be connected. In some embodiments, terminals may include electrical leads, electrical connectors, electrical connectors, solder cups or buckets, and/or the like.</p><p id="p-0304" num="0287">The term &#x201c;compute node&#x201d; or &#x201c;compute device&#x201d; at least in some examples refers to an identifiable entity implementing an aspect of computing operations, whether part of a larger system, distributed collection of systems, or a standalone apparatus. In some examples, a compute node may be referred to as a &#x201c;computing device&#x201d;, &#x201c;computing system&#x201d;, or the like, whether in operation as a client, server, or intermediate entity. Specific implementations of a compute node may be incorporated into a server, base station, gateway, road side unit, on-premise unit, user equipment, end consuming device, appliance, or the like.</p><p id="p-0305" num="0288">The term &#x201c;computer system&#x201d; at least in some examples refers to any type interconnected electronic devices, computer devices, or components thereof. Additionally, the terms &#x201c;computer system&#x201d; and/or &#x201c;system&#x201d; at least in some examples refer to various components of a computer that are communicatively coupled with one another. Furthermore, the term &#x201c;computer system&#x201d; and/or &#x201c;system&#x201d; at least in some examples refer to multiple computer devices and/or multiple computing systems that are communicatively coupled with one another and configured to share computing and/or networking resources.</p><p id="p-0306" num="0289">The term &#x201c;architecture&#x201d; at least in some examples refers to a computer architecture or a network architecture. The term &#x201c;computer architecture&#x201d; at least in some examples refers to a physical and logical design or arrangement of software and/or hardware elements in a computing system or platform including technology standards for interacts therebetween. The term &#x201c;network architecture&#x201d; at least in some examples refers to a physical and logical design or arrangement of software and/or hardware elements in a network including communication protocols, interfaces, and media transmission.</p><p id="p-0307" num="0290">The term &#x201c;platform&#x201d; at least in some examples refers to an environment in which software, applications, program code, and the like can be executed or otherwise operate. The term &#x201c;platform&#x201d; at least in some examples can include one or more of hardware, virtualized hardware, an embedded system (e.g., IoT device, or the like), an operating system (OS), a virtual machine, a container, a client application (e.g., web browser, mobile app, or the like), a distributed application, a web platform, cloud computing service, APIs, an integrated development environment, a sandbox, and/or other elements that program code is executed in or with.</p><p id="p-0308" num="0291">The term &#x201c;appliance,&#x201d; &#x201c;computer appliance,&#x201d; or the like, at least in some examples refers to a computer device or computer system with program code (e.g., software or firmware) that is specifically designed to provide a specific computing resource. A &#x201c;virtual appliance&#x201d; is a virtual machine image to be implemented by a hypervisor-equipped device that virtualizes or emulates a computer appliance or otherwise is dedicated to provide a specific computing resource.</p><p id="p-0309" num="0292">The term &#x201c;user equipment&#x201d; or &#x201c;UE&#x201d; at least in some examples refers to a device with radio communication capabilities and may describe a remote user of network resources in a communications network. The term &#x201c;user equipment&#x201d; or &#x201c;UE&#x201d; may be considered synonymous to, and may be referred to as, client, mobile, mobile device, mobile terminal, user terminal, mobile unit, station, mobile station, mobile user, subscriber, user, remote station, access agent, user agent, receiver, radio equipment, reconfigurable radio equipment, reconfigurable mobile device, etc. Furthermore, the term &#x201c;user equipment&#x201d; or &#x201c;UE&#x201d; may include any type of wireless/wired device or any computing device including a wireless communications interface. Examples of UEs, client devices, etc., include desktop computers, workstations, laptop computers, mobile data terminals, smartphones, tablet computers, wearable devices, machine-to-machine (M2M) devices, machine-type communication (MTC) devices, Internet of Things (IoT) devices, embedded systems, sensors, autonomous vehicles, drones, robots, in-vehicle infotainment systems, instrument clusters, onboard diagnostic devices, dashtop mobile equipment, electronic engine management systems, electronic/engine control units/modules, microcontrollers, control module, server devices, network appliances, head-up display (HUD) devices, helmet-mounted display devices, augmented reality (AR) devices, virtual reality (VR) devices, mixed reality (MR) devices, and/or other like systems or devices.</p><p id="p-0310" num="0293">The term &#x201c;station&#x201d; or &#x201c;STA&#x201d; at least in some examples refers to a logical entity that is a singly addressable instance of a medium access control (MAC) and physical layer (PHY) interface to the wireless medium (WM). The term &#x201c;wireless medium&#x201d; or WM&#x2033; at least in some examples refers to the medium used to implement the transfer of protocol data units (PDUs) between peer physical layer (PHY) entities of a wireless local area network (LAN).</p><p id="p-0311" num="0294">The term &#x201c;network element&#x201d; at least in some examples refers to physical or virtualized equipment and/or infrastructure used to provide wired or wireless communication network services. The term &#x201c;network element&#x201d; may be considered synonymous to and/or referred to as a networked computer, networking hardware, network equipment, network node, router, switch, hub, bridge, radio network controller, network access node (NAN), base station, access point (AP), RAN device, RAN node, gateway, server, network appliance, network function (NF), virtualized NF (VNF), and/or the like.</p><p id="p-0312" num="0295">The term &#x201c;network controller&#x201d; at least in some examples refers to a functional block that centralizes some or all of the control and management functionality of a network domain and may provide an abstract view of the network domain to other functional blocks via an interface.</p><p id="p-0313" num="0296">The term &#x201c;access point&#x201d; or &#x201c;AP&#x201d; at least in some examples refers to an entity that contains one station (STA) and provides access to the distribution services, via the wireless medium (WM) for associated STAs. An AP comprises a STA and a distribution system access function (DSAF).</p><p id="p-0314" num="0297">The term &#x201c;network access node&#x201d; or &#x201c;NAN&#x201d; at least in some examples refers to a network element in a radio access network (RAN) responsible for the transmission and reception of radio signals in one or more cells or coverage areas to or from a UE or station. A &#x201c;network access node&#x201d; or &#x201c;NAN&#x201d; can have an integrated antenna or may be connected to an antenna array by feeder cables. Additionally or alternatively, a &#x201c;network access node&#x201d; or &#x201c;NAN&#x201d; may include specialized digital signal processing, network function hardware, and/or compute hardware to operate as a compute node. In some examples, a &#x201c;network access node&#x201d; or &#x201c;NAN&#x201d; may be split into multiple functional blocks operating in software for flexibility, cost, and performance. In some examples, a &#x201c;network access node&#x201d; or &#x201c;NAN&#x201d; may be a base station (e.g., an evolved Node B (eNB) or a next generation Node B (gNB)), an access point and/or wireless network access point, router, switch, hub, radio unit or remote radio head, Transmission Reception Point (TRxP), a gateway device (e.g., Residential Gateway, Wireline 5G Access Network, Wireline 5G Cable Access Network, Wireline BBF Access Network, and the like), network appliance, and/or some other network access hardware.</p><p id="p-0315" num="0298">The term &#x201c;network access controller&#x201d; at least in some examples refers to a functional block that centralizes some or all of the control and management functionality of a network domain and optionally provides an abstract view of its domain to other functional blocks via well-defined interfaces.</p><p id="p-0316" num="0299">The term &#x201c;E-UTEAN NodeB&#x201d;, &#x201c;eNodeB&#x201d;, or &#x201c;eNB&#x201d; at least in some examples refers to a RAN node providing E-UTRA user plane (PDCP/RLC/MAC/PHY) and control plane (RRC) protocol terminations towards a UE, and connected via an S1 interface to the Evolved Packet Core (EPC). Two or more eNBs are interconnected with each other (and/or with one or more en-gNBs) by means of an X2 interface. The term &#x201c;next generation eNB&#x201d; or &#x201c;ng-eNB&#x201d; at least in some examples refers to a RAN node providing E-UTRA user plane and control plane protocol terminations towards a UE, and connected via the NG interface to the 5GC. Two or more ng-eNBs are interconnected with each other (and/or with one or more gNBs) by means of an Xn interface. The term &#x201c;Next Generation NodeB&#x201d;, &#x201c;gNodeB&#x201d;, or &#x201c;gNB&#x201d; at least in some examples refers to a RAN node providing NR user plane and control plane protocol terminations towards a UE, and connected via the NG interface to the 5GC. Two or more gNBs are interconnected with each other (and/or with one or more ng-eNBs) by means of an Xn interface. The term &#x201c;E-UTRA-NR gNB&#x201d; or &#x201c;en-gNB&#x201d; at least in some examples refers to a RAN node providing NR user plane and control plane protocol terminations towards a UE, and acting as a Secondary Node in E-UTRA-NR Dual Connectivity (EN-DC) scenarios (see e.g., 3GPP TS 37.340 v16.6.0 (2021-07-09)). Two or more en-gNBs are interconnected with each other (and/or with one or more eNBs) by means of an X2 interface. The term &#x201c;Next Generation RAN node&#x201d; or &#x201c;NG-RAN node&#x201d; at least in some examples refers to either a gNB or an ng-eNB.</p><p id="p-0317" num="0300">The term &#x201c;Central Unit&#x201d; or &#x201c;CU&#x201d; at least in some examples refers to a logical node hosting radio resource control (RRC), Service Data Adaptation Protocol (SDAP), and/or Packet Data Convergence Protocol (PDCP) protocols/layers of an NG-RAN node, or RRC and PDCP protocols of the en-gNB that controls the operation of one or more DUs; a CU terminates an F1 interface connected with a DU and may be connected with multiple DUs. The term &#x201c;Distributed Unit&#x201d; or &#x201c;DU&#x201d; at least in some examples refers to a logical node hosting Backhaul Adaptation Protocol (BAP), F1 application protocol (F1AP), radio link control (RLC), medium access control (MAC), and physical (PHY) layers of the NG-RAN node or en-gNB, and its operation is partly controlled by a CU; one DU supports one or multiple cells, and one cell is supported by only one DU; and a DU terminates the F1 interface connected with a CU. The term &#x201c;Radio Unit&#x201d; or &#x201c;RU&#x201d; at least in some examples refers to a logical node hosting PHY layer or Low-PHY layer and radiofrequency (RF) processing based on a lower layer functional split. The term &#x201c;split architecture&#x201d; at least in some examples refers to an architecture in which an RU and DU are physically separated from one another, and/or an architecture in which a DU and a CU are physically separated from one another. The term &#x201c;integrated architecture at least in some examples refers to an architecture in which an RU and DU are implemented on one platform, and/or an architecture in which a DU and a CU are implemented on one platform.</p><p id="p-0318" num="0301">The term &#x201c;Residential Gateway&#x201d; or &#x201c;RG&#x201d; at least in some examples refers to a device providing, for example, voice, data, broadcast video, video on demand, to other devices in customer premises. The term &#x201c;Wireline 5G Access Network&#x201d; or &#x201c;W-SGAN&#x201d; at least in some examples refers to a wireline AN that connects to a 5GC via N2 and N3 reference points. The W-SGAN can be either a W-5GBAN or W-5GCAN. The term &#x201c;Wireline 5G Cable Access Network&#x201d; or &#x201c;W-5GCAN&#x201d; at least in some examples refers to an access network defined in/by CableLabs. The term &#x201c;Wireline BBF Access Network&#x201d; or &#x201c;W-5GBAN&#x201d; at least in some examples refers to an Access Network defined in/by the Broadband Forum (BBF). The term &#x201c;Wireline Access Gateway Function&#x201d; or &#x201c;W-AGF&#x201d; at least in some examples refers to a Network function in W-SGAN that provides connectivity to a 3GPP 5G Core network (5GC) to 5G-RG and/or FN-RG. The term &#x201c;5G-RG&#x201d; at least in some examples refers to an RG capable of connecting to a 5GC playing the role of a user equipment with regard to the 5GC; it supports secure element and exchanges N1 signaling with 5GC. The 5G-RG can be either a 5G-BRG or 5G-CRG.</p><p id="p-0319" num="0302">The term &#x201c;edge computing&#x201d; encompasses many implementations of distributed computing that move processing activities and resources (e.g., compute, storage, acceleration resources) towards the &#x201c;edge&#x201d; of the network, in an effort to reduce latency and increase throughput for endpoint users (client devices, user equipment, etc.). Such edge computing implementations typically involve the offering of such activities and resources in cloud-like services, functions, applications, and subsystems, from one or multiple locations accessible via wireless networks. Thus, the references to an &#x201c;edge&#x201d; of a network, cluster, domain, system or computing arrangement used herein are groups or groupings of functional distributed compute elements and, therefore, generally unrelated to &#x201c;edges&#x201d; (links or connections) as used in graph theory.</p><p id="p-0320" num="0303">The term &#x201c;cloud computing&#x201d; or &#x201c;cloud&#x201d; at least in some examples refers to a paradigm for enabling network access to a scalable and elastic pool of shareable computing resources with self-service provisioning and administration on-demand and without active management by users. Cloud computing provides cloud computing services (or cloud services), which are one or more capabilities offered via cloud computing that are invoked using a defined interface (e.g., an API or the like).</p><p id="p-0321" num="0304">The term &#x201c;computing resource&#x201d; or simply &#x201c;resource&#x201d; at least in some examples refers to any physical or virtual component, or usage of such components, of limited availability within a computer system or network. Examples of computing resources include usage/access to, for a period of time, servers, processor(s), storage equipment, memory devices, memory areas, networks, electrical power, input/output (peripheral) devices, mechanical devices, network connections (e.g., channels/links, ports, network sockets, etc.), operating systems, virtual machines (VMs), software/applications, computer files, and/or the like. A &#x201c;hardware resource&#x201d; at least in some examples refers to compute, storage, and/or network resources provided by physical hardware element(s). A &#x201c;virtualized resource&#x201d; at least in some examples refers to compute, storage, and/or network resources provided by virtualization infrastructure to an application, device, system, etc. The term &#x201c;network resource&#x201d; or &#x201c;communication resource&#x201d; at least in some examples refers to resources that are accessible by computer devices/systems via a communications network. The term &#x201c;system resources&#x201d; at least in some examples refers to any kind of shared entities to provide services, and may include computing and/or network resources. System resources may be considered as a set of coherent functions, network data objects or services, accessible through a server where such system resources reside on a single host or multiple hosts and are clearly identifiable.</p><p id="p-0322" num="0305">The term &#x201c;workload&#x201d; at least in some examples refers to an amount of work performed by a computing system, device, entity, etc., during a period of time or at a particular instant of time. A workload may be represented as a benchmark, such as a response time, throughput (e.g., how much work is accomplished over a period of time), and/or the like. Additionally or alternatively, the workload may be represented as a memory workload (e.g., an amount of memory space needed for program execution to store temporary or permanent data and to perform intermediate computations), processor workload (e.g., a number of instructions being executed by a processor during a given period of time or at a particular time instant), an I/O workload (e.g., a number of inputs and outputs or system accesses during a given period of time or at a particular time instant), database workloads (e.g., a number of database queries during a period of time), a network-related workload (e.g., a number of network attachments, a number of mobility updates, a number of radio link failures, a number of handovers, an amount of data to be transferred over an air interface, etc.), and/or the like. Various algorithms may be used to determine a workload and/or workload characteristics, which may be based on any of the aforementioned workload types.</p><p id="p-0323" num="0306">The term &#x201c;cloud service provider&#x201d; (or CSP) indicates an organization which operates typically large-scale &#x201c;cloud&#x201d; resources comprised of centralized, regional, and Edge data centers (e.g., as used in the context of the public cloud). In other examples, a CSP may also be referred to as a Cloud Service Operator (CSO). References to &#x201c;cloud computing&#x201d; generally refer to computing resources and services offered by a CSP or a CSO, at remote locations with at least some increased latency, distance, or constraints relative to Edge computing.</p><p id="p-0324" num="0307">The term &#x201c;data center&#x201d; at least in some examples refers to a purpose-designed structure that is intended to house multiple high-performance compute and data storage nodes such that a large amount of compute, data storage and network resources are present at a single location. This often entails specialized rack and enclosure systems, suitable heating, cooling, ventilation, security, fire suppression, and power delivery systems. The term may also refer to a compute and data storage node in some contexts. A data center may vary in scale between a centralized or cloud data center (e.g., largest), regional data center, and edge data center (e.g., smallest).</p><p id="p-0325" num="0308">The term &#x201c;data center bridging&#x201d; or &#x201c;DCB&#x201d; at least in some examples refers to a set of protocols and capabilities for use in a data center environment. Additionally or alternatively, the term &#x201c;data center bridging&#x201d; or &#x201c;DCB&#x201d; at least in some examples refers to a set of enhancements to the Ethernet LAN communication protocol for use in data center environments, and in some examples, for use with clustering and storage area networks. Additionally or alternatively, the term &#x201c;data center bridging&#x201d; or &#x201c;DCB&#x201d; at least in some examples refers to means for exchanging configuration information according to the Data Center Bridging eXchange protocol (DCBX) (sometimes referred to as the &#x201c;Data Center Bridging Capabilities Exchange Protocol&#x201d;).</p><p id="p-0326" num="0309">The term &#x201c;network function&#x201d; or &#x201c;NF&#x201d; at least in some examples refers to a functional block within a network infrastructure that has one or more external interfaces and a defined functional behavior. The term &#x201c;network service&#x201d; or &#x201c;NS&#x201d; at least in some examples refers to a composition of Network Function(s) and/or Network Service(s), defined by its functional and behavioral specification(s).</p><p id="p-0327" num="0310">The term &#x201c;RAN function&#x201d; or &#x201c;RANF&#x201d; at least in some examples refers to a functional block within a RAN architecture that has one or more external interfaces and a defined behavior related to the operation of a RAN or RAN node. Additionally or alternatively, the term &#x201c;RAN function&#x201d; or &#x201c;RANF&#x201d; at least in some examples refers to a set of functions and/or NFs that are part of a RAN.</p><p id="p-0328" num="0311">The term &#x201c;Application Function&#x201d; or &#x201c;AF&#x201d; at least in some examples refers to an element or entity that interacts with a 3GPP core network in order to provide services. Additionally or alternatively, the term &#x201c;Application Function&#x201d; or &#x201c;AF&#x201d; at least in some examples refers to an edge compute node or ECT framework from the perspective of a 5G core network.</p><p id="p-0329" num="0312">The term &#x201c;edge compute function&#x201d; or &#x201c;ECF&#x201d; at least in some examples refers to an element or entity that performs an aspect of an edge computing technology (ECT), an aspect of edge networking technology (ENT), or performs an aspect of one or more edge computing services running over the ECT or ENT.</p><p id="p-0330" num="0313">The term &#x201c;management function&#x201d; at least in some examples refers to a logical entity playing the roles of a service consumer and/or a service producer. The term &#x201c;management service&#x201d; at least in some examples refers to a set of offered management capabilities.</p><p id="p-0331" num="0314">The term &#x201c;slice&#x201d; at least in some examples refers to a set of characteristics and behaviors that separate one instance, traffic, data flow, application, application instance, link or connection, RAT, device, system, entity, element, and the like from another instance, traffic, data flow, application, application instance, link or connection, RAT, device, system, entity, element, and the like, or separate one type of instance, and the like, from another instance, and the like. The term &#x201c;network slice&#x201d; at least in some examples refers to a logical network that provides specific network capabilities and network characteristics and/or supports various service properties for network slice service consumers. Additionally or alternatively, the term &#x201c;network slice&#x201d; at least in some examples refers to a logical network topology connecting a number of endpoints using a set of shared or dedicated network resources that are used to satisfy specific service level objectives (SLOs) and/or service level agreements (SLAs). The term &#x201c;network slicing&#x201d; at least in some examples refers to methods, processes, techniques, and technologies used to create one or multiple unique logical and virtualized networks over a common multi-domain infrastructure. Additionally or alternatively, the term &#x201c;network slicing&#x201d; at least in some examples refers to means for creating multiple logical and virtualized networks over a common multi-domain infrastructure. The term &#x201c;access network slice&#x201d;, &#x201c;radio access network slice&#x201d;, or &#x201c;RAN slice&#x201d; at least in some examples refers to a part of a network slice that provides resources in a RAN to fulfill one or more application and/or service requirements (e.g., SLAs, and the like). The term &#x201c;network slice instance&#x201d; or &#x201c;NSF at least in some examples refers to a set of NF instances and the required resources (e.g. compute, storage and networking resources) which form a deployed network slice. Additionally or alternatively, the term &#x201c;network slice instance&#x201d; at least in some examples refers to a representation of a service view of a network slice. The term &#x201c;network instance&#x201d; at least in some examples refers to information identifying a domain. The term &#x201c;service consumer&#x201d; at least in some examples refers to an entity that consumes one or more services.</p><p id="p-0332" num="0315">The term &#x201c;service producer&#x201d; at least in some examples refers to an entity that offers, serves, or otherwise provides one or more services. The term &#x201c;service provider&#x201d; at least in some examples refers to an organization or entity that provides one or more services to at least one service consumer. For purposes of the present disclosure, the terms &#x201c;service provider&#x201d; and &#x201c;service producer&#x201d; may be used interchangeably even though these terms may refer to difference concepts. Examples of service providers include cloud service provider (CSP), network service provider (NSP), application service provider (ASP) (e.g., Application software service provider in a service-oriented architecture (ASSP)), internet service provider (ISP), telecommunications service provider (TSP), online service provider (OSP), payment service provider (PSP), managed service provider (MSP), storage service providers (SSPs), SAML service provider, and/or the like. At least in some examples, SLAs may specify, for example, particular aspects of the service to be provided including quality, availability, responsibilities, metrics by which service is measured, as well as remedies or penalties should agreed-on service levels not be achieved. The term &#x201c;SAML service provider&#x201d; at least in some examples refers to a system and/or entity that receives and accepts authentication assertions in conjunction with a single sign-on (SSO) profile of the Security Assertion Markup Language (SAML) and/or some other security mechanism(s).</p><p id="p-0333" num="0316">The term &#x201c;network function virtualization&#x201d; or &#x201c;NFV&#x201d; at least in some examples refers to the principle of separating network functions from the hardware they run on by using virtualization techniques and/or virtualization technologies. Additionally or alternatively, the term &#x201c;network function virtualization&#x201d; or &#x201c;NFV&#x201d; involves the migration of NFs from embedded services inside proprietary hardware appliances to software-based virtualized NFs (or VNFs) running on standardized CPUs (e.g., within standard x86&#xae; and ARM&#xae; servers, such as those including Intel&#xae; Xeon&#x2122; or AMD&#xae; Epyc&#x2122; or Opteron&#x2122; processors) using industry standard virtualization and cloud computing technologies. Additionally or alternatively, NFV processing and data storage will occur at the Edge data centers that are connected directly to the local cellular site, within the infrastructure Edge. The term &#x201c;virtualized NF&#x201d; or &#x201c;VNF&#x201d; at least in some examples refers to an implementation of an NF that can be deployed on a Network Function Virtualization Infrastructure (NFVI). Additionally or alternatively, the term &#x201c;virtualized NF&#x201d; or &#x201c;VNF&#x201d; at least in some examples refers to a software-based NF operating on multi-function, multi-purpose compute resources (e.g., x86, ARM processing architecture, and the like), which are used by NFV in place of dedicated physical equipment. The term &#x201c;Network Functions Virtualization Infrastructure Manager&#x201d; or &#x201c;NFVI&#x201d; at least in some examples refers to a totality of all hardware and software components that build up the environment in which VNFs are deployed. The term &#x201c;Virtualized Infrastructure Manager&#x201d; or &#x201c;VIM&#x201d; at least in some examples refers to a functional block that is responsible for controlling and managing the NFVI compute, storage and network resources, usually within one operator's infrastructure domain.</p><p id="p-0334" num="0317">The term &#x201c;virtualization container&#x201d;, &#x201c;execution container&#x201d;, or &#x201c;container&#x201d; at least in some examples refers to a partition of a compute node that provides an isolated virtualized computation environment. The term &#x201c;OS container&#x201d; at least in some examples refers to a virtualization container utilizing a shared Operating System (OS) kernel of its host, where the host providing the shared OS kernel can be a physical compute node or another virtualization container. Additionally or alternatively, the term &#x201c;virtualization container&#x201d; or &#x201c;container&#x201d; at least in some examples refers to a lightweight and portable executable image that contains software and some or all of its dependencies. Additionally or alternatively, the term &#x201c;container&#x201d; at least in some examples refers to a standard unit of software (or a package) including code and its relevant dependencies, and/or an abstraction at the application layer that packages code and dependencies together. Additionally or alternatively, the term &#x201c;container&#x201d; or &#x201c;container image&#x201d; at least in some examples refers to a lightweight, standalone, executable software package that includes everything needed to run an application such as, for example, code, runtime environment, system tools, system libraries, and settings.</p><p id="p-0335" num="0318">The term &#x201c;virtual machine&#x201d; or &#x201c;VM&#x201d; at least in some examples refers to a virtualized computation environment that behaves in a same or similar manner as a physical computer and/or a server. The term &#x201c;hypervisor&#x201d; at least in some examples refers to a software element that partitions the underlying physical resources of a compute node, creates VMs, manages resources for VMs, and isolates individual VMs from each other.</p><p id="p-0336" num="0319">The term &#x201c;edge compute node&#x201d; or &#x201c;edge compute device&#x201d; at least in some examples refers to an identifiable entity implementing an aspect of edge computing operations, whether part of a larger system, distributed collection of systems, or a standalone apparatus. In some examples, a compute node may be referred to as a &#x201c;edge node&#x201d;, &#x201c;edge device&#x201d;, &#x201c;edge system&#x201d;, whether in operation as a client, server, or intermediate entity. Additionally or alternatively, the term &#x201c;edge compute node&#x201d; at least in some examples refers to a real-world, logical, or virtualized implementation of a compute-capable element in the form of a device, gateway, bridge, system or subsystem, component, whether operating in a server, client, endpoint, or peer mode, and whether located at an &#x201c;edge&#x201d; of an network or at a connected location further within the network. References to a &#x201c;node&#x201d; used herein are generally interchangeable with a &#x201c;device&#x201d;, &#x201c;component&#x201d;, and &#x201c;sub-system&#x201d;; however, references to an &#x201c;edge computing system&#x201d; generally refer to a distributed architecture, organization, or collection of multiple nodes and devices, and which is organized to accomplish or offer some aspect of services or resources in an edge computing setting.</p><p id="p-0337" num="0320">The term &#x201c;cluster&#x201d; at least in some examples refers to a set or grouping of entities as part of an edge computing system (or systems), in the form of physical entities (e.g., different computing systems, networks or network groups), logical entities (e.g., applications, functions, security constructs, containers), and the like. In some locations, a &#x201c;cluster&#x201d; is also referred to as a &#x201c;group&#x201d; or a &#x201c;domain&#x201d;. In some examples, membership of cluster may be modified or affected based on conditions or functions, including from dynamic or property-based membership, from network or system management scenarios, or from various example techniques discussed below which may add, modify, or remove an entity in a cluster. Clusters may also include or be associated with multiple layers, levels, or properties, including variations in security features and results based on such layers, levels, or properties. Additionally or alternatively, the term &#x201c;cluster&#x201d; at least in some examples refers to a set of worker machines (also referred to as &#x201c;nodes&#x201d;) that run containerized applications. Additionally or alternatively, the term &#x201c;worker machine&#x201d; or &#x201c;node&#x201d; at least in some examples refers to a physical or virtual machine or computing device.</p><p id="p-0338" num="0321">The term &#x201c;Data Network&#x201d; or &#x201c;DN&#x201d; at least in some examples refers to a network hosting data-centric services such as, for example, operator services, the internet, third-party services, or enterprise networks. Additionally or alternatively, a DN at least in some examples refers to service networks that belong to an operator or third party, which are offered as a service to a client or user equipment (UE). DNs are sometimes referred to as &#x201c;Packet Data Networks&#x201d; or &#x201c;PDNs&#x201d;. The term &#x201c;Local Area Data Network&#x201d; or &#x201c;LADN&#x201d; at least in some examples refers to a DN that is accessible by the UE only in specific locations, that provides connectivity to a specific DNN, and whose availability is provided to the UE.</p><p id="p-0339" num="0322">The term &#x201c;Internet of Things&#x201d; or &#x201c;IoT&#x201d; at least in some examples refers to a system of interrelated computing devices, mechanical and digital machines capable of transferring data with little or no human interaction, and may involve technologies such as real-time analytics, machine learning and/or AI, embedded systems, wireless sensor networks, control systems, automation (e.g., smart home, smart building and/or smart city technologies), and the like. IoT devices are usually low-power devices without heavy compute or storage capabilities. The term &#x201c;Edge IoT devices&#x201d; at least in some examples refers to any kind of IoT devices deployed at a network's edge.</p><p id="p-0340" num="0323">The term &#x201c;protocol&#x201d; at least in some examples refers to a predefined procedure or method of performing one or more operations. Additionally or alternatively, the term &#x201c;protocol&#x201d; at least in some examples refers to a common means for unrelated objects to communicate with each other (sometimes also called interfaces). The term &#x201c;communication protocol&#x201d; at least in some examples refers to a set of standardized rules or instructions implemented by a communication device and/or system to communicate with other devices and/or systems, including instructions for packetizing/depacketizing data, modulating/demodulating signals, implementation of protocols stacks, and/or the like. In various implementations, a &#x201c;protocol&#x201d; and/or a &#x201c;communication protocol&#x201d; may be represented using a protocol stack, a finite state machine (FSM), and/or any other suitable data structure. The term &#x201c;standard protocol&#x201d; at least in some examples refers to a protocol whose specification is published and known to the public and is controlled by a standards body. The term &#x201c;protocol stack&#x201d; or &#x201c;network stack&#x201d; at least in some examples refers to an implementation of a protocol suite or protocol family. In various implementations, a protocol stack includes a set of protocol layers, where the lowest protocol deals with low-level interaction with hardware and/or communications interfaces and each higher layer adds additional capabilities.</p><p id="p-0341" num="0324">The term &#x201c;application layer&#x201d; at least in some examples refers to an abstraction layer that specifies shared communications protocols and interfaces used by hosts in a communications network. Additionally or alternatively, the term &#x201c;application layer&#x201d; at least in some examples refers to an abstraction layer that interacts with software applications that implement a communicating component, and may include identifying communication partners, determining resource availability, and synchronizing communication. Examples of application layer protocols include HTTP, HTTPs, File Transfer Protocol (FTP), Dynamic Host Configuration Protocol (DHCP), Internet Message Access Protocol (IMAP), Lightweight Directory Access Protocol (LDAP), MQTT, Remote Authentication Dial-In User Service (RADIUS), Diameter protocol, Extensible Authentication Protocol (EAP), RDMA over Converged Ethernet version 2 (RoCEv2), Real-time Transport Protocol (RTP), RTP Control Protocol (RTCP), Real Time Streaming Protocol (RTSP), Skinny Client Control Protocol (SCCP), Session Initiation Protocol (SIP), Session Description Protocol (SDP), Simple Mail Transfer Protocol (SMTP), Simple Network Management Protocol (SNMP), Simple Service Discovery Protocol (SSDP), Small Computer System Interface (SCSI), Internet SCSI (iSCSI), iSCSI Extensions for RDMA (iSER), Transport Layer Security (TLS), voice over IP (VoIP), Virtual Private Network (VPN), Extensible Messaging and Presence Protocol (XMPP), and/or the like.</p><p id="p-0342" num="0325">The term &#x201c;session layer&#x201d; at least in some examples refers to an abstraction layer that controls dialogues and/or connections between entities or elements, and may include establishing, managing and terminating the connections between the entities or elements.</p><p id="p-0343" num="0326">The term &#x201c;transport layer&#x201d; at least in some examples refers to a protocol layer that provides end-to-end (e2e) communication services such as, for example, connection-oriented communication, reliability, flow control, and multiplexing. Examples of transport layer protocols include datagram congestion control protocol (DCCP), fibre channel protocol (FBC), Generic Routing Encapsulation (GRE), GPRS Tunneling (GTP), Micro Transport Protocol (&#x3bc;TP), Multipath TCP (MPTCP), MultiPath QUIC (MPQUIC), Multipath UDP (MPUDP), Quick UDP Internet Connections (QUIC), Remote Direct Memory Access (RDMA), Resource Reservation Protocol (RSVP), Stream Control Transmission Protocol (SCTP), transmission control protocol (TCP), user datagram protocol (UDP), and/or the like.</p><p id="p-0344" num="0327">The term &#x201c;network layer&#x201d; at least in some examples refers to a protocol layer that includes means for transferring network packets from a source to a destination via one or more networks. Additionally or alternatively, the term &#x201c;network layer&#x201d; at least in some examples refers to a protocol layer that is responsible for packet forwarding and/or routing through intermediary nodes. Additionally or alternatively, the term &#x201c;network layer&#x201d; or &#x201c;internet layer&#x201d; at least in some examples refers to a protocol layer that includes interworking methods, protocols, and specifications that are used to transport network packets across a network. As examples, the network layer protocols include internet protocol (IP), IP security (IPsec), Internet Control Message Protocol (ICMP), Internet Group Management Protocol (IGMP), Open Shortest Path First protocol (OSPF), Routing Information Protocol (RIP), RDMA over Converged Ethernet version 2 (RoCEv2), Subnetwork Access Protocol (SNAP), and/or some other internet or network protocol layer.</p><p id="p-0345" num="0328">The term &#x201c;link layer&#x201d; or &#x201c;data link layer&#x201d; at least in some examples refers to a protocol layer that transfers data between nodes on a network segment across a physical layer. Examples of link layer protocols include logical link control (LLC), medium access control (MAC), Ethernet, RDMA over Converged Ethernet version 1 (RoCEv1), and/or the like.</p><p id="p-0346" num="0329">The term &#x201c;radio resource control&#x201d;, &#x201c;RRC layer&#x201d;, or &#x201c;RRC&#x201d; at least in some examples refers to a protocol layer or sublayer that performs system information handling; paging; establishment, maintenance, and release of RRC connections; security functions; establishment, configuration, maintenance and release of Signaling Radio Bearers (SRBs) and Data Radio Bearers (DRBs); mobility functions/services; QoS management; and some sidelink specific services and functions over the Uu interface (see e.g., 3GPP TS 36.331 v17.0.0 (2022-04-13) and/or 3GPP TS 38.331 v17.0.0 (2022-04-19)). The term &#x201c;Service Data Adaptation Protocol&#x201d;, &#x201c;SDAP layer&#x201d;, or &#x201c;SDAP&#x201d; at least in some examples refers to a protocol layer or sublayer that performs mapping between QoS flows and a data radio bearers (DRBs) and marking QoS flow IDs (QFI) in both DL and UL packets (see e.g., 3GPP TS 37.324 v17.0.0 (2022-04-13)). The term &#x201c;Packet Data Convergence Protocol&#x201d;, &#x201c;PDCP layer&#x201d;, or &#x201c;PDCP&#x201d; at least in some examples refers to a protocol layer or sublayer that performs transfer user plane or control plane data; maintains PDCP sequence numbers (SNs); header compression and decompression using the Robust Header Compression (ROHC) and/or Ethernet Header Compression (EHC) protocols; ciphering and deciphering; integrity protection and integrity verification; provides timer based SDU discard; routing for split bearers; duplication and duplicate discarding; reordering and in-order delivery; and/or out-of-order delivery (see e.g., 3GPP TS 36.323 v17.0.0 (2022-04-15) and/or 3GPP TS 38.323 v17.0.0 (2022-04-14)). The term &#x201c;radio link control layer&#x201d;, &#x201c;RLC layer&#x201d;, or &#x201c;RLC&#x201d; at least in some examples refers to a protocol layer or sublayer that performs transfer of upper layer PDUs; sequence numbering independent of the one in PDCP; error Correction through ARQ; segmentation and/or re-segmentation of RLC SDUs; reassembly of SDUs; duplicate detection; RLC SDU discarding; RLC re-establishment; and/or protocol error detection (see e.g., 3GPP TS 38.322 v17.0.0 (2022-04-15) and 3GPP TS 36.322 v17.0.0 (2022-04-15)).</p><p id="p-0347" num="0330">The term &#x201c;medium access control protocol&#x201d;, &#x201c;MAC protocol&#x201d;, or &#x201c;MAC&#x201d; at least in some examples refers to a protocol that governs access to the transmission medium in a network, to enable the exchange of data between stations in a network. Additionally or alternatively, the term &#x201c;medium access control layer&#x201d;, &#x201c;MAC layer&#x201d;, or &#x201c;MAC&#x201d; at least in some examples refers to a protocol layer or sublayer that performs functions to provide frame-based, connectionless-mode (e.g., datagram style) data transfer between stations or devices. Additionally or alternatively, the term &#x201c;medium access control layer&#x201d;, &#x201c;MAC layer&#x201d;, or &#x201c;MAC&#x201d; at least in some examples refers to a protocol layer or sublayer that performs mapping between logical channels and transport channels; multiplexing/demultiplexing of MAC SDUs belonging to one or different logical channels into/from transport blocks (TB) delivered to/from the physical layer on transport channels; scheduling information reporting; error correction through HARQ (one HARQ entity per cell in case of CA); priority handling between UEs by means of dynamic scheduling; priority handling between logical channels of one UE by means of logical channel prioritization; priority handling between overlapping resources of one UE; and/or padding (see e.g., [IEEE802], 3GPP TS 38.321 v17.0.0 (2022-04-14) and 3GPP TS 36.321 v17.0.0 (2022-04-19)). The term &#x201c;physical layer&#x201d;, &#x201c;PHY layer&#x201d;, or &#x201c;PHY&#x201d; at least in some examples refers to a protocol layer or sublayer that includes capabilities to transmit and receive modulated signals for communicating in a communications network (see e.g., [IEEE802], 3GPP TS 38.201 v17.0.0 (2022-01-05) and 3GPP TS 36.201 v17.0.0 (2022-03-31)).</p><p id="p-0348" num="0331">The term &#x201c;radio technology&#x201d; at least in some examples refers to technology for wireless transmission and/or reception of electromagnetic radiation for information transfer. The term &#x201c;radio access technology&#x201d; or &#x201c;RAT&#x201d; at least in some examples refers to the technology used for the underlying physical connection to a radio based communication network. The term &#x201c;RAT type&#x201d; at least in some examples may identify a transmission technology and/or communication protocol used in an access network, for example, new radio (NR), Long Term Evolution (LTE), narrowband IoT (NB-IOTT), untrusted non-3GPP, trusted non-3GPP, trusted Institute of Electrical and Electronics Engineers (IEEE) 802 (e.g., <i>IEEE Standard for Information Technology&#x2014;Telecommunications and Information Exchange between Systems&#x2014;Local and Metropolitan Area Networks&#x2014;Specific Requirements&#x2014;Part </i>11<i>: Wireless LAN Medium Access Control </i>(<i>MAC</i>) <i>and Physical Layer </i>(<i>PHY</i>) <i>Specifications</i>, IEEE Std 802.11-2020, pp. 1-4379 (26 Feb. 2021) (&#x201c;[IEEE80211]&#x201d;) <i>IEEE Standard for Local and Metropolitan Area Networks: Overview and Architecture</i>, IEEE Std 802-2014, pp. 1-74 (30 Jun. 2014) (&#x201c;[IEEE802]&#x201d;), <i>IEEE Standard for Local and Metropolitan Area Network&#x2014;Bridges and Bridged Networks</i>, IEEE Std 802.1Q-2018, pp. 1-1993 (6 Jul. 2018) (&#x201c;[IEEE802.1Q]&#x201d;), the contents of which is hereby incorporated by reference in its entirety), non-3GPP access, MuLTEfire, WiMAX, wireline, wireline-cable, wireline broadband forum (wireline-BBF), and the like. Examples of RATs and/or wireless communications protocols include Advanced Mobile Phone System (AMPS) technologies such as Digital AMPS (D-AMPS), Total Access Communication System (TACS) (and variants thereof such as Extended TACS (ETACS), and/or the like); Global System for Mobile Communications (GSM) technologies such as Circuit Switched Data (CSD), High-Speed CSD (HSCSD), General Packet Radio Service (GPRS), and Enhanced Data Rates for GSM Evolution (EDGE); Third Generation Partnership Project (3GPP) technologies including, for example, Universal Mobile Telecommunications System (UMTS) (and variants thereof such as UMTS Terrestrial Radio Access (UTRA), Wideband Code Division Multiple Access (W-CDMA), Freedom of Multimedia Access (FOMA), Time Division-Code Division Multiple Access (TD-CDMA), Time Division-Synchronous Code Division Multiple Access (TD-SCDMA), and/or the like), Generic Access Network (GAN)/Unlicensed Mobile Access (UMA), High Speed Packet Access (HSPA) (and variants thereof such as HSPA Plus (HSPA+), and/or the like), Long Term Evolution (LTE) (and variants thereof such as LTE-Advanced (LTE-A), Evolved UTRA (E-UTRA), LTE Extra, LTE-A Pro, LTE LAA, MuLTEfire, and/or the like), Fifth Generation (5G) or New Radio (NR), etc.; ETSI technologies such as High Performance Radio Metropolitan Area Network (HiperMAN) and the like; IEEE technologies such as [IEEE802] and/or WiFi (e.g., [IEEE80211] and variants thereof), Worldwide Interoperability for Microwave Access (WiMAX) (see e.g., <i>IEEE Standard for Air Interface for Broadband Wireless Access Systems</i>, IEEE Std 802.16-2017, pp. 1-2726 (2 Mar. 2018) (&#x201c;[WiMAX]&#x201d;) and variants thereof), Mobile Broadband Wireless Access (MBWA)/iBurst (e.g., IEEE 802.20 and variants thereof), etc.; Integrated Digital Enhanced Network (iDEN) (and variants thereof such as Wideband Integrated Digital Enhanced Network (WiDEN); millimeter wave (mmWave) technologies/standards (e.g., wireless systems operating at 10-300 GHz and above such as 3GPP 5G, Wireless Gigabit Alliance (WiGig) standards (e.g., IEEE 802.11ad, IEEE 802.11ay, and the like); short-range and/or wireless personal area network (WPAN) technologies/standards such as Bluetooth (and variants thereof such as Bluetooth 5.3, Bluetooth Low Energy (BLE), and/or the like), IEEE 802.15 technologies/standards (e.g., IEEE Standard for Low-Rate Wireless Networks, IEEE Std 802.15.4-2020, pp. 1-800 (23 Jul. 2020) (&#x201c;[IEEE802154] &#x201d;), ZigBee, Thread, IPv6 over Low power WPAN (6LoWPAN), WirelessHART, MiWi, ISA100.11a, IEEE Standard for Local and metropolitan area networks&#x2014;Part 15.6: Wireless Body Area Networks, IEEE Std 802.15.6-2012, pp. 1-271 (29 Feb. 2012), WiFi-direct, ANT/ANT+, Z-Wave, 3GPP Proximity Services (ProSe), Universal Plug and Play (UPnP), low power Wide Area Networks (LPWANs), Long Range Wide Area Network (LoRA or LoRaWAN&#x2122;), and the like; optical and/or visible light communication (VLC) technologies/standards such as IEEE Standard for Local and metropolitan area networks&#x2014;Part 15.7: Short-Range Optical Wireless Communications, IEEE Std 802.15.7-2018, pp. 1-407 (23 Apr. 2019), and the like; V2X communication including 3GPP cellular V2X (C-V2X), <i>IEEE Guide for Wireless Access in Vehicular Environments </i>(<i>WAVE</i>) <i>Architecture</i>, IEEE S<smallcaps>TANDARDS </smallcaps>A<smallcaps>SSOCIATION</smallcaps>, IEEE 1609.0-2019 (10 Apr. 2019) (&#x201c;[IEEE16090]&#x201d;), <i>V</i>2<i>X Communications Message Set Dictionary</i>, SAE I<smallcaps>NT'L </smallcaps>(23 Jul. 2020) (&#x201c;[J2735_202007]&#x201d;), <i>Wireless Access in Vehicular Environments </i>(<i>WAVE</i>) (<i>IEEE Standard for Information technology&#x2014;Local and metropolitan area networks&#x2014;Specific requirements&#x2014;Part </i>11: <i>Wireless LAN Medium Access Control </i>(<i>MAC</i>) <i>and Physical Layer </i>(<i>PHY</i>) <i>Specifications Amendment </i>6<i>: Wireless Access in Vehicular Environments</i>, IEEE Std 802.11p-2010, pp. 1-51 (15 Jul. 2010) (&#x201c;[IEEE80211p]&#x201d;), which is now part of [IEEE80211]), IEEE 802.11bd (e.g., for vehicular ad-hoc environments), Dedicated Short Range Communications (DSRC), Intelligent-Transport-Systems (ITS) (including the European ITS-G5, ITS-G5B, ITS-G5C, ITS-G5, and the like); Sigfox; Mobitex; 3GPP2 technologies such as cdmaOne (2G), Code Division Multiple Access 2000 (CDMA 2000), and Evolution-Data Optimized or Evolution-Data Only (EV-DO); Push-to-talk (PTT), Mobile Telephone System (MTS) (and variants thereof such as Improved MTS (IMTS), Advanced MTS (AMTS), and/or the like); Personal Digital Cellular (PDC); Personal Handy-phone System (PHS), Cellular Digital Packet Data (CDPD); Cellular Digital Packet Data (CDPD); DataTAC; Digital Enhanced Cordless Telecommunications (DECT) (and variants thereof such as DECT Ultra Low Energy (DECT ULE), DECT-2020, DECT-5G, and/or the like); Ultra High Frequency (UHF) communication; Very High Frequency (VHF) communication; and/or any other suitable RAT or protocol. In addition to the aforementioned RATs/standards, any number of satellite uplink technologies may be used for purposes of the present disclosure including, for example, radios compliant with standards issued by the International Telecommunication Union (ITU), or the ETSI, among others. The examples provided herein are thus understood as being applicable to various other communication technologies, both existing and not yet formulated.</p><p id="p-0349" num="0332">The term &#x201c;channel&#x201d; at least in some examples refers to any transmission medium, either tangible or intangible, which is used to communicate data or a data stream. The term &#x201c;channel&#x201d; may be synonymous with and/or equivalent to &#x201c;communications channel,&#x201d; &#x201c;data communications channel,&#x201d; &#x201c;transmission channel,&#x201d; &#x201c;data transmission channel,&#x201d; &#x201c;access channel,&#x201d; &#x201c;data access channel,&#x201d; &#x201c;link,&#x201d; &#x201c;data link,&#x201d; &#x201c;carrier,&#x201d; &#x201c;radiofrequency carrier,&#x201d; and/or any other like term denoting a pathway or medium through which data is communicated. Additionally, the term &#x201c;link&#x201d; at least in some examples refers to a connection between two devices through a RAT for the purpose of transmitting and receiving information.</p><p id="p-0350" num="0333">The term &#x201c;subframe&#x201d; at least in some examples at least in some examples refers to a time interval during which a signal is signaled. In some implementations, a subframe is equal to 1 millisecond (ms). The term &#x201c;time slot&#x201d; at least in some examples at least in some examples refers to an integer multiple of consecutive subframes. The term &#x201c;superframe&#x201d; at least in some examples at least in some examples refers to a time interval comprising two time slots.</p><p id="p-0351" num="0334">The term &#x201c;reliability&#x201d; at least in some examples refers to the ability of a computer-related component (e.g., software, hardware, or network element/entity) to consistently perform a desired function and/or operate according to a specification. Additionally or alternatively, the term &#x201c;reliability&#x201d; at least in some examples refers to the probability that a product, system, or service will perform its intended function adequately for a specified period of time, or will operate in a defined environment with a low probability of failure. Additionally or alternatively, the term &#x201c;reliability&#x201d; in the context of network communications (e.g., &#x201c;network reliability&#x201d;) at least in some examples refers to the ability of a network to carry out communication. The term &#x201c;network reliability&#x201d; at least in some examples refers to a probability or measure of delivering a specified amount of data from a source to a destination (or sink).</p><p id="p-0352" num="0335">The term &#x201c;flow&#x201d; at least in some examples refers to a sequence of data and/or data units (e.g., datagrams, packets, or the like) from a source entity/element to a destination entity/element. Additionally or alternatively, the term &#x201c;flow&#x201d; at least in some examples refers to a group of packets or datagrams that may follow the same route or path and/or experience the same level of service. Additionally or alternatively, the terms &#x201c;flow&#x201d; or &#x201c;traffic flow&#x201d; at least in some examples refer to an artificial and/or logical equivalent to a call, connection, or link. Additionally or alternatively, the terms &#x201c;flow&#x201d; or &#x201c;traffic flow&#x201d; at least in some examples refer to a sequence of packets sent from a particular source to a particular unicast, anycast, or multicast destination that the source desires to label as a flow; from an upper-layer viewpoint, a flow may include of all packets in a specific transport connection or a media stream, however, a flow is not necessarily <b>1</b>:<b>1</b> mapped to a transport connection. Additionally or alternatively, the terms &#x201c;flow&#x201d; or &#x201c;traffic flow&#x201d; at least in some examples refer to a set of data and/or data units (e.g., datagrams, packets, or the like) passing an observation point in a network during a certain time interval. Additionally or alternatively, the term &#x201c;flow&#x201d; at least in some examples refers to a user plane data link that is attached to an association. Examples are circuit switched phone call, voice over IP call, reception of an SMS, sending of a contact card, PDP context for internet access, demultiplexing a TV channel from a channel multiplex, calculation of position coordinates from geopositioning satellite signals, etc. For purposes of the present disclosure, the terms &#x201c;traffic flow&#x201d;, &#x201c;data flow&#x201d;, &#x201c;dataflow&#x201d;, &#x201c;packet flow&#x201d;, &#x201c;network flow&#x201d;, and/or &#x201c;flow&#x201d; may be used interchangeably even though these terms at least in some examples refers to different concepts.</p><p id="p-0353" num="0336">The term &#x201c;dataflow&#x201d; or &#x201c;data flow&#x201d; at least in some examples refers to the movement of data through a system including software elements, hardware elements, or a combination of both software and hardware elements. Additionally or alternatively, the term &#x201c;dataflow&#x201d; or &#x201c;data flow&#x201d; at least in some examples refers to a path taken by a set of data from an origination or source to destination that includes all nodes through which the set of data travels.</p><p id="p-0354" num="0337">The term &#x201c;stream&#x201d; at least in some examples refers to a sequence of data elements made available over time. At least in some examples, functions that operate on a stream, which may produce another stream, are referred to as &#x201c;filters,&#x201d; and can be connected in pipelines, analogously to function composition; filters may operate on one item of a stream at a time, or may base an item of output on multiple items of input, such as a moving average. Additionally or alternatively, the term &#x201c;stream&#x201d; or &#x201c;streaming&#x201d; at least in some examples refers to a manner of processing in which an object is not represented by a complete logical data structure of nodes occupying memory proportional to a size of that object, but are processed &#x201c;on the fly&#x201d; as a sequence of events.</p><p id="p-0355" num="0338">The term &#x201c;distributed computing&#x201d; at least in some examples refers to computation resources that are geographically distributed within the vicinity of one or more localized networks' terminations. The term &#x201c;distributed computations&#x201d; at least in some examples refers to a model in which components located on networked computers communicate and coordinate their actions by passing messages interacting with each other in order to achieve a common goal.</p><p id="p-0356" num="0339">The term &#x201c;service&#x201d; at least in some examples refers to the provision of a discrete function within a system and/or environment. Additionally or alternatively, the term &#x201c;service&#x201d; at least in some examples refers to a functionality or a set of functionalities that can be reused. The term &#x201c;microservice&#x201d; at least in some examples refers to one or more processes that communicate over a network to fulfil a goal using technology-agnostic protocols (e.g., HTTP or the like). Additionally or alternatively, the term &#x201c;microservice&#x201d; at least in some examples refers to services that are relatively small in size, messaging-enabled, bounded by contexts, autonomously developed, independently deployable, decentralized, and/or built and released with automated processes. Additionally or alternatively, the term &#x201c;microservice&#x201d; at least in some examples refers to a self-contained piece of functionality with clear interfaces, and may implement a layered architecture through its own internal components. Additionally or alternatively, the term &#x201c;microservice architecture&#x201d; at least in some examples refers to a variant of the service-oriented architecture (SOA) structural style wherein applications are arranged as a collection of loosely-coupled services (e.g., fine-grained services) and may use lightweight protocols. The term &#x201c;network service&#x201d; at least in some examples refers to a composition of NF(s) and/or Network Service(s), defined by its functional and behavioral specification.</p><p id="p-0357" num="0340">The term &#x201c;session&#x201d; at least in some examples refers to a temporary and interactive information interchange between two or more communicating devices, two or more application instances, between a computer and user, and/or between any two or more entities or elements. Additionally or alternatively, the term &#x201c;session&#x201d; at least in some examples refers to a connectivity service or other service that provides or enables the exchange of data between two entities or elements. The term &#x201c;network session&#x201d; at least in some examples refers to a session between two or more communicating devices over a network. The term &#x201c;web session&#x201d; at least in some examples refers to session between two or more communicating devices over the Internet or some other network. The term &#x201c;session identifier,&#x201d; &#x201c;session ID,&#x201d; or &#x201c;session token&#x201d; at least in some examples refers to a piece of data that is used in network communications to identify a session and/or a series of message exchanges.</p><p id="p-0358" num="0341">The term &#x201c;quality&#x201d; at least in some examples refers to a property, character, attribute, or feature of something as being affirmative or negative, and/or a degree of excellence of something. Additionally or alternatively, the term &#x201c;quality&#x201d; at least in some examples, in the context of data processing, refers to a state of qualitative and/or quantitative aspects of data, processes, and/or some other aspects of data processing systems.</p><p id="p-0359" num="0342">The term &#x201c;Quality of Service&#x201d; or &#x201c;QoS' at least in some examples refers to a description or measurement of the overall performance of a service (e.g., telephony and/or cellular service, network service, wireless communication/connectivity service, cloud computing service, etc.). In some cases, the QoS may be described or measured from the perspective of the users of that service, and as such, QoS may be the collective effect of service performance that determine the degree of satisfaction of a user of that service. In other cases, QoS at least in some examples refers to traffic prioritization and resource reservation control mechanisms rather than the achieved perception of service quality. In these cases, QoS is the ability to provide different priorities to different applications, users, or flows, or to guarantee a certain level of performance to a flow. In either case, QoS is characterized by the combined aspects of performance factors applicable to one or more services such as, for example, service operability performance, service accessibility performance; service retain ability performance; service reliability performance, service integrity performance, and other factors specific to each service. Several related aspects of the service may be considered when quantifying the QoS, including packet loss rates, bit rates, throughput, transmission delay, availability, reliability, jitter, signal strength and/or quality measurements, and/or other measurements such as those discussed herein. Additionally or alternatively, the term &#x201c;Quality of Service&#x201d; or &#x201c;QoS&#x2019; at least in some examples refers to mechanisms that provide traffic-forwarding treatment based on flow-specific traffic classification. In some implementations, the term &#x201c;Quality of Service&#x201d; or &#x201c;QoS&#x201d; can be used interchangeably with the term &#x201c;Class of Service&#x201d; or &#x201c;CoS&#x201d;.</p><p id="p-0360" num="0343">The term &#x201c;Class of Service&#x201d; or &#x201c;CoS&#x2019; at least in some examples refers to mechanisms that provide traffic-forwarding treatment based on non-flow-specific traffic classification. In some implementations, the term &#x201c;Class of Service&#x201d; or &#x201c;CoS&#x201d; can be used interchangeably with the term &#x201c;Quality of Service&#x201d; or &#x201c;QoS&#x201d;.</p><p id="p-0361" num="0344">The term &#x201c;QoS flow&#x201d; at least in some examples refers to the finest granularity for QoS forwarding treatment in a network. The term &#x201c;5G QoS flow&#x201d; at least in some examples refers to the finest granularity for QoS forwarding treatment in a 5G System (5GS). Traffic mapped to the same QoS flow (or 5G QoS flow) receive the same forwarding treatment. The term &#x201c;QoS Identifier&#x201d; at least in some examples refers to a scalar that is used as a reference to a specific QoS forwarding behavior (e.g., packet loss rate, packet delay budget, etc.) to be provided to a QoS flow. This may be implemented in an access network by referencing node specific parameters that control the QoS forwarding treatment (e.g., scheduling weights, admission thresholds, queue management thresholds, link layer protocol configuration, etc.).</p><p id="p-0362" num="0345">The term &#x201c;forwarding treatment&#x201d; at least in some examples refers to the precedence, preferences, and/or prioritization a packet belonging to a particular dataflow receives in relation to other traffic of other dataflows. Additionally or alternatively, the term &#x201c;forwarding treatment&#x201d; at least in some examples refers to one or more parameters, characteristics, and/or configurations to be applied to packets belonging to a dataflow when processing the packets for forwarding. Examples of such characteristics may include resource type (e.g., non-guaranteed bit rate (GBR), GBR, delay-critical GBR, etc.); priority level; class or classification; packet delay budget; packet error rate; averaging window; maximum data burst volume; minimum data burst volume; scheduling policy/weights; queue management policy; rate shaping policy; link layer protocol and/or RLC configuration; admission thresholds; etc. In some implementations, the term &#x201c;forwarding treatment&#x201d; may be referred to as &#x201c;Per-Hop Behavior&#x201d; or &#x201c;PHB&#x201d;.</p><p id="p-0363" num="0346">The term &#x201c;queue&#x201d; at least in some examples refers to a collection of entities (e.g., data, objects, events, etc.) are stored and held to be processed later. that are maintained in a sequence and can be modified by the addition of entities at one end of the sequence and the removal of entities from the other end of the sequence; the end of the sequence at which elements are added may be referred to as the &#x201c;back&#x201d;, &#x201c;tail&#x201d;, or &#x201c;rear&#x201d; of the queue, and the end at which elements are removed may be referred to as the &#x201c;head&#x201d; or &#x201c;front&#x201d; of the queue. Additionally, a queue may perform the function of a buffer, and the terms &#x201c;queue&#x201d; and &#x201c;buffer&#x201d; may be used interchangeably throughout the present disclosure. The term &#x201c;enqueue&#x201d; at least in some examples refers to one or more operations of adding an element to the rear of a queue. The term &#x201c;dequeue&#x201d; at least in some examples refers to one or more operations of removing an element from the front of a queue.</p><p id="p-0364" num="0347">The term &#x201c;PDU Connectivity Service&#x201d; at least in some examples refers to a service that provides exchange of protocol data units (PDUs) between a UE and a data network (DN). The term &#x201c;PDU Session&#x201d; at least in some examples refers to an association between a UE and a DN that provides a PDU connectivity service (see e.g., 3GPP TS 38.415 v17.0.0 (2022 Apr. 6) (&#x201c;[TS38415]&#x201d;) and 3GPP TS 38.413 v17.1.1 (2022 Jun. 30) (&#x201c;[TS38413]&#x201d;), the contents of each of which are hereby incorporated by reference in their entireties); a PDU Session type can be IPv4, IPv6, IPv4v6, Ethernet (se e.g., Ethernet (e.g., IEEE Standard for Ethernet, IEEE Std 802.3-2018, pp. 1-5600 (31 Aug. 2018) (&#x201c;[IEEE8023]&#x201d;)), Unstructured, or any other network/connection type, such as those discussed herein. The term &#x201c;PDU Session Resource&#x201d; at least in some examples refers to an NG-RAN interface (e.g., NG, Xn, and/or E1 interfaces) and radio resources provided to support a PDU Session. The term &#x201c;multi-access PDU session&#x201d; or &#x201c;MA PDU Session&#x201d; at least in some examples refers to a PDU Session that provides a PDU connectivity service, which can use one access network at a time or multiple access networks simultaneously.</p><p id="p-0365" num="0348">The term &#x201c;access traffic shaping&#x201d; or The term &#x201c;traffic shaping&#x201d; at least in some examples refers to a bandwidth management technique that manages data transmission to comply with a desired traffic profile or class of service. Traffic shaping ensures sufficient network bandwidth for time-sensitive, critical applications using policy rules, data classification, queuing, QoS, and other techniques. The term &#x201c;throttling&#x201d; at least in some examples refers to the regulation of flows into or out of a network, or into or out of a specific device or element. The term &#x201c;access traffic steering&#x201d; or &#x201c;traffic steering&#x201d; at least in some examples refers to a procedure that selects an access network for a new data flow and transfers the traffic of one or more data flows over the selected access network. Access traffic steering is applicable between one 3GPP access and one non-3GPP access. The term &#x201c;access traffic switching&#x201d; or &#x201c;traffic switching&#x201d; at least in some examples refers to a procedure that moves some or all traffic of an ongoing data flow from at least one access network to at least one other access network in a way that maintains the continuity of the data flow. The term &#x201c;access traffic splitting&#x201d; or &#x201c;traffic splitting&#x201d; at least in some examples refers to a procedure that splits the traffic of at least one data flow across multiple access networks. When traffic splitting is applied to a data flow, some traffic of the data flow is transferred via at least one access channel, link, or path, and some other traffic of the same data flow is transferred via another access channel, link, or path.</p><p id="p-0366" num="0349">The term &#x201c;network address&#x201d; at least in some examples refers to an identifier for a node or host in a computer network, and may be a unique identifier across a network and/or may be unique to a locally administered portion of the network. The term &#x201c;application identifier&#x201d;, &#x201c;application ID&#x201d;, or &#x201c;app ID&#x201d; at least in some examples refers to an identifier that can be mapped to a specific application or application instance; in the context of 3GPP 5G/NR systems, an &#x201c;application identifier&#x201d; at least in some examples refers to an identifier that can be mapped to a specific application traffic detection rule. Additionally or alternatively, the term &#x201c;application identifier&#x201d;, &#x201c;application ID&#x201d;, or &#x201c;app ID&#x201d; at least in some examples refers to a collection of entry points and/or data structures that an application program can access when translated into an application executable. The term &#x201c;endpoint address&#x201d; at least in some examples refers to an address used to determine the host/authority part of a target URI, where the target URI is used to access an NF service (e.g., to invoke service operations) of an NF service producer or for notifications to an NF service consumer.</p><p id="p-0367" num="0350">Examples of identifiers that could be used as a network address, app ID, endpoint address, and/or any other identifier discussed herein include a Closed Access Group Identifier (CAG-ID), Bluetooth hardware device address (BD_ADDR), a cellular network address (e.g., Access Point Name (APN), AMF identifier (ID), AF-Service-Identifier, Edge Application Server (EAS) ID, Data Network Access Identifier (DNAI), Data Network Name (DNN), EPS Bearer Identity (EBI), Equipment Identity Register (EIR) and/or 5G-EIR, Extended Unique Identifier (EUI), Group ID for Network Selection (GIN), Generic Public Subscription Identifier (GPSI), Globally Unique AMF Identifier (GUAMI), Globally Unique Temporary Identifier (GUTI) and/or 5G-GUTI, GPRS tunneling protocol (GTP) tunnel endpoint identifier (TEID) (GTP), Radio Network Temporary Identifier (RNTI) (including any RNTI and variants thereof such as those discussed in [TS38300]), International Mobile Equipment Identity (IMEI), IMEI Type Allocation Code (IMEA/TAC), International Mobile Subscriber Identity (IMSI), IMSI software version (IMSISV), permanent equipment identifier (PEI), Local Area Data Network (LADN) DNN, Mobile Subscriber Identification Number (MSIN), Mobile Subscriber/Station ISDN Number (MSISDN), network identifier (NID), Network Slice Instance (NSI) ID, Network Slice Selection Assistance Information (NSSAI), Single NSSAI (S-NSSAI), Permanent Equipment Identifier (PEI), Public Land Mobile Network (PLMN) ID, QoS Flow ID (QFI) and/or 5G QoS Identifier (5QI), RAN ID, Routing Indicator, SMS Function (SMSF) ID, Stand-alone Non-Public Network (SNPN) ID, Subscription Concealed Identifier (SUCI), Subscription Permanent Identifier (SUPI), Temporary Mobile Subscriber Identity (TMSI) and variants thereof, UE Access Category and Identity, and/or other cellular network related identifiers), a connection endpoint identifier (CEPID), an email address, Enterprise Application Server (EAS) ID, an endpoint address, an Electronic Product Code (EPC) as defined by the EPCglobal Tag Data Standard, a Fully Qualified Domain Name (FQDN), flow ID, flow label (e.g., IPv6 flow label, Flexilink flow label, and the like), an ICMP identifier, Intelligence-Defined Network (IDN) identifier(s), an internet protocol (IP) address in an IP network (e.g., IP version 4 (Ipv4), IP version 6 (IPv6), etc.), an Information-Centric Networking (ICN) name (data packet identifier), an internet packet exchange (IPX) address, Local Area Network (LAN) ID, a media access control (MAC) address, Multiprotocol Label Switching (MPLS) labels, personal area network (PAN) ID, a port number (e.g., Transmission Control Protocol (TCP) port number, User Datagram Protocol (UDP) port number), Preferred Path Route (PPR) Identifier, PPR segment ID (SID), QUIC connection ID, RFID tag, service set identifier (SSID) and variants thereof, socket address, telephone numbers in a public switched telephone network (PTSN), a socket address, universally unique identifier (UUID) (e.g., as specified in ISO/IEC 11578:1996), a Universal Resource Locator (URL) and/or Universal Resource Identifier (URI), Virtual LAN (VLAN) ID, an X.21 address, an X.25 address, Zigbee&#xae; ID, Zigbee&#xae; Device Network ID, any of the identifiers/identities discussed in 3GPP TS 38.300 v17.1.0 (2022-07-19) (&#x201c;[TS38300]&#x201d;) the contents of which are hereby incorporated by reference in its entirety, and/or any other suitable network address and components thereof.</p><p id="p-0368" num="0351">The term &#x201c;network socket&#x201d; or &#x201c;socket&#x201d; at least in some examples refers to an element that serves as an endpoint for sending and receiving data across a network or for inter-process communication. The structure and properties of a socket can be defined by one or more APIs, and may be identified by a socket address or the like.</p><p id="p-0369" num="0352">The term &#x201c;port&#x201d; at least in some examples refers to a communication endpoint, a virtual data connection between two or more entities, and/or a virtual point where network connections start and end. Additionally or alternatively, a &#x201c;port&#x201d; at least in some examples is associated with a specific process or service.</p><p id="p-0370" num="0353">The term &#x201c;tuple&#x201d; at least in some examples refers to a finite ordered list and/or sequence) of elements. The term &#x201c;n-tuple&#x201d; at least in some examples refers to a sequence and/or ordered list of n elements, where n is a number. The term &#x201c;5-tuple&#x201d; at least in some examples refers to a set of five values that can be used to identify a network connection or session (e.g., TCP/IP connection, UDP/TCP session, and/or the like). The set of five values can include, for example, a source network address, a destination network address, a source port, a destination port, and a network and/or transport protocol being used.</p><p id="p-0371" num="0354">The term &#x201c;data rate&#x201d; at least in some examples refers to a transmission speed of a network. Additionally or alternatively, the term &#x201c;data rate&#x201d; at least in some examples refers to the amount of data transmitted during a specified time period and/or the speed at which data is transferred from one entity or element to another entity or element. Additionally or alternatively, the term &#x201c;data rate&#x201d; at least in some examples can be used interchangeably with the &#x201c;bit rate&#x201d;, &#x201c;data signaling rate&#x201d;, &#x201c;symbol rate&#x201d;, &#x201c;throughput&#x201d;, and/or &#x201c;data transfer rate&#x201d;. The term &#x201c;bit rate&#x201d; at least in some examples refers to the number of bits that are conveyed or processed per unit of time. The term &#x201c;physical rate&#x201d; or &#x201c;PHY rate&#x201d; at least in some examples refers to a speed at which one or more bits are actually sent over a transmission medium. Additionally or alternatively, the term &#x201c;physical rate&#x201d; or &#x201c;PHY rate&#x201d; at least in some examples refers to a speed at which data can move across a wired or wireless link between a transmitter and a receiver. The term &#x201c;throughput&#x201d; or &#x201c;network throughput&#x201d; at least in some examples refers to a rate of production or the rate at which something is processed. Additionally or alternatively, the term &#x201c;throughput&#x201d; or &#x201c;network throughput&#x201d; at least in some examples refers to a rate of successful data delivery over a communication channel. The term &#x201c;goodput&#x201d; at least in some examples refers to a number of useful information bits delivered by the network to a certain destination per unit of time. The term &#x201c;channel capacity&#x201d; at least in some examples refers to an upper bound on the rate at which data can be reliably transmitted over a communication channel and/or given noise on a channel. The term &#x201c;bandwidth&#x201d; at least in some examples refers to the maximum rate of data transfer across a given path. Additionally or alternatively, the term &#x201c;bandwidth&#x201d; at least in some examples refers to data carrying capacity of a network or transmission medium.</p><p id="p-0372" num="0355">The term &#x201c;delay&#x201d; at least in some examples refers to a time interval between two events. Additionally or alternatively, the term &#x201c;delay&#x201d; at least in some examples refers to a time interval between the propagation of a signal and its reception. The term &#x201c;packet delay&#x201d; at least in some examples refers to the time it takes to transfer any packet from one point to another. Additionally or alternatively, the term &#x201c;packet delay&#x201d; or &#x201c;per packet delay&#x201d; at least in some examples refers to the difference between a packet reception time and packet transmission time. Additionally or alternatively, the &#x201c;packet delay&#x201d; or &#x201c;per packet delay&#x201d; can be measured by subtracting the packet sending time from the packet receiving time where the transmitter and receiver are at least somewhat synchronized. The term &#x201c;processing delay&#x201d; at least in some examples refers to an amount of time taken to process a packet in a network node. The term &#x201c;transmission delay&#x201d; at least in some examples refers to an amount of time needed (or necessary) to push a packet (or all bits of a packet) into a transmission medium. The term &#x201c;propagation delay&#x201d; at least in some examples refers to amount of time it takes a signal's header to travel from a sender to a receiver. The term &#x201c;network delay&#x201d; at least in some examples refers to the delay of an a data unit within a network (e.g., an IP packet within an IP network). The term &#x201c;queuing delay&#x201d; at least in some examples refers to an amount of time a job waits in a queue until that job can be executed. Additionally or alternatively, the term &#x201c;queuing delay&#x201d; at least in some examples refers to an amount of time a packet waits in a queue until it can be processed and/or transmitted. The term &#x201c;delay bound&#x201d; at least in some examples refers to a predetermined or configured amount of acceptable delay. The term &#x201c;per-packet delay bound&#x201d; at least in some examples refers to a predetermined or configured amount of acceptable packet delay where packets that are not processed and/or transmitted within the delay bound are considered to be delivery failures and are discarded or dropped. The term &#x201c;packet drop rate&#x201d; at least in some examples refers to a share of packets that were not sent to the target due to high traffic load or traffic management and should be seen as a part of the packet loss rate. The term &#x201c;packet loss rate&#x201d; at least in some examples refers to a share of packets that could not be received by the target, including packets dropped, packets lost in transmission and packets received in wrong format. The term &#x201c;latency&#x201d; at least in some examples refers to the amount of time it takes to transfer a first/initial data unit in a data burst from one point to another. The term &#x201c;performance indicator&#x201d; at least in some examples refers to performance data aggregated over a group of network functions (NFs), which is derived from performance measurements collected at the NFs that belong to the group, according to the aggregation method identified in a Performance Indicator definition.</p><p id="p-0373" num="0356">The term &#x201c;application&#x201d; or &#x201c;app&#x201d; at least in some examples refers to a computer program designed to carry out a specific task other than one relating to the operation of the computer itself. Additionally or alternatively, term &#x201c;application&#x201d; or &#x201c;app&#x201d; at least in some examples refers to a complete and deployable package, environment to achieve a certain function in an operational environment. Additionally or alternatively, the term &#x201c;application&#x201d; or &#x201c;app&#x201d; at least in some examples refers to a computer program that defines and implements a useful functionality. The term &#x201c;application executable&#x201d; or &#x201c;executable&#x201d; at least in some examples refers to a representation of an application as collection of executable code. The term &#x201c;application executable&#x201d; or &#x201c;executable&#x201d; at least in some examples refers to a representation of an application in a programming language such as, for example, assembly language, an object-oriented programming language, a declarative programming language, a markup language, a scripting language, and/or some other type of language.</p><p id="p-0374" num="0357">The term &#x201c;algorithm&#x201d; at least in some examples refers to an unambiguous specification of how to solve a problem or a class of problems by performing calculations, input/output operations, data processing, automated reasoning tasks, and/or the like.</p><p id="p-0375" num="0358">The terms &#x201c;instantiate,&#x201d; &#x201c;instantiation,&#x201d; and the like at least in some examples refers to the creation of an instance. An &#x201c;instance&#x201d; also at least in some examples refers to a concrete occurrence of an object, which may occur, for example, during execution of program code.</p><p id="p-0376" num="0359">The term &#x201c;data processing&#x201d; or &#x201c;processing&#x201d; at least in some examples refers to any operation or set of operations which is performed on data or on sets of data, whether or not by automated means, such as collection, recording, writing, organization, structuring, storing, adaptation, alteration, retrieval, consultation, use, disclosure by transmission, dissemination or otherwise making available, alignment or combination, restriction, erasure and/or destruction.</p><p id="p-0377" num="0360">The term &#x201c;packet processor&#x201d; at least in some examples refers to software and/or hardware element(s) that transform a stream of input packets into output packets (or transforms a stream of input data into output data); examples of the transformations include adding, removing, and modifying fields in a packet header, trailer, and/or payload.</p><p id="p-0378" num="0361">The term &#x201c;data pipeline&#x201d; or &#x201c;pipeline&#x201d; at least in some examples refers to a set of data processing elements (or data processors) connected in series and/or in parallel, where the output of one data processing element is the input of one or more other data processing elements in the pipeline; the elements of a pipeline may be executed in parallel or in time-sliced fashion and/or some amount of buffer storage can be inserted between elements.</p><p id="p-0379" num="0362">The term &#x201c;software agent&#x201d; at least in some examples refers to a computer program that acts for a user or other program in a relationship of agency.</p><p id="p-0380" num="0363">The term &#x201c;use case&#x201d; at least in some examples refers to a description of a system from a user's perspective. Use cases sometimes treat a system as a black box, and the interactions with the system, including system responses, are perceived as from outside the system. Use cases typically avoid technical jargon, preferring instead the language of the end user or domain expert.</p><p id="p-0381" num="0364">The term &#x201c;analytics&#x201d; at least in some examples refers to the discovery, interpretation, and communication of meaningful patterns in data.</p><p id="p-0382" num="0365">The term &#x201c;application programming interface&#x201d; or &#x201c;API&#x201d; at least in some examples refers to a set of subroutine definitions, communication protocols, and tools for building software. Additionally or alternatively, the term &#x201c;application programming interface&#x201d; or &#x201c;API&#x201d; at least in some examples refers to a set of clearly defined methods of communication among various components. In some examples, an API may be for a web-based system, operating system, database system, computer hardware, or software library.</p><p id="p-0383" num="0366">The term &#x201c;datagram&#x201d; at least in some examples refers to a unit of data carried by a packet-switched network or otherwise associated with a packet-switched network. A datagram may be structured to have a header section or trailer section that carries control information and a payload section that carries user data. The term &#x201c;datagram&#x201d; at least in some examples may be synonymous with any of the following terms, even though they may refer to different aspects: &#x201c;data unit&#x201d;, a &#x201c;protocol data unit&#x201d; or &#x201c;PDU&#x201d;, a &#x201c;service data unit&#x201d; or &#x201c;SDU&#x201d;, &#x201c;frame&#x201d;, &#x201c;packet&#x201d;, a &#x201c;network packet&#x201d;, &#x201c;segment&#x201d;, &#x201c;block&#x201d;, &#x201c;cell&#x201d;, &#x201c;chunk&#x201d;, and/or the like. Examples of datagrams, network packets, and the like, include internet protocol (IP) packet, Internet Control Message Protocol (ICMP) packet, UDP packet, TCP packet, SCTP packet, Ethernet frame, RRC messages/packets, SDAP PDU, SDAP SDU, PDCP PDU, PDCP SDU, MAC PDU, MAC SDU, BAP PDU. BAP SDU, RLC PDU, RLC SDU, WiFi frames as discussed in [IEEE80211], and/or other like data structures.</p><p id="p-0384" num="0367">The term &#x201c;information element&#x201d; or &#x201c;IE&#x201d; at least in some examples refers to a structural element containing one or more fields. Additionally or alternatively, the term &#x201c;information element&#x201d; or &#x201c;IE&#x201d; at least in some examples refers to a field or set of fields defined in a standard or specification that is used to convey data and/or protocol information.</p><p id="p-0385" num="0368">The term &#x201c;field&#x201d; at least in some examples refers to individual contents of an information element, or a data element that contains content. The term &#x201c;data frame&#x201d; or &#x201c;DF&#x201d; at least in some examples refers to a data type that contains more than one data element in a predefined order. The term &#x201c;data element&#x201d; or &#x201c;DE&#x201d; at least in some examples refers to a data type that contains one single data. Additionally or alternatively, the term &#x201c;data element&#x201d; at least in some examples refers to an atomic state of a particular object with at least one specific property at a certain point in time, and may include one or more of a data element name or identifier, a data element definition, one or more representation terms, enumerated values or codes (e.g., metadata), and/or a list of synonyms to data elements in other metadata registries. Additionally or alternatively, a &#x201c;data element&#x201d; at least in some examples refers to a data type that contains data, which may be referred to as the data element's content (or &#x201c;content items&#x201d;). Content items may include text content, attributes, properties, and/or other elements referred to as &#x201c;child elements.&#x201d; Additionally or alternatively, data elements may include zero or more properties and/or zero or more attributes, each of which may be defined as database objects (e.g., fields, records, etc.), object instances, and/or other data elements. An &#x201c;attribute&#x201d; at least in some examples refers to a markup construct including a name-value pair that exists within a start tag or empty element tag. Attributes contain data related to its element and/or control the element's behavior.</p><p id="p-0386" num="0369">The term &#x201c;reference&#x201d; at least in some examples refers to data useable to locate other data and may be implemented a variety of ways (e.g., a pointer, an index, a handle, a key, an identifier, a hyperlink, etc.).</p><p id="p-0387" num="0370">The term &#x201c;translation&#x201d; at least in some examples refers to the process of converting or otherwise changing data from a first form, shape, configuration, structure, arrangement, embodiment, description, etc. into a second form, shape, configuration, structure, arrangement, embodiment, description, etc.; at least in some examples there may be two different types of translation: transcoding and transformation. The term &#x201c;transcoding&#x201d; at least in some examples refers to taking information/data in one format (e.g., a packed binary format) and translating the same information/data into another format in the same sequence. Additionally or alternatively, the term &#x201c;transcoding&#x201d; at least in some examples refers to taking the same information, in the same sequence, and packaging the information (e.g., bits or bytes) differently. The term &#x201c;transformation&#x201d; at least in some examples refers to changing data from one format and writing it in another format, keeping the same order, sequence, and/or nesting of data items. Additionally or alternatively, the term &#x201c;transformation&#x201d; at least in some examples involves the process of converting data from a first format or structure into a second format or structure, and involves reshaping the data into the second format to conform with a schema or other like specification. Transformation may include rearranging data items or data objects, which may involve changing the order, sequence, and/or nesting of the data items/objects. Additionally or alternatively, the term &#x201c;transformation&#x201d; at least in some examples refers to changing the schema of a data object to another schema.</p><p id="p-0388" num="0371">The term &#x201c;cryptographic mechanism&#x201d; at least in some examples refers to any cryptographic protocol and/or cryptographic algorithm. Additionally or alternatively, the term &#x201c;cryptographic protocol&#x201d; at least in some examples refers to a sequence of steps precisely specifying the actions required of two or more entities to achieve specific security objectives (e.g., cryptographic protocol for key agreement). Additionally or alternatively, the term &#x201c;cryptographic algorithm&#x201d; at least in some examples refers to an algorithm specifying the steps followed by a single entity to achieve specific security objectives (e.g., cryptographic algorithm for symmetric key encryption). The term &#x201c;cryptographic hash function&#x201d;, &#x201c;hash function&#x201d;, or &#x201c;hash&#x201d;) at least in some examples refers to a mathematical algorithm that maps data of arbitrary size (sometimes referred to as a &#x201c;message&#x201d;) to a bit array of a fixed size (sometimes referred to as a &#x201c;hash value&#x201d;, &#x201c;hash&#x201d;, or &#x201c;message digest&#x201d;). A cryptographic hash function is usually a one-way function, which is a function that is practically infeasible to invert.</p><p id="p-0389" num="0372">The term &#x201c;event&#x201d;, in probability theory, at least in some examples refers to a set of outcomes of an experiment (e.g., a subset of a sample space) to which a probability is assigned. Additionally or alternatively, the term &#x201c;event&#x201d; at least in some examples refers to a software message indicating that something has happened. Additionally or alternatively, the term &#x201c;event&#x201d; at least in some examples refers to an object in time, or an instantiation of a property in an object. Additionally or alternatively, the term &#x201c;event&#x201d; at least in some examples refers to a point in space at an instant in time (e.g., a location in space-time). Additionally or alternatively, the term &#x201c;event&#x201d; at least in some examples refers to a notable occurrence at a particular point in time.</p><p id="p-0390" num="0373">The term &#x201c;service level agreement&#x201d; or &#x201c;SLA&#x201d; at least in some examples refers to a level of service expected from a service provider. At least in some examples, an SLA may represent an entire agreement between a service provider and a service consumer that specifies one or more services is to be provided, how the one or more services are to be provided or otherwise supported, times, locations, costs, performance, priorities for different traffic classes and/or QoS classes (e.g., highest priority for first responders, lower priorities for non-critical data flows, and the like), and responsibilities of the parties involved.</p><p id="p-0391" num="0374">The term &#x201c;service level objective&#x201d; or &#x201c;SLO&#x201d; at least in some examples refers to one or more measurable characteristics, metrics, or other aspects of an SLA such as, for example, availability, throughput, frequency, response time, latency, QoS, QoE, and/or other like performance metrics/measurements. At least in some examples, a set of SLOs may define an expected service (or an service level expectation (SLE)) between the service provider and the service consumer and may vary depending on the service's urgency, resources, and/or budget.</p><p id="p-0392" num="0375">The term &#x201c;service level indicator&#x201d; or &#x201c;SLI&#x201d; at least in some examples refers to a measure of a service level provided by a service provider to a service consumer. At least in some examples, SLIs form the basis of SLOs, which in turn, form the basis of SLAs. Examples of SLIs include latency (including e2e latency), throughout, availability, error rate, durability, correctness, and/or other like performance metrics/measurements. At least in some examples, term &#x201c;service level indicator&#x201d; or &#x201c;SLI&#x201d; can be referred to as &#x201c;SLA metrics&#x201d; or the like.</p><p id="p-0393" num="0376">The term &#x201c;service level expectation&#x201d; or &#x201c;SLE&#x201d; at least in some examples refers to an unmeasurable service-related request, but may still be explicitly or implicitly provided in an SLA even if there is little or no way of determining whether the SLE is being met. At least in some examples, an SLO may include a set of SLIs that produce, define, or specify an SLO achievement value. As an example, an availability SLO may depend on multiple components, each of which may have a QoS availability measurement. The combination of QoS measures into an SLO achievement value may depend on the nature and/or architecture of the service.</p><p id="p-0394" num="0377">Although many of the previous examples are provided with use of specific cellular/mobile network terminology, including with the use of 4G/5G 3GPP network components (or expected terahertz-based 6G/6G+ technologies), it will be understood these examples may be applied to many other deployments of wide area and local wireless networks, as well as the integration of wired networks (including optical networks and associated fibers, transceivers, etc.). Furthermore, various standards (e.g., 3GPP, ETSI, etc.) may define various message formats, PDUs, containers, frames, and/or other data structures, as comprising a sequence of optional or mandatory data elements (DEs), data frames (DFs), information elements (IEs), and/or the like. However, the requirements of any particular standard should not limit the scope of the present disclosure, and as such, any combination of containers, frames, DFs, DEs, IEs, values, components, fields, actions, features, and/or data structures are possible, including any combination of containers, frames, DFs, DEs, IEs, values, components, fields, actions, features, and/or data structures that are strictly required to be followed in order to conform to such standards or any combination of containers, frames, DFs, DEs, IEs, values, components, fields, actions, features, and/or data structures strongly recommended and/or used with or in the presence/absence of optional elements.</p><p id="p-0395" num="0378">The present disclosure includes the aforementioned description and the accompanying drawings. The present disclosure shows and described, by way of examples and not of limitation, specific implementations in which the subject matter may be practiced. The present disclosure shows and describes the inventive aspects in sufficient detail to enable those skilled in the art to practice the teachings disclosed herein. Although the present disclosure shows and describes specific example implementations, various modifications and changes may be made to these implementations without departing from the broader scope of the present disclosure. Other aspects may be utilized and derived from the implementations discussed herein, such that structural and logical substitutions and changes may be made without departing from the scope of the present disclosure. The present disclosure is not to be taken in a limiting sense, and the scope of various aspects is defined by the appended claims, along with the full range of equivalents to which such claims are entitled.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-01-45" num="01-45"><claim-text><b>1</b>-<b>45</b>. (canceled)</claim-text></claim><claim id="CLM-00046" num="00046"><claim-text><b>46</b>. An apparatus to provide flow-specific slicing, the apparatus comprising:<claim-text>processor circuitry connected to memory circuitry, wherein the processor circuitry is to execute instructions to:<claim-text>cause instantiation of a virtual lane in a data center network (DCN) to be used for a flow-specific slice for a service hosted by a service provider environment;</claim-text><claim-text>map a network slice instance (NSI) in a communication network (NW) to the instantiated virtual lane; and</claim-text><claim-text>cause an end-to-end (e2e) connection to be established for the flow-specific slice, wherein the e2e connection is established between a user application operated by a user device and a service provider application operated by the service provider environment, and the flow-specific slice includes the instantiated virtual lane and the NSI based on the mapping.</claim-text></claim-text></claim-text></claim><claim id="CLM-00047" num="00047"><claim-text><b>47</b>. The apparatus of <claim-ref idref="CLM-00046">claim 46</claim-ref>, wherein the processor circuitry is to execute the instructions to:<claim-text>send a request for network slice creation to an NW orchestrator in the NW, wherein the request is to cause the NW orchestrator to create the NSI; and</claim-text><claim-text>receive, from the NW orchestrator, a response based on the request for network slice creation, wherein the response includes network slice configuration information for the NSI.</claim-text></claim-text></claim><claim id="CLM-00048" num="00048"><claim-text><b>48</b>. The apparatus of <claim-ref idref="CLM-00047">claim 47</claim-ref>, wherein the NW orchestrator is one or more of an RAN intelligent controller (RIC) in an Open RAN Alliance (O-RAN) framework; a Network Slice Management Function (NSMF) in a Third Generation Partnership Project (3GPP) Fifth Generation (5G) system, a 3GPP 5G Network Slice Orchestrator, a Zero-touch System Management (ZSM) function in a ZSM framework, an Open Network Automation Platform (ONAP) module in an ONAP framework, a Network Slice Controller in an IETF Network Slice framework, a Network Slice Orchestrator in an IETF Network Slice framework, and a container orchestration engine in a containerization framework.</claim-text></claim><claim id="CLM-00049" num="00049"><claim-text><b>49</b>. The apparatus of <claim-ref idref="CLM-00047">claim 47</claim-ref>, wherein the request is to cause the NW orchestrator to instruct a radio access network (RAN) to provision resources for the network slice or instruct a core network (CN) to provision resources for the network slice.</claim-text></claim><claim id="CLM-00050" num="00050"><claim-text><b>50</b>. The apparatus of <claim-ref idref="CLM-00047">claim 47</claim-ref>, wherein the request includes quality of service (QoS) parameters for the flow-specific slice or the NSI, wherein the QoS parameters are based on a service level agreement (SLA) defined for the flow-specific slice.</claim-text></claim><claim id="CLM-00051" num="00051"><claim-text><b>51</b>. The apparatus of <claim-ref idref="CLM-00050">claim 50</claim-ref>, wherein the request includes user information related to the user device, and a length of time or a set of time periods during which the flow-specific slice is to be active or inactive.</claim-text></claim><claim id="CLM-00052" num="00052"><claim-text><b>52</b>. The apparatus of <claim-ref idref="CLM-00047">claim 47</claim-ref>, wherein the response includes a network slice identifier (ID) assigned to the NSI.</claim-text></claim><claim id="CLM-00053" num="00053"><claim-text><b>53</b>. The apparatus of <claim-ref idref="CLM-00047">claim 47</claim-ref>, wherein the processor circuitry is to execute the instructions to:<claim-text>provision the service provider application with a flow-specific slice configuration based on the network slice configuration information.</claim-text></claim-text></claim><claim id="CLM-00054" num="00054"><claim-text><b>54</b>. The apparatus of <claim-ref idref="CLM-00053">claim 53</claim-ref>, wherein the processor circuitry is to execute the instructions to:<claim-text>receive network slice feedback from the NW, wherein the feedback includes metrics related to operation of the network slice in the NW;</claim-text><claim-text>update the flow-specific slice configuration based on the received feedback; and</claim-text><claim-text>provision the service provider application with the updated flow-specific slice configuration, wherein the updated flow-specific slice configuration is to cause changes to QoS parameters of the flow-specific slice or cause changes to resources allocated to the flow-specific slice.</claim-text></claim-text></claim><claim id="CLM-00055" num="00055"><claim-text><b>55</b>. The apparatus of <claim-ref idref="CLM-00046">claim 46</claim-ref>, wherein the flow-specific slice belongs to a data flow, and flow-specific packets belonging to the data flow are communicated between the user application and the service provider application in the flow-specific slice, and wherein the processor circuitry is to execute the instructions to:<claim-text>determine whether received packets belong to the data flow based on metadata included in the received packets.</claim-text></claim-text></claim><claim id="CLM-00056" num="00056"><claim-text><b>56</b>. The apparatus of <claim-ref idref="CLM-00055">claim 55</claim-ref>, wherein, to determine whether received packets belong to the data flow, the processor circuitry is to execute the instructions to:<claim-text>extract the metadata from the received packets;</claim-text><claim-text>compare the extracted metadata with flow-specific slice information of the flow-specific slice; and</claim-text><claim-text>route the received packets to be sent over the flow-specific slice when the extracted metadata matches the flow-specific slice information.</claim-text></claim-text></claim><claim id="CLM-00057" num="00057"><claim-text><b>57</b>. The apparatus of <claim-ref idref="CLM-00056">claim 56</claim-ref>, wherein a service mesh is used to route the received packets to the service provider application, and route packets processed by the service provider application to the flow-specific slice.</claim-text></claim><claim id="CLM-00058" num="00058"><claim-text><b>58</b>. The apparatus of <claim-ref idref="CLM-00055">claim 55</claim-ref>, wherein the processor circuitry is to execute the instructions to:<claim-text>receive packets from the service provider application that belong to the data flow; and</claim-text><claim-text>insert metadata into header section or a payload section of the received packets, wherein the inserted metadata is to cause the received packets to be routed through the flow-specific slice to the user application.</claim-text></claim-text></claim><claim id="CLM-00059" num="00059"><claim-text><b>59</b>. The apparatus of <claim-ref idref="CLM-00058">claim 58</claim-ref>, wherein the metadata includes one or both of a flow-specific slice ID assigned to the flow-specific slice and a network operator ID assigned to the NW.</claim-text></claim><claim id="CLM-00060" num="00060"><claim-text><b>60</b>. The apparatus of <claim-ref idref="CLM-00046">claim 46</claim-ref>, wherein the NW is a cellular network or a wireless local area network (WLAN), the DCN includes a cloud computing service or an edge computing network, and the apparatus is a service provider orchestrator in the service provider environment or a DCN orchestrator in the DCN.</claim-text></claim><claim id="CLM-00061" num="00061"><claim-text><b>61</b>. The apparatus of <claim-ref idref="CLM-00060">claim 60</claim-ref>, wherein:<claim-text>the service provider orchestrator is one or more of a RIC in an O-RAN framework, an NSMF in a 3GPP 5G system, a Network Slice Orchestrator in a 3GPP 5G system, a ZSM function in a ZSM framework, an ONAP module in an ONAP framework, a Network Slice Controller in an IETF Network Slice framework, a Network Slice Orchestrator in an IETF Network Slice framework, and a container orchestration engine in a containerization framework; and</claim-text><claim-text>the DCN orchestrator is one or more of a RIC in an O-RAN framework; an NSMF in a 3GPP 5G system, a Network Slice Orchestrator in a 3GPP 5G system, a ZSM function in a ZSM framework, an ONAP module in an ONAP framework, a Network Slice Controller in an IETF Network Slice framework, a Network Slice Orchestrator in an IETF Network Slice framework, and a container orchestration engine in a containerization framework.</claim-text></claim-text></claim><claim id="CLM-00062" num="00062"><claim-text><b>62</b>. One or more non-transitory computer-readable media (NTCRM) comprising instructions for flow-specific slicing, wherein execution of the instructions by one or more processors of a compute node is to cause the compute node to:<claim-text>cause instantiation of a virtual lane in a data center network (DCN) to be used for a flow-specific slice for a service hosted by a service provider environment;</claim-text><claim-text>send a request for network slice creation to a network (NW) orchestrator in communication NW, wherein the request is to cause the NW orchestrator to create a network slice instance (NSI);</claim-text><claim-text>receive, from the NW orchestrator, a response based on the request for network slice creation, wherein the response includes network slice configuration information for the NSI;</claim-text><claim-text>map the NSI in the NW to the instantiated virtual lane;</claim-text><claim-text>provision a service provider application operated by the service provider environment with a flow-specific slice configuration based on the network slice configuration information; and</claim-text><claim-text>cause an end-to-end (e2e) connection to be established for the flow-specific slice, wherein the e2e connection is established between a user application operated by a user device and the service provider application, and the flow-specific slice includes the instantiated virtual lane and the NSI based on the mapping.</claim-text></claim-text></claim><claim id="CLM-00063" num="00063"><claim-text><b>63</b>. The one or more NTCRM of <claim-ref idref="CLM-00062">claim 62</claim-ref>, wherein the request is to cause the NW orchestrator to instruct a radio access network (RAN) to provision resources for the network slice or instruct a core network (CN) to provision resources for the network slice.</claim-text></claim><claim id="CLM-00064" num="00064"><claim-text><b>64</b>. The one or more NTCRM of <claim-ref idref="CLM-00062">claim 62</claim-ref>, wherein:<claim-text>the request includes quality of service (QoS) parameters for the flow-specific slice or the NSI, user information related to the user device, and a length of time or a set of time periods during which the flow-specific slice is to be active or inactive, and wherein the QoS parameters are based on a service level agreement (SLA) defined for the flow-specific slice; and</claim-text><claim-text>the network slice configuration information includes a network slice identifier (ID) assigned to the NSI.</claim-text></claim-text></claim><claim id="CLM-00065" num="00065"><claim-text><b>65</b>. The one or more NTCRM of <claim-ref idref="CLM-00062">claim 62</claim-ref>, wherein execution of the instructions is to cause the compute node to:<claim-text>receive network slice feedback from the NW, wherein the feedback includes metrics related to operation of the network slice in the NW;</claim-text><claim-text>update the flow-specific slice configuration based on the received feedback; and</claim-text><claim-text>provision the service provider application with the updated flow-specific slice configuration, wherein the updated flow-specific slice configuration is to cause changes to QoS parameters of the flow-specific slice or cause changes to resources allocated to the flow-specific slice.</claim-text></claim-text></claim><claim id="CLM-00066" num="00066"><claim-text><b>66</b>. The one or more NTCRM of <claim-ref idref="CLM-00062">claim 62</claim-ref>, wherein the flow-specific slice belongs to a data flow, and flow-specific packets belonging to the data flow are communicated between the user application and the service provider application in the flow-specific slice, and wherein execution of the instructions is to cause the compute node to:<claim-text>determine whether received packets belong to the data flow based on metadata included in the received packets, and wherein, to determine whether received packets belong to the data flow, the processor circuitry is to execute the instructions to:</claim-text><claim-text>extract the metadata from the received packets;</claim-text><claim-text>compare the extracted metadata with flow-specific slice information of the flow-specific slice; and</claim-text><claim-text>route the received packets to be sent over the flow-specific slice when the extracted metadata matches the flow-specific slice information.</claim-text></claim-text></claim><claim id="CLM-00067" num="00067"><claim-text><b>67</b>. The one or more NTCRM of <claim-ref idref="CLM-00066">claim 66</claim-ref>, wherein execution of the instructions is to cause the compute node to:<claim-text>receive packets from the service provider application that belong to the data flow; and</claim-text><claim-text>insert metadata into header section or a payload section of the received packets, wherein the inserted metadata is to cause the received packets to be routed through the flow-specific slice to the user application, wherein the metadata includes one or both of a flow-specific slice ID assigned to the flow-specific slice and a network operator ID assigned to the NW.</claim-text></claim-text></claim><claim id="CLM-00068" num="00068"><claim-text><b>68</b>. A method of operating a data center network (DCN) orchestrator in a DCN to provide flow-specific slicing, the method comprising:<claim-text>instantiating a virtual lane in the DCN, wherein the virtual lane is to be used for a flow-specific slice for a service hosted by a service provider environment;</claim-text><claim-text>sending, to a network (NW) orchestrator in a communication NW, a request for network slice creation, wherein the request includes quality of service (QoS) parameters for the flow-specific slice, and the request is to cause the NW orchestrator to create a network slice instance (NSI);</claim-text><claim-text>receiving, from the NW orchestrator, a response based on the request for network slice creation, wherein the response includes network slice configuration information for the NSI, and the network slice configuration information includes a network slice identifier (ID) assigned to the NSI;</claim-text><claim-text>mapping the NSI in the NW to the instantiated virtual lane;</claim-text><claim-text>provisioning a service provider application operated by the service provider environment with a flow-specific slice configuration based on the network slice configuration information; and</claim-text><claim-text>causing an end-to-end (e2e) connection to be established for the flow-specific slice, wherein the e2e connection is established between a user application operated by a user device and the service provider application, and the flow-specific slice includes the instantiated virtual lane and the NSI based on the mapping.</claim-text></claim-text></claim><claim id="CLM-00069" num="00069"><claim-text><b>69</b>. The method of <claim-ref idref="CLM-00068">claim 68</claim-ref>, wherein execution of the instructions is to cause the compute node to:<claim-text>receiving network slice feedback from the NW, wherein the feedback includes metrics related to operation of the network slice in the NW;</claim-text><claim-text>updating the flow-specific slice configuration based on the received feedback; and</claim-text><claim-text>provisioning the service provider application with the updated flow-specific slice configuration, wherein the updated flow-specific slice configuration is to cause changes to QoS parameters of the flow-specific slice or cause changes to resources allocated to the flow-specific slice.</claim-text></claim-text></claim><claim id="CLM-00070" num="00070"><claim-text><b>70</b>. The method of <claim-ref idref="CLM-00068">claim 68</claim-ref>, wherein the flow-specific slice belongs to a data flow, and flow-specific packets belonging to the data flow are communicated between the user application and the service provider application in the flow-specific slice, and wherein execution of the instructions is to cause the compute node to:<claim-text>determining whether received packets belong to the data flow based on metadata included in the received packets, and wherein, to determine whether received packets belong to the data flow, the processor circuitry is to execute the instructions to:</claim-text><claim-text>extracting the metadata from the received packets;</claim-text><claim-text>comparing the extracted metadata with flow-specific slice information of the flow-specific slice; and</claim-text><claim-text>routing the received packets to be sent over the flow-specific slice when the extracted metadata matches the flow-specific slice information.</claim-text></claim-text></claim><claim id="CLM-00071" num="00071"><claim-text><b>71</b>. The method of <claim-ref idref="CLM-00070">claim 70</claim-ref>, wherein execution of the instructions is to cause the compute node to:<claim-text>receiving packets from the service provider application that belong to the data flow; and</claim-text><claim-text>inserting metadata into header section or a payload section of the received packets, wherein the inserted metadata is to cause the received packets to be routed through the flow-specific slice to the user application, wherein the metadata includes one or both of a flow-specific slice ID assigned to the flow-specific slice and a network operator ID assigned to the NW.</claim-text></claim-text></claim></claims></us-patent-application>
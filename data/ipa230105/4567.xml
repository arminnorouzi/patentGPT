<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004568A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004568</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17363208</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>2457</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>24578</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>041</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">MULTIPLE SEMANTIC HYPOTHESES FOR SEARCH QUERY INTENT UNDERSTANDING</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Microsoft Technology Licensing, LLC</orgname><address><city>Redmond</city><state>WA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>WU</last-name><first-name>Ming</first-name><address><city>Kirkland</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>NI</last-name><first-name>Yong</first-name><address><city>Bothell</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>MEI</last-name><first-name>Guo</first-name><address><city>Lynnwood</city><state>WA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Microsoft Technology Licensing, LLC</orgname><role>02</role><address><city>Redmond</city><state>WA</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Examples of the present disclosure describe systems and methods for generating multiple semantic hypotheses for search query intent understanding. In aspects, a search query may be received by a query analysis component associated with a search system. The query analysis component may be used to evaluate the search query for ambiguity in the domain, intent, and/or slot(s) of the search query. A set of hypotheses representing for one or more combinations of the domain, intent, and/or slot(s) of the search query may be generated. The set of hypotheses may be scored and/or ranked. Based on the scores/ranks, one or more of the hypotheses in the set of hypotheses may be provided to a user and/or one or more processing components accessible to the search system.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="84.16mm" wi="158.75mm" file="US20230004568A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="253.07mm" wi="155.62mm" orientation="landscape" file="US20230004568A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="232.16mm" wi="136.74mm" file="US20230004568A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="209.38mm" wi="93.56mm" file="US20230004568A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="233.85mm" wi="179.15mm" file="US20230004568A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="187.88mm" wi="137.67mm" file="US20230004568A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="175.51mm" wi="149.52mm" file="US20230004568A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="232.92mm" wi="171.70mm" file="US20230004568A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="152.06mm" wi="140.80mm" file="US20230004568A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">Search query analysis is a challenging problem in many search systems. Query understanding, in particular, is one of the most challenging issues with search query analysis due to the limited amount of information available at the early stages of a search query analysis. The limited availability of information during the early stages often causes the intent of many search queries to be ambiguous. Additionally, many traditional search systems create and analyze only a single semantic hypothesis for a received search query. For at least these reasons, the search results provided by those search systems may be suboptimal or undesirable to the user.</p><p id="p-0003" num="0002">It is with respect to these and other general considerations that the aspects disclosed herein have been made. Also, although relatively specific problems may be discussed, it should be understood that the examples should not be limited to solving the specific problems identified in the background or elsewhere in this disclosure.</p><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0004" num="0003">Examples of the present disclosure describe systems and methods for generating multiple semantic hypotheses for search query intent understanding. In aspects, a search query may be received by a query analysis component associated with a search system. The query analysis component may be used to evaluate the search query for ambiguity in the domain, intent, and/or slot(s) of the search query. A set of hypotheses representing for one or more combinations of the domain, intent, and/or slot(s) of the search query may be generated. The set of hypotheses may be scored and/or ranked. Based on the scores/ranks, one or more of the hypotheses in the set of hypotheses may be provided to a user and/or one or more processing components accessible to the search system.</p><p id="p-0005" num="0004">This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter. Additional aspects, features, and/or advantages of examples will be set forth in part in the description which follows and, in part, will be apparent from the description, or may be learned by practice of the disclosure.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0006" num="0005">Non-limiting and non-exhaustive examples are described with reference to the following figures.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an overview of an example system for generating multiple semantic hypotheses for search query intent understanding.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example input processing system for generating multiple semantic hypotheses for search query intent understanding.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example method for generating multiple semantic hypotheses for search query intent understanding.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram illustrating example physical components of a computing device with which aspects of the disclosure may be practiced.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref> are simplified block diagrams of a mobile computing device with which aspects of the present disclosure may be practiced.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a simplified block diagram of a distributed computing system in which aspects of the present disclosure may be practiced.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a tablet computing device for executing one or more aspects of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0014" num="0013">Many traditional search systems utilize one or more intelligence components to perform search query analysis. A query understanding component is one of these intelligence components and provides semantic analysis of a received search query. One of the most challenging issues with performing query understanding is detecting and resolving search query ambiguity. Detecting search query ambiguity is often difficult using traditional search systems due to the limited amount of information available at the early stages of search query analysis. As one example, a search query may be ambiguous due to short and unstructured query formatting that lacks semantic context. For instance, the search query &#x201c;Washington plan&#x201d; is ambiguous as to whether &#x201c;Washington&#x201d; refers to a person or a location, and whether &#x201c;plan&#x201d; refers to a document, a project, or something else. As another example, a search query may be ambiguous due to grammatical ambiguity. For instance, the search query &#x201c;Find documents from Julian Alexander&#x201d; is ambiguous as to whether the search query refers to two people (e.g., &#x201c;Julian&#x201d; and &#x201c;Alexander&#x201d;) or only one person. As yet another example, a query or request may be ambiguous due to situational ambiguity. For instance, the query &#x201c;Share the presentation&#x201d; is ambiguous as to whether the query refers to displaying the presentation on a display screen or to sending the presentation to a recipient.</p><p id="p-0015" num="0014">The difficulty of detecting search query ambiguity using traditional search systems is exacerbated in enterprise systems, which often incorporate a personalized and contextualized content index comprising data specific to the enterprise and/or to one or more members of the enterprise. Ambiguity is exacerbated because the enterprise content index may comprise terms/concepts that are in conflict with terms/concepts in data sources that are not specific to (or controlled by) the enterprise. As one example, a search query may be ambiguous due to the inherent ambiguity of personalized content. For instance, the search query &#x201c;NFL&#x201d; is ambiguous as to whether &#x201c;NFL&#x201d; refers to an enterprise-agnostic term/concept (e.g., &#x201c;National Football League&#x201d;) or to an enterprise-specific term/concept (e.g., &#x201c;Negative Feedback Loop&#x201d;). Similarly, the search query &#x201c;Call Greg&#x201d; is ambiguous as to whether &#x201c;Greg&#x201d; refers to a member of the enterprise or to a personal contact of the user (e.g., a non-member of the enterprise).</p><p id="p-0016" num="0015">Another challenging issue with performing query understanding is that many traditional search systems implement an &#x201c;early binding&#x201d; approach, where a single hypothesis is generated and selected for a search query prior to evaluating the result data or overall context of the search query. For example, data from a single data source or a single data domain may be used to evaluate a search query. Although the search query may be ambiguous for one or more of the reasons discussed above, a single hypothesis may be generated for the search query. The hypothesis may be based on or limited to the context of the data source or the data domain. For instance, a user having a contact named &#x201c;August&#x201d; may enter the search query &#x201c;August email&#x201d; into an email application. A search system associated with the email application may determine the context of the search query is &#x201c;email search&#x201d; because the search query was received by the email application. Accordingly, the email application data may be searched for instances of or relating to &#x201c;August.&#x201d; As the only reference (or predominant reference) to &#x201c;August&#x201d; may be to a date, a hypothesis in which &#x201c;August&#x201d; refers to a date may be generated. The hypothesis may then be used to provide search results comprising a list of emails sent by the user during the month of August. As the user may have intended the search query to retrieve emails sent to or received from the user contact August, the user may be dissatisfied with the search results. Consequently, the user may be required to reformat and re-execute the query, or to use an alternative application or search system to execute the search query. Both of these scenarios waste the user's time and require additional computational processing to occur, which may severely diminish the user experience.</p><p id="p-0017" num="0016">The present disclosure describes systems and methods for generating multiple semantic hypotheses for search query intent understanding. In examples, a search query may be received by a search system implementing a search engine, a search service, or a similar search tool/utility. The search query may be provided to a query analysis component of or associated with the search system. The query analysis component may evaluate the search query to determine whether one or more parts (e.g., domains, intents, and/or slots) of the search query are ambiguous. In examples, a domain may refer to an area of knowledge (e.g., cryptography, cloud computing, artificial intelligence, sports) or a container/boundary that isolates or defines an application, software functionality, or a set of data (e.g., &#x201c;email&#x201d; domain, &#x201c;user contact&#x201d; domain, &#x201c;software development&#x201d; domain). For instance, the search query &#x201c;Find August emails&#x201d; may be assigned to the &#x201c;email&#x201d; domain. An intent may refer to the goal or an intention of user's search query, request, or other entered input. For instance, the user intent of the search query &#x201c;Find August emails&#x201d; may be to view emails from the user August or emails from the month of August. Accordingly, the &#x201c;find emails&#x201d; intent may be assigned to the search query. A slot may refer to the actionable content within the search query, request, or other entered input. For instance, the search query term &#x201c;August&#x201d; may be assigned to the slot &#x201c;date&#x201d; and/or to the slot &#x201c;user contact.&#x201d; The search query may be evaluated using, for example, a rule-based model or algorithm, a machine learning model or algorithm, or a regular expression. The evaluation may include an analysis of user activity and/or user data associated with one or more applications, services, enterprises, groups, data sources, or entities.</p><p id="p-0018" num="0017">For one or more potential combinations of the search query parts, a hypothesis may be generated. In examples, a hypothesis may represent a potential search query candidate or a statement of user intent for the search query. A hypothesis may comprise one or more domains, intents, and/or slots associated with a search query. A hypothesis may also comprise a confidence score, rating, or label indicating a likelihood that the hypothesis is accurate or is relevant to the search query. A set of the generated hypotheses may be ranked using one or more ranking models or algorithms implemented by or accessible to the query analysis component. One or more of the ranked hypotheses may be provided to a user in response to the search query. Alternatively, one or more of the ranked hypotheses may be provided to one or more processing components accessible to the search system. For example, one or more of the ranked hypotheses may be provided to a processing component, such as an application, a service, or another component that is downstream of the search system. The processing component(s) may generate search results (or additional search results) for the ranked hypotheses. One or more of the search results from the processing component(s) may be merged into a set of search results. The merged set of search results may be provided the user as a response to the search query.</p><p id="p-0019" num="0018">Accordingly, the present disclosure provides a plurality of technical benefits including but not limited to: generating and ranking multiple hypotheses for a search query using a hypothesis ranking algorithm or model, leveraging a wide range of input knowledge during query understanding using an ambiguity detection engine, providing improved intent classification and sequence labeling using a hypothesis generation mechanism, implementing a hypothesis generation mechanism to provide a late-binding approach to query understanding (e.g., multiple potential hypotheses are generated and evaluated based on information from various data sources), using a postprocessing engine to enable downstream components to facilitate query disambiguation, using an ambiguity detection engine to improve search query intent understanding in enterprise environments, using a postprocessing engine to collect user response feedback to improve search query optimization, among other examples.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an overview of an example system for generating multiple semantic hypotheses for search query intent understanding. Example system <b>100</b> as presented is a combination of interdependent components that interact to form an integrated whole. Components of system <b>100</b> may be hardware components or software components (e.g., applications, application programming interfaces (APIs), modules, virtual machines, or runtime libraries) implemented on and/or executed by hardware components of system <b>100</b>. In one example, components of systems disclosed herein may be implemented on a single processing device. The processing device may provide an operating environment for software components to execute and utilize resources or facilities of such system. An example of one or more processing devices comprising such an operating environment is depicted in <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>7</b></figref>. In another example, the components of systems disclosed herein may be distributed across multiple processing devices. For instance, input may be entered on a user device or client device and information may be processed on or accessed from other devices in a network, such as one or more remote cloud devices or web server devices.</p><p id="p-0021" num="0020">In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, system <b>100</b> comprises user devices <b>102</b>A, <b>102</b>B, and <b>102</b>C (collectively &#x201c;user device(s) <b>102</b>&#x201d;), network <b>106</b>, search service <b>108</b>, and data store(s) <b>112</b>. One of skill in the art will appreciate that the scale and structure of systems such as system <b>100</b> may vary and may include additional or fewer components than those described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. As one example, user device(s) <b>102</b> may comprise or locally access search service <b>108</b> and/or data store(s) <b>112</b>.</p><p id="p-0022" num="0021">User device(s) <b>102</b> may be configured to detect and/or collect input data from one or more users or devices. The input data may correspond to user interaction with one or more software applications or services implemented by, or accessible to, user device(s) <b>102</b>. The input data may include, for example, voice input, touch input, text-based input, gesture input, video input, and/or image input. The input data may be detected/collected using one or more sensor components of user device(s) <b>102</b>. Examples of sensors include microphones, touch-based sensors, geolocation sensors, accelerometers, optical/magnetic sensors, gyroscopes, keyboards, and pointing/selection tools. Examples of user device(s) <b>102</b> may include, but are not limited to, personal computers (PCs), mobile devices (e.g., smartphones, tablets, laptops, personal digital assistants (PDAs)), wearable devices (e.g., smart watches, smart eyewear, fitness trackers, smart clothing, body-mounted devices, head-mounted displays), and gaming consoles or devices.</p><p id="p-0023" num="0022">User device(s) <b>102</b> may comprise or otherwise have access to application(s) <b>104</b>. Examples of application(s) <b>104</b> may include, but are not limited to, word processing applications, spreadsheet application, presentation applications, document-reader software, social media software/platforms, search engines, media software/platforms, multimedia player software, content design software/tools, and database applications. Application(s) <b>104</b> may enable users to access and/or interact with one or more types of content, such as text, audio, images, video, animation, and multimedia (e.g., a combination of text, audio, images, video, and/or animation). For instance, application(s) <b>104</b> may comprise or have access to a corpus of content sources (e.g., documents, files, applications, services, web content) including various types of content. Application(s) <b>104</b> may also enable users to input one or more search queries or requests for search content. As one example, application(s) <b>104</b> may enable a user to enter a text-based search query into or select a text-based query from an input element, such as a text field, a radio button, or a dropdown list. In at least one example, application(s) <b>104</b> may also enable a user to specify a search query that is not text-based. For instance, the user may provide a search query in the form of image data, audio data, haptic data, gesture data, or some combination thereof using one or more input elements.</p><p id="p-0024" num="0023">Application(s) <b>104</b> may provide search query (or cause the search query to be provided to) search system <b>108</b> via network <b>106</b>. For instance, application(s) <b>104</b> may provide a &#x201c;Search&#x201d; button, a &#x201c;Find Similar&#x201d; button/option, or a similar search initiation mechanism. Examples of network <b>106</b> may include a private area network (PAN), a local area network (LAN), a wide area network (WAN), and the like. Although network <b>104</b> is depicted as a single network, it is contemplated that network <b>106</b> may represent several networks of similar or varying types.</p><p id="p-0025" num="0024">Search system <b>108</b> may be configured to receive and process search queries received from application(s) <b>104</b>, user device(s) <b>102</b>, and/or other computing devices. In examples, search system <b>108</b> may be implemented in one or more computing devices, service environments, or applications, including application(s) <b>104</b>. Example computing devices or service environments may include server devices (e.g., web servers, file servers, application servers, database servers), cloud computing devices/services (e.g., Infrastructure as a Service (IaaS), Platform as a Service (PaaS), Software as a Service (SaaS), Functions as a Service (FaaS)), virtual devices, PCs, or the like. The computing devices may comprise one or more sensor components, as discussed with respect to user device(s) <b>102</b>. In some examples, search system <b>108</b> may comprise or provide access to one or more search mechanisms for retrieving content and/or accessing content sources. Examples of search mechanisms include web search engines, content discovery services, database search engines, and similar content searching utilities.</p><p id="p-0026" num="0025">Search system <b>108</b> may comprise or otherwise have access to machine learning model(s) <b>110</b>. Search system <b>108</b> may provide received search queries (or content thereof) to machine learning model(s) <b>110</b> as input. In examples, machine learning model(s) <b>110</b> may represent a predictive or statistical utility or program that may be used to identify or predict a response value from one or more predictors. A model may be based on, or incorporate, one or more rule sets, machine learning, a neural network, or the like. Machine learning model(s) <b>110</b> may be trained to implement query understanding to provide semantic analysis of search queries. The semantic analysis may include detecting ambiguity in a search query, generating one or more hypotheses for the search query, ranking/sorting the hypotheses, and providing a set of ranked/sorted search query results to a user and/or one or more processing components accessible to search system <b>108</b>. In some examples, machine learning model(s) <b>110</b> may access data store(s) <b>112</b> during the query understanding process.</p><p id="p-0027" num="0026">Data store(s) <b>112</b> may store content from one or more content sources, such as web-based data sources, enterprise-based data sources, and/or user owned or controlled (e.g., personal or private) data sources. As one example, data store(s) <b>112</b> may comprise user data (e.g., user account/identification data, user data index, user profile/settings, user knowledge graph, user's stored documents and files) and/or application data (e.g., user activity data, user behavioral history, user contact data, user communication data) relating to the user (or user device) that provided the search query. Machine learning model(s) <b>110</b> may use the user data and/or application data as additional information for generating relevant hypotheses for a received search query. As another example, data store(s) <b>112</b> may comprise result data and data resources (e.g., documents, services, knowledge graph content, image content, video content) that satisfy or are relevant to the search request. Machine learning model(s) <b>110</b> may use the result data and data resources to generate search results for the search query. Examples of data store(s) <b>112</b> include, but are not limited to, databases, file systems, file directories, flat files, and virtualized storage systems.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example input processing system for generating multiple semantic hypotheses for search query intent understanding. The techniques implemented by input processing system <b>200</b> may comprise the techniques and data described in system <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Although examples in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and subsequent figures will be discussed in the context of text content, the examples are equally applicable to other types of content, such as image content, and video content. In some examples, one or more data and components described in <figref idref="DRAWINGS">FIG. <b>2</b></figref> (or the functionality thereof) may be distributed across multiple devices. In other examples, a single device may comprise the data and components described in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0029" num="0028">In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, input processing system <b>200</b> comprises search service <b>202</b>, search service <b>202</b> may be configured to receive and process search queries received from one or more users, applications, computing devices, or computing environments. In examples, search service <b>202</b> may be implemented as a standalone service or may be integrated into an application, program, or computing environment, such as an enterprise environment. Search service <b>202</b> may comprise ambiguity detection mechanism <b>204</b>, hypothesis generation mechanism <b>206</b>, and hypothesis ranking mechanism <b>208</b>, and postprocessing engine <b>210</b>. One of skill in the art will appreciate that the scale of input processing system <b>200</b> may vary and may include additional or fewer components than those described in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. As one example, input processing system <b>200</b> may further comprise a search query preprocessing engine, a user interface enabling a user to interact directly with search service <b>202</b>, and/or one or more data sources comprising various data content and data resources. As another example, search service <b>202</b> may leverage or include one or more traditional language understanding models.</p><p id="p-0030" num="0029">Ambiguity detection mechanism <b>204</b> may be configured to detect ambiguity in received search queries (and other received input). Detecting ambiguity may include identifying one or more input signals associated with a search query. Example input signals may include application entry points (e.g., the application detecting and/or providing the search query), user device data (e.g., device identifier, device configuration) personalized context data (e.g., user's personal documents, activity information, and other user data), tenant-level context data (e.g., topics/concepts and acronyms known to an enterprise/organization, document information owned and/or accessible by an enterprise/organization, enterprise knowledge graph information), common world data (e.g., topics/concepts and acronyms known to the general public, publicly accessible documents, resource, and information).</p><p id="p-0031" num="0030">Ambiguity detection mechanism <b>204</b> may identify and/or collect the input signals from one or more data sources using data parsing and/or pattern matching techniques. For example, ambiguity detection mechanism <b>204</b> may parse the search query into one or more tokens (e.g., terms or phrases). The search query tokens may be used to identify input signals associated with user data, a user device, and/or application data stored by or accessible to input processing system <b>200</b>. Identifying the input signals may include the use of a rule-based model or algorithm, a machine learning model or algorithm, or a regular expression. For instance, a language understanding (LU) model may evaluate the search query tokens against multiple data sets corresponding to one or more concepts or topics, applications or services, data domains, enterprise segments (e.g., groups or departments), or entities (e.g., enterprises, organizations, countries). The evaluation may comprise matching a search query token to data in a data set.</p><p id="p-0032" num="0031">Ambiguity detection mechanism <b>204</b> may use the input signals to determine whether there is ambiguity at the domain level, intent level, and/or slot level of the search query. The determination may comprise determining whether a search query token is identified in multiple data sets, identifying whether a search query token has multiple meanings or contexts in one or more data sets, or identifying synonyms and/or acronyms for a search query token, or identifying usage of a search query token in previous search queries. As a specific example, the search query token &#x201c;August&#x201d; may be identified in the &#x201c;Calendar&#x201d; data domain, the &#x201c;Personal Contacts&#x201d; data domain, and the &#x201c;Enterprise Contacts&#x201d; data domain. Based on the input signals for the search query, ambiguity detection mechanism <b>204</b> may generate a set of features. The set of features may identify one or more combinations of the domains, intents, and/or slots for one or more search query tokens. For instance, the set of features may indicate that a search query token may indicate a slot referring to a date (e.g., slot:date) or a slot referring to a user contact (e.g., slot:contact_name).</p><p id="p-0033" num="0032">Hypothesis generation mechanism <b>206</b> is configured to generate one or more hypotheses for a search query. In examples, hypothesis generation mechanism <b>206</b> may receive or otherwise have access to a set of features generated by ambiguity detection mechanism <b>204</b>. Hypothesis generation mechanism <b>206</b> may apply one or more hypothesis modeling techniques to the set of features. As one example, hypothesis generation mechanism <b>206</b> may apply a pattern-based approach, in which a semantic pattern of the search query is analyzed to determine whether the search query tokens of the search query match a predefined order or structure. For instance, the most used sentence structure for scheduling a meeting may be determined to be &#x201c;&#x3c;Action&#x3e;&#x3c;Event&#x3e;&#x3c;User&#x3e;&#x3c;Time&#x3e;&#x201d; (e.g., &#x201c;&#x3c;Schedule&#x3e; a &#x3c;meeting&#x3e; with &#x3c;David&#x3e; at &#x3c;noon&#x3e;&#x201d;). Hypothesis generation mechanism <b>206</b> may determine whether the number and order of the search query tokens matches the four slots (e.g., &#x3c;Action&#x3e;, &#x3c;Event&#x3e;, &#x3c;User&#x3e;, &#x3c;Time&#x3e;) of the sentence structure. If a requisite number and/or order of the search query tokens match a predefined order or structure, a hypothesis corresponding to the indicated intent (e.g., scheduling a meeting) may be generated. For instance, if at least three of the four slots match the predefined order/structure, or comprise terms that match, are semantically similar to, or are synonymous with the terms expected for the predefined order/structure, a hypothesis corresponding to the indicated intent of the predefined order/structure may be generated. However, if a requisite number and/or order of the search query tokens do not match the predefined order or structure, a hypothesis corresponding to the indicated intent may not be generated.</p><p id="p-0034" num="0033">As another example, hypothesis generation mechanism <b>206</b> may apply a machine learning model, in which a semantic pattern of the search query is analyzed to calculate search query parts (e.g., domain, intent, slot) probabilities based on data domain or data category. For instance, a search query structure in which a preposition is followed by a username may be highly indicative of a first domain, whereas a verb followed by a username may be highly indicative of a second domain. Example machine learning models may include neural networks, decision tree algorithms, logistic regression algorithms, support vector machines (SVM) algorithms, k-nearest-neighbor (KNN) algorithms, Na&#xef;ve Bayes classifiers, linear regression algorithms, and k-means clustering algorithms, and conditional random field (CRF) models. In some examples, different machine learning models may be used to tag one or more of the search query parts. For instance, a CRF model may be used for slot tagging and a long short-term memory (LSTM) neural network may be used for domain and/or intent tagging.</p><p id="p-0035" num="0034">Hypothesis generation mechanism <b>206</b> may generate a hypothesis for one or more features in the set of features. A hypothesis may comprise a combination of domains, intents, and/or slots associated with a feature. As a specific example, the feature &#x201c;slot:date&#x201d; may be represented as &#x201c;domain:calendar, intent:search_calendar, slot:date:&#x3c;value&#x3e;.&#x201d; A hypothesis may also comprise a confidence metric (e.g., score, rating, or label) indicating a likelihood that the hypothesis is accurate or is relevant to the search query. The confidence metric may be appended to or otherwise associated with a hypothesis.</p><p id="p-0036" num="0035">Hypothesis ranking mechanism <b>208</b> may be configured to rank hypotheses. In examples, hypothesis ranking mechanism <b>208</b> may extract one or more features of a hypothesis. The features may be provided to a ranking model/algorithm. Alternatively, the extracted features may be used to construct one or more feature vectors (e.g., an n-dimensional vector of numerical features that represent one or more objects), which may be provided to a ranking/algorithm model. Example ranking models/algorithms may implement pointwise approaches (e.g., Pranking, McRank, Combined Regression and Ranking (CRR)), pairwise approaches (e.g., RankNet, LambdaRank, LambdaMART), and/or listwise approaches (e.g., PermuRank, NDCG Boost, ES-Rank).</p><p id="p-0037" num="0036">Based on the received features (or feature vectors(s)), the ranking model/algorithm may apply weights to and rank the hypotheses. The ranking may be based on one or more factors, such as application/service entry point, application/service context (e.g., whether active and/or in focus, application/service feature being used), user access privileges to data/data sources, historical user behavior, search query tokens, or semantic analysis data for the search query (e.g., likelihood that search query terms would be used in certain ways or orders to confer certain meanings). In some examples, the rankings may be used to modify the confidence metrics of the hypotheses. For instance, the rankings may be added or applied as a weight to the confidence metrics. In other examples, the confidence metrics may be provided to the ranking model as a feature. Accordingly, the rankings may be standalone and/or final values. Hypothesis ranking mechanism <b>208</b> may sort the hypotheses according to the rankings. For instance, the hypotheses may be sorted in descending rank order.</p><p id="p-0038" num="0037">Postprocessing engine <b>210</b> may be configured to process ranked hypotheses and/or search results. In one example, postprocessing engine <b>210</b> may provide one or more of the ranked hypotheses to a user in response to a search query. The ranked hypotheses may be provided as a set of candidate data items (e.g., responses, search queries, data resource links) that may presented in a display order that is consistent with the rankings for the hypotheses. Postprocessing engine <b>210</b> may enable a user to select one or more of the candidate data items. The user selection may be used to confirm the user intent of the search query. A search query may be executed and/or search results may be retrieved based on the selected candidate data item. In some examples, the indication of the user selection may be provided to one or more components of search service <b>202</b>. The indication of the user selection may be used to train or update one or more models or algorithms to optimize search query processing.</p><p id="p-0039" num="0038">In another example, postprocessing engine <b>210</b> may provide one or more of the ranked hypotheses to one or more processing components (e.g., applications, services, or computing devices) that are downstream of search service <b>202</b>. For example, a first ranked hypothesis may be used to retrieve search results from a first application (such as an email application), a second ranked hypothesis may be used to retrieve search results from a second application (such as an enterprise user contact application), and the second ranked hypothesis may be used to retrieve search results from a third application (such as an private user contact list). The search results from the processing components may be provided to postprocessing engine <b>210</b>. Postprocessing engine <b>210</b> may merge the search results of the various processing components into a single set of merged search results. The order of the merged search results may be consistent with the rankings for the hypotheses. For example, the search results corresponding to the highest ranked hypothesis may be arranged first in the merged search results (e.g., at the top of the list of merged search results), the search results corresponding to the second highest ranked hypothesis may be arranged second in the merged search results, and so on. Postprocessing engine <b>210</b> may then display the merged search results to the user or provide the merged search results to a user device.</p><p id="p-0040" num="0039">Having described various systems that may be employed by the aspects disclosed herein, this disclosure will now describe one or more methods that may be performed by various aspects of the disclosure. In aspects, method <b>300</b> may be executed by a system, such as system <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> or input processing system <b>200</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. However, method <b>300</b> is not limited to such examples. In other aspects, method <b>300</b> may be performed by a single device or component that integrates the functionality of the components of system <b>100</b> and/or input processing system <b>200</b>. In at least one aspect, method <b>300</b> may be performed by one or more components of a distributed network, such as a web service or a distributed network service (e.g. cloud service).</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example method for generating multiple semantic hypotheses for search query intent understanding. Example method <b>300</b> begins at operation <b>302</b>, where a search query is received. In examples, a search query from a computing device, such as user device(s) <b>102</b>, may be received by a search service, such as search service <b>202</b>. The search query may comprise one or more terms, phrases, questions, or statements. The search query may be submitted to the search service by an application accessible to user device(s) <b>102</b>, such as application(s) <b>104</b>, or submitted directly to the search service via an exposed interface of the search service. For example, a user may input the search query &#x201c;August email&#x201d; into a search service API implemented by an email application. The search service API may provide the search query to the search service.</p><p id="p-0042" num="0041">At operation <b>304</b>, the ambiguity of the search query may be evaluated. In examples, a received search query may be provided to a query analysis component, such as ambiguity detection mechanism <b>204</b>. The query analysis component may parse the search query to identify one or more tokens. For instance, the search query &#x201c;August email&#x201d; may be parsed into the tokens &#x201c;August&#x201d; and &#x201c;email.&#x201d; The token(s) may be provided to an LU model that uses the token(s) to search one or more data sets or data sources for input signals matching, semantically similar to, or relevant to (e.g., similar topic or concept) the token(s). The searching may include the use of named entity recognition, part-of-speech tagging, automatic summarization, sentiment analysis, and/or similar tasks. The data sets or data sources may comprise user data, user device data, and/or application data corresponding to one or more concepts, topics, applications, services, data domains, enterprise segments (e.g., groups or departments), or entities (e.g., enterprises, organizations, countries).</p><p id="p-0043" num="0042">As a specific example, the query analysis component may search for the tokens &#x201c;August&#x201d; and &#x201c;email&#x201d; in one or more data sources of a computing environment. Based on the search token &#x201c;email,&#x201d; the &#x201c;emailsearch&#x201d; domain may be identified as relevant to the search query. In response, input signals from an existing LU model associated with the &#x201c;emailsearch&#x201d; domain may be identified. The input signals may indicate that the token &#x201c;August&#x201d; is recognized as a date in the &#x201c;emailsearch&#x201d; domain (e.g., &#x201c;emailsearch&#x201d; domain: &#x201c;&#x3c;date&#x3e; August&#x3c;/date&#x3e; email&#x201d;). Additionally, based on the search token &#x201c;August,&#x201d; the user's personalized context data may be identified as relevant to the search query. In response, input signals from the personalized context data (or an LU model associated therewith) may be identified. The input signals may indicate that the token &#x201c;August&#x201d; is recognized as a user contact name (e.g., user contact list: [&#x201c;August&#x201d;, &#x201c;Ming&#x201d;, &#x201c;Eric&#x201d;]).</p><p id="p-0044" num="0043">Based on the input signals identified as relevant to the search query, the query analysis component may generate a set of features that identifies one or more combinations of the domains, intents, and/or slots for one or more of the search query tokens. For instance, in the above example, the token &#x201c;email&#x201d; may be tagged as a domain. As ambiguity may not be detected at the domain level (e.g., the token &#x201c;email&#x201d; is only relevant, or is most relevant, to the &#x201c;emailsearch&#x201d; domain), one corresponding feature may be generated (e.g., &#x201c;domain:emailsearch&#x201d;). The token &#x201c;August&#x201d; may be tagged as a slot. Due to the ambiguity as to whether the token &#x201c;August&#x201d; refers to a data or a contact, two corresponding features may be generated (e.g., &#x201c;slot:date&#x201d; and &#x201c;slot:contact_name&#x201d;).</p><p id="p-0045" num="0044">At operation <b>306</b>, one or more hypotheses may be generated for the search query. In examples, the set of features generated by the query analysis component may be provided to a hypothesis component, such as hypothesis generation mechanism <b>206</b>. The hypothesis component may apply one or more hypothesis modeling techniques to the set of features to generate one or more hypotheses. The hypothesis modeling techniques may include a pattern-based approach, in which a semantic pattern of the search query is analyzed to determine whether the search query tokens of the search query match a predefined order or structure. Alternatively, the hypothesis modeling techniques may include the use of a machine learning model, in which a semantic pattern of the search query is analyzed to calculate search query parts probabilities based on data domain or data category.</p><p id="p-0046" num="0045">A generated hypothesis may comprise a structured (or unstructured) combination of domains, intents, and/or slots associated with a corresponding feature. For instance, continuing from the above example, the hypothesis component may determine that the relevant domain for the search query &#x201c;August email&#x201d; is the &#x201c;emailsearch&#x201d; domain and the intent of the search query is to search for emails. Accordingly, the hypothesis component may generate a hypothesis for each feature in the corresponding set of features. The hypothesis for the interpretation of &#x201c;August&#x201d; as a date may be represented as &#x201c;domain:emailsearch, intent:search_email, slots:[date:August],&#x201d; and the hypothesis for the interpretation of &#x201c;August&#x201d; as a user contact may be represented as &#x201c;domain: email search, intent:search_email, slots:[contact_name:August].&#x201d;</p><p id="p-0047" num="0046">The hypothesis component may also generate one or more confidence metrics for the hypotheses, such as a score, a rating, or a label. The confidence metric may indicate a likelihood that a hypothesis is accurate or is relevant to the search query. The confidence metric may be based on the number and/or relevance of input signals associated with the features used to generate a hypothesis. The confidence metric may be also based on additional factors, such as user access level to data or applications, current user context, and historical user activity data. As one example, a hypothesis having a domain that directly matches a search query token may be assigned a higher confidence metric than a hypothesis having a domain that only partially matches a search query.</p><p id="p-0048" num="0047">At operation <b>308</b>, one or more hypotheses may be ranked. In aspects, the hypotheses generated by the hypothesis component may be provided to a ranking component, such as hypothesis ranking mechanism <b>208</b>. The ranking component may apply one or more scores or weights to the features of the hypotheses in order to rank the hypotheses. The ranking may indicate the predicted relevance of a hypothesis to the user's intent for the search query. The ranking may be based on one or more factors, such as the number and/or relevance of input signals associated with the features used to generate a hypothesis, hypothesis confidence metrics, application/service entry point, application/service context (e.g., whether active and/or in focus, application/service feature being used), user access privileges to data/data sources, historical user behavior, search query tokens, or semantic analysis data for the search query (e.g., likelihood that search query terms would be used in certain ways or orders to confer certain meanings).</p><p id="p-0049" num="0048">For example, the ranking component may access information indicating that a user has exchanged several communications (e.g., emails, phone call, texts, chat messages) with the user contact August in the last month. The ranking component may also determine that the user was composing an email message to the user contact August when the search query was received by the search service. Based on this information, the ranking component may add or apply a score, weight, or bonus (e.g., +0.25) to the hypothesis interpreting &#x201c;August&#x201d; as a user contact (e.g., based on communication recency and current user context). The ranking component may further determine that the month is currently July. Based on this information, the ranking component may subtract or apply a score, weight, or penalty (e.g., &#x2212;0.10) to the hypothesis interpreting &#x201c;August&#x201d; as a date (e.g., based on current world knowledge context (that is, August was 11 months ago)). Accordingly, the ranking component may assign a higher score (e.g., 0.95) to the hypothesis interpreting &#x201c;August&#x201d; as a user contact and assign a lower score (e.g., 0.60) to the hypothesis interpreting &#x201c;August&#x201d; as a date. As should be appreciated, alternative scoring formats and methods are contemplated.</p><p id="p-0050" num="0049">In some examples, the ranking component may merge the ranked hypotheses into one or more sets of hypotheses. For instance, the ranked hypotheses may be merged into a single set of hypotheses or the ranked hypotheses may be clustered into multiple sets of hypotheses based on domain, intent, query search token, etc. The ranking component may then sort the merged hypotheses based on one or more criterion. For example, the merged hypotheses may be sorted based on hypothesis ranking.</p><p id="p-0051" num="0050">At operation <b>310</b>, one or more ranked hypotheses may be processed. In aspects, one or more ranked hypotheses may be provided to a postprocessing component, such as postprocessing engine <b>210</b>. The postprocessing component may provide the ranked hypotheses to a user in response to the search query. In one example, ranked hypotheses may be provided as suggested search queries. For instance, the suggested search queries for the search query &#x201c;August emails&#x201d; may be &#x201c;emails from contact August&#x201d; and &#x201c;emails from August 1<sup>st</sup>-31<sup>st</sup>.&#x201d; The processing component may also provide search query refinement options (e.g., &#x201c;emails from August 1<sup>st</sup>-15<sup>th</sup>&#x201d; and &#x201c;emails from August 16<sup>th</sup>-31<sup>st</sup>&#x201d;) and/or related search queries (e.g., &#x201c;emails from contact Augustine,&#x201d; &#x201c;email attachments from contact August,&#x201d; &#x201c;meetings scheduled during August 1<sup>st</sup>-31<sup>st</sup>&#x201d;).</p><p id="p-0052" num="0051">The postprocessing component may also provide the ranked hypotheses to one or more processing components (e.g., applications, services, or computing devices). The ranked hypotheses may be used to retrieve search results from the processing components. For example, a supplemental search query that is formulated from a first hypothesis may be provided to a first application (such as an email application) and a supplemental search query that is formulated from a second hypothesis may be provided to a second application (such as an user contact application). The postprocessing component may receive the search results from the processing components and may merge the search into a single set of merged search results. The merged search results may then be provided to a user in response to the search query. For instance, the search results for the search query &#x201c;August emails&#x201d; may comprise emails from the user contact August and emails from August 1<sup>st</sup>-31<sup>st </sup>emails. The search results may be merged into a single search result set and provided to a user. The presentation order of the merged search results may depend on the ranking order of the respective hypotheses.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIGS. <b>4</b>-<b>7</b></figref> and the associated descriptions provide a discussion of a variety of operating environments in which aspects of the disclosure may be practiced. However, the devices and systems illustrated and discussed with respect to <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>7</b></figref> are for purposes of example and illustration and are not limiting of a vast number of computing device configurations that may be utilized for practicing aspects of the disclosure, described herein.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram illustrating physical components (e.g., hardware) of a computing device <b>400</b> with which aspects of the disclosure may be practiced. The computing device components described below may be suitable for the computing devices and systems described above. In a basic configuration, the computing device <b>400</b> may include at least one processing unit <b>402</b> and a system memory <b>404</b>. Depending on the configuration and type of computing device, the system memory <b>404</b> may comprise, but is not limited to, volatile storage (e.g., random access memory), non-volatile storage (e.g., read-only memory), flash memory, or any combination of such memories.</p><p id="p-0055" num="0054">The system memory <b>404</b> may include an operating system <b>405</b> and one or more program modules <b>406</b> suitable for running software application <b>420</b>, such as one or more components supported by the systems described herein. The operating system <b>405</b>, for example, may be suitable for controlling the operation of the computing device <b>400</b>.</p><p id="p-0056" num="0055">Furthermore, embodiments of the disclosure may be practiced in conjunction with a graphics library, other operating systems, or any other application program and is not limited to any particular application or system. This basic configuration is illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> by those components within a dashed line <b>408</b>. The computing device <b>400</b> may have additional features or functionality. For example, the computing device <b>400</b> may also include additional data storage devices (removable and/or non-removable) such as, for example, magnetic disks, optical disks, or tape. Such additional storage is illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> by a removable storage device <b>409</b> and a non-removable storage device <b>410</b>.</p><p id="p-0057" num="0056">As stated above, a number of program modules and data files may be stored in the system memory <b>404</b>. While executing on the processing unit <b>402</b>, the program modules <b>406</b> (e.g., application <b>420</b>) may perform processes including, but not limited to, the aspects, as described herein. Other program modules that may be used in accordance with aspects of the present disclosure may include electronic mail and contacts applications, word processing applications, spreadsheet applications, database applications, slide presentation applications, drawing or computer-aided application programs, etc.</p><p id="p-0058" num="0057">Furthermore, embodiments of the disclosure may be practiced in an electrical circuit comprising discrete electronic elements, packaged or integrated electronic chips containing logic gates, a circuit utilizing a microprocessor, or on a single chip containing electronic elements or microprocessors. For example, embodiments of the disclosure may be practiced via a system-on-a-chip (SOC) where each or many of the components illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be integrated onto a single integrated circuit. Such an SOC device may include one or more processing units, graphics units, communications units, system virtualization units and various application functionality all of which are integrated (or &#x201c;burned&#x201d;) onto the chip substrate as a single integrated circuit. When operating via an SOC, the functionality, described herein, with respect to the capability of client to switch protocols may be operated via application-specific logic integrated with other components of the computing device <b>400</b> on the single integrated circuit (chip). Embodiments of the disclosure may also be practiced using other technologies capable of performing logical operations such as, for example, AND, OR, and NOT, including but not limited to mechanical, optical, fluidic, and quantum technologies. In addition, embodiments of the disclosure may be practiced within a general-purpose computer or in any other circuits or systems.</p><p id="p-0059" num="0058">The computing device <b>400</b> may also have one or more input device(s) <b>412</b> such as a keyboard, a mouse, a pen, a sound or voice input device, a touch or swipe input device, etc. The output device(s) <b>414</b> such as a display, speakers, a printer, etc. may also be included. The aforementioned devices are examples and others may be used. The computing device <b>400</b> may include one or more communication connections <b>416</b> allowing communications with other computing devices <b>440</b>. Examples of suitable communication connections <b>416</b> include, but are not limited to, radio frequency (RF) transmitter, receiver, and/or transceiver circuitry; universal serial bus (USB), parallel, and/or serial ports.</p><p id="p-0060" num="0059">The term computer readable media as used herein may include computer storage media. Computer storage media may include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, or program modules. The system memory <b>404</b>, the removable storage device <b>409</b>, and the non-removable storage device <b>410</b> are all computer storage media examples (e.g., memory storage). Computer storage media may include RAM, ROM, electrically erasable read-only memory (EEPROM), flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other article of manufacture which can be used to store information and which can be accessed by the computing device <b>400</b>. Any such computer storage media may be part of the computing device <b>400</b>. Computer storage media does not include a carrier wave or other propagated or modulated data signal.</p><p id="p-0061" num="0060">Communication media may be embodied by computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and includes any information delivery media. The term &#x201c;modulated data signal&#x201d; may describe a signal that has one or more characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media may include wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, radio frequency (RF), infrared, and other wireless media.</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref> illustrate a mobile computing device <b>500</b>, for example, a mobile telephone, a smart phone, wearable computer (such as a smart watch), a tablet computer, a laptop computer, and the like, with which embodiments of the disclosure may be practiced. In some aspects, the client may be a mobile computing device. With reference to <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, one aspect of a mobile computing device <b>500</b> for implementing the aspects is illustrated. In a basic configuration, the mobile computing device <b>500</b> is a handheld computer having both input elements and output elements. The mobile computing device <b>500</b> typically includes a display <b>505</b> and one or more input buttons <b>510</b> that allow the user to enter information into the mobile computing device <b>500</b>. The display <b>505</b> of the mobile computing device <b>500</b> may also function as an input device (e.g., a touch screen display).</p><p id="p-0063" num="0062">If included, an optional side input element <b>515</b> allows further user input. The side input element <b>515</b> may be a rotary switch, a button, or any other type of manual input element. In alternative aspects, mobile computing device <b>500</b> may incorporate more or less input elements. For example, the display <b>505</b> may not be a touch screen in some embodiments.</p><p id="p-0064" num="0063">In yet another alternative embodiment, the mobile computing device <b>500</b> is a portable phone system, such as a cellular phone. The mobile computing device <b>500</b> may also include an optional keypad <b>535</b>. Optional keypad <b>535</b> may be a physical keypad or a &#x201c;soft&#x201d; keypad generated on the touch screen display.</p><p id="p-0065" num="0064">In various embodiments, the output elements include the display <b>505</b> for showing a graphical user interface (GUI), a visual indicator <b>520</b> (e.g., a light emitting diode), and/or an audio transducer <b>525</b> (e.g., a speaker). In some aspects, the mobile computing device <b>500</b> incorporates a vibration transducer for providing the user with tactile feedback. In yet another aspect, the mobile computing device <b>500</b> incorporates input and/or output ports, such as an audio input (e.g., a microphone jack), an audio output (e.g., a headphone jack), and a video output (e.g., a HDMI port) for sending signals to or receiving signals from an external device.</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>5</b>B</figref> is a block diagram illustrating the architecture of one aspect of a mobile computing device. That is, the mobile computing device <b>500</b> can incorporate a system (e.g., an architecture) <b>502</b> to implement some aspects. In one embodiment, the system <b>502</b> is implemented as a &#x201c;smart phone&#x201d; capable of running one or more applications (e.g., browser, e-mail, calendaring, contact managers, messaging clients, games, and media clients/players). In some aspects, the system <b>502</b> is integrated as a computing device, such as an integrated personal digital assistant (PDA) and wireless phone.</p><p id="p-0067" num="0066">One or more application programs <b>566</b> may be loaded into the memory <b>562</b> and run on or in association with the operating system <b>564</b>. Examples of the application programs include phone dialer programs, e-mail programs, personal information management (PIM) programs, word processing programs, spreadsheet programs, Internet browser programs, messaging programs, and so forth. The system <b>502</b> also includes a non-volatile storage area <b>568</b> within the memory <b>562</b>. The non-volatile storage area <b>568</b> may be used to store persistent information that should not be lost if the system <b>502</b> is powered down. The application programs <b>566</b> may use and store information in the non-volatile storage area <b>568</b>, such as e-mail or other messages used by an e-mail application, and the like. A synchronization application (not shown) also resides on the system <b>502</b> and is programmed to interact with a corresponding synchronization application resident on a host computer to keep the information stored in the non-volatile storage area <b>568</b> synchronized with corresponding information stored at the host computer. As should be appreciated, other applications may be loaded into the memory <b>562</b> and run on the mobile computing device <b>500</b> described herein (e.g., search engine, extractor module, relevancy ranking module, answer scoring module).</p><p id="p-0068" num="0067">The system <b>502</b> has a power supply <b>570</b>, which may be implemented as one or more batteries. The power supply <b>570</b> might further include an external power source, such as an AC adapter or a powered docking cradle that supplements or recharges the batteries.</p><p id="p-0069" num="0068">The system <b>502</b> may also include a radio interface layer <b>572</b> that performs the function of transmitting and receiving radio frequency communications. The radio interface layer <b>572</b> facilitates wireless connectivity between the system <b>502</b> and the &#x201c;outside world,&#x201d; via a communications carrier or service provider. Transmissions to and from the radio interface layer <b>572</b> are conducted under control of the operating system <b>564</b>. In other words, communications received by the radio interface layer <b>572</b> may be disseminated to the application programs <b>566</b> via the operating system <b>564</b>, and vice versa.</p><p id="p-0070" num="0069">The visual indicator <b>520</b> may be used to provide visual notifications, and/or an audio interface <b>574</b> may be used for producing audible notifications via the audio transducer <b>525</b>. In the illustrated embodiment, the visual indicator <b>520</b> is a light emitting diode (LED) and the audio transducer <b>525</b> is a speaker. These devices may be directly coupled to the power supply <b>570</b> so that when activated, they remain on for a duration dictated by the notification mechanism even though the processor(s) (e.g., processor <b>560</b> and/or special-purpose processor <b>561</b>) and other components might shut down for conserving battery power. The LED may be programmed to remain on indefinitely until the user takes action to indicate the powered-on status of the device. The audio interface <b>574</b> is used to provide audible signals to and receive audible signals from the user. For example, in addition to being coupled to the audio transducer <b>525</b>, the audio interface <b>574</b> may also be coupled to a microphone to receive audible input, such as to facilitate a telephone conversation. In accordance with embodiments of the present disclosure, the microphone may also serve as an audio sensor to facilitate control of notifications, as will be described below. The system <b>502</b> may further include a video interface <b>576</b> that enables an operation of an on-board camera <b>530</b> to record still images, video stream, and the like.</p><p id="p-0071" num="0070">A mobile computing device <b>500</b> implementing the system <b>502</b> may have additional features or functionality. For example, the mobile computing device <b>500</b> may also include additional data storage devices (removable and/or non-removable) such as, magnetic disks, optical disks, or tape. Such additional storage is illustrated in <figref idref="DRAWINGS">FIG. <b>5</b>B</figref> by the non-volatile storage area <b>568</b>.</p><p id="p-0072" num="0071">Data/information generated or captured by the mobile computing device <b>500</b> and stored via the system <b>502</b> may be stored locally on the mobile computing device <b>500</b>, as described above, or the data may be stored on any number of storage media that may be accessed by the device via the radio interface layer <b>572</b> or via a wired connection between the mobile computing device <b>500</b> and a separate computing device associated with the mobile computing device <b>500</b>, for example, a server computer in a distributed computing network, such as the Internet. As should be appreciated such data/information may be accessed via the mobile computing device <b>500</b> via the radio interface layer <b>572</b> or via a distributed computing network. Similarly, such data/information may be readily transferred between computing devices for storage and use according to well-known data/information transfer and storage means, including electronic mail and collaborative data/information sharing systems.</p><p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates one aspect of the architecture of a system for processing data received at a computing system from a remote source, such as a personal computer <b>604</b>, tablet computing device <b>606</b>, or mobile computing device <b>608</b>, as described above. Content displayed at server device <b>602</b> may be stored in different communication channels or other storage types. For example, various documents may be stored using a directory service <b>622</b>, a web portal <b>624</b>, a mailbox service <b>626</b>, an instant messaging store <b>628</b>, or a social networking site <b>630</b>.</p><p id="p-0074" num="0073">An input evaluation service <b>620</b> may be employed by a client that communicates with server device <b>602</b>, and/or input evaluation service <b>620</b> may be employed by server device <b>602</b>. The server device <b>602</b> may provide data to and from a client computing device such as a personal computer <b>604</b>, a tablet computing device <b>606</b> and/or a mobile computing device <b>608</b> (e.g., a smart phone) through a network <b>615</b>. By way of example, the computer system described above may be embodied in a personal computer <b>604</b>, a tablet computing device <b>606</b> and/or a mobile computing device <b>608</b> (e.g., a smart phone). Any of these embodiments of the computing devices may obtain content from the store <b>616</b>, in addition to receiving graphical data useable to be either pre-processed at a graphic-originating system, or post-processed at a receiving computing system.</p><p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an exemplary tablet computing device <b>700</b> that may execute one or more aspects disclosed herein. In addition, the aspects and functionalities described herein may operate over distributed systems (e.g., cloud-based computing systems), where application functionality, memory, data storage and retrieval and various processing functions may be operated remotely from each other over a distributed computing network, such as the Internet or an intranet. User interfaces and information of various types may be displayed via on-board computing device displays or via remote display units associated with one or more computing devices. For example, user interfaces and information of various types may be displayed and interacted with on a wall surface onto which user interfaces and information of various types are projected. Interaction with the multitude of computing systems with which embodiments of the invention may be practiced include, keystroke entry, touch screen entry, voice or other audio entry, gesture entry where an associated computing device is equipped with detection (e.g., camera) functionality for capturing and interpreting user gestures for controlling the functionality of the computing device, and the like.</p><p id="p-0076" num="0075">Aspects of the present disclosure, for example, are described above with reference to block diagrams and/or operational illustrations of methods, systems, and computer program products according to aspects of the disclosure. The functions/acts noted in the blocks may occur out of the order as shown in any flowchart. For example, two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order, depending upon the functionality/acts involved.</p><p id="p-0077" num="0076">The description and illustration of one or more aspects provided in this application are not intended to limit or restrict the scope of the disclosure as claimed in any way. The aspects, examples, and details provided in this application are considered sufficient to convey possession and enable others to make and use the best mode of claimed disclosure. The claimed disclosure should not be construed as being limited to any aspect, example, or detail provided in this application. Regardless of whether shown and described in combination or separately, the various features (both structural and methodological) are intended to be selectively included or omitted to produce an embodiment with a particular set of features. Having been provided with the description and illustration of the present application, one skilled in the art may envision variations, modifications, and alternate aspects falling within the spirit of the broader aspects of the general inventive concept embodied in this application that do not depart from the broader scope of the claimed disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system comprising:<claim-text>a processor; and</claim-text><claim-text>memory coupled to the processor, the memory comprising computer executable instructions that, when executed by the processor, performs a method comprising:<claim-text>receiving a search query from a user;</claim-text><claim-text>identifying one or more tokens in the search query;</claim-text><claim-text>identifying one or more input signals associated with the one or more tokens;</claim-text><claim-text>generating a set of features using the one or more input signals;</claim-text><claim-text>generating one or more hypotheses based on the set of features, wherein the one or more hypotheses respectively represent a search query candidate for the search query and respectively comprise one or more of a domain, an intent, or a slot, wherein:<claim-text>the domain indicates an area of knowledge or a data boundary;</claim-text><claim-text>the intent indicates a goal or an intention of the search query; and</claim-text><claim-text>the slot indicates actionable content within the search query;</claim-text></claim-text><claim-text>ranking the one or more hypotheses based on at least one of the domain, the intent, or the slot; and</claim-text><claim-text>processing the one or more ranked hypotheses.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein identifying the one or more input signals associated with the one or more tokens comprises:<claim-text>determining at least one of:<claim-text>the one or more tokens match one or more terms in the one or more input signals;</claim-text><claim-text>the one or more tokens are similar to one or more terms in the one or more input signals; or</claim-text><claim-text>the one or more tokens are relevant to one or more terms in the one or more input signals.</claim-text></claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the set of features further comprises formatting the one or more input signals into a structured format defining one or more of the domain, the intent, or the slot.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more hypotheses are generated using a pattern-based approach that analyzes a semantic pattern of the search query to determine whether the one or more tokens match a predefined order or structure.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein:<claim-text>when it is determined that the one or more tokens match the predefined order or structure, a hypothesis corresponding to an intent of the predefined order or structure is generated; and</claim-text><claim-text>when it is determined that the one or more tokens do not match the predefined order or structure, the hypothesis corresponding to the intent of the predefined order or structure is not generated.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more hypotheses are generated using a machine learning model that analyzes a semantic pattern of the search query to calculate search query parts probabilities based on data domain or data category.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more hypotheses further respectively comprise a confidence metric indicating a likelihood that a hypothesis is accurate or relevant to the search query.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the confidence metric is based on at least one of: a number of the one or more input signals or a relevance of the one or more input signals.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein ranking the one or more hypotheses comprises applying one or more scores or weights to one or more features of the one or more hypotheses.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein ranking the one or more hypotheses comprises generating one or more rankings based on at least one of:<claim-text>an application entry point;</claim-text><claim-text>an application context; or</claim-text><claim-text>user access privileges.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein ranking the one or more hypotheses comprises generating one or more rankings based on at least one of:<claim-text>historical user behavior;</claim-text><claim-text>the one or more tokens; or</claim-text><claim-text>a semantic analysis data for the search query.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein processing the one or more ranked hypotheses comprises providing the one or more ranked hypotheses as suggested search queries.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein processing the one or more ranked hypotheses further comprises providing at least one of:<claim-text>refinement options for the search query; or</claim-text><claim-text>related search queries.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein processing the one or more ranked hypotheses comprises:<claim-text>formulating one or more supplemental search queries;</claim-text><claim-text>providing the one or more supplemental search queries to one or more processing components; and</claim-text><claim-text>receiving search results for the search query from the one or more processing components.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein respective search results from at least two of the one or more processing components are merged into merged search results and provided as a response to the search query.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein a presentation order of the merged search results is based on rankings of the one or more hypotheses.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. A computer-implemented method comprising:<claim-text>identifying, using a language understanding model, one or more tokens in a search query;</claim-text><claim-text>identifying one or more input signals associated with the one or more tokens;</claim-text><claim-text>generating a set of features using the one or more input signals;</claim-text><claim-text>generating one or more hypotheses based on the set of features, wherein the one or more hypotheses respectively represent a search query candidate for the search query and respectively comprise one or more of a domain, an intent, or a slot, wherein:<claim-text>the domain indicates an area of knowledge or a data boundary;</claim-text><claim-text>the intent indicates a goal or an intention of the search query; and</claim-text><claim-text>the slot indicates actionable content within the search query;</claim-text></claim-text><claim-text>ranking, using a ranking model, the one or more hypotheses based on at least one of the domain, the intent, or the slot; and</claim-text><claim-text>processing the one or more ranked hypotheses.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the one or more input signals comprise at least two of:<claim-text>personalized context data;</claim-text><claim-text>tenant-level context data; and</claim-text><claim-text>common world data.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein:<claim-text>the one or more hypotheses further respectively comprise a confidence score; and</claim-text><claim-text>rankings for the one or more hypotheses are based at least in part on the respective confidence scores.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A device comprising:<claim-text>a processor; and</claim-text><claim-text>memory coupled to the processor, the memory comprising computer executable instructions that, when executed by the processor, performs a method comprising:<claim-text>receiving a search query;</claim-text><claim-text>identifying one or more tokens in the search query;</claim-text><claim-text>identifying one or more input signals associated with the one or more tokens;</claim-text><claim-text>generating a set of features using the one or more input signals;</claim-text><claim-text>generating one or more hypotheses based on the set of features, wherein the one or more hypotheses respectively represent a search query candidate for the search query and respectively comprise one or more of a domain, an intent, or a slot, wherein:<claim-text>the domain indicates an area of knowledge or a data boundary;</claim-text><claim-text>the intent indicates a goal or an intention of the search query; and</claim-text><claim-text>the slot indicates actionable content within the search query;</claim-text></claim-text><claim-text>ranking the one or more hypotheses based on at least one of the domain, the intent, or the slot; and</claim-text><claim-text>processing the one or more ranked hypotheses.</claim-text></claim-text></claim-text></claim></claims></us-patent-application>
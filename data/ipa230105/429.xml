<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000430A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000430</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17468789</doc-number><date>20210908</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2021-0085714</doc-number><date>20210630</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>055</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>12</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>11</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>16</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>145</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>4836</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>055</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>0075</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>7246</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>12</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>112</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>165</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>4806</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>14542</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>0035</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>0042</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>4064</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>6803</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>011</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">DIGITAL CONTENT-BASED DEVICE FOR PROVIDING THERAPEUTICS INFORMATION AND METHOD THEREOF</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>Actibrain Bio, Inc.</orgname><address><city>Seoul</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Kim</last-name><first-name>Sung Yeun</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present invention relates to a digital content-based method for providing therapeutics information, the method comprising: a first step of performing stimulation on a brain of a user to obtain fNIRS (functional near-infrared spectroscopy) data of the user; a second step of extracting a first brain activation area from a plurality of brain areas of the user using the obtained fNIRS data; a third step of determining a first brain state of the user, based on the first brain activation area; a fourth step of providing the user with a content determined corresponding to the first brain state determined in the third step under an XR (Extended Reality) environment; a fifth step in which the user performs a mission corresponding to the content; a sixth step of extracting a second brain activation area from the plurality of brain areas with reference to the fNIRS data of the user following performing the mission; and a seventh step of determining a second brain state of the user, based on the second brain activation area; an eighth step of determining information related to amelioration of the brain state of the user.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="88.05mm" wi="146.90mm" file="US20230000430A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="202.01mm" wi="149.69mm" file="US20230000430A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="211.84mm" wi="160.27mm" file="US20230000430A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="93.98mm" wi="161.37mm" file="US20230000430A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="223.77mm" wi="129.46mm" file="US20230000430A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="70.61mm" wi="129.79mm" file="US20230000430A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="197.19mm" wi="139.78mm" file="US20230000430A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="172.30mm" wi="163.15mm" file="US20230000430A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="96.35mm" wi="121.75mm" file="US20230000430A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="108.37mm" wi="139.87mm" file="US20230000430A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="75.27mm" wi="103.72mm" file="US20230000430A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="161.71mm" wi="127.68mm" file="US20230000430A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="207.86mm" wi="163.32mm" file="US20230000430A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="213.28mm" wi="137.50mm" orientation="landscape" file="US20230000430A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="197.19mm" wi="136.31mm" orientation="landscape" file="US20230000430A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="197.44mm" wi="140.38mm" orientation="landscape" file="US20230000430A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="116.16mm" wi="166.29mm" file="US20230000430A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="228.35mm" wi="158.16mm" file="US20230000430A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="192.19mm" wi="131.57mm" orientation="landscape" file="US20230000430A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="193.21mm" wi="142.07mm" orientation="landscape" file="US20230000430A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="222.25mm" wi="157.14mm" file="US20230000430A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="184.91mm" wi="157.06mm" file="US20230000430A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="214.21mm" wi="156.21mm" file="US20230000430A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application claims priority to Korean Patent Application No. 10-2021-0085714 filed on Jun. 30, 2021, the entire contents of which are incorporated herein by reference.</p><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Technical Field</heading><p id="p-0003" num="0002">The present invention relates to a digital content-based device for providing therapeutics information and a method thereof. More particularly the present invention relates to a device for providing digital therapeutics and a method thereof by collecting signals related to a brain of a user in a state of activity and determining a brain state of the user based thereon.</p><heading id="h-0004" level="1">Description of the Related Art</heading><p id="p-0004" num="0003">The brain changes a neural circuit newly depending on people's behaviors and circumstances and generates new functions or cells resulting in growing up. Further, the function of brain areas may be changed according to what people thinks.</p><p id="p-0005" num="0004">The hippocampus in the brain areas is involved in learning and memory and performs neurogenesis that generates new neurons, this neurogenesis occurring the most actively in the hippocampus. The next most active brain area next to the hippocampus in the neurogenesis is an olfactory related area. When taking a new smell, the brain generates new neurons to distinguish the smell.</p><p id="p-0006" num="0005">However, all nerves fibers including brain cells become dead as time goes on rather than alive for a long-time. Since the cell death means aging or degeneration of cells, cell generation and neurodevelopment should be activated more than the cell death. Thus, in order to activate the nerve fibers, particularly brain cells, it is very crucial to find out factors affecting the rate of neurogenesis and the life span of neurons.</p><p id="p-0007" num="0006">When activation means to activate the brain cell generation, neurogenesis, neurogenesis rate and neuron life span, prior-used methods to activate the brain include exercise, foods, stimulants, music, meditation and the like. However, recently neurologists found out the aforementioned factors, these factors adopted to the brain activation to develop methods for improving brain functions.</p><p id="p-0008" num="0007">In the meantime, when testing or diagnosing brain functions, used are various methods of computer tomography (CT), magnetic resonance imaging (MRI), proton emission tomography (PET), electroencephalograph (EEG), magnetoencephalography (MEG), functional magnetic resonance imaging (FMRI) and the like.</p><heading id="h-0005" level="1">PRIOR ART DOCUMENTS</heading><heading id="h-0006" level="1">Patent Document</heading><p id="p-0009" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0008">(Patent Document 1) Korean Patent No. 10-1754291 (Jul. 6, 2017)</li>    <li id="ul0001-0002" num="0009">(Patent Document 2) Korean Patent Application Publication No. 10-2016-0058812 (May 25, 2016)</li>    <li id="ul0001-0003" num="0010">(Patent Document 3) Korean Patent No. 10-1768393 (Aug. 17, 2017)</li>    <li id="ul0001-0004" num="0011">(Patent Document 4) Korean Patent No. 10-1295187 (Aug. 9, 2013)</li></ul></p><heading id="h-0007" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0010" num="0012">The present invention aims to provide a digital content-based device for providing therapeutics information and a method thereof so as to solve the aforementioned drawbacks of the prior art.</p><p id="p-0011" num="0013">Particularly, the present invention aims to provide a device for providing digital therapeutics and a method thereof by collecting signals related to the brain of a user in a state of activity and determining a brain state of the user.</p><p id="p-0012" num="0014">Further, the present invention aims to provide a device for providing digital therapeutics and a method thereof by performing stimulation on a brain of a user to obtain fNIRS data, extracting an activation area in a plurality of brain areas using the obtained fNIRS data, determining a brain state of the user based on the brain activation area and providing a determined content under an XR (extended reality) environment, allowing the user to perform a mission corresponding to the content.</p><p id="p-0013" num="0015">Further, the present invention aims to provide the device for determining providing digital therapeutics and the method thereof by additionally extracting a brain activation area with respect to fNIRS data of the user who performed the mission, determining a brain state based on the additionally obtained brain activation area, and then determining and providing information related to amelioration of the brain state of the user.</p><p id="p-0014" num="0016">Further, the present invention aims to provide a user with an AI based brain analysis technique capable of predicting an asymptomatic disease in advance and of early diagnosis.</p><p id="p-0015" num="0017">Further, the present invention aims to provide a user with a brain function measurement technique which measures functions of a brain noninvasively in a way of mapping an average of time series blocks of the signal of channel position dependent fNIRS on a head, based on brain activation data imaged following measuring the brain in a state of activity.</p><p id="p-0016" num="0018">Further, the present invention aims to provide a user with a brain activation area, a state cognitive algorithm and a data analysis visualization technique.</p><p id="p-0017" num="0019">Further, the present invention aims to provide a user with a stimulation technique for obtaining brain activation data.</p><p id="p-0018" num="0020">Further, the present invention aims to provide a user with a Hyper-scanning technique which measures changes in the brain of several persons and Inter-brain synchrony.</p><p id="p-0019" num="0021">Further, the present invention aims to provide a user with a determination technique of a brain activation state.</p><p id="p-0020" num="0022">Further, the present invention aims to provide a user with a determination technique of a brain activation using body information (e.g., genetic information, gait pattern information, stress information, EGG change information, a sleep state and attention change information, oxygen saturation change information, and the like).</p><p id="p-0021" num="0023">Further, the present invention aims to provide a user with a determination technique of a brain activation state using imaging scan information (e.g., MRI, PET, CT, fMRI, X-ray and the like).</p><p id="p-0022" num="0024">Further, the present invention aims to provide a user with a technique for predicting, diagnosing and treating a disease, based on processing of a correlation of a plurality of data.</p><p id="p-0023" num="0025">Further, the present invention aims to provide a user with a technique for obtaining data capable of used, as a biomarker in real time and analyzing the same.</p><p id="p-0024" num="0026">Further, the present invention aims to provide a user with a technique for preventing problems related to dementia, MCI, Parkinson's disease, depression, cerebral stroke, Epilepsy, brain cancer and developmental disabilities, managing, diagnosing and treating those diseases.</p><p id="p-0025" num="0027">Further, the present invention aims to provide a user a technique for providing feedback to the user following measuring brain functions, based on a metaverse environment.</p><p id="p-0026" num="0028">Meanwhile, technical aims to be achieved in the present invention are not limited to the aforementioned objects, and other not-mentioned technical aims will be obviously understood by those skilled in the art from the description below.</p><p id="p-0027" num="0029">According to one aspect of the present invention to be achieved, provided is a digital content-based method for providing therapeutics information, wherein the method may include: a step <b>1</b> of performing stimulation on a brain of a user to obtain fNIRS (functional near-infrared spectroscopy) data of the user; a step <b>2</b> of extracting a first brain activation area from a plurality of brain areas of the user using the obtained fNIRS data; a step s of determining a first brain state of the user, based on the first brain activation area; a step <b>4</b> of providing the user with a content determined corresponding to the first brain state determined in the third step under an XR (Extended Reality) environment; a step <b>5</b> in which the user performs a mission corresponding to the content; a step <b>6</b> of extracting a second brain activation area from the plurality of brain areas with reference to the fNIRS data of the user following performing the mission; and a step <b>7</b> of determining a second brain state of the user, based on the second brain activation area; a step <b>8</b> of determining information related to amelioration of the brain state of the user.</p><p id="p-0028" num="0030">Further, the step <b>4</b> may include: a step <b>4</b>-<b>1</b> of determining the first brain state as a base line; a step <b>4</b>-<b>2</b> of determining the content for activating the first brain activation area, corresponding to the first brain state; and a step <b>4</b>-<b>3</b> of providing the user with the content through a device which the user wears, allowing the user to experience the XR environment.</p><p id="p-0029" num="0031">Further, the step <b>5</b> may include: a step <b>5</b>-<b>1</b> in which the user performs the mission changeable depending on a play processing level of the content; and a step <b>5</b>-<b>2</b> of providing information related to the brain of the user in real time while the user is in a state of performing the mission.</p><p id="p-0030" num="0032">Further, the content may include a relaxation content for stabilizing emotion, a problem-solving content for controlling a stressed circumstance, an engagement content, a self-control content for controlling emotion and an impulse control content for controlling an impulsive behavior.</p><p id="p-0031" num="0033">Further, the user may be plural in number and the content may further include a group therapy in which at least a part of the plurality of users performs a mission together.</p><p id="p-0032" num="0034">Further, in the step <b>3</b>, a brain disease of the user may be determined, the brain disease including dementia, MCI, Parkinson's disease, depression, cerebral stroke, Epilepsy, brain cancer and developmental disabilities.</p><p id="p-0033" num="0035">Further, in the step <b>4</b>, the content may be determined relating treatment of the determined brain disease.</p><p id="p-0034" num="0036">Further, prior to the step <b>1</b>, the method may further include a step <b>0</b>.<b>5</b> of collecting body information related to the user and medical imaging information related to the user and in the step <b>3</b>, the first brain state may be determined by using information of the first brain activation area together with the body information related to the user and the medical imaging information related to the user.</p><p id="p-0035" num="0037">Further, in the step <b>3</b>, the first brain state may be determined by additionally using a correlation of activation information related to each of the plurality of brain areas, the body information and the medical imaging information, based on a pre-constructed database.</p><p id="p-0036" num="0038">Further, the body information may include at least one of a degree of hearing loss of the user, gait pattern of the user, a stress level, an EGG change, a sleep state and attention change information, oxygen saturation change and the like, and the medical imaging information may include at least one of an MRI imaging scan related to the user, a CT imaging related to the user and an fMRI imaging scan related to the user.</p><p id="p-0037" num="0039">Further, following the step <b>8</b>, the method may further include a step <b>9</b> of providing the user with at least one of information of the first brain state, information of the second brain state and amelioration information of the brain state.</p><p id="p-0038" num="0040">Further, the step <b>1</b> may include a step <b>1</b>-<b>1</b> of emitting light to a scalp of the user through a plurality of light sources; and a step <b>1</b>-<b>2</b> of detecting the fNIRS data from the scalp to which the light was emitted through a detecting portion corresponding to each of the plurality of light sources. The fNIRS data represents a change of NIR light intensity transmitted through the scalp and may be data from which artifact was removed through a moving average low-pass filter. In the step <b>3</b>, a power spectrum method and a z-score analysis method may be used for determining the first brain state.</p><p id="p-0039" num="0041">Further, in the step <b>3</b>, analysis data for an SMA (supplementary Motor Area) which controls the user's movement based on the first brain activation area may be calculated to determine the first brain state based of the calculated analysis data.</p><p id="p-0040" num="0042">Further, in the step <b>3</b>, in the situation that a specific event happened to the user, it may be determined that there is a limit in the movement of the target object as an analysis data value for the SMA is increased with reference to a reference line, whereas it may be determined that the target object is acquainted with the movement as the analysis data value is decreased with reference to a reference line.</p><p id="p-0041" num="0043">Meanwhile, according to another aspect of the present invention to be achieved, provided is a digital content-based device for providing therapeutics information, wherein the device may include: a brain signal measurement portion which collects signals related to a user; a brain signal stimulating portion which stimulates a brain of the user, in order fora signal collecting operation of the brain signal measurement portion; and a diagnosing portion which determines a brain state of the user, based on the collected signals. The brain signal measurement portion may obtain fNIRS (functional near-infrared spectroscopy) data based on stimulation by the brain signal stimulating portion and extracts a first brain activation area from a plurality of brain areas by using the obtained fNIRS data. The diagnosing portion may determine a first brain state of the user, based on the first brain activation area and may further include a management portion which provides the user with a content determined corresponding to the determined first brain state, under an XR (Extended Reality) environment. When the user performs a mission corresponding to the content, the brain signal measurement portion may extract a second brain activation area from the plurality of brain areas, with reference to fNIRS data of the user who performed the mission. The diagnosing portion may determine information related to amelioration of a brain state of the user by using information of the first brain state and information of the second brain state.</p><heading id="h-0008" level="1">Advantageous Effects</heading><p id="p-0042" num="0044">According to the present invention, provided are a digital content-based device for providing therapeutics information and a method thereof.</p><p id="p-0043" num="0045">Particularly, the present invention is capable of providing the device for providing digital therapeutics and method thereof by collecting signals related to a brain of a user in a state of activity and determining a brain state of the user based thereon.</p><p id="p-0044" num="0046">Further, the present invention is capable of providing the device for providing digital therapeutics and method thereof by performing stimulation on the brain of the user to obtain fNIRS data, extracting an activation area in a plurality of brain areas using the obtained fNIRS data, determining a brain state of the user based on the brain activation area and providing a determined content under an XR (extended reality) environment, allowing the user to perform a mission corresponding to the content.</p><p id="p-0045" num="0047">Further, the present invention is capable of providing the device for determining providing digital therapeutics and the method thereof by additionally extracting a brain activation area with respect to fNIRS data of the user who performed the mission, determining a brain state based on the additionally obtained brain activation area, and then determining and providing information related to amelioration of the brain state of the user.</p><p id="p-0046" num="0048">Further, the present invention is capable of providing the user with an AI based brain analysis technique which allows prediction of an asymptomatic disease in advance and early diagnosis.</p><p id="p-0047" num="0049">Further, the present invention is capable of providing the user with a brain function measurement technique which measures functions of the brain noninvasively in a way of mapping an average of time series blocks of the signal of channel position dependent fNIRS on a head, based on brain activation data imaged following measuring the brain in a state of activity.</p><p id="p-0048" num="0050">Further, the present invention is capable of providing the user with a brain activation area, a state cognitive algorithm and a data analysis visualization technique.</p><p id="p-0049" num="0051">Further, the present invention is capable of providing the user with a stimulation technique for obtaining brain activation data.</p><p id="p-0050" num="0052">Further, the present invention is capable of providing the user with a Hyper-scanning technique which measures changes in the brain of several persons and Inter-brain synchrony.</p><p id="p-0051" num="0053">Further, the present invention is capable of providing a user with a determination technique of a brain activation state.</p><p id="p-0052" num="0054">Further, the present invention is capable of providing the user with a determination technique of the brain activation state using body information (e.g., genetic information, gait pattern information, stress information, EGG change information, a sleep state and attention change information, oxygen saturation change information, and the like).</p><p id="p-0053" num="0055">Further, the present invention aims to provide a user with a determination technique of a brain activation state using imaging scan information (e.g., MRI, PET, CT, fMRI, X-ray and the like).</p><p id="p-0054" num="0056">Further, the present invention is capable of providing the user with a technique for predicting, diagnosing and treating a disease, based on a correlation of a plurality of data.</p><p id="p-0055" num="0057">Further, the present invention is capable of providing the user with a technique for obtaining data capable of used, as a biomarker in real time and analyzing the same.</p><p id="p-0056" num="0058">Further the present invention is capable of providing the user with a technique for preventing problems related to dementia, MCI, Parkinson's disease, depression, cerebral stroke, Epilepsy, brain cancer and developmental disabilities, managing, diagnosing and treating those diseases.</p><p id="p-0057" num="0059">Further, the present invention is capable of providing the user a technique for providing feedback to the user following measuring brain functions, based on a metaverse environment.</p><p id="p-0058" num="0060">Meanwhile, advantageous effects obtained from the present invention are not limited to the aforementioned effects, and other not-mentioned effects will be obviously understood by those skilled in the art from the description below.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0009" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0059" num="0061">The accompanying drawings in the specification illustrate an embodiment of the present invention. The technical essence of the present disclosure will be more clearly understood from the following detailed description taken in conjunction with the accompanying drawings. Therefore, the present invention will not be interpreted to be limited to the drawings in which:</p><p id="p-0060" num="0062"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of an AI based device for providing brain information in connection with the present invention.</p><p id="p-0061" num="0063"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram of a brain signal measurement portion that is a configuration element of the AI based device for providing brain information in connection with the present invention.</p><p id="p-0062" num="0064"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a view for explaining the operation of the brain signal measurement portion in connection with the present invention.</p><p id="p-0063" num="0065"><figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref> are views for explaining fNIRS (functional near-infrared spectroscopy) to be adopted to the present invention.</p><p id="p-0064" num="0066"><figref idref="DRAWINGS">FIG. <b>5</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>5</b>C</figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref> show one example in which signals measured by the brain signal measurement portion are visualized and displayed in connection with the present invention.</p><p id="p-0065" num="0067"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>7</b>D</figref> show one example of each of the signals measured by the brain signal measurement portion, visualized information and processed information in connection with the present invention.</p><p id="p-0066" num="0068"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block view of a brain signal stimulating portion that is a configuration element of the AI based device for providing brain information.</p><p id="p-0067" num="0069"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram of a user data collecting portion in connection with the present invention.</p><p id="p-0068" num="0070"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram of an imaging obtaining portion in connection with the present invention.</p><p id="p-0069" num="0071"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is an exemplary view showing analysis data in an SMA</p><p id="p-0070" num="0072">by using a z-score analysis method according to the embodiment of the present invention.</p><p id="p-0071" num="0073"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a view for explaining a multisensor biodata based model for providing activated XR digital therapeutics according to the present invention.</p><p id="p-0072" num="0074"><figref idref="DRAWINGS">FIG. <b>13</b></figref> and <figref idref="DRAWINGS">FIG. <b>14</b></figref> show one example of each biodata obtained according to the present invention.</p><p id="p-0073" num="0075"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a view for explaining one example which adopts the digital content-based method and system for providing therapeutics information according to the present invention.</p><p id="p-0074" num="0076"><figref idref="DRAWINGS">FIG. <b>16</b></figref> shows one example of a flowchart for explaining the digital content-based method for providing therapeutics information according to the present invention.</p><p id="p-0075" num="0077"><figref idref="DRAWINGS">FIG. <b>17</b></figref> and <figref idref="DRAWINGS">FIG. <b>18</b></figref> show views for explaining a technique for predicting, diagnosing and treating a disease, based on processing of a correlation of a plurality of data in connection with the present invention.</p><p id="p-0076" num="0078"><figref idref="DRAWINGS">FIG. <b>19</b>A to <b>19</b>C</figref> show one example for providing a content determined corresponding to the brain state of the user under an XR (Extended Reality) environment.</p><p id="p-0077" num="0079"><figref idref="DRAWINGS">FIG. <b>20</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>20</b>C</figref> show one example for that the user performs a mission corresponding to the content provided under the XR environment and monitors the brain state.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0010" level="1">DETAILED DESCRIPTION OF THE EMBODIMENTS</heading><p id="p-0078" num="0080">Degenerative Brain Disease</p><p id="p-0079" num="0081">The elderly population ratio (aged 65 or over) in Korea was 13.2% of the total population as of year 2019, however, as the aged population is increasing rapidly, it will be expected to reach 20% as of year 2025.</p><p id="p-0080" num="0082">For the next 45 years, each proportion of a youth population and a working age population is expected to be decrease 3.7% p and 23.3% p, respectively and the elderly population ratio is expected to occupy 40.1% in the total population in 2060.</p><p id="p-0081" num="0083">It is expected that elder care expenses in Korea will increase continuously, reaching 2 times of those in US by 2050 and furthermore this will the highest in the world along with Japan in 2060.</p><p id="p-0082" num="0084">A spectacular increase in the population with dementia to be foreseen in the super-aged society appears and the prevalence rate of dementia shows an increasing trend with age.</p><p id="p-0083" num="0085">Accordingly, dementia is one of urgent problems to be overcome in the modern world that will be entered into the super-aged society before long. The number of the world's dementia prevalence is 4,600 which is greater than the population in Spain, showing a two-fold increase every 20 years and thus will increase rapidly to 130,000,000 by 2050.</p><p id="p-0084" num="0086">It is expected that the East Asian population with dementia will increase 193% by 2050 and the number of domestic patients with dementia is estimated to reach 2,710,000 by 2050.</p><p id="p-0085" num="0087">Accordingly, national dementia care expenses increase resulting in causing social and economic burdens. The spectacular increase in patients with dementia causes an increase in national dementia care expenses. The national dementia care expenses approximated trillion won as of the year 2019 (about 0.7% of GDP) and will increase 2 times every 10 years. Thus, this is estimated to exceed 100 trillion won in 2050 (about 2.0% of GDP).</p><p id="p-0086" num="0088">These economic expenses resulting from dementia are 2 times and 3 times of those for cardia disease and cancer, respectively. The worldwide social&#x22c5;economic expenses was 81.8 billion dollar as of the year 2015 and is expected to increase to 2 trillion dollars by 2030.</p><p id="p-0087" num="0089">Domestic social&#x22c5;economic losses approximate 2 trillion won per year, increasing 2 times or more during recent 4 years (Reference: Search Report of Korean Institute for health &#x26; Welfare Policy).</p><p id="p-0088" num="0090">The worldwide aging population increases the incidence of degenerative brain diseases and social problems. Even though many studies on the treatment and prevention of degenerative brain diseases including dementia are being conducted actively, these are at a standstill. Currently, dementia diagnosis is available through a thorough medical checkup in big hospitals and university hospitals, resulting in problems in terms of psychological, geographical and economic accessibility.</p><p id="p-0089" num="0091">The current screening rate of dementia is 45% (for reference, prevalence rates of 4 major types of cancers are 90% or more), non-invasive dementia diagnosis methods are proposed in various fields. However, there has been not any study on a diagnosis method of dementia on the basis of information gathered through real-time monitoring.</p><p id="p-0090" num="0092">Further, a failure rate of developing a treatment agent for dementia approximates 9.6%, and solanezumab expected as a treatment agent targeting amyloid beta has failed to show promise in Phase III trials.</p><p id="p-0091" num="0093">The reason why a success rate of developing a treatment agent of dementia does not reach 1% is that no onset mechanism was found clearly.</p><p id="p-0092" num="0094">Problems of Prior Diagnosis Technique</p><p id="p-0093" num="0095">The current dementia diagnosis is made up through comprehensive determination on the basis of various tests including brain imaging, electroencephalography, blood test, cerebral spinal fluid examination, Neuropsychological test, etc.</p><p id="p-0094" num="0096">In regard of expenses, the brain imaging is widely used because brain's form such as cerebral atrophy can be seen directly. This uses various kinds of imaging techniques are used including Magnetic Resonance Imaging (MRI), Single-Photon Emission Computed Tomography (SPECT), Positron Emission Tomography (PET), etc., the PET imaging scan helping early diagnosis.</p><p id="p-0095" num="0097">The electroencephalography checks overall cognitive decline by examining memory, attention, visuospatial sense, calculation ability, etc. This is used for early diagnosing a disease, monitoring disease progression and determining efficacies of treatment drugs.</p><p id="p-0096" num="0098">However, the most major drawback of this examination is that the accuracy rate of the examination is proportional to the progression rate for dementia, this meaning that the rate of misdiagnosis is high at very early stage showing no clear symptom.</p><p id="p-0097" num="0099">Further, in a case of cerebral spinal fluid examination, biomarkers accumulated in the brain may be detected directly. However, there is a drawback that it is very painful and inconvenience to collect cerebral spinal fluid for a subject.</p><p id="p-0098" num="0100">Problems of Prior Art Related to Child's Brain Development</p><p id="p-0099" num="0101">As of the year 2019, each population with intellectual disabilities, autism and ADHA is 213,000, 29,000 and 2,060,000, respectively.</p><p id="p-0100" num="0102">The intellectual disabilities and the autism are slow of treatment effects, while in a case of the ADHA, appropriate treatments during childhood avoids continuing this to adulthood. Thus, early diagnosis and treatment of the ADHA is required.</p><p id="p-0101" num="0103">In order to measure a child's brain state with existing MRI, fMRI, CT, etc., it is required that the child hardly moves, differently from his/her developmental features. In a case of toddlers, it is essentially required to administer a sleeping dug and an anesthetic drug.</p><p id="p-0102" num="0104">At this time, when a baby aged less than 2 years is exposed to the anesthetic drug several times, a risk of the occurrence of permanent learning impairment increases 2 times.</p><p id="p-0103" num="0105">Further, in order to develop various kinds of new medicines for brain development, it is required to invest a lot of time and to collect biodata for a certain period of time.</p><p id="p-0104" num="0106">There is a method to check the brain development through multilateral interaction but in a case of the existing product, hyperscanning for measuring a brain state multilaterally is not allowable and thus diversity of such a method for measuring the brain state is required. Accordingly, demands for developing products satisfying this requirement and mobile instruments for measuring the brain state are increasing.</p><heading id="h-0011" level="1">OBJECTS OF THE INVENTION</heading><p id="p-0105" num="0107">Therefore, the present invention intends to contribute to solve social problems of neurologic diseases through building of a deep-learning dataset for early diagnosis and treatment of degenerative brain diseases increasing following aging population.</p><p id="p-0106" num="0108">That is, in order to solve aforementioned problems, required are techniques for Active MRI brain activity assessment of a person with dementia and for early diagnosis of dementia.</p><p id="p-0107" num="0109">Since clinical symptoms are observed long before occurrence of deteriorations in brain structure and function, it is important to assess or diagnose dementia early through the measurement of brain's ability to function.</p><p id="p-0108" num="0110">In order for AI's recognition and understanding of its own accord, it is important to obtain a large scale of AI learning data processed in a form that an AI SW is capable of understanding association between things, AI performance based on machine learning is determined according to utilization of a huge amount of data collected under various circumstances and it is also important that there is synergy between the data and the AI.</p><p id="p-0109" num="0111">According to another object of the present invention, provided are, for a child, a multilateral wireless brain signal measurement device for measuring brain in real time and a brain development examination service.</p><p id="p-0110" num="0112">In order to identify child's brain development state and to held child grow up healthy, the present invention is provided 1) to prevent and diagnose brain diseases such as ADHA, and 2) to provide experience value for cultivating child's attention in everyday life and learning.</p><p id="p-0111" num="0113">Further, the present invention intends to provide a device capable of collecting measure results of brain states for a certain period of time and a solution providing a brain developing program which is, on the basis of the collected data, capable of predicting brain disease risk and is adoptable to everyday life and learning.</p><p id="p-0112" num="0114">According to another object of the present invention, in order to support fields of non-contact learning and emotional work, provided is a sensitivity cognitive/sharing AI (Human-centered AI) service utilizing the construction of a multimodal emotional data network and the N-dimensional emotion mapping.</p><p id="p-0113" num="0115">The emotion cognitive technique adopts a technique which defines an event stream (user's behavior) utilizing ICT and intelligence quotients for social emotional cognition and emotion sharing through a non-contact vital reaction and which is capable of recognize basic emotion and social emotion in a space of the N dimensional emotion mapping.</p><p id="p-0114" num="0116">Further, the non-contact vital reaction is capable of utilizing measurement of a biosignal based five senses by using a sensor camera, an AI speaker, etc. which are usable in everyday life.</p><p id="p-0115" num="0117">Further, the present invention intends to provide and build a data network which is capable of extending the user's behavior event and non-contact vital reaction step by step from a unimodal typed data network to the multimodal data network through which being capable of mapping with the social emotion and is also capable of growing up and evolving through AI.</p><p id="p-0116" num="0118">Further, the emotion AI service may provide a whole new level of human-centered AI service which overcomes unpredictable behavior or emotion of a learner or an emotional labor from a cognitive level to an intuitive level.</p><p id="p-0117" num="0119">In order to achieve the aforementioned objects, the present invention intends to provide a device for providing digital therapeutics and a method thereof by collecting signals related with the brain in a state that the user is moving and determining the brain state of the user based thereon.</p><p id="p-0118" num="0120">Further, the present invention intends to provide the device for providing digital therapeutics and the method thereof by performing stimulation on a brain of a user to obtain fNIRS data, extracting an activation area in a plurality of brain areas using the obtained fNIRS data, determining a brain state of the user based on the brain activation area and providing a determined content under an XR (extended reality) environment, allowing the user to perform a mission corresponding to the content.</p><p id="p-0119" num="0121">Further, the present invention intends to provide the device for determining providing digital therapeutics and the method thereof by additionally extracting a brain activation area with respect to fNIRS data of the user who performed the mission, determining a brain state based on the additionally obtained brain activation area, and then determining and providing information related to amelioration of the brain state of the user.</p><p id="p-0120" num="0122">Further, the present invention intends to provide a user with an AI based brain analysis technique capable of predicting an asymptomatic disease in advance and of early diagnosis.</p><p id="p-0121" num="0123">Further, the present invention intends to provide the user with a brain function measurement technique which measures functions of a brain noninvasively in a way of mapping an average of time series blocks of the signal of channel position dependent fNIRS on a head, based on brain activation data imaged following measuring the brain in a state of activity.</p><p id="p-0122" num="0124">Further, the present invention intends to provide the user with a brain activation area, a state cognitive algorithm and a data analysis visualization technique.</p><p id="p-0123" num="0125">Further, the present invention intends to provide the user with a stimulation technique for obtaining brain activation data.</p><p id="p-0124" num="0126">Further, the present invention intends to provide the user with a Hyper-scanning technique which measures changes in the brain of several persons and Inter-brain synchrony.</p><p id="p-0125" num="0127">Further, the present invention intends to provide the user with a determination technique of a brain activation state.</p><p id="p-0126" num="0128">Further, the present invention intends to provide the user with a determination technique of a brain activation using body information (e.g., genetic information, gait pattern information, stress information, EGG change information, a sleep state and attention change information, oxygen saturation change information, and the like).</p><p id="p-0127" num="0129">Further, the present invention intends to provide the user with a determination technique of a brain activation state using imaging scan information (e.g., MRI, PET, CT, fMRI, X-ray and the like).</p><p id="p-0128" num="0130">Further, the present invention intends to provide the user with a technique for predicting, diagnosing and treating a disease, based on a correlation of a plurality of data.</p><p id="p-0129" num="0131">Further, the present invention intends to provide the user with a technique for obtaining data capable of used, as a biomarker in real time and analyzing the same.</p><p id="p-0130" num="0132">Further, the present invention intends to provide the user with a technique for preventing problems related to dementia, MCI, Parkinson's disease, depression, cerebral stroke, Epilepsy, brain cancer and developmental disabilities, managing, diagnosing and treating those diseases.</p><p id="p-0131" num="0133">Further, the present invention intends to provide the user a technique for providing feedback to the user following measuring brain functions, based on a metaverse environment.</p><p id="p-0132" num="0134">Hereinafter, the AI based device for providing brain information and the method thereof according to preferable embodiments of the present invention will be described in detail with the accompanying drawings.</p><p id="p-0133" num="0135">Hereinafter, preferable embodiments of the present invention will be described with the accompanying drawings. Further, the content of claimed inventions are not limited to the preferable embodiments to be described and whole configuration to be explained in the present embodiments are not essential as a solution.</p><p id="p-0134" num="0136">AI Based Device for Providing Brain Information</p><p id="p-0135" num="0137"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram showing an AI based device for providing brain information in connection with the present invention.</p><p id="p-0136" num="0138">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the AI based device <b>1</b> for providing brain information according to the present invention may include a brain signal measuring portion <b>10</b>, a brain signal stimulating portion <b>20</b>, a user data collecting portion <b>30</b>, an imaging obtaining portion <b>40</b>, a diagnosing portion <b>50</b> and a management portion <b>60</b>.</p><p id="p-0137" num="0139">Firstly, the brain signal measuring portion <b>10</b> collects signals related to a brain of a user.</p><p id="p-0138" num="0140">In particular, the brain signal measuring portion <b>10</b> according to the present invention irradiates a near-infrared ray to the user's brain and detects light penetrating the cerebral cortex of the brain, determines a level of oxygenation of hemoglobin in blood flow of the user's brain based on the detected light and extracts at least one brain activation area from a plurality of brain areas of the user based on the determined level of oxygenation of hemoglobin.</p><p id="p-0139" num="0141">The present invention is characterized in that a signal collecting operation of the brain signal measuring portion <b>10</b> may be performed in a state that the user is moving.</p><p id="p-0140" num="0142">Moving on to the next, the brain signal stimulating portion <b>20</b> stimulates the user's brain for the signal collecting operation of the brain signal measuring portion <b>10</b>.</p><p id="p-0141" num="0143">Furthermore, the brain signal stimulating portion <b>20</b> stimulates the user's brain so as to ameliorate a brain state of the user according to controlling of the management portion.</p><p id="p-0142" num="0144">Further, the user data collecting portion <b>30</b> collects body information related to the user.</p><p id="p-0143" num="0145">The body information related to the user may include the user's auditory information, gait information, stress information, electrocardiogram information, sleep information, attention information, emotional change information and the like.</p><p id="p-0144" num="0146">Further, the imaging obtaining portion <b>40</b> collects medical imaging related to the user.</p><p id="p-0145" num="0147">The imaging obtaining portion <b>40</b> according to the present invention may use an MRI imaging scan obtaining portion that collects an MRI imaging scan related to the user, a CT imaging scan obtaining portion that collects a CT imaging scan related to the user, an fMRI imaging scan obtaining portion that collects an fMRI imaging scan related to the user and the like.</p><p id="p-0146" num="0148">Further, the diagnosing portion <b>50</b> determines the brain state of the user based on the collected signals from the brain signal measuring portion <b>10</b>.</p><p id="p-0147" num="0149">The diagnosing portion <b>50</b> may determine a brain disease of the user. Target diseases may include dementia, Parkinson's disease, cerebral stroke, Epilepsy, brain cancer and developmental disabilities.</p><p id="p-0148" num="0150">Lastly, the management portion <b>60</b> provides information for ameliorating the brain state of the user, corresponding to the brain state of the user determined by the diagnosing portion <b>50</b>.</p><p id="p-0149" num="0151">For example, when the user, by applying a preset reference, is suspected of at least one of dementia, Parkinson's disease, cerebral stroke, Epilepsy, brain cancer and developmental disabilities within a certain period of time, based on the brain state of the user, an operation of the brain signal stimulating portion <b>20</b> for stimulating the user's brain may be triggered for ameliorating the rain state of the user according to controlling of the management portion <b>60</b>.</p><p id="p-0150" num="0152">Hereinafter, respective configuration elements will be described in regard of specific structures and functions with reference to drawings.</p><p id="p-0151" num="0153">Brain Signal Measuring Portion</p><p id="p-0152" num="0154"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram of a brain signal measuring portion that is a configuration element of the AI based device for providing brain information.</p><p id="p-0153" num="0155">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the brain signal measuring portion <b>10</b> may include a brain signal obtaining portion <b>11</b>, a brain signal processing portion <b>12</b>, a brain signal analyzing portion <b>12</b>, a communicating portion <b>14</b> and a display portion <b>15</b>.</p><p id="p-0154" num="0156">Firstly, the brain signal obtaining portion <b>11</b> irradiates a near-infrared ray to the user's brain and detects light penetrating the cerebral cortex of the brain.</p><p id="p-0155" num="0157">Wherein, a signal collecting operation of the brain signal obtaining portion <b>11</b> is performed in a state that the user is moving.</p><p id="p-0156" num="0158">Moving on to the next, the brain signal processing portion <b>12</b> determines a level of oxygenation of hemoglobin in blood flow of the user's brain based on the detected light.</p><p id="p-0157" num="0159">The brain signal processing portion <b>12</b> extracts an oxygenated hemoglobin (Oxy Hb) concentration and a deoxygenated hemoglobin (Deoxy Hb) concentration in blood flow of the user to determine a level of oxygenation of hemoglobin.</p><p id="p-0158" num="0160">Further, the brain signal analyzing portion <b>13</b> extracts at least one brain activation area from a plurality of brain areas of the user based on the determined level of oxygenation of hemoglobin.</p><p id="p-0159" num="0161">Wherein, in the at least one brain activation area, oxygen transferred by the Oxy Hb in blood flow is consumed to decrease the Oxy Hb concentration and to increase the Deoxy Hb concentration corresponding to the decreased Oxy Hb concentration.</p><p id="p-0160" num="0162">The Oxy Hb concentration and the Deoxy Hb concentration have an optical property that changes in a visible-ray area and a near-infrared area and consequentially, the brain signal measuring portion <b>10</b> collects the signal through fNIRS (functional Near-infrared Spectroscopy).</p><p id="p-0161" num="0163">Meanwhile, the brain signal analyzing portion <b>13</b> divides the brain area of the user into multiple areas and determines whether or not each of the divided brain areas is changed to the brain activation area by a predetermined time unit, or whether or not the brain activation area is changed to an inactivation area.</p><p id="p-0162" num="0164">Based thereon, the diagnosing portion <b>50</b> may determine the brain state of the user using brain activation changes of the respective divided brain areas with reference to a predetermined period of time.</p><p id="p-0163" num="0165">Further, the communicating portion <b>14</b> builds networks between the brain signal measuring portion <b>10</b> and other configuration elements (the brain signal stimulating portion <b>20</b>, the user data collecting portion <b>30</b>, the imaging obtaining portion <b>40</b>, the diagnosing portion <b>50</b>, the management portion <b>60</b>, etc.) to support data communication.</p><p id="p-0164" num="0166">Wherein, usable wireless communication techniques may include Wireless LAN (WLAN) (Wi-Fi), Wireless broadband (Wibro), World Interoperability for Microwave Access (Wimax), High Speed Downlink Packet Access (HSDPA) and the like.</p><p id="p-0165" num="0167">Further, usable short range communication techniques may include Bluetooth, Radio Frequency Identification (RFID), Infrared Dara Association (IrDA), Ultra-Wideband (UWB), ZigBee and the like.</p><p id="p-0166" num="0168">Further, the display portion <b>15</b> displays the brain activation change in each of the plurality of the divided brain areas according to the time.</p><p id="p-0167" num="0169">The display portion <b>15</b> may include at least one of a Liquid Crystal Display (LCD), a Thin Film Transistor-Liquid Crystal Display (TFT LCD), an Organic Light-Emitting Diode (OLED), a flexible display and a 3D display.</p><p id="p-0168" num="0170"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a view for explaining the operation of the brain signal measurement portion in connection with the present invention.</p><p id="p-0169" num="0171">Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the brain state of the user and a development state thereof are measured multilaterally in real time in a state that the user is moving. That is, a brain signal measuring device is provided which is capable of measuring brain signals of a multiuser so as to analyze the brain signal wirelessly in real time without any limit.</p><p id="p-0170" num="0172">The brain signal measuring portion <b>10</b> according to the present invention may be a full cover type which covers the whole of the user's head, alternatively a front type which is adhered closely to a front part of the user's head.</p><p id="p-0171" num="0173">Further, as considering circumstances particularly being used for a child, in a case of the brain signal measuring portion <b>10</b>, a UI/UX custom design for providing experience values may be considered which adopts a child custom design and makes up a user friendly environment.</p><p id="p-0172" num="0174">In the present invention, a wearable brain signal measuring technology may be adopted which is capable of being used for a long time by using Bluetooth low energy (BLE). Further, a flexible substrate is used for designing the brain signal measuring device for a child to fit baby's head shape, allowing weight minimization of the device.</p><p id="p-0173" num="0175">Further, used are a brain signal analyzing algorithm that is capable of measuring attention and brain development of the user in terms of physiology through brain activation analyzation, a data transmission algorithm that is capable of securing data reliability even if a channel state is changed, and a brain activation area cognitive algorithm.</p><p id="p-0174" num="0176"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>4</b>B</figref> are views for explaining fNIRS (functional near-infrared spectroscopy) to be adopted to the present invention.</p><p id="p-0175" num="0177">Referring to <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>, in the fNIRS technique applied to the present invention, the fNIRS is an imaging technique which irradiates light of the near-infrared area having a wave length of 650 to 1000 nm and detects light penetrating a brain tissue to measure a change of the hemoglobin concentration noninvasively according to a change in blood flow of the brain without any risk resulting from a surgery.</p><p id="p-0176" num="0178">The fNIRS technique applied to the present invention uses a fNIRS for performing real-time brain measurement under live circumstances in which a patient is able to moving rather than being fixed.</p><p id="p-0177" num="0179">The fNIRS is an imaging technique which irradiates light of the near-infrared area having a wave length of 650 to 1000 nm and detects light penetrating the brain tissue to measure a change of the hemoglobin concentration non-invasively according to a change in blood flow of the brain without any risk resulting from a surgery.</p><p id="p-0178" num="0180">This fNIRS may shows a result in real time differently from the existing assessment methods, reduce costs for buying a device and maintenance fee thereof, and increase reliability of a measurement result as the measurement result shows a sociality directly.</p><p id="p-0179" num="0181"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> shows a comparison between the current brain measuring technique and the fNIRS adopted to the present invention.</p><p id="p-0180" num="0182">In the present invention, a non-identified MRI imaging scan of the brain is collected, an activated MRI imaging scan data of the brain and reviewed clinical data is collected, a feedback is received form a radiologist followed by organizing the same, and the clinical information is structuralized into a labeled imaging scan of the brain, a sheet file in excel format and the like through imaging preprocessing.</p><p id="p-0181" num="0183">That is, collected are an inactivated MRI imaging scan of the brain for MRI diagnosis, clinical information and the like from the medical database operated by a hospital, this allowing defining accurate references for hearing loss, tinnitus and furthermore dementia by using imaging scan reading and pathological reading.</p><p id="p-0182" num="0184">Further, a diagnosis result of the MRI imaging scan is classified into PSAP result data of hearing loss, tinnitus and normalcy and MRI imaging scan of the brain. In a case of hearing loss, tinnitus or normalcy, there may be a misdiagnosis at the time of reading. Thus, database may be constructed under a specific environment.</p><p id="p-0183" num="0185">As a particular reference for hearing loss described hereinafter, there may be used an imaging scan of the brain of a patient diagnosed as hearing loss by a PASAP result. As a particular reference for tinnitus, there may be used an imaging scan of the brain of a patient diagnosed as tinnitus by a PASAP result. As a particular reference of normalcy, there may be an image scan of the brain of a patient diagnosed as normalcy by a PSAP result.</p><p id="p-0184" num="0186">Further, a background service is registered, a questionnaire is filled out before visiting an institution, an interview on mood and vitality is conducted prior to brain measurement, a task for the brain measurement is selected followed by performing the selected task, and determination on whether or not to collect sufficient data is made either to finish the brain measurement or restart the preceding step.</p><p id="p-0185" num="0187">Further, the imaging data adopted to the present invention may be defined as data of an activated MRI imaging scan of the brain.</p><p id="p-0186" num="0188">Further, non-identification of the imaging data may be processes into a non-identifying tag structure (RAW data form) by a non-identifying method.</p><p id="p-0187" num="0189">Further, the metadata adopted to the present invention collects patient's metainformation about imaging information and is used for quality inspection through additional information in a case of patients with hearing loss and tinnitus to secure reliability.</p><p id="p-0188" num="0190">Meanwhile, <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>5</b>C</figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref> show one example in which signals measured by the brain signal measurement portion are visualized and displayed in connection with the present invention.</p><p id="p-0189" num="0191">Referring to <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>5</b>C</figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref>, it may be found that the brain activation area is checked safely without any surgery by irradiating near infrared ray to the brain, followed by detecting light penetrating the cerebral cortex and processing the detected light to measure concentrations of Oxy Hb and Deoxy Hb.</p><p id="p-0190" num="0192">Further, the exemplary device neither has riskiness nor is affected by ambient noises.</p><p id="p-0191" num="0193">Further, this device has high convenience and portability and is cost-effective compared to other brain function imaging devices.</p><p id="p-0192" num="0194"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>7</b>D</figref> show one example of each of the signals measured by the brain signal measurement portion, visualized information and processed information in connection with the present invention.</p><p id="p-0193" num="0195">Referring to <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>7</b>D</figref>, shown is a block average of time series of channel position dependent fNIRS signals.</p><p id="p-0194" num="0196">Further, shown is a mapping of the block average of the channel position dependent fNIRS signals on the head.</p><p id="p-0195" num="0197">In the present invention, in order for the application to machine learning, a data configuration for preventing algorithm bias and a method for collecting data may be used as follow.</p><p id="p-0196" num="0198">Sample bias may occur when the collected data either represents an environment in which the AI system is expected to be performed or does not show this clearly.</p><p id="p-0197" num="0199">Generally, algorithm learns a data set of a subset deliberately selected from a whole data set rather than learning the whole of the data set. Thus, in order to reduce the sample bias, it is important to select a subset that is capable of representing the whole of the data set besides sufficiently large one when selecting the data set of the subset.</p><p id="p-0198" num="0200">Further, measurement bias occurs when there is distortion problem in values by a device used in observing or measuring something, this kind of bias likely to distort the data in a certain direction.</p><p id="p-0199" num="0201">An instrument with measurement bias fails to duplicate an environment in which a model will be operated. The learning data distorts actual data, this resulting in a biased result. The measurement bias is not avoidable even if collecting data more.</p><p id="p-0200" num="0202">Accordingly, in order to solve the aforementioned problem, the present invention configures an environment not allowing resulting in biased results to collect the data.</p><p id="p-0201" num="0203">As a noninvasive method for measuring brain functions, the fNIRS measures a change in blood flow of the brain by using near infrared ray, the measurement principal thereof being based on measurement of a level of oxygenation of hemoglobin in the blood flow of the brain using the far infrared ray.</p><p id="p-0202" num="0204">As irradiating near infrared ray to a living body and detecting and processing a fNIRS signal penetrating the tissue, it is allowable to measure an Oxy Hb concentration and a Deoxy Hb concentration.</p><p id="p-0203" num="0205">The brain activation area consumes oxygen transferred by Oxy Hb in the blood flow and the Oxy Hb is changed into Deoxy Hb. Two such hemoglobins have an optical property that changes in a visible-ray area and a near-infrared area, and concentrations thereof measured by fNIRS are usable as a criterion for brain activity.</p><p id="p-0204" num="0206">Such a method according to the present invention is capable of measuring brain functions in a state that a person is running or moving and of providing a result within a short period of time after examination.</p><p id="p-0205" num="0207">Further, the method allows measuring the brain functions without any medicine and controlling ambient sounds.</p><p id="p-0206" num="0208">In the present invention, in order to build an appropriate model, variables having the highest explanation ability is selected from variables which are determined to have a high correlation with a target item subjected to abnormality detection.</p><p id="p-0207" num="0209">Further, adjust R{circumflex over (&#x2003;)}2 for each subset is measured to select an item made up of the least number of variables from the subset which has the largest value.</p><p id="p-0208" num="0210">Further, an authoring tool is required in order to build AI learning data effectively.</p><p id="p-0209" num="0211">That is, a labeling function is required which automatically tags and labels a target image subjected to labeling, a labeling list, a reference image and the like with labeling project information stored in the server with an imaging labeling application solution.</p><p id="p-0210" num="0212">As a way of the authoring tool for the operation management of the AI learning data, functions of adding, storing and generating an image may be used.</p><p id="p-0211" num="0213">An image desired to be examined may be added using a relevant authoring tool. Following adding an MRI imaging scan of the brain or a fracture part by using a portable MRI device, functions of adding and generating an additional image may be grafted as pressing a plus button.</p><p id="p-0212" num="0214">Further, an authorizing tool using an annotation function may perform a tagging operation for the additionally stored and generated image and an additional information recording operation through a note function for i.e. peculiarity and the like.</p><p id="p-0213" num="0215">As a way of utilization for the operation management of the AI learning data, a cross validation may be performed to verify an exemplary reading model of normalcy, hearing loss and tinnitus for the activated MRI imaging scan of the brain.</p><p id="p-0214" num="0216">Further, a performance is assessed by using various reading criteria, the criteria including measurement of sensitivity, specificity and an Area Under a Receiver operating Characteristic Curve (AUROC). The exemplary reading model may be built through github based thereon.</p><p id="p-0215" num="0217">As mentioned above, the brain signal measuring portion <b>10</b> collects information related to the user's brain and the brain signal collecting operation of the brain signal measuring portion <b>10</b> is performed in a state that the user is moving.</p><p id="p-0216" num="0218">Meanwhile, the diagnosing portion <b>50</b> determines a brain state of the user based on the collected signal.</p><p id="p-0217" num="0219">In particular, the diagnosing portion <b>50</b> may determine the brain state of the user based on at least one brain activation area which was extracted successively for a predetermined period of time.</p><p id="p-0218" num="0220">Herein, the diagnosing portion <b>50</b> may diagnose a brain disease of the user, the brain disease including dementia, Parkinson's disease, cerebral stroke, Epilepsy, brain cancer and developmental disabilities.</p><p id="p-0219" num="0221">Furthermore, the management portion <b>60</b> may be used additionally which provides information for ameliorating the brain state of the user, corresponding to the brain state of the user' determined by the diagnosing portion <b>50</b>.</p><p id="p-0220" num="0222">For example, when the user, by applying preset references, is suspected of at least one of dementia, Parkinson's disease, cerebral stroke, Epilepsy, brain cancer and developmental disabilities within a certain period of time based on the brain state of the user, the management portion <b>60</b> controls the brain signal stimulating portion <b>20</b> to be described below to provide a signal for stimulating the user's brain for ameliorating the brain state of the user.</p><p id="p-0221" num="0223">Brain Signal Stimulating Portion</p><p id="p-0222" num="0224">The brain signal stimulating portion <b>20</b> provides a function of stimulating the user's brain for the signal collecting operation of the brain signal measuring portion <b>10</b>.</p><p id="p-0223" num="0225">Furthermore, the brain signal stimulating portion <b>20</b> may provide a function of stimulating the user's brain according to controlling of the management portion <b>10</b> for ameliorating the brain state of the user.</p><p id="p-0224" num="0226"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block view of a brain signal stimulating portion that is a configuration element of the AI based device for providing brain information.</p><p id="p-0225" num="0227">The brain signal stimulating portion <b>20</b> intensively stimulates a synapse meaning a part in which brain cells are connected to communicate with each other. In order to activate a brain area as long-term memory, the brain area should be stimulated through a place, emotion and a story.</p><p id="p-0226" num="0228">Accordingly, the brain signal stimulating portion <b>20</b> reinforces an activity of a target brain area intensively through multidimensional environmental stimulations based on a natural object disposed in a space where activities, such as exhibition, music, motion, etc., are made and selectively activates a function of the brain area. According to classification criteria of Diagnostic and Statistical manual of mental Disorders (DSM-V) defined by American Psychiatric Association, the brain area may be classified into attention, visuospatial ability, memory, executive ability, verbal ability, calculation ability and sound cognitive ability, and the like. That is, the present invention intensively reinforces various activities of the brain area, such as attention, empathy, creativity, memory, healing, and the like through the natural object, particularly a plant and multi-dimensional environmental stimulation such as sound, sense of touch, scent, sense of sight, memory, and the like and activates functions.</p><p id="p-0227" num="0229">As shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref> and <figref idref="DRAWINGS">FIG. <b>13</b></figref>, a brain activation system <b>10</b> according to a preferable embodiment of the present invention includes a brain activating device <b>24</b> and a management server <b>21</b>, the brain activating device <b>24</b> applying a multi-dimensional environmental stimulation systemized to intensively reinforce an activity of a pre-targeted brain area within a predetermined space where the natural object was installed and the management server <b>21</b> controlling driving of the brain activating device <b>24</b> to apply the multi-dimensional environmental stimulation to the targeted brain area in the space.</p><p id="p-0228" num="0230">The brain activating device <b>24</b> may include a media portion <b>30</b>, an acoustic portion <b>40</b>, a lighting portion <b>50</b> and a scent transferring portion <b>60</b> in order to intensively reinforce the activity of the pre-targeted brain area within the predetermined space where the natural object was installed and to activate the function of the brain area, the media portion <b>30</b> implementing media art corresponding to a concept desired to be generated in the space, the acoustic portion <b>40</b> outputting a sound, the lighting portion <b>50</b> irradiating light and the scent transferring portion <b>60</b> transferring a scent to the user.</p><p id="p-0229" num="0231">User Data Collecting Portion, Imaging Obtaining Portion, Diagnosing Portion and Management Portion</p><p id="p-0230" num="0232">The user data collecting portion <b>30</b> collects body information related to the user. The body information related to the user may include the user's auditory information, gait information, stress information, electrocardiogram information, sleep information, attention information, emotional change information, brain wave information, oxygen saturation information and the like.</p><p id="p-0231" num="0233"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram of a user data collecting portion in connection with the present invention.</p><p id="p-0232" num="0234">Referring to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the user data collecting portion <b>30</b> may include an auditory information collecting portion <b>31</b> that collects the user's auditory information.</p><p id="p-0233" num="0235">Wherein, the diagnosing portion <b>50</b> determines a level of hearing sensitivity damage of the user based on the collected auditory information and may determine the brain state of the user by using at least one brain activation area together with the determined level of hearing sensitivity damage of the user.</p><p id="p-0234" num="0236">Particularly, when the user's hearing sensitivity damage results from hearing loss, the diagnosing portion <b>50</b> may determine the brain state of the user by additionally using the body information related to the user, an average value of pure-tone thresholds in both of the user's ears, a level of the user's hearing loss and information related to the auditory information collecting portion.</p><p id="p-0235" num="0237">As another example, when the user's hearing sensitivity damage results from tinnitus, the diagnosing portion <b>50</b> may determine the brain state of the by additionally using the body information related to the user, an average value of pure-tone thresholds in both of the user's ears, a level of the user's tinnitus and information related to the auditory information collecting portion.</p><p id="p-0236" num="0238">Meanwhile, the brain signal collecting operation of the brain signal measuring portion <b>10</b> may be performed in a state that the user's hearing sensitivity damage occurs while the user is moving.</p><p id="p-0237" num="0239">Further, the user data collecting portion <b>30</b> may include a gait information collecting portion <b>32</b> that collects the user's gait information, a stress collecting portion <b>33</b> that collects the user's stress information, an electrocardiogram information collecting portion <b>34</b> that collects the user's electrocardiogram information, a sleep information collecting portion <b>35</b> that collects the user's sleep information, a attention information collecting portion <b>36</b> that collects the user's attention information, a non-contact typed emotional change collecting portion <b>37</b>, a brain wave information collecting portion <b>38</b> that collects the user's EEG (electroencephalogram) information and an oxygen saturation information collecting portion <b>39</b> that collects the user's oxygen saturation information.</p><p id="p-0238" num="0240">Wherein, the diagnosing portion <b>50</b> may determine a level of the user's hearing sensitivity damage based on the collected auditory information and determine at least one of the user's gait pattern, a level of stress, an electrocardiogram change, a sleep state, an attention change, an EGG change and an oxygen saturation change based on the collected information.</p><p id="p-0239" num="0241">Further, the diagnosing portion <b>50</b> may determine the brain state of the user by using the at least one of the level of the user's hearing sensitivity damage, the user's gait pattern, a level of stress, an electrocardiogram change, a sleep state, an attention change, an EGG change and an oxygen saturation change together with the at least one brain activation area.</p><p id="p-0240" num="0242">Further, the signal collecting operation of the brain signal measuring portion <b>10</b> may be performed under the circumstance being applied with at least one of states that the user's gait information is changing, the user's stress is changing, the user's electrocardiogram is changing, the user's sleep condition is changing and the user's attention is changing, while the user is moving.</p><p id="p-0241" num="0243">Further, the user data collecting portion <b>30</b> may include the non-contact typed emotional change information collecting portion <b>37</b>.</p><p id="p-0242" num="0244">This non-contact typed emotional change information collecting portion <b>37</b> may collect the user's face landmark masking data based on the user's eye tracking to collect the user's emotional change information in a non-contact way.</p><p id="p-0243" num="0245">Wherein, the diagnosing portion <b>50</b> may determine the brain state of the user by using the at least one brain activation area together with the user's emotional change information.</p><p id="p-0244" num="0246">Further, the non-contact typed emotional change information collecting portion <b>37</b> may collect the user's emotional change information based on the user's speech change.</p><p id="p-0245" num="0247">Wherein, the diagnosing portion <b>50</b> may determine the brain state of the user by using the at least one brain activation area together with the user's emotional change information.</p><p id="p-0246" num="0248">Particularly, the diagnosing portion <b>50</b> may determine the brain state of the user based on the at least one brain activation area extracted successively for a predetermined period of time.</p><p id="p-0247" num="0249">Wherein, the diagnosing portion <b>50</b> may determine the brain disease of the user, the brain disease including dementia, Parkinson's disease, cerebral stroke, Epilepsy, brain cancer and developmental disabilities.</p><p id="p-0248" num="0250">Furthermore, additionally used is the management portion <b>60</b> that provides information for ameliorating the brain state of the user, corresponding to the brain state of the user determined by the diagnosing portion <b>50</b>.</p><p id="p-0249" num="0251">Hereinafter, described is the function of the diagnosing portion <b>50</b> using, as a representative of the user data collecting portion <b>30</b>, the auditory information collecting portion <b>31</b> and the non-contact typed emotional change collecting portion <b>37</b>.</p><p id="p-0250" num="0252">Firstly, an embodiment using the auditory information collecting portion <b>31</b> is described in detail.</p><p id="p-0251" num="0253">As the aged society results in a spectacular increase in the population with dementia and Korea enters the aged society, dementia becomes an issue in the youth population besides the aged population.</p><p id="p-0252" num="0254">Particularly, the proportion of patients with severe dementia to overall dementia patients shows a reduction trend, i.e. 32% as of the year 2016 and 30% as of the year 2018, through medication treatment and various programs for severe dementia patients. This means that symptoms of the severe dementia patients are ameliorated whereas early stage of dementia shows a growing trend.</p><p id="p-0253" num="0255">Noise is an unwanted sound considered unpleasant and loud to hearing. Sensorineural hearing loss caused by this noise is referred to as &#x2018;noise-induce hearing loss&#x201d;.</p><p id="p-0254" num="0256">The root cause lies on damage of the sensory organ, that is, cochlea. Particularly, this often occurs as a consequence of damaged outer hair cells. A sound of 75 dB or lower hardly incudes hearing loss, however, a sound pressure of environment noise in the office or conversation circumstance approximates 60 dB, a noise level inside the cabin of buses and subway and restaurants approximating 80 dB, the maximum volume of the earphones of MP3s or portable CD players approximating 100 dB, a noise level of airplanes approximating 140 dB and a noise level of gunfire approximating 170 dB. When listening through earphones at a volume to the extent that the next person can hear, the volume level ranges approximately from 100 dB to 115 dB. Prolonged exposure to a noise of 85 dB or higher may cause damages on ears.</p><p id="p-0255" num="0257">Exposures to a sound pressure of 100 dB for 15 minutes or longer without any protection equipment and to a sound pressure of 110 dB regularly for 1 minute or longer cause risk of hearing loss. In the light of that ordinary noise level inside the cabin of buses and subway is 80 dB, the youth should maintain music sound to 90 db or higher in order to hear music, the hearing loss occurring as a consequence of repeated exposures thereto.</p><p id="p-0256" num="0258">Sound intensity is determined by the amplitude of a sound wave and the scale for measuring intensity is decibel (dB) scale. For every 10 dB increase in the sound intensity, a noise level is increased two times. Usually, a sound intensity of 75 dB or lower does not affect hearing sensitivity damage.</p><p id="p-0257" num="0259">As symptoms of noise-induced hearing loss, when a person has noise-induced hearing loss, he/she is likely to turn on a television, a radio and the like, at a high volume and is often referred to as &#x2018;Saojeong&#x2019; in Korean meaning a person who is slow in understanding what someone says or is partially deaf.</p><p id="p-0258" num="0260">Further, the person with noise-induced hearing loss hardly understands what the other person says accurately even in a little noisy surrounding. Commonly, he/she shows decrease in hearing at 4 kHz and is more likely to be accompanied by tinnitus.</p><p id="p-0259" num="0261">Further, in addition to hearing sensitivity damage and tinnitus, the person with noise-induced hearing loss may feel unpleasant and anxiety, suffers from insomnia, headache and is stressed, this disrupting his/her normal life. Even worse, the noise-induced hearing loss affects pulsation and blood pressure to cause maldigestion and autonomic dysfunction.</p><p id="p-0260" num="0262">The noise-induced hearing loss is diagnosed by performing pure-tone threshold test and an audiometry which measures hearing sensitivity accurately by a frequency, the audiometry including tinnitus test, optoacoustic emission test, loudness recruitment test, auditory brainstem response test and the like. When a loss of hearing sensitivity proceeding gradually following prolonged exposure to noises, particularly the loss to the sound of a high frequency of 4 kHz appearing clearly, the hearing loss is diagnosed.</p><p id="p-0261" num="0263">The damaged hearing sensitivity due to the noise induced-hearing loss is basically irreducible because damaged auditory cells are not repaired. Particularly, if a difficulty in hearing occurs suddenly within a few days, this may be sudden sensorineural hearing loss and thus required are precise examinations as well as treatments with steroid hormones, vasodilators, antiviral agents and the like.</p><p id="p-0262" num="0264">In such a case, it is necessarily required to relieve the ear for a certain period of time for the recovery thereof.</p><p id="p-0263" num="0265">The sudden hearing loss is referred to as sensorineural hearing loss that occurs suddenly without any clear causes, this occurring in one ear commonly but also appearing in both ears extraordinarily. Occasionally, this is accompanied by tinnitus and dizziness.</p><p id="p-0264" num="0266">Generally, the sudden hearing loss is regarded as an urgent disease and needs to start to admission treatment. Supposed causes of the onset may include viral infection occurring in the auditory nerve, blood flow disorder in the inner ear, disruption or damage to the cochlea, immune disorders of the inner ear, neuropathological disease, tumor, ototoxic drugs and the like.</p><p id="p-0265" num="0267">Acoustic tumor may occupy 1 to 2% of patients with the sudden hearing loss. This is diagnosed through MRI and a curative rate thereof is high in a patient who was subjected to the treatment at an early stage through combined modality therapy of adrenal cortical steroids, vasodilators, blood flow improving agents, metabolism improving agents, sedatives and the like, as well as dietary therapy such as low salt diet and high protein diet, while taking a relief in a hospital.</p><p id="p-0266" num="0268">According to the treatment result, generally, one third of patients out of total patient subjected to the treatment were completely recovered, while the symptom was ameliorated in one third of them and there was not treatment effect in the rest.</p><p id="p-0267" num="0269">In a person with severe hearing sensitivity damage, a risk of dementia is five times higher than those who have no hearing sensitivity damage. According to Lancet report, the hearing loss occupies 3% of causes of the onset of dementia, ranked first among 9 potential risk factors thereof.</p><p id="p-0268" num="0270">The hearing loss may be an early symptom of Alzheimer disease showing decline verbal ability in a state that there are background noises.</p><p id="p-0269" num="0271">Further, the hearing loss increases a demand for cognitive resources and the brain has to work harder when auditory ability deteriorated.</p><p id="p-0270" num="0272">Understanding and tries to understand conversations demand that the brain &#x2018;borrows&#x2019; cognitive ability from other parts thereof, particularly memory. Generally, the information transferred to the memory decreases as receiving more information.</p><p id="p-0271" num="0273">The hearing loss causes brain tissue remodeling and/or relative deprivation resulting in decline cognitive ability and the decline auditory ability often results in impaired social interaction and social engagement disorder.</p><p id="p-0272" num="0274">Accordingly, there was a study result that the progression of dementia might be slowed 75% in a fashion of approaching the environment by decreasing a cognitive ability required for interaction and preventing hearing loss.</p><p id="p-0273" num="0275">Further, it is prominent to detect and treat hearing loss early for preventing and reducing decline cognitive ability.</p><p id="p-0274" num="0276">Risks of dementia in each of the elderly with mild hearing loss and severe hearing loss appear two times and five times higher, respectively as compared to the population with normal hearing ability (Lin, Albert, 2014).</p><p id="p-0275" num="0277">30% of the population with hearing loss experienced tinnitus, additionally requiring the treatment of hearing loss together with the examination and treatment of tinnitus (Healthy hearing, 2019). As a result of examination over patients with tinnitus, the tinnitus affected an auditory function first, followed by affecting a cognitive function (particularly attention and thinking ability) and dementia, sequentially.</p><p id="p-0276" num="0278">In conclusion, the tinnitus will likely lead to dementia (Mahoney, Rohrer, Goll, Fox, Rossor, Warren, 2010).</p><p id="p-0277" num="0279">As a result of analysis of 18 literatures from 1996 to 2014, the tinnitus decreases cognitive intelligence while increasing anxiety and depression (Tegg-Quinn, Bennett, Elikelboom, &#x26; Baguley, 2016).</p><p id="p-0278" num="0280">In conclusion, this leads to problems with hearing &#x3e;sentence hearing &#x3e;word hearing &#x3e;overall comprehension &#x3e;responses &#x3e;mild cognitive impairment (MCI) in order.</p><p id="p-0279" num="0281">When there is auditory damage at every 30 dB, a predisposition to cognitive impairment approximates 2 times, this occurring when a problem arises in at least on of hearing, cognition and sight rather than sequentially (LEE, Su-jeong, LEE, Seung-jin, SONG, Ji-yeon, KIM, Hyeong-hee, 2014).</p><p id="p-0280" num="0282">According to the present invention, the user data collecting <b>30</b> may include the auditory information collecting portion <b>31</b>.</p><p id="p-0281" num="0283">Wherein, the diagnosing portion <b>50</b> may determine a level of the user's hearing sensitivity damage based on the collected auditory information and may determine the brain state of the user using the at least one brain activation area together with the determined level of user's hearing sensitivity damage.</p><p id="p-0282" num="0284">Particularly, when the user's hearing sensitivity damage results from hearing loss, the diagnosing portion may determine the brain state of the user by additionally using the body information related to the user, an average value of pure-tone thresholds in both of the user's ears, a level of the user's hearing loss and the information related to the auditory information collecting portion.</p><p id="p-0283" num="0285">As another example, when the user's hearing sensitivity damage results from Tinnitus, the diagnosing portion may determine the brain state of the user by additionally using the body information related to the user, an average value of pure-tone thresholds in both of the user's ears, a level of the user's hearing loss and the information related to the auditory information collecting portion.</p><p id="p-0284" num="0286">Meanwhile, a signal collecting operation of the brain signal measuring portion <b>10</b> may be performed in a state that the user's hearing sensitivity is damaged, while the user is moving.</p><p id="p-0285" num="0287">Moving on to the next, a function of the diagnosing portion <b>50</b> using the non-contact typed emotional change collecting portion <b>37</b> will be described.</p><p id="p-0286" num="0288">Biodata for personal emotion recognition may be collected and the data argumentation may be made based on the non-contact typed emotional change collecting portion <b>37</b>.</p><p id="p-0287" num="0289">Texts and facial expression data may be collected which show 6 types of basic feelings for various domains (age, gender, existence of accessories) in a uniform distribution.</p><p id="p-0288" num="0290">A basic emotion label may be tagged on the collected data and collect face landmark masking data including eye tracking.</p><p id="p-0289" num="0291">Further, pose estimation imaging and images may be collected for understanding a target object's intension and a speech argumentation method may be provided for correcting the emotion data imbalance.</p><p id="p-0290" num="0292">Regarding the biodata based personal emotion recognition, emotions may be recognized through a trained Deep Neural Network (DNN) model using the collected data.</p><p id="p-0291" num="0293">In order to increase an emotion recognition performance, it is allowable to develop and apply preprocessing methods such as noise removal, speech part extraction and the like, and modules for selecting and extracting speech characteristics suitable for the emotion recognition is applicable.</p><p id="p-0292" num="0294">Further, an utterance level emotion recognition model based on deep learning is applicable and extraction of time series of speech is allowable to infer a basic emotion for the target object data and to recognize personal emotion utilizing the speech data.</p><p id="p-0293" num="0295">Among deep learning methodologies, an emotion recognition AI model is applicable which utilizes recurrent neural network taking account of time series, a transformer using attention mechanism and the like. Optimal emotional recognition is allowable by using the designed emotion recognition AI model in machine learning and hyperparameter tuning method such as Bayesian optimization.</p><p id="p-0294" num="0296">Further, it is allowable to recognize contours of eyes, a nose, lips, eyebrows and face, and also to extract an attention level from the collected eye tracking data and face landmark time series (it is allowable to use attention based artificial neural network due to using of consecutive data).</p><p id="p-0295" num="0297">It is allowable to apply a social emotion recognition method through tracking personal emotion and daily situation and to represent emotion embedding advancement and emotions in consecutive spaces rather than classifying them. Also, it is allowable to apply a multi-modal emotion analysis and the like by combining emotion embedding extracted from sight, speech and natural language to an embedding space reflecting continuity of the time series data.</p><p id="p-0296" num="0298">For the social emotion recognition, personal emotion extraction and vectorization methods are applicable by using speech based texts, d-vector based speaker embedding, prior-developed speech emotion recognition methods.</p><p id="p-0297" num="0299">It is allowable to extract and apply characteristics applying Cepstral mean and variance normalization (CMVN) for suppressing performance decline for the speech of daily conversation with uneven tones resulting from emotions and also to apply a language model applying domain adoption capable of taking account of characteristics of the expression and word which are changeable according to situation information.</p><p id="p-0298" num="0300">As the non-contact typed emotional change collecting portion <b>37</b>, a non-contact typed emotional change collecting portion may be used which collects the user's face landmark masking data based on the user's eye tracking to collect the user's emotional change information in a non-contact way.</p><p id="p-0299" num="0301">Wherein, the diagnosing portion <b>50</b> may determine the brain state of the user by using the at least one brain activation area together with the user's emotional change information.</p><p id="p-0300" num="0302">Further, as the non-contact typed emotional change collecting portion <b>37</b> a non-contact typed emotional change collecting portion may be used which collects the user's emotional change information based on the user's speech change.</p><p id="p-0301" num="0303">Wherein, the diagnosing portion <b>50</b> may determine the brain state of user by using the at least one brain activation area together with the user's emotional change information.</p><p id="p-0302" num="0304">Particularly, the diagnosing portion <b>50</b> may determine the brain state of the user based on the at least one of brain activation areas extracted successively for a predetermined period of time.</p><p id="p-0303" num="0305">Wherein, the diagnosing portion <b>50</b> may determine the user's brain disease, the brain disease including dementia, mild cognitive impairment (MCI), Parkinson's disease, depression, cerebral stroke, Epilepsy, brain cancer and developmental disabilities.</p><p id="p-0304" num="0306">Furthermore, a management portion <b>60</b> may be further used which provides information for ameliorating the user's brain state, corresponding to the user's brain state determined by the diagnosing portion <b>50</b>.</p><p id="p-0305" num="0307">Meanwhile, <figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram of an imaging obtaining portion in connection with the present invention.</p><p id="p-0306" num="0308">The imaging obtaining portion <b>40</b> according to the present invention collects a medical imaging related to the user.</p><p id="p-0307" num="0309">As the imaging obtaining portion <b>40</b> according to the present invention, used are an MRI imaging scan obtaining portion <b>41</b> that collects an MRI imaging scan related to the user, a CT imaging scan obtaining portion <b>42</b> that collects a CT imaging scan related to the user and an fMRI imaging scan obtaining portion <b>43</b> that collects an fMRI imaging scan related to the user.</p><p id="p-0308" num="0310">Wherein, the diagnosing portion <b>50</b> may determine the user's brain state based on the at least one brain activation area, body information related to the user and the collected medical imaging related to the user together.</p><p id="p-0309" num="0311">The diagnosing portion <b>50</b> may determine the user's brain diseases including dementia, Parkinson's disease, cerebral stroke, Epilepsy, brain cancer and developmental disabilities.</p><p id="p-0310" num="0312">Lastly, the management portion <b>60</b> provides information for ameliorating the user's brain state, corresponding to the user's brain state determined by the diagnosing portion <b>50</b>.</p><p id="p-0311" num="0313">For example, when the user is suspected of at least one of dementia, Parkinson's disease, cerebral stroke, Epilepsy, brain cancer and developmental disabilities by applying preset references based on the user's brain state, a user's brain stimulating operation of the brain signal stimulating portion <b>20</b> may be triggered for ameliorating the user's brain state according to controlling of the management portion <b>60</b>.</p><p id="p-0312" num="0314">Diagnosing Portion based on the Collected Signals</p><p id="p-0313" num="0315">Firstly, the brain signal stimulating portion <b>20</b> may generate a stimulating signal to stimulate the brain of a target object and output the generated stimulating signals. For example, the brain signal stimulating portion <b>20</b> may be a Head Mounted Display (HMD) device which provides Virtual Reality (VR) imaging but is not limited thereto. In various embodiments, the brain signal stimulating portion <b>20</b> may be one of various devices for providing a content for the brain stimulation in accordance with senses of sight, hearing, touch and the like.</p><p id="p-0314" num="0316">When this brain signal stimulating portion <b>20</b> is an HMD device, the HMD device is mounted on the head of the target object and provides the target object a brain stimulating content for the virtual reality allowing spatial and temporal experiences similar to the reality. This may be also a complex VR experience device which detects physical, cognitive and emotional changes of the user in a state of experiencing the VR by obtaining the user's biodata. For example, the brain stimulating content may include non-interactive imaging such as movies, animations, advertisements, promotion imaging or the like and interactive imaging such as games, electronic manuals, electronic dictionaries, promotion imaging or the like but this is not limited thereto. Wherein, the imaging may be three-dimensional imaging and may include stereoscopic imaging.</p><p id="p-0315" num="0317">This HMD device is formed into a structure capable of being mounted on the user's head and may be implemented into a form displaying various brain stimulating contents for the VR through a display portion inside the HMD device.</p><p id="p-0316" num="0318">Further, when the HMD device has a display portion, one side of the display portion may be disposed facing the face of the target object, allowing the target object to confirm the brain stimulating content when wearing the HMD device.</p><p id="p-0317" num="0319">The brain signal stimulating portion <b>20</b> according to various embodiments may further include a special equipment such as gloves, clothing and the like allowing the target object to feel sensuous effects like seeing and touching something in real and consequently to be immersed in the VR environment.</p><p id="p-0318" num="0320">Next, the brain signal measuring portion <b>10</b> is to obtain fNIRS data generated by the brain stimulation of the target object and this may include a plurality of light sources used for obtaining the fNIRS data and a detecting portion corresponding to each of the plurality of light sources.</p><p id="p-0319" num="0321">Particularly, the brain signal measuring portion <b>10</b> detects the plurality of light sources and the near-infrared ray from each of the plurality of light sources, and may include a detecting portion disposed as a pair with the each light source.</p><p id="p-0320" num="0322">In this brain signal measuring portion <b>10</b>, the light sources and the detecting portions are disposed in a form of a matrix of n&#xd7;m (n and m are natural numbers) and this may be implemented into a form of a headpiece for enveloping the whole scalp of the target object. However, the brain signal measuring portion <b>10</b> is not limited thereto and may be implemented into various forms for detecting the near-infrared ray from the scalp of the target object. A channel is formed in the area between the light source and the detecting portion disposed as described above, allowing detecting the near-infrared ray within the formed channel.</p><p id="p-0321" num="0323">The brain signal measuring portion <b>10</b> emits lights to the scalp of the target object through the plurality of the light sources, detecting a near-infrared ray corresponding to an SMA (supplementary motor area) which controls movement of the target object in near-infrared rays released from the scalp by the emitted lights, through the detecting portion which makes a pair with the each light source, allowing obtaining fNIRS data of the SMA. The brain signal measuring portion <b>10</b> may transfer the obtained fNIRS data to the diagnosing portion <b>50</b>.</p><p id="p-0322" num="0324">The diagnosing portion <b>50</b> determines a state of the target object by using the fNIRS data and may include at least one of a tablet PC (Personal Computer), a notebook computer and/or a personal computer.</p><p id="p-0323" num="0325">Particularly, the diagnosing portion <b>50</b> computes analysis data for the SMA by using the fNIRS data received from the brain signal measuring portion <b>10</b>, determining the state of the target object based on the computed analysis data. Wherein, the SMA plans movement of the target object, implementing and controlling the planned movement. For example, this may be activated when an individual is doing upper or lower workout, eye exercise, hand exercise or the like.</p><p id="p-0324" num="0326">In order to compute the analysis data, the diagnosing portion <b>50</b> may perform power spectrum analysis and z-score analysis. However, this is not limited thereto and various data analysis methods may be used for determining the state of the target object.</p><p id="p-0325" num="0327">The diagnosing portion <b>50</b> may use at least one of a pattern mining method and a machine learning method to determine the state of the target object based on the analysis data computed through such a data analysis method.</p><p id="p-0326" num="0328">When using the pattern mining method, the diagnosing portion <b>50</b> may generate an analysis pattern of the target object by using a pattern generating model trained for generating the analysis pattern based on the analysis data. Wherein, the pattern generating model may be a model based on a clustering algorithm.</p><p id="p-0327" num="0329">The diagnosing portion <b>50</b> may determine the state of the target object by using a state predicting model trained to predict the state of the user stochastically based on the generated analysis pattern as described above. Wherein, when the target object is a patient with a specific disease and a stimulating content is provided for the treatment thereof, the state of the target object may mean a behavioral pattern that is changeable according to the provided stimulating content. For example, the diagnosing portion <b>50</b> may determine the state of the target object relating to exercise ability, sense of balance, learning efficacy, kinesthetic sense, movement planning and/or synesthesia, and the like, but this is not limited thereto.</p><p id="p-0328" num="0330">When using the machine learning method, the diagnosing portion <b>50</b> may determine the state of the target object by using a predicting model for predicting the state of the target object based on the analysis data. For example, the predicting model may be based on models of DNN (Deep Neural Network), CNN (Convolutional Neural Network), DCNN (Deep Convolution Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), SSD (Single Shot Detector) or a U-net based predicting model, but this is not limited thereto.</p><p id="p-0329" num="0331">The diagnosing portion <b>50</b> according to various embodiments may monitor the determined state as described above or provide feedback data for the determined state. For example, the diagnosing portion <b>50</b> may provide monitoring data or feedback data relating to exercise ability, sense of balance, learning efficacy, kinesthetic sense, movement planning and/or synesthesia, and the like.</p><p id="p-0330" num="0332">A whole system according to various embodiments may diagnose the state of the brain such as brain activation, brain diseases and the like by measuring fNIRS data of the brain area to external stimulation in a state that the target object is moving.</p><p id="p-0331" num="0333">As described above, the present invention determines the state of the target object by using the fNIRS data of the SMA that controls the individual's movement and provides the determined state as the monitoring or feedback data and thus allowing providing an appropriate stimulating signal to the target object with movement impairment such as a patient with Parkinson's disease or partial body paralysis caused by an accident for the treatment thereof and checking whether the brain of the target object works properly or not or the normality thereof spatio-temporally and in real time.</p><p id="p-0332" num="0334">The brain stimulating portion <b>20</b> may include an imaging playing device and an input device. The imaging playing device is capable of wire/wireless communication with the input device. The brain signal stimulating portion <b>20</b> according to the provided embodiment means the brain signal stimulating portion (<b>20</b>) of <figref idref="DRAWINGS">FIG. <b>1</b></figref> and will be assumed and described as the HMD device which plays VR imaging.</p><p id="p-0333" num="0335">Firstly, the imaging playing device may include a communication part, a sensing part, a display portion, a storing portion and a control portion.</p><p id="p-0334" num="0336">The communication portion allows the imaging playing portion to communicate with an external device. The communication portion is connected to the diagnosing portion <b>50</b> by using wire/wireless communication allowing transmitting/receiving various kinds of data. Wherein, the various kinds of data may be VR contents and these VR contents may be first- or third-person contents. For example, the third-person content may include an avatar matching the target object, the avatar implementing similar to the appearance of the target object.</p><p id="p-0335" num="0337">The sensing portion includes a movement sensor for sensing the user head movement, allowing outputting a detecting signal by sensing the user head movement through the movement sensor. However, this is not limited thereto and various sensor for sensing the head movement may be used.</p><p id="p-0336" num="0338">The display portion may show the user various contents (e.g. texts, images, videos, icons, banners or symbols). Particularly, the display portion may display the VR content received through the communication portion or stored in the storing portion.</p><p id="p-0337" num="0339">The storing portion may store various kinds of data used for stimulating the brain. For example, the storing portion may store the VR content.</p><p id="p-0338" num="0340">The storing portion according to various embodiment may include at least one type storage medium selected from a flash memory type, a hard disk type, a multimedia card micro type, a card type memory (e.g. an SD or XD memory and the like), a Random Access Memory (RAM), an SRAM (Static Random Access Memory, a Read-Only Memory (ROM), an EEPROM (Electrically Erasable Programmable Read-Only Memory), a PROM (Programmable Read-Only Memory), a magnetic random memory (MRAM), a magnetic disc, and an optical disc. The imaging playing device may be operated in relation with a Web storage that performs a storing function of the storing portion on the internet.</p><p id="p-0339" num="0341">The control portion is connected operably with the communication portion, the sensing portion, the display portion and the storing portion, allowing executing various instruction for providing VR contents used for stimulating the brain of the target object.</p><p id="p-0340" num="0342">Particularly, the control portion may display the VR content received through the communication portion or stored in the storing portion through the display portion. For example, when the VR content is a third-person game content, the third-person game content may include an avatar corresponding to the target object. In this case, the control portion may provide a user interface for generating the avatar.</p><p id="p-0341" num="0343">The control portion according to various embodiments may control the user interface related to the VR content by the operation of the input device by the target object. For example, the control portion controls the user interface for generating the avatar by the operation of the input device by the target object, allowing generating the avatar having an appearance similar to the target object.</p><p id="p-0342" num="0344">The control portion according to various embodiments senses the movement of the head of the user through the sensing portion and plays the VR content corresponding to a direction of the head of the user, allowing displaying the VR content.</p><p id="p-0343" num="0345">The input device (e.g. a controller and the like) is connected with the imaging playing device and the target object operates the input device connected to the imaging playing device, allowing controlling the user interface related to the VIR content displayed through the display portion of the imaging playing device.</p><p id="p-0344" num="0346">The brain signal measuring portion <b>10</b> may include a light source, a detecting portion and a data transmitting/receiving portion.</p><p id="p-0345" num="0347">This plurality of light sources is disposed in a form of a matrix of n&#xd7;m and may emit light to the scalp.</p><p id="p-0346" num="0348">The detecting portion may be provided as a pair with the corresponding light source and disposed in a form of a matric of n&#xd7;m.</p><p id="p-0347" num="0349">A channel is formed between the light source and the detecting portion disposed as described above, the detecting portion detecting near infrared ray in the channel to obtain the fNIRS data.</p><p id="p-0348" num="0350">The data transmitting/receiving portion may transfer the obtained fNIRS data to the diagnosing portion <b>50</b> through the wire or wireless communication.</p><p id="p-0349" num="0351">The diagnosing portion <b>50</b> may include a data receiving portion, a preprocessing portion, an analysis data computing portion and a state determining portion.</p><p id="p-0350" num="0352">Firstly, the data receiving portion may receive the fNIRS data from the brain signal measuring portion <b>10</b>.</p><p id="p-0351" num="0353">The preprocessing portion may perform preprocessing for removing biological or technical artifacts. For example, the preprocessing portion may perform preprocessing by adopting a moving average low-pass filter. However, this is not limited thereto and various filters may be used for removing the artifact.</p><p id="p-0352" num="0354">The analysis data computing portion collects preprocessed data corresponding to the channel related to the SMA at intervals of specific sampling time, allowing obtaining &#x394; data which shows a change in the concentration of oxy- and deoxy-hemoglobin based on the collected data.</p><p id="p-0353" num="0355">The analysis data computing portion may generate analysis data by analyzing the &#x394; data. Particularly, the analysis data computing portion generates the analysis data by using two more analysis methods. For example, the analysis method may include the power spectrum method and the z-score analysis method.</p><p id="p-0354" num="0356">Firstly, the analysis data computing portion may compute a power spectrum value by using the power spectrum analysis method to discern the area of the brain. For example, the analysis data computing portion converts time series data (i.e. the A data collected at intervals of specific sampling time) into a frequency domain using fast Fourier transform and computes power in the near infrared frequency window having a specific frequency range</p><p id="p-0355" num="0357">Next, the analysis data computing portion for computing the analysis data using the z-score method may convert the fNIRS data, that is, x(t)&#x2261;&#x394; into a time series z-score value (z(t)) by using an equation such as z(t)=[x(t)&#x2212;M0]/SD0, wherein the M0 and SD0 may mean the average value of the &#x394; data and the standard deviation thereof, respectively for a reference time range(t).</p><p id="p-0356" num="0358">The analysis data computing portion may compute the power value and the z-score value as the analysis data for the SMA by using the aforementioned analysis methods.</p><p id="p-0357" num="0359">The state determining portion may determine the state of the target object based on the computed analysis data. Particularly, the state determining portion may determine the state of the target object by using at least one of the pattern analysis method and the machine learning method. Herein, the state determining portion may determine exercise ability, sense of balance, learning efficacy, kinesthetic sense, movement planning and/or synesthesia and the like, as the state of the target object.</p><p id="p-0358" num="0360">Firstly, when using the pattern analysis method, the state portion may generate an analysis data pattern of the SMA by using the pattern generating model trained to generate the analysis data pattern. Wherein, the pattern generating model may be a model based on the clustering algorithm. For example, in order to generate the analysis data pattern, the pattern generating model performs the clustering algorithm repeatedly to compute the average value of the silhouette for each of the plurality of SMA analysis data, allowing determining, as an optimum number of patterns, the number of patterns having the smallest value in the number of those having the most dramatically increased average values. Furthermore, the pattern generating model may generate one SMA analysis data pattern by grouping patterns for the plurality of SMA analysis data based on the determined number of patterns by using the clustering algorithm.</p><p id="p-0359" num="0361">The state determining portion according to various embodiments may perform the clustering of a plurality of same SAM analysis data generated by computing the SMA analysis data for the target object at predetermined time intervals multiple times by using the pattern generating model.</p><p id="p-0360" num="0362">The state determining portion according to various embodiments computes similarity and dissimilarity matrices for two sets of data selected from the plurality of SMA analysis data, allowing determining a correlation of the two sets of data based on the computed similarity and dissimilarity. Furthermore, the state determining portion <b>404</b> may generate one analysis data pattern based on the correlation of the analysis data and the optimum number of the patterns.</p><p id="p-0361" num="0363">Next, the state determining portion may predict the state of the target object by using the state predicting model trained to predict the state of the target object stochastically based on the SMA analysis data pattern. Wherein the state predicting model may be a predicting model including steps of: computing SMA analysis data for a plurality of sample target objects different from the target object; generating patterns for each of the plurality of SMA analysis data by using the state predicting model; grouping each of the generated patterns to generate one analysis data pattern for each of the plurality of sample target objects; and determining a pattern related to the state of the target object in each of the generated analysis data.</p><p id="p-0362" num="0364">The state determining portion may determine the state of the target object stochastically based on a comparison result obtained by comparing the pattern related to the predetermined state using the predicting model with the analysis data pattern for the target object. For example, the state determining portion <b>404</b> may determine exercise ability, sense of balance, learning efficacy, kinesthetic sense, movement planning and/or synesthesia, and the like.</p><p id="p-0363" num="0365">Next, when using the machine learning method, the state determining portion may use a state predicting model pre-trained to predict the state of the target object based on the analysis data. For example, the state predicting model may be based on various learning models trained based on the analysis data of other target objects. For example, the predicting models used in various embodiments may be models of DNN, CNN, DCNN, RNN, RBM, DBN, SSD or the U-net based predicting model, but are not limited thereto.</p><p id="p-0364" num="0366">In other words, the state determining portion may predict the state of the target object based on the input of the analysis data of the target object by using the state predicting model pre-trained to predict the state of the target object, that is, exercise ability, sense of balance, learning efficacy, kinesthetic sense, movement planning and/or synesthesia and the like.</p><p id="p-0365" num="0367">The present invention as described above determines the state of the target object by using the SMA analysis data of the target object, allowing determining the target object as a patient with a brain disease or providing an index for preventing the brain disease.</p><p id="p-0366" num="0368">Hereinafter, a method for determining the state of the target object by using the fNIRS (functional near infrared ray spectroscopy) technique in an AI based device for providing brain information <b>1</b> will be described referring to <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>5</b>C</figref>.</p><p id="p-0367" num="0369">The AI based device for providing brain information <b>1</b> obtains fNIRS data of the SMA which controls the movement of the target object by performing brain stimulation for the target object. Particularly, the AI based device for providing brain information <b>1</b> performs the brain stimulation to the target object by the brain signal stimulating portion <b>20</b> and may obtain fNIRS data for the SMA of the target object through the brain signal measuring portion <b>10</b>. Herein, the fNIRS data for the SMA is obtained in an SMA related channel in the channels formed between the light source and the detecting portion making a plurality of pairs with each other and may be transferred to the diagnosing portion <b>50</b>.</p><p id="p-0368" num="0370">The AI based device for providing brain information <b>1</b> computes SMA analysis data by using the obtained fNIRS data (S<b>510</b>). Particularly, the AI based device for providing brain information <b>1</b> may calculate the SMA analysis data by using the power spectrum analysis and the z-score analysis. These calculating methods may be performed as described above.</p><p id="p-0369" num="0371">The AI based device for providing brain information <b>1</b> determines the state of the target object based on the calculated analysis data. Particularly, the AI based device for providing brain information <b>1</b> may determine the state of the target object by using at least one of the pattern analysis method and the machine learning method through the diagnosing portion <b>50</b>. The determined state as described above may be provided as feedback data for treating the disease of the target object or delaying progression thereof or monitoring data for preventing the disease. Further, the user may check whether the brain of the target object works properly or not or the normality thereof spatio-temporally and in real time by using these feedback data and monitoring data.</p><p id="p-0370" num="0372">Hereinafter, a method for determining the state of the target object based on the SMA analysis data calculated by using the z-score method will be described referring to <figref idref="DRAWINGS">FIG. <b>11</b></figref>.</p><p id="p-0371" num="0373"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is an exemplary view showing analysis data in an SMA by using the z-score analysis method according to the embodiment of the present invention.</p><p id="p-0372" num="0374">Referring to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the analysis data may be represented as a time series z-score value in the SMA. Generally, the SMA is an area that plans and controls the movement of the target object. Thus, when the target object performs a certain movement, the activity of the SMA is increased so that the time series z-score value of the SMA is gradually increased with reference to a reference line (z-score=0).</p><p id="p-0373" num="0375">When a specific event for the target object occurs, the time series z-score value is decreased to be a smaller value than the reference line in a section <b>600</b>, <b>602</b>, <b>604</b>, <b>606</b> where the specific event occurred. Herein, the specific event means that becomes acquainted with the movement of the target object. As the target object learns the movement quickly, a gradient of the time series z-score values may be declined sharply.</p><p id="p-0374" num="0376">Even when there is a limit in the movement of the target object or the target object conducts a movement that is difficult to be performed, the SMA activity of the target object may be increased. For example, when the target object performs a new movement or exercise (e.g. tennis, swimming, boozing and the like), the SMA activity in charge of the movement is increased, allowing activating a plan to become acquainted with the new movement or exercise in the SMA. Thus, the target object may acquire or perform the new movement or exercise. As the target object becomes acquainted with such the movement or exercise, the activity of the SMA is gradually decreased, allowing performing this movement or exercise less actively, more naturally and with less planning and effort. Further, in a case of a patient with Parkinson's disease or partial body paralysis caused by an accident, the brain signal stimulating portion <b>20</b> is fitted on the head of the patient to play various brain stimulation contents through the brain signal stimulating portion <b>20</b>, allowing providing a stimulating signal for treating the brain disease of the patient. In this case, the diagnosing portion <b>50</b> computes the analysis data for the SMA of the patient based on the fNIRS data obtained from the brain signal measuring portion <b>10</b>, determining the state of the patient by using the computed analysis data and then providing the brain stimulating content for the treatment based on the determined state of the patient. In a case of the patient with Parkinson's disease or partial body paralysis, since the SMA has a feeble activity or is inactivated, the brain stimulating content is provided for gradually increasing the SMA activity of this patient through the brain signal stimulating portion <b>20</b>, allowing helping treatment of the patient.</p><p id="p-0375" num="0377">As described above, the present invention determines the state of the target object by using the fNIRS data in the SMA related to behavioral implementation such as exercise ability or sense of balance, allowing diagnosing the target object as having the disease that decrease the SMA activation.</p><p id="p-0376" num="0378">Further, the present invention provides the determined state of the target object as the monitoring data or the feedback data, allowing generating an appropriate stimulating signal for preventing or treating the brain disease such as Parkinson's disease and the like.</p><p id="p-0377" num="0379">Further, the present invention may check whether the brain of the target object works properly or not or the normality thereof spatio-temporally and in real time by using the analysis data in the SMA.</p><p id="p-0378" num="0380">Multisensor Biodata Based Model for Providing Activated XR Digital Therapeutics</p><p id="p-0379" num="0381"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a view for explaining a multisensor biodata based model for providing activated XR digital therapeutics according to the present invention.</p><p id="p-0380" num="0382">Herein, the XR environment may include one selected from AR (Augmented Reality), VR (Virtual Reality) and MR (Mixed Reality).</p><p id="p-0381" num="0383">Referring to <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the multisensor biodata based model for providing activated XR digital therapeutics is composed of three steps as shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>.</p><p id="p-0382" num="0384">Measure-&#x3e;Evaluation-&#x3e;Solution</p><p id="p-0383" num="0385">In the measure step, it is allowable to collect medical instrument (PET, CT, MRI, X-Ray) information, results of genetic testing and blood test and the like.</p><p id="p-0384" num="0386">Further, the information is collected through a wearable device (smart watch, band, ECG patch) and information additionally obtained through questionnaires and an application may be used.</p><p id="p-0385" num="0387">Next, in the evaluation step, it is allowable to adopt the brain activation evaluation through Active Brain, brain activation maximization through the XR environment, Cognitive Emotional Behavioral Therapy (CEBT) and the like.</p><p id="p-0386" num="0388">Further, it is allowable to use this information as a biomarker for early stage of brain disease or to adopt a function of continuous tracking/management of the biomarker.</p><p id="p-0387" num="0389">Furthermore, the information may be used for early diagnosis.</p><p id="p-0388" num="0390">Lastly, in the solution step, is it allowable to use the aforementioned information as a plurality of digital therapeutics for the amelioration of cognitive impairment and the like and to improve medication behavior through a concurrent use thereof.</p><p id="p-0389" num="0391">Further, it is allowable to use the information in new medicine development.</p><p id="p-0390" num="0392"><figref idref="DRAWINGS">FIG. <b>13</b></figref> and <figref idref="DRAWINGS">FIG. <b>14</b></figref> show one example of each biodata obtained according to the present invention in association with the main device and data used for obtaining the biodata in the &#x201c;Measure&#x201d; step.</p><p id="p-0391" num="0393">Meanwhile, <figref idref="DRAWINGS">FIG. <b>15</b></figref> is a view for explaining one example which adopts the digital content-based method and system for providing therapeutics information according to the present invention.</p><p id="p-0392" num="0394">In <figref idref="DRAWINGS">FIG. <b>15</b></figref>, shown is one example of a configuration of a multimodal biodata based XR content platform in connection with a smart hospital system.</p><p id="p-0393" num="0395">Referring to <figref idref="DRAWINGS">FIG. <b>15</b></figref>, measured is a dynamic activation state of the brain when taking a rest as well as when conducting a certain behavior, collected and analyzed are a variety of brain related biodata and verified is the biodata for the brain activation in the XR environment.</p><p id="p-0394" num="0396">Further, it is allowable to adopt a Cognitive Behavioral Therapy (CBT) method capable of defining a brain area that affects depression in the XR environment and of activating the relevant region and to proceed not only to develop the therapeutic XR content but also to experience with the XR content simultaneously with measuring the brain in a dynamic state and collecting the biodata suing various biosensors, allowing providing individually tailored therapeutics and inducing the increment of therapeutic effect.</p><p id="p-0395" num="0397">Henceforth, the model of measure+therapeutics will be new data that has not ever been used in the existing diagnosis of depression, that is, a therapeutic module may be used as a preventing module.</p><p id="p-0396" num="0398">Method for Providing Digital based Therapeutics</p><p id="p-0397" num="0399"><figref idref="DRAWINGS">FIG. <b>16</b></figref> shows one example of a flowchart for explaining the digital content-based method for providing therapeutics information according to the present invention.</p><p id="p-0398" num="0400">Referring to <figref idref="DRAWINGS">FIG. <b>16</b></figref>, firstly, the brain stimulation for a user is performed to obtain fNIRS (functional near-infrared spectroscopy) data of the user S<b>1</b>.</p><p id="p-0399" num="0401">Next, a first brain activation area is extracted in a plurality of brain areas of the user by using the obtained fNIRS data S<b>2</b>.</p><p id="p-0400" num="0402">Following the S<b>2</b>, a first brain state of the user is determined based on the first brain activation area S<b>3</b>.</p><p id="p-0401" num="0403">In the S<b>3</b>, a brain disease of the user is determined based on the first brain state of the user, the brain disease including mild cognitive impairment (MCI), Parkinson's disease, depression, cerebral stroke, Epilepsy, brain cancer and developmental disabilities.</p><p id="p-0402" num="0404">Prior to the S<b>1</b>, the method may further include a step <b>0</b>.<b>5</b> of collecting body information related to the user and medical imaging information related to the user. In the step <b>3</b>, the first brain state of the user may be determined by using information of the first brain activation area together with information the body information and the medical imaging information.</p><p id="p-0403" num="0405">In the step <b>3</b>, the first brain state of may be determined by additionally using a correlation of activation information related to each of the plurality of areas, the body information and the medical imaging information based on pre-accumulated database.</p><p id="p-0404" num="0406">Herein, the body information may include at least one of a degree of hearing loss of the user, gait pattern of the user, a stress level, an EGG change, a sleep state and attention change information, oxygen saturation change and the like.</p><p id="p-0405" num="0407">Further, the medical imaging information may include at least one of an MRI imaging scan related to the user, a CT imaging related to the user and an fMRI imaging scan related to the user.</p><p id="p-0406" num="0408">The S<b>1</b> may include a S<b>1</b>-<b>1</b> of emitting light to a scalp of the user through a plurality of light sources and a S<b>1</b>-<b>2</b> of detecting the fNIRS data from the scalp to which the light was emitted through a detecting portion corresponding to each of the plurality of light sources.</p><p id="p-0407" num="0409">Herein the fNIRS data represents a change of NIR light intensity transmitted through the scalp and may be data from which artifact was removed through a moving average low-pass filter.</p><p id="p-0408" num="0410">Further, in the step <b>3</b>, a power spectrum method and a z-score analysis method may be used for determining the first brain state.</p><p id="p-0409" num="0411">Further, in the S<b>3</b>, analysis data for an SMA (supplementary Motor Area) which controls the user's movement based on the first brain activation area may be calculated to determine the first brain state based of the calculated analysis data.</p><p id="p-0410" num="0412">Further, in the S<b>3</b>, in the situation that a specific event happened to the user, it may be determined that there is a limit in the movement of the target object as an analysis data value for the SMA is increased with reference to a reference line, whereas it may be determined that the target object is acquainted with the movement as the analysis data value is decreased with reference to a reference line.</p><p id="p-0411" num="0413">Meanwhile, in the XR (extended Reality) environment, a content determined corresponding to the determined first brain state is provided to the user S<b>4</b>.</p><p id="p-0412" num="0414">The S<b>4</b> may include a S<b>4</b>-<b>1</b> of determining the first brain state as a base line; a S<b>4</b>-<b>2</b> of determining the content for activating the first brain activation area, corresponding to the first brain state and a S<b>4</b>-<b>3</b> of providing the user with the content through a device which the user wears, allowing the user to experience the XR environment.</p><p id="p-0413" num="0415">Further, the content may include a relaxation content for stabilizing emotion, a problem-solving content for controlling a stressed circumstance, an engagement content, a self-control content for controlling emotion and an impulse control content for controlling an impulsive behavior.</p><p id="p-0414" num="0416">Further, the user may be plural in number and the content may further include a group therapy in which at least a part of the plurality of users performs a mission together.</p><p id="p-0415" num="0417">Further, in the step <b>3</b>, a brain disease of the user may be determined, the brain disease including dementia, MCI, Parkinson's disease, depression, cerebral stroke, Epilepsy, brain cancer and developmental disabilities.</p><p id="p-0416" num="0418">Further, in the step <b>4</b>, the content may be determined relating treatment of the determined brain disease.</p><p id="p-0417" num="0419">Further, the user performs a mission corresponding to the content S<b>5</b>.</p><p id="p-0418" num="0420">The S<b>5</b> may include a S<b>5</b>-<b>1</b> in which the user performs the mission changeable depending on a play processing level of the content and a S<b>5</b>-<b>2</b> of providing information related to the brain of the user in real time while the user is in a state of performing the mission.</p><p id="p-0419" num="0421">Further, even not shown, the S<b>5</b> may further include a step of extracting a third brain activation area from the plurality of brain areas with reference to fNIRS data of the user while performing the mission and determining a third brain state of the user based on the third brain activation area.</p><p id="p-0420" num="0422">Further, a second brain activation area is extracted in the plurality of brain areas with reference to the fNIRS data of the user following performing the mission S<b>6</b>.</p><p id="p-0421" num="0423">Further, a second brain state of the user is determined based on the second brain activation area S<b>7</b>.</p><p id="p-0422" num="0424">Further, information related to amelioration of the brain state of the user is determined by using the first and second brain state information S<b>8</b>.</p><p id="p-0423" num="0425">When the step <b>8</b> further includes a step of extracting the activated third brain activation area in the plurality of areas with reference to the fNIRS data of the user in the middle of performing the mission and determining the third brain state of the user based on the third brain activation area, the step <b>8</b> may determine information related to the amelioration of the brain state of the user by using the first brain state information, the second brain state information and the third brain state information together.</p><p id="p-0424" num="0426">Further, the user is provided with at least one of the first brain state information, the second brain state information and the third brain state information S<b>9</b>.</p><p id="p-0425" num="0427"><figref idref="DRAWINGS">FIG. <b>17</b></figref> and <figref idref="DRAWINGS">FIG. <b>18</b></figref> show views for explaining a technique for predicting, diagnosing and treating a disease, based on processing of a correlation of a plurality of data in connection with the present invention.</p><p id="p-0426" num="0428">Referring to <figref idref="DRAWINGS">FIG. <b>17</b></figref>, it is allowable to measure data of memory, judgement, attention, emotional changes and stress fora normal control group based on fNIRS, ECG, EEG, GSR and EMG, to verify a correlation of data of fNIRS, ECG, EEG, GSR and EMG and to perform a curing process through the digital therapeutics in the XR content applied environment. It is allowable to verify a correlation of Active Brain data (fNIRS) with other biodata (ECG, EEG, GSR and EMG).</p><p id="p-0427" num="0429">In <figref idref="DRAWINGS">FIG. <b>17</b></figref>, following wearing an Active brain scanner, a Smart watch, an ECG Patch and the like, an action task is performed in the XR content applied environment, allowing obtaining the data of fNIRS, ECG, EEG, GSR and EMG of the normal control group.</p><p id="p-0428" num="0430">Further, it is allowable to determine the memory, judgement, attention, emotional changes, and stress changes of the normal control group while performing the action task.</p><p id="p-0429" num="0431">Further, it is allowable to verify the correlation of the Active Brain data (fNIRS) with other biodata (ECG, EEG, GSR and EMG).</p><p id="p-0430" num="0432">Further, following wearing the Active brain scanner, the Smart watch, the ECG Patch and the like, a cure task is performed in the XR content applied environment, allowing verifying effects of memory increment, judgement improvement, attention increment and emotional change and stress decrement in the normal control group through brain activation and CNS efficacy increment while performing the cure task.</p><p id="p-0431" num="0433">Further, it is allowable to verify the correlation of the Active Brain data (fNIRS) with other biodata (ECG, EEG, GSR and EMG) while performing the cure task.</p><p id="p-0432" num="0434">Meanwhile, referring to <figref idref="DRAWINGS">FIG. <b>18</b></figref>, it is allowable to measure data of memory, judgement, attention, emotional changes and stress for each of a dementia group, an MCI group and a normal control group based on fNIRS, ECG, EEG and GSR, to obtain brain MRI imaging scan data and SNSB data and to verify a correlation of Active Brain data (fNIRS), other biodata (ECG, EEG, GSR), MRI imaging data and SNSB data according to the classification into the dementia group, the MCI group and the normal control group.</p><p id="p-0433" num="0435">In <figref idref="DRAWINGS">FIG. <b>18</b></figref>, following wearing an Active brain scanner, a Smart watch, an ECG Patch and the like, an action task is performed for each of the dementia group, the MCI group and the normal control group in the XR content applied environment, and SNSB is performed, allowing obtaining the data of fNIRS, ECG, EEG, GSR, EMG, SNSB and brain MRI imaging scan of each of the dementia group, the MCI group and the normal control group.</p><p id="p-0434" num="0436">Further, it is allowable to verify the data of fNIRS, ECG, EEG and GSR for each of the dementia group, the MCI group and the normal control group while performing the action task, and to verify a correlation of the data of fNIRS, ECG, EEG and GSR with the SNSB data for each of the dementia group, the MCI group and the normal control group.</p><p id="p-0435" num="0437"><figref idref="DRAWINGS">FIG. <b>19</b>A to <b>19</b>C</figref> show one example for providing a content determined corresponding to the brain state of the user under an XR (Extended Reality) environment.</p><p id="p-0436" num="0438"><figref idref="DRAWINGS">FIG. <b>19</b>A</figref> shows one example of a baseline measure, FIG. B shows one example for processing an XR-CBT activity and <figref idref="DRAWINGS">FIG. <b>19</b>C</figref> shows one example of a user-tailored curation.</p><p id="p-0437" num="0439">That is, the user wears AR glasses for biosensor &#x26; XR experience such as Active brain scanner, a smart band, an ECG patch and the like. The brain state of the user of the baseline and the multimodal biodata is measured with the XR content having a gentle background, allowing diagnosing a level of depression and showing the user the depression level.</p><p id="p-0438" num="0440">Further, the individually tailored content is configured based on the measured data. Multiple kinds of XR activities and CBD methodologies are combined, 20 or more various XR-CBT content combinations are curated in order to most effectively activating the real time brain state of an individual and then the curated content is provided to the user.</p><p id="p-0439" num="0441">Further, as processing the content and showing the state and activity of the brain and the biodata in real time in a state that the user takes movement, the user may confirm the effect on the brain him- or herself.</p><p id="p-0440" num="0442">Further, following experiencing one content, a content to be proceeded next is curated and then the curated content is provided to the user. It is allowable to confirm the therapeutic effect by providing baseline measure data after completing the content experience and a result for comparing and analyzing the data following the experience.</p><p id="p-0441" num="0443">Accordingly, it is allowable to configure and provide a user tailored effective therapeutic content by collecting and analyzing brain activation data collected by the Active Brain scanner and a variety of biodata (ECG, REP and the like) collected by the multimodal biosensor for the brain state when using the XR content, on the basis of technical skills capable of measuring the brain activation state when the user is moving or takes a certain task.</p><p id="p-0442" num="0444">Further, the XR content which the user experiences are combined with the CBT methodology, accompanying therapeutic effects and maximizing engagement and embodiment. This gives stimulation by using a gamification method, allowing activating the brain of the user at the most with a short period of time.</p><p id="p-0443" num="0445">Further, as measuring an activated brain (by MRI and the like) rather than when taking a rest, it is allowable to contribute more precise treatment, that the user confirms a region of brain activation and a degree thereof him- or herself in real time, to provide and verify the user tailored XR-CBT content curation and to use this for early diagnosing and treating depression by combining measures of a variety of biodata.</p><p id="p-0444" num="0446"><figref idref="DRAWINGS">FIG. <b>20</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>20</b>C</figref> show one example for that the user performs a mission corresponding to the content provided under the XR environment and monitors the brain state.</p><p id="p-0445" num="0447">As shown in <figref idref="DRAWINGS">FIG. <b>20</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>20</b>C</figref>, XR-CBT combined content may be used for the purpose of therapy.</p><p id="p-0446" num="0448">The CBT is a psychotherapy method for treating maladaptive behavior by systemically integrating concept&#x22c5;principal&#x22c5;theory related to a cognitive aspect such as thinking&#x22c5;belief&#x22c5;value and an aspect of psychomotor behavior. A consultant uses this psychotherapy method in order to lead a consultee out into affirmative behavior and thinking changes using various skills.</p><p id="p-0447" num="0449">In a case of depression, it is one way to hele a person with depression to recognize and change negative thinking patterns or behaviors. The depression CBT may be to concentrate on a currently facing problem and on how to solve this problem and to train up a new skill in the real world.</p><p id="p-0448" num="0450">Further, it was revealed that Online CBT helped ameliorating depression symptoms similarly to an antipdressant through various study results.</p><p id="p-0449" num="0451">The Online CBT has not been distributed broadly within the country while this Online CBT is actively used as a depression treatment/management method abroad.</p><p id="p-0450" num="0452">Further, Gamified CBT is gamified with a computerized therapy method, allowing proceeding the CBT effectively with minimization of face-to-fact contact. As increasing the user's participation and maximizing engagement and amusement, it is allowable to provide a new user experience and creating therapeutic effects by inducing attention improvement, learning promotion and affirmative behavior changes.</p><p id="p-0451" num="0453">The XR according to the present invention may improve recovery and healing effects by providing the user with an extended experience through engagement and coexistence in the XR.</p><p id="p-0452" num="0454">As motivating the user in the VR environment, it is allowable that the user successfully completes repeating training possibly boring.</p><p id="p-0453" num="0455">Further, as configuring the optimum environment capable of lowing psychological anxiety and stress, it is allowable that the user experiences highly concentrated meditation and psychological healing.</p><p id="p-0454" num="0456">In case of the existing CBT, many sessions should be proceeded for a long period of time, engagement and self-participation are low and it is difficult to confirm self-state and therapeutic effects. Thus, there is a limit in motivating the user to undergo treatment.</p><p id="p-0455" num="0457">It is very important to increase engagement in order for &#x2018;brain activation&#x2019; for depression therapy. When proceeding the XR experience by providing content experience in a specific space in an appropriate environment, engagement affecting behavioral changes is maximized, allowing effective brain state measure as well as using this XR as a therapeutic means.</p><p id="p-0456" num="0458">XR-CBR combined DTx according to the present invention takes advantages of engagement, coexistence and the like from the existing XR environment, having potential therapeutic effects similar to the online CBT and extending a therapeutic range through XR-CBT content curation according different symptoms and brain activation states of the user.</p><p id="p-0457" num="0459">Types of Contents</p><p id="p-0458" num="0460">(1) Relaxation</p><p id="p-0459" num="0461">It is verified that relation behavior and training have a high effect on amelioration of symptoms of anxiety and depression by meta-analysis. The anxiety symptom is greatly decreased by maintaining composure and controlling emotion, this helps incapacitation of excessive worrying and negative thinking.</p><p id="p-0460" num="0462">(2) Problem-Solving</p><p id="p-0461" num="0463">Problem-solving therapy trains abilities for managing a stressful situation. Negative effects of the stress are lowered through solving a problematic situation and this increases self-efficacy.</p><p id="p-0462" num="0464">(3) Engagement</p><p id="p-0463" num="0465">The user's participation is increased to improve attention and learning effect. As preparing a platform for learning techniques (abilities) in order for the user to feel like experiencing real-situation in the VR, it is allowable to increase engagement and entertainment more.</p><p id="p-0464" num="0466">(4) Self-Control</p><p id="p-0465" num="0467">Since the user's emotion and response is confirmed in real time through Active Brain and multimodal data, the user controls his or her emotion and behavior by checking effects or emotion resulting from his or her behavior (or inaction), consequentially reducing anxiety and worrying.</p><p id="p-0466" num="0468">(5) Group Therapy</p><p id="p-0467" num="0469">As the user has a feeling like performing a task with other peoples rather than doing the task alone, the user is encouraged in interaction with the others and has a feeling of gratitude that is one of affirmative psychological factors. As expressing one's gratitude, it is allowable to causes feeling of wellbeing and happiness and ameliorates symptoms related to depression and anxiety.</p><p id="p-0468" num="0470">(6) Impulse Control</p><p id="p-0469" num="0471">Like a game raising blue and white flag, the user should repress an impulse until an appropriate moment according to an instruction is coming, allowing increasing his or her attention in a situation requiring concentration on the instruction and improving impulse control ability. As paying attention and changing an attentive object properly according to changes in the situation, it is allowable to improve an ability to convert attention.</p><p id="p-0470" num="0472">Content Scenario</p><p id="p-0471" num="0473">(1) Prior to starting a content, a content may be configured for the user to confirm a self-state and a user tailored content is recommended based on the relevant contents.</p><p id="p-0472" num="0474">(2) It is allowable to receive and experience the content that is suitable for one's situation. The content is configured to recommend next content in a connectional manner through the relevant contents by receiving data in real time during the experience, allowing maximizing therapeutic effects.</p><p id="p-0473" num="0475">(3) Following completing the content, any change of the user is confirmed through comparing and analyzing the state with the data before experiencing the content, allowing applying this to the treatment through data set based analysis.</p><p id="p-0474" num="0476">20 or more various kinds of different XR-CBT are configured by matching CBT methods applicable to each of various kinds of XR activities. Those contents are curated in a user tailored way based on multimodal biodata obtained by an Active Brain Scanner and biosensors, allowing inducing the user's continued participation in the treatment without boring in a circumstance requiring repetitive treatment or re-visit.</p><p id="p-0475" num="0477">As one example, in a case of experiencing a rafting-relaxation content, it is allowable to confirm whether the user's emotion is stabilized or not and real time brain state of the user by Active brain screening and biodata. Also, the user may confirm the state his- or herself, allowing realizing the effect of the content.</p><p id="p-0476" num="0478">After experiencing the content with the collected data, next content is curated. Since the user experienced the rafting activity already, a content is selected from contents of Baseball-Group Therapy or Fishing-Impulse Control, allowing informing the user of expected effects through the selected content and the user to experience a new activity and to confirm achievement.</p><p id="p-0477" num="0479">Following completing all experiences, the user feels therapeutic effect by confirm a result of comparing and analyzing data for before and after those experiences.</p><heading id="h-0012" level="1">Effect According to the Present Invention</heading><p id="p-0478" num="0480">When the aforementioned configurations are applied, the present invention is capable of providing a digital content-based device for providing therapeutics information and a method thereof.</p><p id="p-0479" num="0481">Particularly, the present invention is capable of providing the device for providing digital therapeutics and method thereof by collecting signals related to a brain of a user in a state of activity and determining a brain state of the user based thereon.</p><p id="p-0480" num="0482">Further, the present invention is capable of providing the device for providing digital therapeutics and method thereof by performing stimulation on the brain of the user to obtain fNIRS data, extracting an activation area in a plurality of brain areas using the obtained fNIRS data, determining a brain state of the user based on the brain activation area and providing a determined content under an XR (extended reality) environment, allowing the user to perform a mission corresponding to the content.</p><p id="p-0481" num="0483">Further, the present invention is capable of providing the device for determining providing digital therapeutics and the method thereof by additionally extracting a brain activation area with respect to fNIRS data of the user who performed the mission, determining a brain state based on the additionally obtained brain activation area, and then determining and providing information related to amelioration of the brain state of the user.</p><p id="p-0482" num="0484">Further, the present invention is capable of providing the user with an AI based brain analysis technique which allows prediction of an asymptomatic disease in advance and early diagnosis.</p><p id="p-0483" num="0485">Further, the present invention is capable of providing the user with a brain function measurement technique which measures functions of the brain noninvasively in a way of mapping an average of time series blocks of the signal of channel position dependent fNIRS on a head, based on brain activation data imaged following measuring the brain in a state of activity.</p><p id="p-0484" num="0486">Further, the present invention is capable of providing the user with a brain activation area, a state cognitive algorithm and a data analysis visualization technique.</p><p id="p-0485" num="0487">Further, the present invention is capable of providing the user with a stimulation technique for obtaining brain activation data.</p><p id="p-0486" num="0488">Further, the present invention is capable of providing the user with a Hyper-scanning technique which measures changes in the brain of several persons and Inter-brain synchrony.</p><p id="p-0487" num="0489">Further, the present invention is capable of providing a user with a determination technique of a brain activation state.</p><p id="p-0488" num="0490">Further, the present invention is capable of providing the user with a determination technique of the brain activation state using body information (e.g., genetic information, gait pattern information, stress information, EGG change information, a sleep state and attention change information, oxygen saturation change information, and the like).</p><p id="p-0489" num="0491">Further, the present invention aims to provide a user with a determination technique of a brain activation state using imaging scan information (e.g., MRI, PET, CT, fMRI, X-ray and the like).</p><p id="p-0490" num="0492">Further, the present invention is capable of providing the user with a technique for predicting, diagnosing and treating a disease, based on a correlation of a plurality of data.</p><p id="p-0491" num="0493">Further, the present invention is capable of providing the user with a technique for obtaining data capable of used, as a biomarker in real time and analyzing the same.</p><p id="p-0492" num="0494">Further the present invention is capable of providing the user with a technique for preventing problems related to dementia, MCI, Parkinson's disease, depression, cerebral stroke, Epilepsy, brain cancer and developmental disabilities, managing, diagnosing and treating those diseases.</p><p id="p-0493" num="0495">Further, the present invention is capable of providing the user a technique for providing feedback to the user following measuring brain functions, based on a metaverse environment.</p><p id="p-0494" num="0496">Meanwhile, advantageous effects obtained from the present invention are not limited to the aforementioned effects, and other not-mentioned effects will be obviously understood by those skilled in the art from the description below.</p><p id="p-0495" num="0497">Embodiments according to the present invention may be implemented through various methods. For example, the embodiments of the present invention may be implemented through hardware, firmware, software or a combination of the preceding.</p><p id="p-0496" num="0498">In a case of implementation through the hardware, methods according to embodiments of the present invention may be implemented by one or more of ASICs (Application Specific Integrated Circuits), DSPs (Digital Signal Processors), DSPDs (Digital Signal Processing Devices), PLDs (Programmable Logic Devices), FPGAs (Field Programmable Gate Arrays), a processor, a controller, a microcontroller, a microprocessor and the like.</p><p id="p-0497" num="0499">In a case of implementation through the firmware or the software, methods according to embodiments of the present invention may be implemented into a form of a module, a process, a function or the like which performs the aforementioned function or operations. Source code for software is stored in a memory unit and driven by a processor. The memory unit is located on the exterior or interior of the processor, allowing receiving or transferring data from or to the processor may receive and transfer by publicly known various ways.</p><p id="p-0498" num="0500">As aforementioned, those skilled in the art may implement the present invention referring to the detailed description of the embodiments. Even though the present invention is described referring to preferable embodiment above, it will be appreciated that those skilled in the art can correct and modify this invention variously within the scope thereof. For example, those skilled in the art are available to use each configurational element describe above in detail thorough a combination thereof. Accordingly, it is intended to grant the widest scope conforming to principals and novel characteristics disclosed herein rather than to limit the present invention to the embodiments disclosed herein.</p><p id="p-0499" num="0501">The present invention may be implemented into other particular forms within the scope. Thus, the aforementioned detailed description should be considered as an example rather than understood limitedly. The scope of the present invention should be determined by comprehending the claimed inventions attached hereto. The scope of the present invention also includes all modification within a range equivalent thereto. Further, the present invention intends to grant the widest scope conforming to principals and novel characteristics disclosed herein rather than to limit the present invention to the embodiments disclosed herein. Further, it is allowable to configure an embodiment by combining claims which have no explicit citation relation with each other or to add new claims through amendments.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A digital content-based method for providing therapeutics information, wherein<claim-text>the method comprising:</claim-text><claim-text>a step <b>1</b> of performing stimulation on a brain of a user to obtain fNIRS (functional near-infrared spectroscopy) data of the user;</claim-text><claim-text>a step <b>2</b> of extracting a first brain activation area from a plurality of brain areas of the user using the obtained fNIRS data;</claim-text><claim-text>a step <b>3</b> of determining a first brain state of the user, based on the first brain activation area;</claim-text><claim-text>a step <b>4</b> of providing the user with a content determined corresponding to the first brain state determined in the third step under an XR (Extended Reality) environment including at least one of AR (Augmented Reality), VR (Virtual Reality) and MR (Mixed Reality);</claim-text><claim-text>a step <b>5</b> in which the user performs a mission corresponding to the content;</claim-text><claim-text>a step <b>6</b> of extracting a second brain activation area from the plurality of brain areas with reference to the fNIRS data of the user following performing the mission; and</claim-text><claim-text>a step <b>7</b> of determining a second brain state of the user, based on the second brain activation area; an eighth step of determining information related to amelioration of the brain state of the user.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the step <b>4</b> comprises:</claim-text><claim-text>a step <b>4</b>-<b>1</b> of determining the first brain state as a base line;</claim-text><claim-text>a step <b>4</b>-<b>2</b> of determining the content for activating the first brain activation area, corresponding to the first brain state; and</claim-text><claim-text>a step <b>4</b>-<b>3</b> of providing the user with the content through a device which the user wears, allowing the user to experience the XR environment.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the step <b>5</b> comprises:</claim-text><claim-text>a step <b>5</b>-<b>1</b> in which the user performs the mission changeable depending on a play processing level of the content; and</claim-text><claim-text>a step <b>5</b>-<b>2</b> of providing information related to the brain of the user in real time while the user is in a state of performing the mission.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the content comprises a relaxation content for stabilizing emotion, a problem-solving content for controlling a stressed circumstance, an engagement content, a self-control content for controlling emotion and an impulse control content for controlling an impulsive behavior.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein<claim-text>the user is plural in number, and</claim-text><claim-text>the content includes a group therapy in which at least a part of the plurality of users performs a mission together.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein<claim-text>in the step <b>3</b>, a brain disease of the user is determined based on the first brain state, and</claim-text><claim-text>the brain disease includes dementia, MCI, Parkinson's disease, depression, cerebral stroke, Epilepsy, brain cancer and developmental disabilities.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein<claim-text>in the step <b>4</b>, the content is determined relating treatment of the determined brain disease,</claim-text><claim-text>the step <b>5</b> further comprises a step of extracting a third brain activation area from the plurality of brain areas with reference to fNIRS data of the user while performing the mission and determining a third brain state of the user based on the third brain activation area, and</claim-text><claim-text>the step <b>8</b> determines information related to amelioration of the brain state of the user using information of the first brain state together with information of the second brain state and information of the third brain state.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein<claim-text>prior to the step <b>1</b>,</claim-text><claim-text>the method further comprises a step <b>0</b>.<b>5</b> of collecting body information related to the user and medical imaging information related to the user, and</claim-text><claim-text>in the step <b>3</b>, the first brain state is determined by using information of the first brain activation area together with the body information related to the user and the medical imaging information related to the user.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein<claim-text>in the step <b>3</b>, the first brain state is determined by additionally using a correlation of activation information related to each of the plurality of brain areas, the body information and the medical imaging information, based on a pre-constructed database.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein<claim-text>the body information includes at least one of a degree of hearing loss of the user, gait pattern of the user, a stress level, an EGG change, a sleep state and attention change information, oxygen saturation change and the like, and</claim-text><claim-text>the medical imaging information includes at least one of an MRI imaging related to the user, a CT imaging related to the user and a fMRI imaging related to the user.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein<claim-text>following the step <b>8</b>,</claim-text><claim-text>the method further comprises a step <b>9</b> of providing the user with at least one of information of the first brain state, information of the second brain state and amelioration information of the brain state.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein<claim-text>the step <b>1</b> comprises a step <b>1</b>-<b>1</b> of emitting light to a scalp of the user through a plurality of light sources; and</claim-text><claim-text>a step <b>1</b>-<b>2</b> of detecting the fNIRS data from the scalp to which the light was emitted through a detecting portion corresponding to each of the plurality of light sources,</claim-text><claim-text>the fNIRS data represents a change of NIR light intensity transmitted through the scalp and is data from which artifact was removed through a filter, and</claim-text><claim-text>in the step <b>3</b>, at least one of a power spectrum method and a z-score analysis method is used in order to determine the first brain state.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein<claim-text>in the step <b>3</b>,</claim-text><claim-text>analysis data for an SMA (supplementary Motor Area) which controls the user's movement based on the first brain activation area is calculated to determine the first brain state based of the calculated analysis data.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The digital content-based method for providing therapeutics information according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein<claim-text>in the step <b>3</b>,</claim-text><claim-text>in the situation that a specific event happened to the user, it is determined that there is a limit in movement of the target object as an analysis data value for the SMA is increased with reference to a reference line, whereas it is determined that the target object is adept in movement as the analysis data value is decreased with reference to a reference line.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A digital content-based device for providing therapeutics information, wherein<claim-text>the device comprises:</claim-text><claim-text>a brain signal measurement portion which collects signals related to a user;</claim-text><claim-text>a brain signal stimulating portion which stimulates a brain of the user, in order for a signal collecting operation of the brain signal measurement portion; and</claim-text><claim-text>a diagnosing portion which determines a brain state of the user, based on the collected signals, wherein</claim-text><claim-text>the brain signal measurement portion obtains fNIRS (functional near-infrared spectroscopy) data based on stimulation by the brain signal stimulating portion and extracts a first brain activation area from a plurality of brain areas by using the obtained fNIRS data,</claim-text><claim-text>the diagnosing portion determines a first brain state of the user, based on the first brain activation area and further comprises a management portion which provides the user with a content determined corresponding to the determined first brain state, under an XR (Extended Reality) environment,</claim-text><claim-text>when the user performs a mission corresponding to the content, the brain signal measurement portion extracts a second brain activation area from the plurality of brain areas, with reference to fNIRS data of the user who performed the mission, and</claim-text><claim-text>the diagnosing portion determines information related to amelioration of a brain state of the user by using information of the first brain state and information of the second brain state.</claim-text></claim-text></claim></claims></us-patent-application>
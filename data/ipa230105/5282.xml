<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005283A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005283</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17577531</doc-number><date>20220118</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>CN</country><doc-number>202110733719.6</doc-number><date>20210630</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>18</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>19</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>262</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>18</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>19093</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>274</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">INFORMATION EXTRACTION METHOD AND APPARATUS, ELECTRONIC DEVICE AND READABLE STORAGE MEDIUM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</orgname><address><city>Beijing</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>LIU</last-name><first-name>Han</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>HU</last-name><first-name>Teng</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>CHEN</last-name><first-name>Yongfeng</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</orgname><role>03</role><address><city>Beijing</city><country>CN</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present disclosure provides an information extraction method and apparatus, an electronic device and a readable storage medium, and relates to the field of natural language processing technologies. The information extraction method includes: acquiring a to-be-extracted text; acquiring a sample set, the sample set including a plurality of sample texts and labels of sample characters in the plurality of sample texts; determining a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set; and extracting, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text. The present disclosure can simplify steps of information extraction, reduce costs of information extraction and improve flexibility and accuracy of information extraction.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="102.62mm" wi="124.71mm" file="US20230005283A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="124.54mm" wi="126.75mm" file="US20230005283A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="88.98mm" wi="120.14mm" file="US20230005283A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="142.92mm" wi="80.43mm" file="US20230005283A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="89.92mm" wi="113.45mm" file="US20230005283A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application claims the priority of Chinese Patent Application No. 202110733719.6, filed on Jun. 30, 2021, with the title of &#x201c;INFORMATION EXTRACTION METHOD AND APPARATUS, ELECTRONIC DEVICE AND READABLE STORAGE MEDIUM.&#x201d; The disclosure of the above application is incorporated herein by reference in its entirety.</p><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present disclosure relates to the field of computer technologies, and in particular, to the field of natural language processing technologies. An information extraction method and apparatus, an electronic device and a readable storage medium are provided.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">In daily document processing, it is common to extract information. For example, in contract processing, there is a need to know &#x201c;Party A&#x201d;, &#x201c;Party B&#x201d;, &#x201c;contract amount&#x201d; and other information in a document. In legal judgment processing, there is a need to know information such as &#x201c;defendant&#x201d;, &#x201c;prosecutor&#x201d; and &#x201c;suspected crime&#x201d; in a document.</p><p id="p-0005" num="0004">In the prior art, information is generally extracted by an information extraction model, but the information extraction model is effective only for corpus related to a training field, but cannot be accurately extract corpus outside the training field due to the lack of corresponding training data. In order to improve extraction capabilities of the information extraction model in different fields, the most intuitive way is to acquire a large amount of annotation data for training. However, the large amount of annotation data requires a lot of labor costs and is difficult to acquire.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0006" num="0005">According to a first aspect of the present disclosure, an information extraction method is provided, including: acquiring a to-be-extracted text; acquiring a sample set, the sample set including a plurality of sample texts and labels of sample characters in the plurality of sample texts; determining a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set; and extracting, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text.</p><p id="p-0007" num="0006">According to a second aspect of the present disclosure, there is provided an electronic device, including: at least one processor; and a memory communicatively connected with the at least one processor; wherein the memory stores instructions executable by the at least one processor, and the instructions are executed by the at least one processor to enable the at least one processor to perform an information extraction method, wherein the information extraction method includes: acquiring a to-be-extracted text; acquiring a sample set, the sample set including a plurality of sample texts and labels of sample characters in the plurality of sample texts; determining a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set; and extracting, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text.</p><p id="p-0008" num="0007">According to a third aspect of the present disclosure, there is provided a non-transitory computer readable storage medium with computer instructions stored thereon, wherein the computer instructions are used for causing a computer to perform an information extraction method, wherein the information extraction method includes: acquiring a to-be-extracted text; acquiring a sample set, the sample set comprising a plurality of sample texts and labels of sample characters in the plurality of sample texts; determining a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set; and extracting, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text.</p><p id="p-0009" num="0008">As can be seen from the above technical solutions, a prediction label of each character in a to-be-extracted text is determined through an acquired sample set, and then the character meeting a preset requirement is extracted from the to-be-extracted text as an extraction result of the to-be-extracted text, which does not require training of an information extraction model, simplifies steps of information extraction, reduces costs of information extraction, may not limit the field of the to-be-extracted text, and can extract information corresponding to any field name from the to-be-extracted text, thereby greatly improving flexibility and accuracy of information extraction.</p><p id="p-0010" num="0009">It should be understood that the content described in this part is neither intended to identify key or significant features of the embodiments of the present disclosure, nor intended to limit the scope of the present disclosure. Other features of the present disclosure will be made easier to understand through the following description.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0011" num="0010">The accompanying drawings are intended to provide a better understanding of the solutions and do not constitute a limitation on the present disclosure. In the drawings,</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram of a first embodiment according to the present disclosure;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram of a second embodiment according to the present disclosure;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram of a third embodiment according to the present disclosure; and</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram of an electronic device configured to perform an information extraction method according to embodiments of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0016" num="0015">Exemplary embodiments of the present disclosure are illustrated below with reference to the accompanying drawings, which include various details of the present disclosure to facilitate understanding and should be considered only as exemplary. Therefore, those of ordinary skill in the art should be aware that various changes and modifications can be made to the embodiments described herein without departing from the scope and spirit of the present disclosure. Similarly, for clarity and simplicity, descriptions of well-known functions and structures are omitted in the following description.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram of a first embodiment according to the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, an information extraction method according to this embodiment may specifically include the following steps.</p><p id="p-0018" num="0017">In S<b>101</b>, a to-be-extracted text is acquired.</p><p id="p-0019" num="0018">In S<b>102</b>, a sample set is acquired, the sample set including a plurality of sample texts and labels of sample characters in the plurality of sample texts.</p><p id="p-0020" num="0019">In S<b>103</b>, a prediction label of each character in the to-be-extracted text is determined according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set.</p><p id="p-0021" num="0020">In S<b>104</b>, a character meeting a preset requirement is extracted, according to the prediction label of each character, from the to-be-extracted text as an extraction result of the to-be-extracted text.</p><p id="p-0022" num="0021">In the information extraction method according to this embodiment, a prediction label of each character in a to-be-extracted text is determined through an acquired sample set, and then the character meeting a preset requirement is extracted from the to-be-extracted text as an extraction result of the to-be-extracted text, which does not require training of an information extraction model, simplifies steps of information extraction, reduces costs of information extraction, may not limit the field of the to-be-extracted text, and can extract information corresponding to any field name from the to-be-extracted text, thereby greatly improving flexibility and accuracy of information extraction.</p><p id="p-0023" num="0022">In this embodiment, the to-be-extracted text acquired by performing S<b>101</b> consists of a plurality of characters. The field of the to-be-extracted text may be any field.</p><p id="p-0024" num="0023">In this embodiment, after S<b>101</b> is performed to acquire the to-be-extracted text, a to-be-extracted field name may be further acquired. The to-be-extracted field name includes a text of at least one character. The extraction result extracted from the to-be-extracted text is a field value in the to-be-extracted text corresponding to the to-be-extracted field name.</p><p id="p-0025" num="0024">For example, if the to-be-extracted text is &#x201c;Party A Zhang San&#x201d; and the to-be-extracted field name is &#x201c;Party A&#x201d;, in this embodiment, a field value &#x201c;Zhang San&#x201d; corresponding to &#x201c;Party A&#x201d; is required to be extracted from the to-be-extracted text.</p><p id="p-0026" num="0025">In this embodiment, after S<b>101</b> is performed to acquire the to-be-extracted text, S<b>102</b> is performed to acquire a sample set, the sample set including a plurality of sample texts and labels of sample characters in the plurality of sample texts.</p><p id="p-0027" num="0026">In this embodiment, when S<b>102</b> is performed to acquire the sample set, a pre-constructed sample set or a real-time constructed sample set may be acquired. Preferably, in order to improve efficiency of information extraction, in this embodiment, the sample set acquired by performing S<b>102</b> is a pre-constructed sample set.</p><p id="p-0028" num="0027">It may be understood that the sample set acquired by performing S<b>102</b> includes a small number of sample texts, for example, a plurality of sample texts within a preset number. The preset number may be a small value. For example, in this embodiment, the sample set acquired includes only 5 sample texts.</p><p id="p-0029" num="0028">In this embodiment, in the sample set acquired by performing S<b>102</b>, labels of different sample characters correspond to to-be-extracted field names A label of a sample character is configured to indicate whether the sample character is the beginning of a field value, the middle of a field value, or a non-field value.</p><p id="p-0030" num="0029">In this embodiment, in the sample set acquired by performing S<b>102</b>, the label of each sample character may be one of B, I and O. The sample character with the label B indicates that the sample character is the beginning of a field value, the sample character with the label I indicates that the sample character is the middle of a field value, and the sample character with the label O indicates that the sample character is a non-field value.</p><p id="p-0031" num="0030">For example, if a sample text included in the sample set in this embodiment is &#x201c;Party A: Li Si&#x201d; and the to-be-extracted field name in this embodiment is &#x201c;Party A&#x201d;, labels of the sample character in the sample text may be &#x201c;O, O, O, B, I&#x201d; respectively.</p><p id="p-0032" num="0031">In this embodiment, after S<b>102</b> is performed to acquire the sample set, S<b>103</b> is performed to determine a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set.</p><p id="p-0033" num="0032">Specifically, in this embodiment, when S<b>103</b> is performed to determine a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set, the following optional implementation manner may be adopted: calculating, for each character in the to-be-extracted text, a similarity between the character and each sample character in the sample set according to the semantic feature vector of the character and the semantic feature vector of each sample character in the sample set; and taking the label of the sample character with the highest similarity to the character as the prediction label of the character.</p><p id="p-0034" num="0033">That is, in this embodiment, similarities between characters in the to-be-extracted text and sample characters in the sample set are calculated according to semantic feature vectors, so as to take the label of the sample character with the highest similarity to the character in the to-be-extracted text as the prediction label of the character in the to-be-extracted text, thereby improving the accuracy of the determined prediction label.</p><p id="p-0035" num="0034">Optionally, in this embodiment, when S<b>103</b> is performed to calculate similarities between characters and sample characters, the following calculation formula may be used:</p><p id="p-0036" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <mrow>   <mi>s</mi>   <mo>&#x2062;</mo>   <mi>i</mi>   <mo>&#x2062;</mo>   <msubsup>    <mi>m</mi>    <mi>j</mi>    <mi>i</mi>   </msubsup>  </mrow>  <mo>=</mo>  <mfrac>   <mrow>    <msubsup>     <mi>S</mi>     <mi>i</mi>     <mi>T</mi>    </msubsup>    <mo>&#xd7;</mo>    <msub>     <mi>V</mi>     <mi>j</mi>    </msub>   </mrow>   <mrow>    <msqrt>     <mrow>      <msubsup>       <mi>S</mi>       <mi>i</mi>       <mi>T</mi>      </msubsup>      <mo>&#xd7;</mo>      <msub>       <mi>S</mi>       <mi>i</mi>      </msub>     </mrow>    </msqrt>    <mo>&#xd7;</mo>    <msqrt>     <mrow>      <msubsup>       <mi>V</mi>       <mi>j</mi>       <mi>T</mi>      </msubsup>      <mo>&#xd7;</mo>      <msub>       <mi>V</mi>       <mi>j</mi>      </msub>     </mrow>    </msqrt>   </mrow>  </mfrac> </mrow></math></maths></p><p id="p-0037" num="0035">In the formula, sim<sub>j</sub><sup>i </sup>denotes a similarity between an i<sup>th </sup>character and a j<sup>th </sup>sample character; S<sub>i </sub>denotes the semantic feature vector of the i<sup>th </sup>character; T denotes transposition; and V<sub>j </sub>denotes the semantic feature vector of the j<sup>th </sup>sample character.</p><p id="p-0038" num="0036">In this embodiment, when S<b>103</b> is performed, the semantic feature vector of each character in the to-be-extracted text or the semantic feature vector of each sample character in the sample text may be generated directly according to the to-be-extracted text or the sample text.</p><p id="p-0039" num="0037">In order to improve accuracy of the generated semantic feature vector of each character in the to-be-extracted text, in this embodiment, when S<b>103</b> is performed to generate the semantic feature vector of each character in the to-be-extracted text, the following optional implementation manner may be adopted: acquiring a to-be-extracted field name; splicing the to-be-extracted text with the to-be-extracted field name to obtain token embedding, segment embedding and position embedding of each character in a splicing result, for example, inputting the splicing result to an ERNIE model to obtain three vectors outputted by the ERNIE model for each character; and generating the semantic feature vector of each character in the to-be-extracted text according to the token embedding, the segment embedding and the position embedding of each character, for example, adding the token embedding, the segment embedding and the position embedding of each character, inputting such vectors to the ERNIE model, and taking an output result of the ERNIE model as the semantic feature vector of each character.</p><p id="p-0040" num="0038">In order to improve accuracy of the generated semantic feature vector of each sample character in the sample text, in this embodiment, when S<b>103</b> is performed to generate the semantic feature vector of each sample character in the sample set, the following optional implementation manner may be adopted: acquiring a to-be-extracted field name; splicing, for each sample text in the sample set, the sample text with the to-be-extracted field name to obtain token embedding, segment embedding and position embedding of each sample character in a splicing result; and generating the semantic feature vector of each sample character in the sample text according to the token embedding, the segment embedding and the position embedding of each sample character. In this embodiment, the method for obtaining the three vectors and the semantic feature vector of each sample character in the sample text is similar to the method for obtaining the three vectors and the semantic feature vector of each character in the to-be-extracted text.</p><p id="p-0041" num="0039">In this embodiment, when S<b>103</b> is performed to splice the to-be-extracted text with the to-be-extracted field name or splice the sample text with the to-be-extracted field name, splicing may be performed according to a preset splicing rule. Preferably, the splicing rule in this embodiment is &#x201c;[CLS] to-be-extracted field name [SEP] to-be-extracted text or sample text [SEP]&#x201d;, wherein [CLS] and [SEP] are special characters.</p><p id="p-0042" num="0040">For example, if the to-be-extracted field name in this embodiment is &#x201c;Party A&#x201d;, the sample text is &#x201c;Party A: Li Si&#x201d; and the to-be-extracted text is &#x201c;Party A: Zhang San&#x201d;, a splicing result acquired may be &#x201c;[CLS] Party A [SEP] Party A: Li Si [SEP]&#x201d; and &#x201c;[CLS] Party A [SEP] Party A: Zhang San[SEP]&#x201d;.</p><p id="p-0043" num="0041">In this embodiment, after S<b>103</b> is performed to determine the prediction label of each character in the to-be-extracted text, S<b>104</b> is performed to extract, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text. The preset requirement in this embodiment may be one of a preset label requirement and a preset label sequence requirement and correspond to the to-be-extracted field name.</p><p id="p-0044" num="0042">In this embodiment, when S<b>104</b> is performed to extract, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text, characters in the to-be-extracted text that meet a preset label requirement may be sequentially determined in a character order, and then the determined characters are extracted to form the extraction result.</p><p id="p-0045" num="0043">In this embodiment, when S<b>104</b> is performed to extract, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text, the following optional implementation manner may be adopted: generating a prediction label sequence of the to-be-extracted text according to the prediction label of each character; determining a label sequence in the prediction label sequence meeting a preset label sequence requirement; and extracting, from the to-be-extracted text, a plurality of characters corresponding to the determined label sequence as the extraction result.</p><p id="p-0046" num="0044">For example, if the to-be-extracted field name in this embodiment is &#x201c;Party A&#x201d;, the to-be-extracted text is &#x201c;Party A Zhang San&#x201d;, a generated prediction label sequence is &#x201c;OOOBI&#x201d; and a label sequence requirement corresponding to the to-be-extracted field name &#x201c;Party A&#x201d; is &#x201c;BI&#x201d;, &#x201c;Zhang San&#x201d; corresponding to the determined label sequence &#x201c;BI&#x201d; is extracted from the to-be-extracted text as an extraction result.</p><p id="p-0047" num="0045">That is, in this embodiment, in the manner of generating a prediction label sequence, a field value in the to-be-extracted text corresponding to the to-be-extracted field name can be quickly determined, and then the determined field value is extracted as an extraction result, thereby further improving the efficiency of information extraction.</p><p id="p-0048" num="0046"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram of a second embodiment according to the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a flowchart of information extraction is shown in this embodiment. After a to-be-extracted text, a to-be-extracted field name and a sample set are acquired, feature extraction is performed according to the to-be-extracted field name to obtain a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set respectively. Similarities are calculated according to the obtained semantic feature vectors, so as to determine a prediction label of each character in the to-be-extracted text. Output and decoding are performed according to the prediction label of each character, and then a decoding result is taken as an extraction result of the to-be-extracted text.</p><p id="p-0049" num="0047"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram of a third embodiment according to the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, an information extraction apparatus <b>300</b> according to this embodiment may include: a first acquisition unit <b>301</b> configured to acquire a to-be-extracted text; a second acquisition unit <b>302</b> configured to acquire a sample set, the sample set including a plurality of sample texts and labels of sample characters in the plurality of sample texts; a processing unit <b>303</b> configured to determine a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set; and an extraction unit <b>304</b> configured to extract, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text.</p><p id="p-0050" num="0048">The to-be-extracted text acquired by the first acquisition unit <b>301</b> consists of a plurality of characters. The field of the to-be-extracted text may be any field.</p><p id="p-0051" num="0049">After acquiring the to-be-extracted text, the first acquisition unit <b>301</b> may further acquire a to-be-extracted field name The to-be-extracted field name includes a text of at least one character. The extraction result extracted from the to-be-extracted text is a field value in the to-be-extracted text corresponding to the to-be-extracted field name.</p><p id="p-0052" num="0050">In this embodiment, after the first acquisition unit <b>301</b> acquires the to-be-extracted text, the second acquisition unit <b>302</b> acquires a sample set, the sample set including a plurality of sample texts and labels of sample characters in the plurality of sample texts.</p><p id="p-0053" num="0051">When acquiring the sample set, the second acquisition unit <b>302</b> may acquire a pre-constructed sample set or a real-time constructed sample set. Preferably, in order to improve efficiency of information extraction, in this embodiment, the sample set acquired by the second acquisition unit <b>302</b> is a pre-constructed sample set.</p><p id="p-0054" num="0052">The sample set acquired by the second acquisition unit <b>302</b> includes a small number of sample texts, for example, a plurality of sample texts within a preset number. The preset number may be a small value. For example, the sample set acquired by the second acquisition unit <b>302</b> includes only 5 sample texts.</p><p id="p-0055" num="0053">In the sample set acquired by the second acquisition unit <b>302</b>, labels of different sample characters correspond to to-be-extracted field names. A label of a sample character is configured to indicate whether the sample character is the beginning of a field value, the middle of a field value, or a non-field value.</p><p id="p-0056" num="0054">In the sample set acquired by the second acquisition unit <b>302</b>, the label of each sample character may be one of B, I and O. The sample character with the label B indicates that the sample character is the beginning of a field value, the sample character with the label I indicates that the sample character is the middle of a field value, and the sample character with the label O indicates that the sample character is a non-field value.</p><p id="p-0057" num="0055">In this embodiment, after the second acquisition unit <b>302</b> acquires the sample set, the processing unit <b>303</b> determines a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set.</p><p id="p-0058" num="0056">Specifically, when the processing unit <b>303</b> determines a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set, the following optional implementation manner may be adopted: calculating, for each character in the to-be-extracted text, a similarity between the character and each sample character in the sample set according to the semantic feature vector of the character and the semantic feature vector of each sample character in the sample set; and taking the label of the sample character with the highest similarity to the character as the prediction label of the character.</p><p id="p-0059" num="0057">That is, in this embodiment, similarities between characters in the to-be-extracted text and sample characters in the sample set are calculated according to semantic feature vectors, so as to take the label of the sample character with the highest similarity to the character in the to-be-extracted text as the prediction label of the character in the to-be-extracted text, thereby improving the accuracy of the determined prediction label.</p><p id="p-0060" num="0058">The processing unit <b>303</b> may generate the semantic feature vector of each character in the to-be-extracted text or the semantic feature vector of each sample character in the sample text directly according to the to-be-extracted text or the sample text.</p><p id="p-0061" num="0059">In order to improve accuracy of the generated semantic feature vector of each character in the to-be-extracted text, when the processing unit <b>303</b> generates the semantic feature vector of each character in the to-be-extracted text, the following optional implementation manner may be adopted: acquiring a to-be-extracted field name; splicing the to-be-extracted text with the to-be-extracted field name to obtain token embedding, segment embedding and position embedding of each character in a splicing result; and generating the semantic feature vector of each character in the to-be-extracted text according to the token embedding, the segment embedding and the position embedding of each character.</p><p id="p-0062" num="0060">In order to improve accuracy of the generated semantic feature vector of each sample character in the sample text, in this embodiment, when the processing unit <b>303</b> generates the semantic feature vector of each sample character in the sample set, the following optional implementation manner may be adopted: acquiring a to-be-extracted field name; splicing, for each sample text in the sample set, the sample text with the to-be-extracted field name to obtain token embedding, segment embedding and position embedding of each sample character in a splicing result; and generating the semantic feature vector of each sample character in the sample text according to the token embedding, the segment embedding and the position embedding of each sample character. The method for obtaining, by the processing unit <b>303</b>, the three vectors and the semantic feature vector of each sample character in the sample text is similar to the method for obtaining the three vectors and the semantic feature vector of each character in the to-be-extracted text.</p><p id="p-0063" num="0061">When the processing unit <b>303</b> splices the to-be-extracted text with the to-be-extracted field name or splices the sample text with the to-be-extracted field name, splicing may be performed according to a preset splicing rule. Preferably, the splicing rule in the processing unit <b>303</b> is &#x201c;[CLS] to-be-extracted field name [SEP] to-be-extracted text or sample text [SEP]&#x201d;, wherein [CLS] and [SEP] are special characters.</p><p id="p-0064" num="0062">In this embodiment, after the processing unit <b>303</b> determines the prediction label of each character in the to-be-extracted text, the extraction unit <b>304</b> extracts, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text. The preset requirement in the extraction unit <b>304</b> may be one of a preset label requirement and a preset label sequence requirement and correspond to the to-be-extracted field name.</p><p id="p-0065" num="0063">When extracting, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text, the extraction unit <b>304</b> may sequentially determine, in a character order, characters in the to-be-extracted text that meet a preset label requirement, and then extract the determined characters to form the extraction result.</p><p id="p-0066" num="0064">In addition, when the extraction unit <b>304</b> extracts, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text, the following optional implementation manner may be adopted: generating a prediction label sequence of the to-be-extracted text according to the prediction label of each character; determining a label sequence in the prediction label sequence meeting a preset label sequence requirement; and extracting, from the to-be-extracted text, a plurality of characters corresponding to the determined label sequence as the extraction result.</p><p id="p-0067" num="0065">That is, in this embodiment, in the manner of generating a prediction label sequence, a field value in the to-be-extracted text corresponding to the to-be-extracted field name can be quickly determined, and then the determined field value is extracted as an extraction result, thereby further improving the efficiency of information extraction.</p><p id="p-0068" num="0066">Acquisition, storage and application of users' personal information involved in the technical solutions of the present disclosure comply with relevant laws and regulations, and do not violate public order and moral.</p><p id="p-0069" num="0067">According to embodiments of the present disclosure, the present disclosure further provides an electronic device, a readable storage medium and a computer program product.</p><p id="p-0070" num="0068"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram of an electronic device configured to perform an information extraction method according to embodiments of the present disclosure. The electronic device is intended to represent various forms of digital computers, such as laptops, desktops, workbenches, personal digital assistants, servers, blade servers, mainframe computers and other suitable computing devices. The electronic device may further represent various forms of mobile devices, such as personal digital assistants, cellular phones, smart phones, wearable devices and other similar computing devices. The components, their connections and relationships, and their functions shown herein are examples only, and are not intended to limit the implementation of the present disclosure as described and/or required herein.</p><p id="p-0071" num="0069">As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the device <b>400</b> includes a computing unit <b>401</b>, which may perform various suitable actions and processing according to a computer program stored in a read-only memory (ROM) <b>402</b> or a computer program loaded from a storage unit <b>408</b> into a random access memory (RAM) <b>403</b>. The RAM <b>403</b> may also store various programs and data required to operate the device <b>400</b>. The computing unit <b>401</b>, the ROM <b>402</b> and the RAM <b>403</b> are connected to one another by a bus <b>404</b>. An input/output (I/O) interface <b>405</b> may also be connected to the bus <b>404</b>.</p><p id="p-0072" num="0070">A plurality of components in the device <b>400</b> are connected to the I/O interface <b>405</b>, including an input unit <b>406</b>, such as a keyboard and a mouse; an output unit <b>407</b>, such as various displays and speakers; a storage unit <b>408</b>, such as disks and discs; and a communication unit <b>409</b>, such as a network card, a modem and a wireless communication transceiver. The communication unit <b>409</b> allows the device <b>400</b> to exchange information/data with other devices over computer networks such as the Internet and/or various telecommunications networks.</p><p id="p-0073" num="0071">The computing unit <b>401</b> may be a variety of general-purpose and/or special-purpose processing components with processing and computing capabilities. Some examples of the computing unit <b>401</b> include, but are not limited to, a central processing unit (CPU), a graphics processing unit (GPU), various artificial intelligence (AI) computing chips, various computing units that run machine learning model algorithms, a digital signal processor (DSP), and any appropriate processor, controller or microcontroller, etc. The computing unit <b>401</b> performs the methods and processing described above, for example, the information extraction method. For example, in some embodiments, the information extraction method may be implemented as a computer software program that is tangibly embodied in a machine-readable medium, such as the storage unit <b>408</b>.</p><p id="p-0074" num="0072">In some embodiments, part or all of a computer program may be loaded and/or installed on the device <b>400</b> via the ROM <b>402</b> and/or the communication unit <b>409</b>. One or more steps of the information extraction method described above may be performed when the computer program is loaded into the RAM <b>403</b> and executed by the computing unit <b>401</b>. Alternatively, in other embodiments, the computing unit <b>401</b> may be configured to perform the information extraction method described in the present disclosure by any other appropriate means (for example, by means of firmware).</p><p id="p-0075" num="0073">Various implementations of the systems and technologies disclosed herein can be realized in a digital electronic circuit system, an integrated circuit system, a field programmable gate array (FPGA), an application-specific integrated circuit (ASIC), an application-specific standard product (ASSP), a system on chip (SOC), a load programmable logic device (CPLD), computer hardware, firmware, software, and/or combinations thereof. Such implementations may include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which can be special or general purpose, configured to receive data and instructions from a storage system, at least one input apparatus, and at least one output apparatus, and to transmit data and instructions to the storage system, the at least one input apparatus, and the at least one output apparatus.</p><p id="p-0076" num="0074">Program codes configured to implement the methods in the present disclosure may be written in any combination of one or more programming languages. Such program codes may be supplied to a processor or controller of a general-purpose computer, a special-purpose computer, or another programmable data processing apparatus to enable the function/operation specified in the flowchart and/or block diagram to be implemented when the program codes are executed by the processor or controller. The program codes may be executed entirely on a machine, partially on a machine, partially on a machine and partially on a remote machine as a stand-alone package, or entirely on a remote machine or a server.</p><p id="p-0077" num="0075">In the context of the present disclosure, machine-readable media may be tangible media which may include or store programs for use by or in conjunction with an instruction execution system, apparatus or device. The machine-readable media may be machine-readable signal media or machine-readable storage media. The machine-readable media may include, but are not limited to, electronic, magnetic, optical, electromagnetic, infrared, or semiconductor systems, apparatuses or devices, or any suitable combinations thereof. More specific examples of machine-readable storage media may include electrical connections based on one or more wires, a portable computer disk, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read only memory (EPROM or flash memory), an optical fiber, a compact disk read only memory (CD-ROM), an optical storage device, a magnetic storage device, or any suitable combination thereof.</p><p id="p-0078" num="0076">To provide interaction with a user, the systems and technologies described here can be implemented on a computer. The computer has: a display apparatus (e.g., a cathode-ray tube (CRT) or a liquid crystal display (LCD) monitor) for displaying information to the user; and a keyboard and a pointing apparatus (e.g., a mouse or trackball) through which the user may provide input for the computer. Other kinds of apparatuses may also be configured to provide interaction with the user. For example, a feedback provided for the user may be any form of sensory feedback (e.g., visual, auditory, or tactile feedback); and input from the user may be received in any form (including sound input, voice input, or tactile input).</p><p id="p-0079" num="0077">The systems and technologies described herein can be implemented in a computing system including background components (e.g., as a data server), or a computing system including middleware components (e.g., an application server), or a computing system including front-end components (e.g., a user computer with a graphical user interface or web browser through which the user can interact with the implementation mode of the systems and technologies described here), or a computing system including any combination of such background components, middleware components or front-end components. The components of the system can be connected to each other through any form or medium of digital data communication (e.g., a communication network). Examples of the communication network include: a local area network (LAN), a wide area network (WAN) and the Internet.</p><p id="p-0080" num="0078">The computer system may include a client and a server. The client and the server are generally far away from each other and generally interact via the communication network. A relationship between the client and the server is generated through computer programs that run on a corresponding computer and have a client-server relationship with each other. The server may be a cloud server, also known as a cloud computing server or cloud host, which is a host product in the cloud computing service system to solve the problems of difficult management and weak business scalability in the traditional physical host and a virtual private server (VPS). The server may also be a distributed system server, or a server combined with blockchain.</p><p id="p-0081" num="0079">It should be understood that the steps can be reordered, added, or deleted using the various forms of processes shown above. For example, the steps described in the present disclosure may be executed in parallel or sequentially or in different sequences, provided that desired results of the technical solutions disclosed in the present disclosure are achieved, which is not limited herein.</p><p id="p-0082" num="0080">The above specific implementations do not limit the extent of protection of the present disclosure. Those skilled in the art should understand that various modifications, combinations, sub-combinations, and replacements can be made according to design requirements and other factors. Any modifications, equivalent substitutions and improvements made within the spirit and principle of the present disclosure all should be included in the extent of protection of the present disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230005283A1-20230105-M00001.NB"><img id="EMI-M00001" he="8.13mm" wi="76.20mm" file="US20230005283A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An information extraction method, comprising:<claim-text>acquiring a to-be-extracted text;</claim-text><claim-text>acquiring a sample set, the sample set comprising a plurality of sample texts and labels of sample characters in the plurality of sample texts;</claim-text><claim-text>determining a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set; and</claim-text><claim-text>extracting, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of acquiring a sample set comprises: acquiring a pre-constructed sample set.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of determining a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set comprises:<claim-text>calculating, for each character in the to-be-extracted text, a similarity between the character and each sample character in the sample set according to the semantic feature vector of the character and the semantic feature vector of each sample character in the sample set; and</claim-text><claim-text>taking the label of the sample character with the highest similarity to the character as the prediction label of the character.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the semantic feature vector of each character in the to-be-extracted text comprises:<claim-text>acquiring a to-be-extracted field name;</claim-text><claim-text>splicing the to-be-extracted text with the to-be-extracted field name to obtain token embedding, segment embedding and position embedding of each character in a splicing result; and</claim-text><claim-text>generating the semantic feature vector of each character in the to-be-extracted text according to the token embedding, the segment embedding and the position embedding of each character.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the semantic feature vector of each sample character in the sample set comprises:<claim-text>acquiring a to-be-extracted field name;</claim-text><claim-text>splicing, for each sample text in the sample set, the sample text with the to-be-extracted field name to obtain token embedding, segment embedding and position embedding of each sample character in a splicing result; and</claim-text><claim-text>generating the semantic feature vector of each sample character in the sample text according to the token embedding, the segment embedding and the position embedding of each sample character.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of extracting, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text comprises:<claim-text>generating a prediction label sequence of the to-be-extracted text according to the prediction label of each character;</claim-text><claim-text>determining a label sequence in the prediction label sequence meeting a preset label sequence requirement; and</claim-text><claim-text>extracting, from the to-be-extracted text, a plurality of characters corresponding to the determined label sequence as the extraction result of the to-be-extracted text.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. An electronic device, comprising:<claim-text>at least one processor; and</claim-text><claim-text>a memory communicatively connected with the at least one processor;</claim-text><claim-text>wherein the memory stores instructions executable by the at least one processor, and the instructions are executed by the at least one processor to enable the at least one processor to perform an information extraction method, wherein the information extraction method comprises:</claim-text><claim-text>acquiring a to-be-extracted text;</claim-text><claim-text>acquiring a sample set, the sample set comprising a plurality of sample texts and labels of sample characters in the plurality of sample texts;</claim-text><claim-text>determining a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set; and</claim-text><claim-text>extracting, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The electronic device according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the step of acquiring a sample set comprises: acquiring a pre-constructed sample set.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The electronic device according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the step of determining a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set comprises:<claim-text>calculating, for each character in the to-be-extracted text, a similarity between the character and each sample character in the sample set according to the semantic feature vector of the character and the semantic feature vector of each sample character in the sample set; and</claim-text><claim-text>taking the label of the sample character with the highest similarity to the character as the prediction label of the character.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The electronic device according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein generating the semantic feature vector of each character in the to-be-extracted text comprises:<claim-text>acquiring a to-be-extracted field name;</claim-text><claim-text>splicing the to-be-extracted text with the to-be-extracted field name to obtain token embedding, segment embedding and position embedding of each character in a splicing result; and</claim-text><claim-text>generating the semantic feature vector of each character in the to-be-extracted text according to the token embedding, the segment embedding and the position embedding of each character.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The electronic device according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein generating the semantic feature vector of each sample character in the sample set comprises:<claim-text>acquiring a to-be-extracted field name;</claim-text><claim-text>splicing, for each sample text in the sample set, the sample text with the to-be-extracted field name to obtain token embedding, segment embedding and position embedding of each sample character in a splicing result; and</claim-text><claim-text>generating the semantic feature vector of each sample character in the sample text according to the token embedding, the segment embedding and the position embedding of each sample character.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The electronic device according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the step of extracting, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text comprises:<claim-text>generating a prediction label sequence of the to-be-extracted text according to the prediction label of each character;</claim-text><claim-text>determining a label sequence in the prediction label sequence meeting a preset label sequence requirement; and</claim-text><claim-text>extracting, from the to-be-extracted text, a plurality of characters corresponding to the determined label sequence as the extraction result of the to-be-extracted text.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A non-transitory computer readable storage medium with computer instructions stored thereon, wherein the computer instructions are used for causing a computer to perform an information extraction method, wherein the information extraction method comprises:<claim-text>acquiring a to-be-extracted text;</claim-text><claim-text>acquiring a sample set, the sample set comprising a plurality of sample texts and labels of sample characters in the plurality of sample texts;</claim-text><claim-text>determining a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set; and</claim-text><claim-text>extracting, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The non-transitory computer readable storage medium according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the step of acquiring a sample set comprises: acquiring a pre-constructed sample set.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The non-transitory computer readable storage medium according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the step of determining a prediction label of each character in the to-be-extracted text according to a semantic feature vector of each character in the to-be-extracted text and a semantic feature vector of each sample character in the sample set comprises:<claim-text>calculating, for each character in the to-be-extracted text, a similarity between the character and each sample character in the sample set according to the semantic feature vector of the character and the semantic feature vector of each sample character in the sample set; and</claim-text><claim-text>taking the label of the sample character with the highest similarity to the character as the prediction label of the character.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The non-transitory computer readable storage medium according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein generating the semantic feature vector of each character in the to-be-extracted text comprises:<claim-text>acquiring a to-be-extracted field name;</claim-text><claim-text>splicing the to-be-extracted text with the to-be-extracted field name to obtain token embedding, segment embedding and position embedding of each character in a splicing result; and</claim-text><claim-text>generating the semantic feature vector of each character in the to-be-extracted text according to the token embedding, the segment embedding and the position embedding of each character.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer readable storage medium according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein generating the semantic feature vector of each sample character in the sample set comprises:<claim-text>acquiring a to-be-extracted field name;</claim-text><claim-text>splicing, for each sample text in the sample set, the sample text with the to-be-extracted field name to obtain token embedding, segment embedding and position embedding of each sample character in a splicing result; and</claim-text><claim-text>generating the semantic feature vector of each sample character in the sample text according to the token embedding, the segment embedding and the position embedding of each sample character.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer readable storage medium according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the step of extracting, according to the prediction label of each character, a character meeting a preset requirement from the to-be-extracted text as an extraction result of the to-be-extracted text comprises:<claim-text>generating a prediction label sequence of the to-be-extracted text according to the prediction label of each character;</claim-text><claim-text>determining a label sequence in the prediction label sequence meeting a preset label sequence requirement; and</claim-text><claim-text>extracting, from the to-be-extracted text, a plurality of characters corresponding to the determined label sequence as the extraction result of the to-be-extracted text.</claim-text></claim-text></claim></claims></us-patent-application>
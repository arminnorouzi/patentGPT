<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004478A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004478</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17366144</doc-number><date>20210702</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>36</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>32</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>34</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>07</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>3636</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>323</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>3466</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>0787</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>2201</main-group><subgroup>865</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEMS AND METHODS OF CONTINUOUS STACK TRACE COLLECTION TO MONITOR AN APPLICATION ON A SERVER AND RESOLVE AN APPLICATION INCIDENT</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>salesforce.com, inc.</orgname><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Susman</last-name><first-name>Ben</first-name><address><city>Austin</city><state>TX</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Bayer</last-name><first-name>Christian</first-name><address><city>Cambridge</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Babovich</last-name><first-name>Sergei</first-name><address><city>Burlington</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Ranade</last-name><first-name>Sanyogita Sudhir</first-name><address><city>Woburn</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Lodha</last-name><first-name>Saurabh</first-name><address><city>Burlington</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>Cassidy</last-name><first-name>Timothy</first-name><address><city>Burlington</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="06" designation="us-only"><addressbook><last-name>Muralidhar</last-name><first-name>Krishnamurthy</first-name><address><city>Burlington</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="07" designation="us-only"><addressbook><last-name>Forrest</last-name><first-name>Derek</first-name><address><city>Burlington</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="08" designation="us-only"><addressbook><last-name>Xia</last-name><first-name>Bing</first-name><address><city>Burlington</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="09" designation="us-only"><addressbook><last-name>Fairfax</last-name><first-name>Kevin</first-name><address><city>Burlington</city><state>MA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Systems and methods are provided for performing, at a server, a stack trace of an application at a predetermined interval to generate a plurality of stack traces, where each stack trace of the plurality of stack traces is from a different point in time based on the predetermined interval. The stack trace is performed when the application is operating normally and when the application has had a failure. The plurality of stack traces stored are indexed by timestamp. The server may determine a state of the application based on at least one of the plurality of stack traces. The server may condense data for at least one of the plurality of stack traces that are indexed using predetermined failure scenarios for the application. The server may generate a report based on the condensed data and the state of the application, and may transmit the report for display.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="215.48mm" wi="121.16mm" file="US20230004478A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="223.69mm" wi="123.19mm" file="US20230004478A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="101.43mm" wi="123.19mm" file="US20230004478A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="123.19mm" wi="87.29mm" orientation="landscape" file="US20230004478A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="226.06mm" wi="172.30mm" orientation="landscape" file="US20230004478A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="214.97mm" wi="77.47mm" orientation="landscape" file="US20230004478A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="220.13mm" wi="163.75mm" orientation="landscape" file="US20230004478A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="219.79mm" wi="135.30mm" orientation="landscape" file="US20230004478A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">Typical stack tracing of an application that is executed by a server for the benefit of a set of users is performed after a time of failure. The stack tracing is performed in order to determine what caused the failure, and to address the point of failure. Besides stack tracing, applications can be monitored by Application Performance Managers (APMs). Such APMs typically monitor a set of performance metrics. Although the APMs collect performance data for the application, they are typically processing intensive, which generally inhibits the performance of the application that is relied upon by the users.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0002" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0003" num="0002">The accompanying drawings, which are included to provide a further understanding of the disclosed subject matter, are incorporated in and constitute a part of this specification. The drawings also illustrate implementations of the disclosed subject matter and together with the detailed description explain the principles of implementations of the disclosed subject matter. No attempt is made to show structural details in more detail than can be necessary for a fundamental understanding of the disclosed subject matter and various ways in which it can be practiced.</p><p id="p-0004" num="0003"><figref idref="DRAWINGS">FIGS. <b>1</b>-<b>3</b></figref> show example methods of performing continuous stack trace collection to monitor an application and resolve application incidents according to implementations of the disclosed subject matter.</p><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIGS. <b>4</b>A-<b>4</b>B</figref> show an example trace report according to implementations of the disclosed subject matter.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows an example system according to an implementation of the disclosed subject matter.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an example hardware system that may implement the system shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> according to an implementation of the disclosed subject matter.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0003" level="1">DETAILED DESCRIPTION</heading><p id="p-0008" num="0007">Various aspects or features of this disclosure are described with reference to the drawings, wherein like reference numerals are used to refer to like elements throughout. In this specification, numerous details are set forth in order to provide a thorough understanding of this disclosure. It should be understood, however, that certain aspects of disclosure can be practiced without these specific details, or with other methods, components, materials, or the like. In other instances, well-known structures and devices are shown in block diagram form to facilitate describing the subject disclosure.</p><p id="p-0009" num="0008">Implementations of the disclosed subject matter perform stack traces of an application (e.g., a Java&#x2122; application) being executed by a server, both at time of failure and during normal operation. The stack traces may provide a status of an internal state of the application being executed by the server. Stack traces may be captured from the application at a predetermined interval (e.g., every minute) and may be indexed by timestamp and stored for analysis. The stored and indexed stack traces may be analyzed based on a selected time frame and target instance. A report may be generated that condenses the data of a plurality of individual stack traces to provide a status of the application for the selected time frame and target instance of the application. The generated report may include analysis of the stack traces based on predetermined failure scenarios to reduce manual analysis of the plurality of stack traces. Implementations of the disclosed subject matter may perform stack traces across clusters of application servers, and may generate a report which aggregates and/or condenses the cluster data. The generated data-reduced reports may be used to provide a faster time to resolve an incident with an application server and/or cluster of application servers.</p><p id="p-0010" num="0009">Implementations of the disclosed subject matter improve upon current application performance management systems (APMs) that are typically used at a time of application failure, rather than continuously capturing a stack trace from an application at intervals. The APMs generate more data than the stack traces of the disclosed subject matter, which are captured at predetermined intervals. Moreover, stack traces generated by the implementations of the inventive concept are not as processing intensive as APMs, as the stack traces are generated from within the application server. That is, implementations of the disclosed subject matter may perform periodic stack traces that use less processing power of the server than APM systems, while having a high sampling frequency (i.e., many stack traces may be produced). In contrast, APM systems may only perform stack tracing when there is a problem with the application server, and thus may have a low sampling frequency. Moreover, implementations of the disclosed subject matter differ from typical stack tracing, which may be performed after a time of failure, rather than capturing stack traces at predetermined intervals during both normal operation and when the application is experiencing an error as with the disclosed subject matter.</p><p id="p-0011" num="0010">Current APMs typically monitor two sets of performance metrics. The first set of performance metrics relates to the performance experienced by end users of the application (e.g., average response times under peak load), and the second set of performance metrics measures the computational resources used by the application for the load, indicating whether there is adequate capacity to support the load, as well as possible locations of a performance bottleneck. Measurement of these quantities establishes an empirical performance baseline for the application. The baseline can then be used to detect changes in performance. Changes in performance can be correlated with external events and subsequently used to predict future changes in application performance. Although the APMs collect performance data for the application, they typically do not perform stack traces during normal operation, as well as at the time of failure, as is done in the present disclosed subject matter. Some APMs are used to perform stack traces at a time of application failure, rather than continuously capturing a stack trace from an application at intervals. Also, typical APMs generate more data than the traces captured at predetermined intervals, as in the disclosed subject matter.</p><p id="p-0012" num="0011">For example, an on-line shop application and/or other commerce application may be executed on a Java&#x2122; application server (i.e., where one or more servers may execute an application to serve application data to client devices). The on-line shop application may include a plurality of instances (e.g., tens of instances, hundreds of instances, thousands of instances, or the like) that may use an identical code base, but which may be customized to include custom code. Determining the internal state of an application server when it fails is typically difficult, and usually requires attaching a debugger to the instance. Because each application server instance may run identical code, their encountered failure scenarios may be similar, and may manifest themselves through similar stack traces (e.g., Java&#x2122; stack traces).</p><p id="p-0013" num="0012">Implementations of the disclosed subject matter may determine a status of an application server both at time of failure, as well as during normal operation. Stack traces (e.g., Java&#x2122; stack traces) of applications may be performed at predetermined intervals (e.g., every minute, every five minutes, every ten minutes, every hour, or the like) and may index the traces by timestamp and store them for analysis. When performing an analysis of the stored stack traces, a time frame and/or a target instance of the application (e.g., when a plurality of instances may be executed by one or more servers) for which stack traces are to be analyzed may be selected. A report may be generated that condenses the data of individual stack traces into one or more failure scenarios.</p><p id="p-0014" num="0013">The stack trace data may be compressed, and may be transferred to a storage device for storage at predetermined periodic intervals (e.g., every minute, every five minutes, every ten minutes, or the like). The stack trace data may be text data. Portions of the text may be repeated, where the server may compress the repeated portions. In some implementations, the stack trace data may be deleted from the storage device after a predetermined period of time (e.g., five days, seven days, two weeks, or the like). By performing stack traces and predetermined intervals and storing the stack traces in a storage device, baseline comparison data may be generated that may be used to determine the operational state and/or changing operational state of the server executing the application.</p><p id="p-0015" num="0014">The stored data may be used to identify failure scenarios common across all application servers. For example, common failure scenarios may be with communication failures between the server and a third-party system over a communications network. In another example, the failure related to a failed communication between the server and a database. Other failure examples may include when the application is stuck in an endless loop, when the application is executing long-running requests, or the like. Another failure example may be when the server is executing custom code. The failure scenarios may be generalized for one or more applications that are executed by the server.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. <b>1</b>-<b>3</b></figref> show an example method <b>100</b> of performing continuous stack trace collection to monitor an application and resolve application incidents according to implementations of the disclosed subject matter.</p><p id="p-0017" num="0016">As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, method <b>100</b> may include executing an application at a server at operation <b>110</b>. The server may be part of data center <b>202</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, where application server <b>204</b> may execute an application. The server of the data center <b>202</b> may be server <b>700</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, as discussed in detail below. The server may be one or more application servers that may execute one or more instances of the application for one or more user devices, such as computer <b>500</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. The server may have one or more processors (e.g., processor <b>705</b>, <b>805</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>) to execute the one or more application instances.</p><p id="p-0018" num="0017">At operation <b>120</b>, the server may perform a stack trace of the application at a predetermined interval to generate a plurality of stack traces. For example, the predetermined interval may be every minute, every five minutes, every ten minutes, or the like. Each stack trace of the plurality of stack traces may be from a different point in time based on the predetermined interval. The stack trace at operation <b>120</b> may be performed when the application is operating normally and/or when the application has had a failure. In one example, a communicative connection may be established between the application server <b>204</b> and a trace-bot <b>220</b> of the Kubernetes instance <b>218</b> as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. The application server <b>204</b> may generate stack traces, and may transmit them to the trace-bot <b>220</b>. The trace-bot <b>220</b> may collect the traces of the application. That is, the traces of the application may be pushed to the trace-bot <b>220</b>, which may collect the traces. In another example, stack traces (e.g., as part of operation <b>120</b> described above) for an application being executed on the server <b>700</b> and/or <b>800</b> as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> may be pushed to the trace-bot <b>220</b> for collection.</p><p id="p-0019" num="0018">At operation <b>130</b>, the server may store the plurality of stack traces in a storage device that may be communicatively coupled to the server. For example, stack traces generated by the application server <b>204</b> may be pushed and/or transmitted to trace-bot <b>220</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, and the traces that are collected by the trace-bot <b>220</b> may be stored in database <b>222</b>. In another example, the stack traces may be stored in storage device <b>710</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> and/or at database <b>900</b>, both of which may be communicatively coupled to server <b>700</b>. The server may index the stored plurality of stack traces by timestamp at the storage device at operation <b>140</b>. The indexed data may be stored in database <b>222</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, storage <b>710</b>, <b>810</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, and/or database <b>900</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0020" num="0019">At operation <b>150</b>, the server may determine a state of the application based on a portion of the plurality of stack traces (e.g., three stack traces, 10 stack traces, or the like). The server may determine whether the application is operating normally, or whether there is an error, such as a communications error, an endless loop of the application, a long-running request, and/or execution of custom code that has an error, or the like. For example, threads in the application server may be expected to run a maximum of a few hundred milliseconds. When such threads have not finished after a predetermined period of time (e.g., less than 10 seconds), the server may determine that there is an error and that the application is not operating normally.</p><p id="p-0021" num="0020">At operation <b>160</b>, the server may condense data for the portion of the plurality of stack traces that are indexed using predetermined failure scenarios for the application. The stack trace data may be text data that may include repeated portions. The predetermined failure scenarios may include, for example, communication between the server and a third-party system via a communications network, communication between the server a database via the communications network, an endless loop of the application, a long-running request of the application, and/or execution of custom code of the application at the server, or the like. The server may condense the data by correlating threads of the portion of the plurality of stack traces based on processor consumption per each thread. The processor consumption may be the active use and/or a percentage of active use of the processor of the server (e.g., the processor of the application server <b>204</b> of the data center <b>202</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, and/or the processor of the server <b>700</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>). In some implementations, the server may condense the data by removing standard sections of the plurality of stack traces.</p><p id="p-0022" num="0021">For example, the server may correlate threads from the stack trace with the processor consumption for each thread. The server may reduce the repeated data (e.g., &#x201c;boilerplate&#x201d; data) that may be a part of stack traces, but may not be useful in determining the status of an application executed by a server.</p><p id="p-0023" num="0022">The server may classify the stack traces (e.g., the interesting stack traces) and group together stack traces with similar and/or identical text, but with different context (i.e., from a different thread). By classifying and grouping the stack traces, the server may generate a report to show what thread in the application server is doing the same thing, such as waiting for an external web service or database to return data, or the like.</p><p id="p-0024" num="0023">In some implementations, the server may condense the data at operation <b>160</b> by grouping together stack traces based on stack traces having identical text but different contexts, and/or stack traces having identical text and the same context. The server may group together stack traces with similar and/or identical text and context (i.e., taken from a different stack trace snapshot). The threads may span multiple snapshots, but still have identical context and stack trace contents. That is, such threads may be likely to be &#x2018;stuck&#x2019; and not moving forward (i.e., so-called &#x2018;long-running&#x2019; threads). The generated report may include the grouped stack traces.</p><p id="p-0025" num="0024">The server may pattern-match stack traces against a predetermined set of error scenarios, and may classify such stack traces that match the pattern as having an error and/or failure.</p><p id="p-0026" num="0025">The stack traces may be pattern matched against a set of predetermined tasks and/or interactions (which may not necessarily be error conditions). The server may sum each category of pattern matched traces. This may be used to generate a report to show how many application server threads are doing the same thing (e.g., network input/output, communicating with the database, running custom code, or the like). The generated report may assist a user and/or administrator in determining if one or more subsystems appears to be slow and blocking one or more threads. For example, the response of the database that may be less than a predetermined threshold may be shown in different stack traces, and may include similar blocks across threads. The generated report may present the grouped stack traces, which may summarize the issues with the application. In some implementations, the generated report may show processor consumption of each stack trace.</p><p id="p-0027" num="0026">In implementations of the disclosed subject matter, the server may monitor instances of the application, and capture stack traces at predetermined intervals. Stack trace data may be sent to a central aggregator instance of the server that may also provide a user interface (e.g., a graphical user interface (GUI)) for generated reports. The central aggregator at the server may store stack trace data at a storage device and/or database, and may accept inbound connections that include stack trace data. The central aggregator may accept inbound connections containing other runtime instance data, such as job completion data, feature toggle data, database object churn data, and the like. Such runtime instance data may be stored in the storage device and/or database communicatively coupled to the server.</p><p id="p-0028" num="0027">In some implementations of the disclosed subject matter, the stack trace text may be considered without context (e.g., without operating system metadata), and the stack trace text may be compared to one or more other stack traces. The server may group together stack traces, such as identical stack traces, to be presented in the report. In some implementations, the server may collapse, condense, and/or remove sections of the stack trace that may not include information that relates to the operational status of the application. For example, such sections may include boilerplate library stack trace information that may be repeated. By collapsing, condensing, and/or removing this repeated or information (e.g., as shown by the collapsing of Internal RPC Communication <b>304</b> in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>), the report may include information that relates to the operational status of the application. In some implementations of the disclosed subject matter, the server may determine the lines from the stack trace that may be considered boilerplate by performing filtering, statistical analysis, natural language processing, or the like. For example, the server may determine specific patterns within the stack trace text, based on domain specific and/or expert system data. The server may collapse, condense, and/or remove text from the stack trace based on filtering, where the filtering may be based on message size or the like. As described above, the server may collect baseline stack trace data and count occurrences of each line across application server instances and/or specific to application server instances to determine a frequency &#x2018;score&#x2019; for each line. If an average of normalized frequency scores exceeds a predetermined threshold, the server may select the stack trace (e.g., as being an &#x201c;interesting&#x201d; stack trace for the report), and may use at least a portion of the stack trace in the when generating the report.</p><p id="p-0029" num="0028">The server may generate a report based on the condensed data and the state of the application at operation <b>170</b>. For example, the trace-bot <b>220</b> of instance <b>218</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref> may request stack trace data from the database <b>222</b> of the virtual private cloud <b>212</b> for a particular time period, application instance, and the like. The trace-bot <b>220</b> of instance <b>218</b> may generate a report based on the received stack trace data, and other related data (e.g., operating system metadata, and the like). The server may transmit, via a communications interface, the generated report for display. In another example, as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the server <b>700</b> may transmit the generated report to computer <b>500</b>, which may display the generated report on display <b>520</b>. In another example, the server (e.g., server <b>700</b> and/or <b>800</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>) may receive a request (e.g., via communication network <b>600</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>) from a user device (e.g., computer <b>500</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>) for a report on the status of the application. The request may include, for example, the dates and/or times for the stack traces, the customer instance, the number of stack traces to consider, and the like. Based on the request, the server may generate a report for display on the user device (e.g., display <b>520</b> of computer <b>500</b>) that may include analysis of, for example, long running threads, customer-created code with errors (e.g., endless loops), customer-created code links to hosting customer instance, processor consumption for each identified issue thread, third party communication threads, database interaction threads, and the like.</p><p id="p-0030" num="0029">Display <b>300</b> shown in <figref idref="DRAWINGS">FIGS. <b>4</b>A-<b>4</b>B</figref> show an example report generated based on a received request, where the display is generated using the method <b>100</b> shown in <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>3</b></figref> and described throughout. The display <b>300</b> includes user threads <b>310</b> and <b>312</b> (&#x201c;PipelineCallServlet|1117504106|Sites-elf-us-Site|Api-SetTrackingAllowed|OnRequest|3MXInSnnBe&#x2033; #101537 daemon prio=5&#x201d; shown as thread <b>310</b> and &#x201c;PipelineCallServlet|1386079212|Sites-elf-us-Site|Api-SetCookieData|OnRequest|3MXInSnnBe&#x2033; #104160 daemon prio=5&#x201d; shown as thread <b>312</b>) are being held up by a Blocker thread <b>302</b> (&#x201c;PipelineCallServlet|1669292665|Sites-elf-us-Site|_SYSTEM_ApplePay-GetRequest|PipelineCall|3MXInSnnBe&#x201d; tid=-187385452 nid=-187385452 state=RUNNABLE). As described above, the server may collapse blocks of code that are determined to be boilerplate code (e.g., Internal RPC Communication <b>304</b>), and may reduce the output trace text <b>306</b> to a size that may be reviewed by a user and/or operator.</p><p id="p-0031" num="0030">When generating the report, the server may process the stack traces for the user-supplied time frame. For each unique stack trace, the server may build an internal representation for similar stack traces. That is, the representation may add context information that regular stack traces may not have. For example, operating system metadata (e.g., processor consumption) of the stack traces may be used by the server in generating the report. The metadata may be assigned to one or more stack traces based on their process identifier. The metadata may be used to determine and/or identify threads with processor consumption that is greater than a predetermined amount. The operating system metadata and/or the stack trace data may be used in generating a report to show the status of the application at a particular point in time.</p><p id="p-0032" num="0031">In some implementations, method <b>100</b> may include an operation of having the server delete, at the storage device, at least one of the plurality of stack traces after it has been stored for a predetermined period of time. That is, stack traces that may be no longer useful for analysis of the operating state of the application or instances of the application may be deleted after a predetermined period of time.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows optional operations that may be performed as part of method <b>100</b> according to implementations of the disclosed subject matter. At operation <b>180</b>, the server may compare the plurality of stack traces in a time domain. The server may compare a first stack trace at a first time to a second stack trace at a second time. For example, a server may compare a stack trace from a first time (e.g., a minute ago) with a current stack trace to determine whether there is a thread that &#x201c;hangs&#x201d; (i.e., is not operating normally, and is causing delay). That is, implementations of the disclosed subject matter may identify long running and potentially stuck work threads that hang, as the time to complete these requests may be greater than a predetermined period of time (e.g., less than one second).</p><p id="p-0034" num="0033">At operation <b>182</b>, the server may determine a failure and/or error of the application when the compared first stack trace and the second stack trace indicate a thread hang. At operation <b>184</b>, the report generated at operation <b>170</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, may be modified and/or adjusted based on the error and/or failure of the application determined at operation <b>182</b>.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows optional operations that may be performed as part of method <b>100</b> according to implementations of the disclosed subject matter. At operation <b>190</b>, the server may determine a frequency score for each line of code from the application based on a portion of the plurality of stack traces. At operation <b>192</b>, the server may select the portion of the stack traces for the report when an average of normalized frequency of the frequency scores for the lines of code of the application exceeds a predetermined threshold.</p><p id="p-0036" num="0035">That is, the server may identify segments of stack traces of interest for analysis by pruning other portions of stack trace data. For example, the server may use statistical methods, and/or may determine repeated sections, or the like, when determining which portions of the stack trace data to prune.</p><p id="p-0037" num="0036">In implementations of the disclosed subject matter, a server may collect stack trace data (e.g., using the thread dump collector <b>206</b> from the trace-bot <b>220</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>), and determine the number of occurrences of each line of code across application server instances and/or determine the number of occurrences of each line of code that is specific to application server instances. As described above, the server may determine a frequency &#x2018;score&#x2019; for each line of code. If an average of normalized frequency scores exceeds a predetermined threshold, the server may select the stack trace as &#x201c;interesting,&#x201d; and may use at least a portion of the stack trace in the when generating the report.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows example system <b>200</b> that may perform the operations discussed above in connection with <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>3</b></figref> according to an implementation of the disclosed subject matter. Data center <b>202</b> may include one or more application servers <b>204</b>, which may include a thread dump collector <b>206</b>. The application server <b>204</b> may transmit a request for a stack trace to the virtual private cloud <b>212</b> via communications network <b>210</b>. The virtual private cloud <b>212</b> may include an application load balancer (ALB) <b>214</b>, that may provide the trace request <b>216</b> to a Kubernetes instance <b>218</b>. The ALB <b>214</b> manages incoming requests to the virtual private cloud <b>212</b>. Kubernetes instance <b>218</b> may be a container-orchestration system for automating computer application deployment, scaling, and/or management. The Kubernetes instance <b>218</b> may include trace-bot <b>220</b> and a database <b>222</b> (e.g., which may be a Mongo database in Kubernetes). Stack trace data from periodic stack traces by trace-bot <b>220</b> may be stored in database <b>222</b>. The trace-bot <b>220</b> may receive the stack traces of the application and generate reports described above in connection with method <b>100</b>, shown in <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>3</b></figref>.</p><p id="p-0039" num="0038">Implementations of the presently disclosed subject matter may be implemented in and used with a variety of component and network architectures. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is an example computer <b>500</b> which may display application status reports generated by server <b>700</b> and/or <b>800</b> based on the example methods shown in <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>3</b></figref> and described above.</p><p id="p-0040" num="0039">As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the computer <b>500</b> may communicate with a server <b>700</b> (e.g., a server, cloud server, database, cluster, application server, neural network system, or the like) via a wired and/or wireless communications network <b>600</b>. The server <b>700</b> may be a plurality of servers, cloud servers, databases, clusters, application servers, neural network systems, or the like. The server <b>700</b> may include a processor <b>705</b>, which may be a hardware processor, a microprocessor, an integrated circuit, a field programmable gate array, or the like. The server <b>700</b> may include a storage device <b>710</b>. The storage <b>710</b> may use any suitable combination of any suitable volatile and non-volatile physical storage mediums, including, for example, hard disk drives, solid state drives, optical media, flash memory, tape drives, registers, and random access memory, or the like, or any combination thereof. The server <b>700</b> may be communicatively coupled to database <b>900</b>, which may use any suitable combination of any suitable volatile and non-volatile physical storage mediums, including, for example, hard disk drives, solid state drives, optical media, flash memory, tape drives, registers, and random access memory, or the like, or any combination thereof. The server <b>700</b> may be communicatively coupled to server <b>800</b>, which may be one or more servers, cloud servers, databases, clusters, application servers, neural network systems, or the like. The server <b>800</b> may include a processor <b>805</b>, which may be a hardware processor, a microprocessor, an integrated circuit, a field programmable gate array, or the like Server <b>800</b> may include storage <b>810</b>, which may use any suitable combination of any suitable volatile and non-volatile physical storage mediums, including, for example, hard disk drives, solid state drives, optical media, flash memory, tape drives, registers, and random access memory, or the like, or any combination thereof. The server <b>800</b> may be a third-party server to provide data for an application being executed by server <b>700</b>. The server <b>700</b> may use input from the database <b>900</b> and/or server <b>800</b> in dynamically generating a report on the status of the application.</p><p id="p-0041" num="0040">In an example, the application server <b>204</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref> may be server <b>700</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, and the virtual private cloud <b>212</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref> may be server <b>800</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>. The database <b>222</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref> may be the database <b>900</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>. The communications network <b>210</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref> may be the communications network <b>600</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0042" num="0041">The storage <b>710</b> of the server <b>700</b>, the storage <b>810</b> of the server <b>800</b>, and/or the database <b>900</b>, may store data, such as stack trace data, operating system metadata, and the like. Further, if the storage <b>710</b>, storage <b>910</b>, and/or database <b>800</b> is a multitenant system, the storage <b>710</b>, storage <b>910</b>, and/or database <b>800</b> can be organized into separate log structured merge trees for each instance of a database for a tenant. Alternatively, contents of all records on a particular server or system can be stored within a single log structured merge tree, in which case unique tenant identifiers associated with versions of records can be used to distinguish between data for each tenant as disclosed herein. More recent transactions can be stored at the highest or top level of the tree and older transactions can be stored at lower levels of the tree. Alternatively, the most recent transaction or version for each record (i.e., contents of each record) can be stored at the highest level of the tree and prior versions or prior transactions at lower levels of the tree.</p><p id="p-0043" num="0042">The computer (e.g., user computer, enterprise computer, or the like) <b>500</b> may include a bus <b>510</b> which interconnects major components of the computer <b>500</b>, such as a central processor <b>540</b>, a memory <b>570</b> (typically RAM, but which can also include ROM, flash RAM, or the like), an input/output controller <b>580</b>, a user display <b>520</b>, such as a display or touch screen via a display adapter, a user input interface <b>560</b>, which may include one or more controllers and associated user input or devices such as a keyboard, mouse, Wi-Fi/cellular radios, touchscreen, microphone/speakers and the like, and may be communicatively coupled to the I/O controller <b>580</b>, fixed storage <b>530</b>, such as a hard drive, flash storage, Fibre Channel network, SAN device, SCSI device, and the like, and a removable media component <b>550</b> operative to control and receive an optical disk, flash drive, and the like.</p><p id="p-0044" num="0043">The bus <b>510</b> may enable data communication between the central processor <b>540</b> and the memory <b>570</b>, which may include read-only memory (ROM) or flash memory (neither shown), and random access memory (RAM) (not shown), as previously noted. The RAM may include the main memory into which the operating system, development software, testing programs, and application programs are loaded. The ROM or flash memory can contain, among other code, the Basic Input-Output system (BIOS) which controls basic hardware operation such as the interaction with peripheral components. Applications resident with the computer <b>500</b> may be stored on and accessed via a computer readable medium, such as a hard disk drive (e.g., fixed storage <b>530</b>), an optical drive, floppy disk, or other storage medium <b>550</b>.</p><p id="p-0045" num="0044">The fixed storage <b>530</b> can be integral with the computer <b>500</b> or can be separate and accessed through other interfaces. The fixed storage <b>530</b> may be part of a storage area network (SAN). A network interface <b>590</b> can provide a direct connection to a remote server via a telephone link, to the Internet via an internet service provider (ISP), or a direct connection to a remote server via a direct network link to the Internet via a POP (point of presence) or other technique. The network interface <b>590</b> can provide such connection using wireless techniques, including digital cellular telephone connection, Cellular Digital Packet Data (CDPD) connection, digital satellite data connection or the like. For example, the network interface <b>590</b> may enable the computer to communicate with other computers and/or storage devices via one or more local, wide-area, or other networks, such as communications network <b>600</b>.</p><p id="p-0046" num="0045">Many other devices or components (not shown) may be connected in a similar manner (e.g., data cache systems, application servers, communication network switches, firewall devices, authentication and/or authorization servers, computer and/or network security systems, and the like). Conversely, all the components shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> need not be present to practice the present disclosure. The components can be interconnected in different ways from that shown. Code to implement the present disclosure can be stored in computer-readable storage media such as one or more of the memory <b>570</b>, fixed storage <b>530</b>, removable media <b>550</b>, or on a remote storage location.</p><p id="p-0047" num="0046">Some portions of the detailed description are presented in terms of diagrams or algorithms and symbolic representations of operations on data bits within a computer memory. These diagrams and algorithmic descriptions and representations are commonly used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here and generally, conceived to be a self-consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually, though not necessarily, these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers, or the like.</p><p id="p-0048" num="0047">It should be borne in mind, however, that all these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the above discussion, it is appreciated that throughout the description, discussions utilizing terms such as &#x201c;executing,&#x201d; &#x201c;performing,&#x201d; &#x201c;storing,&#x201d; &#x201c;indexing,&#x201d; &#x201c;determining,&#x201d; &#x201c;condensing,&#x201d; &#x201c;generating,&#x201d; &#x201c;transmitting,&#x201d; &#x201c;deleting,&#x201d; &#x201c;comparing,&#x201d; &#x201c;selecting,&#x201d; or the like, refer to the actions and processes of a computer system, or similar electronic computing device, that manipulates and transforms data represented as physical (e.g., electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices.</p><p id="p-0049" num="0048">More generally, various implementations of the presently disclosed subject matter can include or be implemented in the form of computer-implemented processes and apparatuses for practicing those processes. Implementations also can be implemented in the form of a computer program product having computer program code containing instructions implemented in non-transitory and/or tangible media, such as hard drives, solid state drives, USB (universal serial bus) drives, CD-ROMs, or any other machine readable storage medium, wherein, when the computer program code is loaded into and executed by a computer, the computer becomes an apparatus for practicing implementations of the disclosed subject matter. Implementations also can be implemented in the form of computer program code, for example, whether stored in a storage medium, loaded into and/or executed by a computer, or transmitted over some transmission medium, such as over electrical wiring or cabling, through fiber optics, or via electromagnetic radiation, wherein when the computer program code is loaded into and executed by a computer, the computer becomes an apparatus for practicing implementations of the disclosed subject matter. When implemented on a general-purpose microprocessor, the computer program code segments configure the microprocessor to create specific logic circuits. In some configurations, a set of computer-readable instructions stored on a computer-readable storage medium can be implemented by a general-purpose processor, which can transform the general-purpose processor or a device containing the general-purpose processor into a special-purpose device configured to implement or carry out the instructions. Implementations can be implemented using hardware that can include a processor, such as a general purpose microprocessor and/or an Application Specific Integrated Circuit (ASIC) that implements all or part of the techniques according to implementations of the disclosed subject matter in hardware and/or firmware. The processor can be coupled to memory, such as RAM, ROM, flash memory, a hard disk or any other device capable of storing electronic information. The memory can store instructions adapted to be executed by the processor to perform the techniques according to implementations of the disclosed subject matter.</p><p id="p-0050" num="0049">The foregoing description, for purpose of explanation, has been described with reference to specific implementations. However, the illustrative discussions above are not intended to be exhaustive or to limit implementations of the disclosed subject matter to the precise forms disclosed. Many modifications and variations are possible in view of the above teachings. The implementations were chosen and described to explain the principles of implementations of the disclosed subject matter and their practical applications, to thereby enable others skilled in the art to utilize those implementations as well as various implementations with various modifications as can be suited to the particular use contemplated.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method comprising:<claim-text>executing, at a server, an application;</claim-text><claim-text>performing, at a server, a stack trace of the application at a predetermined interval to generate a plurality of stack traces, wherein each stack trace of the plurality of stack traces is from a different point in time based on the predetermined interval, and wherein the stack trace is performed when the application is operating normally and when the application has had a failure;</claim-text><claim-text>storing, at a storage device communicatively coupled to the server, the plurality of stack traces;</claim-text><claim-text>indexing, at the storage device, the stored plurality of stack traces by timestamp;</claim-text><claim-text>determining, at the server, a state of the application based on a portion of the plurality of stack traces;</claim-text><claim-text>condensing, at the server, data for the portion of the plurality of stack traces that are indexed using predetermined failure scenarios for the application by removing repeated data from the portion of the plurality of stack traces;</claim-text><claim-text>generating, at the server, a report based on the condensed data and the state of the application; and</claim-text><claim-text>transmitting, at the server via a communications interface, the generated report for display.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising stack trace data that is text data that includes repeated portions.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least one of the predetermined failure scenarios are selected from the group consisting of: communication between the server and a third-party system via a communications network; communication between the server a database via the communications network; an endless loop of the application; a request of the application that runs for a period of time; and execution of custom code of the application at the server.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the data of at least one of the plurality of stack traces is text data and includes repeated sections.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>deleting, at the storage device, at least one of the plurality of stack traces after it has been stored for a predetermined period of time.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the condensing the data further comprises correlating threads of the portion of the plurality of stack traces based on processor consumption per each thread.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>comparing the plurality of stack traces in a time domain, wherein a first stack trace at a first time is compared to a second stack trace at a second time; and</claim-text><claim-text>determining a failure of the application when the compared first stack trace and the second stack trace indicate a thread hang,</claim-text><claim-text>wherein the generating the report comprises the determined failure of the application.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>determining, at the server, a frequency score for each line of code from the application based on the portion of the plurality of stack traces; and</claim-text><claim-text>selecting the portion of the stack traces for the report when an average of normalized frequency of the frequency scores for the lines of code of the application exceeds a predetermined threshold.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein condensing the data further comprises removing standard sections of the plurality of stack traces.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the condensing the data further comprises grouping together stack traces based on at least one selected from the group consisting of: stack traces having identical text but different contexts, and stack traces having identical text and the same context,<claim-text>wherein the generated report includes the grouped stack traces.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A system comprising:<claim-text>a server comprising a processor coupled to a memory to:<claim-text>execute an application;</claim-text><claim-text>perform a stack trace of the application at a predetermined interval to generate a plurality of stack traces, wherein each stack trace of the plurality of stack traces is from a different point in time based on the predetermined interval, and wherein the stack trace is performed when the application is operating normally and when the application has had a failure;</claim-text><claim-text>store, at a storage device communicatively coupled to the server, the plurality of stack traces;</claim-text><claim-text>index, at the storage device, the stored plurality of stack traces by timestamp;</claim-text><claim-text>determine a state of the application based on a portion of the plurality of stack traces;</claim-text><claim-text>condense data for the portion the plurality of stack traces that are indexed using predetermined failure scenarios for the application by removing repeated data from the portion of the plurality of stack traces;</claim-text><claim-text>generate a report based on the condensed data and the state of the application; and</claim-text><claim-text>transmit, via a communications interface coupled to the server, the generated report for display.</claim-text></claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising stack trace data that is text data that includes repeated portions.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein at least one of the predetermined failure scenarios are selected from the group consisting of: communication between the server and a third-party system via a communications network; communication between the server a database via the communications network; an endless loop of the application; a request of the application that runs for a period of time; and execution of custom code of the application at the server.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the data of at least one of the plurality of stack traces is text data and includes repeated sections.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the server deletes, at the storage device, at least one of the plurality of stack traces after it has been stored for a predetermined period of time.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the condensing the data further comprises correlating threads of the portion of the plurality of stack traces based on processor consumption per each thread.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the server compares the plurality of stack traces in a time domain, wherein a first stack trace at a first time is compared to a second stack trace at a second time,<claim-text>wherein the server determines a failure of the application when the compared first stack trace and the second stack trace indicate a thread hang, and</claim-text><claim-text>wherein the generated report includes the determined failure of the application.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the server determines a frequency score for each line of code from the application based on the portion of the plurality of stack traces, and selects the portion of the stack traces for the report when an average of normalized frequency of the frequency scores for the lines of code of the application exceeds a predetermined threshold.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the server further condenses the data by removing standard sections of the plurality of stack traces.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the server further condenses the data by grouping together stack traces based on at least one selected from the group consisting of: stack traces having identical text but different contexts, and stack traces having identical text and the same context, and<claim-text>wherein the generated report includes the grouped stack traces.</claim-text></claim-text></claim></claims></us-patent-application>
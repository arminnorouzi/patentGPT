<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005112A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005112</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17363761</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>5</main-group><subgroup>50</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>90</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>5</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>5</main-group><subgroup>50</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>90</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>5</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>20224</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">IMAGE MATCHING METHOD</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>V5 TECHNOLOGIES CO., LTD.</orgname><address><city>Hsinchu City</city><country>TW</country></address></addressbook><residence><country>TW</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>HSU</last-name><first-name>Sheng-Chih</first-name><address><city>Hsinchu City</city><country>TW</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>CHEN</last-name><first-name>Chien-Ting</first-name><address><city>Hsinchu City</city><country>TW</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A image matching method includes: converting an original image and a reference image to a hue-based color space; adjusting hue values of the original image based on hue values of the reference image to obtain an adjusted image; generating a hue-difference image based on the adjusted image and the original image; obtaining a binary image based on the hue-difference image; and for each pixel having a non-zero pixel value in the binary image, determining whether an adjacent pixel has a pixel value equal to zero, and in the affirmative, correcting a hue value corresponding to the pixel in the adjusted image based on the hue values corresponding to the adjacent pixel in the original image and in the adjusted image.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="65.36mm" wi="87.97mm" file="US20230005112A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="99.65mm" wi="90.00mm" file="US20230005112A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="239.95mm" wi="167.13mm" file="US20230005112A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="131.57mm" wi="145.97mm" file="US20230005112A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="70.61mm" wi="135.72mm" file="US20230005112A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="238.68mm" wi="143.09mm" orientation="landscape" file="US20230005112A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD</heading><p id="p-0002" num="0001">The disclosure relates to an image matching method, and more particularly to an image matching method in a color space that is represented by hue.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Conventionally, to match colors of an original image to colors of a reference image, histogram matching is performed on RGB (red, green, blue) color channels of the original image based on RGB color channels of the reference image, respectively. Although such approach makes each of the RGB color channels of the original image have a histogram similar to that of the corresponding one of the RGB color channels of the reference image, color distortion may occur since a color mixing ratio of each color in the original image may be changed after histogram matching is performed. Meanwhile, image feature(s) of the original image may be lost as a consequence.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">Therefore, an object of the disclosure is to provide an image matching method for matching colors of an original image to colors of a reference image that can alleviate at least one of the drawbacks of the prior art.</p><p id="p-0005" num="0004">According to the disclosure, the image matching method includes steps of:</p><p id="p-0006" num="0005">converting the original image and the reference image to a color space that is represented by hue;</p><p id="p-0007" num="0006">adjusting hue values of all pixels of the original image based on hue values of pixels of the reference image so as to obtain an adjusted image having a plurality of pixels corresponding respectively to the pixels of the original image;</p><p id="p-0008" num="0007">generating a hue-difference image based on hue values of the pixels of the adjusted image and the hue values of the pixels of the original image, the hue-difference image having a plurality of pixels corresponding to the pixels of the adjusted image, respectively;</p><p id="p-0009" num="0008">for each of the pixels of the hue-difference image, setting a pixel value of the pixel to one when the pixel value is greater than the predetermined threshold, and setting the pixel value of the pixel to zero when the pixel value is not greater than the predetermined threshold, so as to obtain a binary image that has a plurality of pixels corresponding to the pixels of the hue-difference image, respectively; and</p><p id="p-0010" num="0009">for each pixel having a non-zero pixel value in the binary image,<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0010">determining whether at least one adjacent pixel that is adjacent to the pixel has a pixel value equal to zero, and</li>        <li id="ul0002-0002" num="0011">when it is determined that at least one adjacent pixel has a pixel value equal to zero, correcting a hue value of a corresponding one of the pixels of the adjusted image that corresponds to the pixel of the binary image based on the hue value of each of at least one of the pixels of the original image and the hue value of each of at least one of the pixels of the adjusted image, wherein the at least one of the pixels of the original image and the at least one of the pixels of the adjusted image correspond to the at least one adjacent pixel of the binary image.</li>    </ul>    </li></ul></p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0011" num="0012">Other features and advantages of the disclosure will become apparent in the following detailed description of the embodiment with reference to the accompanying drawings, of which:</p><p id="p-0012" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating an example of a computing device configured to implement an image matching method according to an embodiment of the disclosure; and</p><p id="p-0013" num="0014"><figref idref="DRAWINGS">FIGS. <b>2</b> to <b>5</b></figref> cooperatively illustrate a flowchart of an image matching method according to an embodiment of the disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0014" num="0015">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, an embodiment of a computing device <b>1</b> is illustrated. The computing device <b>1</b> is configured to implement an image matching method for matching colors of an original image to colors of a reference image according to an embodiment of the disclosure. The computing device <b>1</b> may be embodied using a computing server, a personal computer, a desktop computer, a laptop computer, a notebook computer, a tablet computer or a smartphone, but is not limited to what are disclosed herein and may vary in other embodiments.</p><p id="p-0015" num="0016">The computing device <b>1</b> includes a storage <b>11</b> and a processor <b>12</b> that are electrically connected to each other.</p><p id="p-0016" num="0017">The storage <b>11</b> is configured to store the reference image. The storage <b>11</b> may be embodied using flash memory, a hard disk drive (HDD) or a solid state disk (SSD), electrically-erasable programmable read-only memory (EEPROM) or any other non-volatile memory devices, but is not limited thereto.</p><p id="p-0017" num="0018">The processor <b>12</b> may include, but not limited to, a central processing unit (CPU), a microprocessor, a micro control unit (MCU), a system on a chip (SoC), or any circuit that is configurable or programmable in a software manner and/or a hardware manner to implement functionalities discussed in this disclosure.</p><p id="p-0018" num="0019"><figref idref="DRAWINGS">FIGS. <b>2</b> to <b>5</b></figref> illustrate an embodiment of the image matching method. The image matching method includes a hue adjustment procedure and a brightness adjustment procedure. It is worth to note that the brightness adjustment procedure is optional and can be omitted according to needs in practice.</p><p id="p-0019" num="0020">Referring to <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>, the hue adjustment procedure includes steps <b>21</b> to <b>27</b> delineated below.</p><p id="p-0020" num="0021">In step <b>21</b>, the processor <b>12</b> converts the original image and the reference image to a color space that is represented by hue. In this embodiment, the color space is a hue, saturation, value (HSV) color space. However, in other embodiments, the color space may be a hue, saturation, intensity (HSI) color space, or any hue-based color space.</p><p id="p-0021" num="0022">In step <b>22</b>, the processor <b>12</b> adjusts hue values of all pixels of the original image based on hue values of pixels of the reference image so as to obtain an adjusted image. The adjusted image has a plurality of pixels corresponding respectively to the pixels of the original image.</p><p id="p-0022" num="0023">Specifically speaking, referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, step <b>22</b> includes sub-steps <b>221</b> to <b>223</b> delineated below.</p><p id="p-0023" num="0024">In sub-step <b>221</b>, the processor <b>12</b> sorts the hue values of the pixels of the reference image in numerical order. In this embodiment, the hue values of the pixels of the reference image are sorted in ascending order; that is, the hue values of the pixels of the reference image are arranged in order from smallest to largest.</p><p id="p-0024" num="0025">In sub-step <b>222</b>, the processor <b>12</b> sorts the hue values of the pixels of the original image in numerical order. Similarly, the hue values of the pixels of the original image are also sorted in ascending order.</p><p id="p-0025" num="0026">In sub-step <b>223</b>, with respect to each pixel of the original image, the processor <b>12</b> determines an ordinal number of the hue value of the pixel, and replaces the hue value of the pixel of the original image with the hue value of one of the pixels of the reference image that has an ordinal number corresponding to the ordinal number of the hue value of the pixel of the original image, so as to obtain the adjusted image. In some embodiments, the hue value of the pixel of the original image is replaced by the hue value of the pixel of the reference image that has the same ordinal number as the hue value of the pixel of the original image. It should be noted that when the original image has plural pixels, of which the hue values are identical and which are sorted to have different ordinal numbers, the processor <b>12</b> uses the smallest one of the ordinal numbers of the identical hue values to select the hue value in the reference image that is sorted to have an ordinal number equal to the smallest one of the ordinal numbers of the identical hue values in the original image, and replaces the identical hue values in the original image with the hue value in the reference image thus selected. For example, in a scenario where the original image has three pixels, of which the hue values are all equal to 15 and which are sorted to have different ordinal numbers 30<sup>th</sup>, 31<sup>st </sup>and 32<sup>rd</sup>, respectively, the processor <b>12</b> uses the smallest one of the ordinal numbers (i.e., 30<sup>th</sup>, hereinafter also referred to as the designated ordinal number) to select the hue value of one of the pixels of the reference image that has the designated ordinal number (i.e., 30<sup>th</sup>). Thereafter, the processor <b>15</b> replaces the identical hue values (i.e., 15) of the three pixels of the original image with the hue value thus selected.</p><p id="p-0026" num="0027">In step <b>23</b>, the processor <b>12</b> generates a hue-difference image based on hue values of the pixels of the adjusted image and the hue values of the pixels of the original image. The hue-difference image has a plurality of pixels corresponding to the pixels of the adjusted image, respectively. Specifically, for each pixel of the adjusted image and the corresponding one of the pixels of the original image, the processor <b>12</b> calculates an absolute value of a difference between the hue value of the pixel of the adjusted image and the hue value of the corresponding one of the pixels of the original image, and makes the absolute value serve as the pixel value of the pixel of the hue-difference image that corresponds to the pixel of the adjusted image.</p><p id="p-0027" num="0028">In step <b>24</b>, for each of the pixels of the hue-difference image, the processor <b>12</b> sets a pixel value of the pixel to one when the pixel value is greater than a predetermined threshold, and sets the pixel value of the pixel to zero when the pixel value is not greater than the predetermined threshold, so as to obtain a binary image. The binary image has a plurality of pixels corresponding to the pixels of the hue-difference image, respectively. In particular, the predetermined threshold is equal to a sum of an average of the pixel values of the pixels of the hue-difference image and a standard deviation of the pixel values of the pixels of the hue-difference image. In one embodiment, the average of the pixel values and the standard deviation of the pixel values are each calculated with respect to all pixels of the hue-difference image. In one embodiment, the average of the pixel values and the standard deviation of the pixel values are each calculated with respect to pixel(s) of the hue-difference image that has a non-zero pixel value.</p><p id="p-0028" num="0029">In step <b>25</b>, with respect to each pixel having a non-zero pixel value in the binary image, the processor <b>12</b> determines whether at least one adjacent pixel that is adjacent to the pixel has a pixel value equal to zero. When it is determined that at least one adjacent pixel has a pixel value equal to zero, a flow of procedure of the image matching method proceeds to step <b>26</b>. On the other hand, when it is determined that no adjacent pixel has a pixel value equal to zero, the flow proceeds to step <b>27</b>. It is worth to note that for a pixel that is not located at a boundary of the binary image, the pixel would have a total of eight adjacent pixels that are directly connected to and adjacent to the pixel. For a pixel that is located at the boundary of the binary image and is located at a corner, the pixel would have a total of three adjacent pixels that are directly connected to and adjacent to the pixel. For a pixel that is located at the boundary of the binary image and is located at an edge rather than a corner, the pixel would have a total of five adjacent pixels that are directly connected to and adjacent to the pixel. Specifically, in step <b>25</b>, for each pixel of the binary image that has a non-zero pixel value, the flow goes to step <b>26</b> when it is determined that any one of the adjacent pixels has a pixel value equal to zero, and goes to step <b>27</b> when it is determined that each of the adjacent pixels has a pixel value not equal to zero.</p><p id="p-0029" num="0030">In step <b>26</b>, for each pixel of the binary image having a non-zero pixel value and having at least one adjacent pixel with a pixel value equal to zero, the processor <b>12</b> corrects a hue value of a corresponding one of the pixels of the adjusted image that corresponds to the pixel of the binary image based on the hue value of each of at least one of the pixels of the original image and the hue value of each of at least one of the pixels of the adjusted image, wherein the at least one of the pixels of the original image and the at least one of the pixels of the adjusted image correspond to the at least one adjacent pixel of the binary image that has the pixel value equal to zero. More specifically, in step <b>26</b>, for each pixel of the binary image that has a non-zero pixel value and that has the at least one adjacent pixel having a pixel value of zero, the processor <b>12</b> calculates a sum of an average of the hue value(s) of the at least one of the pixels of the original image that corresponds to the at least one adjacent pixel of the binary image and the hue value of the corresponding one of pixels of the adjusted image that corresponds to the pixel of the binary image. Then, the processor <b>12</b> subtracts, from the sum thus calculated, an average of the hue value(s) of the at least one of the pixels of the adjusted image that corresponds to the at least one adjacent pixel of the binary image, so as to obtain the hue value of the corresponding one of the pixels of the adjusted image that corresponds to the pixel of the binary image.</p><p id="p-0030" num="0031">In step <b>27</b>, for each pixel of the binary image having a non-zero pixel value and having each adjacent pixel with a pixel value not equal to zero, the processor <b>12</b> calculates an average of the pixel values of those of the pixels of the hue-difference image that are not greater than the predetermined threshold, and corrects the hue value of the corresponding one of the pixels of the adjusted image that corresponds to the pixel of the binary image based on the average of the pixel values of those of the pixels of the hue-difference image that are not greater than the predetermined threshold.</p><p id="p-0031" num="0032">Specifically speaking, referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, correcting the hue value in step <b>27</b> includes sub-steps <b>271</b> to <b>273</b> delineated below.</p><p id="p-0032" num="0033">In sub-step <b>271</b>, the processor <b>12</b> determines whether an average of the hue values of all pixels of the adjusted image is smaller than an average of the hue values of all pixels of the original image. When it is determined that the average of the hue values of all pixels of the adjusted image is smaller than the average of the hue values of all pixels of the original image, the flow proceeds to sub-step <b>272</b>. Otherwise, when it is determined that the average of the hue values of all pixels of the adjusted image is not smaller than the average of the hue values of all pixels of the original image, the flow proceeds to sub-step <b>273</b>.</p><p id="p-0033" num="0034">In sub-step <b>272</b>, for each pixel of the binary image having a non-zero pixel value and having each adjacent pixel with a pixel value not equal to zero, the processor <b>12</b> corrects the hue value of the corresponding one of the pixels of the adjusted image that corresponds to the pixel of the binary image by subtracting therefrom the average of the pixel values of those of the pixels of the hue-difference image that are not greater than the predetermined threshold.</p><p id="p-0034" num="0035">In sub-step <b>273</b>, for each pixel of the binary image having a non-zero pixel value and having each adjacent pixel with a pixel value not equal to zero, the processor <b>12</b> corrects the hue value of the corresponding one of the pixels of the adjusted image that corresponds to the pixel of the binary image by adding thereto the average of the pixel values of those of the pixels of the hue-difference image that are not greater than the predetermined threshold.</p><p id="p-0035" num="0036">After performance of the hue adjustment procedure, the brightness adjustment procedure is performed on the adjusted image. Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the brightness adjustment procedure includes step <b>31</b> delineated below.</p><p id="p-0036" num="0037">In step <b>31</b>, the processor <b>12</b> performs histogram matching on brightness values of the pixels of the adjusted image based on brightness values of the pixels of the reference image. In this way, brightness of the adjusted image would be made similar to that of the reference image.</p><p id="p-0037" num="0038">It is worth to note that the image matching method according to the disclosure may be applied to inspect products for defect detection. In particular, two pictures of the same object taken under different conditions (e.g., different ambient light) may have different colors, and such color difference may be misleading and may cause an incorrect result of defect detection. The image matching method according to the disclosure can reduce the aforesaid color difference, and thus misjudgment due to color difference may be alleviated and accuracy of defect detection may be enhanced. It should be noted that application of the image matching method is not limited to the disclosure herein, and the image matching method may be used in any field where color adjustment is involved.</p><p id="p-0038" num="0039">In summary, the image matching method according to the disclosure utilizes the computing device <b>1</b> to convert the original image and the reference image to the color space that is represented by hue, and to adjust the hue values of the pixels of the original image based on the hue values of the pixels of the reference image so as to obtain the adjusted image. In this way, the issue of color distortion, which may occur when RGB (red, green, blue) color channels of the original image are separately adjusted, may be avoided. Moreover, the image matching method according to the disclosure utilizes the computing device <b>1</b> to correct the hue value(s) of specifically conditioned pixel (s) in the adjusted image so as to alleviate abnormally large variations of hue values in the adjusted image, which may otherwise cause image distortion. Further, histogram matching is performed on the brightness values of the pixels of the adjusted image based on the brightness values of the pixels of the reference image, so as to make brightness of the adjusted image similar to that of the reference image.</p><p id="p-0039" num="0040">In the description above, for the purposes of explanation, numerous specific details have been set forth in order to provide a thorough understanding of the embodiment. It will be apparent, however, to one skilled in the art, that one or more other embodiments may be practiced without some of these specific details. It should also be appreciated that reference throughout this specification to &#x201c;one embodiment,&#x201d; &#x201c;an embodiment,&#x201d; an embodiment with an indication of an ordinal number and so forth means that a particular feature, structure, or characteristic may be included in the practice of the disclosure. It should be further appreciated that in the description, various features are sometimes grouped together in a single embodiment, figure, or description thereof for the purpose of streamlining the disclosure and aiding in the understanding of various inventive aspects, and that one or more features or specific details from one embodiment may be practiced together with one or more features or specific details from another embodiment, where appropriate, in the practice of the disclosure.</p><p id="p-0040" num="0041">While the disclosure has been described in connection with what is considered the exemplary embodiment, it is understood that this disclosure is not limited to the disclosed embodiment but is intended to cover various arrangements included within the spirit and scope of the broadest interpretation so as to encompass all such modifications and equivalent arrangements.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image matching method for matching colors of an original image to colors of a reference image, the image matching method comprising steps of:<claim-text>converting the original image and the reference image to a color space that is represented by hue;</claim-text><claim-text>adjusting hue values of all pixels of the original image based on hue values of pixels of the reference image so as to obtain an adjusted image having a plurality of pixels corresponding respectively to the pixels of the original image;</claim-text><claim-text>generating a hue-difference image based on hue value s of the pixels of the adjusted image and the hue values of the pixels of the original image, the hue-difference image having a plurality of pixels corresponding to the pixels of the adjusted image, respectively;</claim-text><claim-text>for each of the pixels of the hue-difference image, setting a pixel value of the pixel to one when the pixel value is greater than a predetermined threshold, and setting the pixel value of the pixel to zero when the pixel value is not greater than the predetermined threshold, so as to obtain a binary image that has a plurality of pixels corresponding to the pixels of the hue-difference image, respectively; and</claim-text><claim-text>for each pixel having a non-zero pixel value in the binary image,<claim-text>determining whether at least one adjacent pixel that is adjacent to the pixel has a pixel value equal to zero, and</claim-text><claim-text>when it is determined that at least one adjacent pixel has a pixel value equal to zero, correcting a hue value of a corresponding one of the pixels of the adjusted image that corresponds to the pixel of the binary image based on the hue value of each of at least one of the pixels of the original image and the hue value of each of at least one of the pixels of the adjusted image, wherein the at least one of the pixels of the original image and the at least one of the pixels of the adjusted image correspond to the at least one adjacent pixel of the binary image.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The image matching method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of adjusting hue values of all pixels of the original image includes:<claim-text>sorting the hue values of the pixels of the reference image in numerical order;</claim-text><claim-text>sorting the hue values of the pixels of the original image in numerical order; and</claim-text><claim-text>with respect to each pixel of the original image, determining an ordinal number of the hue value of the pixel, and replacing the hue value of the pixel of the original image with the hue value of one of the pixels of the reference image that has an ordinal number corresponding to the ordinal number of the hue value of the pixel of the original image, so as to obtain the adjusted image.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The image matching method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of generating a hue-difference image includes:<claim-text>with respect to each pixel of the adjusted image and the corresponding one of the pixels of the original image, calculating an absolute value of a difference between the hue value of the pixel of the adjusted image and the hue value of the corresponding one of the pixels of the original image, and making the absolute value serve as the pixel value of the pixel of the hue-difference image that corresponds to the pixel of the adjusted image.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The image matching method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predetermined threshold is equal to a sum of an average of pixel values of the pixels of the hue-difference image and a standard deviation of the pixel values of the pixels of the hue-difference image.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The image matching method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of correcting a hue value includes, for each pixel of the binary image that has a non-zero pixel value and that has at least one adjacent pixel having a pixel value of zero:<claim-text>calculating a sum of an average of the hue value (s) of the at least one of the pixels of the original image that corresponds to the at least one adjacent pixel of the binary image and the hue value of the corresponding one of the pixels of the adjusted image that corresponds to the pixel of the binary image; and</claim-text><claim-text>subtracting, from the sum thus calculated, an average of the hue value(s) of the at least one of the pixels of the adjusted image that corresponds to the at least one adjacent pixel of the binary image, so as to obtain the hue value of the corresponding one of the pixels of the adjusted image that corresponds to the pixel of the binary image.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The image matching method as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising steps of:<claim-text>for each pixel having a non-zero pixel value in the binary image, when it is determined that the adjacent pixel has a pixel value not equal to zero,<claim-text>calculating an average of the pixel values of those of the pixels of the hue-difference image that are not greater than the predetermined threshold, and</claim-text><claim-text>correcting the hue value of the corresponding one of the pixels of the adjusted image that corresponds to the pixel of the binary image based on the average of the pixel values of those of the pixels of the hue-difference image that are not greater than the predetermined threshold.</claim-text></claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The image matching method as claimed in <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the step of correcting the hue value includes:<claim-text>determining whether an average of the hue values of all pixels of the adjusted image is smaller than an average of the hue values of all pixels of the original image;</claim-text><claim-text>when it is determined that the average of the hue values of all pixels of the adjusted image is smaller than the average of the hue values of all pixels of the original image, correcting the hue value of the corresponding one of pixels of the adjusted image that corresponds to the pixel of the binary image by subtracting therefrom the average of the pixel values that are not greater than the predetermined threshold; and</claim-text><claim-text>when it is determined that the average of the hue values of all pixels of the adjusted image is not smaller than the average of the hue values of all pixels of the original image, correcting the hue value of the corresponding one of pixels of the adjusted image that corresponds to the pixel of the binary image by adding thereto the average of the pixel values of those of the pixels of the hue-difference image that are not greater than the predetermined threshold.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The image matching method as claimed in <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the color space is a hue, saturation, value (HSV) color space.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The image matching method as claimed in <claim-ref idref="CLM-00008">claim 8</claim-ref>, subsequent to the step of correcting the hue value, further comprising:<claim-text>performing histogram matching on brightness values of the pixels of the adjusted image based on brightness values of the pixels of the reference image.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005168A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005168</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17930721</doc-number><date>20220909</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-064479</doc-number><date>20200331</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>521</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>894</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>521</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>894</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30204</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30244</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10028</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10116</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">INFORMATION PROCESSING DEVICE, INFORMATION PROCESSING METHOD, AND INFORMATION PROCESSING PROGRAM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/011504</doc-number><date>20210319</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17930721</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>FUJIFILM CORPORATION</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>ODA</last-name><first-name>Yoshinari</first-name><address><city>Kanagawa</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A CPU acquires a distance image or a visible light image obtained by imaging a marker for measuring an SID as an object to be imaged using a TOF camera or a visible light camera. In addition, the CPU derives a marker distance between the TOF camera or the visible light camera and the marker from an image of a marker region corresponding to the marker in the acquired distance image or visible light image. Further, the CPU derives the SID on the basis of the derived marker distance and information indicating a positional relationship between an acquisition unit and the marker.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="133.94mm" wi="158.75mm" file="US20230005168A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="244.52mm" wi="161.21mm" file="US20230005168A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="248.41mm" wi="133.43mm" file="US20230005168A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="156.29mm" wi="114.72mm" file="US20230005168A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="249.94mm" wi="164.68mm" file="US20230005168A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="188.81mm" wi="161.21mm" file="US20230005168A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="251.12mm" wi="164.68mm" file="US20230005168A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="173.14mm" wi="114.72mm" file="US20230005168A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation application of International Application No. PCT/JP2021/011504, filed on Mar. 19, 2021, the disclosure of which is incorporated herein by reference in its entirety. Further, this application claims priority from Japanese Patent Application No. 2020-064479 filed on Mar. 31, 2020, the disclosure of which is incorporated herein by reference in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">1. Technical Field</heading><p id="p-0003" num="0002">The present disclosure relates to an information processing device, an information processing method, and an information processing program.</p><heading id="h-0004" level="1">2. Description of the Related Art</heading><p id="p-0004" num="0003">In general, in a case in which a radiography apparatus captures radiographic images using a radiation detector, a distance between a radiation source and the radiation detector is detected. For example, according to a technique disclosed in JP2019-33829A, it is possible to measure a distance between a radiation source and a radiation detector on the basis of a camera image obtained by imaging a marker that is provided on a housing of an electronic cassette.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0005" num="0004">In the technique disclosed in JP2019-33829A, the marker is provided on the housing of the electronic cassette. Therefore, for example, in a case in which the marker is hidden by a subject which is an object to be imaged, it may be difficult to appropriately measure the distance between the radiation source and the radiation detector.</p><p id="p-0006" num="0005">The present disclosure has been made in view of the above circumstances, and an object of the present disclosure is to provide an information processing device, an information processing method, and an information processing program that can appropriately measure a distance between a radiation source and a radiation detector.</p><p id="p-0007" num="0006">According to a first aspect of the present disclosure, there is provided an information processing device comprising at least one processor and a memory that stores commands executable by the processor. The processor acquires a captured image obtained by imaging a marker for measuring a distance between a radiation source and a radiation detector as an object to be imaged using an imaging device, derives a marker distance between the imaging device and the marker from an image of a marker region corresponding to the marker in the acquired captured image, and derives the distance between the radiation source and the radiation detector on the basis of the derived marker distance and information indicating a positional relationship between the radiation detector and the marker.</p><p id="p-0008" num="0007">According to a second aspect of the present disclosure, in the information processing device according to the first aspect, the processor may derive the distance between the radiation source and the radiation detector further on the basis of information indicating a positional relationship between the imaging device and the radiation source.</p><p id="p-0009" num="0008">According to a third aspect of the present disclosure, in the information processing device according to the first aspect or the second aspect, the object to be imaged may include a subject that is positioned between the radiation source and the radiation detector, and the processor may derive a subject distance between the imaging device and the subject from an image of a subject region corresponding to the subject in the acquired captured image and derive a body thickness of the subject on the basis of the derived subject distance and the distance between the radiation source and the radiation detector.</p><p id="p-0010" num="0009">According to a fourth aspect of the present disclosure, in the information processing device according to the first aspect or the second aspect, the object to be imaged may include a subject that is positioned between the radiation source and the radiation detector, and the processor may derive a subject distance between the imaging device and the subject from an image of a subject region corresponding to the subject in the acquired captured image and derive a body thickness of the subject on the basis of the derived subject distance, the distance between the radiation source and the radiation detector, and a distance between the radiation detector and the subject.</p><p id="p-0011" num="0010">According to a fifth aspect of the present disclosure, in the information processing device according to any one of the first to fourth aspects, the imaging device may be a distance image capture device that captures a distance image indicating a distance to the object to be imaged as the captured image, and the processor may derive a distance indicated by the image of the marker region corresponding to the marker in the distance image as the marker distance.</p><p id="p-0012" num="0011">According to a sixth aspect of the present disclosure, in the information processing device according to the fifth aspect, the processor may specify the marker region in the distance image on the basis of a shape of the marker.</p><p id="p-0013" num="0012">According to a seventh aspect of the present disclosure, in the information processing device according to the fifth aspect, the processor may acquire a visible light image obtained by imaging the marker as the object to be imaged using a visible light image capture device that captures the visible light image of the object to be imaged and set, as the marker region, a region of an image, which corresponds to a position of the marker specified by the image of the marker in the visible light image, in the distance image.</p><p id="p-0014" num="0013">According to an eighth aspect of the present disclosure, in the information processing device according to any one of the fifth to seventh aspects, the distance image capture device may capture the distance image using a time-of-flight (TOF) method.</p><p id="p-0015" num="0014">According to a ninth aspect of the present disclosure, in the information processing device according to any one of the first to fourth aspects, the imaging device may be a visible light image capture device that captures a visible light image of the object to be imaged as the captured image, and the processor may derive the marker distance on the basis of a size of the marker region in the visible light image and a reference size of the marker region associated with a reference value of the marker distance.</p><p id="p-0016" num="0015">According to a tenth aspect of the present disclosure, in the information processing device according to any one of the first to ninth aspects, the processor may store the derived distance between the radiation source and the radiation detector in a storage unit and acquire the distance between the radiation source and the radiation detector from the storage unit to derive the distance between the radiation source and the radiation detector, without deriving the marker distance, in a case in which a position of the marker region specified from the captured image acquired currently is the same as a position of the marker region specified from the captured image acquired previously.</p><p id="p-0017" num="0016">According to an eleventh aspect of the present disclosure, in the information processing device according to any one of the first to ninth aspects, the processor may store the derived distance between the radiation source and the radiation detector in a storage unit and output information indicating a warning for a period until the marker distance is derived from the captured image acquired currently in a case in which a position of the marker region specified from the captured image acquired currently is different from a position of the marker region specified from the captured image acquired previously.</p><p id="p-0018" num="0017">Further, according to a twelfth aspect of the present disclosure, there is provided an information processing method executed by a computer. The information processing method comprises: acquiring a captured image obtained by imaging a marker for measuring a distance between a radiation source and a radiation detector as an object to be imaged using an imaging device; deriving a marker distance between the imaging device and the marker from an image of a marker region corresponding to the marker in the acquired captured image; and deriving the distance between the radiation source and the radiation detector on the basis of the derived marker distance and information indicating a positional relationship between the radiation detector and the marker.</p><p id="p-0019" num="0018">In addition, according to a thirteenth aspect of the present disclosure, there is provided an information processing program that causes a computer to execute a process comprising: acquiring a captured image obtained by imaging a marker for measuring a distance between a radiation source and a radiation detector as an object to be imaged using an imaging device; deriving a marker distance between the imaging device and the marker from an image of a marker region corresponding to the marker in the acquired captured image; and deriving the distance between the radiation source and the radiation detector on the basis of the derived marker distance and information indicating a positional relationship between the radiation detector and the marker.</p><p id="p-0020" num="0019">According to the present disclosure, it is possible to appropriately measure the distance between the radiation source and the radiation detector.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0021" num="0020">Exemplary embodiments according to the technique of the present disclosure will be described in detail based on the following figures, wherein:</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram schematically illustrating an example of an overall configuration of a radiography system according to a first embodiment,</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an example of a configuration of a console according to the first embodiment,</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a functional block diagram illustrating an example of a functional configuration of the console according to the first embodiment,</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is a schematic diagram illustrating an example of a positional relationship among a focus of a radiation emitting device, an imaging element of a TOF camera, a radiation detector, and a marker as viewed from an X-axis direction,</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> is a schematic diagram illustrating an example of a positional relationship among the focus of the radiation emitting device, the imaging element of the TOF camera, the radiation detector, and the marker as viewed from a Z-axis direction,</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating an example of a distance image captured by the TOF camera,</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating an example of a flow of an SID derivation process of the console according to the first embodiment,</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram schematically illustrating an example of an overall configuration of a radiography system according to a second embodiment,</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating an example of a flow of an SID derivation process of a console according to the second embodiment, and</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating a modification example of the embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0032" num="0031">Hereinafter, embodiments of the disclosure will be described in detail with reference to the drawings. In addition, each of the embodiments does not limit the disclosure.</p><heading id="h-0008" level="1">First Embodiment</heading><p id="p-0033" num="0032">First, an example of the overall configuration of a radiography system according to this embodiment will be described. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example of the overall configuration of a radiography system <b>1</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the radiography system <b>1</b> according to this embodiment comprises a console <b>10</b>, a radiation emitting device <b>12</b>, a time-of-flight (TOF) camera <b>14</b>, and a radiography apparatus <b>16</b>. The console <b>10</b> according to this embodiment is an example of an information processing device according to the present disclosure. In addition, <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an aspect in which a radiographic image is captured in a state in which a subject W is standing up (standing state). However, the state of the subject W is not limited. For example, the subject W may be in a state (sitting state) in which it is sitting on a chair (including a wheelchair) and the like.</p><p id="p-0034" num="0033">The radiation emitting device <b>12</b> according to this embodiment comprises a radiation source <b>20</b> that irradiates the subject W, which is an example of an object to be imaged, with radiation R, such as X-rays, and a collimator <b>24</b> that limits an irradiation field of the radiation R emitted from the radiation source <b>20</b>. In addition, the radiation emitting device <b>12</b> comprises a radiation source control unit (not illustrated) that controls the radiation source <b>20</b> and the collimator <b>24</b>.</p><p id="p-0035" num="0034">A method by which a user, such as a doctor or a technician, instructs the radiation emitting device <b>12</b> to emit the radiation R is not limited. For example, in a case in which the radiation emitting device <b>12</b> is provided with an irradiation button or the like, the user, such as a radiology technician, may input an instruction to emit the radiation R with the irradiation button such that the radiation R is emitted from the radiation emitting device <b>12</b>. Further, for example, the user, such as the radiology technician, may operate the console <b>10</b> to input the instruction to emit the radiation R such that the radiation R is emitted from the radiation emitting device <b>12</b>.</p><p id="p-0036" num="0035">In a case in which the radiation emitting device <b>12</b> receives the instruction to emit the radiation R, it emits the radiation R from a focus <b>22</b> of a radiation tube of the radiation source <b>20</b> according to irradiation conditions, such as the set tube voltage, tube current, and irradiation period, under the control of the radiation source control unit. For example, in this embodiment, the irradiation field has a rectangular shape. Therefore, a rectangular-pyramid-shaped region that has the focus <b>22</b> as the apex and the irradiation field as the base is irradiated with the radiation R emitted from the focus <b>22</b>.</p><p id="p-0037" num="0036">Further, as illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the TOF camera <b>14</b> is provided in the vicinity of an exit port through which the radiation R is emitted from the radiation emitting device <b>12</b>. The TOF camera <b>14</b> is a camera that captures a distance image indicating a distance to the object to be imaged using the TOF method with an imaging element <b>28</b>. The TOF camera <b>14</b> according to this embodiment is an example of an imaging device and a distance image capture device according to the present disclosure. Specifically, the TOF camera <b>14</b> emits light, such as infrared rays, to the object to be imaged and measures the distance between the TOF camera <b>14</b> and the object to be imaged on the basis of the time until reflected light is received or a phase change between the emitted light and the received light. In the distance image captured by the TOF camera <b>14</b>, each pixel has distance information indicating the distance between the TOF camera <b>14</b> and the object to be imaged. In addition, in the TOF camera <b>14</b> according to this embodiment, the distance between the imaging element <b>28</b> and the object to be imaged is applied as the distance between the TOF camera <b>14</b> and the object to be imaged. Further, the distance image is an image from which the distance to the object to be imaged can be derived.</p><p id="p-0038" num="0037">The radiography apparatus <b>16</b> comprises a radiation detector <b>30</b>, a control unit <b>31</b>A, a storage unit <b>31</b>B, and an interface (I/F) unit <b>31</b>C.</p><p id="p-0039" num="0038">The radiation detector <b>30</b> has a function of generating a radiographic image. As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the radiation detector <b>30</b> is disposed in an imaging table <b>32</b>. In the radiography apparatus <b>16</b> according to this embodiment, in a case in which imaging is performed, the subject W is positioned on an imaging surface <b>32</b>A of the imaging table <b>32</b> by the user.</p><p id="p-0040" num="0039">The radiation detector <b>30</b> detects the radiation R transmitted through the subject W and the imaging table <b>32</b>, generates a radiographic image on the basis of the detected radiation R, and outputs image data indicating the generated radiographic image. The type of the radiation detector <b>30</b> according to this embodiment is not particularly limited. For example, the radiation detector <b>30</b> may be an indirect-conversion-type radiation detector that converts the radiation R into light and converts the converted light into charge or a direct-conversion-type radiation detector that directly converts the radiation R into charge.</p><p id="p-0041" num="0040">The control unit <b>31</b>A controls the overall operation of the radiography apparatus <b>16</b> under the control of the console <b>10</b>. The control unit <b>31</b>A comprises a central processing unit (CPU), a read only memory (ROM), and a random access memory (RAM) which are not illustrated. For example, various programs including an imaging processing program which is executed by the CPU and is used to perform control related to the capture of radiographic images are stored in the ROM in advance. The RAM temporarily stores various kinds of data.</p><p id="p-0042" num="0041">For example, image data of the radiographic image captured by the radiation detector <b>30</b> and various other kinds of information are stored in the storage unit <b>31</b>B. Specific examples of the storage unit <b>31</b>B include a hard disk drive (HDD) and a solid state drive (SSD). The I/F unit <b>31</b>C transmits and receives various kinds of information to and from the console <b>10</b> using wireless communication or wired communication. The image data of the radiographic image captured by the radiation detector <b>30</b> is transmitted to the console <b>10</b> through the I/F unit <b>31</b>C by wireless communication or wired communication.</p><p id="p-0043" num="0042">In addition, a base <b>36</b> of the imaging table <b>32</b> according to this embodiment is provided with a marker <b>38</b> for measuring the distance between the radiation source <b>20</b> and the radiation detector <b>30</b> (SID: source to image receptor distance; hereinafter, referred to as an &#x201c;SID&#x201d;). The marker <b>38</b> according to this embodiment is an example of a marker according to the present disclosure. The marker <b>38</b> is provided at a position that is not hidden by the positioned subject W. Specifically, in the capture of the distance image by the TOF camera <b>14</b>, the marker <b>38</b> is provided at a position that is not hidden by the subject W. In this embodiment, the size and shape of the marker <b>38</b> are predetermined. Further, in this embodiment, the SID means the length of a perpendicular line drawn from the focus <b>22</b> of the radiation source <b>20</b> to the detection surface <b>30</b>A of the radiation detector <b>30</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0044" num="0043">Meanwhile, the console <b>10</b> according to this embodiment has a function of controlling the radiation emitting device <b>12</b>, the TOF camera <b>14</b>, and the radiography apparatus <b>16</b> using, for example, an imaging order and various kinds of information acquired from a radiology information system (RIS) (not illustrated) or the like through a wireless communication local area network (LAN) or the like.</p><p id="p-0045" num="0044">For example, the console <b>10</b> according to this embodiment is a server computer. As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the console <b>10</b> comprises a control unit <b>50</b>, a storage unit <b>52</b>, an I/F unit <b>54</b>, an operation unit <b>56</b>, and a display unit <b>58</b>. The control unit <b>50</b>, the storage unit <b>52</b>, the I/F unit <b>54</b>, the operation unit <b>56</b>, and the display unit <b>58</b> are connected to each other through a bus <b>59</b>, such as a system bus or a control bus, such that they can transmit and receive various kinds of information.</p><p id="p-0046" num="0045">The control unit <b>50</b> according to this embodiment controls the overall operation of the console <b>10</b>. The control unit <b>50</b> comprises a CPU <b>50</b>A, a ROM <b>50</b>B, and a RAM <b>50</b>C. For example, various programs including an SID derivation processing program <b>51</b> executed by the CPU <b>50</b>A are stored in the ROM <b>50</b>B in advance. The RAM <b>50</b>C temporarily stores various kinds of data. The CPU <b>50</b>A according to this embodiment is an example of a processor according to the present disclosure, and the ROM <b>50</b>B according to this embodiment is an example of a memory according to the present disclosure. Further, the SID derivation processing program <b>51</b> according to this embodiment is an example of an information processing program according to the present disclosure.</p><p id="p-0047" num="0046">For example, the image data of the radiographic image captured by the radiography apparatus <b>16</b> and various other kinds of information (which will be described in detail below) are stored in the storage unit <b>52</b>. An HDD or an SSD is given as a specific example of the storage unit <b>52</b>.</p><p id="p-0048" num="0047">The operation unit <b>56</b> is used by the user to input, for example, instructions which are related to the capture of a radiographic image and include an instruction to emit the radiation R or various kinds of information. The operation unit <b>56</b> is not particularly limited. Examples of the operation unit <b>56</b> include various switches, a touch panel, a touch pen, and a mouse. The display unit <b>58</b> displays various kinds of information. In addition, the operation unit <b>56</b> and the display unit <b>58</b> may be integrated into a touch panel display.</p><p id="p-0049" num="0048">The I/F unit <b>54</b> transmits and receives various kinds of information to and from the radiography apparatus <b>16</b> and the RIS (not illustrated) using wireless communication or wired communication. In the radiography system <b>1</b> according to this embodiment, the console <b>10</b> receives the image data of the radiographic image captured by the radiography apparatus <b>16</b> from the radiography apparatus <b>16</b> through the I/F unit <b>54</b>, using wireless communication or wired communication.</p><p id="p-0050" num="0049">In addition, <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a functional block diagram illustrating an example of the functional configuration of the console <b>10</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the console <b>10</b> comprises an acquisition unit <b>60</b> and a derivation unit <b>62</b>. For example, in the console <b>10</b> according to this embodiment, the CPU <b>50</b>A of the control unit <b>50</b> executes the SID derivation processing program <b>51</b> stored in the ROM <b>50</b>B to function as the acquisition unit <b>60</b> and the derivation unit <b>62</b>.</p><p id="p-0051" num="0050">The acquisition unit <b>60</b> has a function of acquiring the distance image captured by the TOF camera <b>14</b>. For example, the acquisition unit <b>60</b> according to this embodiment acquires image data indicating the distance image captured by the TOF camera <b>14</b> from the TOF camera <b>14</b> through the I/F unit <b>31</b>C and the I/F unit <b>54</b>. The image data indicating the distance image acquired by the acquisition unit <b>60</b> is output to the derivation unit <b>62</b>.</p><p id="p-0052" num="0051">The derivation unit <b>62</b> has a function of deriving the SID. Specifically, the derivation unit <b>62</b> derives the distance between the TOF camera <b>14</b> and the marker <b>38</b> (hereinafter, referred to as a marker distance) from an image of a region (hereinafter, referred to as a marker region) corresponding to the marker <b>38</b> in the distance image. The marker region according to this embodiment is an example of a marker region according to the present disclosure, and the marker distance according to this embodiment is an example of a marker distance according to the present disclosure. Further, the derivation unit <b>62</b> derives the SID on the basis of the marker distance and information indicating the positional relationship between the radiation detector <b>30</b> and the marker <b>38</b>.</p><p id="p-0053" num="0052">Here, a method by which the derivation unit <b>62</b> according to this embodiment derives the SID will be described in detail with reference to <figref idref="DRAWINGS">FIGS. <b>4</b>A to <b>5</b></figref>. <figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is a schematic diagram illustrating an example of the positional relationship among the focus <b>22</b> of the radiation emitting device <b>12</b>, the imaging element <b>28</b> of the TOF camera <b>14</b>, the radiation detector <b>30</b>, and the marker <b>38</b> as viewed from the X-axis direction. Further, <figref idref="DRAWINGS">FIG. <b>4</b>B</figref> is a schematic diagram illustrating an example of the positional relationship among the focus <b>22</b> of the radiation emitting device <b>12</b>, the imaging element <b>28</b> of the TOF camera <b>14</b>, the radiation detector <b>30</b>, and the marker <b>38</b> as viewed from the Z-axis direction (from the side of an arrow U in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>). <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example of a distance image <b>70</b> captured by the TOF camera <b>14</b>. In addition, in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>, <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>, and <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the illustration of the subject W is omitted for convenience of illustration omission.</p><p id="p-0054" num="0053">A vector from the focus <b>22</b> to the radiation detector <b>30</b> which has the same length as the SID is represented by the addition of a vector from the focus <b>22</b> to the imaging element <b>28</b>, a vector r<sup>&#x2192; </sup>from the imaging element <b>28</b> to the marker <b>38</b>, and a vector from the marker <b>38</b> to the radiation detector <b>30</b>. Therefore, the length of the vector obtained by adding the vector from the focus <b>22</b> to the imaging element <b>28</b>, the vector r<sup>&#x2192; </sup>from the imaging element <b>28</b> to the marker <b>38</b>, and the vector from the marker <b>38</b> to the radiation detector <b>30</b> is the SID.</p><p id="p-0055" num="0054">In this embodiment, the SID is derived using a polar coordinate system in which the position of the imaging element <b>28</b> of the TOF camera <b>14</b> is set as the origin having the coordinates (0, 0, 0) and the position of the marker <b>38</b>, the position of the radiation detector <b>30</b>, and the position of the focus <b>22</b> of the radiation source <b>20</b> are represented by three parameters of (r, &#x3b8;, &#x3c6;).</p><p id="p-0056" num="0055">It is assumed that the positional relationship between the focus <b>22</b> and the imaging element <b>28</b> is (x<sub>1</sub>, y<sub>1</sub>, z<sub>1</sub>). For example, in the radiography system <b>1</b> according to this embodiment, the positional relationship (x<sub>1</sub>, y<sub>1</sub>, z<sub>1</sub>) does not change and is set to a fixed value. Further, in this embodiment, the positional relationship (x<sub>1</sub>, y<sub>1</sub>, z<sub>1</sub>) is stored in advance as information indicating the positional relationship between the focus <b>22</b> and the imaging element <b>28</b>, for example, in a storage unit (not illustrated) of the radiation emitting device <b>12</b>. The positional relationship (x<sub>1</sub>, y<sub>1</sub>, z<sub>1</sub>) according to this embodiment is an example of information indicating a positional relationship between an imaging device and a radiation source according to the present disclosure.</p><p id="p-0057" num="0056">Meanwhile, it is assumed that the positional relationship between the imaging element <b>28</b> and the marker <b>38</b> is (x<sub>2</sub>, y<sub>z</sub>, z<sub>2</sub>). For example, in the radiography system <b>1</b> according to this embodiment, the positional relationship (x<sub>2</sub>, y<sub>2</sub>, z<sub>2</sub>) changes and is not set to a fixed value.</p><p id="p-0058" num="0057">Further, it is assumed that the positional relationship between the marker <b>38</b> and the radiation detector <b>30</b> is (x<sub>3</sub>, y<sub>3</sub>, z<sub>3</sub>). For example, in the radiography system <b>1</b> according to this embodiment, the positional relationship (x<sub>3</sub>, y<sub>3</sub>, z<sub>3</sub>) does not change and is set to a fixed value. Further, in this embodiment, the positional relationship (x<sub>3</sub>, y<sub>3</sub>, z<sub>3</sub>) is stored in advance as information indicating the positional relationship between the marker <b>38</b> and the radiation detector <b>30</b> in, for example, the storage unit <b>31</b>B (not illustrated in <figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref>) of the radiography apparatus <b>16</b>. The positional relationship (x<sub>3</sub>, y<sub>3</sub>, z<sub>3</sub>) according to this embodiment is an example of information indicating the positional relationship between the radiation detector and the marker according to the present disclosure.</p><p id="p-0059" num="0058">Furthermore, it is assumed that is a vector from the imaging element <b>28</b> (0, 0, 0) to the marker <b>38</b> is r<sup>&#x2192; </sup>and the distance between the imaging element <b>28</b> and the marker <b>38</b> is r. Moreover, it is assumed that an intersection point between the foot of a perpendicular line drawn from the marker <b>38</b> to an X-Y plane of Z=0 through the imaging element <b>28</b> (0, 0, 0) and the X-Y plane is H. In addition, it is assumed that a vector from the imaging element <b>28</b> to the intersection point H is h<sup>&#x2192;</sup>. In <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>, the vector h<sup>&#x2192; </sup>appears to overlap the vector r<sup>&#x2192;</sup>.</p><p id="p-0060" num="0059">The angle &#x3b8; that defines the polar coordinate system is an angle formed between the vector r<sup>&#x2192; </sup>connecting the imaging element <b>28</b> (0, 0, 0) and the marker <b>38</b> and the z-axis. In addition, the angle &#x3c6; that defines the polar coordinate system is an angle formed between the vector h<sup>&#x2192; </sup>and the x-axis. The angle &#x3b8; and the angle &#x3c6; can be derived from the position of a marker image <b>72</b> indicating the marker <b>38</b> in the distance image <b>70</b>. For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the angle &#x3b8; is reflected in an angle &#x3b8;<b>1</b> formed between a straight line connecting a center <b>82</b> of the distance image <b>70</b> corresponding to the position of the imaging element <b>28</b> and the marker image <b>72</b> and the z-axis passing through the center <b>82</b>. Specifically, the angles can be derived from the number of pixels of the marker image <b>72</b> in each of the vertical direction (z direction) and the horizontal direction (x direction) in the distance image <b>70</b> and the angle of view of the TOF camera <b>14</b>. In addition, the marker image <b>72</b> according to this embodiment is an example of an image of the marker region corresponding to the marker according to the present disclosure.</p><p id="p-0061" num="0060">The position (r, &#x3b8;, &#x3c6;) of the marker <b>38</b> in the polar coordinate system can be converted into a rectangular coordinate system (x<sub>2</sub>, y<sub>2</sub>, z<sub>2</sub>) by the following Expression (1) to (3).</p><p id="p-0062" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>x</i><sub>2</sub><i>=r</i>&#xd7;sin &#x3b8;&#xd7;cos &#x3c6;&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0063" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>y</i><sub>2</sub><i>=r</i>&#xd7;sin &#x3b8;&#xd7;sin &#x3c6;&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0064" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>z</i><sub>2</sub><i>=r</i>&#xd7;cos &#x3b8;&#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0065" num="0061">Therefore, the SID can be derived from the positional relationship (x<sub>1</sub>, y<sub>1</sub>, z<sub>1</sub>) between the focus <b>22</b> and the imaging element <b>28</b> and the positional relationship (x<sub>2</sub>, y<sub>2</sub>, z<sub>2</sub>) between the imaging element <b>28</b> and the marker <b>38</b>, and the positional relationship (x<sub>3</sub>, y<sub>3</sub>, z<sub>3</sub>) between the marker <b>38</b> and the radiation detector <b>30</b> by the following Expression (4).</p><p id="p-0066" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>SID</i>=&#x221a;{square root over (<i>x</i><sup>2</sup><i>+y</i><sup>2</sup><i>+z</i><sup>2</sup>)}&#x2003;&#x2003;(4)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0067" num="0062">(where (x, y, z)=(x<sub>1</sub>+x<sub>2</sub>+x<sub>3</sub>, y<sub>1</sub>+y<sub>2</sub>+y<sub>3</sub>, z<sub>1</sub>+z<sub>2</sub>+z<sub>3</sub>))</p><p id="p-0068" num="0063">In addition, as described above, since the SID is the distance of the perpendicular line from the focus <b>22</b> to the detection surface <b>30</b>A of the radiation detector <b>30</b>, it may be derived by the following Expression (5).</p><p id="p-0069" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>SID=y</i><sub>1</sub><i>+y</i><sub>2</sub><i>+y</i><sub>3 </sub>&#x2003;&#x2003;(5)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0070" num="0064">Further, the derivation unit <b>62</b> according to this embodiment has a function of deriving a body thickness of the positioned subject W. For example, in this embodiment, a value obtained by subtracting the distance between the imaging element <b>28</b> and the subject W and the distance between the detection surface <b>30</b>A of the radiation detector <b>30</b> and the imaging surface <b>32</b>A of the imaging table <b>32</b> from the derived SID is derived as the body thickness of the subject W. The distance between the detection surface <b>30</b>A of the radiation detector <b>30</b> and the imaging surface <b>32</b>A of the imaging table <b>32</b> is a value obtained from, for example, the design values of the radiation detector <b>30</b> and the imaging table <b>32</b> and is stored in advance, for example, in the storage unit <b>31</b>B of the radiography apparatus <b>16</b> in this embodiment. In addition, in a case in which a predetermined condition is satisfied, for example, in a case in which the distance between the detection surface <b>30</b>A of the radiation detector <b>30</b> and the imaging surface <b>32</b>A of the imaging table <b>32</b> is sufficiently short, the distance may be ignored in the derivation of the body thickness.</p><p id="p-0071" num="0065">Next, the operation of the console <b>10</b> according to this embodiment will be described with reference to the drawings.</p><p id="p-0072" num="0066">In the console <b>10</b> according to this embodiment, the CPU <b>50</b>A of the control unit <b>50</b> executes the SID derivation processing program <b>51</b> stored in the ROM <b>50</b>B to perform an SID derivation process whose example is illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating an example of the flow of the SID derivation process performed in the console <b>10</b> according to this embodiment. In addition, the timing when the CPU <b>50</b>A performs the SID derivation process is not limited, and the CPU <b>50</b>A may perform the SID derivation process at any timing. For example, the SID derivation process may be performed at the timing when an instruction input from the user by the operation of the operation unit <b>56</b> after the positioning of the subject W ends is received or the timing when an instruction to emit the radiation R from the user is received.</p><p id="p-0073" num="0067">In Step S<b>100</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the acquisition unit <b>60</b> acquires the distance image from the TOF camera <b>14</b>. Specifically, the acquisition unit <b>60</b> instructs the TOF camera <b>14</b> to capture a distance image and acquires the distance image captured by the TOF camera <b>14</b> on the basis of the instruction through the I/F unit <b>54</b>. The distance image acquired by the acquisition unit <b>60</b> is output to the derivation unit <b>62</b>.</p><p id="p-0074" num="0068">Then, in Step S<b>102</b>, the derivation unit <b>62</b> determines whether or not positional information indicating the position of the marker region corresponding to the marker <b>38</b> in the distance image <b>70</b> is stored in the storage unit <b>52</b>. Specifically, the positional information of the marker region is information indicating the position of the marker image <b>72</b> in the distance image <b>70</b> and the size of the marker image <b>72</b>. For example, in this embodiment, the distance image <b>70</b> including the marker image <b>72</b> is adopted as the positional information of the marker region. In this embodiment, in a case in which the SID is derived, the positional information of the marker region is stored in the storage unit <b>52</b> to be associated with the derived SID, which will be described in detail below. Therefore, the derivation unit <b>62</b> determines whether or not the positional information of the marker region is stored in the storage unit <b>52</b> in association with the SID used in the previous process. In a case in which the positional information of the marker region is not stored in the storage unit <b>52</b>, for example, in a case in which the radiography system <b>1</b> is operated for the first time to capture a radiographic image, the determination result in Step S<b>102</b> is &#x201c;No&#x201d;, and the process proceeds to Step S<b>112</b>. On the other hand, in a case in which the positional information of the marker region is stored in the storage unit <b>52</b>, the determination result in Step S<b>102</b> is &#x201c;Yes&#x201d;, and the process proceeds to Step S<b>104</b>.</p><p id="p-0075" num="0069">In Step S<b>104</b>, the derivation unit <b>62</b> acquires the positional information of the marker region from the storage unit <b>52</b>. Then, in Step S<b>106</b>, the derivation unit <b>62</b> determines whether or not the position of the marker region in the previous distance image <b>70</b> is the same as the position of the marker region in the current distance image <b>70</b>. Specifically, it is determined whether or not the position and size (the number of pixels) of the marker image <b>72</b> in the previous distance image <b>70</b> used to derive the SID, which is the positional information of the marker region acquired in Step S<b>104</b>, are the same as the position and size of the marker image <b>72</b> in the current distance image <b>70</b> which has been captured by the TOF camera <b>14</b> and acquired in Step S<b>100</b>.</p><p id="p-0076" num="0070">In addition, in this embodiment, a method of extracting an image corresponding to the shape of the marker <b>38</b> in the distance image <b>70</b> is adopted as the method by which the derivation unit <b>62</b> specifies the marker image <b>72</b> from the distance image <b>70</b>. In a case in which the shape of the marker <b>38</b> is a characteristic shape such as a triangular shape, an image corresponding to the characteristics may be extracted from the distance image <b>70</b>. Further, even in a case in which the shape of the marker <b>38</b> is a general shape such as a rectangular shape, a condition for defining the shape may be defined. For example, in a case in which the marker <b>38</b> has a rectangular shape, a width-to-height ratio may be defined. An image in which the width-to-height ratio is a predetermined ratio may be extracted from the distance image <b>70</b>.</p><p id="p-0077" num="0071">In a case in which the position of the marker region in the previous distance image <b>70</b> is the same as the position of the marker region in the current distance image <b>70</b>, the determination result in Step S<b>106</b> is &#x201c;Yes&#x201d;, and the process proceeds to Step S<b>108</b>. In a case in which the position of the marker region in the previous distance image <b>70</b> is the same as the position of the marker region in the current distance image <b>70</b>, the SID derived from the previous distance image <b>70</b> is equal to the SID derived from the current distance image <b>70</b>. Therefore, the previously derived SID can be applied to the current capture of the radiographic image without newly deriving the SID. Therefore, in Step S<b>108</b>, the derivation unit <b>62</b> acquires the SID stored in the storage unit <b>52</b> in association with the positional information of the marker region from the storage unit <b>52</b> and then proceeds to Step S<b>122</b>.</p><p id="p-0078" num="0072">On the other hand, in a case in which the position of the marker region in the previous distance image <b>70</b> is different from the position of the marker region in the current distance image <b>70</b>, the determination result in Step S<b>106</b> is &#x201c;No&#x201d;, and the process proceeds to Step S<b>110</b>. In Step S<b>110</b>, the derivation unit <b>62</b> starts outputting information indicating a predetermined warning. In addition, the specific content of the warning, the output destination of the warning, and a warning method are not particularly limited. For example, as the content of the warning, the fact that preparations are being made may be displayed on the display unit <b>58</b> in at least one of a visible display manner or an audible display manner.</p><p id="p-0079" num="0073">Then, in Step S<b>112</b>, the derivation unit <b>62</b> acquires information indicating the positional relationship between the TOF camera <b>14</b> and the radiation source <b>20</b>. Specifically, in this embodiment, as described above, the positional relationship (x<sub>1</sub>, y<sub>1</sub>, z<sub>1</sub>) between the focus <b>22</b> and the imaging element <b>28</b> is acquired.</p><p id="p-0080" num="0074">Then, in Step S<b>114</b>, the acquisition unit <b>60</b> acquires information indicating the positional relationship between the marker <b>38</b> and the radiation detector <b>30</b>. Specifically, in this embodiment, as described above, the positional relationship (x<sub>3</sub>, y<sub>3</sub>, z<sub>3</sub>) between the marker <b>38</b> and the radiation detector <b>30</b> is acquired.</p><p id="p-0081" num="0075">Then, in Step S<b>116</b>, the derivation unit <b>62</b> derives the marker distance from the TOF camera <b>14</b> (imaging element <b>28</b>) to the marker <b>38</b>. Specifically, the marker distance is derived on the basis of the pixel value of an image corresponding to the marker image <b>72</b> included in the distance image <b>70</b> acquired in Step S<b>100</b>. Then, in Step S<b>118</b>, the derivation unit <b>62</b> derives the SID using the above-described Expression (4) or (5) as described above.</p><p id="p-0082" num="0076">Then, in Step S<b>120</b>, the derivation unit <b>62</b> stores the SID derived in the Step S<b>118</b> and the positional information of the marker region in the storage unit <b>52</b> to be associated with each other. As described above, for example, the derivation unit <b>62</b> according to this embodiment stores the SID derived in Step S<b>118</b> in the storage unit <b>52</b> to be associated with the distance image <b>70</b> acquired in Step S<b>100</b>.</p><p id="p-0083" num="0077">In Step S<b>122</b> following Step S<b>108</b> or Step S<b>120</b>, the acquisition unit <b>60</b> determines whether or not a warning is being issued. In a case in which the information indicating the warning is output by the process in Step S<b>110</b>, the determination result in Step S<b>122</b> is &#x201c;Yes&#x201d;, and the process proceeds to Step S<b>124</b>. In Step S<b>124</b>, the derivation unit <b>62</b> stops outputting the information indicating the warning and then proceeds to Step S<b>126</b>. On the other hand, in a case in which the information indicating the warning is not output, the determination result in Step S<b>122</b> is &#x201c;No&#x201d;, and the process proceeds to Step S<b>126</b>.</p><p id="p-0084" num="0078">In Step S<b>126</b>, the derivation unit <b>62</b> derives an subject distance from the TOF camera <b>14</b> to the subject W. Specifically, the derivation unit <b>62</b> derives the distance from the imaging element <b>28</b> to a body surface of the subject W facing the radiation emitting device <b>12</b> on the basis of the pixel value of an image corresponding to the subject W included in the distance image <b>70</b> acquired in Step S<b>100</b>. In addition, the subject distance derived here may be, for example, the distance between the position of the subject W facing the imaging element <b>28</b> and the imaging element <b>28</b> or the distance between the imaging element <b>28</b> and the position of the subject W having the largest thickness in the capture range of the radiographic image. The distance to which position of the subject W the subject distance is set as is not limited, and any subject distance may be used.</p><p id="p-0085" num="0079">Then, in Step S<b>128</b>, the derivation unit <b>62</b> acquires the distance between the detection surface <b>30</b>A of the radiation detector <b>30</b> and the imaging surface <b>32</b>A of the imaging table <b>32</b> as described above. Then, in Step S<b>130</b>, the derivation unit <b>62</b> derives the body thickness of the subject W as described above. Specifically, the derivation unit <b>62</b> subtracts the subject distance derived in Step S<b>126</b> and the distance between the detection surface <b>30</b>A of the radiation detector <b>30</b> and the imaging surface <b>32</b>A of the imaging table <b>32</b> acquired in Step S<b>128</b> from the SID acquired in Step S<b>108</b> or the SID derived in Step S<b>118</b>.</p><p id="p-0086" num="0080">The body thickness of the subject W derived in this way is used, for example, for setting imaging conditions. Examples of the imaging conditions include the values of the tube voltage and the tube current of the radiation source <b>20</b> of the radiation emitting device <b>12</b> and the irradiation time of the radiation R which are imaging conditions determined by the body thickness and imaging part of the subject W. Therefore, the derivation unit <b>62</b> outputs information indicating the derived body thickness to a predetermined output destination in order to set the imaging conditions. In a case in which Step S<b>130</b> ends in this way, this SID derivation process ends.</p><p id="p-0087" num="0081">As described above, in this embodiment, the derivation unit <b>62</b> derives the marker distance between the TOF camera <b>14</b> and the marker <b>38</b> from the image of the marker region corresponding to the marker <b>38</b> in the distance image captured by the TOF camera <b>14</b>. Further, the derivation unit <b>62</b> derives the SID on the basis of the derived marker distance and information indicating the positional relationship between the radiation detector <b>30</b> and the marker <b>38</b>. Therefore, according to the console <b>10</b> of this embodiment, the SID can be measured by the marker <b>38</b> that is provided at a position away from the radiation detector <b>30</b> and the imaging table <b>32</b>. Therefore, it is possible to appropriately measure the SID.</p><p id="p-0088" num="0082">In addition, in this embodiment, the aspect in which the derivation unit <b>62</b> extracts an image corresponding to the shape of the marker <b>38</b> from the distance image <b>70</b> to specify the marker image <b>72</b> and the marker region. However, a method for specifying the marker image <b>72</b> and the marker region from the distance image <b>70</b> is not limited to this embodiment. For example, a visible light camera (see a visible light camera <b>15</b> in a second embodiment of <figref idref="DRAWINGS">FIG. <b>7</b></figref>) may be provided together with the TOF camera <b>14</b>, and the marker image <b>72</b> and the marker region may be specified using a visible light image captured by the visible light camera. In this case, a position on the distance image <b>70</b> and a position on the visible light image captured by the visible light camera are aligned in advance on the basis of a position in the real space. Then, image recognition is applied to the visible light image captured by the visible light camera, an image indicating the marker <b>38</b> is detected from the visible light image, and an image and a region in the distance image <b>70</b> corresponding to the position of the marker image <b>72</b> and the marker region specified by the detected image are used as the marker image <b>72</b> and the marker region.</p><heading id="h-0009" level="1">Second Embodiment</heading><p id="p-0089" num="0083">In the first embodiment, the aspect in which the SID is derived using the distance image captured by the TOF camera <b>14</b> has been described. In contrast, in this embodiment, an aspect in which the SID is derived using a visible light image captured by a visible light camera will be described. In addition, for a console <b>10</b>, a radiation emitting device <b>12</b>, and a radiation detector <b>30</b> according to this embodiment, the detailed description of the same configurations and operations as those in the first embodiment will be omitted.</p><p id="p-0090" num="0084"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating an example of the overall configuration of a radiography system <b>1</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the radiography system <b>1</b> according to this embodiment comprises a visible light camera <b>15</b> having an imaging element <b>29</b> instead of the TOF camera <b>14</b> according to the first embodiment. The visible light camera <b>15</b> is a so-called general camera and captures a visible light image. The visible light camera <b>15</b> according to this embodiment is an example of the imaging device and a visible light image capture device according to the present disclosure. Specifically, the visible light camera <b>15</b> receives visible light reflected by an object to be imaged using the imaging element <b>29</b> and captures a visible light image on the basis of the received visible light.</p><p id="p-0091" num="0085">In addition, an acquisition unit <b>60</b> according to this embodiment has a function of acquiring the visible light image captured by the visible light camera <b>15</b>. For example, the acquisition unit <b>60</b> according to this embodiment acquires image data indicating the visible light image captured by the visible light camera <b>15</b> from the visible light camera <b>15</b> through the I/F unit <b>54</b>. The image data indicating the visible light image acquired by the acquisition unit <b>60</b> is output to a derivation unit <b>62</b>.</p><p id="p-0092" num="0086">Further, the derivation unit <b>62</b> according to this embodiment has a function of deriving the SID on the basis of the visible light image and derives the marker distance from the image of the marker region in the visible light image.</p><p id="p-0093" num="0087">Specifically, the size of the marker region in the visible light image captured by the visible light camera <b>15</b> in a state in which the marker distance is set as a reference value, specifically, the position and size (the number of pixels) of the marker region in the visible light image are acquired as a reference size in advance. In other words, the reference size of the marker region associated with the reference value of the marker distance is acquired in advance and stored in, for example, the storage unit <b>31</b>B of the radiography apparatus <b>16</b>. The derivation unit <b>62</b> derives the marker distance on the basis of the size of the marker region in the visible light image acquired by the acquisition unit <b>60</b> and the reference size of the marker region associated with the reference value of the marker distance. For example, in a case in which the size of the marker region in the visible light image acquired by the acquisition unit <b>60</b> is 1.5 times the reference size of the marker region, the derivation unit <b>62</b> derives a value that is one third of the reference value of the marker distance as the current marker distance. The derivation unit <b>62</b> derives the SID using the derived marker distance in the same manner as that in the first embodiment.</p><p id="p-0094" num="0088">Further, the operation of the console <b>10</b> according to this embodiment, specifically, an SID derivation process performed by the console <b>10</b> will be described.</p><p id="p-0095" num="0089"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating an example of the flow of the SID derivation process performed in the console <b>10</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the SID derivation process according to this embodiment includes a process in Step S<b>101</b> instead of Step S<b>100</b> in the SID derivation process (see <figref idref="DRAWINGS">FIG. <b>6</b></figref>) according to the first embodiment.</p><p id="p-0096" num="0090">In Step S<b>101</b> of <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the acquisition unit <b>60</b> acquires a visible light image from the visible light camera <b>15</b> as described above. Specifically, the acquisition unit <b>60</b> instructs the visible light camera <b>15</b> to capture a visible light image and acquires a visible light image captured by the visible light camera <b>15</b> on the basis of the instruction through the I/F unit <b>54</b>. The visible light image acquired by the acquisition unit <b>60</b> is output to the derivation unit <b>62</b>.</p><p id="p-0097" num="0091">Further, the SID derivation process according to this embodiment includes processes in Steps S<b>115</b> and S<b>117</b> instead of Step S<b>116</b> of the SID derivation process (see <figref idref="DRAWINGS">FIG. <b>6</b></figref>) according to the first embodiment.</p><p id="p-0098" num="0092">In Step S<b>115</b>, the derivation unit <b>62</b> acquires the reference value of the marker distance and the reference size of the marker region as described above. Then, in Step S<b>117</b>, the derivation unit <b>62</b> derives the marker distance as described above. Specifically, the size of the marker region in the visible light image acquired in Step S<b>101</b> is derived. Then, the derived size of the marker region is compared with the reference size of the marker region acquired in Step S<b>115</b>. Further, the marker distance is derived on the basis of the comparison result and the reference value of the marker distance.</p><p id="p-0099" num="0093">As described above, in this embodiment, the SID can be derived using the visible light image captured by the visible light camera <b>15</b>. Therefore, according to the console <b>10</b> of this embodiment, the SID can be measured by the marker <b>38</b> that is provided at a position away from the radiation detector <b>30</b> and the imaging table <b>32</b>. Therefore, it is possible to appropriately measure the SID.</p><p id="p-0100" num="0094">As described above, the console <b>10</b> according to each of the above-described embodiments comprises the CPU <b>50</b>A as at least one processor and the ROM <b>50</b>B storing commands that can be executed by the CPU <b>50</b>A. The CPU <b>50</b>A acquires the distance image or the visible light image obtained by imaging the marker <b>38</b> for measuring the SID as the object to be imaged with the TOF camera <b>14</b> or the visible light camera <b>15</b>. In addition, the CPU <b>50</b>A derives the marker distance between the TOF camera <b>14</b> or the visible light camera <b>15</b> and the marker <b>38</b> from the image of the marker region corresponding to the marker <b>38</b> in the acquired distance image or visible light image. Further, the CPU <b>50</b>A derives the SID on the basis of the derived marker distance and information indicating the positional relationship between the acquisition unit <b>60</b> and the marker <b>38</b>.</p><p id="p-0101" num="0095">As described above, according to the console <b>10</b> of this embodiment, it is possible to measure the SID on the basis of the distance image or the visible light image obtained by imaging the marker <b>38</b> as the object to be imaged.</p><p id="p-0102" num="0096">Therefore, according to the console <b>10</b> of this embodiment, the SID can be measured by the marker <b>38</b> that is provided at a position away from the radiation detector <b>30</b> and the imaging table <b>32</b>. Therefore, it is possible to appropriately measure the SID. For example, even in a case in which the radiation detector <b>30</b> or the imaging table <b>32</b> is hidden by the subject, it is possible to measure the SID.</p><p id="p-0103" num="0097">In addition, in each of the above-described embodiments, the aspect in which the console <b>10</b>, the radiation emitting device <b>12</b>, and the radiography apparatus <b>16</b> are stationary systems in the radiography system <b>1</b> has been described. However, the radiography system <b>1</b> is not limited to this embodiment. For example, a mobile cart, that is, a nursing cart may be used as the radiography system <b>1</b>. Further, in each of the above-described embodiments, since the marker <b>38</b> is fixed to the base <b>36</b> of the imaging table <b>32</b>, the disposition of the marker <b>38</b> with respect to the radiation detector <b>30</b> is fixed. Meanwhile, in the case of the nursing cart or the like, each of the radiation detector <b>30</b> and the marker <b>38</b> is handled individually. Therefore, the disposition of the marker <b>38</b> with respect to the radiation detector <b>30</b> may not be fixed. In this case, a jig having a predetermined length in which the marker <b>38</b> is disposed may be attached to an attachment position of a housing or the like that includes the radiation detector <b>30</b>, and the SID may be derived using the distance image or the captured image as in each of the above-described embodiments.</p><p id="p-0104" num="0098">Further, for example, as in the example illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, in a case in which a distance image <b>70</b> is obtained by imaging the radiation detector <b>30</b> or the detection surface <b>30</b>A of the radiation detector <b>30</b> corresponding to the disposition of the radiation detector <b>30</b>, the positional relationship between the marker <b>38</b> and the radiation detector <b>30</b> may be derived from the distance image <b>70</b>. Specifically, it is assumed that, in the polar coordinate system described in the first embodiment, the positional relationship between the marker <b>38</b> and the TOF camera <b>14</b> is (x<sub>m</sub>, y<sub>m</sub>, z<sub>m</sub>), and the positional relationship between the radiation detector <b>30</b> and the TOF camera <b>14</b> is (x<sub>p</sub>, y<sub>p</sub>, z<sub>p</sub>). These positional relationships are obtained from a marker image <b>72</b> and a detector image <b>73</b> of the radiation detector <b>30</b> in the distance image. The positional relationship (x<sub>3</sub>, y<sub>3</sub>, z<sub>3</sub>) between the marker <b>38</b> and the radiation detector <b>30</b> is obtained by the following Expression (6).</p><p id="p-0105" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>(<i>X</i><sub>3</sub><i>, y</i><sub>3</sub><i>, z</i><sub>3</sub>)=(<i>x</i><sub>p</sub><i>, y</i><sub>p</sub><i>,z</i><sub>p</sub>)&#x2212;(<i>x</i><sub>m</sub><i>, y</i><sub>m</sub><i>, z</i><sub>m</sub>) &#x2003;&#x2003;(6)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0106" num="0099">Furthermore, in each of the above-described embodiments, the aspect in which the distance image is captured by the TOF method using the TOF camera has been described as an example of the aspect of capturing the distance image. However, the distance image capture device for capturing the distance image is not limited to the TOF camera. For example, the following aspect may be used: a distance image capture device that irradiates an object to be imaged with infrared light having a pattern and captures a distance image corresponding to reflected light from the object to be imaged is used, and a structured light method is applied to capture the distance image. Further, for example, a depth-from-defocus (DFD) method that restores the distance on the basis of the degree of blurring of an edge region included in the distance image may be applied. In the case of this aspect, for example, an aspect is known which uses a distance image captured by a monocular camera using a color aperture filter.</p><p id="p-0107" num="0100">In addition, in each of the above-described embodiments, the aspect in which the TOF camera <b>14</b> or the visible light camera <b>15</b> is provided in the radiation emitting device <b>12</b> has been described. However, the position where the TOF camera <b>14</b> or the visible light camera <b>15</b> is provided is not limited to this aspect. The position of the TOF camera <b>14</b> or the visible light camera <b>15</b> is not limited, and the TOF camera <b>14</b> or the visible light camera <b>15</b> may be disposed at any position where the marker <b>38</b> can be imaged. The TOF camera <b>14</b> or the visible light camera <b>15</b> may be provided separately from the radiation emitting device <b>12</b>.</p><p id="p-0108" num="0101">Further, in each of the above-described embodiments, the aspect in which the console <b>10</b> is an example of the information processing device according to the present disclosure has been described. However, devices other than the console <b>10</b> may have the functions of the information processing device according to the present disclosure. In other words, for example, the radiation emitting device <b>12</b>, the radiography apparatus <b>16</b>, or an external device other than the console <b>10</b> may have some or all of the functions of the acquisition unit <b>60</b> and the derivation unit <b>62</b>.</p><p id="p-0109" num="0102">In each of the above-described embodiments, for example, the following various processors can be used as a hardware structure of processing units performing various processes such as the acquisition unit <b>60</b> and the derivation unit <b>62</b>. The various processors include, for example, a programmable logic device (PLD), such as a field programmable gate array (FPGA), that is a processor whose circuit configuration can be changed after manufacture and a dedicated electric circuit, such as an application specific integrated circuit (ASIC), that is a processor having a dedicated circuit configuration designed to perform a specific process, in addition to the CPU that is a general-purpose processor which executes software (program) to function as various processing units as described above.</p><p id="p-0110" num="0103">One processing unit may be configured by one of the various processors or a combination of two or more processors of the same type or different types (for example, a combination of a plurality of FPGAs or a combination of a CPU and an FPGA). In addition, a plurality of processing units may be configured by one processor.</p><p id="p-0111" num="0104">A first example of the configuration in which a plurality of processing units are configured by one processor is an aspect in which one processor is configured by a combination of one or more CPUs and software and functions as a plurality of processing units. A representative example of this aspect is a client computer or a server computer. A second example of the configuration is an aspect in which a processor that implements the functions of the entire system including a plurality of processing units using one integrated circuit (IC) chip is used. A representative example of this aspect is a system-on-chip (SoC). As such, various processing units are configured by using one or more of the various processors as a hardware structure.</p><p id="p-0112" num="0105">In addition, specifically, an electric circuit (circuitry) obtained by combining circuit elements, such as semiconductor elements, can be used as the hardware structure of the various processors.</p><p id="p-0113" num="0106">In each of the above-described embodiments, the aspect in which the SID derivation processing program <b>51</b> is stored (installed) in the storage unit <b>52</b> in advance has been described. However, the present disclosure is not limited thereto. The SID derivation processing program <b>51</b> may be recorded on a recording medium, such as a compact disc read only memory (CD-ROM), a digital versatile disc read only memory (DVD-ROM), or a universal serial bus (USB) memory, and then provided. In addition, the SID derivation processing program <b>51</b> may be downloaded from an external device through the network.</p><p id="p-0114" num="0107">The disclosure of JP2020-064479 filed on Mar. 31, 2020 is incorporated herein by reference in its entirety.</p><p id="p-0115" num="0108">All of the documents, the patent applications, and the technical standards described in the specification are incorporated by reference herein to the same extent as it is specifically and individually stated that individual documents, patent applications, and technical standards are incorporated by reference.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An information processing device comprising:<claim-text>at least one processor; and</claim-text><claim-text>a memory that stores commands executable by the processor, wherein the processor acquires a captured image obtained by imaging a marker for measuring a distance between a radiation source and a radiation detector as an object to be imaged using an imaging device, derives a marker distance between the imaging device and the marker from an image of a marker region corresponding to the marker in the acquired captured image, and derives the distance between the radiation source and the radiation detector on the basis of the derived marker distance and information indicating a positional relationship between the radiation detector and the marker.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor derives the distance between the radiation source and the radiation detector further on the basis of information indicating a positional relationship between the imaging device and the radiation source.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the object to be imaged includes a subject that is positioned between the radiation source and the radiation detector, and the processor derives a subject distance between the imaging device and the subject from an image of a subject region corresponding to the subject in the acquired captured image and derives a body thickness of the subject on the basis of the derived subject distance and the distance between the radiation source and the radiation detector.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the object to be imaged includes a subject that is positioned between the radiation source and the radiation detector, and the processor derives a subject distance between the imaging device and the subject from an image of a subject region corresponding to the subject in the acquired captured image and derives a body thickness of the subject on the basis of the derived subject distance, the distance between the radiation source and the radiation detector, and a distance between the radiation detector and the subject.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the imaging device is a distance image capture device that captures a distance image indicating a distance to the object to be imaged as the captured image, and the processor derives a distance indicated by the image of the marker region corresponding to the marker in the distance image as the marker distance.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The information processing device according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the processor specifies the marker region in the distance image on the basis of a shape of the marker.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The information processing device according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the processor acquires a visible light image obtained by imaging the marker as the object to be imaged using a visible light image capture device that captures the visible light image of the object to be imaged and sets, as the marker region, a region of an image, which corresponds to a position of the marker specified by the image of the marker in the visible light image, in the distance image.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The information processing device according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the distance image capture device captures the distance image using a time-of-flight (TOF) method.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the imaging device is a visible light image capture device that captures a visible light image of the object to be imaged as the captured image, and the processor derives the marker distance on the basis of a size of the marker region in the visible light image and a reference size of the marker region associated with a reference value of the marker distance.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor stores the derived distance between the radiation source and the radiation detector in a storage device and acquires the distance between the radiation source and the radiation detector from the storage device to derive the distance between the radiation source and the radiation detector, without deriving the marker distance, in a case in which a position of the marker region specified from the captured image acquired currently is the same as a position of the marker region specified from the captured image acquired previously.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor stores the derived distance between the radiation source and the radiation detector in a storage device and outputs information indicating a warning for a period until the marker distance is derived from the captured image acquired currently in a case in which a position of the marker region specified from the captured image acquired currently is different from a position of the marker region specified from the captured image acquired previously.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. An information processing method executed by a computer, the information processing method comprising:<claim-text>acquiring a captured image obtained by imaging a marker for measuring a distance between a radiation source and a radiation detector as an object to be imaged using an imaging device;</claim-text><claim-text>deriving a marker distance between the imaging device and the marker from an image of a marker region corresponding to the marker in the acquired captured image; and</claim-text><claim-text>deriving the distance between the radiation source and the radiation detector on the basis of the derived marker distance and information indicating a positional relationship between the radiation detector and the marker.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A non-transitory computer-readable storage medium storing an information processing program that causes a computer to execute a process comprising:<claim-text>acquiring a captured image obtained by imaging a marker for measuring a distance between a radiation source and a radiation detector as an object to be imaged using an imaging device;</claim-text><claim-text>deriving a marker distance between the imaging device and the marker from an image of a marker region corresponding to the marker in the acquired captured image; and</claim-text><claim-text>deriving the distance between the radiation source and the radiation detector on the basis of the derived marker distance and information indicating a positional relationship between the radiation detector and the marker.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003535A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003535</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17779905</doc-number><date>20200227</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>C</subclass><main-group>21</main-group><subgroup>34</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>51</main-group><subgroup>07</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>51</main-group><subgroup>222</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>C</subclass><main-group>21</main-group><subgroup>3438</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20220501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>51</main-group><subgroup>07</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>51</main-group><subgroup>222</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>017</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>50</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">RENDEZVOUS ASSISTANCE SYSTEM AND RENDEZVOUS ASSISTANCE METHOD</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Mitsubishi Electric Corporation</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MIYAHARA</last-name><first-name>Tadashi</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>SHIMOTANI</last-name><first-name>Mitsuo</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Mitsubishi Electric Corporation</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/008012</doc-number><date>20200227</date></document-id><us-371c12-date><date>20220525</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The purpose of the present disclosure is to achieve smooth rendezvous of a vehicle and a user even if there are numerous persons at a meeting point. A rendezvous assistance system includes a mobile terminal carried by a user who wants to rendezvous with a dispatched vehicle, and a rendezvous assistance device that assists rendezvous of the dispatched vehicle and the user at a meeting point. The rendezvous assistance device includes a message generator that generates a message that requests the user to do a gesture, a vehicle controller that determines timing of transmission of the message, and a vehicle communicator that transmits a message to the mobile terminal. The mobile terminal includes a mobile communicator that receives a message from the rendezvous assistance device and a notification unit that notifies the user of a request to do a gesture in accordance with the message.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="112.10mm" wi="83.57mm" file="US20230003535A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="196.43mm" wi="146.98mm" file="US20230003535A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="137.50mm" wi="112.18mm" file="US20230003535A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="203.96mm" wi="164.17mm" file="US20230003535A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="192.87mm" wi="114.89mm" file="US20230003535A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="155.19mm" wi="163.66mm" file="US20230003535A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="149.94mm" wi="163.66mm" file="US20230003535A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="149.27mm" wi="163.58mm" file="US20230003535A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="163.75mm" wi="163.58mm" file="US20230003535A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="136.57mm" wi="115.99mm" file="US20230003535A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="149.01mm" wi="163.75mm" file="US20230003535A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="163.83mm" wi="154.69mm" file="US20230003535A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="234.87mm" wi="165.78mm" orientation="landscape" file="US20230003535A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="173.31mm" wi="149.61mm" file="US20230003535A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="237.15mm" wi="164.17mm" orientation="landscape" file="US20230003535A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="143.34mm" wi="111.68mm" file="US20230003535A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="142.49mm" wi="168.74mm" file="US20230003535A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="156.38mm" wi="163.58mm" file="US20230003535A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="152.57mm" wi="163.75mm" file="US20230003535A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="148.84mm" wi="163.49mm" file="US20230003535A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="238.34mm" wi="164.00mm" orientation="landscape" file="US20230003535A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="173.82mm" wi="144.78mm" file="US20230003535A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="231.31mm" wi="165.52mm" orientation="landscape" file="US20230003535A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00023" num="00023"><img id="EMI-D00023" he="220.47mm" wi="162.81mm" file="US20230003535A1-20230105-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00024" num="00024"><img id="EMI-D00024" he="245.36mm" wi="152.15mm" file="US20230003535A1-20230105-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00025" num="00025"><img id="EMI-D00025" he="126.58mm" wi="107.95mm" file="US20230003535A1-20230105-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00026" num="00026"><img id="EMI-D00026" he="173.57mm" wi="155.87mm" file="US20230003535A1-20230105-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00027" num="00027"><img id="EMI-D00027" he="162.05mm" wi="151.21mm" file="US20230003535A1-20230105-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00028" num="00028"><img id="EMI-D00028" he="126.49mm" wi="114.55mm" file="US20230003535A1-20230105-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00029" num="00029"><img id="EMI-D00029" he="103.80mm" wi="155.62mm" file="US20230003535A1-20230105-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00030" num="00030"><img id="EMI-D00030" he="228.94mm" wi="141.14mm" orientation="landscape" file="US20230003535A1-20230105-D00030.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00031" num="00031"><img id="EMI-D00031" he="208.62mm" wi="164.34mm" file="US20230003535A1-20230105-D00031.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00032" num="00032"><img id="EMI-D00032" he="232.92mm" wi="108.97mm" file="US20230003535A1-20230105-D00032.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00033" num="00033"><img id="EMI-D00033" he="159.34mm" wi="163.58mm" file="US20230003535A1-20230105-D00033.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00034" num="00034"><img id="EMI-D00034" he="153.08mm" wi="164.00mm" file="US20230003535A1-20230105-D00034.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00035" num="00035"><img id="EMI-D00035" he="142.49mm" wi="163.83mm" file="US20230003535A1-20230105-D00035.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00036" num="00036"><img id="EMI-D00036" he="224.03mm" wi="163.15mm" file="US20230003535A1-20230105-D00036.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00037" num="00037"><img id="EMI-D00037" he="170.86mm" wi="112.69mm" file="US20230003535A1-20230105-D00037.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00038" num="00038"><img id="EMI-D00038" he="138.68mm" wi="154.09mm" file="US20230003535A1-20230105-D00038.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00039" num="00039"><img id="EMI-D00039" he="147.24mm" wi="161.88mm" file="US20230003535A1-20230105-D00039.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00040" num="00040"><img id="EMI-D00040" he="224.62mm" wi="165.02mm" file="US20230003535A1-20230105-D00040.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00041" num="00041"><img id="EMI-D00041" he="163.91mm" wi="115.49mm" file="US20230003535A1-20230105-D00041.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00042" num="00042"><img id="EMI-D00042" he="56.56mm" wi="92.29mm" file="US20230003535A1-20230105-D00042.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00043" num="00043"><img id="EMI-D00043" he="64.18mm" wi="115.99mm" file="US20230003535A1-20230105-D00043.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The technique disclosed in the specification of the present disclosure aims at rendering possible smooth rendezvous of a dispatched vehicle and a user.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">In recent years, the automobile industry has been commercializing various services using vehicle sharing as a keyword, or has been developing technology for vehicle sharing. For example, ride-hailing or ride-sharing services are vehicle dispatching services in which users can use a vehicle that they do not own.</p><p id="p-0004" num="0003">With advances in automated operation technology, services are envisaged in which unattended vehicles go to pick users up by automatic operation.</p><p id="p-0005" num="0004">These services are required to achieve smooth rendezvous of a user and a vehicle. In view of this, Patent Document 1 discloses a technique for assisting rendezvous by displaying a meeting place on a map.</p><heading id="h-0003" level="1">PRIOR ART DOCUMENT</heading><p id="p-0006" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0005">Patent Document 1: Japanese Patent Application Laid-Open No. 2019-053547</li></ul></p><heading id="h-0004" level="1">SUMMARY</heading><heading id="h-0005" level="1">Problems to be Solved by the Invention</heading><p id="p-0007" num="0006">With the technique of Patent Document 1, the vehicle is capable of recognizing a. meeting point on the map. There is, however, a problem in that smooth rendezvous of a vehicle and a user is difficult to achieve because, if there are numerous persons at a meeting point, it can be difficult for the vehicle to recognize which person is its user.</p><p id="p-0008" num="0007">The present disclosure has been made in light of the problem described above, and it is an object of the present disclosure to achieve smooth rendezvous of a vehicle and a user even if there are numerous persons at a meeting point.</p><p id="p-0009" num="0008">Means to Solve the Invention</p><p id="p-0010" num="0009">A rendezvous assistance system according to the present disclosure includes a mobile terminal carried by a user who wants to rendezvous with a dispatched vehicle, and a rendezvous assistance device that communicates with the mobile terminal and assists rendezvous of the dispatched vehicle and the user at a meeting point. The rendezvous assistance device includes a message generator that generates a message that requests the user to do a gesture, a vehicle controller that determines timing when the dispatched vehicle is at or around the meeting point as timing of transmission of the message, and a vehicle communicator that transmits the message to the mobile terminal with the timing of transmission. The mobile terminal includes a mobile communicator that receives the message from the rendezvous assistance device, and a notification unit that sends a notification that requests the user to do the gesture in accordance with the message.</p><heading id="h-0006" level="1">Effects of the Invention</heading><p id="p-0011" num="0010">According to the technique described in the present disclosure, the mobile terminal sends a notification that requests the user to do a gesture with timing when the dispatched vehicle is at or around the meeting point. When the user has made a gesture in response to the notification, the vehicle is capable of identifying the user even if there are numerous persons at the meeting point. This achieves smooth rendezvous of the vehicle and the user.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0007" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating a configuration of a rendezvous assistance system according to Embodiment 1.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flowchart illustrating operations of the rendezvous assistance system according to Embodiment 1.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating a configuration of a rendezvous assistance system according to Embodiment 2.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating operations of the rendezvous assistance device according to Embodiment 2.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a positional-relationship display screen according to Embodiment 2.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates the positional-relationship display screen according to Embodiment 2.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates the positional-relationship display screen according to Embodiment 2.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates the positional-relationship display screen according to Embodiment 2.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates gesture information.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates a gesture selection screen.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart illustrating operations of a mobile terminal according to Embodiment 2.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates a condition in which there are numerous persons at a meeting point and the driver is unable to identify his/her user</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows an example of a notification on the mobile terminal that has received a message from the rendezvous assistance device.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates a condition in which the driver identifies the user by the gesture of the user.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart illustrating operations of a rendezvous assistance device according to Variation 1 of Embodiment 2.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>16</b></figref> illustrates a positional-relationship display screen according to Variation 1 of Embodiment 2.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>17</b></figref> illustrates the positional-relationship display screen according to Variation 1 of Embodiment 2.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>18</b></figref> illustrates the positional-relationship display screen according to Variation 1 of Embodiment 2.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>19</b></figref> illustrates the positional-relationship display screen according to Variation 1 of Embodiment 2.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>20</b></figref> shows an example of selecting a gesture by an audio command.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>21</b></figref> illustrates a condition in which a user inputs identification information to the mobile terminal, instead of refusing to do a gesture.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>22</b></figref> illustrates a condition in which the driver identifies the user from the identification information.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>23</b></figref> is a block diagram illustrating a configuration of a rendezvous assistance system according to Variation <b>6</b> of Embodiment 2.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>24</b></figref> is a flowchart illustrating operations of a mobile terminal according to Variation <b>6</b> of Embodiment 2.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>25</b></figref> illustrates a vehicle approach notification received by the mobile terminal.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>26</b></figref> illustrates a condition in which the mobile terminal displays the direction of approach of a vehicle on a map.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>27</b></figref> illustrates a condition in which an icon indicating the direction of approach of a vehicle is superimposed and displayed on an image captured by a camera of the mobile terminal.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>28</b></figref> illustrates a relationship between the direction of travel of a vehicle and the direction of approach of the vehicle.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>29</b></figref> illustrates an effect of guiding the user's line of vision to the direction of approach of the vehicle.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>30</b></figref> is a conceptual diagram illustrating how the user is guided to the meeting point outside a building.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>31</b></figref> is a block diagram illustrating a configuration of a rendezvous assistance system according to Embodiment 3.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>32</b></figref> is a flowchart illustrating operations of the rendezvous assistance device according to Embodiment 3.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>33</b></figref> shows an example of displaying the result of identifying the user by gesture recognition.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>34</b></figref> shows an example of displaying the result of identifying the user by gesture recognition.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>35</b></figref> shows an example of displaying the result of identifying the user by gesture recognition.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>36</b></figref> is a block diagram illustrating a configuration of a rendezvous assistance system according to Embodiment 4.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>37</b></figref> is a flowchart illustrating operations of the rendezvous assistance device according to Embodiment 4.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>38</b></figref> shows an example of an announcement made via an outside-vehicle annunciator.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>39</b></figref> shows an example of an announcement made via the outside-vehicle annunciator.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>40</b></figref> is a block diagram illustrating a configuration of a rendezvous assistance system according to Embodiment 5.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>41</b></figref> is a flowchart illustrating operations of a vehicle dispatch server according to Embodiment 5.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>42</b></figref> illustrates a hardware configuration of the rendezvous assistance device and the communication terminal.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>43</b></figref> illustrates a hardware configuration of the rendezvous assistance device and the communication terminal.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0008" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0055" num="0054">A. Embodiment 1</p><p id="p-0056" num="0055">A-1. Configuration</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating a configuration of a rendezvous assistance system <b>301</b> according to Embodiment 1. The rendezvous assistance system <b>301</b> assists smooth rendezvous of a dispatched vehicle X and a user who wants to rendezvous with the dispatched vehicle X. The rendezvous assistance system <b>301</b> includes a rendezvous assistance device <b>101</b> mounted on the dispatched vehicle X and a mobile terminal <b>201</b> of the user. Note that the rendezvous assistance device <b>101</b> may be a device mounted stationary on the dispatched vehicle X, or may be a mobile terminal that is brought and used in the dispatched vehicle X as necessary.</p><p id="p-0058" num="0057">The rendezvous assistance device <b>101</b> includes a vehicle controller <b>11</b>. a message generator <b>12</b>, a positioner <b>13</b>, and a vehicle communicator <b>14</b>. The rendezvous assistance device <b>101</b> is connected to a global navigation satellite system (GNSS) receiver <b>31</b> and a communication device <b>32</b> that are mounted on the dispatched vehicle X, and is configured to be capable of using these devices.</p><p id="p-0059" num="0058">The vehicle controller <b>11</b> performs overall control of the rendezvous assistance device <b>101</b>. The message generator <b>12</b> generates a message that requests a user to do a gesture (hereinafter, simply referred to as the &#x201c;message&#x201d;). The GNSS receiver <b>31</b> receives a GNSS signal. The positioner <b>13</b> acquires a GNSS signal received by the GNSS receiver <b>31</b> and measures the location of the dispatched vehicle X on the basis of the GNSS signal. Note that the positioner <b>13</b> may measure the location of the dispatched vehicle X by other methods. The positioner <b>13</b> may correct the result of measuring the location of the dispatched vehicle X on the basis of the GNSS signal, for example in response to measurement signals obtained by a gyroscopic sensor and an acceleration sensor (not shown), or may further correct the measurement result by map matching.</p><p id="p-0060" num="0059">The communication device <b>32</b> serves as a communication interface that allows the vehicle communicator <b>14</b> to communicate with the mobile terminal <b>201</b>. The communication device <b>32</b> configures a communication network with a mobile communicator <b>22</b> of the mobile terminal <b>201</b>. The vehicle communicator <b>14</b> transmits the message generated by the message generator <b>12</b> to the mobile terminal <b>201</b> via the communication device <b>32</b> when the dispatched vehicle X is at or around the meeting point. The message is transmitted for the purpose of causing the user to do a gesture and allowing the dispatched vehicle X to check this gesture and grasp the accurate location of the user. Accordingly, &#x201c;the dispatched vehicle X is around the meeting point&#x201d; described above means that the dispatched vehicle X or the driver is approaching the meeting point to the extent that the dispatched vehicle X or the driver is capable of checking the gesture of the user who is at the meeting point. For example, &#x201c;being around the meeting point&#x201d; may refer to &#x201c;being within a 30-meter radius of the meeting point.&#x201d; Note that such information on the meeting point is shared in advance between the dispatched vehicle X and the user.</p><p id="p-0061" num="0060">The mobile terminal <b>201</b> is a terminal carried by the user, and may for example be a PDA or a smartphone. The mobile terminal <b>201</b> includes a mobile controller <b>21</b>, a mobile communicator <b>22</b>, and a notification unit <b>23</b>. The mobile controller <b>21</b> performs overall control of the mobile terminal <b>201</b>. The mobile communicator <b>22</b> receives a message from the rendezvous assistance device <b>101</b>. The notification unit <b>23</b> sends a notification that requests the user to do a gesture (hereinafter, referred to as a &#x201c;gesture request notification&#x201d;) on the basis of the message received by the mobile communicator <b>22</b>. The gesture request notification may be provided, for example, in at least one of forms including a display, audio, and vibrations depending on output means included in the mobile terminal <b>201</b>.</p><p id="p-0062" num="0061">A-2. Operations</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flowchart illustrating operations of the rendezvous assistance system <b>301</b>. It is assumed that, before the start of this flowchart, the rendezvous assistance device <b>101</b> and the mobile terminal <b>201</b> share information on a meeting point in advance as a result of, for example, the conclusion of a vehicle dispatch contract between the dispatched vehicle X and the user.</p><p id="p-0064" num="0063">First, in the rendezvous assistance device <b>101</b>, the positioner <b>13</b> acquires a GNSS signal from the GNSS receiver <b>31</b> and measures the location of the dispatched vehicle X (step S<b>101</b>). The vehicle controller <b>11</b> acquires the location of the dispatched vehicle X from the positioner <b>13</b> and determines whether the dispatched vehicle X is at or around the meeting point (step S<b>102</b>). The vehicle controller <b>11</b> repeats step S<b>102</b> until the answer in step S<b>102</b> turns to &#x201c;Yes.&#x201d;</p><p id="p-0065" num="0064">When, the dispatched vehicle X is at or around the meeting point in step S<b>102</b>, the message generator <b>12</b> generates a message that requests the user to do a gesture (step S<b>103</b>). Then, the vehicle communicator <b>14</b> transmits the message generated by the message generator <b>12</b> to the mobile terminal <b>201</b> via the communication device <b>32</b>, and the message is received by the mobile terminal <b>201</b> (step S<b>104</b>).</p><p id="p-0066" num="0065">Next, in the mobile terminal <b>201</b>, the notification unit <b>23</b> sends the message received by the mobile communicator <b>22</b> as a notification to the user (step S<b>105</b>). When the user makes a gesture upon receipt of this notification, the dispatched vehicle X is capable of checking this gesture and accurately grasping the location of the user, In particular, even if there are numerous persons at the meeting point, the dispatched vehicle X is capable of identifying the user who is making the gesture as its user. This achieves smooth rendezvous of the dispatched vehicle X and the user.</p><p id="p-0067" num="0066">A-3. Effects</p><p id="p-0068" num="0067">The rendezvous assistance system <b>301</b> according to Embodiment I includes the mobile terminal <b>201</b> carried by the user who wants to rendezvous with the dispatched vehicle X, and the rendezvous assistance device <b>101</b> that assists rendezvous of the dispatched vehicle X and the user at a meeting point by communication with the mobile terminal <b>201</b>. The rendezvous assistance device <b>101</b> includes the message generator <b>12</b> that generates a message that requests the user to do a gesture, the vehicle controller <b>11</b> that determines timing when the dispatched vehicle X is at or around the meeting point as the timing of transmission of the message, and the vehicle communicator <b>14</b> that transmits the message to the mobile terminal with the determined timing of transmission.</p><p id="p-0069" num="0068">The mobile terminal <b>201</b> includes the mobile communicator <b>22</b> that receives a message from the rendezvous assistance device <b>101</b>, and the notification unit <b>23</b> that sends a notification that requests the user to do a gesture on the basis of the message. When the dispatched vehicle X is at or around the meeting point, the mobile terminal <b>201</b> sends a notification that requests the user to do a gesture to the dispatched vehicle X, and the user makes a gesture in response to this notification, Thus, the dispatched vehicle X is capable of identifying the user even if there are numerous persons at the meeting point. This achieves smooth rendezvous of the dispatched vehicle X and the user.</p><p id="p-0070" num="0069">B. Embodiment 2</p><p id="p-0071" num="0070">B-1. Configuration</p><p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating a configuration of a rendezvous assistance system <b>302</b>A according to Embodiment 2. The rendezvous assistance system <b>302</b>A includes a rendezvous assistance device <b>102</b> mounted on a dispatched vehicle X and a mobile terminal <b>202</b>A. The rendezvous assistance device <b>102</b> is connected to a GNSS receiver <b>31</b>, a communication device <b>32</b>, a display device <b>33</b>, an audio output device <b>34</b>, and a manipulator <b>35</b> that are mounted on the dispatched vehicle X, and is configured to be capable of using these devices.</p><p id="p-0073" num="0072">The rendezvous assistance device <b>102</b> includes a storage <b>15</b> in addition to the configuration of the rendezvous assistance device <b>101</b> according to Embodiment 1. The storage <b>15</b> stores location information on a meeting point. In addition to this, the storage <b>15</b> may further store identification information on the user. The vehicle controller <b>11</b> of the rendezvous assistance device <b>102</b> is connected to the display device <b>33</b>, the audio output device <b>34</b>, and the manipulator <b>35</b>.</p><p id="p-0074" num="0073">The display device <b>33</b> and the audio output device <b>34</b> serve as output interfaces for the driver of the dispatched vehicle X. The display device <b>33</b> may be configured with, for example, a liquid crystal display, an organic EL display, or an HUD. The audio output device <b>34</b> may be configured with a speaker. The manipulator <b>35</b> serves as an input interface for the driver of the dispatched vehicle X and is configured with, for example, a touch panel, mechanical switches, or an audio input device.</p><p id="p-0075" num="0074">The mobile terminal <b>202</b>A includes, in addition to the configuration of the mobile terminal <b>201</b> according to Embodiment 1, a positioner <b>24</b>, an operation unit <b>25</b>, and a storage <b>30</b>. The storage <b>30</b> stores location information on a meeting point. In addition to this, the storage <b>30</b> may further store identification information on the dispatched vehicle X such as vehicle type, color, and registration number. The mobile terminal <b>202</b>A further includes a display <b>26</b> and an audio output unit <b>27</b> that serve as a notification unit.</p><p id="p-0076" num="0075">The positioner <b>24</b> measures the location of the mobile terminal <b>202</b>A by a method similar to that used by the positioner <b>13</b> of the rendezvous assistance device <b>102</b>. The operation unit <b>25</b> serves as an input interface of the mobile terminal <b>202</b>A and may be configured with, for example, a touch panel, mechanical switches, or an audio input device. The display <b>26</b> may be configured with, for example, a liquid crystal display or an organic EL display. the audio output unit <b>27</b> may be configured with a speaker.</p><p id="p-0077" num="0076">B-2. Operations</p><p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating operations of the rendezvous assistance device <b>102</b>. It is assumed that, before the start of this flowchart, the rendezvous assistance device <b>101</b> and the mobile terminal <b>201</b> share information on a meeting point as a result of, for example, the conclusion of a vehicle dispatch contract between the dispatched vehicle X and a user. Thus, the storage <b>15</b> of the rendezvous assistance device <b>102</b> and the storage <b>30</b> of the mobile terminal <b>202</b>A store the location information on the meeting point. Hereinafter, the operations of the rendezvous assistance device <b>102</b> will be described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0079" num="0078">When the dispatched vehicle X has started travelling to the meeting point, the positioner <b>13</b> acquires a GNSS signal from the GNSS receiver <b>31</b> and measures the location of the dispatched vehicle X (step S<b>201</b>). Then the vehicle controller <b>11</b> acquires the location information on the meeting point from the storage <b>15</b>, acquires the location information on the dispatched vehicle X from the positioner <b>13</b>, and on the bases of the received information, displays a positional relationship of the dispatched vehicle X and the meeting point on the display device <b>33</b> (step S<b>202</b>).</p><p id="p-0080" num="0079"><figref idref="DRAWINGS">FIGS. <b>5</b> to <b>8</b></figref> show examples of a positional-relationship display screen of the display device <b>33</b> that displays the positional relationship of the dispatched vehicle X and the meeting point. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the location of the meeting point is indicated by an object <b>50</b>, and the location of the dispatched vehicle X is indicated by an object <b>51</b>. The positional relationship of the objects <b>50</b> and <b>51</b> indicates the distance and direction between the meeting point and the dispatched vehicle X. A plurality of concentric circles about the object <b>50</b> indicate distances from the meeting point. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the concentric circles that respectively indicate the distances of 20 m, 50 m, and <b>100</b> m from the meeting point are displayed. Also, the distance of the dispatched vehicle X from the meeting point is added to the object <b>51</b>. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the dispatched vehicle X is 1 km away from the meeting point and therefore the object <b>51</b> is displayed outside the largest concentric circle.</p><p id="p-0081" num="0080">Referring back to the flowchart in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the vehicle controller <b>11</b> determines whether to check the location of the user (step S<b>203</b>). As illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, an icon <b>56</b> for displaying the location of the user is displayed on the positional-relationship display screen. The driver who wants to check the location of the user presses the icon <b>56</b>. In the condition illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the vehicle is far away from the meeting point and therefore there is little need to check the location of the user. If the driver has not pressed the icon <b>56</b> for a given period of time, the vehicle controller <b>11</b> determines that there is no need to check the location of the user. Thus, the processing of the rendezvous assistance device <b>102</b> returns to step S<b>201</b>, and the positional-relationship display screen is updated in the subsequent step S<b>202</b>.</p><p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates the positional-relationship display screen when the dispatched vehicle X is approaching 30 m from the meeting point. In <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the object <b>51</b> is displayed inside a concentric circle that represents a distance of 50 m from the meeting point. The inside of the smallest concentric circle that represents a distance of 20 m from the meeting point is displayed in a different color from the other concentric circles and expresses that the dispatched vehicle X is approaching the meeting point.</p><p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates the positional-relationship display screen when the dispatched vehicle X has arrived at the meeting point, without the driver pressing the icon <b>56</b> on the positional-relationship display screen in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. In <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the object <b>51</b> is displayed in the center of the concentric circles, and the object <b>50</b> is not displayed. When the dispatched vehicle X has arrived at the meeting point, the driver needs to check whether the user also has arrived at the meeting point.</p><p id="p-0084" num="0083">When the driver has pressed the icon <b>56</b>, operation information on the icon <b>56</b> is input from the manipulator <b>35</b> to the vehicle controller <b>11</b>, and the vehicle controller <b>11</b> determines to check the location of the user (Yes in step S<b>203</b>). Then, the vehicle communicator <b>14</b> sends a request to transmit the location information to the mobile terminal <b>202</b>A and receives location information on the mobile terminal <b>202</b>A as the location information on the user from the mobile terminal <b>202</b>A (step S<b>204</b>). Then, the vehicle controller <b>11</b> causes the display device <b>33</b> to display the positional relationship of the dispatched vehicle X and the meeting point (step S<b>205</b>). The location of the user as used herein is synonymous with the location of the mobile terminal <b>202</b>A. In this way, the vehicle controller <b>11</b> acquires the operation information on the driver of the dispatched vehicle X and causes the display device <b>33</b> to display the positional relationship of the dispatched vehicle X, the meeting point, and the user with timing based on the operation information on the driver.</p><p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows an example of the positional-relationship display screen on the display device <b>33</b> in step S<b>205</b>. In <figref idref="DRAWINGS">FIG. <b>8</b></figref>, in addition to the display in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the location of the user is indicated by an object <b>52</b>. Also, a distance of 35 m between the user and the meeting point is added to the object <b>52</b>. This display enables the driver to grasp that the user is at a location <b>35</b> m of from the dispatched vehicle X in the upper right direction.</p><p id="p-0086" num="0085">Then, the vehicle controller <b>11</b> determines whether or not to request the user to do a gesture (step S<b>206</b>). The positional-relationship display screen illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> displays an icon <b>54</b> for requesting the user to do a gesture. The driver grasps the location of the user by looking at the positional-relationship display screen and presses the icon <b>54</b> when having determined that the user is at a viewable location from the dispatched vehicle X. If the driver has not pressed the icon <b>54</b> for a given period of time, the vehicle controller <b>11</b> determines not to request the user to do a gesture. Thus, the processing of the rendezvous assistance device <b>102</b> returns to step S<b>204</b>, and the positional-relationship display screen is updated in the subsequent step S<b>205</b>.</p><p id="p-0087" num="0086">When the driver has pressed the icon <b>54</b>, operation information on the icon <b>54</b> is input from the manipulator <b>35</b> to the vehicle controller <b>11</b>, and the vehicle controller <b>11</b> determines to request the user to do a gesture (Yes in step S<b>206</b>). Then, the message generator <b>12</b> selects one gesture from among a plurality of gestures prepared in advance, and generates a message that prompts the user to do the selected gesture (step S<b>207</b>). In this way, the timing of generation of the message is determined by the driver's operation. Then, when the message is generated as will be described later, the message is transmitted to the mobile terminal <b>202</b>A. In other words, the timing of transmission of the message is determined by the timing based on information on the driver's operation.</p><p id="p-0088" num="0087"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates gesture information stored in storage <b>15</b>. The gesture information is information on candidates for the gesture requested to the user to do, and includes an identification number, body-part attribute, and motion attribute of each gesture. The body-part attribute is information that indicates the body part that makes the gesture, and the motion attribute is information that indicates how the body part indicated by the body-part attribute is moved. On the basis of the gesture information, the vehicle controller <b>11</b> causes the display device <b>33</b> to display a gesture selection screen for allowing the driver to select a gesture. <figref idref="DRAWINGS">FIG. <b>10</b></figref> shows one example of the gesture selection screen. This gesture selection screen displays icons that visually represent gestures with identification numbers G<b>1</b> to G<b>8</b> (hereinafter, referred to as &#x201c;gestures G<b>1</b> to G<b>8</b>&#x201d;), and the driver selects an icon to select a gesture type that the driver requests the user to do. For example, when the driver has selected the gesture G<b>1</b>, the message generator <b>12</b> generates a message saying &#x201c;Please raise one hand.&#x201d; This message may include an icon that visually expresses the gesture, in addition to the text saying &#x201c;Please raise one hand.&#x201d;</p><p id="p-0089" num="0088">Although the driver selects a gesture from among a plurality of candidates prepared in advance in the above description, the method of generating a message is not limited thereto. For example, the driver may set a new gesture by designating a body-part attribute and a motion attribute. As another alternative, the rendezvous assistance device <b>102</b> and the mobile terminal <b>202</b>A may prescribe a gesture to be required for rendezvous when concluding a vehicle dispatch contract.</p><p id="p-0090" num="0089">When the message generator <b>12</b> has generated a message, the vehicle communicator <b>14</b> transmits the message to the mobile terminal <b>202</b>A (step S<b>208</b>). In this way, the operations of the rendezvous assistance device <b>102</b> end.</p><p id="p-0091" num="0090">Next, operations of the mobile terminal <b>202</b>A will be described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. First, the positioner <b>24</b> measures the location of the mobile terminal <b>202</b>A (step S<b>301</b>). Then, the mobile controller <b>21</b> acquires location information on the meeting point from the storage <b>30</b> and acquires the location information on the mobile terminal <b>202</b>A from the positioner <b>24</b>. On the basis of the acquired information, the mobile controller <b>21</b> causes the display <b>26</b> to display a positional relationship of the mobile terminal <b>202</b>A and the meeting point (step S<b>302</b>). Here, the positional-relationship display screen displayed on the display <b>26</b> may be obtained by, for example, replacing the dispatched vehicle X with the mobile terminal <b>202</b>A on the display of the positional relationship of the dispatched vehicle X and the meeting point illustrated in, for example, <figref idref="DRAWINGS">FIGS. <b>5</b> to <b>7</b></figref>.</p><p id="p-0092" num="0091">Then, the mobile controller <b>21</b> determines whether a request to transmit location information is sent from the dispatched vehicle X (step S<b>303</b>). This request-to-transmit is sent from the rendezvous assistance device <b>102</b> to the mobile terminal <b>202</b>A in step S<b>204</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. Upon receipt of a request to transmit location information from the dispatched vehicle X, the mobile communicator <b>22</b> transmits the location information on the mobile terminal <b>202</b>A to the dispatched vehicle X (step S<b>304</b>).</p><p id="p-0093" num="0092">This location information is received by the vehicle communicator <b>14</b> of the rendezvous assistance device <b>102</b> via the communication device <b>32</b>.</p><p id="p-0094" num="0093">After step S<b>304</b> or if the request to transmit location information is not received from the dispatched vehicle X in step S<b>304</b>, the mobile controller <b>21</b> determines whether the mobile communicator <b>22</b> has received a message from the dispatched vehicle X (step S<b>305</b>). When the mobile communicator <b>22</b> has not received a message from the dispatched vehicle X in step S<b>305</b>, the processing of the mobile terminal <b>202</b>A returns to step S<b>301</b>. When the mobile communicator <b>22</b> has received a message from the dispatched vehicle X in step S<b>305</b>, the display <b>26</b> and the audio output unit <b>27</b> send a message notification to the user (step S<b>306</b>). In this way, the operations of the mobile terminal <b>202</b>A end.</p><p id="p-0095" num="0094">The procedure from when the dispatched vehicle X has arrived at the meeting point to when the user makes a gesture will be described with reference to <figref idref="DRAWINGS">FIGS. <b>12</b> to <b>14</b></figref>. In <figref idref="DRAWINGS">FIGS. <b>12</b> and <b>14</b></figref>, the user is indicated by a reference sign Z. The gesture type is assumed to be &#x201c;raise one hand.</p><p id="p-0096" num="0095"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates a situation in which the dispatched vehicle X has arrived at the meeting point, but a driver Y is unable to identify a user Z because there are numerous persons at the meeting point. In this case, the rendezvous assistance device <b>02</b> transmits a message to the mobile terminal <b>202</b>A, and thereby the mobile terminal <b>202</b>A notifies the user of the message that requests the user to do a gesture. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, an icon that indicates the gesture of raising one hand is displayed on the display <b>70</b> of the mobile terminal <b>202</b>A, and a voice saying &#x201c;Please raise one hand&#x201d; is output from a speaker <b>71</b> of the mobile terminal <b>202</b>A. In this example, both a display and audio are used as a message notification, but either one of them may be used or vibration may be added as a message notification. When the user Z has made the gesture of raising one hand in response to the notification, the driver Y is able to identify the user Z from among the numerous persons as illustrated in <figref idref="DRAWINGS">FIG. <b>14</b></figref>. Then, the driver Y drives the dispatched vehicle X to just in front of the user Z and achieves smooth rendezvous with the user Z.</p><p id="p-0097" num="0096">B-3. Variation <b>1</b></p><p id="p-0098" num="0097">In the flowchart illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the rendezvous assistance device <b>102</b> causes the driver to determine the timing of checking the location of the user in step S<b>203</b>. Alternatively, the rendezvous assistance device <b>102</b> may cause the display device <b>33</b> to display the location of the user from the beginning. <figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart of such processing of the rendezvous assistance device <b>102</b> according to a variation. In this flowchart, after the positioner <b>13</b> has measured the location of the dispatched vehicle X (step S<b>401</b>), the vehicle communicator <b>14</b> acquires the location of the user from the mobile terminal <b>202</b>A (step S<b>402</b>). Then, the vehicle controller <b>11</b> causes the display device <b>33</b> to display a positional relationship of the dispatched vehicle X, the meeting point, and the user (step S<b>403</b>). The subsequent steps S<b>404</b> to S<b>406</b> are the same as steps S<b>206</b> to S<b>208</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0099" num="0098"><figref idref="DRAWINGS">FIGS. <b>16</b> to <b>19</b></figref> show examples of displaying the positional relationship on the display device <b>33</b> according to this variation. In <figref idref="DRAWINGS">FIG. <b>16</b></figref>, the dispatched vehicle X is 1 km away from the meeting point, and the user is 200 m away from the meeting point. At this point in time, the object <b>52</b> indicating the location of the user is also displayed. In <figref idref="DRAWINGS">FIG. <b>17</b></figref>, the dispatched vehicle X is 500 m away from the meeting point, and the user is 70 m away from the meeting point. <figref idref="DRAWINGS">FIG. <b>18</b></figref> shows an example of displaying the positional relationship at the time when the dispatched vehicle X is 60 m away from the meeting point and the user has arrived at the meeting point. In <figref idref="DRAWINGS">FIG. <b>18</b></figref>, the object <b>52</b> is displayed in the center of the concentric circles, and the object <b>50</b> representing the location of the meeting point is not displayed. <figref idref="DRAWINGS">FIG. <b>19</b></figref> illustrates the positional-relationship display screen at the time when the dispatched vehicle X has arrived at the meeting point. This positional-relationship display screen displays an icon <b>54</b> for requesting the user to do a gesture.</p><p id="p-0100" num="0099">The variation described with reference to <figref idref="DRAWINGS">FIGS. <b>15</b> to <b>19</b></figref> increases the amount of communication between the rendezvous assistance device <b>102</b> and the mobile terminal <b>202</b>A during transmission and reception of the location information on the user, but eliminates the need for the driver to perform the operation of determining the timing of checking the location of the user.</p><p id="p-0101" num="0100">B-4. Variation 2</p><p id="p-0102" num="0101">In step S<b>302</b> in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the mobile terminal <b>202</b>A displays the positional relationship of the meeting point and the mobile terminal <b>202</b>A on the display <b>26</b>. Alternatively, the mobile terminal <b>202</b>A may acquire the location information on the dispatched vehicle X from the rendezvous assistance device <b>102</b> and display the positional relationship of the meeting point, the mobile terminal <b>202</b>A, and the dispatched vehicle X on the display <b>26</b>. This display may be obtained by, for example, interchanging the object <b>51</b> representing the location of the dispatched vehicle X with the object <b>52</b> representing the location of the user on the display of the positional relationship illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. The timing of displaying the location of the dispatched vehicle X may be displayed from the beginning, or may be determined by a user operation.</p><p id="p-0103" num="0102">B-5. Variation 3</p><p id="p-0104" num="0103">In <figref idref="DRAWINGS">FIG. <b>10</b></figref>, a case is described in which the message generator <b>12</b> selects the gesture designated by the driver on the gesture selection screen, and generates a message. Alternatively, the driver may designate a gesture by other methods. For example, the driver may designate a gesture by a voice command as illustrated in <figref idref="DRAWINGS">FIG. <b>20</b></figref>. In <figref idref="DRAWINGS">FIG. <b>20</b></figref>, when the driver says &#x201c;Please raise one hand,&#x201d; the manipulator <b>35</b> serving as an audio input device recognizes keywords such as &#x201c;one hand&#x201d; and &#x201c;raise&#x201d; from the speech voice and sends a notification to the vehicle controller <b>11</b>. The vehicle controller <b>11</b> identifies the gesture designated by the driver as a gesture G<b>1</b> from the result of recognizing the speech voice by the audio input device. Then, the message generator <b>12</b> generates a message that requests the user to do the gesture G<b>1</b> of &#x201c;raising one hand.&#x201d;</p><p id="p-0105" num="0104">Alternatively, the driver may do a gesture so that the user is able to do the same gesture as the driver. In this case, the manipulator <b>35</b> includes an on-vehicle gesture recognition unit that recognizes a person in the dispatched vehicle X. The vehicle controller <b>11</b> acquires the result of recognizing the driver's gesture via the on-vehicle gesture recognition unit and determines the gesture of the same type as the driver's gesture as a gesture type to be included in the message. Then, the message generator <b>12</b> generates a message that requests the user to do the gesture of the same type as the driver's gesture. This configuration enables the driver to more intuitively designate a gesture. In the case where the gesture requested to the user to do is determined by the driver's voice or gesture, the message generator <b>12</b> does not necessarily have to select one gesture from among predetermined gestures. For example, the message generator <b>12</b> may generate a message directly from the driver's voice saying &#x201c;Please raise one hand&#x201d; or a captured image of the drivers' gesture.</p><p id="p-0106" num="0105">B-6. Variation 4</p><p id="p-0107" num="0106">In the flowchart in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the driver determines the timing of generation of the message in step S<b>206</b>, i.e., the timing of transmission of the message, while looking at the display of the positional relationship of the vehicle, the meeting point, and the user. Alternatively, the timing of transmission may be determined by the rendezvous assistance device <b>102</b>. The message needs to be transmitted with timing when the user's gesture is visible from the dispatched vehicle X. Thus, the rendezvous assistance device <b>102</b> determines the timing of transmission of the message on the basis of the positional relationship of the vehicle and the user. For example, the rendezvous assistance device <b>102</b> may determine the timing of transmission of the message on the basis of the distance between the vehicle and the user, e.g., a distance of 20 m or less between the vehicle and the user.</p><p id="p-0108" num="0107">Moreover, the vehicle controller <b>11</b> may confirm, as a prerequisite for transmitting a message, that the user is at a visible location from the dispatched vehicle X with reference to a 3D map of the meeting point. This prevents the rendezvous assistance device <b>102</b> from transmitting a message to the mobile terminal <b>202</b>A when the distance between the dispatched vehicle X and the user is short but the user is shadowed by a building or any other obstacle and invisible from the dispatched vehicle X. Also, in the case where the user is at or around the meeting point but is shadowed by a building or any other obstacle and invisible from the dispatched vehicle X, the vehicle controller <b>11</b> may specify a location of the meeting point that is visible from the dispatched vehicle X and may transmit this location to the mobile terminal <b>202</b>A so as to guide the user to the location visible from the dispatched vehicle X.</p><p id="p-0109" num="0108">As another alternative, the vehicle controller <b>11</b> may determine the timing of transmission of a message on the basis of the speed of the dispatched vehicle X. Specifically, the vehicle controller <b>11</b> may confirm, as a prerequisite for transmitting a message, that the speed of the dispatched vehicle X is less than or equal to a threshold value or typically that the dispatched vehicle X is making a stop. This prevents the driver from overlooking the user's gesture while driving the dispatched vehicle X.</p><p id="p-0110" num="0109">B-7. Variation <b>5</b></p><p id="p-0111" num="0110">The description thus far is based on the premise that the user who has received a message notification makes a gesture. However, in some cases, the user may be unable to do a gesture or may do not want to do a gesture for some reasons such as the user has his/her hands full. In such a case, according to this variation, the mobile terminal <b>202</b>A provides information with which the user is identified (hereinafter, referred to as &#x201c;identification information&#x201d;), instead of with a gesture, to the rendezvous assistance device <b>102</b>, so that the driver is able to identify the user from among numerous persons even if the user is not doing a gesture.</p><p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. <b>21</b></figref> illustrates a condition in which the mobile terminal <b>202</b>A that has received a message from the rendezvous assistance device <b>102</b> sends a message notification to the user. The speaker <b>71</b> of the mobile terminal <b>202</b>A outputs a voice saying &#x201c;The vehicle is arriving, so please raise your right hand.&#x201d; At this time, it is assumed that the user has his/her hands full and is thus unable to raise his/her right hand. The user may say &#x201c;I have my hands full and I'm the person who is holding a baby.&#x201d; Here, the &#x201c;person who is holding a baby&#x201d; serves as the identification information. The mobile terminal <b>202</b>A is provided with a microphone and acquires and transmits the user's speech voice to the rendezvous assistance device <b>102</b> via the mobile communicator <b>22</b>. In the rendezvous assistance device <b>102</b>, the vehicle controller <b>11</b> causes the audio output device <b>34</b> to output the user's speech voice, which includes the identification information acquired from the mobile terminal <b>202</b>A by the vehicle communicator <b>14</b>, either directly as illustrated in <figref idref="DRAWINGS">FIG. <b>22</b></figref> or after being translated simply to, for example, &#x201c;the person who is holding a baby.&#x201d; This enables the driver Y to identify the user Z who is holding a baby.</p><p id="p-0113" num="0112">B-8. Variation <b>6</b></p><p id="p-0114" num="0113">If the user makes a gesture while facing in the direction of approach of the dispatched vehicle X, the user's gesture is more likely to be visible from the driver. In view of this, according to this variation, a notification that indicates the direction of approach of the dispatched vehicle X is sent to a user who has arrived at the meeting point, so the user is guided to face in the direction of approach. <figref idref="DRAWINGS">FIG. <b>23</b></figref> is a block diagram illustrating a configuration of a rendezvous assistance system <b>302</b>B according to a variation for guiding a user. The rendezvous assistance system <b>302</b>B includes the rendezvous assistance device <b>102</b> and a mobile terminal <b>202</b>B. The mobile terminal <b>202</b>B includes, in addition to the configuration of the mobile terminal <b>202</b>A according to Embodiment 2 in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a rear camera <b>28</b> and a front camera <b>29</b>. The rear camera <b>28</b> is a camera that captures an image on the side opposite to the display side of the mobile terminal <b>202</b>B. The front camera <b>29</b> is a camera that captures an image on the display side of the mobile terminal <b>202</b>B. When a user is looking at the display of the mobile terminal <b>202</b>B, the rear camera <b>28</b> is capable of capturing an image on the side opposite to the user, and the front camera <b>29</b> is capable of capturing an image of the user.</p><p id="p-0115" num="0114"><figref idref="DRAWINGS">FIG. <b>24</b></figref> is a flowchart illustrating operations of the mobile terminal <b>202</b>B in the rendezvous assistance system <b>302</b>B. Hereinafter, the operations of the mobile terminal <b>202</b>B will be described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>24</b></figref>. Steps S<b>301</b> to S<b>304</b> are similar to those in the operations of the mobile terminal <b>202</b>A illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. After step S<b>304</b> or when it is determined in step S<b>303</b> that there is no request to transmit location information from the dispatched vehicle X, the mobile communicator <b>22</b> of the mobile terminal <b>202</b>B acquires the location information on the dispatched vehicle X from the rendezvous assistance device <b>103</b> (step S<b>304</b>A). Then, the mobile controller <b>21</b> acquires the location information on the mobile terminal <b>202</b>B from the positioner <b>24</b> and determines whether the distance between the mobile terminal <b>202</b>B and the dispatched vehicle X is less than a predetermined threshold value (step S<b>304</b>B).</p><p id="p-0116" num="0115">In step S<b>304</b>B, the mobile controller <b>21</b> waits until the distance between the mobile terminal <b>202</b>B and the dispatched vehicle X becomes less than the threshold value. When the distance between the mobile terminal <b>202</b>B and the dispatched vehicle X is less than the threshold value, the mobile terminal <b>202</b>B issues a vehicle approach notification (step S<b>304</b>C). <figref idref="DRAWINGS">FIG. <b>25</b></figref> illustrates a condition in which the audio output unit <b>27</b> issues a vehicle approach notification by producing a beeping sound. Alternatively, in addition to or instead of producing a sound, the mobile terminal <b>202</b>B may issue a vehicle approach notification by transmitting vibrations. This enables the user to notice the approach of the dispatched vehicle X even if, for example the user has the mobile terminal <b>202</b>B in his/her pocket, and to pick up the mobile terminal <b>20213</b> and prepare for rendezvous with the dispatched vehicle X. Preparing for rendezvous means starting an application for assisting rendezvous in the mobile terminal <b>202</b>B.</p><p id="p-0117" num="0116">Next, the mobile controller <b>21</b> estimates a route of the dispatched vehicle X to the meeting point on the basis of the location information on the dispatched vehicle X and the location information on the meeting point, and estimates the direction of approach of the dispatched vehicle X to the meeting point. Then, the mobile controller <b>21</b> displays the estimated direction of approach of the dispatched vehicle X on the display <b>26</b> (step S<b>304</b>D). <figref idref="DRAWINGS">FIG. <b>26</b></figref> illustrates a condition in which the direction of approach of the dispatched vehicle X is displayed on a display <b>70</b> of the mobile terminal <b>202</b>B. When the user has started an application for assisting rendezvous upon receipt of the above-described vehicle approach notification, the map of the meeting point is displayed on the display <b>70</b>. Here, the map is displayed such that the bearing on the map on the display <b>70</b> matches the bearing on the mobile terminal <b>202</b>B. Therefore, an arrow that indicates the direction of approach of the dispatched vehicle X displayed on the display <b>70</b> matches the actual direction of approach of the dispatched vehicle X, and the user is able to grasp the direction of approach of the vehicle by looking at the direction of approach of the dispatched vehicle X displayed on the display <b>70</b>. Although the direction of approach is notified by the display in <figref idref="DRAWINGS">FIG. <b>26</b></figref>, the direction of approach may be notified by audio.</p><p id="p-0118" num="0117">As illustrated in <figref idref="DRAWINGS">FIG. <b>27</b></figref>, when the user has started the rear camera <b>28</b> of the mobile terminal <b>202</b>B and captured an image in the direction of approach of the vehicle with the rear camera <b>28</b>, the mobile controller <b>21</b> may superimpose and display an icon <b>55</b> that indicates a virtual dispatched vehicle X at a position on the display <b>26</b>, the position corresponding to the direction of approach of the vehicle in the image captured by the rear camera <b>28</b>. This enables the user to more intuitively grasp the direction of approach of the vehicle.</p><p id="p-0119" num="0118">Note that when the screen as illustrated in <figref idref="DRAWINGS">FIG. <b>26</b></figref> is shown on the display <b>26</b>, the mobile terminal <b>203</b> may determine whether the user is looking in the direction of approach of the dispatched vehicle X. Specifically, the front camera <b>29</b> captures an image of the user's face. The mobile controller <b>21</b> compares the orientation of the user's face or the direction of the user's line of vision in the image captured by the front camera <b>29</b> with the direction of approach of the dispatched vehicle X displayed on the display <b>70</b> and determines whether the user is looking in the direction of approach of the dispatched vehicle X. Then, if the user is not looking in the direction of approach of the dispatched vehicle X, the display <b>26</b> or the audio output unit <b>27</b> may issue a notification that prompts the user to look in the direction of approach of the dispatched vehicle X.</p><p id="p-0120" num="0119">In the example described above, the mobile controller <b>21</b> determines whether the user is looking in the direction of approach of the dispatched vehicle X from the orientation of the user's face or the direction of the user's line of vision. Alternatively, the mobile terminal <b>202</b>B may display a confirmation icon on the screen that displays the direction of approach of the dispatched vehicle X, and the mobile controller <b>21</b> may determine, in response to a user operation of pressing that icon, that the user is looking in the direction of approach of the dispatched vehicle X.</p><p id="p-0121" num="0120"><figref idref="DRAWINGS">FIG. <b>28</b></figref> illustrates a relationship of the direction of travel of the dispatched vehicle X and the direction of approach thereof. In the case where the dispatched vehicle X makes a turn at a corner or any other point before arriving at the meeting point, a current travel direction <b>57</b> of the dispatched vehicle X does not match an approach direction <b>58</b> of the dispatched vehicle X travelling toward the meeting point. In this case, the approach direction <b>58</b> in <figref idref="DRAWINGS">FIG. <b>28</b></figref> corresponds to the direction of approach of the dispatched vehicle X described with reference to <figref idref="DRAWINGS">FIGS. <b>26</b> and <b>27</b></figref>.</p><p id="p-0122" num="0121">Guiding the user's line of vision in the direction of approach of the dispatched vehicle X is effective when the meeting point is at, for example, an intersection between buildings where it is difficult to receive GNSS signals. <figref idref="DRAWINGS">FIG. <b>29</b></figref> illustrates the case in which the meeting point is at the intersection surrounded by buildings <b>59</b> to <b>62</b>. At such a meeting point, it is difficult for the user Z who is standing even at the meeting point to know in which direction the user is facing and from which direction the dispatched vehicle X is coming.</p><p id="p-0123" num="0122">In the above description, the user's line of vision who is at the meeting point is guided in the direction of approach of the dispatched vehicle X. In addition to this, the mobile terminal <b>202</b>B may perform processing for guiding the user to the meeting point. In the case in which a user Z is inside a building <b>64</b> and the meeting point is on the road in front of the building <b>64</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>30</b></figref>, it may be difficult for the user Z to know from which exit the user should go out. In this case, the user Z may start an application of the mobile terminal <b>202</b>B and captures an image with the rear camera <b>28</b>. The mobile controller <b>21</b> may estimate an appropriate route to the exit inside the building <b>64</b> from the image captured by the rear camera <b>28</b> and guide the user to the exist by superimposing and displaying an arrow <b>65</b> that indicates the route to the exit on the image that is captured by the rear camera <b>28</b> and displayed on the display <b>26</b>.</p><p id="p-0124" num="0123">B-9. Variation <b>7</b></p><p id="p-0125" num="0124">The flowchart in <figref idref="DRAWINGS">FIG. <b>15</b></figref> does not refer to processing of the rendezvous assistance device <b>102</b> that is performed after the driver has visually recognized the user's gesture. When the driver has visually recognized the user's gesture, the rendezvous assistance device <b>102</b> may notify the mobile terminal <b>202</b>A of this recognition. For example, the vehicle controller <b>11</b> may display an icon that is to be operated by the driver after having visually recognized the user's gesture, on the positional-relationship display screen illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> and, when the icon is operated, may determine that the driver has visually recognized the user's gesture. Alternatively, when the manipulator <b>35</b> serving as an audio recognition unit has recognized the driver's speech voice saying, for example, &#x201c;The gesture is visually recognized,&#x201d; the vehicle controller <b>11</b> may determine that the driver has visually recognized the user's gesture. As another alternative, when the manipulator <b>35</b>, which serves as a gesture recognition unit for recognizing the driver's gesture, has recognized a predetermined driver's gesture, the vehicle controller <b>11</b> may determine that the driver has visually recognized the user's gesture. When the mobile terminal <b>202</b>A has issued a notification indicating the driver's recognition of the user's gesture, to the user by a display or audio, the user is able to stop doing the gesture and does not need to unnecessarily continue the gesture for a long time.</p><p id="p-0126" num="0125">B-10. Variation <b>8</b></p><p id="p-0127" num="0126">In <figref idref="DRAWINGS">FIGS. <b>21</b> and <b>22</b></figref>, a case is described in which the user does not make a gesture. On the contrary, when the user makes a gesture, the mobile terminal <b>202</b>A may issue a notification indicating the user's gesture to the rendezvous assistance device <b>102</b>. For example, the mobile controller <b>21</b> of the mobile terminal <b>202</b>A displays a text stating &#x201c;Will you make a gesture?&#x201d; and Yes and No buttons on the message notification screen displayed on the display <b>26</b>. When the user selects &#x201c;Yes,&#x201d; the mobile communicator <b>22</b> issues a notification indicating that the user is making a gesture or is to make a gesture, to the rendezvous assistance device <b>102</b>. When the user selects &#x201c;No,&#x201d; the mobile controller <b>21</b> causes the display <b>26</b> or the audio output unit <b>27</b> to display a message or output a voice that requests the user to input identification information, instead of doing a gesture. In this way, when the operation unit <b>25</b> has acquired operation information on the user's intention to do a gesture, the mobile communicator <b>22</b> transmits information indicating the user's intension to do a gesture to the vehicle communicator <b>14</b> of the rendezvous assistance device <b>102</b>. Then, the vehicle controller <b>11</b> notifies the driver of the dispatched vehicle of the user's intension to do a gesture, via the display device <b>33</b> or the audio output device <b>34</b>. This configuration enables the driver to confirm the user's intention to do a gesture.</p><p id="p-0128" num="0127">B-11. Variation <b>9</b></p><p id="p-0129" num="0128">A case is assumed in which there are a plurality of dispatched vehicles X each provided with the rendezvous assistance device <b>102</b> according to the present embodiment, and each dispatched vehicle X is trying to rendezvous with its user at the same or close meeting points. The &#x201c;close meeting points&#x201d; as used herein mean that the gestures of the persons at the respective meeting points are visible from one another. In this case, if a plurality of dispatched vehicles X require their user to do the same gesture, each dispatched vehicle X may mistakenly recognize a different person who is making the gesture as its user. This may inhibit smooth rendezvous. Accordingly, it is desirable to make adjustments such that the dispatched vehicles X avoid requiring their user to do the same gesture.</p><p id="p-0130" num="0129">In view of this, the rendezvous assistance device <b>102</b> mounted on each dispatched vehicle X shares the types of gestures that the other rendezvous assistance devices <b>102</b> require their user to do. For example, it is assumed that vehicles A, B, and C are at the same meeting point. First, when the vehicle communicator <b>14</b> in the rendezvous assistance device <b>102</b> of the vehicle A has transmitted a gesture G<b>1</b> to the mobile terminal <b>202</b>A of its user, this gesture G<b>1</b> is also transmitted as a used gesture to the rendezvous assistance devices <b>102</b> of the other vehicles B and C. In this way, the vehicles A to C share the information that the gesture G<b>1</b> has already been used. The vehicles B and C that issue a request for a gesture thereafter will request their user to do different gestures other than the gesture G<b>1</b>. At this time, for example, the gesture G<b>1</b> may be displayed in gray in order not to be selected on the gesture selection screen displayed on the display devices <b>33</b> of the rendezvous assistance devices <b>102</b> of the vehicles B and C. Next, when the vehicle communicator <b>14</b> in the rendezvous assistance device <b>102</b> of the vehicle B has transmitted a gesture G<b>2</b> to the mobile terminal <b>202</b>A of its user, similarly this gesture G<b>2</b> is also transmitted as a used gesture to the rendezvous assistance devices <b>102</b> of the other vehicles A and C. In the same manner as described above, the vehicle C becomes incapable of selecting the gestures G<b>1</b> and G<b>2</b>. The history of the used gestures accumulated in this manner will be reset after a lapse of a given period of time, e.g., 15 minutes.</p><p id="p-0131" num="0130">B-12. Variation 10</p><p id="p-0132" num="0131">Instead of adjusting gestures as described in &#x3c;B-11&#x3e;, the rendezvous assistance device <b>102</b> may again transmit a message that requests a user to do a gesture of a different type to the mobile terminal <b>202</b>A if numerous persons are doing the requested gesture at the meeting point. At this time, the driver may be allowed to select a newly required gesture on the gesture selection screen.</p><p id="p-0133" num="0132">B-13. Variation 11</p><p id="p-0134" num="0133">The above description given with reference to <figref idref="DRAWINGS">FIG. <b>12</b></figref>, for example, is based on the premise that the driver rides on the dispatched vehicle X. However, the driver may be a remote control operator who operates the dispatched vehicle X by remote control. In this case, the various input and output interfaces of the rendezvous assistance device <b>102</b> described above are provided not in the dispatched vehicle X but in the place where the remote control operator is present.</p><p id="p-0135" num="0134">C. Embodiment 3</p><p id="p-0136" num="0135">C-1. Configuration</p><p id="p-0137" num="0136"><figref idref="DRAWINGS">FIG. <b>31</b></figref> is a block diagram illustrating a configuration of a rendezvous assistance system <b>303</b> according to Embodiment 3. The rendezvous assistance system <b>303</b> includes a rendezvous assistance device <b>103</b> and a mobile terminal <b>203</b>. The rendezvous assistance device <b>103</b> is different from the rendezvous assistance device <b>102</b> according to Embodiment 2 in that it is connected to an outside-vehicle gesture recognition unit <b>36</b> and configured to be capable of using the outside-vehicle gesture recognition unit <b>36</b>. The outside-vehicle gesture recognition unit <b>36</b> is a device that is mounted on a dispatched vehicle X and recognizes a gesture of a person outside the dispatched vehicle X. For example, the outside-vehicle gesture recognition unit <b>36</b> may include a camera that captures an image around the dispatched vehicle X, and a processor that analyzes the image captured by the camera to recognize a gesture. On the basis of the result of gesture recognition by the outside-vehicle gesture recognition unit <b>36</b>, the vehicle controller <b>11</b> identifies, as its user, a person who is making a gesture required by the rendezvous assistance device <b>103</b> outside the dispatched vehicle X, and notifies the driver of the identified user via the display device <b>33</b> or the audio output device <b>34</b>.</p><p id="p-0138" num="0137">C-2. Operations</p><p id="p-0139" num="0138"><figref idref="DRAWINGS">FIG. <b>32</b></figref> is a flowchart illustrating operations of the rendezvous assistance device <b>103</b>. Hereinafter, the operations of the rendezvous assistance device <b>103</b> will be described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>32</b></figref>. Steps S<b>201</b> to S<b>208</b> are similar to those in the flowchart of processing of the rendezvous assistance device <b>102</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. After the vehicle communicator <b>14</b> has transmitted a message to the mobile terminal <b>203</b> in step S<b>208</b>, the vehicle controller <b>11</b> determines whether a person outside the vehicle has made the gesture required to do by the rendezvous assistance device <b>103</b> (hereinafter, referred to as the &#x201c;requested gesture&#x201d;) (step S<b>209</b>). When a person outside the vehicle has made the requested gesture, the outside-vehicle gesture recognition unit <b>36</b> detects this gesture and sends a notification to the vehicle controller <b>11</b>. The vehicle controller <b>11</b> makes this determination in step S<b>209</b> in accordance with the notification received from the outside-vehicle gesture recognition unit <b>36</b>. The vehicle controller <b>11</b> repeats step S<b>209</b> until a person outside the vehicle makes the requested gesture. When having determined in step S<b>209</b> that a person outside the vehicle has made the requested gesture, the vehicle controller <b>11</b> identifies the person who has made the gesture as its user and sends a notification indicating the result of user identification to the driver via the display device <b>33</b> or the audio output device <b>34</b> (step S<b>210</b>). Through the processing described above, the operations of the rendezvous assistance device <b>103</b> end.</p><p id="p-0140" num="0139"><figref idref="DRAWINGS">FIGS. <b>33</b> to <b>35</b></figref> show examples of display when the display device <b>33</b> provides a notification to the driver in step S<b>210</b>. In <figref idref="DRAWINGS">FIG. <b>33</b></figref>, objects <b>66</b>, <b>67</b>, and <b>68</b> are displayed, the object <b>66</b> representing the location of the dispatched vehicle X, the object <b>67</b> representing the location of the user, and the object <b>68</b> representing the direction of the user as viewed from the dispatched vehicle X. At first glance, the display in <figref idref="DRAWINGS">FIG. <b>33</b></figref> is similar to the display in <figref idref="DRAWINGS">FIG. <b>8</b></figref> described in Embodiment 2. However, the location of the user displayed in <figref idref="DRAWINGS">FIG. <b>33</b></figref> is the location identified by gesture recognition, whereas the location of the user displayed in <figref idref="DRAWINGS">FIG. <b>8</b></figref> is the location measured based on the GLASS signal and other information. Thus, the object <b>67</b> displays the location of the user with higher precision. This enables the driver to accurately grasp the location of the user.</p><p id="p-0141" num="0140">Although the location of the user is represented by the object <b>67</b> that imitates the mobile terminal in <figref idref="DRAWINGS">FIG. <b>33</b></figref>, the location of the user may be represented by an object <b>69</b> that imitates the gesture made by the user.</p><p id="p-0142" num="0141">Moreover, the vehicle controller <b>11</b> may superimpose and display a frame <b>73</b> that differentiates the user on the image of the meeting point on the display device <b>33</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>35</b></figref>. The image of the meeting point as used herein may be an image captured by the outside-vehicle gesture recognition unit <b>36</b>, or may be an image captured by an outside-vehicle image capturing device such as an electron mirror of the dispatched vehicle X. The vehicle controller <b>11</b> may also display a virtual image object that surrounds the user in the actual view on the display device <b>33</b>, which serves as a translucent display such as an HUD. The vehicle controller <b>11</b> may also detect the direction of the line of vision of the driver and execute display for guiding the line of vision of the driver to the user.</p><p id="p-0143" num="0142">As another alternative, the vehicle controller <b>11</b> may pause the image of the user who is making a gesture for a given period of time and display this image on the display device <b>33</b>, or may display the user in enlarged dimensions on the display device <b>33</b>.</p><p id="p-0144" num="0143">In the above description, the result of gesture recognition is notified of the driver via a display on the display device <b>33</b>. Besides this, the result of gesture recognition may be notified of the driver by audio by the audio output device <b>34</b>. For example, the vehicle controller <b>11</b> may use the location information on the user identified by gesture recognition and cause the audio output device <b>34</b> to output the direction of the user as viewed from the dispatched vehicle X by, for example, making an announcement saying &#x201c;Please look in the direction of 10 degrees on the right side.&#x201d;</p><p id="p-0145" num="0144">With this configuration, the driver is notified of the location of the user identified by gesture recognition via a display or audio. This eliminates the need for the driver to look around in order to visually recognize a person who is making a gesture.</p><p id="p-0146" num="0145">Alternatively, the vehicle controller <b>11</b> may cause the audio output device <b>34</b> to output an announcement about information other than the direction of the user, such as clothes and appearance of the user identified based on the result of gesture recognition. As another alternative, the vehicle controller <b>11</b> may notify the driver of only the fact that the gesture is recognized, via the display device <b>33</b> or the audio output device <b>34</b>. In this case, the driver is able to look for the user in full confidence that the user is making a gesture.</p><p id="p-0147" num="0146">C-3. Variation of Notifying Driver of Information that User is Recognized by Driver</p><p id="p-0148" num="0147">In the same manner as in Variation [B-<b>9</b>] of Embodiment 2, after step S<b>210</b> in <figref idref="DRAWINGS">FIG. <b>32</b></figref>, the rendezvous assistance device <b>103</b> may notify the mobile terminal <b>203</b> of the fact that the user is recognized b the driver. The fact that the &#x201c;user is recognized&#x201d; as used herein includes a case in which the driver recognizes the user on the display screen of the display device <b>33</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>35</b></figref>.</p><p id="p-0149" num="0148">D. Embodiment 4</p><p id="p-0150" num="0149">D-1. Configuration</p><p id="p-0151" num="0150"><figref idref="DRAWINGS">FIG. <b>36</b></figref> is a block diagram illustrating a configuration of a rendezvous assistance system <b>304</b> according to Embodiment 4. The rendezvous assistance system <b>304</b> includes a rendezvous assistance device <b>104</b> and a mobile terminal <b>204</b>. A dispatched vehicle X on which the rendezvous assistance device <b>104</b> is mounted is a full autonomous driving vehicle that includes an autonomous driving control device <b>37</b>. The autonomous driving control device <b>37</b> controls autonomous driving of the dispatched vehicle X. Thus, the dispatched vehicle X has no driver. Accordingly, the rendezvous assistance device <b>104</b> is different from the rendezvous assistance device <b>103</b> according to Embodiment 3 in that it is connected to the autonomous driving control device <b>37</b> and an outside-vehicle annunciator <b>38</b>, and configured to be capable of using these devices, instead of being connected to the display device <b>33</b>, the audio output device <b>34</b>, and the manipulator <b>35</b> that serve as input and output interfaces for the driver,. The outside-vehicle annunciator <b>38</b> is an annunciator that is mounted on the dispatched vehicle X and may, for example, be a klaxon, a turn-signal flasher unit, a lighting device, or an outside-vehicle display. The outside-vehicle annunciator <b>38</b> makes an announcement to the user who has been identified by the vehicle controller <b>11</b> on the basis of the result of recognition by the outside-vehicle gesture recognition unit <b>36</b>, so as to help the user notice the dispatched vehicle X.</p><p id="p-0152" num="0151">D-2. Operations</p><p id="p-0153" num="0152"><figref idref="DRAWINGS">FIG. <b>37</b></figref> is a flowchart illustrating operations of the rendezvous assistance device <b>104</b>. Hereinafter, the operations of the rendezvous assistance device <b>104</b> will be described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>37</b></figref>.</p><p id="p-0154" num="0153">When the autonomous driving control device <b>37</b> operates the dispatched vehicle X toward a meeting point by autonomous control, the positioner <b>13</b> acquires a GNSS signal from the GNSS receiver <b>31</b> and measures the location of the dispatched vehicle X (step S<b>401</b>). Then, the vehicle communicator <b>14</b> issues a request to transmit location information to the mobile terminal <b>204</b> and receives the location information on the mobile terminal <b>204</b> as location information on the user from the mobile terminal <b>204</b> (step S<b>402</b>).</p><p id="p-0155" num="0154">Then, the vehicle controller <b>11</b> determines whether a gesture request condition is satisfied (step S<b>403</b>). One example of the gesture request condition may be a condition about the positional relationship of the dispatched vehicle X, the meeting point, and the user, such as a condition that the distance between the dispatched vehicle X and the meeting point is within a predetermined distance, e.g., <b>50</b> m, and the user is within 10 m from the meeting point. When the gesture request condition is not satisfied in step S<b>403</b>, the processing of the rendezvous assistance device <b>104</b> returns to step S<b>401</b>.</p><p id="p-0156" num="0155">When the gesture request condition is satisfied in step S<b>403</b>, the message generator <b>12</b> automatically selects one gesture from among candidates for a gesture prepared in advance, and generates a message that requests the user to do the selected gesture (step S<b>404</b>). Here, the message generator <b>12</b> may give precedence to the candidates for a gesture, for example, in ascending order of load required for execution or in order of easiness of automatic recognition, and may select the gesture with highest precedence. As another alternative, the vehicle controller <b>11</b> may acquire current gestures that persons outside the vehicle are making from the outside-vehicle gesture recognition unit <b>36</b>, and the message generator <b>12</b> may exclude those gestures made by the persons outside the vehicle from the selection. Then, the vehicle communicator <b>14</b> transmits the message to the mobile terminal <b>204</b> (step S<b>405</b>).</p><p id="p-0157" num="0156">Thereafter, the vehicle controller <b>11</b> determines whether any person outside the vehicle has made the requested gesture (step S<b>406</b>). When the requested gesture is made by a person outside the vehicle, the outside-vehicle gesture recognition unit <b>36</b> detects this and sends a notification to the vehicle controller <b>11</b>. The vehicle controller <b>11</b> makes this determination in step S<b>406</b> in accordance with the notification received from the outside-vehicle gesture recognition unit <b>36</b>. The vehicle controller <b>11</b> repeats step S<b>406</b> until the requested gesture is made by a person outside the vehicle. When having determined in step S<b>406</b> that the requested gesture is made by a person outside the vehicle, the vehicle controller <b>11</b> identifies this person who is making the gesture as its user. Then, the vehicle controller <b>11</b> makes an announcement that the dispatched vehicle X is his/her dispatched vehicle to the user via the outside-vehicle annunciator <b>38</b> (step S<b>407</b>). Through the processing described above, the operations of the rendezvous assistance device <b>104</b> end.</p><p id="p-0158" num="0157">Next, an example of an announcement made via the outside-vehicle annunciator <b>38</b> will be described. <figref idref="DRAWINGS">FIG. <b>38</b></figref> shows an example in which an outside-vehicle display <b>72</b> provided on the front grille of the dispatched vehicle X serves as the outside-vehicle annunciator <b>38</b>. The outside-vehicle display <b>72</b> displays &#x201c;Hi, Msen!.&#x201d; Here, it is assumed that &#x201c;Msen&#x201d; represents identification information that is specific to the user and provided from the mobile terminal <b>204</b> to the rendezvous assistance device <b>104</b> and stored in the storage <b>15</b> when a vehicle dispatch contract is concluded between the user and the dispatched vehicle X.</p><p id="p-0159" num="0158"><figref idref="DRAWINGS">FIG. <b>39</b></figref> shows an example in which the headlights of the dispatched vehicle X serve as the outside-vehicle annunciator <b>38</b>. An announcement is made to the user by irradiating the foot of the user with the headlights. In the rendezvous assistance device <b>104</b> in which the user is identified by gesture recognition, the location of the user can be identified with high precision. Accordingly, it is possible to make an announcement as illustrated in <figref idref="DRAWINGS">FIG. <b>39</b></figref>, using the location information on the user identified with high precision.</p><p id="p-0160" num="0159">The outside-vehicle annunciator <b>38</b> may make an announcement only while the user is making a gesture.</p><p id="p-0161" num="0160">E. Embodiment 5</p><p id="p-0162" num="0161">E-1. Configuration</p><p id="p-0163" num="0162"><figref idref="DRAWINGS">FIG. <b>40</b></figref> is a block diagram illustrating a configuration of a rendezvous assistance system <b>305</b> according to Embodiment 5. The rendezvous assistance system <b>305</b> includes a rendezvous assistance device <b>105</b>, a mobile terminal <b>205</b>, and a vehicle dispatch server <b>401</b>. The configurations of the rendezvous assistance device <b>105</b> and the mobile terminal <b>205</b> are similar to the configurations of the rendezvous assistance device <b>102</b> and the mobile terminal <b>202</b>A according to Embodiment 2.</p><p id="p-0164" num="0163">The vehicle dispatch server <b>401</b> configures a communication network with the communication device <b>32</b> and the mobile communicator <b>22</b>. The descriptions in Embodiments 1 to 4 are given on the premise that a vehicle dispatch contract has been concluded between the rendezvous assistance device and the mobile terminal. In the rendezvous assistance system <b>305</b>, the vehicle dispatch server <b>401</b> performs processing for concluding a vehicle dispatch contract. Operations of the rendezvous assistance system <b>305</b> other than the processing for concluding a vehicle dispatch contract are similar to the operations of the rendezvous assistance system <b>302</b>A according to Embodiment 2, and therefore the following description focuses on the processing for concluding a vehicle dispatch contract.</p><p id="p-0165" num="0164">E-2. Operations</p><p id="p-0166" num="0165"><figref idref="DRAWINGS">FIG. <b>41</b></figref> is a flowchart illustrating operations of the vehicle dispatch server <b>401</b>. Hereinafter, the operations of the vehicle dispatch server <b>401</b> will be described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>41</b></figref>. First, the vehicle dispatch server <b>401</b> receives a vehicle dispatch request from the mobile terminal <b>205</b> (step S<b>501</b>). The vehicle dispatch request includes information on the meeting point and may further include conditions that are required for the dispatched vehicle by the user, such as desired vehicle type.</p><p id="p-0167" num="0166">Then, the vehicle dispatch server <b>401</b> sounds out the rendezvous assistance device <b>105</b> of at least one dispatched vehicle X that satisfies the vehicle dispatch request about whether vehicle dispatch is possible (step S<b>502</b>). If there are no conditions for requesting vehicle dispatch, the vehicle dispatch server <b>401</b> may sound out the rendezvous assistance device <b>105</b> of at least one dispatched vehicle X that is close to the meeting point about whether vehicle dispatch is possible. Here, the vehicle dispatch server <b>401</b> may sound out the rendezvous assistance device <b>105</b> of an autonomous driving vehicle preferentially about whether vehicle dispatch is possible.</p><p id="p-0168" num="0167">Then, the vehicle dispatch server <b>401</b> receives a response to the inquiry about whether vehicle dispatch is possible from the rendezvous assistance device <b>105</b> of the dispatched vehicle X that has been sounded out about the possibility of vehicle dispatch (step S<b>503</b>). Then, the vehicle dispatch server <b>401</b> transmits to the mobile terminal <b>205</b> information on the dispatched vehicle X from which the response indicating that vehicle dispatch is possible has been received (step S<b>504</b>). Thereafter, the vehicle dispatch server <b>401</b> receives, from the mobile terminal <b>205</b>, information on the user's profile and information on the dispatched vehicle X that is selected as a dispatched vehicle by the user (selected vehicle information) (step S<b>505</b>).</p><p id="p-0169" num="0168">Then, the vehicle dispatch server <b>401</b> transmits the user's profile to the rendezvous assistance device <b>105</b> of the dispatched vehicle X selected as a dispatched vehicle by the user, and sends a notification about the conclusion of a contract to both of the dispatched vehicle X and the rendezvous assistance device <b>105</b> of the mobile terminal <b>205</b> (step S<b>506</b>). The user's profile as used herein may include, for example, payment information for the user, information about where to make contact, and the identification information referred to in &#x3c;B-7&#x3e;.</p><p id="p-0170" num="0169">Although the vehicle dispatch server <b>401</b> performs the processing for concluding a vehicle dispatch contract in the above description, the rendezvous assistance device <b>105</b> and the mobile terminal <b>205</b> may directly perform the processing for concluding a vehicle contract.</p><p id="p-0171" num="0170">F. Hardware Configuration</p><p id="p-0172" num="0171">In the rendezvous assistance devices <b>101</b> to <b>105</b> described above, the vehicle controller <b>11</b>, the message generator <b>12</b>, the positioner <b>13</b>, the vehicle communicator <b>14</b>, and the storage <b>15</b> are implemented via a processing circuit <b>81</b> illustrated in <figref idref="DRAWINGS">FIG. <b>42</b></figref>. That is, the processing circuit <b>81</b> that configures each of the rendezvous assistance devices <b>101</b> to <b>105</b> includes the vehicle controller <b>11</b>, the message generator <b>12</b>, the positioner <b>13</b>, the vehicle communicator <b>14</b>, and the storage <b>15</b> (hereinafter, referred to as the &#x201c;vehicle controller <b>11</b> and other constituent elements&#x201d;). In the mobile terminals <b>201</b>, <b>202</b>A, <b>202</b>B, and <b>203</b> to <b>205</b> described above, the mobile controller <b>21</b>, the mobile communicator <b>22</b>, and the positioner <b>24</b> are also implemented via the processing circuit <b>81</b> illustrated in <figref idref="DRAWINGS">FIG. <b>42</b></figref>. That is, the processing circuit <b>81</b> that configures each of the mobile terminals <b>201</b>, <b>202</b>A, <b>202</b>B, and <b>203</b> to <b>205</b> includes the mobile controller <b>21</b>, the mobile communicator <b>22</b>, and the positioner <b>24</b> (hereinafter, referred to as the &#x201c;mobile controller <b>21</b> and other constituent elements&#x201d;).. For example, dedicated hardware may be applied to the processing circuit <b>81</b>, or a processor that executes programs stored in a memory may be applied to the processing circuit <b>81</b>. Examples of the processor include a central processing unit, a processing device, an arithmetic unit, a microprocessor, a microcomputer, and a digital signal processor (DSP).</p><p id="p-0173" num="0172">In the case where the processing circuit <b>81</b> is dedicated hardware, the processing circuit <b>81</b> corresponds to, for example, a single circuit, a composite circuit, a programmed processor, a parallel-programmed processor, an application specific integrated circuit (ASIC), a field-programmable gate array (FPGA), or any combination of these circuits. The functions of constituent elements, such as the vehicle controller <b>11</b> and other constituent elements or the mobile controller <b>21</b> and other constituent elements, may be implemented via a plurality of processing circuits <b>81</b>, or may be collectively implemented via a single processing circuit.</p><p id="p-0174" num="0173">In the case where the processing circuit <b>81</b> is a processor, the functions of constituent elements, such as the vehicle controller <b>11</b> and other constituent elements or the mobile controller <b>21</b> and other constituent elements, are implemented by combination with software (e.g., software, firmware, or both software and firmware). The software or the like is described as a program and stored in a memory. As illustrated in <figref idref="DRAWINGS">FIG. <b>43</b></figref>, a processor <b>82</b> that is applied to the processing circuit <b>81</b> achieves the function of each constituent element by reading and executing programs stored in a memory <b>83</b>. That is, each of the rendezvous assistance devices <b>101</b> to <b>105</b> includes the memory <b>83</b> that stores a program for causing the processing circuit <b>81</b> to eventually execute a step of generating a message that requests a user to do a gesture, a step of transmitting the message to the mobile terminal <b>201</b>, <b>202</b>A, <b>202</b>B, or <b>203</b> to <b>205</b> when the dispatched vehicle is at or around the meeting point. In other words, it can also be said that this program causes a computer to execute the procedure or method performed by the vehicle controller <b>11</b> and other constituent elements. Each of the mobile terminals <b>201</b>, <b>202</b>A, <b>202</b>B, and <b>203</b> to <b>205</b> also includes the memory <b>83</b> that stores a program for causing the processing circuit <b>81</b> to eventually execute a step of receiving a message from the rendezvous assistance devices <b>101</b> to <b>105</b> and the step of sending a notification that requests the user to do a gesture to the user on the basis of the message. In other words, it can also be said that this program causes a computer to execute the procedure or method performed by the mobile controller <b>21</b> and other constituent elements. Examples of the memory <b>83</b> may include non-volatile or volatile semiconductor memories such as a random access memory (RAM), a read only memory (ROM), a flash memory, an erasable programmable read only memory (EPROM), or an electrically erasable programmable read only memory (EEPROM), a hard disk drive (HDD), a magnetic disk, a flexible disk, an optical disk, a compact disk, a mini-disk, a digital versatile disk (DVD), and drivers for these disks, and or any other possible storage medium that may be used in the future.</p><p id="p-0175" num="0174">In the configurations described above, the functions of the vehicle controller <b>11</b> and other constituent elements and the mobile controller <b>21</b> and constituent elements are implemented via either hardware or software. However, the present disclosure is not limited thereto, and the rendezvous assistance devices <b>101</b> to <b>105</b> may be configured such that some of the vehicle controller <b>11</b> and other constituent elements are implemented via dedicated hardware, and the other constituent elements are implemented via software. The mobile terminals <b>201</b>, <b>202</b>A, <b>202</b>B, and <b>203</b> to <b>205</b> may also be configured such that some of the mobile controller <b>21</b> and other constituent elements are implemented via dedicated hardware, and the other constituent elements are implemented via software.</p><p id="p-0176" num="0175">As described above, the processing circuits can achieve each of the above-described functions via hardware, software, or any other service or via any combination of them. Although the storage <b>15</b> is configured with the memory <b>83</b>, the storage <b>15</b> may be configured with a single memory <b>83</b>, or with individual memories. The same applies to the storage <b>30</b>.</p><p id="p-0177" num="0176">Although the rendezvous assistance devices <b>101</b> to <b>105</b> are on-vehicle devices in the above description, the present disclosure is also applicable to systems that are constructed by appropriately combining a portable navigation device (PND), a communication terminal (e.g., a mobile terminal such as a mobile phone, a smartphone, or a tablet), the functions of applications installed in these devices, and servers (including the vehicle dispatch server <b>401</b> and other servers). In this case, the functions or constituent elements of the rendezvous assistance devices <b>101</b> to <b>105</b> described above may be distributed into and arranged in each equipment that constructs a system, or may be collectively arranged in any one equipment.</p><p id="p-0178" num="0177">While the invention has been shown and described in detail, the foregoing description is in all aspects illustrative and not restrictive. It is therefore to be understood that numerous modifications and variations can be devised without departing from the scope of the invention.</p><p id="p-0179" num="0178">Explanation of Reference Signs<ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0179"><b>11</b> vehicle controller</li>    <li id="ul0002-0002" num="0180"><b>12</b> message generator</li>    <li id="ul0002-0003" num="0181"><b>13</b> positioner</li>    <li id="ul0002-0004" num="0182"><b>14</b> vehicle communicator</li>    <li id="ul0002-0005" num="0183"><b>15</b> storage</li>    <li id="ul0002-0006" num="0184"><b>21</b> mobile controller</li>    <li id="ul0002-0007" num="0185"><b>22</b> mobile communicator</li>    <li id="ul0002-0008" num="0186"><b>23</b> notification unit</li>    <li id="ul0002-0009" num="0187"><b>24</b> positioner</li>    <li id="ul0002-0010" num="0188"><b>25</b> operation unit</li>    <li id="ul0002-0011" num="0189"><b>26</b> display</li>    <li id="ul0002-0012" num="0190"><b>27</b> audio output unit</li>    <li id="ul0002-0013" num="0191"><b>28</b> rear camera</li>    <li id="ul0002-0014" num="0192"><b>29</b> front camera</li>    <li id="ul0002-0015" num="0193"><b>30</b> storage</li>    <li id="ul0002-0016" num="0194"><b>31</b> GNSS receiver</li>    <li id="ul0002-0017" num="0195"><b>32</b> communication device</li>    <li id="ul0002-0018" num="0196"><b>33</b> display</li>    <li id="ul0002-0019" num="0197"><b>34</b> audio output device</li>    <li id="ul0002-0020" num="0198"><b>35</b> manipulator</li>    <li id="ul0002-0021" num="0199"><b>36</b> outside-vehicle gesture recognition unit</li>    <li id="ul0002-0022" num="0200"><b>37</b> autonomous driving control device</li>    <li id="ul0002-0023" num="0201"><b>38</b> outside-vehicle annunciator</li>    <li id="ul0002-0024" num="0202"><b>50</b> to <b>52</b>, <b>66</b> to <b>69</b> object</li>    <li id="ul0002-0025" num="0203"><b>54</b> to <b>56</b> icon</li>    <li id="ul0002-0026" num="0204"><b>70</b> display</li>    <li id="ul0002-0027" num="0205"><b>71</b> speaker</li>    <li id="ul0002-0028" num="0206"><b>72</b> outside-vehicle display</li>    <li id="ul0002-0029" num="0207"><b>81</b> processing circuit</li>    <li id="ul0002-0030" num="0208"><b>82</b> processor</li>    <li id="ul0002-0031" num="0209"><b>83</b> memory</li>    <li id="ul0002-0032" num="0210"><b>101</b> to <b>105</b> rendezvous assistance device</li>    <li id="ul0002-0033" num="0211"><b>201</b>, <b>202</b>A, <b>202</b>B, <b>203</b> to <b>205</b> mobile terminal</li>    <li id="ul0002-0034" num="0212"><b>301</b>, <b>302</b>A, <b>302</b>B, <b>303</b> to <b>305</b> rendezvous assistance system</li>    <li id="ul0002-0035" num="0213"><b>401</b> vehicle dispatch server</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-01-19" num="01-19"><claim-text><b>1</b>-<b>19</b>. (canceled)</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A rendezvous assistance system comprising:<claim-text>a mobile terminal carried by a user who wants to rendezvous with a dispatched vehicle; and</claim-text><claim-text>a rendezvous assistance device that communicates with the mobile terminal and assists rendezvous of the dispatched vehicle and the user at a meeting point,</claim-text><claim-text>the rendezvous assistance device including:</claim-text><claim-text>a first processor to execute a first program; and</claim-text><claim-text>a first memory to store the first program which, when execute by the first processor, performs processes of,</claim-text><claim-text>generating a message that requests the user to do a gesture,</claim-text><claim-text>determining timing when the dispatched vehicle is at or around the meeting point as timing of transmission of the message,</claim-text><claim-text>wherein the message includes a type of the gesture, the type of the gesture including a body-part attribute and a motion attribute, the body-part attribute indicating a body part that makes the gesture, and an motion attribute indicating how the body part indicated by the body-part attribute is moved,</claim-text><claim-text>determining the type of the gesture specified by the driver of the dispatched vehicle as the type of the gesture to be included in the message, and</claim-text><claim-text>transmitting the message to the mobile terminal with the timing of transmission, and the mobile terminal including:</claim-text><claim-text>a second processor to execute a second program; and</claim-text><claim-text>a second memory to store the second program which, when execute by the second processor, performs processes of,</claim-text><claim-text>receiving the message from the rendezvous assistance device, and</claim-text><claim-text>sending a notification that requests the user to do the gesture in accordance with the message.</claim-text></claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein<claim-text>the rendezvous assistance device causes a display mounted on the dispatched vehicle to display a positional relationship of the dispatched vehicle, the meeting point, and the mobile terminal.</claim-text></claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein<claim-text>the rendezvous assistance device acquires driver operation information on the dispatched vehicle and causes the display to display the positional relationship of the dispatched vehicle, the meeting point, and the mobile terminal with timing based on the driver operation information.</claim-text></claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein<claim-text>the rendezvous assistance device acquires driver operation information on the dispatched vehicle and determines the timing of transmission of the message in accordance with timing based on the driver operation information.</claim-text></claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein<claim-text>the rendezvous assistance device causes a display mounted on the dispatched vehicle to display a gesture selection screen for selecting the type of the gesture, and determines the type of the gesture to be included in the message in accordance with a result of selection made by a driver of the dispatched vehicle on the gesture selection screen.</claim-text></claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein<claim-text>the rendezvous assistance device determines the type of the gesture to be included in the message from a result of recognizing a speech voice of a driver of the dispatched vehicle.</claim-text></claim-text></claim><claim id="CLM-00026" num="00026"><claim-text><b>26</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein<claim-text>the rendezvous assistance device acquires a result of recognizing a gesture of a driver of the dispatched vehicle from an on-vehicle gesture recognition unit and determines the type of the gesture to be included in the message from the result of recognizing the gesture of the driver, the on-vehicle gesture recognition being mounted on the dispatched vehicle and recognizing a gesture of a person in the dispatched vehicle.</claim-text></claim-text></claim><claim id="CLM-00027" num="00027"><claim-text><b>27</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein<claim-text>when executed by the second processor, the second program performs processes of, acquiring operation information on the user,</claim-text><claim-text>when acquiring operation information on an intention of the user to do the gesture, the mobile terminal transmits information that indicates the intension of the user to do the gesture to the rendezvous assistance device, and</claim-text><claim-text>the rendezvous assistance device notifies the driver of the dispatched vehicle of the intention of the user to do the gesture.</claim-text></claim-text></claim><claim id="CLM-00028" num="00028"><claim-text><b>28</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00027">claim 27</claim-ref>, wherein<claim-text>when the user does not do the gesture, the mobile terminal acquires, from the user, operation input of identification information for identifying the user,</claim-text><claim-text>the mobile terminal transmits the identification information to the rendezvous assistance device, and</claim-text><claim-text>the rendezvous assistance device notifies the driver of the dispatched vehicle of the identification information.</claim-text></claim-text></claim><claim id="CLM-00029" num="00029"><claim-text><b>29</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein<claim-text>the mobile terminal acquires a location of the dispatched vehicle from the rendezvous assistance device, and</claim-text><claim-text>when a distance between the dispatched vehicle and the mobile terminal is less than a threshold value, the mobile terminal notifies the user of information indicating that the distance between the dispatched vehicle and the mobile terminal is less than the threshold value.</claim-text></claim-text></claim><claim id="CLM-00030" num="00030"><claim-text><b>30</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein<claim-text>the mobile terminal acquires a location of the dispatched vehicle from the rendezvous assistance device, and</claim-text><claim-text>the mobile terminal notifies the user of a direction of approach of the dispatched vehicle to the meeting point.</claim-text></claim-text></claim><claim id="CLM-00031" num="00031"><claim-text><b>31</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein<claim-text>the rendezvous assistance device acquires a result of recognizing a gesture from an outside-vehicle gesture recognition unit that is mounted on the dispatched vehicle and that recognizes a gesture of a person who is outside the dispatched vehicle.</claim-text></claim-text></claim><claim id="CLM-00032" num="00032"><claim-text><b>32</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00030">claim 30</claim-ref>, wherein<claim-text>the rendezvous assistance device identifies a person who is doing the gesture requested to do by the message outside the dispatched vehicle as the user in accordance with the result of recognizing a gesture by the outside-vehicle gesture recognition unit, and notifies the driver of the dispatched vehicle of the user identified.</claim-text></claim-text></claim><claim id="CLM-00033" num="00033"><claim-text><b>33</b>. A rendezvous assistance system comprising:<claim-text>a mobile terminal carried by a user who wants to rendezvous with a dispatched vehicle; and</claim-text><claim-text>a rendezvous assistance device that communicates with the mobile terminal and assists rendezvous of the dispatched vehicle and the user at a meeting point,</claim-text><claim-text>the rendezvous assistance device including:</claim-text><claim-text>a first processor to execute a first program; and</claim-text><claim-text>a first memory to store the first program which, when execute by the first processor, performs processes of,</claim-text><claim-text>generating a message that requests the user to do a gesture,</claim-text><claim-text>determining timing when the dispatched vehicle is at or around the meeting point as timing of transmission of the message,</claim-text><claim-text>transmitting the message to the mobile terminal with the timing of transmission,</claim-text><claim-text>acquiring a result of recognizing a gesture from an outside-vehicle gesture recognition unit that is mounted on the dispatched vehicle and that recognizes a gesture of a person who is outside the dispatched vehicle, and</claim-text><claim-text>identifying a person who is doing the gesture requested to do by the message outside the dispatched vehicle as the user in accordance with the result of recognizing a gesture by the outside-vehicle gesture recognition unit, and causing an outside-vehicle annunciator mounted on the dispatched vehicle to make an announcement to the user, and</claim-text><claim-text>the mobile terminal including:</claim-text><claim-text>a second processor to execute a second program; and</claim-text><claim-text>a second memory to store the second program which, when execute by the second processor, performs processes of,</claim-text><claim-text>receiving the message from the rendezvous assistance device, and</claim-text><claim-text>sending a notification that requests the user to do the gesture in accordance with the message, wherein</claim-text><claim-text>the dispatched vehicle is a full autonomous driving vehicle.</claim-text></claim-text></claim><claim id="CLM-00034" num="00034"><claim-text><b>34</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00033">claim 33</claim-ref>, wherein<claim-text>the outside-vehicle annunciator is an outside-vehicle display provided on an outer surface of the dispatched vehicle, and</claim-text><claim-text>the rendezvous assistance device makes an announcement to the user by displaying identification information on the user on the outside-vehicle display.</claim-text></claim-text></claim><claim id="CLM-00035" num="00035"><claim-text><b>35</b>. The rendezvous assistance system according to <claim-ref idref="CLM-00033">claim 33</claim-ref>, wherein<claim-text>the outside-vehicle annunciator is a headlight of the dispatched vehicle, and</claim-text><claim-text>the rendezvous assistance device makes an announcement to the user by irradiating the user with the headlight.</claim-text></claim-text></claim><claim id="CLM-00036" num="00036"><claim-text><b>36</b>. A rendezvous assistance method comprising:<claim-text>generating a message that requests a user who wants to rendezvous with a dispatched vehicle to do a gesture;</claim-text><claim-text>determining timing when the dispatched vehicle is at or around a meeting point with the user as timing of transmission of the message; and</claim-text><claim-text>transmitting the message to a mobile terminal of the user with the timing of transmission, wherein</claim-text><claim-text>the message includes a type of the gesture, the type of the gesture including a body-part attribute and a motion attribute, the body-part attribute indicating a body part that makes the gesture, and an motion attribute indicating how the body part indicated by the body-part attribute is moved, and</claim-text><claim-text>the type of the gesture to be included in the message is specified by a driver of the dispatched vehicle.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005498A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005498</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17366782</doc-number><date>20210702</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>10</class><subclass>L</subclass><main-group>25</main-group><subgroup>78</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>10</class><subclass>L</subclass><main-group>21</main-group><subgroup>0272</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>10</class><subclass>L</subclass><main-group>25</main-group><subgroup>18</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>L</subclass><main-group>25</main-group><subgroup>78</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>L</subclass><main-group>21</main-group><subgroup>0272</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>L</subclass><main-group>25</main-group><subgroup>18</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">Detecting and Compensating for the Presence of a Speaker Mask in a Speech Signal</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Digital Voice Systems, Inc.</orgname><address><city>Westford</city><state>MA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Clark</last-name><first-name>Thomas</first-name><address><city>Westford</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Hardwick</last-name><first-name>John C.</first-name><address><city>Acton</city><state>MA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Compensating a speech signal for the presence of a speaker mask includes receiving a speech signal, dividing the speech signal into subframes, generating speech parameters for a subframe, and determining whether the subframe is suitable for use in detecting a mask. If the subframe is suitable for use in detecting a mask, the speech parameters for the subframe are used in determining whether a mask is present. If a mask is present, the speech parameters for the subframe are modified to produce modified speech parameters that compensate for the presence of the mask.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="216.58mm" wi="103.29mm" file="US20230005498A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="221.15mm" wi="164.93mm" file="US20230005498A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="218.61mm" wi="107.10mm" file="US20230005498A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="201.00mm" wi="145.88mm" orientation="landscape" file="US20230005498A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">This description relates generally to the processing of speech.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Speech is generally considered to be a non-stationary signal having signal properties that change over time. These changes in signal properties are generally linked to changes made in the properties of a person's vocal tract to produce different sounds. A sound is typically sustained for some short period, such as 10-100 ms, and then the vocal tract is changed again to produce the next sound. The transition between sounds may be slow and continuous or it may be rapid as in the onset of speech.</p><p id="p-0004" num="0003">A speech signal corresponding to recorded or transmitted speech may be processed to enhance the quality and intelligibility of the speech. This processing may be part of speech encoding, which is also known as speech compression, which seeks to reduce the data rate needed to represent a speech signal without substantially reducing the quality or intelligibility of the speech. Speech compression techniques may be implemented by a speech coder, which also may be referred to as a voice coder or vocoder.</p><p id="p-0005" num="0004">A speech coder is generally viewed as including an encoder and a decoder. The encoder produces a compressed stream of bits from a digital representation of speech, such as may be generated at the output of an analog-to-digital converter having as an input an analog signal produced by a microphone. The decoder converts the compressed bit stream into a digital representation of speech that is suitable for playback through a digital-to-analog converter and a speaker. In many applications, the encoder and the decoder are physically separated, and the bit stream is transmitted between them using a communication channel.</p><p id="p-0006" num="0005">A key parameter of a speech coder is the amount of compression the coder achieves, which is measured by the bit rate of the stream of bits produced by the encoder. The bit rate of the encoder is generally a function of the desired fidelity (i.e., speech quality) and the type of speech coder employed. Different types of speech coders have been designed to operate at different bit rates. For example, low to medium rate speech coders may be used in mobile communication applications. These applications typically require high quality speech and robustness to artifacts caused by acoustic noise and channel noise (e.g., bit errors).</p><p id="p-0007" num="0006">One approach for low to medium rate speech coding is a model-based speech coder or vocoder. A vocoder models speech as the response of a system to excitation over short time intervals. Examples of vocoder systems include linear prediction vocoders such as MELP, homomorphic vocoders, channel vocoders, sinusoidal transform coders (&#x201c;STC&#x201d;), harmonic vocoders and multiband excitation (&#x201c;MBE&#x201d;) vocoders. In these vocoders, speech is divided into short segments (typically 10-40 ms), with each segment being characterized by a set of model parameters. These parameters typically represent a few basic elements of each speech segment, such as the segment's pitch, voicing state, and spectral envelope. A vocoder may use one of a number of known representations for each of these parameters. For example, the pitch may be represented as a pitch period, a fundamental frequency or pitch frequency (which is the inverse of the pitch period), or a long-term prediction delay. Similarly, the voicing state may be represented by one or more voicing metrics, by a voicing probability measure, or by a set of voicing decisions. The spectral envelope may be represented by a set of spectral magnitudes or other spectral measurements. Since they permit a speech segment to be represented using only a small number of parameters, model-based speech coders, such as vocoders, typically are able to operate at medium to low data rates. However, the quality of a model-based system is dependent on the accuracy of the underlying model. Accordingly, a high fidelity model must be used if these speech coders are to achieve high speech quality.</p><p id="p-0008" num="0007">An MBE vocoder is a harmonic vocoder based on the MBE speech model that has been shown to work well in many applications. The MBE vocoder combines a harmonic representation for voiced speech with a flexible, frequency-dependent voicing structure based on the MBE speech model. This allows the MBE vocoder to produce natural sounding unvoiced speech and makes the MBE vocoder robust to the presence of acoustic background noise. These properties allow the MBE vocoder to produce higher quality speech at low to medium data rates and have led to its use in a number of commercial mobile communication applications.</p><p id="p-0009" num="0008">The MBE vocoder (like other vocoders) analyzes speech at fixed intervals, with typical intervals being 10 ms or 20 ms. The result of the MBE analysis is a set of MBE model parameters including a fundamental frequency, a set of voicing errors, a gain value, and a set of spectral magnitudes. The model parameters are then quantized at a fixed interval, such as 20 ms, to produce quantizer bits at the vocoder bit rate. At the decoder, the model parameters are reconstructed from the received bits. For example, model parameters may be reconstructed at 20 ms intervals, and then overlapping speech segments may be synthesized and added together at 10 ms intervals.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0010" num="0009">Techniques are provided for detecting whether a speech signal has been &#x201c;muffled&#x201d; by a mask being worn by the person who spoke to produce the speech signal, and for boosting the speech to reverse the muffling caused by the mask, while limiting the boosting of background noise.</p><p id="p-0011" num="0010">In one general aspect, compensating a speech signal for the presence of a speaker mask includes receiving a speech signal, dividing the speech signal into subframes, generating speech parameters for a subframe, and determining whether the subframe is suitable for use in detecting a mask. If the subframe is suitable for use in detecting a mask, the speech parameters for the subframe are used in determining whether a mask is present. If a mask is present, the speech parameters for the subframe are modified to produce modified speech parameters that compensate for the presence of the mask.</p><p id="p-0012" num="0011">Implementations may include one or more of the following features. For example, the speech parameters for the subframe may include a speech spectrum and spectral band energies for multiple voice bands, and using the speech parameters for the subframe in determining whether a mask is present may include examining a spectral slope for a subset of the voice bands. For example, a subset of the voice bands in the frequency range from 750 Hz to 4000 Hz may be examined. Determining whether a mask is present may include comparing the spectral slope to a threshold value and determining that a mask is present when the spectral slope exceeds the threshold value. Determining whether a mask is present also may include updating an average spectral slope corresponding to multiple subframes using the speech parameters for the subframe and examining the updated average spectral slope for a subset of the voice bands.</p><p id="p-0013" num="0012">Determining whether the subframe is suitable for use in detecting a mask also may include determining whether signal energy of the subframe exceeds a threshold value.</p><p id="p-0014" num="0013">Modifying the speech parameters for the subframe to produce modified speech parameters that compensate for the presence of the mask may include boosting gains in a subset of voice bands affected by the presence of a mask. Boost levels may vary between voice bands in the subset of voice bands. For example, boost levels may be reduced for any voice bands in the subset of voice bands that do not include signal energy that exceeds noise energy by a threshold margin.</p><p id="p-0015" num="0014">The speech parameters may be model parameters of a Multi-Band Excitation speech model.</p><p id="p-0016" num="0015">In another general aspect, a communications device configured to compensate a speech signal for the presence of a speaker mask includes a microphone, a speech encoder that receives a speech signal from the microphone and generates digital speech parameters, and a transmitter that receives the digital speech parameters from the speech encoder and transmits the digital speech parameters. The speech encoder may be configured to divide the speech signal into subframes, generate speech parameters for a subframe, and determine whether the subframe is suitable for use in detecting a mask. If the subframe is suitable for use in detecting a mask, the speech encoder may use the speech parameters for the subframe in determining whether a mask is present. If a mask is present, the speech encoder may modify the speech parameters for the subframe to produce modified speech parameters that compensate for the presence of the mask and provide the modified speech parameters to the transmitter as the digital speech parameters.</p><p id="p-0017" num="0016">Implementations may include one or more of the features discussed above.</p><p id="p-0018" num="0017">In another general aspect, a speech encoder configured to compensate a speech signal for the presence of a speaker mask is configured to receive a speech signal, divide the speech signal into subframes, generate speech parameters for a subframe, and determine whether the subframe is suitable for use in detecting a mask. If the subframe is suitable for use in detecting a mask, the speech encoder may use the speech parameters for the subframe in determining whether a mask is present. If a mask is present, the speech encoder may modify the speech parameters for the subframe to produce modified speech parameters that compensate for the presence of the mask and provide the modified speech parameters to the transmitter as the digital speech parameters.</p><p id="p-0019" num="0018">Implementations may include one or more of the features discussed above.</p><p id="p-0020" num="0019">Other features will be apparent from the following description, including the drawings, and the claims.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">DESCRIPTION OF DRAWINGS</heading><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of a speech processing system employing mask detection and compensation.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a graph of the frequency response of a cloth mask.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow chart showing operation of a speech processing system.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram of a communications device.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0025" num="0024">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a speech processing system <b>100</b> may be employed to detect the presence of a mask and to compensate for the mask to improve quality and intelligibility of a speech signal. The system <b>100</b> includes a mask detector <b>105</b> and a mask compensator <b>110</b>. The mask detector <b>105</b> receives an analog or digital speech signal <b>115</b> and processes the speech signal <b>115</b> to determine whether the speaker who spoke the speech corresponding to the speech signal <b>115</b> was wearing a mask when doing so. The mask detector <b>105</b> provides the mask compensator <b>110</b> with an indication <b>120</b> of whether a mask is present and speech parameters <b>125</b> corresponding to the speech signal (which may include the speech signal itself).</p><p id="p-0026" num="0025">The mask compensator <b>110</b> receives the indication <b>120</b> and speech parameters <b>125</b> and, when a mask is present, modifies the speech parameters <b>125</b> to account for the presence of the mask. The mask compensator then produces output speech <b>130</b> that has been modified to account for the presence of a mask. The output speech may include speech parameters, an analog or digital speech signal, or sound produced by a speaker within the mask compensator <b>110</b>.</p><p id="p-0027" num="0026">Wearing a mask while speaking has been observed to cause negative impact to the quality and intelligibility of speech, such as speech corresponding to the speech signal <b>115</b>. The mask, whether it is a cloth mask or an N95 mask, acts like a filter. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the frequency response <b>200</b> of a speech signal is generally attenuated most at higher frequencies. The attenuation of speech in dB has been observed to be generally linear with frequency. At frequencies below 750 Hz, the attenuation is negligible, but the attenuation increases linearly to around 12 dB at 4 kHz for a typical cloth mask.</p><p id="p-0028" num="0027">In one implementation, the mask detector <b>105</b> determines whether a mask is present by examining the spectral slope of the speech signal. When a mask is detected, the mask compensator <b>110</b> applies an inverse filter to correct for the mask by boosting impacted portions of the speech signal. This correction is complicated by the presence of background noise, as simply applying a static inverse filter to the signal would amplify the background noise as well as the signal. To account for noise, the mask compensator <b>110</b> dynamically weights the filter such that the mask correcting boost is eliminated when the signal is primarily noise. The mask compensator <b>110</b> also may apply the boost in frequency bands that contain primarily signal while not applying the boost in frequency bands that are dominated by noise.</p><p id="p-0029" num="0028">Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the speech processing system <b>100</b> may operate according to a procedure <b>300</b>. Initially, the speech signal <b>115</b> is divided into subframes (step <b>305</b>). Each subframe corresponds to a 10 ms window of the speech signal <b>115</b> generated using a 25 ms hamming window.</p><p id="p-0030" num="0029">Speech parameters then are generated for a subframe (step <b>310</b>). This includes computing a 256-point DFT on the windowed speech corresponding to the subframe to produce a speech spectrum. The speech spectrum is used to calculate sixteen spectral band energies for bands that are each 250 Hz wide, where the mask detector <b>105</b> examines the spectral slope of voice bands in the spectrum between 750 Hz and 4000 Hz to determine whether a mask is present. The spectral band energies are used to estimate noise levels in the sixteen bands. The noise estimation is made by averaging the signal levels in each band over time and by tracking the minimum signal level observed in each band.</p><p id="p-0031" num="0030">The mask detector <b>105</b> maintains a Boolean state variable that tracks whether a mask has been detected. The average gain and the average spectral slope over multiple subframes also computed and tracked. Certain subframes that are low in energy or have a slope that is too small are excluded from the average spectral slope calculation. Bands that are dominated by noise also are excluded from the slope calculation.</p><p id="p-0032" num="0031">When a subframe is processed, the mask detector <b>105</b> determines whether the subframe is suitable for use in updating the average spectral slope (step <b>315</b>). If the subframe is suitable, the mask detector <b>105</b> updates the average spectral slope (step <b>320</b>) and compares the updated average to a threshold (step <b>325</b>). If the average exceeds the threshold, a mask is determined to be present and the mask detector <b>105</b> updates the Boolean state variable to indicate that a mask is present (step <b>330</b>). If the average does not exceed the threshold, no mask is determined to be present and the mask detector <b>105</b> updates the Boolean state variable to indicate that no mask is present (step <b>335</b>).</p><p id="p-0033" num="0032">The mask compensator <b>110</b> generates an initial frequency boost curve for the subframe (step <b>340</b>). The mask compensator does so using the speech parameters for the subframe and the state variable indicating whether a mask is present. When a mask is present, the initial boost curve provides 12 dB of gain at 4 kHz and tapers linearly to 0 dB of gain at 750 Hz. When no mask is present, the boost is 0 dB for all frequencies. This initial boost curve would be the best filter to correct the signal if no background noise were present.</p><p id="p-0034" num="0033">The mask compensator <b>110</b> then weights the boost curve to account for noise (step <b>345</b>). This weighting is undertaken to prevent boosting of bands that are dominated by noise. For each band, the mask compensator <b>110</b> compares the signal level for the band to the noise level for the band. When the signal level exceeds the noise level by enough margin, the boost weighting for the band is set to 1.0 (full boost) for the current subframe and several subsequent subframes. When the signal level exceeds the noise level by another smaller margin, then the boost weighting for the band is set to 0.5 (half boost) for the current subframe and several subsequent subframes. Otherwise, the boost weighting for the band is set to 0.0 (no boost) to disable boosting for the band. As long as the presence or absence of a mask doesn't change, the weights are held for several subframes because it is not desirable to switch the dynamic weighting excessively. The overall effect is to reduce or eliminate the boost for bands where the signal-to-noise ratio is low.</p><p id="p-0035" num="0034">The mask compensator <b>110</b> then applies the weighted boost curve to the spectrum (step <b>350</b>). For example, the log<sub>2 </sub>boost curve may be converted to a linear scale at each DFT frequency and the DFT coefficients may be scaled accordingly. This eliminates or reduces the attenuation to the spectrum imposed by the mask without boosting the background noise. The resulting boosted spectrum then may be used to estimate the spectral magnitudes of each voice harmonic.</p><p id="p-0036" num="0035">The modified spectrum then is used to generate enhanced output speech (step <b>355</b>) before proceeding to the next subframe.</p><p id="p-0037" num="0036">The speech processing system <b>100</b> may be operated independently to enhance a signal that is potentially degraded by a mask, or it may be incorporated into a speech coder, such as a AMBE vocoder that uses the spectrum to estimate the magnitudes for each voice harmonic. When mask detection and compensation is employed, this spectrum gets scaled to compensate for the mask. However, an inverse-DFT also may be applied to the spectrum to produce a modified spectrum that then is overlap-added with neighboring spectra to get a resulting compensated speech signal.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a communications device <b>400</b> that samples analog speech or some other signal from a microphone <b>405</b>. An analog-to-digital (&#x201c;A-to-D&#x201d;) converter <b>410</b> digitizes the sampled speech to produce a digital speech signal. The digital speech is processed by a MBE speech encoder unit <b>415</b> to produce a digital bit stream <b>420</b> suitable for transmission by a transmitter or storage. The speech encoder processes each subframe of the digital speech signal to produce a corresponding frame of bits in the bit stream output of the encoder. This includes estimating generalized MBE model parameters for the subframe. The MBE model parameters include a fundamental frequency, a set of voicing errors, a gain value, and a set of spectral magnitudes.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>4</b></figref> also depicts a received bit stream <b>425</b> entering a MBE speech decoder unit <b>430</b> that processes each frame of bits to produce a corresponding frame of synthesized speech samples. A digital-to-analog (&#x201c;D-to-A&#x201d;) converter unit <b>435</b> then converts the digital speech samples to an analog signal that can be passed to a speaker unit <b>440</b> for conversion into an acoustic signal suitable for human listening.</p><p id="p-0040" num="0039">A mask detector and a mask compensator, such as the mask detector <b>105</b> and the mask compensator <b>110</b>, may be incorporated most efficiently in the MBE speech encoder unit <b>415</b>, but may also be employed in the MBE speech decoder unit <b>430</b>. And the mask detector and the mask compensator may be divided, with the mask detector being included in the MBE speech encoder unit <b>415</b> and the mask compensator being included in the MBE speech decoder unit <b>430</b>. And some implementations may include only a mask compensator, with the presence of the mask being determined by other means, such as a camera or an indication by a user (e.g., by pressing a button).</p><p id="p-0041" num="0040">The details of a particular implementation of the procedure <b>300</b> in an MBE vocoder are provided below.</p><p id="p-0042" num="0041">Spectrum Measurement</p><p id="p-0043" num="0042">The input to the process is an 8 kHz speech signal, s(n). However, the process can be adjusted to work for different sampling rates. For each subframe, the spectrum, S<sub>m</sub>(k), is measured from s(n) and stored for later use in estimating the MBE spectral amplitude model parameters. The spectrum is measured by first windowing s(n) and transforming the result into the frequency domain using DFT:</p><p id="p-0044" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <mtext>                </mtext>  <mrow>   <mrow>    <msub>     <mi>S</mi>     <msub>      <mi>w</mi>      <mi>m</mi>     </msub>    </msub>    <mo>(</mo>    <mi>k</mi>    <mo>)</mo>   </mrow>   <mo>=</mo>   <mrow>    <mrow>     <munderover>      <mo>&#x2211;</mo>      <mrow>       <mi>n</mi>       <mo>=</mo>       <mrow>        <mo>-</mo>        <mn>127</mn>       </mrow>      </mrow>      <mn>127</mn>     </munderover>     <mrow>      <mrow>       <msub>        <mi>w</mi>        <mi>m</mi>       </msub>       <mo>(</mo>       <mi>n</mi>       <mo>)</mo>      </mrow>      <mo>&#x2062;</mo>      <mrow>       <mi>s</mi>       <mo>&#x2061;</mo>       <mo>(</mo>       <mrow>        <mi>n</mi>        <mo>+</mo>        <mn>127</mn>       </mrow>       <mo>)</mo>      </mrow>      <mstyle><mtext>?</mtext></mstyle>      <mtext>   </mtext>      <mi>for</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mn>0</mn>     </mrow>    </mrow>    <mo>&#x2264;</mo>    <mi>k</mi>    <mo>&#x3c;</mo>    <mn>128</mn>   </mrow>  </mrow> </mrow></math></maths><maths id="MATH-US-00001-2" num="00001.2"><math overflow="scroll"> <mrow>  <mstyle><mtext>?</mtext></mstyle>  <mtext mathsize="6pt">indicates text missing or illegible when filed</mtext> </mrow></math></maths></p><p id="p-0045" num="0043">Where w<sub>m</sub>(n) is a 25 ms hamming window defined as follows:</p><p id="p-0046" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mrow>  <mrow>   <msub>    <mi>w</mi>    <mi>m</mi>   </msub>   <mo>(</mo>   <mi>n</mi>   <mo>)</mo>  </mrow>  <mo>=</mo>  <mrow>   <mo>{</mo>   <mtable>    <mtr>     <mtd>      <mrow>       <mn>0.54</mn>       <mo>+</mo>       <mrow>        <mn>0.46</mn>        <mrow>         <mi>cos</mi>         <mtext> </mtext>         <mo>[</mo>         <mrow>          <mfrac>           <mi>&#x3c0;</mi>           <mn>100</mn>          </mfrac>          <mo>&#x2062;</mo>          <mi>n</mi>         </mrow>         <mo>]</mo>        </mrow>       </mrow>      </mrow>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>for</mi>        <mtext>   </mtext>        <mo>-</mo>        <mn>100</mn>       </mrow>       <mo>&#x2264;</mo>       <mi>n</mi>       <mo>&#x3c;</mo>       <mn>100</mn>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mn>0</mn>     </mtd>     <mtd>      <mi>otherwise</mi>     </mtd>    </mtr>   </mtable>  </mrow> </mrow></math></maths></p><p id="p-0047" num="0000">The square magnitude of the result is stored as the spectrum measurement, S<sub>m</sub>(k) for the subframe:</p><p id="p-0048" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>S</i><sub>m</sub>(<i>k</i>)=|<i>S</i><sub>w</sub><sub><sub2>m</sub2></sub>(<i>k</i>)|<sup>2 </sup>for 0&#x2264;<i>k&#x2264;</i>128<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0049" num="0044">Computation of Spectral Band Energies</p><p id="p-0050" num="0045">The spectrum, S<sub>m</sub>(k), is used to compute the spectral energy in 16 frequency bands:</p><p id="p-0051" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>e</i><sub>i</sub>=0.5 log<sub>2</sub>[&#x3a3;<sub>k=8i</sub><sup>8i+15</sup><i>S</i><sub>m</sub>(<i>k</i>)]&#x2212;7.0 for 0&#x2264;<i>i&#x3c;</i>16<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0052" num="0046">Estimation of the Noise Spectrum</p><p id="p-0053" num="0047">The spectral energies in each band are then used to update an estimate of the noise energy in each band. The following process is used:</p><p id="p-0054" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="offset" colwidth="49pt" align="left"/><colspec colname="1" colwidth="168pt" align="left"/><thead><row><entry/><entry namest="offset" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/><entry>if v<sub>count </sub>&#x3c; 8 then</entry></row><row><entry/><entry>&#x2003;a<sub>i</sub><sup>(0) </sup>&#x21d0; (v<sub>count </sub>&#xb7; a<sub>i</sub><sup>(&#x2212;1) </sup>+ e<sub>i</sub>)/(v<sub>count </sub>+ 1)</entry></row><row><entry/><entry>&#x2003;m<sub>i</sub><sup>(0) </sup>&#x21d0; 16.0</entry></row><row><entry/><entry>&#x2003;c<sub>i</sub><sup>(0) </sup>&#x21d0; 300</entry></row><row><entry/><entry>else if e<sub>i </sub>&#x3c; a<sub>i</sub><sup>(&#x2212;1) </sup>+ 2 then</entry></row><row><entry/><entry>&#x2003;if e<sub>i </sub>&#x3c; a<sub>i</sub><sup>(&#x2212;1) </sup>and e<sub>i </sub>&#x3c; 2 then</entry></row><row><entry/><entry>&#x2003;&#x2003;a<sub>i</sub><sup>(0) </sup>&#x21d0; 0.5 &#xb7; a<sub>i</sub><sup>(&#x2212;1) </sup>+ 0.5 &#xb7; e<sub>i</sub></entry></row><row><entry/><entry>&#x2003;else</entry></row><row><entry/><entry>&#x2003;&#x2003;a<sub>i</sub><sup>(0) </sup>&#x21d0; 0.9 &#xb7; a<sub>i</sub><sup>(&#x2212;1) </sup>+ 0.1 &#xb7; e<sub>i</sub></entry></row><row><entry/><entry>&#x2003;endif</entry></row><row><entry/><entry>&#x2003;m<sub>i</sub><sup>(0) </sup>&#x21d0; 16.0</entry></row><row><entry/><entry>&#x2003;c<sub>i</sub><sup>(0) </sup>&#x21d0; 300</entry></row><row><entry/><entry>else if c<sub>i</sub><sup>(&#x2212;1) </sup>&#x3e; 0 then</entry></row><row><entry/><entry>&#x2003;if e<sub>i </sub>&#x3c; m<sub>i</sub><sup>(&#x2212;1) </sup>&#x2212; 2 then</entry></row><row><entry/><entry>&#x2003;&#x2003;a<sub>i</sub><sup>(0) </sup>&#x21d0; e<sub>i</sub></entry></row><row><entry/><entry>&#x2003;else</entry></row><row><entry/><entry>&#x2003;&#x2003;a<sub>i</sub><sup>(0) </sup>&#x21d0; a<sub>i</sub><sup>(&#x2212;1)</sup></entry></row><row><entry/><entry>&#x2003;&#x2003;m<sub>i</sub><sup>(0) </sup>&#x21d0; 0.9 &#xb7; m<sub>i</sub><sup>(&#x2212;1) </sup>+ 0.1 &#xb7; e<sub>i</sub></entry></row><row><entry/><entry>&#x2003;endif</entry></row><row><entry/><entry>&#x2003;c<sub>i</sub><sup>(0) </sup>&#x21d0; c<sub>i</sub><sup>(&#x2212;1) </sup>&#x2212; 1</entry></row><row><entry/><entry>else</entry></row><row><entry/><entry>a<sub>i</sub><sup>(0) </sup>&#x21d0; m<sub>i</sub><sup>(&#x2212;1)</sup></entry></row><row><entry/><entry>m<sub>i</sub><sup>(0) </sup>&#x21d0; 16.0</entry></row><row><entry/><entry>&#x2003;c<sub>i</sub><sup>(0) </sup>&#x21d0; 300</entry></row><row><entry/><entry>end if</entry></row><row><entry/><entry namest="offset" nameend="1" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0055" num="0048">The process updates three vectors. The vector a<sub>i </sub>for 0&#x2264;i&#x3c;16 stores the average noise level for each band. The vector m<sub>i </sub>for 0&#x2264;i&#x3c;16 tracks the minimum noise level for each band. The vector c<sub>i </sub>for 0&#x2264;i&#x3c;16 contains a 3 second counter for each band. Note that the process is designed to be called at 10 ms intervals such that 300 iterations of the process corresponds to 3 seconds. Generally, a speaker pauses to breathe more often than once every 3 seconds.</p><p id="p-0056" num="0049">The initial conditions for each of the state variables above are as follows:</p><p id="p-0057" num="0050">a<sub>0</sub>=7.0, a<sub>1</sub>=6.0, a<sub>2</sub>=5.0, a<sub>3</sub>=4.0, a<sub>4</sub>=3.0, a<sub>5</sub>=2.0</p><p id="p-0058" num="0051">a<sub>i</sub>=1.0 where 6&#x2264;i&#x3c;16</p><p id="p-0059" num="0052">m<sub>i</sub>=16.0 where 0&#x2264;i&#x3c;16</p><p id="p-0060" num="0053">c<sub>i</sub>=16.0 where 0&#x2264;i&#x3c;16</p><p id="p-0061" num="0054">V<sub>count</sub>=0</p><p id="p-0062" num="0055">Note that, in the process above, the superscript notation, v<sup>(0)</sup>, refers to the new value for variable v in the current subframe. Whereas, v<sup>(&#x2212;1)</sup>, refers to the prior value for variable in the prior subframe.</p><p id="p-0063" num="0056">Calculating the Dynamic Boost Weighting</p><p id="p-0064" num="0057">The spectral band energies from the current subframe, S<sub>b</sub>(n), and the current estimate of noise spectrum, are used to compute a set of weights. Integer counters, C<sub>FB</sub>(n) for 0&#x2264;n&#x3c;16, are updated as follows:</p><p id="p-0065" num="0000"><maths id="MATH-US-00003" num="00003"><math overflow="scroll"> <mrow>  <mrow>   <msub>    <mi>C</mi>    <mi>FB</mi>   </msub>   <mo>(</mo>   <mi>n</mi>   <mo>)</mo>  </mrow>  <mo>=</mo>  <mrow>   <mo>{</mo>   <mtable>    <mtr>     <mtd>      <mn>5</mn>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>when</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <msub>          <mi>S</mi>          <mi>b</mi>         </msub>         <mo>(</mo>         <mi>n</mi>         <mo>)</mo>        </mrow>       </mrow>       <mo>&#x3e;</mo>       <mrow>        <mrow>         <msub>          <mi>S</mi>          <mi>N</mi>         </msub>         <mo>(</mo>         <mi>n</mi>         <mo>)</mo>        </mrow>        <mo>+</mo>        <mn>1.</mn>       </mrow>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mrow>       <mi>max</mi>       <mo>[</mo>       <mrow>        <mn>2</mn>        <mo>,</mo>        <mrow>         <msub>          <mi>C</mi>          <mi>FB</mi>         </msub>         <mo>(</mo>         <mi>n</mi>         <mo>)</mo>        </mrow>       </mrow>       <mo>]</mo>      </mrow>     </mtd>     <mtd>      <mrow>       <mrow>        <mrow>         <mi>when</mi>         <mo>&#x2062;</mo>         <mtext>   </mtext>         <mrow>          <msub>           <mi>S</mi>           <mi>N</mi>          </msub>          <mo>(</mo>          <mi>n</mi>          <mo>)</mo>         </mrow>        </mrow>        <mo>+</mo>        <mn>1.</mn>       </mrow>       <mo>&#x3e;</mo>       <mrow>        <msub>         <mi>S</mi>         <mi>b</mi>        </msub>        <mo>(</mo>        <mi>n</mi>        <mo>)</mo>       </mrow>       <mo>&#x3e;</mo>       <mrow>        <mrow>         <msub>          <mi>S</mi>          <mi>N</mi>         </msub>         <mo>(</mo>         <mi>n</mi>         <mo>)</mo>        </mrow>        <mo>+</mo>        <mn>0.5</mn>       </mrow>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mrow>       <mi>max</mi>       <mo>[</mo>       <mrow>        <mn>0</mn>        <mo>,</mo>        <mrow>         <mrow>          <msub>           <mi>C</mi>           <mi>FB</mi>          </msub>          <mo>(</mo>          <mi>n</mi>          <mo>)</mo>         </mrow>         <mo>-</mo>         <mn>1</mn>        </mrow>       </mrow>       <mo>]</mo>      </mrow>     </mtd>     <mtd>      <mi>otherwise</mi>     </mtd>    </mtr>   </mtable>  </mrow> </mrow></math></maths></p><p id="p-0066" num="0058">When C<sub>FB</sub>(n)&#x3e;0, for band n, the weight for that band will allow full boost. Additionally, integer counters, C<sub>HB</sub>(n) for 0&#x2264;n&#x3c;16, are updated as follows:</p><p id="p-0067" num="0000"><maths id="MATH-US-00004" num="00004"><math overflow="scroll"> <mrow>  <mrow>   <msub>    <mi>C</mi>    <mi>HB</mi>   </msub>   <mo>(</mo>   <mi>n</mi>   <mo>)</mo>  </mrow>  <mo>=</mo>  <mrow>   <mo>{</mo>   <mtable>    <mtr>     <mtd>      <mn>10</mn>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>when</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <msub>          <mi>S</mi>          <mi>b</mi>         </msub>         <mo>(</mo>         <mi>n</mi>         <mo>)</mo>        </mrow>       </mrow>       <mo>&#x3e;</mo>       <mrow>        <mrow>         <msub>          <mi>S</mi>          <mi>N</mi>         </msub>         <mo>(</mo>         <mi>n</mi>         <mo>)</mo>        </mrow>        <mo>+</mo>        <mn>1.</mn>       </mrow>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mrow>       <mi>max</mi>       <mo>[</mo>       <mrow>        <mn>4</mn>        <mo>,</mo>        <mrow>         <msub>          <mi>C</mi>          <mi>HB</mi>         </msub>         <mo>(</mo>         <mi>n</mi>         <mo>)</mo>        </mrow>       </mrow>       <mo>]</mo>      </mrow>     </mtd>     <mtd>      <mrow>       <mrow>        <mrow>         <mi>when</mi>         <mo>&#x2062;</mo>         <mtext>   </mtext>         <mrow>          <msub>           <mi>S</mi>           <mi>N</mi>          </msub>          <mo>(</mo>          <mi>n</mi>          <mo>)</mo>         </mrow>        </mrow>        <mo>+</mo>        <mn>1.</mn>       </mrow>       <mo>&#x3e;</mo>       <mrow>        <msub>         <mi>S</mi>         <mi>b</mi>        </msub>        <mo>(</mo>        <mi>n</mi>        <mo>)</mo>       </mrow>       <mo>&#x3e;</mo>       <mrow>        <mrow>         <msub>          <mi>S</mi>          <mi>N</mi>         </msub>         <mo>(</mo>         <mi>n</mi>         <mo>)</mo>        </mrow>        <mo>+</mo>        <mn>0.5</mn>       </mrow>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mrow>       <mi>max</mi>       <mo>[</mo>       <mrow>        <mn>0</mn>        <mo>,</mo>        <mrow>         <mrow>          <msub>           <mi>C</mi>           <mi>HB</mi>          </msub>          <mo>(</mo>          <mi>n</mi>          <mo>)</mo>         </mrow>         <mo>-</mo>         <mn>1</mn>        </mrow>       </mrow>       <mo>]</mo>      </mrow>     </mtd>     <mtd>      <mi>otherwise</mi>     </mtd>    </mtr>   </mtable>  </mrow> </mrow></math></maths></p><p id="p-0068" num="0059">When C<sub>FB</sub>(n)&#x3e;0, for band n, the weight for that band is 1.0, enabling full boost for that band. When C<sub>HB</sub>(n)&#x3e;0, for band n, the weight for that band is 0.5, which will allow half boost for the band. Otherwise, the weight for the band is 0.0, which disables boost for the band.</p><p id="p-0069" num="0000"><maths id="MATH-US-00005" num="00005"><math overflow="scroll"> <mrow>  <mrow>   <mi>w</mi>   <mo>&#x2061;</mo>   <mo>(</mo>   <mi>n</mi>   <mo>)</mo>  </mrow>  <mo>=</mo>  <mrow>   <mo>{</mo>   <mtable>    <mtr>     <mtd>      <mn>1.</mn>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>when</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <msub>          <mi>C</mi>          <mi>FB</mi>         </msub>         <mo>(</mo>         <mi>n</mi>         <mo>)</mo>        </mrow>       </mrow>       <mo>&#x3e;</mo>       <mn>0</mn>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mn>0.5</mn>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>when</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <msub>          <mi>C</mi>          <mi>FB</mi>         </msub>         <mo>(</mo>         <mi>n</mi>         <mo>)</mo>        </mrow>       </mrow>       <mo>=</mo>       <mrow>        <mrow>         <mn>0</mn>         <mo>&#x2062;</mo>         <mtext>   </mtext>         <mi>and</mi>         <mo>&#x2062;</mo>         <mtext>   </mtext>         <mrow>          <msub>           <mi>C</mi>           <mi>HB</mi>          </msub>          <mo>(</mo>          <mi>n</mi>          <mo>)</mo>         </mrow>        </mrow>        <mo>&#x3e;</mo>        <mn>0</mn>       </mrow>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mn>0.</mn>     </mtd>     <mtd>      <mi>otherwise</mi>     </mtd>    </mtr>   </mtable>  </mrow> </mrow></math></maths></p><p id="p-0070" num="0060">Later, these weights will be applied to the boost filter. The weights can reduce or eliminate the boost in particular bands that are noisy.</p><p id="p-0071" num="0061">Mask Detection</p><p id="p-0072" num="0062">Mask detection uses the spectral band energies, e<sub>i </sub>for 0&#x2264;i&#x3c;16, and the average noise levels, a<sub>i </sub>for 0&#x2264;i&#x3c;16. Mask detection also uses three state variables: is the detector state, G<sub>M </sub>is the maximum gain, and M<sub>A </sub>is the average slope. Variable d is a Boolean where 0 indicates that a mask has not been detected and 1 means that a mask has been detected. d<sup>(&#x2212;1) </sup>refers to the value of variable d in the prior subframe, whereas d<sup>(0) </sup>(or simply d) refers to the value of variable d in the current subframe. The initial value for d is 0. Similarly, the superscripts <sup>(&#x2212;1) </sup>and <sup>(0) </sup>can be used to refer to values of variables G<sub>M </sub>and M<sub>A </sub>in the prior and current subframes. The initial values are: G<sub>M</sub>=0 and M<sub>A</sub>=9.0/16.</p><p id="p-0073" num="0063">As an initial step in mask detection, the noise cutoff band is determined. This is the lowest frequency band for which the signal energy does not exceed the noise energy by at least 3 dB.</p><p id="p-0074" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>if <i>e</i><sub>i&#x2190;1</sub>&#x2212;0.5&#x3c;<i>a</i><sub>i&#x2192;1 </sub>then <i>C=i </i><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0075" num="0064">If C&#x3c;6, then this subframe does not have enough bands with voice and the mask detection process ends and returns the detection state of the prior subframe. If the mask detection process ends at this point, then state variables G<sub>M </sub>and M<sub>A </sub>are not updated.</p><p id="p-0076" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>If <i>C</i>&#x3c;6 then {<i>d</i><sup>(0)</sup><i>=d</i><sup>(&#x2212;1)</sup><i>,G</i><sub>M</sub><sup>(0)</sup><i>=G</i><sub>M</sub><sup>(&#x2212;1)</sup><i>,M</i><sub>A</sub><sup>(0)</sup><i>=M</i><sub>A</sub><sup>(&#x2212;1)</sup>}<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0077" num="0065">Next, a gain value is computed by computing the average spectral band energy in the lowest 6 frequency bands.</p><p id="p-0078" num="0000"><maths id="MATH-US-00006" num="00006"><math overflow="scroll"> <mrow>  <mi>G</mi>  <mo>=</mo>  <mfrac>   <mrow>    <msubsup>     <mo>&#x2211;</mo>     <mrow>      <mi>i</mi>      <mo>=</mo>      <mn>0</mn>     </mrow>     <mn>5</mn>    </msubsup>    <msub>     <mi>e</mi>     <mi>i</mi>    </msub>   </mrow>   <mn>6</mn>  </mfrac> </mrow></math></maths></p><p id="p-0079" num="0066">Next, the maximum gain is updated as follows:</p><p id="p-0080" num="0000"><maths id="MATH-US-00007" num="00007"><math overflow="scroll"> <mrow>  <msubsup>   <mi>G</mi>   <mi>M</mi>   <mrow>    <mo>(</mo>    <mn>0</mn>    <mo>)</mo>   </mrow>  </msubsup>  <mo>=</mo>  <mrow>   <mo>{</mo>   <mtable>    <mtr>     <mtd>      <mi>G</mi>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>when</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mi>G</mi>       </mrow>       <mo>&#x3e;</mo>       <mrow>        <msubsup>         <mi>G</mi>         <mi>M</mi>         <mrow>          <mo>(</mo>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>          <mo>)</mo>         </mrow>        </msubsup>        <mo>-</mo>        <mn>0.01</mn>       </mrow>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mrow>       <msubsup>        <mi>G</mi>        <mi>M</mi>        <mrow>         <mo>(</mo>         <mrow>          <mo>-</mo>          <mn>1</mn>         </mrow>         <mo>)</mo>        </mrow>       </msubsup>       <mo>-</mo>       <mn>0.01</mn>      </mrow>     </mtd>     <mtd>      <mi>otherwise</mi>     </mtd>    </mtr>   </mtable>  </mrow> </mrow></math></maths></p><p id="p-0081" num="0067">If G&#x3c;G<sub>M</sub>&#x2212;1.0, then the mask detection process ends and returns the detection state of the prior subframe. The mask detector excludes low energy subframes from detection.</p><p id="p-0082" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>d</i><sup>(0)</sup><i>=d</i><sup>(&#x2212;1) </sup>when <i>G&#x3c;G</i><sub>M</sub>&#x2212;1.0<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0083" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>M</i><sub>A</sub><sup>(0)</sup><i>=M</i><sub>A</sub><sup>(&#x2212;1) </sup>when <i>G&#x3c;G</i><sub>M</sub>&#x2212;1.0<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0084" num="0068">Otherwise, the detection process continues and the spectral slope of the current subframe is computed as follows:</p><p id="p-0085" num="0000"><maths id="MATH-US-00008" num="00008"><math overflow="scroll"> <mrow>  <msub>   <mi>M</mi>   <mi>c</mi>  </msub>  <mo>=</mo>  <mfrac>   <mrow>    <mn>13</mn>    <mo>&#x2062;</mo>    <mrow>     <mo>(</mo>     <mrow>      <msub>       <mi>e</mi>       <mn>2</mn>      </msub>      <mo>-</mo>      <msub>       <mi>e</mi>       <mi>C</mi>      </msub>     </mrow>     <mo>)</mo>    </mrow>   </mrow>   <mrow>    <mi>C</mi>    <mo>-</mo>    <mn>3</mn>   </mrow>  </mfrac> </mrow></math></maths></p><p id="p-0086" num="0069">If the spectral slope is less than 3.0, then the detection process ends and returns the detection state from the prior subframe.</p><p id="p-0087" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>d</i><sup>(0)</sup><i>=d</i><sup>(&#x2212;1) </sup>when <i>M</i><sub>C</sub>&#x3c;3.0<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0088" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>M</i><sub>A</sub><sup>(0)</sup><i>=M</i><sub>A</sub><sup>(&#x2212;1) </sup>when <i>M</i><sub>C</sub>&#x3c;3.0<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0089" num="0070">The average spectral slope, M<sub>A</sub>, is then computed as follows:</p><p id="p-0090" num="0000"><maths id="MATH-US-00009" num="00009"><math overflow="scroll"> <mrow>  <msubsup>   <mi>M</mi>   <mi>A</mi>   <mrow>    <mo>(</mo>    <mn>0</mn>    <mo>)</mo>   </mrow>  </msubsup>  <mo>=</mo>  <mrow>   <mo>{</mo>   <mtable>    <mtr>     <mtd>      <mrow>       <mrow>        <mn>0.75</mn>        <msubsup>         <mi>M</mi>         <mi>A</mi>         <mrow>          <mo>(</mo>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>          <mo>)</mo>         </mrow>        </msubsup>       </mrow>       <mo>+</mo>       <mrow>        <mn>0.25</mn>        <msub>         <mi>M</mi>         <mi>C</mi>        </msub>       </mrow>      </mrow>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>if</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <msub>         <mi>M</mi>         <mi>C</mi>        </msub>       </mrow>       <mo>&#x3e;</mo>       <mrow>        <msubsup>         <mi>M</mi>         <mi>A</mi>         <mrow>          <mo>(</mo>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>          <mo>)</mo>         </mrow>        </msubsup>        <mo>+</mo>        <mn>2.</mn>       </mrow>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mrow>       <mrow>        <mn>0.875</mn>        <msubsup>         <mi>M</mi>         <mi>A</mi>         <mrow>          <mo>(</mo>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>          <mo>)</mo>         </mrow>        </msubsup>       </mrow>       <mo>+</mo>       <mrow>        <mn>0.125</mn>        <msub>         <mi>M</mi>         <mi>C</mi>        </msub>       </mrow>      </mrow>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>else</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mi>if</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <msub>         <mi>M</mi>         <mi>C</mi>        </msub>       </mrow>       <mo>&#x3e;</mo>       <mrow>        <msubsup>         <mi>M</mi>         <mi>A</mi>         <mrow>          <mo>(</mo>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>          <mo>)</mo>         </mrow>        </msubsup>        <mo>+</mo>        <mn>1.</mn>       </mrow>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mrow>       <mrow>        <mn>0.96</mn>        <msubsup>         <mi>M</mi>         <mi>A</mi>         <mrow>          <mo>(</mo>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>          <mo>)</mo>         </mrow>        </msubsup>       </mrow>       <mo>+</mo>       <mrow>        <mn>0.04</mn>        <msub>         <mi>M</mi>         <mi>C</mi>        </msub>       </mrow>      </mrow>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>else</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mi>if</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <msub>         <mi>M</mi>         <mi>C</mi>        </msub>       </mrow>       <mo>&#x3e;</mo>       <mrow>        <msubsup>         <mi>M</mi>         <mi>A</mi>         <mrow>          <mo>(</mo>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>          <mo>)</mo>         </mrow>        </msubsup>        <mo>+</mo>        <mn>0.5</mn>       </mrow>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mrow>       <mrow>        <mn>0.98</mn>        <msubsup>         <mi>M</mi>         <mi>A</mi>         <mrow>          <mo>(</mo>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>          <mo>)</mo>         </mrow>        </msubsup>       </mrow>       <mo>+</mo>       <mrow>        <mn>0.02</mn>        <msub>         <mi>M</mi>         <mi>C</mi>        </msub>       </mrow>      </mrow>     </mtd>     <mtd>      <mi>otherwise</mi>     </mtd>    </mtr>   </mtable>  </mrow> </mrow></math></maths></p><p id="p-0091" num="0000">Note that this approach allows the average slope to capture abrupt increases in slope, while accounting for decreases in slope over a longer time period. This allows for earlier detection when a mask is present.</p><p id="p-0092" num="0071">The average spectral slope is used to update the current mask detection state, d<sup>(0)</sup>, as follows:</p><p id="p-0093" num="0000"><maths id="MATH-US-00010" num="00010"><math overflow="scroll"> <mrow>  <msup>   <mi>d</mi>   <mrow>    <mo>(</mo>    <mn>0</mn>    <mo>)</mo>   </mrow>  </msup>  <mo>=</mo>  <mrow>   <mo>{</mo>   <mtable>    <mtr>     <mtd>      <mn>1</mn>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>when</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <msub>         <mi>M</mi>         <mi>A</mi>        </msub>       </mrow>       <mo>&#x3e;</mo>       <mn>9.5</mn>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mn>0</mn>     </mtd>     <mtd>      <mi>otherwise</mi>     </mtd>    </mtr>   </mtable>  </mrow> </mrow></math></maths></p><p id="p-0094" num="0072">Next, the log<sub>2 </sub>boost at 4 Khz is computed. If a mask was detected, the log<sub>2 </sub>boost is 2.0, representing a 12 dB gain at 4 kHz. Otherwise, the log boost is set to 0.0 if no mask is detected.</p><p id="p-0095" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>M</i><sub>B</sub>=2.0<i>d</i><sup>(0) </sup><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0096" num="0073">As a variation of the mask detection process, the boost required to compensate for the mask can be derived from the average spectral slope in relation to a typical spectral slope. This allows the amount of boost to vary depending upon different mask characteristics. This also may allow for correction of muffling caused by something other than a mask.</p><p id="p-0097" num="0074">Calculation of the Boost Required to Compensate for the Mask</p><p id="p-0098" num="0075">After the mask detection process determines the appropriate boost, M<sub>B</sub>, the amount of boost, B(i), to be applied to the spectrum at each DFT frequency is calculated as follows</p><p id="p-0099" num="0000"><maths id="MATH-US-00011" num="00011"><math overflow="scroll"> <mrow>  <mrow>   <mi>B</mi>   <mo>&#x2061;</mo>   <mo>(</mo>   <mi>i</mi>   <mo>)</mo>  </mrow>  <mo>=</mo>  <mrow>   <mo>{</mo>   <mtable>    <mtr>     <mtd>      <mn>0</mn>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>for</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mn>0</mn>       </mrow>       <mo>&#x2264;</mo>       <mi>i</mi>       <mo>&#x3c;</mo>       <mn>24</mn>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mfrac>       <mrow>        <mrow>         <mo>(</mo>         <mrow>          <mi>i</mi>          <mo>-</mo>          <mn>24</mn>         </mrow>         <mo>)</mo>        </mrow>        <mo>&#x2062;</mo>        <msub>         <mi>M</mi>         <mi>B</mi>        </msub>       </mrow>       <mn>104</mn>      </mfrac>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>for</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mn>24</mn>       </mrow>       <mo>&#x2264;</mo>       <mi>i</mi>       <mo>&#x3c;</mo>       <mn>128</mn>      </mrow>     </mtd>    </mtr>   </mtable>  </mrow> </mrow></math></maths></p><p id="p-0100" num="0076">The variable corresponds to frequency, where i=0 represents 0 Hz and i=128 represents 4 KHz</p><p id="p-0101" num="0077">Applying the Boost Weighting Function to the Boost Filter</p><p id="p-0102" num="0078">The weighting function, w(n), was computed previously for sixteen bands. The weighting is next applied to the boost as follows:</p><p id="p-0103" num="0000"><maths id="MATH-US-00012" num="00012"><math overflow="scroll"> <mrow>  <mrow>   <mover>    <mi>B</mi>    <mo>.</mo>   </mover>   <mo>(</mo>   <mi>i</mi>   <mo>)</mo>  </mrow>  <mo>=</mo>  <mrow>   <mrow>    <mi>B</mi>    <mo>&#x2061;</mo>    <mo>(</mo>    <mi>i</mi>    <mo>)</mo>   </mrow>   <mo>*</mo>   <mrow>    <mi>w</mi>    <mo>&#x2061;</mo>    <mo>(</mo>    <mrow>     <mo>&#x230a;</mo>     <mfrac>      <mi>i</mi>      <mn>8</mn>     </mfrac>     <mo>&#x230b;</mo>    </mrow>    <mo>)</mo>   </mrow>  </mrow> </mrow></math></maths></p><p id="p-0104" num="0079">Applying the Boost to the Spectrum</p><p id="p-0105" num="0080">{dot over (B)}(i) represents the log<sub>2 </sub>boost to be applied to the spectrum, S<sub>m</sub>(i). The boosted spectrum is denoted, {dot over (S)}<sub>m</sub>(i), and is calculated as follows:</p><p id="p-0106" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>{dot over (S)}</i><sub>m</sub>(<i>i</i>)=2<sup>2{dot over (B)}(i)</sup><i>&#xb7;S</i><sub>m</sub>(<i>i</i>)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0107" num="0000">Since S<sub>m</sub>(t) represents the squared magnitude, the scale factor is 2<sup>2B(i) </sup>rather than just 2<sup>B(i)</sup>.</p><p id="p-0108" num="0081">This is what would happen if the scale factor was applied to the real and imaginary components of the spectrum prior to squaring and summing them.</p><p id="p-0109" num="0082">Magnitude Estimation</p><p id="p-0110" num="0083">The magnitudes for each harmonic of the subframe are estimated by using a weighted sum of the boosted spectral energies.</p><p id="p-0111" num="0000"><maths id="MATH-US-00013" num="00013"><math overflow="scroll"> <mrow>  <mrow>   <mi>M</mi>   <mo>&#x2061;</mo>   <mo>(</mo>   <mi>l</mi>   <mo>)</mo>  </mrow>  <mo>=</mo>  <mrow>   <mrow>    <mn>0.5</mn>    <mrow>     <msub>      <mi>log</mi>      <mn>2</mn>     </msub>     <mo>[</mo>     <mrow>      <mn>0.001</mn>      <mo>+</mo>      <mrow>       <munderover>        <mo>&#x2211;</mo>        <mrow>         <mi>k</mi>         <mo>=</mo>         <mn>0</mn>        </mrow>        <mn>128</mn>       </munderover>       <mrow>        <mrow>         <msub>          <mi>w</mi>          <mi>ME</mi>         </msub>         <mo>(</mo>         <mrow>          <mi>k</mi>          <mo>,</mo>          <mi>l</mi>          <mo>,</mo>          <mi>f</mi>         </mrow>         <mo>)</mo>        </mrow>        <mo>&#x2062;</mo>        <mrow>         <msub>          <mover>           <mi>S</mi>           <mo>.</mo>          </mover>          <mi>m</mi>         </msub>         <mo>(</mo>         <mi>k</mi>         <mo>)</mo>        </mrow>       </mrow>      </mrow>     </mrow>     <mo>]</mo>    </mrow>   </mrow>   <mo>-</mo>   <mn>7.</mn>  </mrow> </mrow></math></maths></p><p id="p-0112" num="0084">The spectral weighting function, w<sub>ME</sub>(k,l,f), is defined as</p><p id="p-0113" num="0000"><maths id="MATH-US-00014" num="00014"><math overflow="scroll"> <mrow>  <mrow>   <msub>    <mi>w</mi>    <mi>ME</mi>   </msub>   <mo>(</mo>   <mrow>    <mi>k</mi>    <mo>,</mo>    <mi>l</mi>    <mo>,</mo>    <mi>f</mi>   </mrow>   <mo>)</mo>  </mrow>  <mo>=</mo>  <mrow>   <mo>{</mo>   <mtable>    <mtr>     <mtd>      <mn>1.</mn>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>if</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <semantics definitionURL="">          <mo>&#x2758;</mo>          <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>         </semantics>         <mrow>          <mi>k</mi>          <mo>-</mo>          <mrow>           <mn>256</mn>           <mo>&#x2062;</mo>           <mrow>            <mo>(</mo>            <mrow>             <mi>l</mi>             <mo>+</mo>             <mn>1</mn>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#x2062;</mo>           <mi>f</mi>          </mrow>         </mrow>         <semantics definitionURL="">          <mo>&#x2758;</mo>          <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>         </semantics>        </mrow>       </mrow>       <mo>&#x3c;</mo>       <mrow>        <mrow>         <mn>128</mn>         <mo>&#x2062;</mo>         <mi>f</mi>        </mrow>        <mo>-</mo>        <mn>0.5</mn>       </mrow>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mn>0.</mn>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>if</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <semantics definitionURL="">          <mo>&#x2758;</mo>          <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>         </semantics>         <mrow>          <mi>k</mi>          <mo>-</mo>          <mrow>           <mn>256</mn>           <mo>&#x2062;</mo>           <mrow>            <mo>(</mo>            <mrow>             <mi>l</mi>             <mo>+</mo>             <mn>1</mn>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#x2062;</mo>           <mi>f</mi>          </mrow>         </mrow>         <semantics definitionURL="">          <mo>&#x2758;</mo>          <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>         </semantics>        </mrow>       </mrow>       <mo>&#x3c;</mo>       <mrow>        <mrow>         <mn>128</mn>         <mo>&#x2062;</mo>         <mi>f</mi>        </mrow>        <mo>+</mo>        <mn>0.5</mn>       </mrow>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mrow>       <mrow>        <mn>128</mn>        <mo>&#x2062;</mo>        <mi>f</mi>       </mrow>       <mo>+</mo>       <mn>0.5</mn>       <mo>-</mo>       <mrow>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>        </semantics>        <mrow>         <mi>k</mi>         <mo>-</mo>         <mrow>          <mn>256</mn>          <mo>&#x2062;</mo>          <mrow>           <mo>(</mo>           <mrow>            <mi>l</mi>            <mo>+</mo>            <mn>1</mn>           </mrow>           <mo>)</mo>          </mrow>          <mo>&#x2062;</mo>          <mi>f</mi>         </mrow>        </mrow>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>        </semantics>       </mrow>      </mrow>     </mtd>     <mtd>      <mi>otherwise</mi>     </mtd>    </mtr>   </mtable>  </mrow> </mrow></math></maths></p><p id="p-0114" num="0085">As can be seen in this equation, the weight at a particular frequency is 0.0 for energy that is wholly contained in another harmonic (or band). The weight is 1.0 when the energy is entirely contained within the current harmonic (or band). The weight is between 0.0 and 1.0 when the energy at a particular frequency is split between the current harmonic (or band) and an adjacent harmonic (or band).</p><p id="p-0115" num="0086">While the techniques are described largely in the context of a MBE vocoder, the described techniques may be readily applied to other systems and/or vocoders. For example, other MBE type vocoders may also benefit from the techniques regardless of the bit rate or frame size. In addition, the techniques described may be applicable to many other speech coding systems that use a different speech model with alternative parameters (such as STC, MELP, MB-HTC, CELP, HVXC or others) or which use different methods for analysis, quantization. Other implementations are within the scope of the following claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001 MATH-US-00001-2" nb-file="US20230005498A1-20230105-M00001.NB"><img id="EMI-M00001" he="12.36mm" wi="76.20mm" file="US20230005498A1-20230105-M00001.TIF" alt="text missing or illegible when filed" img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230005498A1-20230105-M00002.NB"><img id="EMI-M00002" he="8.13mm" wi="76.20mm" file="US20230005498A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00003" nb-file="US20230005498A1-20230105-M00003.NB"><img id="EMI-M00003" he="8.81mm" wi="76.20mm" file="US20230005498A1-20230105-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00004" nb-file="US20230005498A1-20230105-M00004.NB"><img id="EMI-M00004" he="8.81mm" wi="76.20mm" file="US20230005498A1-20230105-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00005" nb-file="US20230005498A1-20230105-M00005.NB"><img id="EMI-M00005" he="8.81mm" wi="76.20mm" file="US20230005498A1-20230105-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00006" nb-file="US20230005498A1-20230105-M00006.NB"><img id="EMI-M00006" he="7.37mm" wi="76.20mm" file="US20230005498A1-20230105-M00006.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00007" nb-file="US20230005498A1-20230105-M00007.NB"><img id="EMI-M00007" he="7.03mm" wi="76.20mm" file="US20230005498A1-20230105-M00007.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00008" nb-file="US20230005498A1-20230105-M00008.NB"><img id="EMI-M00008" he="5.67mm" wi="76.20mm" file="US20230005498A1-20230105-M00008.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00009" nb-file="US20230005498A1-20230105-M00009.NB"><img id="EMI-M00009" he="15.16mm" wi="76.20mm" file="US20230005498A1-20230105-M00009.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00010" nb-file="US20230005498A1-20230105-M00010.NB"><img id="EMI-M00010" he="5.67mm" wi="76.20mm" file="US20230005498A1-20230105-M00010.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00011" nb-file="US20230005498A1-20230105-M00011.NB"><img id="EMI-M00011" he="8.81mm" wi="76.20mm" file="US20230005498A1-20230105-M00011.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00012" nb-file="US20230005498A1-20230105-M00012.NB"><img id="EMI-M00012" he="5.67mm" wi="76.20mm" file="US20230005498A1-20230105-M00012.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00013" nb-file="US20230005498A1-20230105-M00013.NB"><img id="EMI-M00013" he="8.13mm" wi="76.20mm" file="US20230005498A1-20230105-M00013.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00014" nb-file="US20230005498A1-20230105-M00014.NB"><img id="EMI-M00014" he="13.04mm" wi="76.20mm" file="US20230005498A1-20230105-M00014.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of compensating a speech signal for the presence of a speaker mask, the method comprising:<claim-text>receiving a speech signal;</claim-text><claim-text>dividing the speech signal into subframes;</claim-text><claim-text>generating speech parameters for a subframe;</claim-text><claim-text>determining whether the subframe is suitable for use in detecting a mask;</claim-text><claim-text>if the subframe is suitable for use in detecting a mask, using the speech parameters for the subframe in determining whether a mask is present; and</claim-text><claim-text>if a mask is present, modifying the speech parameters for the subframe to produce modified speech parameters that compensate for the presence of the mask.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the speech parameters for the subframe include a speech spectrum and spectral band energies for multiple voice bands.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein using the speech parameters for the subframe in determining whether a mask is present comprises examining a spectral slope for a subset of the voice bands.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein using the speech parameters for the subframe in determining whether a mask is present comprises examining a spectral slope for a subset of the voice bands in a frequency range from 750 Hz to 4000 Hz.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein determining whether a mask is present comprises comparing the spectral slope to a threshold value and determining that a mask is present when the spectral slope exceeds the threshold value.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein using the speech parameters for the subframe in determining whether a mask is present comprises updating an average spectral slope corresponding to multiple subframes using the speech parameters for the subframe and examining the updated average spectral slope for a subset of the voice bands.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining whether the subframe is suitable for use in detecting a mask comprises determining whether signal energy of the subframe exceeds a threshold value.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein modifying the speech parameters for the subframe to produce modified speech parameters that compensate for the presence of the mask comprises boosting gains in a subset of voice bands affected by the presence of a mask.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein boosting gains in a subset of voice bands affected by the presence of a mask comprises using boost levels that vary between voice bands in the subset of voice bands.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein boosting gains in a subset of voice bands affected by the presence of a mask comprises reducing boost levels for any voice bands in the subset of voice bands that do not include signal energy that exceeds noise energy by a threshold margin.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the speech parameters comprise model parameters of a Multi-Band Excitation speech model.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A communications device configured to compensate a speech signal for the presence of a speaker mask, the communications device comprising:<claim-text>a microphone;</claim-text><claim-text>a speech encoder that receives a speech signal from the microphone and generates digital speech parameters; and</claim-text><claim-text>a transmitter that receives the digital speech parameters from the speech encoder and transmits the digital speech parameters;</claim-text><claim-text>wherein the speech encoder is configured to:</claim-text><claim-text>divide the speech signal into subframes;</claim-text><claim-text>generate speech parameters for a subframe;</claim-text><claim-text>determine whether the subframe is suitable for use in detecting a mask;</claim-text><claim-text>if the subframe is suitable for use in detecting a mask, use the speech parameters for the subframe in determining whether a mask is present;</claim-text><claim-text>if a mask is present, modify the speech parameters for the subframe to produce modified speech parameters that compensate for the presence of the mask; and</claim-text><claim-text>provide the modified speech parameters to the transmitter as the digital speech parameters.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The communications device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the speech parameters for the subframe include a speech spectrum and spectral band energies for multiple voice bands.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The communications device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein using the speech parameters for the subframe in determining whether a mask is present comprises examining a spectral slope for a subset of the voice bands.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The communications device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein using the speech parameters for the subframe in determining whether a mask is present comprises examining a spectral slope for a subset of the voice bands in a frequency range from 750 Hz to 4000 Hz.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The communications device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein determining whether a mask is present comprises comparing the spectral slope to a threshold value and determining that a mask is present when the spectral slope exceeds the threshold value.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The communications device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein using the speech parameters for the subframe in determining whether a mask is present comprises updating an average spectral slope corresponding to multiple subframes using the speech parameters for the subframe and examining the updated average spectral slope for a subset of the voice bands.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The communications device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein determining whether the subframe is suitable for use in detecting a mask comprises determining whether signal energy of the subframe exceeds a threshold value.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The communications device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein determining whether the subframe is suitable for use in detecting a mask comprises determining whether signal energy of the subframe exceeds a minimum threshold value.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The communications device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein modifying the speech parameters for the subframe to produce modified speech parameters that compensate for the presence of the mask comprises boosting gains in a subset of voice bands affected by the presence of a mask.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The communications device of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein boosting gains in a subset of voice bands affected by the presence of a mask comprises using boost levels that vary between voice bands in the subset of voice bands.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The communications device of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein boosting gains in a subset of voice bands affected by the presence of a mask comprises reducing boost levels for any voice bands in the subset of voice bands that do not include signal energy that exceeds noise energy by a threshold margin.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. A speech encoder configured to compensate a speech signal for the presence of a speaker mask, the speech encoder being operable to:<claim-text>receive a speech signal;</claim-text><claim-text>divide the speech signal into subframes;</claim-text><claim-text>generate speech parameters for a subframe;</claim-text><claim-text>determine whether the subframe is suitable for use in detecting a mask;</claim-text><claim-text>if the subframe is suitable for use in detecting a mask, use the speech parameters for the subframe in determining whether a mask is present; and</claim-text><claim-text>if a mask is present, modify the speech parameters for the subframe to produce modified speech parameters that compensate for the presence of the mask.</claim-text></claim-text></claim></claims></us-patent-application>
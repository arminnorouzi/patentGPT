<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007056A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007056</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17363434</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>29</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>1066</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>403</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>80</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">DATA STREAM PRIORITIZATION FOR COMMUNICATION SESSION</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Microsoft Technology Licensing, LLC</orgname><address><city>Redmond</city><state>WA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>COX</last-name><first-name>Landon Prentice</first-name><address><city>Seattle</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>YAN</last-name><first-name>Yu</first-name><address><city>Bellevue</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>ABDOLLAHIAN NOGHABI</last-name><first-name>Shadi</first-name><address><city>Kirkland</city><state>WA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Microsoft Technology Licensing, LLC</orgname><role>02</role><address><city>Redmond</city><state>WA</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method for data stream prioritization by a session controller is described. Usage data associated with a video communication session is received for one or more client devices of the video communication session. The usage data is based on content within data streams of the video communication session. A first client device of the one or more client devices is identified as having a higher priority level during the video communication session based on the usage data. Instructions are sent to the first client device during the video communication session causing the first client device to improve a quality of a first data stream generated by the first client device for the video communication session.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="55.80mm" wi="100.75mm" file="US20230007056A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="192.87mm" wi="126.07mm" orientation="landscape" file="US20230007056A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="225.55mm" wi="154.09mm" orientation="landscape" file="US20230007056A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="228.52mm" wi="143.43mm" file="US20230007056A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="229.28mm" wi="143.43mm" file="US20230007056A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="229.87mm" wi="154.52mm" file="US20230007056A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="184.07mm" wi="128.27mm" file="US20230007056A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="178.65mm" wi="140.80mm" file="US20230007056A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">Communication systems such as video-conferencing systems often balance interactivity and scale among participants of a video conference or other communication session. When a communication session has relatively few participants (e.g., less than 25), a relatively small number of media servers may forward video streams of each participant to every other participant. However, as the number of participants grows, the bandwidth required to forward every stream to all participants grows quadratically. Moreover, additional video streams may exceed a processing capability of a single media server. In these scenarios, a hierarchy of media servers may be created to balance a workload of processing and/or combining the video streams. However, this hierarchy may increase latency for some participants and degrades the interactivity experience of the communication session.</p><p id="p-0003" num="0002">It is with respect to these and other general considerations that embodiments have been described. Also, although relatively specific problems have been discussed, it should be understood that the embodiments should not be limited to solving the specific problems identified in the background.</p><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0004" num="0003">Aspects of the present disclosure are directed to improving image quality of a stream of input images.</p><p id="p-0005" num="0004">In one aspect, a method for data stream prioritization by a session controller is provided. Usage data associated with a video communication session is received for one or more client devices of the video communication session. The usage data is based on content within data streams of the video communication session. A first client device of the one or more client devices is identified as having a higher priority level during the video communication session based on the usage data. Instructions are sent to the first client device during the video communication session causing the first client device to improve a quality of a first data stream generated by the first client device for the video communication session.</p><p id="p-0006" num="0005">In another aspect, a method for data stream prioritization by a media server is provided. A plurality of data streams of a video communication session are forwarded to a plurality of client devices of the video communication session. Usage data associated with the video communication session is collected based on the plurality of data streams during the video communication session. The usage data is based on content within the plurality of data streams. The usage data is sent to a session controller of the video communication session during the video communication session. Instructions to improve a quality of an identified stream of the plurality of data streams are received from the session controller during the video communication session. The instructions are based on the usage data. A first process to improve the quality of the identified stream is performed in response to the instructions.</p><p id="p-0007" num="0006">In yet another aspect, a system for data stream prioritization is provided. The system comprises a media server configured to route data streams for a video communication session. The system also comprises a session controller configured to: receive usage data associated with a video communication session for one or more client devices of the video communication session, wherein the usage data is based on content within data streams of the video communication session; identify a first client device of the one or more client devices as having a higher priority level during the video communication session based on the usage data; and send instructions to the first client device during the video communication session causing the first client device to improve a quality of a first data stream generated by the first client device for the video communication session.</p><p id="p-0008" num="0007">This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS/FIGURES</heading><p id="p-0009" num="0008">Non-limiting and non-exhaustive examples are described with reference to the following Figures.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a block diagram of an example of a system configuration in which a session controller for a communication session among a plurality of client devices may be implemented, according to an example embodiment.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIGS. <b>2</b>A, <b>2</b>B, <b>2</b>C, and <b>2</b>D</figref> show block diagrams of example data streams between client devices and a media server for a communication session, according to an example embodiment.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a flowchart of an example method for data stream prioritization, according to an example embodiment.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a flowchart of another example method for data stream prioritization, according to an example embodiment.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram illustrating example physical components of a computing device with which aspects of the disclosure may be practiced.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b></figref> are simplified block diagrams of a mobile computing device with which aspects of the present disclosure may be practiced.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0016" num="0015">In the following detailed description, references are made to the accompanying drawings that form a part hereof, and in which are shown by way of illustrations specific embodiments or examples. These aspects may be combined, other aspects may be utilized, and structural changes may be made without departing from the present disclosure. Embodiments may be practiced as methods, systems, or devices. Accordingly, embodiments may take the form of a hardware implementation, an entirely software implementation, or an implementation combining software and hardware aspects. The following detailed description is therefore not to be taken in a limiting sense, and the scope of the present disclosure is defined by the appended claims and their equivalents.</p><p id="p-0017" num="0016">The present disclosure describes various examples of a session controller for a communication session among a plurality of client devices. Generally, the client devices are used by a participant or viewer of the communication session, for example, participants in a video conference. However, some participants may not be actively involved in the communication session, while others may be consistently active. In various scenarios, for example, participants may be actively speaking, only watching and listening, present at the client device but not paying attention to the communication session, or absent from the client device (e.g., having walked away from their desk). The session controller is configured to prioritize client devices during the communication session based on usage data for the communication session.</p><p id="p-0018" num="0017">The usage data generally indicates, suggests, or may be used to estimate a level of interactivity of the participant within the communication session. In some aspects, the usage data is metadata associated with the client device, for example, whether a microphone of the client device is muted or unmuted, whether audio output at the client device is muted, and/or whether an application supporting the communication session is in a foreground of a user interface (e.g., a currently active user interface window) or a background of the user interface. In some aspects, the usage data is based on content of the communication session, for example, whether the participant is speaking, has asked a question, and/or is answering a question. The session controller may prioritize a client device by reducing audio and/or video compression levels, increasing allocated bandwidth, reducing latency, etc. Moreover, the session controller may deprioritize a client device in some scenarios (e.g., participant is not speaking or interacting) by, for example, increasing audio and/or video compression levels, reducing allocated bandwidth, and/or increasing latency.</p><p id="p-0019" num="0018">This and many further aspects for a computing device are described herein. For instance, <figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a block diagram of an example of a system configuration <b>100</b> in which a session controller <b>130</b> for a communication session among a plurality of client devices <b>110</b> may be implemented, according to an example embodiment. The communication session may be a teleconference, video conference, online document collaboration session, online gaming session, chat session, or other suitable communication session. In other words, the communication session is shared among the plurality of client devices <b>110</b> (e.g., participants of the communication session). Generally, at least some of the plurality of client devices <b>110</b> are presenters that transmit one or more data streams (e.g., audio, video, chat, game data, etc.) to other client devices of the plurality of client devices <b>110</b>, as described below. In contrast to members of a Wi-Fi access point (e.g., members of a same Service Set Identifier), participants in the communication session actively send a data stream to other participants, actively receive data streams from other participants, or both send and receive data streams with other participants where the data streams are for application layer content (e.g., audio for a phone call, video for a video call, etc.).</p><p id="p-0020" num="0019">The communication session may be routed through one or more media servers, such as media servers <b>120</b> and <b>122</b>, as described below. The plurality of client devices <b>110</b> are communicatively coupled with the session controller <b>130</b> and/or media servers <b>120</b> and <b>122</b> by communication links (not shown) to form a network, such as a wide area network (WAN), a local area network (LAN), enterprise network, a combination thereof, or other suitable network configuration. The communication links may include one or more of wired and/or wireless portions.</p><p id="p-0021" num="0020">The plurality of client devices <b>110</b> comprises a client device <b>112</b> (&#x201c;Client A&#x201d;), a client device <b>114</b> (&#x201c;Client B&#x201d;), a client device <b>116</b> (&#x201c;Client C&#x201d;), and a client device <b>118</b> (&#x201c;Client D&#x201d;), which may be computing devices having one or more of a user input device (e.g., keyboard, mouse), touch screen display, microphone, display, audio speakers, camera module, etc. The client devices may be personal computers, tablets, smart phones, telephones, network-enabled televisions (or other Internet-of-Things, IoT devices), network-enabled gaming consoles, or other suitable client devices for a communication session, in various embodiments and/or scenarios. In some embodiments, one or more of the plurality of client devices <b>110</b> execute a machine-learning process, such as a neural network model (not shown). Example machine learning processes may include determination of whether a participant is speaking (e.g., based on audio recorded from a microphone), determining whether a participant is present (e.g., based on facial recognition), or other suitable processing.</p><p id="p-0022" num="0021">In some embodiments, a client device includes a data collector, such as data collector <b>160</b> of the client device <b>116</b>. The data collector <b>160</b> is configured to collect usage data, for example, one or more of diagnostic data, content data, status data, or other suitable data from the client device <b>116</b> during a communication session. Although the data collector has been omitted from the client devices <b>112</b>, <b>114</b>, and <b>118</b> for clarity, any of the plurality of client devices <b>110</b> may include a data collector, in other embodiments. The data collector <b>160</b> provides the usage data to the session controller <b>130</b>, which allows the session controller <b>130</b> to identify client devices that are active or inactive, etc., as described below.</p><p id="p-0023" num="0022">Diagnostic data may include an identifier of bandwidth (e.g., transfer rate) used by a data stream (e.g., 75 kilobits per second), a codec identifier used for encoding audio or video within a data stream (e.g., H.264, H.265, MPEG-4), a video resolution of a data stream (e.g., 1920&#xd7;1080), or other suitable diagnostic data. Content data may include a portion of a data stream, for example, several seconds of audio, one or more images from an image data stream, a portion of a text chat, application data, or other suitable content data. In some aspects, usage data based on content includes whether a participant is speaking, has asked a question, and/or is answering a question. In some scenarios, metadata is embedded within data streams of the communication session, for example, as application data with user interface flags indicating whether a microphone is muted or unmuted, whether a &#x201c;hand&#x201d; has been raised, etc. Status data may include a connection status for a network interface (e.g., connected or disconnected), a connection status for a messaging application (e.g., online, offline, in a meeting, etc.), a connection status for a telephone, a window size and/or display area size for displaying a data stream, or other suitable status data. In some aspects, the status data is metadata associated with the client device, for example, whether a microphone of the client device is muted or unmuted, whether audio output at the client device is muted, and/or whether an application supporting the communication session is in a foreground of a user interface (e.g., a currently active user interface window) or a background of the user interface.</p><p id="p-0024" num="0023">In some embodiments, the data collector <b>160</b> processes the usage data to determine an activity level of a participant within a communication session (e.g., active, inactive, last active two minutes ago, etc.) and provides an identifier corresponding to the activity level to the session controller <b>130</b>. In these embodiments, the data collector <b>160</b> may offload at least some of the processing for determining whether to identify a client device as active or inactive, for example.</p><p id="p-0025" num="0024">In some scenarios, a client device may be located behind a router, modem, or other network device that provides network access to multiple devices. In the example shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the client device <b>118</b> is located behind a router <b>140</b> and the router <b>140</b> also provides network access to a computing device <b>141</b>. The router <b>140</b> may be a Wi-Fi router, cable modem, network switch, or other suitable device that separates a local area network from the Internet, a wide area network, or other suitable network. The router <b>140</b> may provide a dynamic host configuration protocol and/or network address translation service, for example. In some embodiments, the router <b>140</b> may include a data collector <b>164</b> that is generally analogous to the data collector <b>160</b> and provides usage data related to the client device <b>118</b>. In some scenarios, the data collector <b>164</b> may provide usage data related to a different device, such as computing device <b>141</b>. The computing device <b>141</b> may be a personal computer, tablet, smartphone, or other device that is connected to the router <b>140</b>. For example, the client device <b>118</b> may be a parent's personal computer used for work, while the computing device <b>141</b> may be a personal computer used by the parent's child, a smartphone of the parent, a network-enabled television (or other Internet-of-Things, IoT device), a network-enabled gaming console, or other suitable device. Generally, the computing device <b>141</b> is not a member of the plurality of client devices <b>110</b> connected to the communication session, but bandwidth utilized by the computing device <b>141</b> (e.g., from a video streaming app, online game, etc.) may affect a quality of service of the client device <b>118</b> because of a shared network connection (e.g., via the router <b>140</b>). Accordingly, in some scenarios, the router <b>140</b> may provide usage data to the session controller <b>130</b> and may even provide usage data related to different communication sessions of the computing device <b>141</b> (e.g., bandwidth being used, priority level of the different communication session, etc.).</p><p id="p-0026" num="0025">In various embodiments, the communication session may comprise one, two, three, or more data streams for each client device. In one embodiment, for example, each client device of a teleconference may receive a downlink data stream that includes audio data from the other client devices (e.g., combined by a media server). Moreover, each client device of the teleconference may also transmit an uplink data stream that includes audio data from that client device (e.g. to be combined by the media server and transmitted to the other client devices). For example, in a teleconference among clients A, B, C, and D, the client A transmits an uplink data stream that includes audio data from client A and receives a downlink data stream that includes audio data from clients B, C, and D, the client B transmits an uplink data stream that includes audio data from client B and receives a downlink data stream that includes audio data from clients A, C, and D, and so on.</p><p id="p-0027" num="0026">In another embodiment, each client device of a teleconference may receive a separate downlink data stream with audio data from each of the other client devices of the teleconference and also transmit an uplink data stream with its own audio data. For example, in a teleconference among clients A, B, C, and D, the client A transmits an uplink data stream that includes audio data from client A and receives three separate downlink data streams that include audio data from clients B, C, and D, the client B transmits an uplink data stream that includes audio data from client B and receives three separate downlink data streams that include audio data from clients A, C, and D, and so on.</p><p id="p-0028" num="0027">A communication session may comprise more than one type of data stream. For example, while a teleconference may only include audio data streams, a video conference may include an image data stream and an audio data stream. In some aspects, a communication session may include audio data streams, audio data streams and image data streams (e.g., as separate streams), audio data and image data as a single data stream (e.g., as a video with sound), or other suitable combinations of data streams. The data streams may also include text data streams (e.g., for a chat window), a file data stream (e.g., for a file sharing capability), an application data stream (e.g., for a video game, collaborative editing software), or other suitable data streams. In some embodiments, a client device receives multiple data streams for a communication session, such as separate image data streams for the other client devices, but the image data streams are separate only at an application level and are transmitted to the client device within a single stream at a transport level (e.g., at a transmission control protocol/Internet protocol layer).</p><p id="p-0029" num="0028">In some embodiments and/or scenarios, a client device may provide only a subset of data streams that are utilized within a communication session. For example, during a video conference, the client device <b>114</b> may not provide an image data stream when its camera is disabled or turned off by a participant, or the client device <b>112</b> may not provide an audio data stream when its microphone has been muted by a participant. In some scenarios, at least some of the client devices <b>112</b>, <b>114</b>, <b>116</b>, and <b>118</b> receive a control signal from the session controller <b>130</b> that causes the client devices to start, stop, and/or change one or more data streams during the communication session, for example, as client devices are newly connected, disconnected, prioritized, and/or deprioritized during the communication session, as described below.</p><p id="p-0030" num="0029">In some aspects, the communication session is hosted and/or managed by one or more media servers, for example, media server <b>120</b> and media server <b>122</b>. Examples of the media server <b>120</b> and/or <b>122</b> include network servers, application servers, cloud servers, or other suitable computing devices. Generally, the media servers are configured to receive data streams from client devices and forward the data streams to other client devices. In some scenarios, a media server may receive a data stream from a client device via another media server. In other scenarios, a media server may send a data stream to a client device via another media server. As an example using the system configuration <b>100</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the media server <b>120</b> may receive a first data stream from client device <b>112</b> and receive a second data stream from the client device <b>114</b>. The media server <b>120</b> may also transmit one or more data streams to the client device <b>112</b>, one or more data streams to the client device <b>114</b>, and one or more data streams to the media server <b>122</b> (e.g., to reach the client device <b>116</b> and client device <b>118</b>). The media servers may include a data collector, such as the data collector <b>162</b> of the media server <b>120</b>. The data collector <b>162</b> is generally analogous to the data collector <b>160</b> and provides usage data related to the client device <b>112</b> and the client device <b>114</b>, for example.</p><p id="p-0031" num="0030">In some aspects, the media server <b>120</b> and/or media server <b>122</b> are configured to combine and/or divide data streams. For example, the media server <b>122</b> may combine data streams from the client device <b>116</b> and the client device <b>118</b> into a single stream that is transmitted to the media server <b>120</b>. The media server <b>120</b> may then combine the single stream (with data streams from client device <b>116</b> and <b>118</b>) with a data stream from the client device <b>112</b> and transmit the combined data stream to the client device <b>114</b>, for example.</p><p id="p-0032" num="0031">The media server <b>120</b> and/or media server <b>122</b> may be configured to perform one or more processes on at least some of the data streams, for example, to change image quality (e.g., image resolution, color depth, bit rate, compression ratio, codec, image enhancement algorithms, etc.), change audio quality (e.g., bit rate, compression ratio, codec, noise cancellation, echo cancellation, etc.), or change other suitable characteristics of the data streams. As one example, the media server <b>120</b> may increase image resolution and add image enhancement algorithm processing to an image data stream from the client device <b>112</b>. As another example, the media server <b>122</b> may reduce a bit rate and stop echo cancellation for an audio data stream from the client device <b>116</b>. In other words, the media servers <b>120</b> and <b>122</b> may increase quality and/or decrease quality for various data streams. Moreover, the media servers <b>120</b> and <b>122</b> may change the characteristics of the data streams during a communication session, as described herein. In some scenarios, the media server <b>120</b> and/or <b>122</b> (or a different media server) receive one or more control signals from the session controller <b>130</b> that cause the media servers <b>120</b> and/or <b>122</b> to start, stop, and/or change one or more data streams during the communication session, for example, as client devices are newly connected, disconnected, prioritized, and/or deprioritized during the communication session, as described below.</p><p id="p-0033" num="0032">In some aspects, processing on the data streams and even data streams themselves may be divided among two or more media servers for a communication session. As one example, a first media server may handle audio data streams while a second media server may handle image data streams for a communication session (e.g., separate media servers handling the data streams in parallel). As another example, two or more media servers may be connected in series where a first media server performs processing on an audio data stream and performs a pass-through of an image data stream (e.g., forwarding the stream without further processing), while a second media server that receives the processed audio data stream and the image data stream performs image quality enhancement on the image data stream before transmitting the processed audio data stream and enhanced image data stream to a client device (or another media server).</p><p id="p-0034" num="0033">The session controller <b>130</b> is a computing device, such as a network server, application server, cloud server, or other suitable computing device. In some scenarios, the session controller <b>130</b> is combined with the media server <b>120</b> and/or media server <b>122</b> (e.g., implemented or co-hosted on a same network server). Generally, the session controller <b>130</b> is configured to receive usage data associated with a communication session for the plurality of client devices <b>110</b>, identify an active or higher priority client device based on the usage data, and send instructions to a data stream handler to cause the data stream handler to improve a quality of a data stream for the client device.</p><p id="p-0035" num="0034">In some scenarios, the session controller <b>130</b> may receive usage data from each of the plurality of client devices <b>110</b>. However, in other scenarios, the session controller <b>130</b> may receive usage data from one or more of the plurality of client devices <b>110</b> (e.g., a subset of the plurality). In other words, one or more of the plurality of client devices <b>110</b> do not provide usage data to the session controller <b>130</b>. In one such scenario, usage data for those client devices may be provided by a media server or other client devices of the plurality of client devices <b>110</b>. For example, where a first client device does not directly provide usage data to the session controller <b>130</b> but transmits a data stream to a second client device, the second client device may provide usage data associated with the first client device to the session controller <b>130</b> based on the data stream transmitted by the first client device. In another such scenario, usage data for some client devices is not available and those client devices are not prioritized, deprioritized, or identified as higher or lower priority, etc. In yet another scenario, usage data for those client devices is not available and the client devices are always prioritized, set to a default prioritization level, or not deprioritized relative to other client devices.</p><p id="p-0036" num="0035">In some aspects, the session controller <b>130</b> is configured to identify an inactive client device (or client device having a lower priority level) based on the usage data and send instructions (e.g., a deprioritization control signal) to a data stream handler to cause the data stream handler to lower a quality level (e.g., deprioritize) of the data stream for the inactive client device. In various scenarios, the data stream handler may be a client device that originates the data stream and/or a media server that routes the data stream to or from a client device. For example, data stream handlers for a data stream sent from the client device <b>112</b> comprise the client device <b>112</b> which originates the data stream, the media server <b>120</b> which routes the data stream to the client device <b>114</b> and the media server <b>122</b>, and the media server <b>122</b> which routes the data stream to the client device <b>116</b> and the client device <b>118</b>. In some scenarios, the data stream handler may be the router <b>140</b> or another suitable network device.</p><p id="p-0037" num="0036">In various aspects, the session controller <b>130</b> is configured to identify active client devices and/or inactive client devices, or client devices having lower or higher priority levels, at different times of the communication session, for example, as client devices are newly connected and/or as existing client devices of the communication session are disconnected, prioritized, and/or deprioritized during the communication session, or as updated usage data is received. In some scenarios, prioritizing a first client device is performed along with deprioritizing a second client device. For example, where a communication session has a maximum number of 50 active client stations out of a total of 1000 client stations of the communication session (e.g., due to performance limitations of bandwidth, media server availability, etc.), the session controller <b>130</b> may prioritize an active client device corresponding to a participant that is answering a question and deprioritize an inactive client device corresponding to a participant that previously asked the question (or another inactive client device) to maintain the maximum number of active client stations.</p><p id="p-0038" num="0037">The instructions, such as the prioritization control signal and/or the deprioritization control signal, are generated by the session controller <b>130</b> and configured to cause the data stream handler to prioritize or improve a quality of a first data stream and/or deprioritize or reduce a quality of a second data stream. The instructions may be transmitted using a dedicated management packet, in some scenarios. In other scenarios, the instructions may be transmitted within a data packet of a data stream, for example, in a header of the data packet of the data stream. In various embodiments, the prioritization control signal and/or deprioritization control signal may be flags, for example, true/false or 0/1 that indicate whether to enable or disable a feature, bit patterns that indicate an identifier for a compression ratio to be used, or other suitable messages that indicate a change in quality characteristics of the data stream.</p><p id="p-0039" num="0038">In various scenarios, the data stream handler may improve a quality of, or prioritize, a data stream by reducing audio and/or video compression levels, increasing allocated bandwidth, reducing latency (e.g., by re-routing a data stream for upstream and/or downstream through a different media server), using a higher quality of service level, increasing image quality enhancement levels of an image processor, etc. In other scenarios, the session controller <b>130</b> may reduce a quality of, or deprioritize, a data stream in some scenarios (e.g., participant is not speaking or interacting) by, for example, increasing audio and/or video compression levels, reducing allocated bandwidth, and/or increasing latency. In still other scenarios, the instructions are generated by the session controller <b>130</b> and configured to improve data access priority for shared resources, for example, for electronic documents in an online document collaboration environment. Improved data access priority may correspond to granting or denying a participant having priority for edits or overwrite capability, granting or denying access to files locked by other participants, etc.</p><p id="p-0040" num="0039">Prioritization and deprioritization may correspond to two, three, or more different priority levels, in various embodiments. As one example with two priority levels, client devices may be identified as being active or inactive, or high priority or low priority. As other examples with three priority levels, client devices may be identified as having low activity, medium activity, and high activity, or low activity, default activity, and high activity. In other scenarios, the session controller <b>130</b> uses a scale for priority levels, for example, corresponding to integer values of 1 to 10 for lowest priority to highest priority. In some scenarios, the session controller <b>130</b> ranks each of the plurality of client devices <b>110</b> and identifies a top 5 client devices, top 10 client devices, top 10% of client devices, or other suitable group of client devices as having a higher priority level.</p><p id="p-0041" num="0040">In some scenarios, such as in the context of an online game played on a personal computer, smartphone, or gaming console, prioritization and/or deprioritization may be based on a user's interactivity level (e.g., prioritized when actively engaged in a battle and deprioritized when viewing a cut-scene) and/or level of play (e.g., prioritized on an advanced or more difficult level and deprioritized on an early or low difficulty level).</p><p id="p-0042" num="0041">The session controller <b>130</b> comprises a priority processor <b>132</b> configured to identify active clients and inactive clients (or higher/lower priority) based on usage data. As described above, the usage data may be collected by one or more of data collectors within client devices (e.g., data collector <b>160</b>), data collectors within media servers (e.g., data collector <b>162</b>), and/or data collectors within other devices (e.g., data collector <b>164</b>). The data collectors <b>160</b>, <b>162</b>, and <b>164</b> may be implemented as one or more of a client application or portion thereof (e.g., an application that supports the communication session), an operating system module, firmware (e.g., camera module firmware, network module firmware), integrated circuit, etc. in various embodiments.</p><p id="p-0043" num="0042">In some embodiments, the usage data is based on content within a data stream. For example, the priority processor <b>132</b> and/or the data collectors <b>160</b>, <b>162</b>, and/or <b>164</b> may process sound within an audio data stream to determine whether a participant that uses a client device is active or inactive, or determine an activity level of the participant. In various aspects, the priority processor <b>132</b> identifies an active client device based on conversational dynamics within the communication session, for example, when the participant is speaking, asking a question, answering a question, etc.</p><p id="p-0044" num="0043">In some scenarios, the session controller <b>130</b> prioritizes a data stream from a client device when a participant of the client device is speaking and/or deprioritizes the data stream when the participant is not speaking. The priority processor <b>132</b> may determine when a participant is speaking or not speaking based upon a mute status of a microphone of the corresponding client device (e.g., muted corresponding to not speaking, etc.). In some scenarios, the priority processor <b>132</b> may analyze a portion of audio from an audio data stream to determine whether the participant is speaking, for example, by performing voice analysis against background noise, voice matching with a prior audio sample of the participant, etc. The session controller <b>130</b> may monitor audio data streams from a client device and track a time at which the participant last spoke (e.g., 5 seconds ago, 2 minutes ago, etc.) and determine that the participant is inactive when that time exceeds a predetermined threshold (e.g., 5 minutes).</p><p id="p-0045" num="0044">The session controller <b>130</b> may prioritize a data stream from a client device when a participant of the client device is asking a question, in various embodiments. Since questions are often spoken with a raised inflection (e.g., rising pitch) at an end of the question, the priority processor <b>132</b> may be configured to identify an asked question when a raised inflection followed by a brief pause is detected during an audio data stream. In some scenarios, the priority processor <b>132</b> identifies an asked question when a user interface control corresponding to a &#x201c;hand raise&#x201d; has been pressed by a participant and the participant is then given an opportunity to speak. The session controller <b>130</b> may also prioritize a data stream from a client device when a participant of the client device is answering a question, for example, when speaking after a question has been asked.</p><p id="p-0046" num="0045">In some aspects, the usage data is based on metadata associated with a data stream. For example, the session controller <b>130</b> may determine whether a participant is present at a client device and prioritize data streams associated with the client device when the participant is present, while deprioritizing those data streams when the participant is not present (e.g., having left the room or area near the client device). In some examples, the session controller <b>130</b> determines whether the participant is present using facial recognition and/or body detection (e.g., the user is present when a face is detected). In other examples, the session controller <b>130</b> determines whether the participant is present based on an audio status of the client device (e.g., when a headset or speakers are turned off, the participant is not present). In some scenarios, the session controller <b>130</b> detects an intermission (e.g., a break point during a long presentation or seminar) when a plurality of client devices have changed to a &#x201c;not present&#x201d; status within a short time period (e.g., within 2 minutes) and avoids changing the active status of the client devices during the intermission.</p><p id="p-0047" num="0046">The session controller <b>130</b> may determine whether a participant at a client device is paying attention to (e.g., observing), a display of the client device and prioritize data streams associated with the client device when the participant is paying attention, while deprioritizing those data streams when the participant is not paying attention. The session controller <b>130</b> may determine that the participant is paying attention when they are looking at the display (e.g., using facial recognition and/or foveal detection on an image from a camera module), when display windows associated with the communication session are in a foreground of a user interface (e.g., a currently active user interface window), and/or when keyboard and/or mouse activity is detected (e.g., detecting keystrokes, mouse button presses, mouse-related events such as &#x201c;mouse over&#x201d;, audio that includes keyboard or mouse clicks). In some scenarios, the session controller <b>130</b> may determine that a participant is not paying attention when a face is not detected, and/or when keyboard and/or mouse activity has not been detected within a predetermined threshold (e.g., 2 minutes).</p><p id="p-0048" num="0047">In some scenarios, the session controller <b>130</b> determines that the participant is not paying attention when other services or applications not associated with the communication session are using a large share of system resources (e.g., memory usage, processor usage, disk drive usage, network bandwidth usage) of the client device that exceed one or more usage thresholds, for example, more than 40% processor usage, more than 200 kbps network bandwidth usage, etc. In some scenarios, the usage thresholds correspond to typical usage for video streaming applications, which may suggest that the participant is watching a movie instead of the communication session. In other scenarios, the session controller <b>130</b> determines that the participant is not paying attention when the session controller <b>130</b> receives usage data from another data source (not shown), such as a search engine or network service, that indicates the participant (e.g., through an associated login or credentials) has accessed the search engine or network service during the communication session. In one example, the session controller <b>130</b> may determine that a participant is paying attention when a window resolution associated with an application for the communication session is maximized, exceeds a size threshold (e.g., taking up 25% of a total screen area), etc. As another example, the session controller <b>130</b> may determine that other participants are paying attention to a participant (e.g., a presenter) when a window resolution associated with the participant is maximized and/or exceeds a size threshold, when the other participants are observing the participant (e.g., through foveal detection), etc.</p><p id="p-0049" num="0048">The session controller <b>130</b> may send instructions (e.g., a prioritization control signal and/or deprioritization control signal) to a data stream handler associated with the communication session, as described above. In some scenarios, the session controller <b>130</b> sends a deprioritization control signal to a data stream handler and/or application that is not associated with the communication session. As one example, when usage data for a video streaming application (e.g., for watching a movie) on a client device exceeds a usage threshold, the session controller <b>130</b> may send a deprioritization control signal to the video streaming application to limit its resource usage so as to not degrade the communication session. As another example, when multiple devices share a network connection, such as the client device <b>118</b> and the computing device <b>141</b> sharing a network connection via the router <b>140</b>, the session controller <b>130</b> may identify the client device <b>118</b> and/or the computing device <b>141</b> as active or inactive to save bandwidth on the shared network connection. In other words, when a parent is a participant in a webinar using the client device <b>118</b> while their child is a participant in an online learning program using the computing device <b>141</b>, the session controller <b>130</b> may identify the computing device <b>141</b> as inactive when the child is not paying attention to the online learning program, which may save bandwidth and improve connection quality on the shared network connection for the webinar on the client device <b>118</b>.</p><p id="p-0050" num="0049">With the advent of <b>5</b>G, Multi-access Edge Computing (MEC) with data stream processing has become important to improve performance of cloud services. In MEC, there is a hierarchy of devices and servers. For instance, client devices (e.g., the plurality of client devices <b>110</b>) may transmit data streams to cell towers. The cell towers relay the data stream to edge servers in on-premises (i.e., &#x201c;on-prem&#x201d;) edges as uplink data traffic. The on-premises edge servers (e.g., media server <b>120</b>, media server <b>122</b>) may process the data streams as described above, forward the data streams to other client devices, and transmit usage data to network servers (e.g., session controller <b>130</b>) at network edges of a cloud infrastructure.</p><p id="p-0051" num="0050">Due to physical constraints (both dimensional and geographic), the edge servers at the on-premises edges have limited computing power and memory capacity when compared to the cloud servers because the edge servers are geographically distributed at locations proximal to the cell towers. It is cost-prohibitive and/or physically infeasible to install extensive computing resources at the edge servers, for example to identify higher priority or lower priority client devices and send control signals or instructions to reconfigure other edge servers. However, improved latency and quality of experience is provided when using a MEC network configuration by obtaining usage data based on the data streams at the media server <b>120</b> (at the on-prem edge) and sending the usage data to the session controller <b>130</b> (at the network edge or within the cloud) for identification of higher priority client devices and control signal generation.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIGS. <b>2</b>A, <b>2</b>B, <b>2</b>C, and <b>2</b>D</figref> show block diagrams of example data streams between client devices <b>212</b>, <b>214</b>, <b>216</b>, and <b>218</b> and a media server <b>220</b> for a communication session, according to an example embodiment. The client devices <b>212</b>, <b>214</b>, <b>216</b>, and <b>218</b> generally correspond to the plurality of client devices <b>110</b> and the media server <b>220</b> generally corresponds to the media server <b>120</b> and/or <b>122</b>. The communication session is managed by a session controller <b>230</b>, which generally corresponds to the session controller <b>130</b>. The communication session comprises first, second, third, and fourth data streams between the media server <b>220</b> and the client devices <b>212</b>, <b>214</b>, <b>216</b>, and <b>218</b>, respectively. Although only four client devices are shown in <figref idref="DRAWINGS">FIGS. <b>2</b>A, <b>2</b>B, <b>2</b>C, and <b>2</b>D</figref>, additional client devices may be coupled to the communication session in other scenarios.</p><p id="p-0053" num="0052">In <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, the first data stream between the client device <b>212</b> and the media server <b>220</b> is prioritized while a participant using the client device <b>212</b> is presenting during the communication session. The second data stream is prioritized while a participant using the client device <b>214</b> is actively watching the communication session. The third and fourth data streams are not prioritized, or may be deprioritized. In an embodiment, the client device <b>212</b> provides usage data that includes a &#x201c;presenting&#x201d; flag to the session controller <b>230</b> during the communication session. The client device <b>214</b> provides usage data that includes facial recognition identifying the participant of the client device <b>214</b> while watching the communication session.</p><p id="p-0054" num="0053">In <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, a participant using the client device <b>216</b> asks a question during the communication session and the session controller <b>230</b> sends a prioritization control signal to the media server <b>220</b> and/or the client device <b>216</b> to cause a prioritization of the third data stream. In an embodiment, the participant using the client device <b>216</b> activates a user interface control corresponding to a &#x201c;hand raise&#x201d; and is then given an opportunity to speak (e.g., by a user interface function activated by the presenter or by other participants muting their microphones). The session controller <b>230</b> sends the prioritization control signal in response to the hand raise, for example. The session controller <b>230</b> may send a deprioritization control signal to the media server <b>220</b> and/or the client device <b>214</b> to deprioritize the second data stream, for example, to reduce resource utilization on the media server <b>220</b> for the communication session.</p><p id="p-0055" num="0054">In <figref idref="DRAWINGS">FIG. <b>2</b>C</figref>, a participant using the client device <b>218</b> answers the asked question and the session controller <b>230</b> sends a prioritization control signal to the media server <b>220</b> and/or the client device <b>218</b> to cause a prioritization of the fourth data stream. The session controller <b>230</b> also sends a deprioritization control signal to the media server <b>220</b> and/or the client device <b>216</b> to cause a deprioritization of the third data stream. In an embodiment, for example, the session controller <b>230</b> sends the prioritization control signal in response to voice detection on the fourth data stream after the asked question on the third data stream.</p><p id="p-0056" num="0055">In <figref idref="DRAWINGS">FIG. <b>2</b>D</figref>, a participant using the client device <b>214</b> takes over as a presenter during the communication session and the session controller <b>230</b> sends a prioritization control signal to the media server <b>220</b> and/or the client device <b>214</b> to cause a prioritization of the second data stream. The session controller <b>230</b> also sends deprioritization control signals to the media server <b>220</b> and/or the client devices <b>212</b> and <b>218</b> to cause a deprioritization of the first and fourth data streams.</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a flowchart of an example method <b>300</b> for data stream prioritization, according to an example embodiment. Technical processes shown in these figures will be performed automatically unless otherwise indicated. In any given embodiment, some steps of a process may be repeated, perhaps with different parameters or data to operate on. Steps in an embodiment may also be performed in a different order than the top-to-bottom order that is laid out in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. Steps may be performed serially, in a partially overlapping manner, or fully in parallel. Thus, the order in which steps of method <b>300</b> are performed may vary from one performance to the process of another performance of the process. Steps may also be omitted, combined, renamed, regrouped, be performed on one or more machines, or otherwise depart from the illustrated flow, provided that the process performed is operable and conforms to at least one claim. The steps of <figref idref="DRAWINGS">FIG. <b>3</b></figref> may be performed by the session controller <b>130</b> (e.g., via the priority processor <b>132</b>), the media server <b>120</b>, the session controller <b>230</b>, the media server <b>220</b>, or other suitable computing device.</p><p id="p-0058" num="0057">Method <b>300</b> begins with step <b>302</b>. At step <b>302</b>, usage data associated with a video communication session is received for one or more client devices of the video communication session. The usage data is based on content within data streams of the video communication session and may be received by a session controller for the video communication session. The session controller may correspond to the session controller <b>130</b> or the session controller <b>230</b>, and the one or more client devices may correspond to ones of the plurality of client devices <b>110</b> or the client devices <b>212</b>, <b>214</b>, <b>216</b>, and <b>218</b>.</p><p id="p-0059" num="0058">In some aspects, the usage data is received during the communication session and the usage data indicates a level of interactivity of participants of the communication session (e.g., participants using the plurality of client devices <b>110</b>). In some embodiments, receiving the usage data comprises monitoring the usage data during the video communication session. For example, the session controller may monitor for a usage threshold to be met during the communication session and dynamically identify client devices as having the higher priority level during the video communication session based on the usage data. Example thresholds may include when more than 50 client devices have joined, when a presenter has stopped presenting, when a question has been asked, when a hand has been raised, etc.</p><p id="p-0060" num="0059">At step <b>304</b>, a first client device of the one or more client devices is identified as having a higher priority level during the video communication session based on the usage data. In some scenarios, an active client device of the plurality of client devices <b>110</b> is identified by the session controller <b>130</b> during the communication session based on the usage data. For example, the session controller <b>130</b> identifies the client device <b>212</b> or <b>214</b> (<figref idref="DRAWINGS">FIG. <b>2</b>A</figref>), the client device <b>212</b> or <b>216</b> (<figref idref="DRAWINGS">FIG. <b>2</b>B</figref>), the client device <b>212</b> or <b>218</b> (<figref idref="DRAWINGS">FIG. <b>2</b>C</figref>), or the client device <b>214</b> (<figref idref="DRAWINGS">FIG. <b>2</b>D</figref>) as a higher priority client device or active client device.</p><p id="p-0061" num="0060">In various aspects, identifying the first client device as having a higher priority level comprises one or more of determining that a participant of the video communication session using the first client device is actively speaking during the video communication session, determining that a participant of the video communication session using the first client device is asking a question during the video communication session, or determining that a participant of the video communication session using the first client device is answering a question during the video communication session.</p><p id="p-0062" num="0061">In some aspects, the usage data indicates whether a participant of the video communication session is observing an application associated with the video communication session and observing the application corresponds to the higher priority level. The usage data may further indicate whether the participant of the video communication session is interacting with the application associated with the video communication session and interacting with the application corresponds to the higher priority level.</p><p id="p-0063" num="0062">At step <b>306</b>, instructions are sent to the first client device during the video communication session causing the first client device to improve a quality of a first data stream generated by the first client device for the video communication session. In some scenarios, the instructions include a prioritization control signal sent to a first data stream handler of the first data stream. The first data stream may be one of an upstream data stream or a downstream data stream. In some scenarios, the instructions cause the first client device to improve multiple data streams, such as an uplink data stream and a downlink data stream, or multiple uplink data streams, etc. The prioritization control signal causes the first data stream handler to prioritize the first data stream for the active client device during the communication session. In some embodiments, the session controller <b>230</b> sends the instructions to the media server <b>220</b> or the client devices <b>212</b> and <b>214</b> (<figref idref="DRAWINGS">FIG. <b>2</b>A</figref>), to the media server <b>220</b> or the client devices <b>212</b> and <b>216</b> (<figref idref="DRAWINGS">FIG. <b>2</b>B</figref>), to the media server <b>220</b> or the client devices <b>212</b> and <b>218</b> (<figref idref="DRAWINGS">FIG. <b>2</b>C</figref>), or to the media server <b>220</b> or the client device <b>214</b> (<figref idref="DRAWINGS">FIG. <b>2</b>D</figref>).</p><p id="p-0064" num="0063">In various aspects, the instructions cause the first client device to perform at least one of reducing audio compression of the first data stream, reducing video compression of the first data stream, increasing image resolution of the first data stream, increasing image color depth of the first data stream, increasing a bit rate of the first data stream, and/or increasing allocated bandwidth for the first client device.</p><p id="p-0065" num="0064">In some embodiments, the method <b>300</b> further comprises sending instructions to a media server that routes the first data stream, such as the media server <b>120</b> or the media server <b>122</b>. The instructions cause the media server to perform at least one of reducing audio compression of the first data stream, reducing video compression of the first data stream, increasing image resolution of the first data stream, increasing image color depth of the first data stream, increasing a bit rate of the first data stream, and/or increasing allocated bandwidth for the first client device.</p><p id="p-0066" num="0065">In some aspects, the method <b>300</b> further comprises identifying, by the session controller, an inactive client device of the plurality of client devices during the communication session based on the usage data, and sending, by the session controller, a deprioritization control signal to a second data stream handler of a second data stream associated with the inactive client device, wherein the deprioritization control signal causes the second data stream handler to deprioritize the second data stream for the inactive client device during the communication session. For example, the session controller <b>230</b> sends the deprioritization control signal to the client device <b>214</b> (<figref idref="DRAWINGS">FIG. <b>2</b>B</figref>), to the client device <b>216</b> (<figref idref="DRAWINGS">FIG. <b>2</b>C</figref>), or to the client devices <b>212</b> and <b>218</b> (<figref idref="DRAWINGS">FIG. <b>2</b>D</figref>).</p><p id="p-0067" num="0066">In some aspects, the method <b>300</b> further comprises identifying a second client device of the one or more client devices as having a lower priority level during the video communication session based on the usage data. Instructions are sent to the second client device during the video communication session causing the second client device to reduce a quality of a second data stream generated by the second client device for the video communication session. For example, the session controller <b>230</b> sends the deprioritization control signal to the client device <b>214</b> (<figref idref="DRAWINGS">FIG. <b>2</b>B</figref>), to the client device <b>216</b> (<figref idref="DRAWINGS">FIG. <b>2</b>C</figref>), or to the client devices <b>212</b> and <b>218</b> (<figref idref="DRAWINGS">FIG. <b>2</b>D</figref>). In some scenarios, the lower priority level is relative to a current priority level. For example, where a current priority level is a high priority level, the lower priority level may be a regular priority level, a default priority level, or a low priority level.</p><p id="p-0068" num="0067">In some scenarios, the method <b>300</b> further comprises identifying the first client device as having one of a lower priority level or a default priority level at a later time during the video communication session based on the usage data, and sending instructions to the first client device during the video communication session causing the first client device to reduce the quality of the first data stream. In other words, after first raising a priority level of the first client device, the session controller later reduces the priority level of the first client device, for example, if the first client device starts presenting and later stops presenting.</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a flowchart of an example method <b>400</b> for data stream prioritization, according to an example embodiment. Technical processes shown in these figures will be performed automatically unless otherwise indicated. In any given embodiment, some steps of a process may be repeated, perhaps with different parameters or data to operate on. Steps in an embodiment may also be performed in a different order than the top-to-bottom order that is laid out in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. Steps may be performed serially, in a partially overlapping manner, or fully in parallel. Thus, the order in which steps of method <b>400</b> are performed may vary from one performance to the process of another performance of the process. Steps may also be omitted, combined, renamed, regrouped, be performed on one or more machines, or otherwise depart from the illustrated flow, provided that the process performed is operable and conforms to at least one claim. The steps of <figref idref="DRAWINGS">FIG. <b>4</b></figref> may be performed by the media server <b>120</b>, the media server <b>220</b>, or other suitable computing device.</p><p id="p-0070" num="0069">Method <b>400</b> begins with step <b>402</b>. At step <b>402</b>, a plurality of data streams of a video communication session are forwarded by a media server to a plurality of client devices of the video communication session. In some embodiments, the media server generally corresponds to the media server <b>120</b> and/or the media server <b>220</b>.</p><p id="p-0071" num="0070">At step <b>404</b>, usage data associated with the video communication session is collected based on the plurality of data streams during the video communication session. The usage data is based on content within the plurality of data streams. In some aspects, the usage data indicates a level of interactivity of participants of the video communication session that utilize the plurality of client devices.</p><p id="p-0072" num="0071">At step <b>406</b>, the usage data is sent to a session controller of the video communication session during the video communication session. In some embodiments, the session controller corresponds to the session controller <b>130</b> and/or the session controller <b>230</b>.</p><p id="p-0073" num="0072">At step <b>408</b>, instructions to improve a quality of an identified stream of the plurality of data streams are received from the session controller during the video communication session. The instructions are based on the usage data and, in some aspects, may include a prioritization control signal for the identified stream.</p><p id="p-0074" num="0073">At step <b>410</b>, a first process to improve the quality of the identified stream is performed in response to the instructions. The first process is configured to prioritize the identified stream among the plurality of data streams in response to the instructions or prioritization control signal. Performing the first process may comprise at least one of reducing audio compression of the identified data stream, reducing video compression of the identified data stream, increasing image resolution of the identified data stream, increasing image color depth of the identified data stream, increasing a bit rate of the identified data stream, and/or increasing allocated bandwidth for a client device of the plurality of client devices that corresponds to the identified data stream.</p><p id="p-0075" num="0074">In some aspects, the identified stream is a first identified stream and the instructions are first instructions and the method <b>300</b> further comprises receiving second instructions to reduce a quality of a second identified stream of the plurality of data streams from the session controller during the video communication session, and performing a second process to reduce the quality of the second identified stream in response to the instructions.</p><p id="p-0076" num="0075">In some aspects, the method <b>300</b> further includes analyzing at least some content of the plurality of data streams to obtain the usage data. For example, the data collector <b>162</b> may analyze audio, speech, images, and/or application data to obtain the usage data.</p><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIGS. <b>5</b>-<b>7</b></figref> and the associated descriptions provide a discussion of a variety of operating environments in which aspects of the disclosure may be practiced. However, the devices and systems illustrated and discussed with respect to <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>7</b></figref> are for purposes of example and illustration and are not limiting of a vast number of computing device configurations that may be utilized for practicing aspects of the disclosure, as described herein.</p><p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram illustrating physical components (e.g., hardware) of a computing device <b>500</b> with which aspects of the disclosure may be practiced. The computing device components described below may have computer executable instructions for implementing a data stream processor application <b>520</b> on a computing device (e.g., session controller <b>130</b>, session controller <b>230</b>, media server <b>120</b>, media server <b>122</b>), including computer executable instructions for data stream processor application <b>520</b> that can be executed to implement the methods disclosed herein. In a basic configuration, the computing device <b>500</b> may include at least one processing unit <b>502</b> and a system memory <b>504</b>. Depending on the configuration and type of computing device, the system memory <b>504</b> may comprise, but is not limited to, volatile storage (e.g., random access memory), non-volatile storage (e.g., read-only memory), flash memory, or any combination of such memories. The system memory <b>504</b> may include an operating system <b>505</b> and one or more program modules <b>506</b> suitable for running data stream processor application <b>520</b>, such as one or more components with regard to <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref> and, in particular, data collector <b>521</b> (e.g., corresponding to data collectors <b>160</b>, <b>162</b>, <b>164</b>), and priority processor <b>522</b> (e.g., corresponding to priority processor <b>132</b>).</p><p id="p-0079" num="0078">The operating system <b>505</b>, for example, may be suitable for controlling the operation of the computing device <b>500</b>. Furthermore, embodiments of the disclosure may be practiced in conjunction with a graphics library, other operating systems, or any other application program and is not limited to any particular application or system. This basic configuration is illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> by those components within a dashed line <b>508</b>. The computing device <b>500</b> may have additional features or functionality. For example, the computing device <b>500</b> may also include additional data storage devices (removable and/or non-removable) such as, for example, magnetic disks, optical disks, or tape. Such additional storage is illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> by a removable storage device <b>509</b> and a non-removable storage device <b>510</b>.</p><p id="p-0080" num="0079">As stated above, a number of program modules and data files may be stored in the system memory <b>504</b>. While executing on the processing unit <b>502</b>, the program modules <b>506</b> (e.g., data stream processor application <b>520</b>) may perform processes including, but not limited to, the aspects, as described herein. Other program modules that may be used in accordance with aspects of the present disclosure, and in particular for prioritizing data streams, may include data collector <b>521</b> and priority processor <b>522</b>.</p><p id="p-0081" num="0080">Furthermore, embodiments of the disclosure may be practiced in an electrical circuit comprising discrete electronic elements, packaged or integrated electronic chips containing logic gates, a circuit utilizing a microprocessor, or on a single chip containing electronic elements or microprocessors. For example, embodiments of the disclosure may be practiced via a system-on-a-chip (SOC) where each or many of the components illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> may be integrated onto a single integrated circuit. Such an SOC device may include one or more processing units, graphics units, communications units, system virtualization units and various application functionality all of which are integrated (or &#x201c;burned&#x201d;) onto the chip substrate as a single integrated circuit. When operating via an SOC, the functionality, described herein, with respect to the capability of client to switch protocols may be operated via application-specific logic integrated with other components of the computing device <b>500</b> on the single integrated circuit (chip). Embodiments of the disclosure may also be practiced using other technologies capable of performing logical operations such as, for example, AND, OR, and NOT, including but not limited to mechanical, optical, fluidic, and quantum technologies. In addition, embodiments of the disclosure may be practiced within a general purpose computer or in any other circuits or systems.</p><p id="p-0082" num="0081">The computing device <b>500</b> may also have one or more input device(s) <b>512</b> such as a keyboard, a mouse, a pen, a sound or voice input device, a touch or swipe input device, etc. The output device(s) <b>514</b> such as a display, speakers, a printer, etc. may also be included. The aforementioned devices are examples and others may be used. The computing device <b>500</b> may include one or more communication connections <b>516</b> allowing communications with other computing devices <b>550</b>. Examples of suitable communication connections <b>516</b> include, but are not limited to, radio frequency (RF) transmitter, receiver, and/or transceiver circuitry; universal serial bus (USB), parallel, and/or serial ports.</p><p id="p-0083" num="0082">The term computer readable media as used herein may include computer storage media. Computer storage media may include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, or program modules. The system memory <b>504</b>, the removable storage device <b>509</b>, and the non-removable storage device <b>510</b> are all computer storage media examples (e.g., memory storage). Computer storage media may include RAM, ROM, electrically erasable read-only memory (EEPROM), flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other article of manufacture which can be used to store information and which can be accessed by the computing device <b>500</b>. Any such computer storage media may be part of the computing device <b>500</b>. Computer storage media does not include a carrier wave or other propagated or modulated data signal.</p><p id="p-0084" num="0083">Communication media may be embodied by computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and includes any information delivery media. The term &#x201c;modulated data signal&#x201d; may describe a signal that has one or more characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media may include wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, radio frequency (RF), infrared, and other wireless media.</p><p id="p-0085" num="0084"><figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b></figref> illustrate a mobile computing device <b>600</b>, for example, a mobile telephone, a smart phone, wearable computer (such as a smart watch), a tablet computer, a laptop computer, and the like, with which embodiments of the disclosure may be practiced. In some aspects, the client may be a mobile computing device. With reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, one aspect of a mobile computing device <b>600</b> for implementing the aspects is illustrated. In a basic configuration, the mobile computing device <b>600</b> is a handheld computer having both input elements and output elements. The mobile computing device <b>600</b> typically includes a display <b>605</b> and one or more input buttons <b>610</b> that allow the user to enter information into the mobile computing device <b>600</b>. The display <b>605</b> of the mobile computing device <b>600</b> may also function as an input device (e.g., a touch screen display). If included, an optional side input element <b>615</b> allows further user input. The side input element <b>615</b> may be a rotary switch, a button, or any other type of manual input element. In alternative aspects, mobile computing device <b>600</b> may incorporate more or less input elements. For example, the display <b>605</b> may not be a touch screen in some embodiments. In yet another alternative embodiment, the mobile computing device <b>600</b> is a portable phone system, such as a cellular phone. The mobile computing device <b>600</b> may also include an optional keypad <b>635</b>. Optional keypad <b>635</b> may be a physical keypad or a &#x201c;soft&#x201d; keypad generated on the touch screen display. In various embodiments, the output elements include the display <b>605</b> for showing a graphical user interface (GUI), a visual indicator <b>620</b> (e.g., a light emitting diode), and/or an audio transducer <b>625</b> (e.g., a speaker). In some aspects, the mobile computing device <b>600</b> incorporates a vibration transducer for providing the user with tactile feedback. In yet another aspect, the mobile computing device <b>600</b> incorporates input and/or output ports, such as an audio input (e.g., a microphone jack), an audio output (e.g., a headphone jack), and a video output (e.g., a HDMI port) for sending signals to or receiving signals from an external device.</p><p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram illustrating the architecture of one aspect of a mobile computing device. That is, the mobile computing device <b>600</b> can incorporate a system (e.g., an architecture) <b>702</b> to implement some aspects. In one embodiment, the system <b>702</b> is implemented as a &#x201c;smart phone&#x201d; capable of running one or more applications (e.g., browser, e-mail, calendaring, contact managers, messaging clients, games, and media clients/players). In some aspects, the system <b>702</b> is integrated as a computing device, such as an integrated personal digital assistant (PDA) and wireless phone.</p><p id="p-0087" num="0086">One or more application programs <b>766</b> may be loaded into the memory <b>762</b> and run on or in association with the operating system <b>764</b>. Examples of the application programs include phone dialer programs, e-mail programs, personal information management (PIM) programs, word processing programs, spreadsheet programs, Internet browser programs, messaging programs, and so forth. The system <b>702</b> also includes a non-volatile storage area <b>768</b> within the memory <b>762</b>. The non-volatile storage area <b>768</b> may be used to store persistent information that should not be lost if the system <b>702</b> is powered down. The application programs <b>766</b> may use and store information in the non-volatile storage area <b>768</b>, such as email or other messages used by an email application, and the like. A synchronization application (not shown) also resides on the system <b>702</b> and is programmed to interact with a corresponding synchronization application resident on a host computer to keep the information stored in the non-volatile storage area <b>768</b> synchronized with corresponding information stored at the host computer.</p><p id="p-0088" num="0087">The system <b>702</b> has a power supply <b>770</b>, which may be implemented as one or more batteries. The power supply <b>770</b> may further include an external power source, such as an AC adapter or a powered docking cradle that supplements or recharges the batteries.</p><p id="p-0089" num="0088">The system <b>702</b> may also include a radio interface layer <b>772</b> that performs the function of transmitting and receiving radio frequency communications. The radio interface layer <b>772</b> facilitates wireless connectivity between the system <b>702</b> and the &#x201c;outside world,&#x201d; via a communications carrier or service provider. Transmissions to and from the radio interface layer <b>772</b> are conducted under control of the operating system <b>764</b>. In other words, communications received by the radio interface layer <b>772</b> may be disseminated to the application programs <b>766</b> via the operating system <b>764</b>, and vice versa.</p><p id="p-0090" num="0089">The visual indicator <b>720</b> may be used to provide visual notifications, and/or an audio interface <b>774</b> may be used for producing audible notifications via an audio transducer <b>625</b> (e.g., audio transducer <b>625</b> illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>). In the illustrated embodiment, the visual indicator <b>720</b> is a light emitting diode (LED) and the audio transducer <b>625</b> may be a speaker. These devices may be directly coupled to the power supply <b>770</b> so that when activated, they remain on for a duration dictated by the notification mechanism even though the processor <b>760</b> and other components might shut down for conserving battery power. The LED may be programmed to remain on indefinitely until the user takes action to indicate the powered-on status of the device. The audio interface <b>774</b> is used to provide audible signals to and receive audible signals from the user. For example, in addition to being coupled to the audio transducer <b>625</b>, the audio interface <b>774</b> may also be coupled to a microphone to receive audible input, such as to facilitate a telephone conversation. In accordance with embodiments of the present disclosure, the microphone may also serve as an audio sensor to facilitate control of notifications, as will be described below. The system <b>702</b> may further include a video interface <b>776</b> that enables an operation of peripheral device <b>730</b> (e.g., on-board camera) to record still images, video stream, and the like.</p><p id="p-0091" num="0090">A mobile computing device <b>600</b> implementing the system <b>702</b> may have additional features or functionality. For example, the mobile computing device <b>600</b> may also include additional data storage devices (removable and/or non-removable) such as, magnetic disks, optical disks, or tape. Such additional storage is illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref> by the non-volatile storage area <b>768</b>.</p><p id="p-0092" num="0091">Data/information generated or captured by the mobile computing device <b>600</b> and stored via the system <b>702</b> may be stored locally on the mobile computing device <b>600</b>, as described above, or the data may be stored on any number of storage media that may be accessed by the device via the radio interface layer <b>772</b> or via a wired connection between the mobile computing device <b>600</b> and a separate computing device associated with the mobile computing device <b>600</b>, for example, a server computer in a distributed computing network, such as the Internet. As should be appreciated such data/information may be accessed via the mobile computing device <b>600</b> via the radio interface layer <b>772</b> or via a distributed computing network. Similarly, such data/information may be readily transferred between computing devices for storage and use according to well-known data/information transfer and storage means, including electronic mail and collaborative data/information sharing systems.</p><p id="p-0093" num="0092">As should be appreciated, <figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b></figref> are described for purposes of illustrating the present methods and systems and is not intended to limit the disclosure to a particular sequence of steps or a particular combination of hardware or software components.</p><p id="p-0094" num="0093">The description and illustration of one or more aspects provided in this application are not intended to limit or restrict the scope of the disclosure as claimed in any way. The aspects, examples, and details provided in this application are considered sufficient to convey possession and enable others to make and use the best mode of claimed disclosure. The claimed disclosure should not be construed as being limited to any aspect, example, or detail provided in this application. Regardless of whether shown and described in combination or separately, the various features (both structural and methodological) are intended to be selectively included or omitted to produce an embodiment with a particular set of features. Having been provided with the description and illustration of the present application, one skilled in the art may envision variations, modifications, and alternate aspects falling within the spirit of the broader aspects of the general inventive concept embodied in this application that do not depart from the broader scope of the claimed disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for data stream prioritization by a session controller, the method comprising:<claim-text>receiving usage data associated with a video communication session for one or more client devices of the video communication session, wherein the usage data is based on content within data streams of the video communication session;</claim-text><claim-text>identifying a first client device of the one or more client devices as having a higher priority level during the video communication session based on the usage data; and</claim-text><claim-text>sending instructions to the first client device during the video communication session causing the first client device to improve a quality of a first data stream generated by the first client device for the video communication session.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein receiving the usage data comprises monitoring the usage data during the video communication session;<claim-text>the method further comprising dynamically identifying client devices of the one or more client devices as having the higher priority level during the video communication session based on the usage data.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the usage data indicates a level of interactivity of participants of the video communication session that utilize the one or more client devices.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, the method further comprising:<claim-text>identifying a second client device of the one or more client devices as having a lower priority level during the video communication session based on the usage data; and</claim-text><claim-text>sending instructions to the second client device during the video communication session causing the second client device to reduce a quality of a second data stream generated by the second client device for the video communication session.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, the method further comprising:<claim-text>identifying the first client device as having one of a lower priority level or a default priority level at a later time during the video communication session based on the usage data; and</claim-text><claim-text>sending instructions to the first client device during the video communication session causing the first client device to reduce the quality of the first data stream.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first data stream is one of an upstream data stream or a downstream data stream.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein identifying the first client device as having a higher priority level comprises determining that a participant of the video communication session using the first client device is actively speaking during the video communication session.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein identifying the first client device as having a higher priority level comprises determining that a participant of the video communication session using the first client device is asking a question during the video communication session.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein identifying the first client device as having a higher priority level comprises determining that a participant of the video communication session using the first client device is answering a question during the video communication session.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the usage data indicates whether a participant of the video communication session is observing an application associated with the video communication session and observing the application corresponds to the higher priority level.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the usage data indicates whether the participant of the video communication session is interacting with the application associated with the video communication session and interacting with the application corresponds to the higher priority level.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions cause the first client device to perform at least one of reducing audio compression of the first data stream, reducing video compression of the first data stream, increasing image resolution of the first data stream, increasing image color depth of the first data stream, increasing a bit rate of the first data stream, and/or increasing allocated bandwidth for the first client device.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, the method further comprising sending instructions to a media server that routes the first data stream, wherein the instructions cause the media server to perform at least one of reducing audio compression of the first data stream, reducing video compression of the first data stream, increasing image resolution of the first data stream, increasing image color depth of the first data stream, increasing a bit rate of the first data stream, and/or increasing allocated bandwidth for the first client device.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A method for data stream prioritization by a media server, the method comprising:<claim-text>forwarding a plurality of data streams of a video communication session to a plurality of client devices of the video communication session;</claim-text><claim-text>collecting usage data associated with the video communication session based on the plurality of data streams during the video communication session, wherein the usage data is based on content within the plurality of data streams;</claim-text><claim-text>sending the usage data to a session controller of the video communication session during the video communication session;</claim-text><claim-text>receiving instructions to improve a quality of an identified stream of the plurality of data streams from the session controller during the video communication session, wherein the instructions are based on the usage data;</claim-text><claim-text>performing a first process to improve the quality of the identified stream in response to the instructions.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the identified stream is a first identified stream and the instructions are first instructions;<claim-text>wherein the method further comprises:<claim-text>receiving second instructions to reduce a quality of a second identified stream of the plurality of data streams from the session controller during the video communication session;</claim-text><claim-text>performing a second process to reduce the quality of the second identified stream in response to the instructions.</claim-text></claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein performing the first process comprises at least one of reducing audio compression of the identified data stream, reducing video compression of the identified data stream, increasing image resolution of the identified data stream, increasing image color depth of the identified data stream, increasing a bit rate of the identified data stream, and/or increasing allocated bandwidth for a client device of the plurality of client devices that corresponds to the identified data stream.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the usage data indicates a level of interactivity of participants of the video communication session that utilize the plurality of client devices.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, the method further comprising analyzing at least some content of the plurality of data streams to obtain the usage data.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A system for data stream prioritization, the system comprising:<claim-text>a media server configured to route data streams for a video communication session;</claim-text><claim-text>a session controller configured to:<claim-text>receive usage data associated with a video communication session for one or more client devices of the video communication session, wherein the usage data is based on content within data streams of the video communication session;</claim-text><claim-text>identify a first client device of the one or more client devices as having a higher priority level during the video communication session based on the usage data; and</claim-text><claim-text>send instructions to the first client device during the video communication session causing the first client device to improve a quality of a first data stream generated by the first client device for the video communication session.</claim-text></claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein:<claim-text>the usage data indicates a level of interactivity of participants of the video communication session that utilize the plurality of client devices.</claim-text></claim-text></claim></claims></us-patent-application>
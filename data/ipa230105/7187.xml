<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007188A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007188</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17942920</doc-number><date>20220912</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>CN</country><doc-number>202010758051.6</doc-number><date>20200731</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>268</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>462</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>43</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>268</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>4622</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>4307</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">VIDEO SOURCE SWITCHING METHOD, PLAYING METHOD, APPARATUS, DEVICE, AND STORAGE MEDIUM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/CN2021/102625</doc-number><date>20210628</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17942920</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED</orgname><address><city>Shenzhen</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>HAN</last-name><first-name>Cunai</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">This application discloses a video source switching method, a playing method, an apparatus, a device, and a storage medium. The video source switching method includes obtaining switching information; determining a first key frame of a first video source according to the switching information, the first key frame being a next key frame of a current playing time of the first video source; querying a first time value of the first key frame; identifying a second video source according to the switching information; and switching video sources if a distance between a current time value of the second video source and the first time value is less than or equal to a threshold.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="180.34mm" wi="148.59mm" file="US20230007188A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="194.56mm" wi="150.62mm" file="US20230007188A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="104.48mm" wi="145.71mm" file="US20230007188A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="179.32mm" wi="141.73mm" file="US20230007188A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="139.36mm" wi="143.93mm" file="US20230007188A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="179.32mm" wi="140.38mm" file="US20230007188A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="167.13mm" wi="114.98mm" file="US20230007188A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="75.44mm" wi="115.15mm" file="US20230007188A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="235.20mm" wi="130.89mm" file="US20230007188A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation application of PCT Application No. PCT/CN2021/102625, filed on Jun. 28, 2021, which claims priority to Chinese Patent Application No. 202010758051.6, entitled &#x201c;VIDEO SOURCE SWITCHING METHOD, PLAYING METHOD, APPARATUS, DEVICE, AND STORAGE MEDIUM&#x201d; and filed with the China National Intellectual Property Administration on Jul. 31, 2020. The two applications are both incorporated by reference in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD OF THE TECHNOLOGY</heading><p id="p-0003" num="0002">This application relates to the field of multimedia processing technologies, and in particular, to a video source switching method, a video playing method, an apparatus, a device, and a storage medium.</p><heading id="h-0003" level="1">BACKGROUND OF THE DISCLOSURE</heading><p id="p-0004" num="0003">With the popularity of smart terminals and the development of the Internet, viewing online videos on various smart terminals has become an important part in people's lives. It has become an important task for various online video websites or video APPs to provide users with a better viewing experience. To improve playing quality of network video sources, bit rates of the network video sources are gradually increasing.</p><p id="p-0005" num="0004">During video playing, if a playing error or frame freezing occurs, to ensure normal viewing for a user, an original high bit rate video source needs to be switched to a low bit rate video source. During video source switching, an image after the switching and an image that has been played previously may be discontinuous or repeated. In the related art, to implement video source switching, a player may need to be restarted. However, problems such as a black screen may occur in a smart terminal due to a long switching time.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0006" num="0005">To resolve at least one of the foregoing technical problems, embodiments of this application provide a video source switching method, a video playing method, an apparatus, a device, and a storage medium, to achieve smooth switching between different video sources.</p><p id="p-0007" num="0006">One aspect of this application provides a video source switching method. The video source switching method includes obtaining switching information; determining a first key frame of a first video source according to the switching information, the first key frame being a next key frame of a current playing time of the first video source; querying a first time value of the first key frame; identifying a second video source according to the switching information; and switching video sources if a distance between a current time value of the second video source and the first time value is less than or equal to a threshold.</p><p id="p-0008" num="0007">Another aspect of this application provides a video playing method, including obtaining a video switching event, the video switching event including any one of a switching request event, a playing error event, or a frame freezing event from a user terminal; and performing video source switching according to the video switching event, the video source switching being performed by using the foregoing video source switching method.</p><p id="p-0009" num="0008">Another aspect of this application provides a video playing method, including: displaying an image definition information list; playing a video source with corresponding definition in the image definition information list in response to a video playing instruction; and displaying video image definition information or a video source switching prompt after video source switching when a video switching event is triggered, the video source switching being performed by using the foregoing video source switching method.</p><p id="p-0010" num="0009">According to another aspect of this application, a video source switching apparatus is provided, including: an obtaining module, configured to obtain switching information; a localization module, configured to determine a first key frame of a first video source according to the switching information, the first key frame being a next key frame of a current playing time of the first video source; a query module, configured to query a first time value of the first key frame; a second video source localization module, configured to identify a second video source according to the switching information; and a switching module, configured to switch video sources when a distance between a current time value of the second video source and the first time value is less than or equal to a preset threshold.</p><p id="p-0011" num="0010">According to another aspect of this application, a computer device is provided, including a memory and a processor, the memory storing a computer program; and the computer program, when executed by the processor, causing the processor to perform the method described in the foregoing aspect.</p><p id="p-0012" num="0011">According to another aspect of this application, a non-transitory computer-readable storage medium is provided, storing a computer program, the computer program, when executed by a processor, causing the processor to perform the method described in the foregoing aspect.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> is a structural block diagram of a video switching system according to an embodiment of this application;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b>B</figref> is a structural block diagram of a player engine according to an embodiment of this application;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flowchart of a video source switching method according to an embodiment of this application;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart of a video source switching method according to another embodiment of this application;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of an implementation of step <b>390</b> in <figref idref="DRAWINGS">FIG. <b>3</b></figref>;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart of a video playing method according to an embodiment of this application;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart of a video playing method according to another embodiment of this application;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>7</b>D</figref> are display interfaces in an execution process of the embodiment shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a structural block diagram of a video source switching apparatus according to an embodiment of this application; and</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a structural block diagram of a computer device according to an embodiment of this application.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0023" num="0022">This application is further described below with reference to the accompanying drawings and specific embodiments of this specification. The described embodiments are not to be considered as a limitation to this application. All other embodiments obtained by a person of ordinary skill in the art without creative efforts shall fall within the protection scope of this application.</p><p id="p-0024" num="0023">In the following descriptions, the term &#x201c;some embodiments&#x201d; describes subsets of all possible embodiments, but it may be understood that &#x201c;some embodiments&#x201d; may be the same subset or different subsets of all the possible embodiments, and can be combined with each other without conflict.</p><p id="p-0025" num="0024">Unless otherwise defined, meanings of all technical and scientific terms used in this specification are the same as those usually understood by a person skilled in the art to which this application belongs. Terms used in this specification are merely used to describe objectives of the embodiments of this application, but are not intended to limit this application.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> is a structural block diagram of a video switching system according to an embodiment of this application.</p><p id="p-0027" num="0026">As shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, the video switching system <b>100</b> includes a server <b>110</b> and a player <b>170</b>. The player <b>170</b> may be a related application that provides a video service function. The player <b>170</b> may be configured in a user terminal such as a smartphone, a smart wearable device, a tablet computer, a notebook computer, a personal digital assistant, or an on-board computer. The server <b>110</b> is configured to provide data of different video sources to the user terminal, and provide a video playing service to the user terminal by using the player <b>170</b> installed in the user terminal. The server may be an independent physical server, or may be a server cluster including a plurality of physical servers or a distributed system, or may be a cloud server providing basic cloud computing services, such as a cloud service, a cloud database, cloud computing, a cloud function, cloud storage, a network service, cloud communication, a middleware service, a domain name service, a security service, a CDN, big data, and an artificial intelligence platform. For example, the server <b>110</b> encodes sources at different bit rates for a specified source. The bit rate refers to the number of data bits transmitted per unit time during data transmission, generally in a unit of kbps (that is, kilobits per second). The bit rate is also referred to as a sampling rate. A higher sampling rate per unit time indicates higher precision of an encoded video file and higher approximation of the video file to an original file. Further, the sources at different bit rates include three sources at different bit rates, that is, a high bit rate source, a medium bit rate source, and a low bit rate source. A specific quantity of the sources is not limited, and may be flexibly set. The different bit rates may be any one of different resolutions, different definitions, and different frame rates. The frame rate refers to the number of frames of pictures transmitted in one second, which may also be interpreted as the number of refreshes per second of a graphics processing unit. The number of frames of pictures displayed per second affects image fluency and is in direct proportion to the image fluency. A higher frame rate indicates more fluent images, and a lower frame rate indicates a stronger sense of jitter of the images. Due to a special physiological structure of human eyes, when a frame rate of images is higher than 16 fps, the images are considered to be continuous. For example, three sources at different frame rates may be used, and frame rates of the three sources at different frame rates may be 30 fps (Frames Per Second), 60 fps, and 120 fps respectively.</p><p id="p-0028" num="0027">As shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, the player <b>170</b> may include a device maximum decoding capability module <b>120</b>, a player engine <b>130</b>, a bit rate switching processing module <b>140</b>, and a player upper layer <b>150</b>. The device maximum decoding capability module <b>120</b> is configured to query a maximum bit rate capability supported by a current device. Further, an Andorid platform may obtain, via a system interface, maximum bit rate capabilities that the current device can support for different encoding formats and different definitions; and an ios (a mobile operating system of Apple Inc.) platform sets, according to a test result, a device capability supporting playing at a high bit rate.</p><p id="p-0029" num="0028">For example, the maximum bit rate capability may be a maximum frame rate capability. In this embodiment, the player <b>170</b> may further include a screen refresh rate detection module <b>160</b>, which obtains a screen refresh rate of a current system via a system interface. If the screen refresh rate supports a high frame rate mode, it indicates that a rendering side has already supported rendering of a high frame rate video. If the current screen refresh rate does not support the high frame rate mode, modification of the screen refresh rate may be attempted to support a high frame rate, and whether the screen refresh rate is successfully modified may be determined according to an event called back by the system. If the screen refresh rate is successfully modified, a high frame rate video may be played; otherwise, it indicates that the current screen does not support rendering of a high frame rate video.</p><p id="p-0030" num="0029">The player engine <b>130</b> plays a video source in a playing address given by the player upper layer <b>150</b>. In this embodiment, a video source in a playing address at a high frame rate given by the player upper layer <b>150</b> is played. In addition, during playing, the player engine <b>130</b> detects frame freezing. In this embodiment, the frame freezing is detected by counting a frame loss rate. If the number of frames lost per unit time in a played video reaches a maximum limit, for example, the number of frames lost within <b>5</b> seconds exceeds <b>50</b>, a related event is sent. This indicates that the frame freezing occurs during current playing, which affects user playing. The sent related event includes related frame rate information and error information. In addition, if an error is reported during playing, for example, error information such as unsuccessful playing due to a network cause occurs, a related event is also sent, so that the bit rate switching processing module <b>140</b> receives information about a frame freezing event or a playing error event.</p><p id="p-0031" num="0030">The bit rate switching processing module <b>140</b> determines whether to perform bit rate reduction processing according to the playing error event and frame freezing event sent by the player engine <b>130</b> and a bit rate of a source at which the playing error event and frame freezing event occurs, and informs the player upper layer <b>150</b> of video switching event information. The player upper layer <b>150</b> performs related operations according to the video switching event information. For example, when a high frame rate source is played, the bit rate switching processing module <b>140</b> determines whether to perform frame rate reduction processing according to a frame rate of a source with an error and informs the player upper layer of information about an event that needs to be switched, and the player upper layer performs frame rate reduction and replaying operations. If a playing error event and a frame freezing event due to frame loss occur, and a current frame rate is a high frame rate, for example, 120 fps, the frame rate may be switched to 60 fps. If an error or frame freezing occurs in a source of 60 fps, a frame rate of the source may be switched to 30 fps. However, if a frame rate of a source with an error is 30 fps, error information or a frame freezing prompt is directly sent, so that a user actively switches the frame rate.</p><p id="p-0032" num="0031">In this embodiment, the player upper layer <b>150</b> is further configured to obtain a switching request event from the user terminal. For example, when traffic is limited or WiFi is not connected, a user tends to select a low bit rate video source for playing; while when traffic is sufficient and WiFi is reconnected, the user tends to select a high bit rate video source for playing. For example, sources at different bit rates may refer to sources at different frame rates.</p><p id="p-0033" num="0032">Sources at different frame rates are used as an example to illustrate functions of the player upper layer <b>150</b>. The player upper layer <b>150</b> mainly completes playing scheduling of sources at different bit rates. The player upper layer <b>150</b> obtains a definition list and a frame rate list of sources currently selected by the user from the server <b>110</b>, determines whether there is a high frame rate source in the currently selected sources, and determines whether the high frame rate source has a corresponding backup low frame rate source for switching.</p><p id="p-0034" num="0033">If there is a high frame rate source in the server <b>110</b>, according to an encoding format and resolution of the high frame rate source, a highest frame rate that can be supported by the current encoding format and resolution is obtained. If a frame rate of the high frame rate source is less than the highest frame rate, a decoding side may support decoding of the high frame rate source.</p><p id="p-0035" num="0034">If both decoding and rendering support the high frame rate source, a playing address of the high frame rate source is set to the player engine, and the player <b>170</b> starts to play a high frame rate video. Meanwhile, the player upper layer <b>150</b> monitors the video switching event and determines whether to perform frame rate switching according to the monitored event. For example, if the high frame rate source needs to be switched to a low frame rate source, an address of the low frame rate source is reset to the player engine <b>130</b>, and the player <b>170</b> starts to play a low frame rate video, thereby ensuring normal viewing of the video by the user.</p><p id="p-0036" num="0035">In the video switching system shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, various module parameters, including a decoding capability and a rendering capability, that need to be involved during playing of a high bit rate video source are considered. Before a high frame rate source is requested, it is ensured that the current device can normally play a high frame rate source, thereby ensuring a high quality playing experience for the user. In addition, by using a frame loss rate detection mechanism, it is convenient to count a playing situation of high frame rate sources played by the user, and a playing result can be fed back in time, thereby facilitating timely processing by the player upper layer, and avoiding affecting the playing quality for the user. For an error and frame freezing that occur during playing, the frame rate reduction processing is added, to ensure normal viewing for the user when the playing is abnormal.</p><p id="p-0037" num="0036">The video switching system shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> faces a technical problem of how to achieve smooth switching during switching between video sources at different bit rates.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>1</b>B</figref> is a structural diagram of the player engine <b>130</b> according to an embodiment of this application. The player engine <b>130</b> includes: a first demuxer <b>131</b>, a second demuxer <b>132</b>, a decoder <b>133</b>, and a synchronous rendering module <b>134</b>. The demuxers mainly complete parsing and downloading of data. During parsing, the demuxers parse a timestamp of each corresponding packet according to format standards of video sources. The first demuxer <b>131</b> is configured to locate and open an address of a first video source, and parse and download data of the first video source. The second demuxer <b>132</b> is configured to locate and open an address of a second video source, and parse and download data of the second video source. Both the first demuxer <b>131</b> and the second demuxer <b>132</b> store the parsed and downloaded data in a buffer queue. The decoder <b>133</b> can decode the data in the buffer queue, and the synchronous rendering module <b>134</b> synchronously renders the decoded data to a display screen to implement video playing.</p><p id="p-0039" num="0038">To achieve smooth switching operations between video sources at different bit rates, an embodiment of this application provides a video source switching method. In the method, during switching between video sources at different bit rates, a switching moment of a new video source is set as a time value of a key frame corresponding to an original video source, thereby resolving the problem that images after the switching are discontinuous. The switching method may be applied to a user terminal, or may be applied to a server, or may be applied to a hardware implementation environment including the user terminal and the server. In addition, the switching method may alternatively be software, such as an application having a video source switching function, run on the user terminal or the server. The user terminal may be a smartphone, a tablet computer, a notebook computer, a desktop computer, a smart speaker, a smartwatch, or the like, but is not limited thereto. The server may be an independent physical server, or may be a server cluster including a plurality of physical servers or a distributed system, or may be a cloud server providing basic cloud computing services, such as a cloud service, a cloud database, cloud computing, a cloud function, cloud storage, a network service, cloud communication, a middleware service, a domain name service, a security service, a CDN, big data, and an artificial intelligence platform.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flowchart of an application example when the switching method is applied to a user terminal. In one embodiment, the switching method may be performed by the player <b>170</b> installed in the user terminal shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, and the first video source and the second video source involved in switching are video sources at different bit rates. Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the method may include the following steps <b>210</b> to <b>250</b>.</p><p id="p-0041" num="0040">Step <b>210</b>: Obtain switching information.</p><p id="p-0042" num="0041">In one embodiment, the switching information may include information of an address such as a url address of a to-be-switched second video source, and may further include time information triggered by a video switching event. The video switching event includes any one of a switching request event, a playing error event, or a frame freezing event from a user terminal.</p><p id="p-0043" num="0042">In this embodiment, the switching information may be obtained by detecting status information of a dynamic update address interface. The dynamic update address interface is an interface provided by the player engine <b>130</b>, and the player upper layer <b>150</b> may invoke the interface to set the url address, which is similar to updateSourceDataUrl( ) to update the address of the to-be-switched second video source. In this dynamic update manner, the player may also invoke the interface to set a switching address during playing without affecting video playing.</p><p id="p-0044" num="0043">Step <b>220</b>: Determine a first key frame of the first video source according to the switching information, the first key frame being a next key frame of a current playing time of the first video source.</p><p id="p-0045" num="0044">Step <b>230</b>: Query a first time value of the first key frame.</p><p id="p-0046" num="0045">Steps <b>220</b> to <b>230</b> are performed by the first demuxer <b>131</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>. After the player upper layer <b>150</b> sets the address of the to-be-switched second video source to the dynamic update address interface, the player engine <b>130</b> detects that there is a to-be-switched address, and informs the first demuxer <b>131</b> of the video switching event. The first demuxer <b>131</b> queries a time value of the first key frame (that is, the first time value). After obtaining the first time value, the first demuxer <b>131</b> stops work and no longer requests data. The first time value may be a value of time such as a moment or a timestamp corresponding to the first key frame. Generally, the first time value may be obtained by querying the timestamp.</p><p id="p-0047" num="0046">Step <b>240</b>: Locate the second video source according to the switching information.</p><p id="p-0048" num="0047">As described above, the switching information includes the address of the second video source. Therefore, the second video source may be located and opened according to the switching information.</p><p id="p-0049" num="0048">Step <b>250</b>: Perform video source switching when a distance between a current time value of the second video source and the first time value is less than or equal to a preset threshold.</p><p id="p-0050" num="0049">When the distance between the current time value and the first time value meets a condition of the preset threshold, it is considered that the data of the second video source has reached a playing position of the first key frame of the first video source, and synchronous rendering processing is performed to perform the video source switching. The preset threshold may be reasonably set to a value that is small enough, so that the video switching is imperceptible to a viewer. The preset threshold may be set to 80 ms, or may be set to 60 ms or 50 ms. The specific value is not limited herein, and may be set according to a playing parameter and a condition under which the switching is imperceptible to the viewer. The smooth switching between video sources at different bit rates is achieved by setting the switching moment at a position so that a distance between the switching moment and the first time value is less than the preset threshold.</p><p id="p-0051" num="0050">In this embodiment, in some cases, if there is a frame at the same moment as the first time value in the second video source, the video source switching may be performed when the current time value of the second video source is equal to the first time value. In some cases, if there is no frame at the same moment as the first time value in the second video source, the video source switching may be performed when the current time value is greater than or less than the first time value and the distance between the current time value and the first time value is less than or equal to the preset threshold.</p><p id="p-0052" num="0051">In this embodiment, the current time value of the second video source may be compared with the first time value, and the video source switching is performed until the current time value is greater than or equal to the first time value and the distance between the current time value to the first time value is less than or equal to the preset threshold. The manner of determining the position of the switching moment is convenient and easy to implement.</p><p id="p-0053" num="0052">In the video source switching method provided in this embodiment, during switching between video sources at different bit rates, a switching moment of the second video source is set as a time value of a key frame corresponding to the first video source, to achieve the smooth switching between the video sources at different bit rates, thereby resolving the technical problem that images are discontinuous in the related art.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart of a video source switching method according to another embodiment of this application. This embodiment is also described by using an example in which the method is applied to the implementation environment shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>. The method is performed by the player <b>170</b> installed in the user terminal shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>. In the method, a first video source and a second video source involved in switching are video sources at different bit rates. Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the method may include the following steps:</p><p id="p-0055" num="0054">Step <b>310</b>: Obtain switching information.</p><p id="p-0056" num="0055">Content of the switching information and the method for obtaining the switching information are the same as those in step <b>210</b>, and details are not described herein again.</p><p id="p-0057" num="0056">Step <b>320</b>: Determine a first key frame of the first video source according to the switching information, the first key frame being a next key frame of a current playing time of the first video source.</p><p id="p-0058" num="0057">Step <b>330</b>: Read data of the first video source until the first key frame by using a first demuxer, the data of the first video source being stored in a buffer queue.</p><p id="p-0059" num="0058">Step <b>340</b>: Query a first time value of the first key frame.</p><p id="p-0060" num="0059">Steps <b>320</b> to <b>340</b> are performed by the first demuxer <b>131</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>. After the player upper layer <b>150</b> sets the address of the to-be-switched second video source to the dynamic update address interface, the player engine <b>130</b> detects that there is a to-be-switched address, and informs the first demuxer <b>131</b> of the video switching event. The first demuxer <b>131</b> continuously reads the data of the first video source until a next key frame of a current playing event, that is, the first key frame, and stores the read data in the buffer queue of the player engine <b>130</b>. A size of the buffer queue is set according to a comprehensive consideration of parameters such as playing performance, for example, may be set to <b>150</b> frames. The specific size is not limited herein. Since data of the to-be-switched second video source has not been obtained, and the player is not ready for work of switching playing, continuous reading and caching of the data of the first video source buys time for the work of the switching playing. When the first demuxer <b>131</b> queries the time value of the first key frame (that is, the first time value), the first demuxer <b>131</b> stops work and no longer requests data. The first time value may be a value of time such as a moment or a timestamp corresponding to the first key frame. Generally, the first time value may be obtained by querying the timestamp.</p><p id="p-0061" num="0060">Step <b>350</b>: Identify the second video source according to the switching information.</p><p id="p-0062" num="0061">As described above, the switching information includes the address of the second video source. Before step <b>350</b>, the method may further include a step of creating the second demuxer <b>132</b>. The second demuxer <b>132</b> is started to locate the second video source.</p><p id="p-0063" num="0062">Step <b>360</b>: Determine a second key frame of the second video source, a time value of the second key frame being less than the first time value and closest to the first time value.</p><p id="p-0064" num="0063">Step <b>370</b>: Read, from the second key frame, data of the second video source by using the second demuxer, to obtain one or more data packets, store the one or more data packets in the buffer queue, and add a second video source identifier to the first one of the one or more data packets.</p><p id="p-0065" num="0064">Steps <b>350</b> to <b>370</b> are performed by the second demuxer <b>132</b>. After the second video source is located and opened, the second demuxer <b>132</b> performs a seek operation in the opened second video source by using a backward mode, to find a key frame before the first time value and closest to the first time value, which is defined as the second key frame. Since the seek operation is performed by using the backward mode, the determined time value of the second key frame (that is, the second time value, which may be a value of time such as a moment or a timestamp corresponding to the second key frame) needs to be less than the first time value. The second demuxer <b>132</b> stores, from the second key frame, the read data of the second video source in the buffer queue. At this point, the buffer queue has stored the data of the first video source and the data of the second video source. In this embodiment, the seek operation refers to an operation of searching for a target position. For example, in step <b>360</b>, assuming that the value of the time (that is, the first time value) such as the moment or the timestamp corresponding to the first key frame is 2700 ms, the target position to be searched for by the seek operation is a position of a key frame in the second video source, and a value of time (that is, the second time value) such as a moment or a timestamp corresponding to the position of the key frame is less than 2700 ms and closest to the 2700 ms.</p><p id="p-0066" num="0065">In this embodiment, the first demuxer is turned off after the data of the second video source is successfully read.</p><p id="p-0067" num="0066">Step <b>380</b>: When the second video source identifier is detected during decoding of the data in the buffer queue by a decoder, refresh the buffer queue or restart the decoder.</p><p id="p-0068" num="0067">In this embodiment, the data in the buffer queue may be decoded by using the decoder <b>133</b>. Since data of the first video source before the first key frame is also in the buffer queue, the decoder <b>133</b> continuously decodes and synchronously renders the data of the first video source before the first key frame.</p><p id="p-0069" num="0068">When the second video source identifier is detected during decoding, a flush function is invoked to refresh the buffer queue or restart the decoder <b>133</b>. The first video source and the second video source are video sources at different bit rates. If encoding parameters of the first video source and the second video source are inconsistent, the decoder <b>133</b> needs to be restarted. If the parameters of the first video source and the second video source are consistent, there is no need to restart the decoder. In this case, the flush function needs to be invoked to refresh the buffer queue, which saves time consumed for restarting the decoder. For example, if the first video source and the second video source are video sources at different frame rates, the encoding parameters of the first video source and the second video source are consistent, and switching time can be saved by using the method of refreshing the buffer queue by invoking the flush function.</p><p id="p-0070" num="0069">Step <b>390</b>: Switch video sources when a distance between a current time value of the second video source and the first time value is less than or equal to a preset threshold.</p><p id="p-0071" num="0070">When the refreshing or restarting is completed, the data of the second video source is decoded again, and a distance between a current time value of the data to the first time value is determined. When the distance is less than or equal to the preset threshold, video source switching is performed. When the distance between the current time value and the first time value meets a condition of the preset threshold, it is considered that the data of the second video source has reached a playing position of the first key frame of the first video source, and synchronous rendering processing is performed to perform the video source switching. Setting of the preset threshold and the method for determining the video source switching moment are the same as those in step <b>250</b>, and details are not described herein.</p><p id="p-0072" num="0071">In this embodiment, step <b>390</b> is performed from the second key frame, which helps to quickly find the switching moment.</p><p id="p-0073" num="0072">In one embodiment, step <b>390</b> may include step <b>391</b> and step <b>392</b> shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0074" num="0073">Step <b>391</b>: Decode the second video source from the second key frame, to obtain decoded data.</p><p id="p-0075" num="0074">Step <b>392</b>: Discard the decoded data when the distance is greater than the preset threshold, and synchronize and render the decoded data when the distance is less than or equal to the preset threshold, to perform the video source switching.</p><p id="p-0076" num="0075">In step <b>391</b> and step <b>392</b>, quick decoding processing is implemented. Before the switching moment is reached, the decoded data is discarded, and synchronization and rendering are not performed, thereby saving synchronization and rendering time. Until the switching moment is reached, that is, the current time value meets the condition of the preset threshold, the decoded data is synchronized and rendered to perform the video source switching.</p><p id="p-0077" num="0076">In the video source switching method provided in this embodiment, there is no need to restart the entire player. A process of restarting the player is mainly as follows: Create a player resource ((thread creation, initialization of a parameter setting, and the like); the demuxer establishes a connection and downloads the data according to the address; the decoder is restarted and performs decoding; and the rendering module is restarted and performs rendering. The whole process may consume 700 ms to 900 ms, and a black screen occurs within this time period. When the player is restarted with a new video source address being used, it is needed to seek to the previous playing position. If a position fed back by seek is different from the previous playing position, it indicates that data of the position fed back by the seek is not aligned with data of the previous playing position, resulting in images that are discontinuous. In addition, if a time value of the position fed back by the seek is less than a time value of the previous playing position, images are repeated.</p><p id="p-0078" num="0077">In this embodiment, during switching between video sources at different bit rates, a switching moment of the second video source is set as a time value of a key frame corresponding to the first video source, to achieve the smooth switching between the video sources at different bit rates, thereby resolving the technical problem that images after the switching are discontinuous in the related art. In addition, the method reduces time for creating the player and initializing the parameter is reduced, and time consumed for creating the rendering module. Especially, in a case of consistent encoding parameters of different video sources, time consumed for restarting the decoder is also reduced. The switching process consumes about 200 ms to 300 ms in total. In addition, since the rendering module is not recreated, frames displayed previously are continuously displayed on the screen. Therefore, the black screen does not occur, and due to short switching time, the video switching is basically imperceptible to the user.</p><p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart of a video playing method according to an embodiment of this application. The video playing method is interactively performed by the player <b>170</b> and the server <b>110</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, and includes the following steps <b>510</b> to <b>520</b>.</p><p id="p-0080" num="0079">Step <b>510</b>: Obtain a video switching event, the video switching event including any one of a switching request event, a playing error event, or a frame freezing event from a user terminal. Step <b>510</b> is performed by the player <b>170</b> installed in the user terminal, and for example, is performed by the player upper layer <b>150</b> in the player <b>170</b>. For a specific video switching event, reference may be made to the description of the various video switching events obtained by the player upper layer <b>150</b> in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>.</p><p id="p-0081" num="0080">Step <b>520</b>: Switch video sources according to the video switching event, the video source switching being performed by using the foregoing video source switching method.</p><p id="p-0082" num="0081">In the video playing method provided in this embodiment, the video source switching is performed according to the video switching event, to achieve smooth switching between different video sources during video playing.</p><p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart of a video playing method according to another embodiment of this application. The video playing method is performed by the player <b>170</b> installed in the user terminal shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, and includes the following steps <b>610</b> to <b>630</b>.</p><p id="p-0084" num="0083">Step <b>610</b>: Display an image definition information list. A video playing interface of the user terminal displays the image definition information list for a user to select video sources with different definitions.</p><p id="p-0085" num="0084">Step <b>620</b>: Play a video source with corresponding definition in the image definition information list in response to a video playing instruction.</p><p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>7</b>D</figref> show display interfaces of a user terminal during video playing. <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> is a display interface during video playing, and the display interface <b>710</b> displays a currently played video <b>720</b>. <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> is a display interface after an instruction touched by a user is obtained by the interface. In this case, a function list <b>740</b> is displayed on the interface. The function list <b>740</b> includes a link used for triggering the image definition information list, such as &#x201c;<b>270</b>P&#x201d; shown in the figure. After the user taps the &#x201c;<b>270</b>P&#x201d;, a display interface for the user to select definition shown in <figref idref="DRAWINGS">FIG. <b>7</b>C</figref> is entered, and an image definition information list <b>750</b> is displayed. The user may select a desired definition option from the image definition information list <b>750</b>. For example, after the user taps the &#x201c;HDR Wonderful World of Color&#x201d;, a video source with &#x201c;HDR&#x201d; definition is played in response to the video playing instruction. The HDR (High-dynamic-range) represents high-dynamic-range imaging, which can improve an exposure dynamic range of an image, thereby obtaining a better image display experience.</p><p id="p-0087" num="0086">Step <b>630</b>: Display video image definition information or a video source switching prompt after video source switching when a video switching event is triggered, the video source switching being performed by using the foregoing video source switching method.</p><p id="p-0088" num="0087"><figref idref="DRAWINGS">FIG. <b>7</b>D</figref> shows a display interface after the video source switching. Content in an information prompt box <b>760</b> is &#x201c;a video source of second definition is being played&#x201d;. The information prompt box <b>760</b> is used for prompting information about the video source switching. In this embodiment, video image definition information after switching may be directly displayed on the display interface. For example, the &#x201c;second definition&#x201d; may be displayed on the upper right or bottom right of the display interface.</p><p id="p-0089" num="0088">For example, the video switching event includes any one of a switching request event, a playing error event, or a frame freezing event from the user terminal.</p><p id="p-0090" num="0089">Referring to the display interfaces shown in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>7</b>D</figref>, the method in this embodiment is applied to video playing, and a specific process is as follows:</p><p id="p-0091" num="0090">In the display interface during video playing shown in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, the user may enable the player to enter the display interface shown in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> by touching the display interface <b>710</b> or another operation method. The display interface in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> displays the currently played video <b>720</b>, a progress bar <b>730</b>, and the function list <b>740</b>. Different options in the function list <b>740</b> are used for opening corresponding option lists, so that the user can freely select corresponding option information. The option &#x201c;<b>270</b>P&#x201d; in the list <b>740</b> is image definition information of the video source of the currently played video, and the option can be linked to the image definition information list <b>750</b> in <figref idref="DRAWINGS">FIG. <b>7</b>C</figref>.</p><p id="p-0092" num="0091">After the user taps the option &#x201c;<b>270</b>P&#x201d;, the display interface shown in <figref idref="DRAWINGS">FIG. <b>7</b>C</figref> is entered. The image definition information list <b>750</b> on the display interface includes a plurality of definition options, and for example, are <b>270</b>P Standard Definition, <b>480</b>P High Definition, <b>720</b>P Ultra High Definition, <b>1080</b>P Blue-Ray Definition, and HDR Wonderful World of Color. The switching request event from the user terminal may be triggered by tapping any one of the definition options. The switching request event includes image definition information of a to-be-switched video source. Different image definition information corresponds to video sources at different bit rates stored in the server <b>110</b>. The above definition options are merely examples. Names and the number of the definition options, and the image definition information represented by the definition options may be flexibly set, which are not limited herein.</p><p id="p-0093" num="0092">The switching request event is triggered when the user taps any one of the definition options. After obtaining the switching request event, the player upper layer <b>150</b> updates the dynamic update address interface in the player engine <b>130</b>. In addition, during the current video playing, if the player engine <b>130</b> detects a playing error or frame freezing, the player engine <b>130</b> sends a playing error event or a frame freezing event to the bit rate switching processing module <b>140</b>. The bit rate switching processing module <b>140</b> determines whether to perform bit rate reduction processing according to the playing error event and frame freezing event sent by the player engine <b>130</b> and a bit rate of the source with an error, and informs the player upper layer <b>150</b> of the video switching event. It can be seen that the video switching event that can be obtained by the player upper layer <b>150</b> includes the switching request event, the playing error event, and the frame freezing event from the user terminal.</p><p id="p-0094" num="0093">The player engine <b>130</b> obtains switching information corresponding to image definition information selected by the user by detecting the status information of the dynamic update address interface. According to the switching information, the player engine <b>130</b> performs the video source switching method shown in the foregoing embodiment, to complete smooth switching between video sources.</p><p id="p-0095" num="0094">For example, when the user taps the &#x201c;HDR Wonderful World of Color&#x201d; option, that is, when the switching request event from the user terminal is triggered, a user playing instruction is generated. After completing switching to a HDR video source in response to the user playing instruction, the player displays video source switching prompt information shown in the information prompt box <b>760</b> in <figref idref="DRAWINGS">FIG. <b>7</b>D</figref>, to prompt the user that video source switching has been completed.</p><p id="p-0096" num="0095">In this embodiment, for the user playing instruction generated according to the playing error event or frame freezing event, the player may also display the video source switching prompt information in the information prompt box <b>760</b> after completing video source switching in response to the user playing instruction.</p><p id="p-0097" num="0096">A specific description about the image definition information, and displayed specific content and positions of the involved information such as the prompt information on the display interfaces may be flexibly set, which are not limited herein.</p><p id="p-0098" num="0097">In the video playing method provided in this embodiment, the video source switching is performed according to the video switching event, to achieve smooth switching during video playing.</p><p id="p-0099" num="0098"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic diagram of a video source switching apparatus according to an embodiment of this application. The apparatus includes an obtaining module <b>810</b>, a identifying module <b>820</b>, a query module <b>830</b>, a second video source identifying module <b>840</b>, and a switching module <b>850</b>.</p><p id="p-0100" num="0099">The obtaining module <b>810</b> is configured to obtain switching information.</p><p id="p-0101" num="0100">The identifying module <b>820</b> is configured to determine a first key frame of a first video source according to the switching information, the first key frame being a next key frame of a current playing time of the first video source.</p><p id="p-0102" num="0101">The query module <b>830</b> is configured to query a first time value of the first key frame.</p><p id="p-0103" num="0102">The second video source identifying module <b>840</b> is configured to identify a second video source according to the switching information.</p><p id="p-0104" num="0103">The switching module <b>850</b> is configured to perform video source switching when a distance between a current time value of the second video source and the first time value is less than or equal to a preset threshold.</p><p id="p-0105" num="0104">According to the video source switching apparatus provided in this embodiment, during switching between video sources at different bit rates, a switching moment of the second video source is set as a time value of a key frame corresponding to the first video source, to achieve the smooth switching between the video sources at different bit rates.</p><p id="p-0106" num="0105">The term unit (and other similar terms such as subunit, module, submodule, etc.) in this disclosure may refer to a software unit, a hardware unit, or a combination thereof. A software unit (e.g., computer program) may be developed using a computer programming language. A hardware unit may be implemented using processing circuitry and/or memory. Each unit can be implemented using one or more processors (or processors and memory). Likewise, a processor (or processors and memory) can be used to implement one or more units. Moreover, each unit can be part of an overall unit that includes the functionalities of the unit.</p><p id="p-0107" num="0106">An embodiment of this application further provides a computer device, including a memory and a processor, the memory storing a computer program, and the computer program, when executed by the processor, causing the processor to perform the method in the foregoing embodiments.</p><p id="p-0108" num="0107">In one embodiment, the computer device may be a user terminal, or may be a server.</p><p id="p-0109" num="0108">In this embodiment, an example in which the computer device is a user terminal is used, is as follows:</p><p id="p-0110" num="0109">As shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the computer device <b>900</b> may include components such as a radio frequency (RF) circuit <b>910</b>, a memory <b>920</b> including one or more computer readable storage media, an input unit <b>930</b>, a display unit <b>940</b>, a sensor <b>950</b>, an audio circuit <b>960</b>, a short-range wireless communications module <b>970</b>, a processor <b>980</b> including one or more processing cores, and a power supply <b>990</b>. A person skilled in the art may understand that the device structure shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref> does not constitute a limitation to the electronic device. The computer device may include more or fewer components than those shown in the figure, or some components may be combined, or a different component deployment may be used.</p><p id="p-0111" num="0110">The RF circuit <b>910</b> may be configured to receive and transmit signals during an information receiving and transmitting process or a call process. Particularly, after receiving downlink information from a base station, the RF circuit delivers the downlink information to one or more processors <b>980</b> for processing, and transmits related uplink data to the base station. Generally, the RF circuit <b>910</b> includes, but not limited to, an antenna, at least one amplifier, a tuner, one or more oscillators, a subscriber identity module (SIM) card, a transceiver, a coupler, a low noise amplifier (LNA), and a duplexer. In addition, the RF circuit <b>910</b> may also communicate with a network and another device through wireless communication. The wireless communication may use any communication standard or protocol, which includes, but not limited to, Global system for mobile communication (GSM), general packet radio service (GPRS), Code Division Multiple Access (CDMA), Wideband Code Division Multiple Access (WCDMA), Long Term Evolution (LTE), email, short messaging service (SMS), and the like.</p><p id="p-0112" num="0111">The memory <b>920</b> may be configured to store a software program and a module. The processor <b>980</b> runs the software program and the module stored in the memory <b>920</b>, to implement various functional applications and data processing. The memory <b>920</b> may mainly include a program storage area and a data storage area. The program storage area may store an operating system, an application program required by at least one function (such as a sound playback function and an image display function), and the like. The data storage area may store data (such as audio data and an address book) created according to the use of the device <b>900</b>, and the like. In addition, the memory <b>920</b> may include a high-speed random access memory, and may further include a nonvolatile memory, such as at least one magnetic disk storage device, a flash memory, or another volatile solid-state storage device. Correspondingly, the memory <b>920</b> may further include a memory controller, so as to provide access of the processor <b>980</b> and the input unit <b>930</b> to the memory <b>920</b>. Although <figref idref="DRAWINGS">FIG. <b>9</b></figref> shows the RF circuit <b>910</b>, it may be understood that the wireless communications unit is not a necessary component of the device <b>900</b>, and when required, the wireless communications unit may be omitted as long as the scope of the essence of the present disclosure is not changed.</p><p id="p-0113" num="0112">The input unit <b>930</b> may be configured to receive input digit or character information, and generate a keyboard, mouse, joystick, optical, or track ball signal input related to a user setting and function control. For example, the input unit <b>930</b> may include a touch-sensitive surface <b>932</b> and another input device <b>931</b>. The touch-sensitive surface <b>932</b> may also be referred to as a touch display screen or a touch panel, and may collect a touch operation of a user on or near the touch-sensitive surface (such as an operation of a user on or near the touch-sensitive surface <b>932</b> by using any suitable object or accessory, such as a finger or a stylus), and drive a corresponding connection apparatus according to a preset program. In this embodiment, the touch-sensitive surface <b>932</b> may include two parts: a touch detection apparatus and a touch controller. The touch detection apparatus detects a touch position of the user, detects a signal generated by the touch operation, and transfers the signal to the touch controller. The touch controller receives the touch information from the touch detection apparatus, converts the touch information into touch point coordinates, and transmits the touch point coordinates to the <b>980</b>. Moreover, the touch controller can receive and execute a command sent from the processor <b>980</b>. In addition, the touch-sensitive surface <b>932</b> may be implemented by using various types, such as a resistive type, a capacitance type, an infrared type, and a surface sound wave type. In addition to the touch-sensitive surface <b>932</b>, the input unit <b>930</b> may further include another input device <b>931</b>. For example, the another input device <b>931</b> may include, but not limited to, one or more of a physical keyboard, a functional key (such as a volume control key or a switch key), a track ball, a mouse, and a joystick.</p><p id="p-0114" num="0113">The display unit <b>940</b> may be configured to display information input by the user or information provided for the user, and various graphical user interfaces of the device <b>900</b>. The graphical user interfaces may be formed by a graph, a text, an icon, a video, or any combination thereof. The display unit <b>940</b> may include a display panel <b>941</b>. In this embodiment, the display panel <b>941</b> may be configured by using a liquid crystal display (LCD), an organic light-emitting diode (OLED), or the like. Further, the touch-sensitive surface <b>932</b> may cover the display panel <b>941</b>. After detecting a touch operation on or near the touch-sensitive surface <b>932</b>, the touch-sensitive surface <b>932</b> transfers the touch operation to the processor <b>980</b>, so as to determine a type of a touch event. Then, the processor <b>980</b> provides corresponding visual output on the display panel <b>941</b> according to the type of the touch event. Although, in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the touch-sensitive surface <b>932</b> and the display panel <b>941</b> are used as two separate parts to implement input and output functions, in some embodiments, the touch-sensitive surface <b>932</b> and the display panel <b>941</b> may be integrated to implement the input and output functions.</p><p id="p-0115" num="0114">The computer device <b>900</b> may further include at least one sensor <b>950</b>, for example, an optical sensor, a movement sensor, and another sensor. For example, the optical sensor may include an ambient light sensor and a proximity sensor. The ambient light sensor may adjust luminance of the display panel <b>941</b> according to brightness of the ambient light. The proximity sensor may switch off the display panel <b>941</b> and/or backlight when the device <b>900</b> is moved to the ear. As one type of motion sensor, a gravity acceleration sensor can detect magnitude of accelerations in various directions (generally on three axes), may detect magnitude and a direction of the gravity when static, and may be applied to an application that recognizes the attitude of the mobile phone (for example, switching between landscape orientation and portrait orientation, a related game, and magnetometer attitude calibration), a function related to vibration recognition (such as a pedometer and a knock), and the like. Other sensors, such as a gyroscope, a barometer, a hygrometer, a thermometer, and an infrared sensor, which may be configured in the device <b>900</b>, are not further described herein.</p><p id="p-0116" num="0115">The audio circuit <b>960</b>, a speaker <b>961</b>, and a microphone <b>962</b> may provide audio interfaces between the user and the device <b>900</b>. The audio circuit <b>960</b> may convert received audio data into an electric signal and transmit the electric signal to the speaker <b>961</b>. The speaker <b>961</b> converts the electric signal into a sound signal for output. On the other hand, the microphone <b>962</b> converts a collected sound signal into an electric signal. The audio circuit <b>960</b> receives the electric signal and converts the electric signal into audio data, and outputs the audio data to the processor <b>980</b> for processing. Then, the processor <b>980</b> sends the audio data to, for example, another control device by using the RF circuit <b>910</b>, or outputs the audio data to the memory <b>920</b> for further processing. The audio circuit <b>960</b> may further include an earplug jack, so as to provide communication between a peripheral earphone and the device <b>900</b>.</p><p id="p-0117" num="0116">The short-range wireless communications module <b>970</b> may be a wireless fidelity (WiFi) module, a Bluetooth module, an infrared module, or the like. The device <b>900</b> may transmit, by using the short-range wireless communications module <b>970</b>, information to a wireless transmission module that is set in a battle device.</p><p id="p-0118" num="0117">The processor <b>980</b> is a control center of the device <b>900</b>, and is connected to various parts of the entire control device by using various interfaces and lines. By running or executing a software program and/or module stored in the memory <b>920</b>, and invoking data stored in the memory <b>920</b>, the processor performs various functions and data processing of the device <b>900</b>, thereby performing overall monitoring on the control device. In this embodiment, the processor <b>980</b> may include the one or more processing cores. In this embodiment, the processor <b>980</b> may integrate an application processor and a modem processor. The application processor mainly processes an operating system, a user interface, an application program, and the like. The modem processor mainly processes wireless communication. It may be understood that the modem processor may not be integrated into the processor <b>950</b>.</p><p id="p-0119" num="0118">The device <b>900</b> further includes the power supply <b>990</b> (such as a battery) for supplying power to the components. In this embodiment, the power supply may be logically connected to the processor <b>980</b> by using a power management system, thereby implementing functions such as charging, discharging, and power consumption management by using the power management system. The power supply <b>990</b> may further include one or more of a direct current or alternating current power supply, a re-charging system, a power failure detection circuit, a power supply converter or inverter, a power supply state indicator, and any other component.</p><p id="p-0120" num="0119">Although not shown in the figure, the device <b>900</b> may further include a camera, a Bluetooth module, and the like, which are not further described herein.</p><p id="p-0121" num="0120">An embodiment of this application further provides a computer-readable storage medium, storing a computer program, the computer program, when executed by a processor, causing the processor to perform the method in the foregoing embodiments.</p><p id="p-0122" num="0121">The terms such as &#x201c;first&#x201d;, &#x201c;second&#x201d;, &#x201c;third&#x201d;, and &#x201c;fourth&#x201d; (if any) in the specification and accompanying drawings of this application are used for distinguishing similar objects and not necessarily used for describing any particular order or sequence. Data used in this way is interchangeable in a suitable case, so that the embodiments of this application described herein can be implemented in a sequence in addition to the sequence shown or described herein. Moreover, the terms &#x201c;include&#x201d;, &#x201c;contain&#x201d;, and any other variants thereof mean to cover the non-exclusive inclusion. For example, a process, method, system, product, or an apparatus that includes a list of steps or units is not necessarily limited to those steps or units that are clearly listed, but may include other steps or units not expressly listed or inherent to such a process, method, system, product, or an apparatus.</p><p id="p-0123" num="0122">It should be understood that, in this embodiment, &#x201c;at least one&#x201d; means one or more, and &#x201c;a plurality of&#x201d; means two or more. &#x201c;And/or&#x201d; is used to describe an association between associated objects, and indicates that there may be three types of relationships. For example, &#x201c;A and/or B&#x201d; may indicate that only A exists, only B exists, and both A and B exist, where A and B may be singular or plural. The character &#x201c;/&#x201d; in this specification generally indicates an &#x201c;or&#x201d; relationship between the associated objects. &#x201c;At least one of the following items&#x201d; or a similar expression means any combination of these items, including a single item or any combination of a plurality of items. For example, at least one of a, b, or c may represent a, b, c, &#x201c;a and b&#x201d;, &#x201c;a and c&#x201d;, &#x201c;b and c&#x201d;, or &#x201c;a, b, and c&#x201d;, where a, b, and c may be singular or plural.</p><p id="p-0124" num="0123">In the several embodiments provided in this application, it should be understood that the disclosed system, apparatus, and method may be implemented in other manners. For example, the described apparatus embodiment is merely an example. For example, the unit division is merely a logical function division and may be other division in various embodiments. For example, a plurality of units or components may be combined or integrated into another system, or some features may be ignored or not performed. In addition, the displayed or discussed mutual couplings or direct couplings or communication connections may be implemented by using some interfaces. The indirect couplings or communication connections between the apparatuses or units may be implemented in electronic, mechanical, or other forms.</p><p id="p-0125" num="0124">The units described as separate components may or may not be physically separated, and the components displayed as units may or may not be physical units, and may be located in one place or may be distributed over a plurality of network units. Some or all of the units may be selected according to the needs to achieve the objectives of the solutions of the embodiments.</p><p id="p-0126" num="0125">In addition, functional units in the embodiments of this application may be integrated into one processing unit, or each of the units may be physically separated, or two or more units may be integrated into one unit. The integrated unit may be implemented in the form of hardware, or may be implemented in a form of a software functional unit.</p><p id="p-0127" num="0126">When the integrated unit is implemented in the form of a software functional unit and sold or used as an independent product, the integrated unit may be stored in a computer-readable storage medium. Based on such an understanding, the technical solutions of this application essentially, or the part contributing to the prior art, or all or some of the technical solutions may be implemented in the form of a software product. The computer software product is stored in a storage medium and includes several instructions for instructing a computer apparatus (which may be a personal computer, a server, a network apparatus, or the like) to perform all or some of the steps of the methods described in the embodiments of this application. The foregoing storage medium includes various media capable of storing program codes, such as, a USB flash drive, a mobile hard disk, a Read Only Memory (ROM), a Random Access Memory (RAM), a magnetic disk, or an optical disc. <b>32</b>Step numbers in the foregoing method embodiments are set only for ease of description, and constitute no limitation to a sequence of the steps. The sequence of performing the steps in the embodiments may be adaptively adjusted based on understanding of a person skilled in the art. <b>32</b>The embodiments of this application are described above in detail, but this application is not limited to the above embodiments. A person skilled in the art may further make various equivalent variations or replacements without departing from the spirit of this application, and the equivalent variations or replacements are all included within the scope defined by the claims of this application.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A video source switching method, comprising:<claim-text>obtaining switching information;</claim-text><claim-text>determining a first key frame of a first video source according to the switching information, the first key frame being a next key frame of a current playing time of the first video source;</claim-text><claim-text>querying a first time value of the first key frame;</claim-text><claim-text>identifying a second video source according to the switching information; and</claim-text><claim-text>switching video sources if a distance between a current time value of the second video source and the first time value is less than or equal to a threshold.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein after the identifying a second video source according to the switching information, the method further comprises:<claim-text>determining a second key frame of the second video source, a time value of the second key frame being less than the first time value and being closest to the first time value, wherein</claim-text><claim-text>the switching video sources is performed from the second key frame if a distance between a current time value of the second video source and the first time value is less than or equal to a threshold.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein after the determining a first key frame of a first video source according to the switching information, the method further comprises:<claim-text>reading data of the first video source up to the first key frame by using a first demuxer, the data of the first video source being stored in a buffer queue.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein after the determining a second key frame of the second video source, the method further comprises:<claim-text>reading, from the second key frame data of the second video source by using a second demuxer, to obtain one or more data packets, storing the one or more data packets in the buffer queue, and adding a second video source identifier to the first one of the one or more data packets.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising:<claim-text>turning off the first demuxer after the data of the second video source is successfully read.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising:<claim-text>if the second video source identifier is detected during decoding of the data in the buffer queue by a decoder, refreshing the buffer queue or restarting the decoder.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the switching video sources if a distance between a current time value of the second video source and the first time value is less than or equal to a threshold comprises:<claim-text>decoding the second video source from the second key frame, to obtain decoded data;</claim-text><claim-text>discarding the decoded data if the distance is greater than the threshold; and</claim-text><claim-text>synchronizing and rendering the decoded data if the distance is less than or equal to the threshold, to switching the video sources.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the obtaining switching information comprises:<claim-text>obtaining the switching information by detecting status information of a dynamic update address interface.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first video source and the second video source are video sources at different frame rates.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein obtaining switching information further comprises:<claim-text>obtaining a video switching event, the video switching event comprising any one of a switching request event, a playing error event, or a frame freezing event from a user terminal; and</claim-text><claim-text>switching the video sources comprises: switching video sources according to the video switching event,</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>displaying an image definition information list;</claim-text><claim-text>playing a video source with corresponding definition in the image definition information list in response to a video playing instruction; and</claim-text><claim-text>displaying video image definition information or a video source switching prompt after switching the video sources triggered by a video switching event.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the video switching event comprises any one of a switching request event, a playing error event, or a frame freezing event from a user terminal.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A video source switching apparatus, comprising:<claim-text>a memory and a processor, the memory storing a computer program, and the computer program, when executed by the processor, causing the processor to perform: obtaining switching information;</claim-text><claim-text>determining a first key frame of a first video source according to the switching information, the first key frame being a next key frame of a current playing time of the first video source;</claim-text><claim-text>querying a first time value of the first key frame;</claim-text><claim-text>identifying a second video source according to the switching information; and</claim-text><claim-text>switching video sources if a distance between a current time value of the second video source and the first time value is less than or equal to a threshold.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A non-transitory computer-readable storage medium, storing a computer program, the computer program, when executed by a processor, causing the processor to perform:<claim-text>obtaining switching information;</claim-text><claim-text>determining a first key frame of a first video source according to the switching information, the first key frame being a next key frame of a current playing time of the first video source;</claim-text><claim-text>querying a first time value of the first key frame;</claim-text><claim-text>identifying a second video source according to the switching information; and</claim-text><claim-text>switching video sources if a distance between a current time value of the second video source and the first time value is less than or equal to a threshold.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The storage medium according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein after the identifying a second video source according to the switching information, the computer program further causes the processor to perform:<claim-text>determining a second key frame of the second video source, a time value of the second key frame being less than the first time value and being closest to the first time value, wherein</claim-text><claim-text>the switching video sources is performed from the second key frame if a distance between a current time value of the second video source and the first time value is less than or equal to a threshold.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The storage medium according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein after the determining a first key frame of a first video source according to the switching information, the computer program further causes the processor to perform:<claim-text>reading data of the first video source up to the first key frame by using a first demuxer, the data of the first video source being stored in a buffer queue.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The storage medium according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein after the determining a second key frame of the second video source, the computer program further causes the processor to perform:<claim-text>reading, from the second key frame data of the second video source by using a second demuxer, to obtain one or more data packets, storing the one or more data packets in the buffer queue, and adding a second video source identifier to the first one of the one or more data packets.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The storage medium according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the computer program further causes the processor to perform:<claim-text>turning off the first demuxer after the data of the second video source is successfully read.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The storage medium according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the computer program further causes the processor to perform:<claim-text>if the second video source identifier is detected during decoding of the data in the buffer queue by a decoder, refreshing the buffer queue or restarting the decoder.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The storage medium according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the switching video sources if a distance between a current time value of the second video source and the first time value is less than or equal to a threshold comprises:<claim-text>decoding the second video source from the second key frame, to obtain decoded data;</claim-text><claim-text>discarding the decoded data if the distance is greater than the threshold; and</claim-text><claim-text>synchronizing and rendering the decoded data if the distance is less than or equal to the threshold, to switching the video sources.</claim-text></claim-text></claim></claims></us-patent-application>
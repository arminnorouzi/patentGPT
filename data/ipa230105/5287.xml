<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005288A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005288</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17944863</doc-number><date>20220914</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20220101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>12</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20220101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20220101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>13</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20220101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>147</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20130101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>32</subgroup><symbol-position>L</symbol-position><classification-value>N</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>N</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20220101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>50</subgroup><symbol-position>L</symbol-position><classification-value>N</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>12</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>67</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>1335</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>13</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>1306</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>1365</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>147</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>32</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0227</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>53</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">Enrollment Using Synthetic Fingerprint Image and Fingerprint Sensing Systems</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17141088</doc-number><date>20210104</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11475691</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17944863</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16287943</doc-number><date>20190227</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10885293</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17141088</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15607354</doc-number><date>20170526</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10255474</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16287943</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>14566495</doc-number><date>20141210</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>9665785</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>15607354</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>14243858</doc-number><date>20140402</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>8913802</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>14566495</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>13802695</doc-number><date>20130313</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>8913801</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>14243858</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>61666595</doc-number><date>20120629</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Apple Inc.</orgname><address><city>Cupertino</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Han</last-name><first-name>Byron B.</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Marciniak</last-name><first-name>Craig A.</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A fingerprint sensing system. The fingerprint sensing system includes: at least one sensor; at least one display device; at least one application processor; and at least one secure enclave processor. The application processor(s) receives fingerprint data from the sensor(s) and provides the fingerprint data to the secure enclave processor(s). The secure enclave processor(s) decodes the fingerprint data and provides a signal indicative of at least one matched node. The application processor(s), responsive to receipt of the signal indicative of the matched node(s), presents at least a portion of a synthetic fingerprint image via at least one display device corresponding to the matched node(s).</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="115.40mm" wi="124.88mm" file="US20230005288A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="108.29mm" wi="143.34mm" file="US20230005288A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="138.01mm" wi="139.45mm" file="US20230005288A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="138.01mm" wi="139.45mm" file="US20230005288A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="138.01mm" wi="139.45mm" file="US20230005288A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="214.46mm" wi="126.49mm" file="US20230005288A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="57.23mm" wi="112.27mm" file="US20230005288A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="229.45mm" wi="143.76mm" file="US20230005288A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="129.79mm" wi="126.92mm" file="US20230005288A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application is a continuation of U.S. patent application Ser. No. 17/141,088, filed Jan. 4, 2021, which is a continuation of U.S. patent application Ser. No. 16/287,943, filed Feb. 27, 2019, now U.S. Pat. No. 10,885,293, which is a continuation of U.S. patent application Ser. No. 15/607,354, filed May 26, 2017, now U.S. Pat. No. 10,255,474, which is a continuation of U.S. patent application Ser. No. 14/566,495, filed Dec. 10, 2014, now U.S. Pat. No. 9,665,785, which is a continuation of U.S. patent application Ser. No. 14/243,858, filed Apr. 2, 2014, now U.S. Pat. No. 8,913,802, which is a continuation of U.S. patent application Ser. No. 13/802,695, filed Mar. 13, 2013, now U.S. Pat. No. 8,913,801, which claims the benefit under 35 U.S.C. &#xa7; 119(e) to U.S. Provisional Patent Application No. 61/666,595, which was filed on Jun. 29, 2012, all of which are incorporated by reference as if fully disclosed herein.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">Embodiments described herein relate generally to fingerprint sensing systems and examples of enrollment using synthetic fingerprint images are described.</p><heading id="h-0003" level="1">BACKGROUND DESCRIPTION</heading><p id="p-0004" num="0003">Fingerprint sensing technology has become widespread in use and is often used to provide secure access to sensitive electronic devices and/or data. Generally, capacitive fingerprint sensors may be used to determine an image of a fingerprint through measuring capacitance through multiple capacitive sensing elements. The higher the capacitance, the nearer the surface of an adjacent or overlying finger to the capacitive sensing element. Thus, fingerprint ridges provide a higher capacitance to an underlying capacitive sensing element than do fingerprint valleys.</p><p id="p-0005" num="0004">Data generated by a fingerprint sensor may be encrypted for security purposes and processed using a secure processor. A fingerprint match to a known fingerprint image may also be determined by the secure processor. In this manner, fingerprint data may be kept secure and may not be exposed unencrypted or unsecured to non-secure processors.</p><p id="p-0006" num="0005">Fingerprint images may generally be considered to be made up of several &#x2018;nodes&#x2019;, with each node representing a region of the fingerprint image. Nodes may generally be overlapping, such that the nodes may be stitched together to form an entire fingerprint image.</p><p id="p-0007" num="0006">Fingerprint sensors may be smaller than the fingerprint, and a user may be required to roll, swipe, or otherwise move their finger to expose different regions of the finger to the fingerprint sensor in order for the system to obtain a complete fingerprint image.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0008" num="0007">One sample embodiment, as described herein, is a fingerprint sensing system. The fingerprint sensing system includes: at least one sensor; at least one display device; at least one application processor; and at least one secure enclave processor. The application processor(s) receives fingerprint data from the sensor(s) and provides the fingerprint data to the secure enclave processor(s). The secure enclave processor(s) decodes the fingerprint data and provides a signal indicative of at least one matched node. The application processor(s), responsive to receipt of the signal indicative of the matched node(s), presents at least a portion of a synthetic fingerprint image via at least one display device corresponding to the matched node(s).</p><p id="p-0009" num="0008">Another example embodiment, as described herein, is a method of fingerprint sensing, the method includes receiving fingerprint data from at least one sensor utilizing at least one application processor. The fingerprint data is provided to at least one secure enclave processor utilizing the application processor(s). The secure enclave processor(s) decodes the fingerprint data and provides a signal indicative of at least one matched node. Responsive to receipt of the signal indicative of the matched node(s), at least a portion of a synthetic fingerprint image is presented via at least one display device, the portion of the synthetic fingerprint image corresponding to the matched node(s) utilizing the application processor(s).</p><p id="p-0010" num="0009">A further example embodiment, as described herein, is a fingerprint sensing system. The fingerprint sensing system includes: a sensor; a display device; an application processor; and a secure enclave processor. The application processor is configured to provide at least a portion of a synthetic fingerprint image for display on the display device. The application processor is also configured to receive fingerprint data from the sensor and provide the fingerprint data to the secure enclave processor. The secure enclave processor is configured to decode the fingerprint data and provide a signal indicative of a matched node. The application processor, responsive to receipt of the signal indicative of the matched node, is configured to change a portion of the synthetic fingerprint image corresponding to the matched node.</p><p id="p-0011" num="0010">While multiple embodiments are disclosed, including variations thereof, still other embodiments of the present disclosure will become apparent to those skilled in the art from the following detailed description, which shows and describes illustrative embodiments of the disclosure. As will be realized, the disclosure is capable of modifications in various obvious aspects, all without departing from the spirit and scope of the present disclosure. Accordingly, the drawings and detailed description are to be regarded as illustrative in nature and not restrictive.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE FIGURES</heading><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic illustration of a fingerprint sensing system in accordance with an embodiment of the present invention.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic illustration of a synthetic fingerprint image displayed on a display device in accordance with an embodiment of the present invention.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic illustration of a synthetic fingerprint image displayed on a display device during an initial portion of an enrollment process in accordance with an embodiment of the present invention.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is a schematic illustration of a synthetic fingerprint image displayed on a display device during an enrollment process in accordance with an embodiment of the present invention.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> is a flow chart illustrating a method for using the fingerprint sensing system to display feedback to a user.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic illustration of a system in accordance with an embodiment of the present invention.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram of one embodiment of a system arranged in accordance with an embodiment of the present invention.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart illustrating an example method of fingerprint sensing, as described herein.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0020" num="0019">The use of fingerprint sensing technology to provide secure access to sensitive electronic devices and/or data is gaining in popularity. Embodiments described herein may be configured to operate with a variety of sensors, including strip or swipe sensors, array or other two-dimensional sensors, and the like. Capacitive fingerprint sensors are one technology that may be used to determine the image of a fingerprint.</p><p id="p-0021" num="0020">Because fingerprint sensors may be smaller than the fingerprint, a user may be required to roll, swipe, or otherwise move their finger to expose different regions of the finger to the fingerprint sensor for the system to obtain a complete fingerprint image. However, it may be difficult for the user to be certain a sufficient amount of their finger has been exposed to the fingerprint sensor. Further, the user may not be aware that certain portions of their finger were not exposed to the sensor (e.g. missed the sensor or were never intended to be placed on the sensor). Accordingly, it may be useful for the fingerprint sensor system to provide a feedback mechanism to inform a user which portions of their finger have passed over the sensor (or, in some examples, which portions of their finger have been matched to stored data).</p><p id="p-0022" num="0021">Thus, example embodiments described herein, may display an image of a fingerprint on a display device during an enrollment process or testing process to provide feedback to a user regarding portions of the finger which need to be presented to the sensor. However, it may be undesirable to display an image of an actual user's fingerprint on the display for security reasons. Accordingly, it may be useful to display a synthetic fingerprint rather than the user's actual fingerprint for these operations.</p><p id="p-0023" num="0022">The following terminology is exemplary, and not intended to be limiting in any way.</p><p id="p-0024" num="0023">The text &#x201c;capacitive sensing element&#x201d;, and variants thereof, generally refers to one or more sensors that may sense data elements of any kind, including information sensed with respect to individual locations. For example and without limitation, a capacitive sensing element may sense data or other information with respect to a relatively small region of a fingerprint image.</p><p id="p-0025" num="0024">After reading this application, those skilled in the art would recognize that these statements of terminology would be applicable to techniques, methods, physical elements, and systems (whether currently known or otherwise), including extensions thereof inferred or inferable by those skilled in the art after reading this application.</p><p id="p-0026" num="0025">Generally, examples described herein include fingerprint sensing systems that may facilitate enrollment using a synthetic fingerprint image. Enrollment includes a process by which a user may roll, swipe, or otherwise move their finger across a fingerprint sensor so the fingerprint sensing system may obtain fingerprint data corresponding to the user's finger. The fingerprint sensing system during enrollment may match the fingerprint data corresponding to the user's finger to known, stored, fingerprint data to identify (e.g. authenticate) the user.</p><p id="p-0027" num="0026">It may be difficult for the user to be certain a sufficient amount of their finger has been exposed to the fingerprint sensor. For example, the user may not be aware that certain portions of their finger were not exposed to the sensor (e.g. missed the sensor or were never intended to be placed on the sensor). Accordingly, examples of the present invention may provide a feedback mechanism to inform a user which portions of their finger have passed over the sensor (or, in some examples, which portions of their finger have been matched to stored data).</p><p id="p-0028" num="0027">In some examples, an image of a fingerprint is displayed on a display screen viewable by the user to inform the user which portions of their finger no longer need to be passed over the sensor to complete enrollment. As will be described further below, portions of the displayed fingerprint may be filled in, or otherwise changed, reflecting the portions which are no longer needed. However, it may not be desirable to display an image of the actual fingerprint data being collected by the fingerprint sensor, because doing so may compromise the security of the fingerprint data (e.g. if malicious screen capture software is running on the device that may capture the displayed fingerprint data). Accordingly, examples described below may provide for a synthetic fingerprint image to be displayed and to provide feedback to the user by altering portions of the synthetic fingerprint image during an enrollment process. The synthetic fingerprint image may be a static predetermined image or in some examples the synthetic fingerprint image may be generated using the actual received fingerprint information from the fingerprint sensor, or may be generated using other factors&#x2014;e.g. time of day.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic illustration of a fingerprint sensing system <b>100</b> according to an embodiment of the present invention. The fingerprint sensing system <b>100</b> includes a sensor <b>105</b>, a processing platform <b>110</b> and a display device <b>112</b>. Other components, including user interface elements, may be included in the fingerprint sensing system <b>100</b> in other embodiments.</p><p id="p-0030" num="0029">The sensor <b>105</b> may include any type of fingerprint sensor, such as a capacitive sensor or capacitive sensing element that may generate signals corresponding to ridges and valleys of a fingerprint. The sensor <b>105</b> may include an active area <b>115</b> that is responsive to ridges and valleys placed on the active area <b>115</b>. The sensor <b>105</b> may be below or adjacent a user interface element, such as a button <b>117</b>. The active area <b>115</b> of the sensor <b>105</b> may be smaller than an entire fingerprint in some embodiments. Accordingly, as has been described above, a user may be required to move a finger around in order to expose the entire fingerprint to the active area <b>115</b>.</p><p id="p-0031" num="0030">The processing platform <b>110</b> may include any number of processing unit(s), each of which may be implemented by a processor, and computer readable storage media sufficient to store executable instructions that, when executed by the processing unit(s), may cause the processing unit(s) to perform the functions described herein. The actual hardware and software configuration of the processing platform <b>110</b> may vary in different embodiments. The processing platform <b>110</b> includes an application processor (AP) <b>120</b> and a secure enclave processor (SEP) <b>122</b>. The application processor <b>120</b> may be implemented using one or more suitable processors, and the secure enclave processor <b>122</b> may also be implemented using one or more processors, which processors are different than those used to implement the application processor <b>120</b>. In some examples, the application processor <b>120</b> may be implemented using a device's central processing unit (CPU), while the secure enclave processor <b>122</b> may be a separate processor.</p><p id="p-0032" num="0031">The secure enclave processor <b>122</b> is generally used to manipulate secure data (e.g. to decrypt encrypted fingerprint data from the sensor <b>105</b> and match the decrypted data with stored fingerprint template data in a template library <b>124</b>). The template library <b>124</b> may be stored on any computer readable storage medium (e.g. memory) in communication with the secure enclave processor <b>122</b>, and one or more distinct computer readable storage media may be used to implement the template library <b>124</b>. The secure enclave processor <b>122</b> may have access to a key or other security parameter usable to decrypt data received from the sensor <b>105</b>. For example, the secure enclave processor <b>122</b> and the sensor <b>105</b> may share a factory provisioned key, enabling the secure enclave processor <b>122</b> to decrypt data received from the sensor <b>105</b>. The application processor <b>120</b> may not have access to the key or other security parameter, and may be unable to decrypt data received from the sensor <b>105</b>. In this manner, the application processor <b>120</b> may be prevented from ever accessing decrypted data from the fingerprint sensor <b>105</b>, which may improve the security of the fingerprint data, for example, making the decrypted fingerprint data inaccessible or less accessible to other programs which may be running on the application processor <b>120</b>.</p><p id="p-0033" num="0032">Embodiments of the present invention may display an image of a fingerprint on a display device, such as the display device <b>112</b> during an enrollment process to provide feedback to a user regarding portions of the finger which need to be presented to the sensor <b>105</b>. However, it may be undesirable to display an image of an actual user's fingerprint on the display for security reasons. Accordingly, the application processor <b>120</b> may include a synthetic fingerprint generator <b>130</b>. The synthetic fingerprint generator <b>130</b> may be implemented, for example by a computer readable storage medium or a plurality of such computer readable storage media (e.g. one or more memories) storing executable instructions for generating a synthetic fingerprint. The application processor <b>120</b> may execute the instructions for generating a synthetic fingerprint and cause the synthetic fingerprint to be displayed on the display device <b>112</b>.</p><p id="p-0034" num="0033">The synthetic fingerprint generator <b>130</b> may generate the synthetic fingerprint image in a variety of ways. The synthetic fingerprint is generally an image resembling a fingerprint but which is not a replica of the user's actual fingerprint. In some examples, a synthetic fingerprint image may be selected from a library of stored synthetic fingerprint images, which may be stored on a computer readable storage medium (e.g. memory) accessible to the application processor <b>120</b>. In some examples, the synthetic fingerprint generator <b>130</b> may generate or select a synthetic fingerprint image whose features are determined based on some aspect of the enrollment process, including, but not limited to, time of day, type of device, device ID, node of fingerprint first captured, or combinations thereof.</p><p id="p-0035" num="0034">During operation, a user may place all or a portion of their finger over the sensor <b>105</b>. The sensor <b>105</b> may provide encrypted fingerprint data to the processing platform <b>110</b>. The encrypted fingerprint data may be received by the application processor <b>120</b>, however, the application processor <b>120</b> may not be able to decrypt the fingerprint data. The application processor <b>120</b> may provide the encrypted fingerprint data to the secure enclave processor <b>122</b>. Moreover, the application processor <b>120</b> may, responsive to the initiation of an enrollment process, provide a synthetic fingerprint image on the display device <b>112</b>. As described above, the synthetic fingerprint image may be provided from a stored image or may be generated responsive to an aspect of the enrollment process.</p><p id="p-0036" num="0035">The secure enclave processor <b>122</b> may accordingly receive the encrypted fingerprint data, decrypt the fingerprint data, and search for a match in the template library <b>124</b>. Generally, fingerprint data of nodes of a finger may be matched to stored fingerprint data in the template library <b>124</b>. For example, the sensor <b>105</b> may not provide data at once representing an entire fingerprint image, but may provide fingerprint data representing a node (e.g. a portion of a fingerprint). The secure enclave processor <b>122</b> may match the node with data stored in the template library <b>124</b> to find a match. The secure enclave processor <b>122</b> may provide a signal indicative of a match, or lack thereof, to the application processor <b>120</b>. The secure enclave processor <b>122</b> may further provide an indication to the application processor <b>120</b> of which node of the fingerprint was matched.</p><p id="p-0037" num="0036">The application processor may display all or a portion of the synthetic fingerprint image on the display device <b>112</b>. As nodes of the fingerprint are received and matched by the secure enclave processor, the application processor may cause corresponding portions of the synthetic fingerprint image displayed on the display device <b>112</b> to change, thereby providing feedback to the user of which portions of the fingerprint had been successfully received, and in some examples matched, by the secure enclave processor <b>122</b>. The application processor <b>120</b> may provide this feedback by executing stored executable instructions for enrollment feedback, which may be stored in a computer readable storage medium (e.g. memory) accessible to the application processor <b>120</b>.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic illustration of a synthetic fingerprint image displayed on a display device in accordance with an embodiment of the present invention. The display device <b>200</b> may be implemented using the display device <b>112</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The synthetic fingerprint image <b>205</b> may be a schematic representation of a fingerprint which may be displayed during enrollment, but which may not be an accurate representation of the fingerprint being enrolled, as has been described above. The different nodes of a fingerprint are shown schematically with dotted lines in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The grid <b>210</b> depicts regions of 16 nodes that may represent a fingerprint, for example, the node <b>215</b> is near a center of the fingerprint. The nodes are shown adjacent one another in <figref idref="DRAWINGS">FIG. <b>2</b></figref> for ease of illustration, but in some embodiments of the present invention the nodes may overlap, allowing the nodes to be stitched together to form a completed fingerprint image. The grid <b>210</b> or other delineation of nodes may or may not itself be displayed on the display device <b>200</b>.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic illustration of a synthetic fingerprint image displayed on a display device during an initial portion of an enrollment process in accordance with an embodiment of the present invention. In embodiments of the present invention, an indicator may be displayed on the display device <b>200</b> illustrating which node of a finger the user should attempt to present first, or next, to a sensor. The display device <b>200</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref> may be implemented, for example, by the display device <b>112</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The application processor as described in <figref idref="DRAWINGS">FIG. <b>1</b></figref> may display the indication in accordance with computer executable instructions for the same stored in a medium accessible to the application processor. The indicator <b>305</b> may be a box, as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, and may be shaded, colored, outlined, or otherwise different than the surrounding image. In some examples, the indicator <b>305</b> may not have a contour, but portions of the synthetic fingerprint image <b>205</b> corresponding to the node to be indicated may instead be displayed in a different color, dashing, thickness, or otherwise different than the remaining synthetic fingerprint image <b>205</b>.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is a schematic illustration of a synthetic fingerprint image displayed on a display device during an enrollment process in accordance with an embodiment of the present invention. In embodiments of the present invention, portions of a synthetic fingerprint image displayed on the display device <b>200</b> may change during the enrollment process to indicate to a user that those portions have been captured (e.g. matched) by the device. The display device <b>200</b> of <figref idref="DRAWINGS">FIG. <b>4</b>A</figref> may be implemented, for example, by the display device <b>112</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The application processor as described in <figref idref="DRAWINGS">FIG. <b>1</b></figref> may change portions of the synthetic fingerprint image in accordance with computer executable instructions for the same stored in a medium accessible to the application processor. Portions of the synthetic fingerprint image may change, for example, by changing a dash pattern, color, shading, thickness, etc. of the lines making up the synthetic fingerprint image and/or regions of the synthetic fingerprint image, including the background. In the example of <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>, the synthetic fingerprint image <b>205</b> is shown in dashed lines. As a user enrolls a finger, portions (e.g. nodes) of the finger which are successfully captured may be displayed in solid lines, e.g. the node <b>405</b> shown in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref> has been successfully captured and is shown in solid lines. By changing portions of the synthetic fingerprint image during enrollment, a user may receive feedback as to which portions of the finger still need to be presented to a sensor, such as the sensor <b>105</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0041" num="0040">During operation, referring back to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the application processor <b>120</b> may cause the display device <b>112</b> to display a synthetic fingerprint image. The application processor <b>120</b> may further cause the display device <b>112</b> to display an indication of an initial node for fingerprint enrollment, in accordance with stored executable instructions. During enrollment, fingerprint data may be received by the application processor <b>120</b> from the sensor <b>105</b> and passed to the secure enclave processor <b>122</b>. The secure enclave processor <b>122</b> may decode the fingerprint data and match the fingerprint data with data stored in the template library <b>124</b>. The secure enclave processor <b>122</b> may provide a signal to the application processor <b>120</b> indicative of a matched node of the fingerprint. The application processor may accordingly cause the synthetic fingerprint image displayed on the display device <b>112</b> to change to indicate matching of the particular node has occurred.</p><p id="p-0042" num="0041">An illustrative method for using the fingerprint sensing system will now be discussed in further detail. <figref idref="DRAWINGS">FIG. <b>4</b>B</figref> is a flow chart illustrating a method for sensing fingerprint data and providing feedback to a user. The method <b>400</b> may begin with operation <b>402</b> and the sensor <b>105</b> may capture data corresponding to one or more fingerprints of a user. In other words, the sensor <b>105</b> may capture data corresponding to one or more features (examples of which include valleys and ridges) on a user's finger.</p><p id="p-0043" num="0042">Once the initial fingerprint data has been captured, the method <b>400</b> may proceed to operation <b>404</b>. In operation <b>404</b>, the display device <b>112</b> may display feedback to the user. The feedback may include the synthetic fingerprint image, text, or the like. The feedback may correspond to the data received in operation <b>402</b>. For example, the feedback may indicate to a user the portions of finger that were captured by the sensor <b>105</b>, may provide a percentage of the finger surface sensed by the sensor <b>105</b>, or the like.</p><p id="p-0044" num="0043">After operation <b>404</b>, the method <b>400</b> may proceed to operation <b>406</b>. In operation <b>406</b>, the processor <b>122</b> may determine whether additional data is required. For example, the processor may determine whether a sufficient number of nodes were captured by the sensor <b>105</b> in order to evaluate the fingerprint data to determine if there is a match. The number of nodes may depend on the size of the finger, the accuracy or sensitivity of the initial captured data, desired match accuracy, and so on.</p><p id="p-0045" num="0044">In operation <b>406</b>, if additional data is required, the method <b>400</b> may proceed to operation <b>408</b>. In operation <b>408</b>, the sensor <b>105</b> may be configured to capture additional fingerprint data. As one example, the display device <b>112</b> may provide output to a user requesting that he or she provide additional input to the sensor <b>105</b>. In another example, the sensor <b>105</b> may automatically scan the sensing surface or area to sense the fingerprint (assuming the user's finger may not have been removed).</p><p id="p-0046" num="0045">Once the additional data has been sensed, the method <b>400</b> may proceed to operation <b>410</b>. In operation <b>410</b>, the display device <b>112</b> may display feedback corresponding to the additional data. Operation <b>410</b> may be substantially similar to operation <b>404</b>, but may vary the synthetic fingerprint or other output data based on the additional data collected. For example, one or more nodes of the synthetic fingerprint may be colored, thickened, highlighted, or the like to indicate to the user that those additional nodes were captured by the sensor <b>105</b>. After operation <b>410</b>, the method <b>400</b> may proceed to operation <b>412</b>.</p><p id="p-0047" num="0046">If in operation <b>406</b> no additional data is required, the method <b>400</b> may proceed to operation <b>412</b>. In operation <b>412</b>, the processor <b>122</b> may determine whether the sensed fingerprint data matches a stored data corresponding to a fingerprint. For example, the sensed data may be compared with a plurality of fingerprint templates. If in operation <b>412</b>, the processor determines that the sensed fingerprint is a match, the method <b>400</b> may proceed to operation <b>414</b>. In operation <b>414</b>, the display device <b>112</b> may provide feedback to the user indicating the match of the fingerprint. For example, the synthetic fingerprint may be colored or filled in, highlighted, or the like.</p><p id="p-0048" num="0047">If in operation <b>412</b>, the sensed fingerprint data does not correspond to a stored fingerprint, the method <b>400</b> may proceed to operation <b>416</b>. In operation <b>416</b> the processor may determine whether additional data is required. For example, the processor may have determined that the fingerprint was not a match due to insufficient or inaccurate data. In this case, the method <b>400</b> may return to operation <b>408</b> and the sensor may capture additional fingerprint data. However, if in operation <b>416</b>, the processor determines additional data is not required, the method <b>400</b> may proceed to operation <b>418</b>. For example, the processor may have sufficient data to analyze the fingerprint data and may determine that the data does not match any stored fingerprints. In these instances, during operation <b>418</b>, the display device <b>112</b> may provide feedback corresponding to the mismatch or un-matched state of the fingerprint data. After either operation <b>414</b> or <b>418</b>, the method <b>400</b> may proceed to an end state <b>420</b>.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic illustration of a system in accordance with an embodiment of the present invention. Described embodiments may include touch I/O device <b>1001</b> that can receive touch input for interacting with computing system <b>1003</b> via wired or wireless communication channel <b>1002</b>. The touch I/O device <b>1001</b> may include, for example the sensor <b>105</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> and the display device <b>112</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> in some embodiments. In some embodiments, the touch I/O device <b>1001</b> may include the sensor <b>105</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, but the display device <b>112</b> may be separate. The computing system <b>1003</b> may include, for example the platform <b>110</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> in some embodiments. Referring again to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, touch I/O device <b>1001</b> may be used to provide user input to computing system <b>1003</b> in lieu of or in combination with other input devices such as a keyboard, mouse, etc. One or more touch I/O devices <b>1001</b> may be used for providing user input to computing system <b>1003</b>. Touch I/O device <b>1001</b> may be an integral part of computing system <b>1003</b> (e.g., touch screen on a laptop) or may be separate from computing system <b>1003</b>.</p><p id="p-0050" num="0049">Touch I/O device <b>1001</b> may include a touch sensitive panel which is wholly or partially transparent, semitransparent, non-transparent, opaque or any combination thereof. Touch I/O device <b>1001</b> may be embodied as a touch screen, touch pad, a touch screen functioning as a touch pad (e.g., a touch screen replacing the touchpad of a laptop), a touch screen or touchpad combined or incorporated with any other input device (e.g., a touch screen or touchpad disposed on a keyboard) or any multi-dimensional object having a touch sensitive surface for receiving touch input.</p><p id="p-0051" num="0050">In one example, touch I/O device <b>1001</b> embodied as a touch screen may include a transparent and/or semitransparent touch sensitive panel partially or wholly positioned over at least a portion of a display. According to this embodiment, touch I/O device <b>1001</b> functions to display graphical data transmitted from computing system <b>1003</b> (and/or another source) and also functions to receive user input. In other embodiments, touch I/O device <b>1001</b> may be embodied as an integrated touch screen where touch sensitive components/devices are integral with display components/devices. In still other embodiments a touch screen may be used as a supplemental or additional display screen for displaying supplemental or the same graphical data as a primary display and to receive touch input.</p><p id="p-0052" num="0051">Touch I/O device <b>1001</b> may be configured to detect the location of one or more touches or near touches on device <b>1001</b> based on capacitive, resistive, optical, acoustic, inductive, mechanical, chemical measurements, or any phenomena that can be measured with respect to the occurrences of the one or more touches or near touches in proximity to deice <b>1001</b>. Software, hardware, firmware or any combination thereof may be used to process the measurements of the detected touches to identify and track one or more gestures. A gesture may correspond to stationary or non-stationary, single or multiple, touches or near touches on touch I/O device <b>1001</b>. A gesture may be performed by moving one or more fingers or other objects in a particular manner on touch I/O device <b>1001</b> such as tapping, pressing, rocking, scrubbing, twisting, changing orientation, pressing with varying pressure and the like at essentially the same time, contiguously, or consecutively. A gesture may be characterized by, but is not limited to a pinching, sliding, swiping, rotating, flexing, dragging, or tapping motion between or with any other finger or fingers. A single gesture may be performed with one or more hands, by one or more users, or any combination thereof.</p><p id="p-0053" num="0052">Computing system <b>1003</b> may drive a display with graphical data to display a graphical user interface (GUI). The GUI may be configured to receive touch input via touch I/O device <b>1001</b>. Embodied as a touch screen, touch I/O device <b>1001</b> may display the GUI. Alternatively, the GUI may be displayed on a display separate from touch I/O device <b>1001</b>. The GUI may include graphical elements displayed at particular locations within the interface. Graphical elements may include but are not limited to a variety of displayed virtual input devices including virtual scroll wheels, a virtual keyboard, virtual knobs, virtual buttons, any virtual UI, and the like. A user may perform gestures at one or more particular locations on touch I/O device <b>1001</b> which may be associated with the graphical elements of the GUI. In other embodiments, the user may perform gestures at one or more locations that are independent of the locations of graphical elements of the GUI. Gestures performed on touch I/O device <b>1001</b> may directly or indirectly manipulate, control, modify, move, actuate, initiate or generally affect graphical elements such as cursors, icons, media files, lists, text, all or portions of images, or the like within the GUI. For instance, in the case of a touch screen, a user may directly interact with a graphical element by performing a gesture over the graphical element on the touch screen. Alternatively, a touch pad generally provides indirect interaction. Gestures may also affect non-displayed GUI elements (e.g., causing user interfaces to appear) or may affect other actions within computing system <b>1003</b> (e.g., affect a state or mode of a GUI, application, or operating system). Gestures may or may not be performed on touch I/O device <b>1001</b> in conjunction with a displayed cursor. For instance, in the case in which gestures are performed on a touchpad, a cursor (or pointer) may be displayed on a display screen or touch screen and the cursor may be controlled via touch input on the touchpad to interact with graphical objects on the display screen. In other embodiments in which gestures are performed directly on a touch screen, a user may interact directly with objects on the touch screen, with or without a cursor or pointer being displayed on the touch screen.</p><p id="p-0054" num="0053">Feedback may be provided to the user via communication channel <b>1002</b> in response to or based on the touch or near touches on touch I/O device <b>1001</b>. Feedback may be transmitted optically, mechanically, electrically, olfactory, acoustically, or the like or any combination thereof and in a variable or non-variable manner.</p><p id="p-0055" num="0054">Attention is now directed towards embodiments of a system architecture that may be embodied within any portable or non-portable device including but not limited to a communication device (e.g. mobile phone, smart phone), a multi-media device (e.g., MP<b>3</b> player, TV, radio), a portable or handheld computer (e.g., tablet, netbook, laptop), a desktop computer, an All-In-One desktop, a peripheral device, or any other system or device adaptable to the inclusion of system architecture <b>2000</b>, including combinations of two or more of these types of devices. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram of one embodiment of a system arranged in accordance with an embodiment of the present invention. The system <b>2000</b> generally includes one or more computer-readable media <b>2001</b>, processing system <b>2004</b>, Input/Output (I/O) subsystem <b>2006</b>, radio frequency (RF) circuitry <b>2008</b> and audio circuitry <b>2010</b>. These components may be coupled by one or more communication buses or signal lines <b>2003</b>. Each such bus or signal line may be denoted in the form <b>2003</b>-X, where X is a unique number. The bus or signal line may carry data of the appropriate type between components; each bus or signal line may differ from other buses/lines, but may perform generally similar operations. They system of <figref idref="DRAWINGS">FIG. <b>6</b></figref> may represent a more detailed example of the system <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> in some embodiments. For example, the sensor <b>105</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> may be included in the Touch I/O device <b>2012</b> or fingerprint sensor <b>2042</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the platform <b>110</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> may be implemented using the processing system <b>2004</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, and the display device may be included in the Touch I/O device <b>2012</b> and/or other I/O devices <b>2014</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0056" num="0055">It should be apparent that the architecture shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is only one example architecture of system <b>2000</b>, and that system <b>2000</b> could have more or fewer components than shown, or a different configuration of components. The various components shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> can be implemented in hardware, software, firmware or any combination thereof, including one or more signal processing and/or application specific integrated circuits.</p><p id="p-0057" num="0056">RF circuitry <b>2008</b> is used to send and receive information over a wireless link or network to one or more other devices and includes well-known circuitry for performing this function. RF circuitry <b>2008</b> and audio circuitry <b>2010</b> are coupled to processing system <b>2004</b> via peripherals interface <b>2016</b>. Interface <b>2016</b> includes various known components for establishing and maintaining communication between peripherals and processing system <b>2004</b>. Audio circuitry <b>2010</b> is coupled to audio speaker <b>2050</b> and microphone <b>2052</b> and includes known circuitry for processing voice signals received from interface <b>2016</b> to enable a user to communicate in real-time with other users. In some embodiments, audio circuitry <b>2010</b> includes a headphone jack (not shown).</p><p id="p-0058" num="0057">Peripherals interface <b>2016</b> couples the input and output peripherals of the system to processor <b>2018</b> and computer-readable medium <b>2001</b>. One or more processors <b>2018</b> communicate with one or more computer-readable media <b>2001</b> via controller <b>2020</b>. Computer-readable medium <b>2001</b> can be any device or medium that can store code and/or data for use by one or more processors <b>2018</b>. Medium <b>2001</b> can include a memory hierarchy, including but not limited to cache, main memory and secondary memory. The memory hierarchy can be implemented using any combination of RAM (e.g., SRAM, DRAM, DDRAM), ROM, FLASH, magnetic and/or optical storage devices, such as disk drives, magnetic tape, CDs (compact disks) and DVDs (digital video discs). Medium <b>2001</b> may also include a transmission medium for carrying information-bearing signals indicative of computer instructions or data (with or without a carrier wave upon which the signals are modulated). For example, the transmission medium may include a communications network, including but not limited to the Internet (also referred to as the World Wide Web), intranet(s), Local Area Networks (LANs), Wide Local Area Networks (WLANs), Storage Area Networks (SANs), Metropolitan Area Networks (MAN) and the like.</p><p id="p-0059" num="0058">One or more processors <b>2018</b> run various software components stored in medium <b>2001</b> to perform various functions for system <b>2000</b>. In some embodiments, the software components include operating system <b>2022</b>, communication module (or set of instructions) <b>2024</b>, touch processing module (or set of instructions) <b>2026</b>, graphics module (or set of instructions) <b>2028</b>, one or more applications (or set of instructions) <b>2030</b>, which may include instructions for synthetic fingerprint generation, instructions for feedback regarding initial fingerprint node indication, and instructions for feedback regarding enrolled nodes, as has been described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>4</b></figref>, and fingerprint sensing module (or set of instructions) <b>2038</b>. Each of these modules and above noted applications correspond to a set of instructions for performing one or more functions described above and the methods described in this application (e.g., the computer-implemented methods and other information processing methods described herein). These modules (e.g., sets of instructions) need not be implemented as separate software programs, procedures or modules, and thus various subsets of these modules may be combined or otherwise re-arranged in various embodiments. In some embodiments, medium <b>2001</b> may store a subset of the modules and data structures identified above. Furthermore, medium <b>2001</b> may store additional modules and data structures not described above.</p><p id="p-0060" num="0059">Operating system <b>2022</b> includes various procedures, sets of instructions, software components and/or drivers for controlling and managing general system tasks (e.g., memory management, storage device control, power management, etc.) and facilitates communication between various hardware and software components.</p><p id="p-0061" num="0060">Communication module <b>2024</b> facilitates communication with other devices over one or more external ports <b>2036</b> or via RF circuitry <b>2008</b> and includes various software components for handling data received from RF circuitry <b>2008</b> and/or external port <b>2036</b>.</p><p id="p-0062" num="0061">Graphics module <b>2028</b> includes various known software components for rendering, animating and displaying graphical objects on a display surface. In embodiments in which touch I/O device <b>2012</b> is a touch sensitive display (e.g., touch screen), graphics module <b>2028</b> includes components for rendering, displaying, and animating objects on the touch sensitive display.</p><p id="p-0063" num="0062">One or more applications <b>2030</b> can include any applications installed on system <b>2000</b>, including without limitation, a browser, address book, contact list, email, instant messaging, word processing, keyboard emulation, widgets, JAVA-enabled applications, encryption, digital rights management, voice recognition, voice replication, location determination capability (such as that provided by the global positioning system (GPS)), a music player, etc. The applications <b>2030</b> may also include applications for performing functions described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>4</b></figref>, including synthetic fingerprint selection and/or display, feedback for initial enrollment node, and feedback for indicating captured nodes.</p><p id="p-0064" num="0063">Touch processing module <b>2026</b> includes various software components for performing various tasks associated with touch I/O device <b>2012</b> including but not limited to receiving and processing touch input received from I/O device <b>2012</b> via touch I/O device controller <b>2032</b>.</p><p id="p-0065" num="0064">System <b>2000</b> may further include fingerprint sensing module <b>2038</b> for performing the method/functions as described herein in connection with <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>4</b></figref>. Fingerprint sensing module <b>2038</b> may at least function to perform various tasks associated with the fingerprint sensor, such as receiving and processing fingerprint sensor input. The fingerprint sensing module <b>2038</b> may also control certain operational aspects of the fingerprint sensor <b>2042</b>, such as its capture of fingerprint data and/or transmission of the same to the processor <b>2018</b> and/or secure processor <b>2040</b>. Module <b>2038</b> may also interact with the touch I/O device <b>2012</b>, graphics module <b>2028</b> or other graphical display. Module <b>2038</b> may be embodied as hardware, software, firmware, or any combination thereof. Although module <b>2038</b> is shown to reside within medium <b>2001</b>, all or portions of module <b>2038</b> may be embodied within other components within system <b>2000</b> or may be wholly embodied as a separate component within system <b>2000</b>.</p><p id="p-0066" num="0065">I/O subsystem <b>2006</b> is coupled to touch I/O device <b>2012</b> and one or more other I/O devices <b>2014</b> for controlling or performing various functions. Touch I/O device <b>2012</b> communicates with processing system <b>2004</b> via touch I/O device controller <b>2032</b>, which includes various components for processing user touch input (e.g., scanning hardware). One or more other input controllers <b>2034</b> receives/sends electrical signals from/to other I/O devices <b>2014</b>. Other I/O devices <b>2014</b> may include physical buttons, dials, slider switches, sticks, keyboards, touch pads, additional display screens, or any combination thereof.</p><p id="p-0067" num="0066">If embodied as a touch screen, touch I/O device <b>2012</b> displays visual output to the user in a GUI. The visual output may include text, graphics, video, and any combination thereof. Some or all of the visual output may correspond to user-interface objects. Touch I/O device <b>2012</b> forms a touch-sensitive surface that accepts touch input from the user. Touch I/O device <b>2012</b> and touch screen controller <b>2032</b> (along with any associated modules and/or sets of instructions in medium <b>2001</b>) detects and tracks touches or near touches (and any movement or release of the touch) on touch I/O device <b>2012</b> and converts the detected touch input into interaction with graphical objects, such as one or more user-interface objects. In the case in which device <b>2012</b> is embodied as a touch screen, the user can directly interact with graphical objects that are displayed on the touch screen. Alternatively, in the case in which device <b>2012</b> is embodied as a touch device other than a touch screen (e.g., a touch pad); the user may indirectly interact with graphical objects that are displayed on a separate display screen embodied as I/O device <b>2014</b>.</p><p id="p-0068" num="0067">Touch I/O device <b>2012</b> may be analogous to the multi-touch sensitive surface described in the following U.S. Pat. No. 6,323,846 (Westerman et al.), U.S. Pat. No. 6,570,557 (Westerman et al.), and/or U.S. Pat. No. 6,677,932 (Westerman), and/or U.S. Patent Publication 2002/0015024A1, each of which is hereby incorporated by reference in its entirety for any purpose.</p><p id="p-0069" num="0068">Embodiments in which touch I/O device <b>2012</b> is a touch screen, the touch screen may use LCD (liquid crystal display) technology, LPD (light emitting polymer display) technology, OLED (organic LED), or OEL (organic electro luminescence), although other display technologies may be used in other embodiments.</p><p id="p-0070" num="0069">Feedback may be provided by touch I/O device <b>2012</b> based on the user's touch input as well as a state or states of what is being displayed and/or of the computing system. Feedback may be transmitted optically (e.g., light signal or displayed image), mechanically (e.g., haptic feedback, touch feedback, force feedback, or the like), electrically (e.g., electrical stimulation), olfactory, acoustically (e.g., beep or the like), or the like or any combination thereof and in a variable or non-variable manner.</p><p id="p-0071" num="0070">System <b>2000</b> also includes power system <b>2045</b> for powering the various hardware components and may include a power management system, one or more power sources, a recharging system, a power failure detection circuit, a power converter or inverter, a power status indicator and any other components typically associated with the generation, management and distribution of power in portable devices.</p><p id="p-0072" num="0071">In some embodiments, peripherals interface <b>2016</b>, one or more processors <b>2018</b>, and memory controller <b>2020</b> may be implemented on a single chip, such as processing system <b>2004</b>. In some other embodiments, they may be implemented on separate chips.</p><p id="p-0073" num="0072">In addition to the foregoing, the system <b>2000</b> may include a secure processor <b>2040</b> in communication with a fingerprint sensor <b>2042</b>, via a fingerprint I/O controller <b>2044</b>. The operation of these various elements will now be described.</p><p id="p-0074" num="0073">The fingerprint sensor <b>2042</b> may operate to capacitively capture a series of images, or nodes. When taken together, these nodes may form a fingerprint. The full set of nodes may be referred to herein as a &#x201c;mesh.&#x201d;</p><p id="p-0075" num="0074">Each node in the mesh may be separately captured by the fingerprint sensor <b>2042</b>, which may be an array sensor. Generally, there is some overlap between images in nodes representing adjacent portions of a fingerprint. Such overlap may assist in assembling the fingerprint from the nodes, as various image recognition techniques may be employed to use the overlap to properly identify and/or align adjacent nodes in the mesh.</p><p id="p-0076" num="0075">Sensed fingerprint data may be transmitted through the fingerprint I/O controller <b>2044</b> to the processor <b>2018</b> and/or the secure processor <b>2040</b>. In some embodiments, the data is relayed from the fingerprint I/O controller <b>2044</b> to the secure processor <b>2040</b> directly. Generally, the fingerprint data is encrypted by any of the fingerprint sensor <b>2042</b>, the fingerprint I/O controller <b>2044</b> or another element prior to being transmitted to either processor. The secure processor <b>2040</b> may decrypt the data to reconstruct the node.</p><p id="p-0077" num="0076">Fingerprint data, either as nodes or meshes, may be stored in the computer-readable medium <b>2001</b> and accessed as necessary. In some embodiments, only the secure processor <b>2040</b> may access stored fingerprint data, while in other embodiments either the secure processor or the processor <b>2018</b> may access such data.</p><p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example method of fingerprint sensing, as described herein. The method begins with receiving fingerprint data from at least one sensor, step <b>700</b>. Example approaches that may be used for receiving the fingerprint data are described in detail above. These example approaches may include utilizing at least one application processor.</p><p id="p-0079" num="0078">The received fingerprint data is provided to at least one processor, step <b>702</b>. The processor(s), as described in detail above, may include at least one secure enclave processor. The processor(s) decodes the fingerprint data, step <b>704</b>, and provides a signal indicative of at least one matched node, step <b>706</b>. Various example processes whereby the processor(s) performs these operations are described in detail above.</p><p id="p-0080" num="0079">Responsive to receipt of the signal indicative of the matched node(s), at least a portion of a synthetic fingerprint image is presented via at least one display device, step <b>708</b>. The portion of the synthetic fingerprint image presented corresponds to the matched node(s), as may be determined utilizing at least one application processor(s). Examples of the operation of application processors performing this step are described above.</p><p id="p-0081" num="0080">Although embodiments have been described herein with respect to particular configurations and sequences of operations, it should be understood that alternative embodiments may add, omit, or change elements, operations and the like. Accordingly, the embodiments disclosed herein are meant to be examples and not limitations.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>We claim:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method, comprising:<claim-text>at an electronic device with a display and a fingerprint sensor:<claim-text>capturing first fingerprint information using the fingerprint sensor;</claim-text><claim-text>in response to capturing the first fingerprint information, displaying, on the display, a fingerprint representation with a first portion of the fingerprint representation displayed differently from remaining portions of the fingerprint representation, the remaining portions of the fingerprint representation including a second portion of the fingerprint representation;</claim-text><claim-text>after displaying the fingerprint representation with the first portion of the fingerprint representation displayed differently from remaining portions of the fingerprint representation, capturing second fingerprint information using the fingerprint sensor; and</claim-text><claim-text>in response to capturing the second fingerprint information, changing an appearance of the second portion of the fingerprint representation.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second portion of the fingerprint representation is changed to be displayed differently from remaining portions of the fingerprint representation other than the first portion of the fingerprint representation and the second portion of the fingerprint representation.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first portion of the fingerprint representation and the second portion of the fingerprint representation are changed in the same manner.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first portion of the fingerprint representation and the second portion of the fingerprint representation are changed by changing a property of one or more lines in the fingerprint representation.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the fingerprint representation is a graphical element that includes elements that represent fingerprint ridges.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the first portion of the fingerprint representation and the second portion of the fingerprint representation are changed by changing a property of one or more elements that represent fingerprint ridges.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the property is a line thickness.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. An electronic device comprising:<claim-text>a fingerprint sensor; and</claim-text><claim-text>a display;</claim-text><claim-text>wherein the electronic device is configured to:<claim-text>capture first fingerprint information using the fingerprint sensor;</claim-text><claim-text>in response to capturing the first fingerprint information, display, on the display, a fingerprint representation with a first portion of the fingerprint representation displayed differently from remaining portions of the fingerprint representation, the remaining portions of the fingerprint representation including a second portion of the fingerprint representation;</claim-text><claim-text>after displaying the fingerprint representation with the first portion of the fingerprint representation displayed differently from remaining portions of the fingerprint representation, capture second fingerprint information using the fingerprint sensor; and</claim-text><claim-text>in response to capturing the second fingerprint information, change an appearance of the second portion of the fingerprint representation.</claim-text></claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The electronic device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the second portion of the fingerprint representation is changed to be displayed differently from remaining portions of the fingerprint representation other than the first portion of the fingerprint representation and the second portion of the fingerprint representation.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The electronic device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first portion of the fingerprint representation and the second portion of the fingerprint representation are changed in the same manner.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The electronic device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first portion of the fingerprint representation and the second portion of the fingerprint representation are changed by changing a property of one or more lines in the fingerprint representation.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The electronic device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the fingerprint representation is a graphical element that includes elements that represent fingerprint ridges.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The electronic device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the first portion of the fingerprint representation and the second portion of the fingerprint representation are changed by changing a property of one or more elements that represent fingerprint ridges.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The electronic device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the property is a color.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A non-transitory computer readable medium storing instructions that when executed by an electronic device cause the electronic device to:<claim-text>capture first fingerprint information using a fingerprint sensor;</claim-text><claim-text>in response to capturing the first fingerprint information, display, on a display, a fingerprint representation with a first portion of the fingerprint representation displayed differently from remaining portions of the fingerprint representation, the remaining portions of the fingerprint representation including a second portion of the fingerprint representation;</claim-text><claim-text>after displaying the fingerprint representation with the first portion of the fingerprint representation displayed differently from remaining portions of the fingerprint representation, capture second fingerprint information using the fingerprint sensor; and</claim-text><claim-text>in response to capturing the second fingerprint information, change an appearance of the second portion of the fingerprint representation.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the second portion of the fingerprint representation is changed to be displayed differently from remaining portions of the fingerprint representation other than the first portion of the fingerprint representation and the second portion of the fingerprint representation.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the first portion of the fingerprint representation and the second portion of the fingerprint representation are changed in the same manner.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the first portion of the fingerprint representation and the second portion of the fingerprint representation are changed by changing a property of one or more lines in the fingerprint representation.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the fingerprint representation is a graphical element that includes elements that represent fingerprint ridges.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the first portion of the fingerprint representation and the second portion of the fingerprint representation are changed by changing at least one of a dash pattern or a shading of one or more elements that represent fingerprint ridges.</claim-text></claim></claims></us-patent-application>
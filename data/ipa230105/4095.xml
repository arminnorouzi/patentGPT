<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004096A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004096</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17780960</doc-number><date>20200928</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>19212419.6</doc-number><date>20191129</date></priority-claim><priority-claim sequence="02" kind="regional"><country>EP</country><doc-number>20151169.8</doc-number><date>20200110</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>03</class><subclass>F</subclass><main-group>7</main-group><subgroup>20</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>82</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>03</class><subclass>F</subclass><main-group>7</main-group><subgroup>70675</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>03</class><subclass>F</subclass><main-group>7</main-group><subgroup>70525</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>82</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e79">METHOD AND SYSTEM FOR PREDICTING PROCESS INFORMATION WITH A PARAMETERIZED MODEL</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>ASML Netherlands B.V.</orgname><address><city>Veldhoven</city><country>NL</country></address></addressbook><residence><country>NL</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MIDDLEBROOKS</last-name><first-name>Scott Anderson</first-name><address><city>Duizel</city><country>NL</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>WARNAAR</last-name><first-name>Patrick</first-name><address><city>Tilburg</city><country>NL</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>HELFENSTEIN</last-name><first-name>Patrick Philipp</first-name><address><city>Eindhoven</city><country>NL</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>KONIJNENBERG</last-name><first-name>Alexander Prasetya</first-name><address><city>Veldhoven</city><country>NL</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>PISARENCO</last-name><first-name>Maxim</first-name><address><city>Son en Breugel</city><country>NL</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>VAN KRAAIJ</last-name><first-name>Markus Gerardus Martinus Maria</first-name><address><city>Eindhoven</city><country>NL</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>ASML Netherlands B.V.</orgname><role>03</role><address><city>Veldhoven</city><country>NL</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/EP2020/077115</doc-number><date>20200928</date></document-id><us-371c12-date><date>20220527</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method and system for predicting complex electric field images with a parameterized model are described. A latent space representation of a complex electric field image is determined based on dimensional data in a latent space of the parameterized model for a given input to the parameterized model. The given input may be a measured amplitude (e.g., intensity) associated with the complex electric field image. The complex electric field image is predicted based on the latent space representation of the complex electric field image. The predicted complex electric field image includes an amplitude and a phase. The parameterized model comprises encoder-decoder architecture. In some embodiments, determining the latent space representation of the electric field image comprises minimizing a function constrained by a set of electric field images that could be predicted by the parameterized model based on the dimensional data in the latent space and the given input.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="193.63mm" wi="140.04mm" file="US20230004096A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="152.15mm" wi="129.20mm" file="US20230004096A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="99.57mm" wi="111.84mm" file="US20230004096A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="147.15mm" wi="159.43mm" file="US20230004096A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="171.62mm" wi="130.64mm" file="US20230004096A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="187.20mm" wi="91.69mm" orientation="landscape" file="US20230004096A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="222.84mm" wi="142.07mm" file="US20230004096A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="93.73mm" wi="141.99mm" orientation="landscape" file="US20230004096A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="230.04mm" wi="73.07mm" file="US20230004096A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="176.19mm" wi="139.78mm" orientation="landscape" file="US20230004096A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="115.99mm" wi="144.78mm" file="US20230004096A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="186.18mm" wi="146.30mm" file="US20230004096A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims priority of EP application 19212419.6 which was filed on 2019 Nov. 29 and EP application 20151169.8 which was filed on 2020 Jan. 10 and whom are incorporated herein in their entirety by reference.</p><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">This description relates to a method and system for predicting process information with a parameterized model.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">A lithographic apparatus is a machine constructed to apply a desired pattern onto a substrate. A lithographic apparatus can be used, for example, in the manufacture of integrated circuits (ICs). A lithographic apparatus may, for example, project a pattern (also often referred to as &#x201c;design layout&#x201d; or &#x201c;design&#x201d;) at a patterning device (e.g., a mask) onto a layer of radiation-sensitive material (resist) provided on a substrate (e.g., a wafer).</p><p id="p-0005" num="0004">To project a pattern on a substrate a lithographic apparatus may use electromagnetic radiation. The wavelength of this radiation determines the minimum size of features which can be formed on the substrate. Typical wavelengths currently in use are 365 nm (i-line), 248 nm, 193 nm and 13.5 nm. A lithographic apparatus, which uses extreme ultraviolet (EUV) radiation, having a wavelength within the range 4-20 nm, for example 6.7 nm or 13.5 nm, may be used to form smaller features on a substrate than a lithographic apparatus which uses, for example, radiation with a wavelength of 193 nm.</p><p id="p-0006" num="0005">Low-k<sub>1 </sub>lithography may be used to process features with dimensions smaller than the classical resolution limit of a lithographic apparatus. In such process, the resolution formula may be expressed as CD=k<sub>1</sub>&#xd7;&#x3bb;/NA, where &#x3bb; is the wavelength of radiation employed, NA is the numerical aperture of the projection optics in the lithographic apparatus, CD is the &#x201c;critical dimension&#x201d; (generally the smallest feature size printed, but in this case half-pitch) and k<sub>1 </sub>is an empirical resolution factor. In general, the smaller k<sub>1 </sub>the more difficult it becomes to reproduce the pattern on the substrate that resembles the shape and dimensions planned by a circuit designer in order to achieve particular electrical functionality and performance.</p><p id="p-0007" num="0006">To overcome these difficulties, sophisticated fine-tuning steps may be applied to the lithographic projection apparatus and/or design layout. These include, for example, but are not limited to, optimization of NA, customized illumination schemes, use of phase shifting patterning devices, various optimization of the design layout such as optical proximity correction (OPC, sometimes also referred to as &#x201c;optical and process correction&#x201d;) in the design layout, or other methods generally defined as &#x201c;resolution enhancement techniques&#x201d; (RET). Alternatively, tight control loops for controlling a stability of the lithographic apparatus may be used to improve reproduction of the pattern at low k1.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0008" num="0007">Various metrology operations may be used to measure features of a design. These operations may include measuring overlay, for example. Overlay can be determined based on computationally intensive determination of a complex electric field image associated with the design. Advantageously, the present method(s) and system(s) are configured for (less computationally intensive) prediction of complex electric field images, determination of one or more metrology metrics, and/or other operations with a parameterized model.</p><p id="p-0009" num="0008">According to an embodiment, there is provided a method for predicting electric field images with a parameterized model. The method comprises determining, based on dimensional data in a latent space of the parameterized model, a latent space representation of an electric field image for a given input to the parameterized model; and predicting the electric field image based on the latent space representation of the electric field image.</p><p id="p-0010" num="0009">In some embodiments, the electric field image comprises a complex electric field image having an amplitude and a phase.</p><p id="p-0011" num="0010">In some embodiments, the given input comprises a measured amplitude associated with the complex electric field image.</p><p id="p-0012" num="0011">In some embodiments, the amplitude comprises an intensity.</p><p id="p-0013" num="0012">In some embodiments, determining the latent space representation of the electric field image comprises minimizing a function constrained by a set of electric field images that could be predicted by the parameterized model based on the dimensional data in the latent space and the given input.</p><p id="p-0014" num="0013">In some embodiments, the latent space representation of the electric field image comprises a tensor.</p><p id="p-0015" num="0014">In some embodiments, the parameterized model is a machine learning model.</p><p id="p-0016" num="0015">In some embodiments, the parameterized model comprises encoder-decoder architecture.</p><p id="p-0017" num="0016">In some embodiments, the encoder-decoder architecture comprises variational encoder-decoder architecture. The method further comprises training the variational encoder-decoder architecture with a probabilistic latent space, which generates realizations in an output space.</p><p id="p-0018" num="0017">In some embodiments, the latent space comprises low dimensional encodings.</p><p id="p-0019" num="0018">In some embodiments, the dimensional data in the latent space is encoded by an encoder of the encoder-decoder architecture.</p><p id="p-0020" num="0019">In some embodiments, the method further comprises training the parameterized model with a training set of complex electric field images.</p><p id="p-0021" num="0020">In some embodiments, the set of complex electric field images is generated during a through focus measurement.</p><p id="p-0022" num="0021">In some embodiments, the training comprises encoding the complex electric field images in the training set into the dimensional data in the latent space, and transforming the dimensional data in the latent space into recovered versions of the complex electric field images in the training set to facilitate verification of the training.</p><p id="p-0023" num="0022">In some embodiments, the method further comprises iteratively providing additional complex electric field images as input to the parameterized model. The additional complex electric field images are determined based on an extent to which the recovered versions of the complex electric field images match the complex electric field images in the training set.</p><p id="p-0024" num="0023">In some embodiments, the method further comprises encoding, with the encoder, higher dimensional data associated with the electric field images into the dimensional data in the latent space.</p><p id="p-0025" num="0024">In some embodiments, predicting the electric field image based on the latent space representation of the electric field image comprises passing the latent space representation of the electric field image through a decoder of the encoder-decoder architecture.</p><p id="p-0026" num="0025">In some embodiments, the method further comprises determining a metrology metric based on the latent space representation of the electric field image.</p><p id="p-0027" num="0026">In some embodiments, determining the metrology metric based on the latent space representation of the electric field image comprises providing the latent space representation of the electric field image to a regression network that is included in or separate from the parameterized model.</p><p id="p-0028" num="0027">In some embodiments, the metrology metric is overlay.</p><p id="p-0029" num="0028">In some embodiments, the method further comprises correcting for aberrations associated with a metrology apparatus based on the latent space representation of the electric field image and/or the predicted electric field image.</p><p id="p-0030" num="0029">In some embodiments, the method further comprises determining, based on the predicted electric field image, adjustments to semiconductor manufacturing process parameters for patterning substrate geometry as part of a semiconductor manufacturing process.</p><p id="p-0031" num="0030">According to another embodiment, there is provided a non-transitory computer readable medium having instructions thereon, the instructions when executed by a computer implementing any of the methods described herein.</p><p id="p-0032" num="0031">According to another embodiment, there is provided a metrology apparatus configured to determine one or more metrology metrics for a semiconductor manufacturing process. The apparatus comprises one or more processors configured to: determine, based on dimensional data in a latent space of a parameterized model, a latent space representation of an electric field image for a given input; predict, with the parameterized model, the electric field image based on the latent space representation of the electric field image; and determine the one or more metrology metrics for the semiconductor manufacturing process based on the predicted electric field image.</p><p id="p-0033" num="0032">According to another embodiment, there is provided lithographic cell comprising a metrology apparatus. The metrology apparatus is configured to: determine, based on dimensional data in a latent space of a parameterized model, a latent space representation of an electric field image for a given input; predict, with the parameterized model, the electric field image based on the latent space representation of the electric field image; and determine one or more metrology metrics for the semiconductor manufacturing process based on the predicted electric field image.</p><p id="p-0034" num="0033">According to another embodiment, there is provided a method for determining one or more metrology metrics for a semiconductor manufacturing process. The method comprises: determining, based on dimensional data in a latent space of a parameterized model, a latent space representation of an electric field image for a given input; predicting, with the parameterized model, the electric field image based on the latent space representation of the electric field image; and determining the one or more metrology metrics for the semiconductor manufacturing process based on the predicted electric field image.</p><p id="p-0035" num="0034">In some embodiments, the electric field image comprises a complex electric field image having an amplitude and a phase.</p><p id="p-0036" num="0035">In some embodiments, the one or more determined metrology metrics comprise one or more of overlay, a critical dimension, a reconstruction of a three dimensional profile of features of a substrate, or a dose or focus of a lithography apparatus at a moment when the features of the substrate were printed with the lithography apparatus.</p><p id="p-0037" num="0036">In some embodiments, the given input comprises a measured amplitude associated with the complex electric field image.</p><p id="p-0038" num="0037">In some embodiments, the amplitude comprises an intensity.</p><p id="p-0039" num="0038">In some embodiments, the method comprises adjusting one or more semiconductor manufacturing process parameters based on the determined one or more metrology metrics.</p><p id="p-0040" num="0039">According to another embodiment, there is provided a method for predicting process information with a parameterized model, comprising: determining, in a latent space of the parameterized model, a latent space representation of a given input to the parameterized model; transforming the latent space representation of the given input, based on a reference latent space representation for the given input, into a transformed latent space representation of the given input; and predicting the process information based on the transformed latent space representation of the given input.</p><p id="p-0041" num="0040">In some embodiments, the given input is associated with a target, and received from one of a plurality of target characterization apparatuses configured to generate the given input. It should be noted that &#x201c;target&#x201d; is used broadly and may refer to any features and/or structure in any substrate, layer, or other portion of a of a device and/or other physical object that is imaged, measured, or otherwise characterized in one way or another. This may include, for example, a metrology target and/or other measurement structures. The targets may be located inside or outside product areas on a wafer, for example.</p><p id="p-0042" num="0041">In some embodiments, the transforming and predicting are configured such that the predicted process information for the target is the same, independent of which one of the target characterization apparatuses generated the given input.</p><p id="p-0043" num="0042">In some embodiments, the transforming comprises one or more mathematical operations performed on the latent space representation of the given input.</p><p id="p-0044" num="0043">In some embodiments, the transforming is performed in the latent space.</p><p id="p-0045" num="0044">In some embodiments, the reference latent space representation comprises a weighted combination and/or an average of latent space representations of previously received inputs to the parameterized model, or a latent space representation of an input from a specific target characterization apparatus configured to generate the given input.</p><p id="p-0046" num="0045">In some embodiments, the process information and the given input are associated with a semiconductor manufacturing process.</p><p id="p-0047" num="0046">In some embodiments, the predicted process information comprises one or more of a predicted image, or a predicted process measurement. It should be noted that &#x201c;image&#x201d; is used broadly and may refer to any image generated (e.g., measured, predicted, acquired, etc.) during a manufacturing process. This may include, for example, in the context of semiconductor devices, field-plane acquisitions, pupil plane acquisitions, and/or other images.</p><p id="p-0048" num="0047">In some embodiments, the predicted process measurement comprises one or more of a metrology metric, an xyz position, a dimension, an electric field, a wavelength, an illumination and/or detection pupil, a bandwidth, an illumination and/or detection polarization angle, or an illumination and/or a detection retardance angle.</p><p id="p-0049" num="0048">In some embodiments, the given input comprises one or more of an input image, or an input process measurement.</p><p id="p-0050" num="0049">According to another embodiment, there is provided a method for predicting process information with a parameterized model, comprising: determining, based on dimensional data, in a latent space of the parameterized model, a latent space representation of an optimum set of process parameters associated with a given input to the parameterized model; and predicting the process information based on the latent space representation of the optimum set of process conditions.</p><p id="p-0051" num="0050">In some embodiments, the predicted process information comprises one or more of a design parameter, or a metrology measurement recipe parameter, for a target.</p><p id="p-0052" num="0051">In some embodiments, the design parameter comprises one or more of a critical dimension, a pitch, a segmentation pitch, line geometry, contact geometry, or hole geometry associated with the target.</p><p id="p-0053" num="0052">In some embodiments, the metrology measurement recipe parameter comprises one or more of a wavelength, a bandwidth, an aperture, an illumination and/or detection pupil, a bandwidth, an illumination and/or detection polarization angle, an illumination and/or a detection retardance angle, or a dose for measuring the target.</p><p id="p-0054" num="0053">In some embodiments, the optimum set of process parameters define optimum measurement conditions for measuring a metrology metric for a target.</p><p id="p-0055" num="0054">In some embodiments, the optimum set of process parameters comprise one or more of an intensity, a contrast, an edge response, a diffraction efficiency, or an overlay sensitivity.</p><p id="p-0056" num="0055">In some embodiments, the given input comprises one or more of a defined design parameter, or a defined metrology measurement recipe parameter, for a target.</p><p id="p-0057" num="0056">In some embodiments, the parameterized model is a machine learning model.</p><p id="p-0058" num="0057">In some embodiments, the parameterized model comprises encoder-decoder architecture.</p><p id="p-0059" num="0058">In some embodiments, the latent space comprises low dimensional encodings.</p><p id="p-0060" num="0059">According to another embodiment, there is provided a method for predicting process information with a parameterized model, comprising: determining, in a latent space of the parameterized model, a latent space representation of a given input to the parameterized model; transforming the latent space representation of the given input, based on a reference latent space representation for the given input, into a transformed latent space representation of the given input; determining, based on the transformed latent space representation, a latent space representation of an optimum set of process parameters associated with the given input; and predicting the process information based on the transformed latent space representation of the given input and the latent space representation of the optimum set of process parameters associated with the given input.</p><p id="p-0061" num="0060">According to another embodiment, there is provided a method for predicting process information with a parameterized model, comprising: determining, in a latent space of the parameterized model, a latent space representation of a given input to the parameterized model; transforming the latent space representation of the given input, based on a reference latent space representation for the given input, into a transformed latent space representation of the given input; determining, based on the transformed latent space representation of the given input, a latent space representation of an electric field image for the given input; determining, based on the transformed latent space representation, a latent space representation of an optimum set of process parameters associated with the given input; and predicting the process information based on the transformed latent space representation of the given input, the latent space representation of the electric field image, and the latent space representation of the optimum set of process parameters associated with the given input.</p><p id="p-0062" num="0061">According to another embodiment, there is provided a non-transitory computer readable medium having instructions thereon, the instructions when executed by a computer implementing the method of any of the embodiments described above.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0063" num="0062">The accompanying drawings, which are incorporated in and constitute a part of the specification, illustrate one or more embodiments and, together with the description, explain these embodiments. Embodiments of the invention will now be described, by way of example only, with reference to the accompanying schematic drawings in which corresponding reference symbols indicate corresponding parts, and in which:</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a schematic overview of a lithographic apparatus, according to an embodiment.</p><p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts a schematic overview of a lithographic cell, according to an embodiment.</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts a schematic representation of holistic lithography, representing a cooperation between three technologies to optimize semiconductor manufacturing, according to an embodiment.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example metrology apparatus, such as a scatterometer, according to an embodiment.</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates encoder-decoder architecture, according to an embodiment.</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates encoder-decoder architecture within a neural network, according to an embodiment.</p><p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example camera associated with obtaining complex electric field images, according to an embodiment.</p><p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a summary of operations of a present method for predicting electric field images with a parameterized model, according to an embodiment.</p><p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an example of a parameterized model, according to an embodiment.</p><p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram of an example computer system, according to an embodiment.</p><p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is an alternative design for the lithography apparatus of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to an embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0075" num="0074">Process information (e.g., images, measurements, process parameters, metrology metrics, etc.) may be used to guide various manufacturing operations. Predicting or otherwise determining the process information with a parameterized model as described herein may be faster, more efficient, require fewer computing resources, and/or have other advantages over prior methods for determining process information.</p><p id="p-0076" num="0075">Phase retrieval, for example, may be used for determination of a complex electric field image. The complex electric field image may be associated with a target. The target may be a portion of a semiconductor device (e.g., a portion of a pattern and/or features patterned in a substrate), and/or other targets, for example. As described above, it should be noted that &#x201c;target&#x201d; is used broadly and refers to any features and/or structure in any substrate, layer, or other portion of a of a device and/or other physical object that is imaged, measured, or otherwise characterized in one way or another. The complex electric field image may be used, in turn, to determine one or more metrology metrics such as overlay, for example, and/or other information for the target.</p><p id="p-0077" num="0076">Phase retrieval comprises recovering a complex (valued) electric field from corresponding amplitude (e.g., intensity) measurements (e.g., for a particular target). Phase retrieval is difficult due to a large number of unknowns (e.g., on the order of 10<sup>6</sup>), nonlinearity, and non-convexity associated with the equation satisfied by the complex electric field. Existing approaches for phase retrieval include introducing redundancy in the amplitude measurements or exploiting prior knowledge about the complex electric field image (e.g., to reduce the number of unknowns). These and other approaches require redundant data, making assumptions, are computationally intensive, and/or have other disadvantages.</p><p id="p-0078" num="0077">In contrast, the present method(s) and system(s) are configured for prediction of complex electric field images with a parameterized model. Prediction of complex electric field images with a parameterized model may be less computationally intensive and/or have other advantages compared to prior methods. The parameterized model is configured to significantly reduce the dimensionality of the phase retrieval problem, which can then be solved using a gradient-based optimization scheme (for example) in few dimensions.</p><p id="p-0079" num="0078">As another example, data from different process sensors and/or tools may be different, even for the same measured or imaged target. Prior attempts to resolve these differences include physically adjusting the components of one or more of the sensors or tools, adjusting measuring or imaging parameters on a given sensor or tool, and/or making other adjustments to bring data from a particular sensor or tool into better agreement with data from other sensors or tools. However, these adjustments are not always applied consistently, depend on human judgement and/or a particular arrangement of physical components, and/or have other disadvantages.</p><p id="p-0080" num="0079">In contrast, the present method(s) and system(s) are configured to determine, in one or more latent spaces of a parameterized model (where there are fewer dimensions of data to analyze compared to the number of dimensions in the raw data from the different sensors and/or tools), a latent space representation of a given input to the parameterized model. The latent space representation is transformed, based on a reference latent space representation for the given input, into a transformed latent space representation of the given input; and process information is predicted based on the transformed latent space representation of the given input. For example, the given input may be associated with a target, and received from one of a plurality of different sensors and/or tools configured to generate the given input. The transforming and predicting are configured such that predicted and/or otherwise determined process information (e.g., images, measurements, process parameters, metrology metrics, etc.) from the parameterized model, for the target, is the same, independent of which one of the sensors and/or tools generated the given input.</p><p id="p-0081" num="0080">As a third example, operations such as target design, manufacturing recipe determination, and/or other operations often require iterative experimentation where selected design or recipe variables are purposefully adjusted in each iteration, while other variables remain fixed for that iteration. Each iteration often requires various measurements to be recorded and analyzed. After several iterations, a particular target design, or manufacturing recipe may be chosen (e.g., by a process of elimination and/or a different method).</p><p id="p-0082" num="0081">In contrast, the present method(s) and system(s) are configured to determine, based on dimensional data in one or more latent spaces of a parameterized model (again, where there are fewer dimensions of data to analyze compared to the number of dimensions in raw data from the different experimental iterations), a latent space representation of an optimum set of process parameters associated with a given input to the parameterized model. The given input may comprise required (e.g., unchangeable because of design requirements, machine capability, physics, etc.) elements of a target design, or manufacturing recipe, for example, or other input. The presents system(s) and method(s) are configured to predict and/or otherwise determine process information such as an optimum target design or manufacturing recipe based on the latent space representation of the optimum set of process conditions.</p><p id="p-0083" num="0082">These examples are not intended to be limiting. It should also be noted that one or more parameterized models may perform some or all of the operations described above. For example, one parameterized model may be trained to predict complex electric field images, transform data from different sensors and/or tools such that data for the same target matches, and determine an optimum target design and/or manufacturing recipe; or these different operations may be performed by different parameterized models. The different applications (predicting complex electric field images, transforming data from different sensors and/or tools such that data for the same target from different sensors and/or tools still matches, and determining an optimum target design and/or manufacturing recipe) may be used together, or they may be used separately.</p><p id="p-0084" num="0083">In addition, although specific reference may be made in this text to the manufacture of ICs, the description herein has many other possible applications. For example, it may be employed in the manufacture of integrated optical systems, guidance and detection patterns for magnetic domain memories, liquid-crystal display panels, thin-film magnetic heads, etc. In these alternative applications, the skilled artisan will appreciate that, in the context of such alternative applications, any use of the terms &#x201c;reticle&#x201d;, &#x201c;wafer&#x201d; or &#x201c;die&#x201d; in this text should be considered as interchangeable with the more general terms &#x201c;mask&#x201d;, &#x201c;substrate&#x201d; and &#x201c;target portion&#x201d;, respectively. In addition, it should be noted that the method described herein may have many other possible applications in diverse fields such as language processing systems, self-driving cars, medical imaging and diagnosis, semantic segmentation, denoising, chip design, electronic design automation, etc. The present method may be applied in any fields where quantifying uncertainty in machine learning model predictions is advantageous.</p><p id="p-0085" num="0084">In the present document, the terms &#x201c;radiation&#x201d; and &#x201c;beam&#x201d; are used to encompass all types of electromagnetic radiation, including ultraviolet radiation (e.g. with a wavelength of 365, 248, 193, 157 or 126 nm) and EUV (extreme ultra-violet radiation, e.g. having a wavelength in the range of about 5-100 nm).</p><p id="p-0086" num="0085">A patterning device may comprise, or may form, one or more design layouts. The design layout may be generated utilizing CAD (computer-aided design) programs. This process is often referred to as EDA (electronic design automation). Most CAD programs follow a set of predetermined design rules in order to create functional design layouts/patterning devices. These rules are set based processing and design limitations. For example, design rules define the space tolerance between devices (such as gates, capacitors, etc.) or interconnect lines, to ensure that the devices or lines do not interact with one another in an undesirable way. One or more of the design rule limitations may be referred to as a &#x201c;critical dimension&#x201d; (CD). A critical dimension of a device can be defined as the smallest width of a line or hole, or the smallest space between two lines or two holes. Thus, the CD regulates the overall size and density of the designed device. One of the goals in device fabrication is to faithfully reproduce the original design intent on the substrate (via the patterning device).</p><p id="p-0087" num="0086">The term &#x201c;reticle,&#x201d; &#x201c;mask,&#x201d; or &#x201c;patterning device&#x201d; as employed in this text may be broadly interpreted as referring to a generic patterning device that can be used to endow an incoming radiation beam with a patterned cross-section, corresponding to a pattern that is to be created in a target portion of the substrate. The term &#x201c;light valve&#x201d; can also be used in this context. Besides the classic mask (transmissive or reflective; binary, phase-shifting, hybrid, etc.), examples of other such patterning devices include a programmable mirror array.</p><p id="p-0088" num="0087">As a brief introduction, <figref idref="DRAWINGS">FIG. <b>1</b></figref> schematically depicts a lithographic apparatus LA. The lithographic apparatus LA includes an illumination system (also referred to as illuminator) IL configured to condition a radiation beam B (e.g., UV radiation, DUV radiation or EUV radiation), a mask support (e.g., a mask table) T constructed to support a patterning device (e.g., a mask) MA and connected to a first positioner PM configured to accurately position the patterning device MA in accordance with certain parameters, a substrate support (e.g., a wafer table) WT configured to hold a substrate (e.g., a resist coated wafer) W and coupled to a second positioner PW configured to accurately position the substrate support in accordance with certain parameters, and a projection system (e.g., a refractive projection lens system) PS configured to project a pattern imparted to the radiation beam B by patterning device MA onto a target portion C (e.g., comprising one or more dies) of the substrate W.</p><p id="p-0089" num="0088">In operation, the illumination system IL receives a radiation beam from a radiation source SO, e.g. via a beam delivery system BD. The illumination system IL may include various types of optical components, such as refractive, reflective, magnetic, electromagnetic, electrostatic, and/or other types of optical components, or any combination thereof, for directing, shaping, and/or controlling radiation. The illuminator IL may be used to condition the radiation beam B to have a desired spatial and angular intensity distribution in its cross section at a plane of the patterning device MA.</p><p id="p-0090" num="0089">The term &#x201c;projection system&#x201d; PS used herein should be broadly interpreted as encompassing various types of projection system, including refractive, reflective, catadioptric, anamorphic, magnetic, electromagnetic and/or electrostatic optical systems, or any combination thereof, as appropriate for the exposure radiation being used, and/or for other factors such as the use of an immersion liquid or the use of a vacuum. Any use of the term &#x201c;projection lens&#x201d; herein may be considered as synonymous with the more general term &#x201c;projection system&#x201d; PS.</p><p id="p-0091" num="0090">The lithographic apparatus LA may be of a type wherein at least a portion of the substrate may be covered by a liquid having a relatively high refractive index, e.g., water, so as to fill a space between the projection system PS and the substrate W&#x2014;which is also referred to as immersion lithography. More information on immersion techniques is given in U.S. Pat. No. 6,952,253, which is incorporated herein by reference.</p><p id="p-0092" num="0091">The lithographic apparatus LA may also be of a type having two or more substrate supports WT (also named &#x201c;dual stage&#x201d;). In such &#x201c;multiple stage&#x201d; machine, the substrate supports WT may be used in parallel, and/or steps in preparation of a subsequent exposure of the substrate W may be carried out on the substrate W located on one of the substrate support WT while another substrate W on the other substrate support WT is being used for exposing a pattern on the other substrate W.</p><p id="p-0093" num="0092">In addition to the substrate support WT, the lithographic apparatus LA may comprise a measurement stage. The measurement stage is arranged to hold a sensor and/or a cleaning device. The sensor may be arranged to measure a property of the projection system PS or a property of the radiation beam B. The measurement stage may hold multiple sensors. The cleaning device may be arranged to clean part of the lithographic apparatus, for example a part of the projection system PS or a part of a system that provides the immersion liquid. The measurement stage may move beneath the projection system PS when the substrate support WT is away from the projection system PS.</p><p id="p-0094" num="0093">In operation, the radiation beam B is incident on the patterning device, e.g. mask, MA which is held on the mask support MT, and is patterned by the pattern (design layout) present on patterning device MA. Having traversed the mask MA, the radiation beam B passes through the projection system PS, which focuses the beam onto a target portion C of the substrate W. With the aid of the second positioner PW and a position measurement system IF, the substrate support WT can be moved accurately, e.g., so as to position different target portions C in the path of the radiation beam B at a focused and aligned position. Similarly, the first positioner PM and possibly another position sensor (which is not explicitly depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>) may be used to accurately position the patterning device MA with respect to the path of the radiation beam B. Patterning device MA and substrate W may be aligned using mask alignment marks M<b>1</b>, M<b>2</b> and substrate alignment marks P<b>1</b>, P<b>2</b>. Although the substrate alignment marks P<b>1</b>, P<b>2</b> as illustrated occupy dedicated target portions, they may be located in spaces between target portions. Substrate alignment marks P<b>1</b>, P<b>2</b> are known as scribe-lane alignment marks when these are located between the target portions C.</p><p id="p-0095" num="0094"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts a schematic overview of a lithographic cell LC. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> the lithographic apparatus LA may form part of lithographic cell LC, also sometimes referred to as a lithocell or (litho)cluster, which often also includes apparatus to perform pre- and post-exposure processes on a substrate W. Conventionally, these include spin coaters SC configured to deposit resist layers, developers DE to develop exposed resist, chill plates CH and bake plates BK, e.g. for conditioning the temperature of substrates W e.g. for conditioning solvents in the resist layers. A substrate handler, or robot, RO picks up substrates W from input/output ports I/O<b>1</b>, I/O<b>2</b>, moves them between the different process apparatus and delivers the substrates W to the loading bay LB of the lithographic apparatus LA. The devices in the lithocell, which are often also collectively referred to as the track, are typically under the control of a track control unit TCU that in itself may be controlled by a supervisory control system SCS, which may also control the lithographic apparatus LA, e.g. via lithography control unit LACU.</p><p id="p-0096" num="0095">In order for the substrates W (<figref idref="DRAWINGS">FIG. <b>1</b></figref>) exposed by the lithographic apparatus LA to be exposed correctly and consistently, it is desirable to inspect substrates to measure properties of patterned structures, such as overlay errors between subsequent layers, line thicknesses, critical dimensions (CD), etc. For this purpose, inspection tools (not shown) may be included in the lithocell LC. If errors are detected, adjustments, for example, may be made to exposures of subsequent substrates or to other processing steps that are to be performed on the substrates W, especially if the inspection is done before other substrates W of the same batch or lot are still to be exposed or processed.</p><p id="p-0097" num="0096">An inspection apparatus, which may also be referred to as a metrology apparatus, is used to determine properties of the substrates W (<figref idref="DRAWINGS">FIG. <b>1</b></figref>), and in particular, how properties of different substrates W vary or how properties associated with different layers of the same substrate W vary from layer to layer. The inspection apparatus may alternatively be constructed to identify defects on the substrate W and may, for example, be part of the lithocell LC, or may be integrated into the lithographic apparatus LA, or may even be a stand-alone device. The inspection apparatus may measure the properties on a latent image (image in a resist layer after the exposure), or on a semi-latent image (image in a resist layer after a post-exposure bake step PEB), or on a developed resist image (in which the exposed or unexposed parts of the resist have been removed), or even on an etched image (after a pattern transfer step such as etching).</p><p id="p-0098" num="0097"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts a schematic representation of holistic lithography, representing a cooperation between three technologies to optimize semiconductor manufacturing. Typically, the patterning process in a lithographic apparatus LA is one of the most critical steps in the processing which requires high accuracy of dimensioning and placement of structures on the substrate W (<figref idref="DRAWINGS">FIG. <b>1</b></figref>). To ensure this high accuracy, three systems (in this example) may be combined in a so called &#x201c;holistic&#x201d; control environment as schematically depicted in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. One of these systems is the lithographic apparatus LA which is (virtually) connected to a metrology apparatus (e.g., a metrology tool) MT (a second system), and to a computer system CL (a third system). A &#x201c;holistic&#x201d; environment may be configured to optimize the cooperation between these three systems to enhance the overall process window and provide tight control loops to ensure that the patterning performed by the lithographic apparatus LA stays within a process window. The process window defines a range of process parameters (e.g. dose, focus, overlay) within which a specific manufacturing process yields a defined result (e.g. a functional semiconductor device)&#x2014;typically within which the process parameters in the lithographic process or patterning process are allowed to vary.</p><p id="p-0099" num="0098">The computer system CL may use (part of) the design layout to be patterned to predict which resolution enhancement techniques to use and to perform computational lithography simulations and calculations to determine which mask layout and lithographic apparatus settings achieve the largest overall process window of the patterning process (depicted in <figref idref="DRAWINGS">FIG. <b>3</b></figref> by the double arrow in the first scale SC<b>1</b>). Typically, the resolution enhancement techniques are arranged to match the patterning possibilities of the lithographic apparatus LA. The computer system CL may also be used to detect where within the process window the lithographic apparatus LA is currently operating (e.g. using input from the metrology tool MT) to predict whether defects may be present due to e.g. sub-optimal processing (depicted in <figref idref="DRAWINGS">FIG. <b>3</b></figref> by the arrow pointing &#x201c;0&#x201d; in the second scale SC<b>2</b>).</p><p id="p-0100" num="0099">The metrology apparatus (tool) MT may provide input to the computer system CL to enable accurate simulations and predictions, and may provide feedback to the lithographic apparatus LA to identify possible drifts, e.g. in a calibration status of the lithographic apparatus LA (depicted in <figref idref="DRAWINGS">FIG. <b>3</b></figref> by the multiple arrows in the third scale SC<b>3</b>).</p><p id="p-0101" num="0100">In lithographic processes, it is desirable to make frequent measurements of the structures created, e.g., for process control and verification. Tools to make such measurements include metrology tool (apparatus) MT. Different types of metrology tools MT for making such measurements are known, including scanning electron microscopes or various forms of scatterometer metrology tools MT. Scatterometers are versatile instruments which allow measurements of the parameters of a lithographic process by having a sensor in the pupil or a conjugate plane with the pupil of the objective of the scatterometer, measurements usually referred as pupil based measurements, or by having the sensor in the image plane or a plane conjugate with the image plane, in which case the measurements are usually referred as image or field based measurements. Such scatterometers and the associated measurement techniques are further described in patent applications US20100328655, US2011102753A1, US20120044470A, US20110249244, US20110026032 or EP1,628,164A, incorporated herein by reference in their entirety. Aforementioned scatterometers may measure features of a substrate such as gratings using light from soft x-ray and visible to near-IR wavelength range, for example.</p><p id="p-0102" num="0101">In some embodiments, a scatterometer MT is an angular resolved scatterometer. In these embodiments, scatterometer reconstruction methods may be applied to the measured signal to reconstruct or calculate properties of a grating and/or other features in a substrate. Such reconstruction may, for example, result from simulating interaction of scattered radiation with a mathematical model of the target structure and comparing the simulation results with those of a measurement. Parameters of the mathematical model are adjusted until the simulated interaction produces a diffraction pattern similar to that observed from the real target.</p><p id="p-0103" num="0102">In some embodiments, scatterometer MT is a spectroscopic scatterometer MT. In these embodiments, spectroscopic scatterometer MT may be configured such that the radiation emitted by a radiation source is directed onto target features of a substrate and the reflected or scattered radiation from the target is directed to a spectrometer detector, which measures a spectrum (i.e. a measurement of intensity as a function of wavelength) of the specular reflected radiation. From this data, the structure or profile of the target giving rise to the detected spectrum may be reconstructed, e.g. by Rigorous Coupled Wave Analysis and non-linear regression or by comparison with a library of simulated spectra.</p><p id="p-0104" num="0103">In some embodiments, scatterometer MT is a ellipsometric scatterometer. The ellipsometric scatterometer allows for determining parameters of a lithographic process by measuring scattered radiation for each polarization states. Such a metrology apparatus (MT) emits polarized light (such as linear, circular, or elliptic) by using, for example, appropriate polarization filters in the illumination section of the metrology apparatus. A source suitable for the metrology apparatus may provide polarized radiation as well. Various embodiments of existing ellipsometric scatterometers are described in U.S. patent application Ser. Nos. 11/451,599, 11/708,678, 12/256,780, 12/486,449, 12/920,968, 12/922,587, 13/000,229, 13/033,135, 13/533,110 and 13/891,410 incorporated herein by reference in their entirety.</p><p id="p-0105" num="0104">In some embodiments, scatterometer MT is adapted to measure the overlay of two misaligned gratings or periodic structures (and/or other target features of a substrate) by measuring asymmetry in the reflected spectrum and/or the detection configuration, the asymmetry being related to the extent of the overlay. The two (typically overlapping) grating structures may be applied in two different layers (not necessarily consecutive layers), and may be formed substantially at the same position on the wafer. The scatterometer may have a symmetrical detection configuration as described e.g. in patent application EP1,628,164A, such that any asymmetry is clearly distinguishable. This provides a way to measure misalignment in gratings. Further examples for measuring overlay may be found in PCT patent application publication no. WO 2011/012624 or US patent application US 20160161863, incorporated herein by reference in their entirety.</p><p id="p-0106" num="0105">Other parameters of interest may be focus and dose. Focus and dose may be determined simultaneously by scatterometry (or alternatively by scanning electron microscopy) as described in US patent application US2011-0249244, incorporated herein by reference in its entirety. A single structure (e.g., feature in a substrate) may be used which has a unique combination of critical dimension and sidewall angle measurements for each point in a focus energy matrix (FEM&#x2014;also referred to as Focus Exposure Matrix). If these unique combinations of critical dimension and sidewall angle are available, the focus and dose values may be uniquely determined from these measurements.</p><p id="p-0107" num="0106">A metrology target may be an ensemble of composite gratings and/or other features in a substrate, formed by a lithographic process, commonly in resist, but also after etch processes, for example. Typically the pitch and line-width of the structures in the gratings depend on the measurement optics (in particular the NA of the optics) to be able to capture diffraction orders coming from the metrology targets. A diffracted signal may be used to determine shifts between two layers (also referred to &#x2018;overlay&#x2019;) or may be used to reconstruct at least part of the original grating as produced by the lithographic process. This reconstruction may be used to provide guidance of the quality of the lithographic process and may be used to control at least part of the lithographic process. Targets may have smaller sub-segmentation which are configured to mimic dimensions of the functional part of the design layout in a target. Due to this sub-segmentation, the targets will behave more similar to the functional part of the design layout such that the overall process parameter measurements resemble the functional part of the design layout. The targets may be measured in an underfilled mode or in an overfilled mode. In the underfilled mode, the measurement beam generates a spot that is smaller than the overall target. In the overfilled mode, the measurement beam generates a spot that is larger than the overall target. In such overfilled mode, it may also be possible to measure different targets simultaneously, thus determining different processing parameters at the same time.</p><p id="p-0108" num="0107">Overall measurement quality of a lithographic parameter using a specific target is at least partially determined by the measurement recipe used to measure this lithographic parameter. The term &#x201c;substrate measurement recipe&#x201d; may include one or more parameters of the measurement itself, one or more parameters of the one or more patterns measured, or both. For example, if the measurement used in a substrate measurement recipe is a diffraction-based optical measurement, one or more of the parameters of the measurement may include the wavelength of the radiation, the polarization of the radiation, the incident angle of radiation relative to the substrate, the orientation of radiation relative to a pattern on the substrate, etc. One of the criteria to select a measurement recipe may, for example, be a sensitivity of one of the measurement parameters to processing variations. More examples are described in US patent application US2016-0161863 and published US patent application US 2016/0370717A1 incorporated herein by reference in its entirety.</p><p id="p-0109" num="0108"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example metrology apparatus (tool) MT, such as a scatterometer. MT comprises a broadband (white light) radiation projector <b>40</b> which projects radiation onto a substrate <b>42</b>. The reflected or scattered radiation is passed to a spectrometer detector <b>44</b>, which measures a spectrum <b>46</b> (i.e. a measurement of intensity as a function of wavelength) of the specular reflected radiation. From this data, the structure or profile giving rise to the detected spectrum may be reconstructed <b>48</b> by processing unit PU, e.g. by Rigorous Coupled Wave Analysis and non-linear regression or by comparison with a library of simulated spectra as shown at the bottom of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. In general, for the reconstruction, the general form of the structure is known and some parameters are assumed from knowledge of the process by which the structure was made, leaving only a few parameters of the structure to be determined from the scatterometry data. Such a scatterometer may be configured as a normal-incidence scatterometer or an oblique-incidence scatterometer, for example.</p><p id="p-0110" num="0109">It is often desirable to be able computationally determine how a patterning process would produce a desired pattern on a substrate. Computational determination may comprise simulation and/or modeling, for example. Models and/or simulations may be provided for one or more parts of the manufacturing process. For example, it is desirable to be able to simulate the lithography process of transferring the patterning device pattern onto a resist layer of a substrate as well as the yielded pattern in that resist layer after development of the resist, simulate metrology operations such as the determination of overlay, and/or perform other simulations. The objective of a simulation may be to accurately predict, for example, metrology metrics (e.g., overlay, a critical dimension, a reconstruction of a three dimensional profile of features of a substrate, a dose or focus of a lithography apparatus at a moment when the features of the substrate were printed with the lithography apparatus, etc), manufacturing process parameters (e.g., edge placements, aerial image intensity slopes, sub resolution assist features (SRAF), etc.), and/or other information which can then be used to determine whether an intended or target design has been achieved. The intended design is generally defined as a pre-optical proximity correction design layout which can be provided in a standardized digital file format such as GDSII, OASIS or another file format.</p><p id="p-0111" num="0110">Simulation and/or modeling can be used to determine one or more metrology metrics (e.g., performing overlay and/or other metrology measurements), configure one or more features of the patterning device pattern (e.g., performing optical proximity correction), configure one or more features of the illumination (e.g., changing one or more characteristics of a spatial/angular intensity distribution of the illumination, such as change a shape), configure one or more features of the projection optics (e.g., numerical aperture, etc.), and/or for other purposes. Such determination and/or configuration can be generally referred to as mask optimization, source optimization, and/or projection optimization, for example. Such optimizations can be performed on their own, or combined in different combinations. One such example is source-mask optimization (SMO), which involves the configuring of one or more features of the patterning device pattern together with one or more features of the illumination. The optimizations may use the parameterized model described herein to predict values of various parameters (including images, etc.), for example.</p><p id="p-0112" num="0111">In some embodiments, an optimization process of a system may be represented as a cost function. The optimization process may comprise finding a set of parameters (design variables, process variables, etc.) of the system that minimizes the cost function. The cost function can have any suitable form depending on the goal of the optimization. For example, the cost function can be weighted root mean square (RMS) of deviations of certain characteristics (evaluation points) of the system with respect to the intended values (e.g., ideal values) of these characteristics. The cost function can also be the maximum of these deviations (i.e., worst deviation). The term &#x201c;evaluation points&#x201d; should be interpreted broadly to include any characteristics of the system or fabrication method. The design and/or process variables of the system can be confined to finite ranges and/or be interdependent due to practicalities of implementations of the system and/or method. In the case of a lithographic projection apparatus, the constraints are often associated with physical properties and characteristics of the hardware such as tunable ranges, and/or patterning device manufacturability design rules. The evaluation points can include physical points on a resist image on a substrate, as well as non-physical characteristics such as dose and focus, for example.</p><p id="p-0113" num="0112">In some embodiments, the present system(s) and method(s) may include an empirical model that performs one or more of the operations described herein. The empirical model may predict outputs based on correlations between various inputs (e.g., one or more characteristics of a complex electric field image, one or more characteristics of a design layout, one or more characteristics of the patterning device, one or more characteristics of the illumination used in the lithographic process such as the wavelength, etc.).</p><p id="p-0114" num="0113">As an example, the empirical model may be a parameterized model and/or other models. The parameterized model may be a machine learning model and/or any other parameterized model. In some embodiments, the machine learning model (for example) may be and/or include mathematical equations, algorithms, plots, charts, networks (e.g., neural networks), and/or other tools and machine learning model components. For example, the machine learning model may be and/or include one or more neural networks having an input layer, an output layer, and one or more intermediate or hidden layers. In some embodiments, the one or more neural networks may be and/or include deep neural networks (e.g., neural networks that have one or more intermediate or hidden layers between the input and output layers).</p><p id="p-0115" num="0114">As an example, the one or more neural networks may be based on a large collection of neural units (or artificial neurons). The one or more neural networks may loosely mimic the manner in which a biological brain works (e.g., via large clusters of biological neurons connected by axons). Each neural unit of a neural network may be connected with many other neural units of the neural network. Such connections can be enforcing or inhibitory in their effect on the activation state of connected neural units. In some embodiments, each individual neural unit may have a summation function that combines the values of all its inputs together. In some embodiments, each connection (or the neural unit itself) may have a threshold function such that a signal must surpass the threshold before it is allowed to propagate to other neural units. These neural network systems may be self-learning and trained, rather than explicitly programmed, and can perform significantly better in certain areas of problem solving, as compared to traditional computer programs. In some embodiments, the one or more neural networks may include multiple layers (e.g., where a signal path traverses from front layers to back layers). In some embodiments, back propagation techniques may be utilized by the neural networks, where forward stimulation is used to reset weights on the &#x201c;front&#x201d; neural units. In some embodiments, stimulation and inhibition for the one or more neural networks may be freer flowing, with connections interacting in a more chaotic and complex fashion. In some embodiments, the intermediate layers of the one or more neural networks include one or more convolutional layers, one or more recurrent layers, and/or other layers.</p><p id="p-0116" num="0115">The one or more neural networks may be trained (i.e., whose parameters are determined) using a set of training data (e.g., ground truths). The training data may include a set of training samples. Each sample may be a pair comprising an input object (typically an image, a measurement, a tensor or vector which may be called a feature tensor or vector) and a desired output value (also called the supervisory signal). A training algorithm analyzes the training data and adjusts the behavior of the neural network by adjusting the parameters (e.g., weights of one or more layers) of the neural network based on the training data. For example, given a set of N training samples of the form {(x<sub>1</sub>, y<sub>1</sub>), (x<sub>2</sub>, y<sub>2</sub>), . . . , (x<sub>N</sub>, y<sub>N</sub>)} such that x<sub>i </sub>is the feature tensor/vector of the i-th example and y<sub>i </sub>is its supervisory signal, a training algorithm seeks a neural network g: X&#x2192;Y, where X is the input space and Y is the output space. A feature tensor/vector is an n-dimensional tensor/vector of numerical features that represent some object (e.g., a complex electric field image). The tensor/vector space associated with these vectors is often called the feature or latent space. After training, the neural network may be used for making predictions using new samples.</p><p id="p-0117" num="0116">As described herein, the present method(s) and system(s) include a parameterized model (e.g., a machine learning model such as a neural network) that uses a variational encoder-decoder architecture. In the middle (e.g., middle layers) of the model (e.g., a neural network), the present model formulates a low-dimensional encoding (e.g., latent space) that encapsulates information in an input (e.g., a complex electric field image and/or other input associated with a pattern or other features of a semiconductor manufacturing process) to the model. The present system(s) and method(s) leverage the low dimensionality and compactness of the latent space to make determinations directly in the latent space.</p><p id="p-0118" num="0117">By way of a non-limiting example, <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates (variational) encoder-decoder architecture <b>50</b>. Encoder-decoder architecture <b>50</b> has an encoding portion <b>52</b> (an encoder) and a decoding portion <b>54</b> (a decoder). In the example shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, encoder-decoder architecture <b>50</b> may output predicted complex electric field images <b>56</b>.</p><p id="p-0119" num="0118">By way of another non-limiting example, <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates encoder-decoder architecture <b>50</b> within a neural network <b>62</b>. Encoder-decoder architecture <b>50</b> includes encoding portion <b>52</b> and decoding portion <b>54</b>. In <figref idref="DRAWINGS">FIG. <b>6</b></figref>, x represents encoder input (e.g., an input complex electric field image and/or extracted features of the input complex electric field image) and x&#x2032; represents decoder output (e.g., a predicted output image and/or predicted features of an output image). In some embodiments, x&#x2032; may represent an output from an intermediate layer of neural network (in comparison to a final output of the overall model), for example, and/or other outputs. In <figref idref="DRAWINGS">FIG. <b>6</b></figref>, z represents the latent space <b>64</b> and/or a low dimensional encoding (tensor/vector). In some embodiments, z is or is related to a latent variable.</p><p id="p-0120" num="0119">In some embodiments, the low dimensional encoding z represents one or more features of an input (e.g., a complex electric field image). The one or more features of the input may be considered key or critical features of the input. Features may be considered key or critical features of an input because they are relatively more predictive than other features of a desired output and/or have other characteristics, for example. The one or more features (dimensions) represented in the low dimensional encoding may be predetermined (e.g., by a programmer at the creation of the present machine learning model), determined by prior layers of the neural network, adjusted by a user via a user interface associated with a system described herein, and/or may be determined in by other methods. In some embodiments, a quantity of features (dimensions) represented by the low dimensional encoding may be predetermined (e.g., by the programmer at the creation of the present machine learning model), determined based on output from prior layers of the neural network, adjusted by the user via the user interface associated with a system described herein, and/or determined by other methods.</p><p id="p-0121" num="0120">It should be noted that even though a machine learning model, a neural network, and/or encoder-decoder architecture are mentioned throughout this specification, a machine learning model, a neural network, and encoder-decoder architecture are just examples, and the operations described herein may be applied to different parameterized models.</p><p id="p-0122" num="0121">As described above, process information (e.g., images, measurements, process parameters, metrology metrics, etc.) may be used to guide various manufacturing operations. Utilizing the relatively lower dimensionality of a latent space to predict and/or otherwise determine the process information may be faster, more efficient, require fewer computing resources, and/or have other advantages over prior methods for determining process information.</p><p id="p-0123" num="0122">The low dimensional latent space can be used advantageously for prediction of complex electric filed images, for example. Prediction of complex electric field images requires determination and/or prediction of a phase associated with a complex electric field image based on a corresponding amplitude measurement. Typical phase retrieval comprises recovering a complex (valued) electric field x&#x2208;C<sup>n </sup>from corresponding amplitude (e.g., intensity) measurements, y, (e.g., for a particular target) according to the equation:</p><p id="p-0124" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>y=|Ax|+&#x3f5;</i>&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0125" num="0000">where y&#x2208;R<sup>m </sup>is a measurement vector, A&#x2208;C<sup>m&#xd7;n </sup>is a measurement matrix, &#x3f5;&#x2208;R<sup>m </sup>is the measurement noise (with E representing the noise), x is the complex-valued electric field at a camera level that is perfectly in focus, A is a defocus operator that propagates the in-focus electric field to out-of-focus electric fields (as a consequence of introducing measurement diversity by moving the camera along z), y is the collection of amplitude measurements (e.g., the modulus of the electric fields at the camera for various de-focus positions (potentially polluted with random noise &#x3f5;)), m is a size of the measured signal, and n is the size of the retrieved complex-valued electric field. As an example: n may be a number of pixels for a camera (assuming one wants to retrieve the electric field for all pixels and not a subset), and m=K*n where K is a positive integer corresponding to a number of (through-focus) measurements (i.e. the number of different acquisitions one takes with the camera).</p><p id="p-0126" num="0123">Phase retrieval is difficult due to a large number of unknowns (e.g., on the order of 10<sup>6</sup>), nonlinearity, and non-convexity associated with the complex electric field (which combine to make phase retrieval a highly dimensional problem). Existing approaches for phase retrieval include introducing redundancy in the amplitude measurements (e.g., taking more amplitude measurements than dimensions of a true signal for x, such that m&#x3e;n, usually in the form of an oversampled Fourier transform, short-time Fourier transform, random Gaussian measurements, coded diffraction patterns using random masks or structured illuminations, wavelet transform, and/or Gabor frames), or exploiting prior knowledge about the complex electric field image (e.g., exploiting knowledge about the true signal x (prior information) such as sparsity, gradient sparsity (total variation), smoothness, compactness, non-negativity, etc.) to reduce the number of unknowns).</p><p id="p-0127" num="0124">As an example, phase retrieval is used to retrieve the aberrated complex-valued electric field at a camera (e.g., a sensor used to acquire an electric field image). <figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example camera <b>70</b> associated with obtaining complex electric field images (e.g., variables x, y, and A described above are related to camera <b>70</b>). <figref idref="DRAWINGS">FIG. <b>7</b></figref> also illustrates a pupil <b>72</b> (and associated aberrations <b>74</b>), a target <b>76</b>, and illumination <b>78</b>. Having access to the full field (both amplitude and phase) allows one to computationally remove aberrations <b>74</b> associated with a corresponding sensor (e.g., camera <b>70</b>) via a back-transform to pupil <b>72</b>, dividing out aberrations <b>74</b> (obtained from a separate calibration step), followed by a forward transform to camera <b>70</b>. The cleaned up image at camera <b>70</b> allows for a more robust overlay, and/or other metrology parameter, determination.</p><p id="p-0128" num="0125">These and other prior approaches require redundant data, making assumptions, are computationally intensive, and/or have other disadvantages. Redundant measurements lead to a decrease in throughput. Manual incorporation of assumptions and/or other prior information into the phase retrieval problem introduces a bias as it is not directly determined by the data. Also a computational cost of goods is high since the dimensionality of x is large, making the iterative phase retrieval operations very time consuming.</p><p id="p-0129" num="0126">Advantageously, the present system(s) and method(s) solve the phase retrieval problem using the parameterized model(s) described herein. The parameterized model is configured for predicting electric field images, predicting metrology metrics (e.g., instead of or in addition to the metrology apparatuses described above), and/or predicting other information. The parameterized model is configured to significantly reduce the dimensionality of the phase retrieval problem, which can then be solved using a simple gradient-based optimization scheme in few dimensions, and/or using other methods.</p><p id="p-0130" num="0127"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a summary method <b>80</b> of operations of a present method for predicting electric field images with a parameterized model. At an operation <b>82</b>, the parameterized model is trained. At an operation <b>84</b>, a latent space representation of an electric field image is determined for a given input. At an operation <b>86</b>, the electric field image is predicted with a parameterized model. At an operation <b>88</b>, one or more metrology metrics are determined based on the latent space representation of the electric field image, the predicted electric field image, and/or other information. The operations of method <b>80</b> presented below are intended to be illustrative. In some embodiments, method <b>80</b> may be accomplished with one or more additional operations not described, and/or without one or more of the operations discussed. For example, method <b>80</b> may not require determining one or more metrology metrics. Additionally, the order in which the operations of method <b>80</b> are illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> and described below is not intended to be limiting. In some embodiments, one or more portions of method <b>80</b> may be implemented (e.g., by simulation, modeling, etc.) in one or more processing devices (e.g., one or more processors). The one or more processing devices may include one or more devices executing some or all of the operations of method <b>80</b> in response to instructions stored electronically on an electronic storage medium. The one or more processing devices may include one or more devices configured through hardware, firmware, and/or software to be specifically designed for execution of one or more of the operations of method <b>80</b>, for example.</p><p id="p-0131" num="0128">At an operation <b>82</b>, the parameterized model is trained. The parameterized model may be a machine learning model comprising a neural network, encoder-decoder architecture, and/or other components. The encoder-decoder architecture may be variational encoder-decoder architecture and/or other architecture. In some embodiments, the parameterized model may be a variational deep neural network (DNN) that includes an encoder, a decoder, and/or other components. In some embodiments, this or similar structures for the parameterized model facilitate the inclusion of uncertainties in predictions from the parameterized model and/or has other advantages. For example, since the parameterized model is variational (as described herein), the parameterized model is able to output multiple prediction realizations for a single input. This in turn means that an uncertainty metric can be determined for those realizations, for example by calculating the standard deviation of those realizations.</p><p id="p-0132" num="0129">Operation <b>82</b> comprises training the variational encoder-decoder architecture with a probabilistic latent space, which generates realizations in an output space. In some embodiments, the latent space comprises low dimensional encodings (e.g., as described above). The parameterized model is trained with existing data (e.g., measured and/or simulated complex field images having an amplitude and a phase, corresponding metrology metrics, etc.) and/or other information. In some embodiments, the parameterized model may model (or model the functionality of) one or more of the pupil, the aberrations, the target, or the illumination shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, for example.</p><p id="p-0133" num="0130">When the parameterized model is trained, the latent space forms a compressed, continuous representation of encoded images (for example), which facilitates performance of various operations in the latent space. Advantageously, the latent space is low dimensional (e.g., compared to the image space). The various operations may include determination of latent space representations of complex electric field images (as described below), and/or other operations, for example. This may be computationally less expensive to perform in the latent space compared to the image space, due at least to the low dimensional value of the latent space (relative to the image space), for example.</p><p id="p-0134" num="0131">In some embodiments, the dimensional data in the latent space is encoded by the encoder of the encoder-decoder architecture. In some embodiments, predictions, and/or other output from the parameterized model are generated by the decoder of the encoder-decoder architecture. As described herein, the encoder comprises a portion of the parameterized model configured to transform model inputs into the dimensional data in the latent space, and the decoder comprises a different portion of the parameterized model configured to transform the dimensional data in the latent space into the output realizations. Transforming may include, for example, encoding, decoding, projecting, mapping, etc. By way of a non-limiting practical example, in some embodiments, model inputs may be complex electric field images and/or other information associated with a semiconductor device manufacturing process. The dimensional data in the latent space may comprise multi-dimensional tensors and/or vectors associated with model inputs. The output realizations may comprise predicted complex electric field images, metrology metrics, and/or other information. In some embodiments, the predicting comprises decoding, with one or more layers and/or one or more nodes of a neural network, a multi-dimensional tensor and/or vector of the dimensional data into an output realization.</p><p id="p-0135" num="0132">The parameterized model is trained with (known&#x2014;e.g., measured and/or modeled) electric field images, corresponding amplitude measurements, metrology metrics, and/or other information. The electric field images and corresponding amplitude measurements and/or metrology metrics may form input object/output value training pairs, for example (as described herein). The electric field images may be complex electric field images and/or other electric field images. A complex electric field image may include an amplitude, a phase, and/or other information. The amplitude may be the absolute value of the complex-valued electric field, for example. The amplitude may comprise an image intensity for example, and or other parameters that are a function of the amplitude. The phase may comprise the angle of the complex-valued electric field vector in the complex plane, for example. As such, the parameterized model is trained with corresponding amplitude and/or phase information for the electric field images, and/or other information.</p><p id="p-0136" num="0133">In some embodiments, operation <b>82</b> comprises training the parameterized model with a training set of complex electric field images. In some embodiments, the set of complex electric field images is generated during a through focus measurement and/or generated in other ways. For example, in some embodiments, the set of complex electric field images is generated by adjusting the position of the camera (e.g., camera <b>70</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>) obtaining the images up and/or down in a &#x201c;z&#x201d; direction (e.g., as shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>).</p><p id="p-0137" num="0134">In some embodiments, operation <b>82</b> comprises encoding, with the encoder, higher dimensional data associated with the electric field images into the dimensional data in the latent space. In some embodiments, operation <b>82</b> comprises encoding the complex electric field images, the measured amplitudes, the metrology metrics, and/or other information in the training set into the dimensional data in the latent space, and transforming the dimensional data in the latent space into recovered versions of the complex electric field images in the training set, predicting metrology metrics, and/or performing other operations to facilitate verification of the training.</p><p id="p-0138" num="0135">In some embodiments, operation <b>82</b> comprises iteratively providing additional complex electric field images as input to the parameterized model. The additional complex electric field images are determined based on an extent to which the recovered versions of the complex electric field images match the complex electric field images in the training set. For example, during training, if a recovered (or predicted) complex electric field image matches a corresponding input image, fewer or no additional complex electric field images may need to be provided for training Conversely, if a recovered (or predicted) complex electric field image does not match, or poorly matches a corresponding input image, several additional complex electric field images may need to be provided for training. This process may be repeated any number of times until the parameterized model is sufficiently trained.</p><p id="p-0139" num="0136"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an example of a parameterized model <b>90</b>. Parameterized model <b>90</b> may be a variational autoencoder, for example. Parameterized model <b>90</b> uses an encoder or encoder network <b>91</b> to encode inputs (x) <b>92</b> (e.g., complex electric field images with amplitude and phase, measured amplitudes, metrology metrics, and/or other inputs) into a continuous representation, also called latent space (z) <b>93</b>, and a decoder or decoder network <b>94</b> to generate a corresponding output (x&#x2032;) <b>95</b> (predicted images having a predicted amplitude and phase, and/or other outputs such as predicted metrology metrics). For example, encoder or encoder network <b>91</b> (E(x)) may be configured to convert an input image x&#x2208;C<sup>n </sup>into a lower-dimensional, real-valued continuous latent vector z&#x2208;R<sup>k </sup>(k&#x3c;&#x3c;n). C may represent the space of complex-valued numbers, R may represent the space of real-valued numbers, k may represent the dimension of the latent space, and n may represent the dimension of the input space. Encoder or encoder network <b>91</b> may also model the uncertainty of this latent vector. Decoder or decoder network <b>94</b> D(z) may be configured to convert the continuous latent vector back into a copy of the input image x&#x2032;.</p><p id="p-0140" num="0137">As shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, in some embodiments, parameterized model <b>90</b> includes a portion <b>96</b> configured to determine one or more metrology metrics (v) <b>97</b> (this is further described below). Training of both networks <b>91</b>, <b>94</b>, and portion <b>96</b>, is performed using input object/output value pairs (e.g., the electric field images and corresponding amplitude measurements and/or metrology metrics as described above).</p><p id="p-0141" num="0138">Parameterized model <b>90</b> learns to encode complex electric field images x in a low dimensional latent space. Given a low-dimensional input vector z, in the latent space, decoder or decoder network <b>94</b> is able to generate new samples D(z). The variational nature of parameterized model <b>90</b> enables the prediction of uncertainties, which in turn can be used for uncertainty guided training (active learning). This may include providing more training examples of complex electric field images to parameterized model <b>90</b> that generate large uncertainty. In some embodiments, a loss function for training parameterized model <b>90</b> can be a classical (L1, L2, etc.) norm or a similarity metric that is learned directly from the data using a discriminator network, for example.</p><p id="p-0142" num="0139">In some embodiments, parameterized model <b>90</b> may be fully trained. In these embodiments, operation <b>82</b> may be configured to improve parameterized model <b>90</b> by training parameterized model <b>90</b> with new and/or otherwise different input object/output value pairs. In some embodiments, parameterized model <b>90</b> may be partially trained or not trained. In these embodiments, operation <b>82</b> may facilitate at least partial training of parameterized model <b>90</b> including forming latent space <b>93</b>.</p><p id="p-0143" num="0140">Returning to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, at an operation <b>84</b>, a latent space representation of an (e.g., complex) electric field image is determined for a given input to the parameterized model. The given input comprises a measured amplitude associated with the electric field image, and/or other information. The latent space representation of the electric field image comprises a continuous latent tensor, vector, and/or other latent space representations. The latent space representation is determined based on dimensional data in the latent space of the parameterized model, and/or other information. In some embodiments, determining the latent space representation of the electric field image comprises minimizing a function constrained by a set of electric field images that could be predicted by the parameterized model based on the dimensional data in the latent space and the given input.</p><p id="p-0144" num="0141">For example, to eventually predict a complex electric field image (which includes both amplitude and phase), from amplitude only measurements, y, determining the latent space representation of the electric field image comprises minimizing the following objective function:</p><p id="p-0145" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msup>      <mi>x</mi>      <mo>*</mo>     </msup>     <mo>=</mo>     <mrow>      <munder>       <mi>argmin</mi>       <mrow>        <mi>x</mi>        <mo>&#x2208;</mo>        <mrow>         <mi>Range</mi>         <mo>&#x2061;</mo>         <mo>(</mo>         <mi>D</mi>         <mo>)</mo>        </mrow>       </mrow>      </munder>      <mo>&#x2062;</mo>      <msup>       <mrow>        <mo>&#xf605;</mo>        <mrow>         <mi>y</mi>         <mo>-</mo>         <mrow>          <semantics definitionURL="">           <mo>&#x2758;</mo>           <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>          </semantics>          <mi>Ax</mi>          <semantics definitionURL="">           <mo>&#x2758;</mo>           <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>          </semantics>         </mrow>        </mrow>        <mo>&#xf606;</mo>       </mrow>       <mn>2</mn>      </msup>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>2</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0146" num="0000">where Range (D) is the set of potential images that can be generated by a pre-trained decoder D. It should be noted that x&#x2032; (described above) represents any predicted image, and x* is the particular image that minimizes the norm in equation (2), i.e. the image containing the amplitude and phase that one is trying to retrieve. The minimization problem above can be equivalently formulated in the lower dimensional latent space representation as follows:</p><p id="p-0147" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msup>      <mi>z</mi>      <mo>*</mo>     </msup>     <mo>=</mo>     <mrow>      <munder>       <mi>argmin</mi>       <mrow>        <mi>z</mi>        <mo>&#x2208;</mo>        <msup>         <mi>R</mi>         <mi>k</mi>        </msup>       </mrow>      </munder>      <mo>&#x2062;</mo>      <msup>       <mrow>        <mo>&#xf605;</mo>        <mrow>         <mi>y</mi>         <mo>-</mo>         <mrow>          <semantics definitionURL="">           <mo>&#x2758;</mo>           <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>          </semantics>          <mrow>           <mi>AD</mi>           <mo>&#x2061;</mo>           <mo>(</mo>           <mi>z</mi>           <mo>)</mo>          </mrow>          <semantics definitionURL="">           <mo>&#x2758;</mo>           <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>          </semantics>         </mrow>        </mrow>        <mo>&#xf606;</mo>       </mrow>       <mn>2</mn>      </msup>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>3</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0148" num="0000">The variable z* is or represents the latent space representation of the electric field image. The continuous representation of the latent space facilitates gradient-based optimization to efficiently guide the search for optimal z*, for example.</p><p id="p-0149" num="0142">At an operation <b>86</b>, the electric field image is predicted with the parameterized model. The electric field image is predicted based on the latent space representation of the electric field image and/or other information. In some embodiments, predicting the electric field image based on the latent space representation of the electric field image (e.g., operation <b>86</b>) comprises passing the latent space representation of the electric field image through a decoder of the encoder-decoder architecture.</p><p id="p-0150" num="0143">For example, as shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, a decoder or decoder network <b>94</b> (or a portion of decoder network <b>94</b>) maps, projects, decodes, or otherwise transforms the low dimensional latent space representation of the electric field image in latent space <b>93</b> to output <b>95</b>. In some embodiments, output <b>95</b> is predicted based on the dimensional data in latent space <b>93</b>, the low dimensional latent space representation of the complex electric field image in latent space <b>93</b>, and/or other information. Output <b>95</b> is a predicted complex electric field image in this example. Put another way, once z* is found, the complex electric field image is predicted by a forward pass of the solution (to z*) through the decoder such that</p><p id="p-0151" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>x*=D</i>(<i>z</i>*).&#x2003;&#x2003;(4)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0152" num="0000">Since the optimization is performed on the lower dimensional latent space variable z, the computational cost of goods is reduced substantially compared to prior methods. Other advantages are contemplated.</p><p id="p-0153" num="0144">Returning to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, at operation <b>88</b>, one or more metrology metrics are determined based on the predicted electric field image, the low dimensional latent space representation of the (complex) electric field image, the dimensional data in the latent space, and/or other information. Determination may include prediction and/or other determinations. For example, in some embodiments, a metrology metric such as overlay may be predicted and/or otherwise determined based on an average of an intensity range of one or more predicted complex electric field images over a region of interest. As another example, in some embodiments, a metrology metric may be predicted and/or otherwise determined based on the latent space representation of the electric field image. In some embodiments, determining the one or more metrology metrics based on the latent space representation of the electric field image comprises providing the latent space representation of the electric field image to a regression network and/or other predictor that is included in or separate from the parameterized model. In some embodiments, other low dimensional data in the latent space may be provided to such a regression network for prediction and/or other determination of the one or more metrology metrics.</p><p id="p-0154" num="0145">For example, as shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, portion <b>96</b> of parameterized model <b>90</b> (comprising a regression network R(z) in this example) is configured to determine one or more metrology metrics <b>97</b> based on the low-dimensional data in latent space <b>93</b>. In the example shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the one or more metrology metrics comprise overlay (v). The overlay may be determined based on a latent vector in the latent space (e.g., the latent space representation of the complex electric field image) and/or other information. For example, a metrology metric may be predicted and/or otherwise determined by a forward pass of z* through the regression network (e.g., portion <b>96</b>) such that:</p><p id="p-0155" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>v*=R</i>(<i>z</i>*).&#x2003;&#x2003;(5)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0156" num="0000">It should be noted that v (described herein) can be any predicted metrology metric (such as overlay), and v* is the particular metrology metric that corresponds to image x*.</p><p id="p-0157" num="0146">As shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, in some embodiments, parameterized model <b>90</b> may be configured such that additional information which is intrinsically embedded in the original signal x (e.g., input <b>92</b>) can be extracted via an additional step such as, for example, feeding it to a regression network (e.g., portion <b>96</b>). In this way, metrology information can be extracted simultaneously with phase retrieval. Here, the example metrology metric is overlay, but the method can be extended to any additional scalar parameter (e.g., one or more metrology metrics and/or other metrics) that is embedded in x. In some embodiments, the one or more metrology metrics comprise one or more of overlay, a critical dimension, a reconstruction of a three dimensional profile of features of a substrate, a dose or focus of a lithography apparatus at a moment when the features of the substrate were printed with the lithography apparatus, alignment, and/or other metrology metrics.</p><p id="p-0158" num="0147">By way of a non-limiting practical example, the present systems, methods, apparatus, etc., described herein, may be used for determining one or more metrology metrics (e.g., overlay as described above) for semiconductor manufacturing processes using a parameterized model (e.g., <b>90</b> shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>) comprising one or more machine learning algorithms (e.g., encoder network <b>91</b>, decoder network <b>94</b>, portion <b>96</b>, etc. shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>). A feature vector (e.g., low dimensional encoded latent space data) associated with an unknown electric field image may be determined, encoded, and/or otherwise received (e.g., via control circuitry that is part of a computer system such as computer system <b>100</b> shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref> described below). As described herein, the feature vector represents values corresponding to a latent space representation of an electric field image (e.g., see latent space <b>93</b> in <figref idref="DRAWINGS">FIG. <b>9</b></figref>). Using the control circuitry, the feature vector may be input into (e.g., provided to) a machine learning model or a portion of a machine learning model (e.g., decoder network <b>94</b> shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>). In some embodiments, the machine learning model may comprise a generative classifier (e.g., a decoder) used to identify a known electric field image based on labeled feature vectors corresponding to latent space representations of electric field images. The known electric field image is a higher dimensional representation of the latent space representation of the electric field image (e.g., as described herein). In some embodiments, again using the control circuitry, a first prediction from the machine learning model is received. The first prediction may indicate whether the first feature vector corresponds to the known electric field image. In response to the first prediction indicating that the first feature vector corresponds to the known electric field image, a recommendation for a metrology metric for a semiconductor manufacturing process corresponding to the known electric field image may be generated for display on a user interface (e.g., see display <b>112</b> shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref> and described below). This operation may be performed by portion <b>96</b> of parameterized model <b>90</b>, for example, and/or other components described herein.</p><p id="p-0159" num="0148">Returning to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, in some embodiments, a metrology apparatus may perform some or all of operation <b>88</b> and/or the other operations described herein. For example, in some embodiments, a metrology apparatus may be configured to determine one or more metrology metrics for a semiconductor manufacturing process. The apparatus may comprise one or more processors configured to: determine, based on dimensional data in a latent space of a parameterized model, a latent space representation of an electric field image for a given input; predict, with the parameterized model, the electric field image based on the latent space representation of the electric field image; and determine the one or more metrology metrics for the semiconductor manufacturing process based on the predicted electric field image. In some embodiments, the metrology apparatus may be included in lithographic cell (e.g., as described herein) or the metrology apparatus may stand alone.</p><p id="p-0160" num="0149">In some embodiments, operation <b>88</b> comprises determining, based on one or more predicted electric field images, one or more metrology metrics, and/or other information, adjustments to semiconductor manufacturing process parameters for patterning substrate geometry as part of a semiconductor manufacturing process. In some embodiments, the one or more semiconductor manufacturing process parameters comprise one or more of a mask design, a pupil shape, a dose, a focus, and/or other parameters. In some embodiments, the one or more semiconductor manufacturing process parameters comprise the mask design such that the mask design is changed from a first mask design to a second mask design. Other examples, related to several different aspects of an integrated circuit fabrication process, and/or other processes, are contemplated.</p><p id="p-0161" num="0150">The principles described herein (e.g., utilizing the relatively lower dimensionality of a latent space in a trained parameterized model to predict and/or otherwise determine process information) may have multiple additional applications (e.g., in addition to and/or instead of the complex electric field prediction application shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref> and described above). For example, the present system(s) and method(s) may be used to harmonize data from different process sensors and/or tools that may be different, even for the same measured or imaged target.</p><p id="p-0162" num="0151">The present method(s) and system(s) are configured to determine, in a latent space of a parameterized model (where there are fewer dimensions of data to analyze compared to the number of dimensions in the raw data from the different sensors and/or tools), a latent space representation of a given input to the parameterized model. The latent space representation is transformed, based on a reference latent space representation for the given input, into a transformed latent space representation of the given input; and process information is predicted based on the transformed latent space representation of the given input. For example, the given input may be associated with a target, and received from one of a plurality of different sensors and/or tools configured to generate the given input. The transforming and predicting are configured such that predicted and/or otherwise determined process information (e.g., images, measurements, process parameters, metrology metrics, etc.) from the parameterized model, for the target, is the same, independent of which one of the sensors and/or tools generated the given input.</p><p id="p-0163" num="0152">In some embodiments, the given input is associated with a target, and received from one of a plurality of target characterization apparatuses configured to generate the given input. The target characterization apparatuses may include various sensors and/or tools configured to generate data about a target. The data may include images, values for various metrics, and/or other information. In some embodiments, the given input comprises one or more of an input image, an input process measurement and/or series of process measurements, and/or other information. In some embodiments, the latent space representation may be a tensor, a vector, and/or other latent space representations (e.g., something that has fewer dimensions than the number of dimensions associated with the given input).</p><p id="p-0164" num="0153">In some embodiments, the transforming comprises one or more mathematical operations performed on the latent space representation of the given input. In some embodiments, the transforming is performed in the latent space. The mathematical operations may include translation (e.g., in x, y, z, or other equivalent dimensions in the latent space); a (higher order) polynomial modeling covering all (or a subset of the) dimensions such as scaling, rotation, etc.; and/or other operations.</p><p id="p-0165" num="0154">In some embodiments, the reference latent space representation comprises a weighted combination of previously received inputs to the parameterized model, an average of latent space representations of previously received inputs to the parameterized model, a latent space representation of an input from a specific target characterization apparatus configured to generate the given input, and/or other latent space representations. For example, a user may have a particular sensor and/or other tool that the user thinks consistently provides the most accurate and/or otherwise best data for a target (e.g., a &#x201c;golden tool&#x201d;). The reference latent space representation may be an encoding of data (e.g., an image and/or other data) from that sensor and/or other tool.</p><p id="p-0166" num="0155">By way of a non-limiting example, the given input may comprise an image (e.g., any image associated with or generated during semiconductor manufacturing). The image may be encoded by encoder architecture of the parameterized model into a low dimensional vector that represents the image in the latent space. The various dimensions of the vector may be translated within the latent space such that the vector that represents the input image matches the reference latent space representation (as one example&#x2014;other transformations are possible). The transformed vector may then be decoded into the predicted process information.</p><p id="p-0167" num="0156">In some embodiments, the predicted process information comprises one or more of a predicted image, a predicted process measurement (e.g., a metric value), and/or other information. In some embodiments, the predicted process measurement comprises one or more of a metrology metric, an xyz position, a dimension, an electric field, a wavelength, an illumination and/or detection pupil, a bandwidth, an illumination and/or detection polarization angle, an illumination and/or a detection retardance angle, and/or other process measurements.</p><p id="p-0168" num="0157">In this example, the parameterized model may have variational encoder-decoder architecture with a probabilistic latent space, which generates realizations in an output space. In some embodiments, the latent space comprises low dimensional encodings (e.g., as described above). The parameterized model is trained with existing data (e.g., measured and/or simulated data (e.g., images, values for various metrics, etc.) from different target characterization apparatuses (e.g., sensors, tools, etc.) for the same target, etc.) and/or other information. The training data may include, for example, different data from a wide range of different target characterization apparatuses, but for the same target. As described above, the dimensional data in the latent space is encoded by the encoder of the encoder-decoder architecture. In some embodiments, predictions, and/or other output from the parameterized model are generated by the decoder of the encoder-decoder architecture.</p><p id="p-0169" num="0158">In addition, the training of the parameterized model can be extended for (matching) characterization apparatuses for any type of measurement (field, pupil, position, height, etc.) The training of the parameterized model may also be extended by adding target characterization apparatus constants (e.g., machine constants from calibrations and/or hardware specifications) to the training data. In such embodiments, the latent space transformation may potentially be used to determine root causes for the variation between characterization apparatuses. For example, a systematic offset in positioning (such as an xyz position of a stage and/or optical components) can translate into an overlay error.</p><p id="p-0170" num="0159">As another example, the present method(s) and system(s) may be configured to determine, based on dimensional data in the latent space of a parameterized model (again, where there are fewer dimensions of data to analyze compared to the number of dimensions in raw data from the different experimental iterations), a latent space representation of an optimum set of process parameters associated with a given input to the parameterized model, and predict process information based on the latent space representation of the optimum set of process conditions.</p><p id="p-0171" num="0160">In some embodiments, the given input comprises one or more of a defined design parameter, a defined metrology measurement recipe parameter, and/or other defined information for a target. The defined design parameters and/or the defined metrology measurement recipe parameters may be unchangeable because of design requirements (e.g., a certain size, shape, location, and/or other requirement for one or more features of a target design), machine capability, materials used during the manufacturing process, scientific limitations (e.g., the laws of physics, chemistry, etc.), required relationships between elements of a target design, required steps in a manufacturing recipe, for example, or other input.</p><p id="p-0172" num="0161">In some embodiments, the predicted process information comprises one or more of a design parameter, a metrology measurement recipe parameter, and/or other parameters, for a target. In some embodiments, the design parameter comprises one or more of a critical dimension, a pitch, a segmentation pitch, line geometry, contact geometry, hole geometry, and/or other information associated with the target. In some embodiments, the metrology measurement recipe parameter comprises one or more of a wavelength, a bandwidth, an aperture, an illumination and/or detection pupil, a bandwidth, an illumination and/or detection polarization angle, an illumination and/or a detection retardance angle, a dose, and/or other recipe parameters for measuring the target.</p><p id="p-0173" num="0162">In some embodiments, the optimum set of process parameters define optimum measurement conditions for measuring a metrology metric for a target. The optimum measurement conditions may be the ideal measurement conditions for a given target for the measurement of a specific metrology metric, for example, and/or other measurement conditions. In some embodiments, the optimum set of process parameters comprise one or more of an intensity, a contrast, an edge response, a diffraction efficiency, an overlay sensitivity, and/or other process parameters. By way of a non-limiting example, each process parameter may have an ideal working range: intensity: in the middle of the measurement camera range; contrast: high contrast with surrounding features; edge response: as low as possible overshoot at edges; diffraction efficiency: as high as possible (but linked to intensity); overlay sensitivity: above a minimum threshold, e.g. absolute sensitivity &#x3e;0.2 (on a scale of 0-2), and also linked to intensity. Given these constraints, it can be determined how these parameters project back onto the measurement conditions. This will give a probability distribution over the measurement conditions where it matches best with the optimum process parameters.</p><p id="p-0174" num="0163">Put another way, a user may input defined target design or metrology measurement recipe parameters into the parameterized model. The parameterized model may be configured such that there is an optimum set of process parameters defining optimum measurement conditions for the input. The parameterized model may then predict (determine), based on the input, the optimum set of process parameters, and/or other information, one or more (e.g., recommended) design parameters and/or metrology recipe parameters for the input. In other words, the model is configured to output the best possible target design (e.g., parameters that define this best possible target design), and/or best possible measurement settings (e.g., parameters) for a metrology apparatus, given the limitations input into the model by the user (based on what the model has been trained to know about the optimum set of process parameters for that input).</p><p id="p-0175" num="0164">In this example, the parameterized model may have variational encoder-decoder architecture with a probabilistic latent space, which generates realizations in an output space. In some embodiments, the latent space comprises low dimensional encodings (e.g., as described above). The parameterized model is trained with existing data (e.g., measured and/or simulated target designs, corresponding known measurement conditions and/or metrology metrics, etc.) and/or other information. As described above, the dimensional data in the latent space is encoded by the encoder of the encoder-decoder architecture. In some embodiments, predictions, and/or other output from the parameterized model are generated by the decoder of the encoder-decoder architecture. It should be noted that parameterized model may be trained for predicting and/or otherwise determining any target design and/or metrology measurement recipe parameters. For example, the parameterized model may be used for an overlay target design and/or measurement recipe parameters, a target after etch image and/or measurement recipe parameters, an image based overlay target design and/or measurement recipe parameters, a focus target design and/or measurement recipe parameters, an alignment target design and/or measurement recipe parameters, and/or other targets and/or measurement recipe parameters.</p><p id="p-0176" num="0165">As described above, one parameterized model may be trained to predict complex electric field images, transform data from different sensors and/or tools such that data for the same target matches, and determine an optimum target design and/or manufacturing recipe; or these different operations may be performed by different parameterized models. The different applications (predicting complex electric field images, transforming data from different sensors and/or tools such that data for the same target from different sensors and/or tools still matches, and determining an optimum target design and/or manufacturing recipe) may be used together, or they may be used separately.</p><p id="p-0177" num="0166">As an example, the present system(s) and method(s) may be configured to predict process information such as matching data for the same target from different sensors and/or tools and optimum target designs and/or manufacturing recipes (e.g., a combination of two of the three applications described herein) with a single parameterized model. In other words, the parameterized model may be configured to co-optimize a target design and measurement recipe parameters. This may include determining, in the latent space of the parameterized model, a latent space representation of a given input to the parameterized model (e.g., as described above). The latent space representation of the given input may be transformed, based on a reference latent space representation for the given input, into a transformed latent space representation of the given input (e.g., as described above). A latent space representation of an optimum set of process parameters associated with the given input may be determined based on the transformed latent space representation of the given input (e.g., as described above), and the process information may be predicted based on the transformed latent space representation of the given input and the latent space representation of the optimum set of process parameters associated with the given input.</p><p id="p-0178" num="0167">As another example, the present system(s) and method(s) may be configured to predict process information such as complex electric field images, matching data for the same target from different sensors and/or tools, and optimum target designs and/or manufacturing recipes (e.g., a combination of all three applications described herein) with a single parameterized model. This may include determining, in the latent space of the parameterized model, a latent space representation of a given input to the parameterized model (e.g., as described herein), transforming the latent space representation of the given input, based on a reference latent space representation for the given input, into a transformed latent space representation of the given input; determining, based on the transformed latent space representation of the given input, a latent space representation of an electric field image for the given input; determining, based on the transformed latent space representation, a latent space representation of an optimum set of process parameters associated with the given input; predicting the process information based on the transformed latent space representation of the given input, the latent space representation of the electric field image, and the latent space representation of the optimum set of process parameters associated with the given input; and/or other operations.</p><p id="p-0179" num="0168">It should be noted that although the description herein often refers to a (single) latent space, this should not be considered limiting. The principles described herein may be applied with and/or to any number of latent spaces. For example, the systems, methods, (metrology) apparatus, non-transitory computer readable media, etc., described herein may be configured such that a determination, based on dimensional data in one or more latent spaces of a parameterized model (or one or more parameterized models), of a latent space representation of an electric field image is made for a given input to the parameterized model. The electric field image may be determined based on the latent space representation of the electric field image and or other information. As described above, in some embodiments, the electric field image comprises a complex electric field image having an amplitude and a phase, and the given input comprises a measured amplitude associated with the complex electric field image. Determining the latent space representation of the electric field image comprises minimizing a function constrained by a set of electric field images that could be predicted by the parameterized model based on the dimensional data in the one or more latent spaces and the given input.</p><p id="p-0180" num="0169">The one or more latent spaces may be used in series (e.g., for analyzing data and/or making a first prediction, then a second, etc.), in parallel (e.g., for analyzing data and/or making predictions simultaneously), and/or in other ways. Advantageously, individual latent spaces of the parameterized model may be more robust compared to a single latent space. For example, separate latent spaces may be focused on specific properties of a dataset, e.g. one for a retrieving phase, another for classification based on measurement parameters, etc. One combined latent space may be configured to capture all possibilities, while in the case of separate latent spaces, each individual latent space may be configured to (e.g., trained to) focus on a specific topic and/or aspect of a dataset. Individual latent spaces may potentially be simpler but be better at capturing information (e.g., when set up accordingly).</p><p id="p-0181" num="0170">In some embodiments, the one or more latent spaces may comprise at least two latent spaces, a plurality of latent spaces, and/or other quantities of latent spaces, with individual latent spaces corresponding to different regimes of the parameterized model. The different regimes of the parameterized model may comprise an encoding regime (e.g., <b>91</b> shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>), a decoding regime (e.g., <b>94</b> shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>), a complex electric field parameter determination regime (e.g., a regime that determines inputs <b>92</b> shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref> and/or other features of an input electric field image), a phase retrieval regime (e.g., similar to and/or the same as <b>94</b> shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>), and/or other regimes. In some embodiments, the different regimes may correspond to different operations performed by a parameterized model (or one or more parameterized models). By way of a non-limiting example, in some embodiments, multiple latent spaces may be used in parallel, e.g., one for the image encoding and/or decoding, another for predicting aberrations, another for recipe settings (e.g., predicting or recommending process set points), etc. Individual latent spaces that correspond to different regimes may be more robust compared to a single latent space associated with multiple regimes.</p><p id="p-0182" num="0171">In some embodiments, individual latent spaces may be associated with different independent parameters and corresponding dimensional data for the given input to the parameterized model. Individual latent spaces that correspond to different independent parameters may also be more robust compared to a single latent space associated with multiple parameters. For example, in some embodiments, the present system(s) and method(s) may include or utilize a first latent space, for phase retrieval as described herein, and a second separate latent space that deals with disturbances which are tool-dependent (i.e., due to optical differences). The first latent space may be configured to (e.g., trained to) perform the phase retrieval, and independent of this first latent space, the second latent space may be configured to (e.g., trained to) deal with differences in an image caused by tool specific properties. It should be noted that this is just one possible example, and is not intended to be limiting. Many other possible examples are contemplated.</p><p id="p-0183" num="0172"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram that illustrates a computer system <b>100</b> that can perform and/or assist in implementing the methods, flows, systems or the apparatus disclosed herein. Computer system <b>100</b> includes a bus <b>102</b> or other communication mechanism for communicating information, and a processor <b>104</b> (or multiple processors <b>104</b> and <b>105</b>) coupled with bus <b>102</b> for processing information. Computer system <b>100</b> also includes a main memory <b>106</b>, such as a random access memory (RAM) or other dynamic storage device, coupled to bus <b>102</b> for storing information and instructions to be executed by processor <b>104</b>. Main memory <b>106</b> also may be used for storing temporary variables or other intermediate information during execution of instructions to be executed by processor <b>104</b>. Computer system <b>100</b> further includes a read only memory (ROM) <b>108</b> or other static storage device coupled to bus <b>102</b> for storing static information and instructions for processor <b>104</b>. A storage device <b>110</b>, such as a magnetic disk or optical disk, is provided and coupled to bus <b>102</b> for storing information and instructions.</p><p id="p-0184" num="0173">Computer system <b>100</b> may be coupled via bus <b>102</b> to a display <b>112</b>, such as a cathode ray tube (CRT) or flat panel or touch panel display for displaying information to a computer user. An input device <b>114</b>, including alphanumeric and other keys, is coupled to bus <b>102</b> for communicating information and command selections to processor <b>104</b>. Another type of user input device is cursor control <b>116</b>, such as a mouse, a trackball, or cursor direction keys for communicating direction information and command selections to processor <b>104</b> and for controlling cursor movement on display <b>112</b>. This input device typically has two degrees of freedom in two axes, a first axis (e.g., x) and a second axis (e.g., y), that allows the device to specify positions in a plane. A touch panel (screen) display may also be used as an input device.</p><p id="p-0185" num="0174">According to one embodiment, portions of one or more methods described herein may be performed by computer system <b>100</b> in response to processor <b>104</b> executing one or more sequences of one or more instructions contained in main memory <b>106</b>. Such instructions may be read into main memory <b>106</b> from another computer-readable medium, such as storage device <b>110</b>. Execution of the sequences of instructions contained in main memory <b>106</b> causes processor <b>104</b> to perform the process steps described herein. One or more processors in a multi-processing arrangement may also be employed to execute the sequences of instructions contained in main memory <b>106</b>. In an alternative embodiment, hard-wired circuitry may be used in place of or in combination with software instructions. Thus, the description herein is not limited to any specific combination of hardware circuitry and software.</p><p id="p-0186" num="0175">The term &#x201c;computer-readable medium&#x201d; as used herein refers to any medium that participates in providing instructions to processor <b>104</b> for execution. Such a medium may take many forms, including but not limited to, non-volatile media, volatile media, and transmission media. Non-volatile media include, for example, optical or magnetic disks, such as storage device <b>110</b>. Volatile media include dynamic memory, such as main memory <b>106</b>. Transmission media include coaxial cables, copper wire and fiber optics, including the wires that comprise bus <b>102</b>. Transmission media can also take the form of acoustic or light waves, such as those generated during radio frequency (RF) and infrared (IR) data communications. Common forms of computer-readable media include, for example, a floppy disk, a flexible disk, hard disk, magnetic tape, any other magnetic medium, a CD-ROM, DVD, any other optical medium, punch cards, paper tape, any other physical medium with patterns of holes, a RAM, a PROM, and EPROM, a FLASH-EPROM, any other memory chip or cartridge, a carrier wave as described hereinafter, or any other medium from which a computer can read.</p><p id="p-0187" num="0176">Various forms of computer readable media may be involved in carrying one or more sequences of one or more instructions to processor <b>104</b> for execution. For example, the instructions may initially be borne on a magnetic disk of a remote computer. The remote computer can load the instructions into its dynamic memory and send the instructions over a telephone line using a modem. A modem local to computer system <b>100</b> can receive the data on the telephone line and use an infrared transmitter to convert the data to an infrared signal. An infrared detector coupled to bus <b>102</b> can receive the data carried in the infrared signal and place the data on bus <b>102</b>. Bus <b>102</b> carries the data to main memory <b>106</b>, from which processor <b>104</b> retrieves and executes the instructions. The instructions received by main memory <b>106</b> may optionally be stored on storage device <b>110</b> either before or after execution by processor <b>104</b>.</p><p id="p-0188" num="0177">Computer system <b>100</b> may also include a communication interface <b>118</b> coupled to bus <b>102</b>. Communication interface <b>118</b> provides a two-way data communication coupling to a network link <b>120</b> that is connected to a local network <b>122</b>. For example, communication interface <b>118</b> may be an integrated services digital network (ISDN) card or a modem to provide a data communication connection to a corresponding type of telephone line. As another example, communication interface <b>118</b> may be a local area network (LAN) card to provide a data communication connection to a compatible LAN. Wireless links may also be implemented. In any such implementation, communication interface <b>118</b> sends and receives electrical, electromagnetic or optical signals that carry digital data streams representing various types of information.</p><p id="p-0189" num="0178">Network link <b>120</b> typically provides data communication through one or more networks to other data devices. For example, network link <b>120</b> may provide a connection through local network <b>122</b> to a host computer <b>124</b> or to data equipment operated by an Internet Service Provider (ISP) <b>126</b>. ISP <b>126</b> in turn provides data communication services through the worldwide packet data communication network, now commonly referred to as the &#x201c;Internet&#x201d; <b>128</b>. Local network <b>122</b> and Internet <b>128</b> both use electrical, electromagnetic or optical signals that carry digital data streams. The signals through the various networks and the signals on network link <b>120</b> and through communication interface <b>118</b>, which carry the digital data to and from computer system <b>100</b>, are exemplary forms of carrier waves transporting the information.</p><p id="p-0190" num="0179">Computer system <b>100</b> can send messages and receive data, including program code, through the network(s), network link <b>120</b>, and communication interface <b>118</b>. In the Internet example, a server <b>130</b> might transmit a requested code for an application program through Internet <b>128</b>, ISP <b>126</b>, local network <b>122</b> and communication interface <b>118</b>. One such downloaded application may provide all or part of a method described herein, for example. The received code may be executed by processor <b>104</b> as it is received, and/or stored in storage device <b>110</b>, or other non-volatile storage for later execution. In this manner, computer system <b>100</b> may obtain application code in the form of a carrier wave.</p><p id="p-0191" num="0180"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a detailed view of an alternative design for the lithographic projection apparatus LA shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. (<figref idref="DRAWINGS">FIG. <b>1</b></figref> relates to DUV radiation because lenses are used and a transparent reticle is used, while <figref idref="DRAWINGS">FIG. <b>11</b></figref> relates to a lithographic apparatus which uses EUV radiation because mirrors and a reflective reticle are used.) As shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the lithographic projection apparatus can include the source SO, the illumination system IL, and the projection system PS. The source SO is configured such that a vacuum environment can be maintained in an enclosing structure <b>220</b> of the source SO. An EUV (for example) radiation emitting plasma <b>210</b> may be formed by a discharge produced plasma source. EUV radiation may be produced by a gas or vapor, for example Xe gas, Li vapor or Sn vapor in which plasma <b>210</b> is created to emit radiation in the EUV range of the electromagnetic spectrum. The plasma <b>210</b> is created by, for example, an electrical discharge causing at least partially ionized plasma. Partial pressures of, for example, 10 Pa of Xe, Li, Sn vapor or any other suitable gas or vapor may be required for efficient generation of the radiation. In some embodiments, a plasma of excited tin (Sn) is provided to produce EUV radiation.</p><p id="p-0192" num="0181">The radiation emitted by plasma <b>210</b> is passed from a source chamber <b>211</b> into a collector chamber <b>212</b> via an optional gas barrier or contaminant trap <b>230</b> (in some cases also referred to as contaminant barrier or foil trap) which is positioned in or behind an opening in source chamber <b>211</b>. The contaminant trap <b>230</b> may include a channel structure. Chamber <b>211</b> may include a radiation collector CO which may be a grazing incidence collector, for example. Radiation collector CO has an upstream radiation collector side <b>251</b> and a downstream radiation collector side <b>252</b>. Radiation that traverses collector CO can be reflected off a grating spectral filter <b>240</b> to be focused in a virtual source point IF along the optical axis indicated by the line &#x2018;O&#x2019;. The virtual source point IF is commonly referred to as the intermediate focus, and the source is arranged such that the intermediate focus IF is located at or near an opening <b>221</b> in the enclosing structure <b>220</b>. The virtual source point IF is an image of the radiation emitting plasma <b>210</b>.</p><p id="p-0193" num="0182">Subsequently, the radiation traverses the illumination system IL, which may include a facetted field mirror device <b>22</b> and a facetted pupil mirror device <b>24</b> arranged to provide a desired angular distribution of the radiation beam <b>21</b>, at the patterning device MA, as well as a desired uniformity of radiation intensity at the patterning device MA. Upon reflection of the radiation beam <b>21</b> at the patterning device MA, held by the support structure (table) T, a patterned beam <b>26</b> is formed and the patterned beam <b>26</b> is imaged by the projection system PS via reflective elements <b>28</b>, <b>30</b> onto a substrate W held by the substrate table WT. More elements than shown may generally be present in illumination optics unit IL and projection system PS. The grating spectral filter <b>240</b> may optionally be present, depending upon the type of lithographic apparatus, for example. Further, there may be more mirrors present than those shown in the figures, for example there may be 1-6 additional reflective elements present in the projection system PS than shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>.</p><p id="p-0194" num="0183">Collector optic CO, as illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, is depicted as a nested collector with grazing incidence reflectors <b>253</b>, <b>254</b> and <b>255</b>, just as an example of a collector (or collector mirror). The grazing incidence reflectors <b>253</b>, <b>254</b> and <b>255</b> are disposed axially symmetric around the optical axis O and a collector optic CO of this type may be used in combination with a discharge produced plasma source, often called a DPP source.</p><p id="p-0195" num="0184">Further embodiments are disclosed in the subsequent list of numbered clauses:</p><p id="p-0196" num="0000">1. A method for determining one or more metrology metrics for a semiconductor manufacturing process, the method comprising:</p><p id="p-0197" num="0185">determining, based on dimensional data in a latent space of a parameterized model, a latent space representation of an electric field image for a given input;</p><p id="p-0198" num="0186">predicting, with the parameterized model, the electric field image based on the latent space representation of the electric field image; and</p><p id="p-0199" num="0187">determining the one or more metrology metrics for the semiconductor manufacturing process based on the predicted electric field image.</p><p id="p-0200" num="0000">2. The method of clause 1, wherein the electric field image comprises a complex electric field image having an amplitude and a phase.<br/>3. The method of any of clauses 1-2, wherein the one or more determined metrology metrics comprise one or more of overlay, a critical dimension, a reconstruction of a three dimensional profile of features of a substrate, or a dose or focus of a lithography apparatus at a moment when the features of the substrate were printed with the lithography apparatus.<br/>4. The method of any of clauses 1-3, wherein the electric field image comprises a complex electric field image, and wherein the given input comprises a measured amplitude associated with the complex electric field image.<br/>5. The method of clause 4, wherein the amplitude comprises an intensity.<br/>6. The method of any of clauses 1-5, further comprising adjusting one or more semiconductor manufacturing process parameters based on the determined one or more metrology metrics.<br/>7. A method for predicting electric field images with a parameterized model, the method comprising:</p><p id="p-0201" num="0188">determining, based on dimensional data in a latent space of the parameterized model, a latent space representation of an electric field image for a given input to the parameterized model; and</p><p id="p-0202" num="0189">predicting the electric field image based on the latent space representation of the electric field image.</p><p id="p-0203" num="0000">8. The method of clause 7, wherein the electric field image comprises a complex electric field image having an amplitude and a phase.<br/>9. The method of clause 8, wherein the given input comprises a measured amplitude associated with the complex electric field image.<br/>10. The method of clause 9, wherein the amplitude comprises an intensity.<br/>11. The method of any of clauses 7-10, wherein determining the latent space representation of the electric field image comprises minimizing a function constrained by a set of electric field images that could be predicted by the parameterized model based on the dimensional data in the latent space and the given input.<br/>12. The method of clause 11, wherein the latent space representation of the electric field image comprises a tensor.<br/>13. The method of any of clauses 7-12, wherein the parameterized model is a machine learning model.<br/>14. The method of any of clauses 7-13, wherein the parameterized model comprises encoder-decoder architecture.<br/>15. The method of clause 14, wherein the encoder-decoder architecture comprises variational encoder-decoder architecture, the method further comprising training the variational encoder-decoder architecture with a probabilistic latent space, which generates realizations in an output space.<br/>16. The method of clause 15, wherein the latent space comprises low dimensional encodings.<br/>17. The method of any of clauses 14-16, wherein the dimensional data in the latent space is encoded by an encoder of the encoder-decoder architecture.<br/>18. The method of any of clauses 14-17, further comprising training the parameterized model with a training set of complex electric field images.<br/>19. The method of clause 18, wherein the set of complex electric field images is generated on basis of a through focus measurement and optionally a complex electric field image reconstruction algorithm.<br/>20. The method of clause 18 or 19, wherein the training comprises encoding the complex electric field images in the training set into the dimensional data in the latent space, and transforming the dimensional data in the latent space into recovered versions of the complex electric field images in the training set to facilitate verification of the training.<br/>21. The method of clause 20, further comprising iteratively providing additional complex electric field images as input to the parameterized model, the additional complex electric field images determined based on an extent to which the recovered versions of the complex electric field images match the complex electric field images in the training set.<br/>22. The method of any of clauses 16-21, further comprising encoding, with the encoder, higher dimensional data associated with the electric field images into the dimensional data in the latent space.<br/>23. The method of any of clauses 14-22, wherein predicting the electric field image based on the latent space representation of the electric field image comprises passing the latent space representation of the electric field image through a decoder of the encoder-decoder architecture.<br/>24. The method of any of clauses 7-23, further comprising determining a metrology metric based on the latent space representation of the electric field image.<br/>25. The method of clause 24, wherein determining the metrology metric based on the latent space representation of the electric field image comprises providing the latent space representation of the electric field image to a regression network that is included in or separate from the parameterized model.<br/>26. The method of clause 24 or 25, wherein the metrology metric is overlay.<br/>27. The method of any of clauses 7-26, further comprising correcting for aberrations associated with a metrology apparatus based on the latent space representation of the electric field image and/or the predicted electric field image.<br/>28. The method of any of clauses 7-27, further comprising determining, based on the predicted electric field image, adjustments to semiconductor manufacturing process parameters for patterning substrate geometry as part of a semiconductor manufacturing process.<br/>29. A non-transitory computer readable medium having instructions thereon, the instructions when executed by a computer implementing the method of any of clauses 1-28.<br/>30. A metrology apparatus configured to determine one or more metrology metrics for a semiconductor manufacturing process, the apparatus comprising one or more processors configured to:</p><p id="p-0204" num="0190">determine, based on dimensional data in a latent space of a parameterized model, a latent space representation of an electric field image for a given input;</p><p id="p-0205" num="0191">predict, with the parameterized model, the electric field image based on the latent space representation of the electric field image; and</p><p id="p-0206" num="0192">determine the one or more metrology metrics for the semiconductor manufacturing process based on the predicted electric field image.</p><p id="p-0207" num="0000">31. A lithographic cell comprising a metrology apparatus, the metrology apparatus configured to:</p><p id="p-0208" num="0193">determine, based on dimensional data in a latent space of a parameterized model, a latent space representation of an electric field image for a given input;</p><p id="p-0209" num="0194">predict, with the parameterized model, the electric field image based on the latent space representation of the electric field image; and</p><p id="p-0210" num="0195">determine one or more metrology metrics for a semiconductor manufacturing process based on the predicted electric field image.</p><p id="p-0211" num="0000">32. A method for predicting process information with a parameterized model, comprising:</p><p id="p-0212" num="0196">determining, in a latent space of the parameterized model, a latent space representation of a given input to the parameterized model;</p><p id="p-0213" num="0197">transforming the latent space representation of the given input, based on a reference latent space representation for the given input, into a transformed latent space representation of the given input; and</p><p id="p-0214" num="0198">predicting the process information based on the transformed latent space representation of the given input.</p><p id="p-0215" num="0000">33. The method of clause 32, wherein the given input is associated with a target, and received from one of a plurality of target characterization apparatuses configured to generate the given input; and</p><p id="p-0216" num="0199">wherein the transforming and predicting are configured such that the predicted process information for the target is the same, independent of which one of the target characterization apparatuses generated the given input.</p><p id="p-0217" num="0000">34. The method of clauses 32 or 33, wherein the transforming comprises one or more mathematical operations performed on the latent space representation of the given input.<br/>35. The method of any of clauses 32-34, wherein the transforming is performed in the latent space.<br/>36. The method of any of clauses 32-35, wherein the reference latent space representation comprises a weighted combination and/or an average of latent space representations of previously received inputs to the parameterized model, or a latent space representation of an input from a specific target characterization apparatus configured to generate the given input.<br/>37. The method of any of clauses 32-36, wherein the process information and the given input are associated with a semiconductor manufacturing process.<br/>38. The method of any of clauses 32-37, wherein the predicted process information comprises one or more of a predicted image, or a predicted process measurement.<br/>39. The method of clause 37, wherein the predicted process measurement comprises one or more of a metrology metric, an xyz position, a dimension, an electric field, a wavelength, an illumination and/or detection pupil, a bandwidth, an illumination and/or detection polarization angle, or an illumination and/or a detection retardance angle.<br/>40. The method of any of clauses 32-39, wherein the given input comprises one or more of an input image, or an input process measurement.<br/>41. A method for predicting process information with a parameterized model, comprising:</p><p id="p-0218" num="0200">determining, based on dimensional data, in a latent space of the parameterized model, a latent space representation of an optimum set of process parameters associated with a given input to the parameterized model; and</p><p id="p-0219" num="0201">predicting the process information based on the latent space representation of the optimum set of process conditions.</p><p id="p-0220" num="0000">42. The method of clause 41, wherein the predicted process information comprises one or more of a design parameter, or a metrology measurement recipe parameter, for a target.<br/>43. The method of clause 42, wherein the design parameter comprises one or more of a critical dimension, a pitch, a segmentation pitch, line geometry, contact geometry, or hole geometry associated with the target.<br/>44. The method of clause 42, wherein the metrology measurement recipe parameter comprises one or more of a wavelength, a bandwidth, an aperture, an illumination and/or detection pupil, a bandwidth, an illumination and/or detection polarization angle, an illumination and/or a detection retardance angle, or a dose for measuring the target.<br/>45. The method of any of clauses 41-44, wherein the optimum set of process parameters define optimum measurement conditions for measuring a metrology metric for a target.<br/>46. The method of clause 45, wherein the optimum set of process parameters comprise one or more of an intensity, a contrast, an edge response, a diffraction efficiency, or an overlay sensitivity.<br/>47. The method of any of clauses 41-46, wherein the given input comprises one or more of a defined design parameter, or a defined metrology measurement recipe parameter, for a target.<br/>48. The method of any of clauses 32-47, wherein the parameterized model is a machine learning model.<br/>49. The method of any of clauses 42-48, wherein the parameterized model comprises encoder-decoder architecture.<br/>50. The method of any of clauses 32-49, wherein the latent space comprises low dimensional encodings.<br/>51. A method for predicting process information with a parameterized model, comprising:</p><p id="p-0221" num="0202">determining, in a latent space of the parameterized model, a latent space representation of a given input to the parameterized model;</p><p id="p-0222" num="0203">transforming the latent space representation of the given input, based on a reference latent space representation for the given input, into a transformed latent space representation of the given input;</p><p id="p-0223" num="0204">determining, based on the transformed latent space representation, a latent space representation of an optimum set of process parameters associated with the given input; and</p><p id="p-0224" num="0205">predicting the process information based on the transformed latent space representation of the given input and the latent space representation of the optimum set of process parameters associated with the given input.</p><p id="p-0225" num="0000">52. A method for predicting process information with a parameterized model, comprising:</p><p id="p-0226" num="0206">determining, in a latent space of the parameterized model, a latent space representation of a given input to the parameterized model;</p><p id="p-0227" num="0207">transforming the latent space representation of the given input, based on a reference latent space representation for the given input, into a transformed latent space representation of the given input;</p><p id="p-0228" num="0208">determining, based on the transformed latent space representation of the given input, a latent space representation of an electric field image for the given input;</p><p id="p-0229" num="0209">determining, based on the transformed latent space representation, a latent space representation of an optimum set of process parameters associated with the given input; and</p><p id="p-0230" num="0210">predicting the process information based on the transformed latent space representation of the given input, the latent space representation of the electric field image, and the latent space representation of the optimum set of process parameters associated with the given input.</p><p id="p-0231" num="0000">53. A non-transitory computer readable medium having instructions thereon, the instructions when executed by a computer implementing the method of any of clauses 32-52.<br/>54. A non-transitory computer readable medium having instructions thereon, the instructions when executed by a computer causing the computer to:</p><p id="p-0232" num="0211">determine, based on dimensional data in one or more latent spaces of a parameterized model, a latent space representation of an electric field image for a given input to the parameterized model; and</p><p id="p-0233" num="0212">predict the electric field image based on the latent space representation of the electric field image.</p><p id="p-0234" num="0000">55. The medium of clause 54, wherein the one or more latent spaces comprise at least two latent spaces.<br/>56. The medium of any of clauses 54 or 55, wherein the one or more latent spaces comprise a plurality of latent spaces, with individual latent spaces of the plurality of latent spaces corresponding to different regimes of the parameterized model.<br/>57. The medium of clause 56, wherein the different regimes of the parameterized model comprise an encoding regime, a decoding regime, a complex electric field parameter determination regime, and/or a phase retrieval regime.<br/>58. The medium of any of clauses 54-57, wherein the one or more latent spaces comprise at least two latent spaces associated with different independent parameters and corresponding dimensional data for the given input to the parameterized model.<br/>59. The medium of any of clauses 54-58, wherein the electric field image comprises a complex electric field image having an amplitude and a phase, and the given input comprises a measured amplitude associated with the complex electric field image.<br/>60. The medium of any of clauses 54-59, wherein determining the latent space representation of the electric field image comprises minimizing a function constrained by a set of electric field images that could be predicted by the parameterized model based on the dimensional data in the one or more latent spaces and the given input.<br/>61. A method for predicting electric field images with a parameterized model, the method comprising:</p><p id="p-0235" num="0213">determining, based on dimensional data in one or more latent spaces of the parameterized model, a latent space representation of an electric field image for a given input to the parameterized model; and</p><p id="p-0236" num="0214">predicting the electric field image based on the latent space representation of the electric field image.</p><p id="p-0237" num="0000">62. The method of clause 61, wherein the one or more latent spaces comprise at least two latent spaces.<br/>63. The method of any of clauses 61 or 62, wherein the one or more latent spaces comprise a plurality of latent spaces, with individual latent spaces of the plurality of latent spaces corresponding to different regimes of the parameterized model.<br/>64. The method of clause 63, wherein the different regimes of the parameterized model comprise an encoding regime, a decoding regime, a complex electric field parameter determination regime, and/or a phase retrieval regime.<br/>65. The method of any of clauses 61-64, wherein the one or more latent spaces comprise at least two latent spaces associated with different independent parameters and corresponding dimensional data for the given input to the parameterized model.<br/>66. The method of any of clauses 61-65, wherein the electric field image comprises a complex electric field image having an amplitude and a phase, and the given input comprises a measured amplitude associated with the complex electric field image.<br/>67. The method of any of clauses 61-66, wherein determining the latent space representation of the electric field image comprises minimizing a function constrained by a set of electric field images that could be predicted by the parameterized model based on the dimensional data in the one or more latent spaces and the given input.<br/>68. A metrology apparatus comprising one or more processors configured to:</p><p id="p-0238" num="0215">determine, based on dimensional data in one or more latent spaces of a parameterized model, a latent space representation of an electric field image for a given input to the parameterized model; and</p><p id="p-0239" num="0216">predict the electric field image based on the latent space representation of the electric field image.</p><p id="p-0240" num="0000">69. The apparatus of clause 68, wherein the one or more latent spaces comprise at least two latent spaces.<br/>70. The apparatus of any of clauses 68 or 69, wherein the one or more latent spaces comprise a plurality of latent spaces, with individual latent spaces of the plurality of latent spaces corresponding to different regimes of the parameterized model.<br/>71. The apparatus of clause 70, wherein the different regimes of the parameterized model comprise an encoding regime, a decoding regime, a complex electric field parameter determination regime, and/or a phase retrieval regime.<br/>72. The apparatus of any of clauses 68-71, wherein the one or more latent spaces comprise at least two latent spaces associated with different independent parameters and corresponding dimensional data for the given input to the parameterized model.<br/>73. The apparatus of any of clauses 68-72, wherein the electric field image comprises a complex electric field image having an amplitude and a phase, and the given input comprises a measured amplitude associated with the complex electric field image.<br/>74. The apparatus of any of clauses 68-73, wherein determining the latent space representation of the electric field image comprises minimizing a function constrained by a set of electric field images that could be predicted by the parameterized model based on the dimensional data in the one or more latent spaces and the given input.<br/>75. A method for determining one or more metrology metrics for semiconductor manufacturing processes using machine learning algorithms, comprising:</p><p id="p-0241" num="0217">receiving, using control circuitry, a feature vector associated with an unknown electric field image, wherein the feature vector represents values corresponding to a latent space representation of an electric field image;</p><p id="p-0242" num="0218">inputting, using the control circuitry, the feature vector into a machine learning model, wherein the machine learning model comprises a generative classifier used to identify a known electric field image based on labeled feature vectors corresponding to latent space representations of electric field images, wherein the known electric field image is a higher dimensional representation of the latent space representation of the electric field image;</p><p id="p-0243" num="0219">receiving, using the control circuitry, a first prediction from the machine learning model, wherein the first prediction indicates whether the first feature vector corresponds to the known electric field image; and</p><p id="p-0244" num="0220">in response to the first prediction indicating that the first feature vector corresponds to the known electric field image, generating for display, on a user interface, a recommendation for a metrology metric for a semiconductor manufacturing process corresponding to the known electric field image.</p><p id="p-0245" num="0221">The concepts disclosed herein may simulate or mathematically model any generic imaging system for imaging sub wavelength features, and may be especially useful with emerging imaging technologies capable of producing increasingly shorter wavelengths. Emerging technologies already in use include EUV (extreme ultra violet), DUV lithography that is capable of producing a 193 nm wavelength with the use of an ArF laser, and even a 157 nm wavelength with the use of a Fluorine laser. Moreover, EUV lithography is capable of producing wavelengths within a range of 20-5 nm by using a synchrotron or by hitting a material (either solid or a plasma) with high energy electrons in order to produce photons within this range.</p><p id="p-0246" num="0222">While the concepts disclosed herein may be used for imaging on a substrate such as a silicon wafer, it shall be understood that the disclosed concepts may be used with any type of lithographic imaging systems, e.g., those used for imaging on substrates other than silicon wafers, and/or metrology systems. In addition, the combination and sub-combinations of disclosed elements may comprise separate embodiments. For example, predicting a complex electric field image and determining a metrology metric such as overlay may be performed by the same parameterized model and/or different parameterized models. These features may comprise separate embodiments, and/or these features may be used together in the same embodiment.</p><p id="p-0247" num="0223">Although specific reference may be made in this text to embodiments of the invention in the context of a metrology apparatus, embodiments of the invention may be used in other apparatus. Embodiments of the invention may form part of a mask inspection apparatus, a lithographic apparatus, or any apparatus that measures or processes an object such as a wafer (or other substrate) or mask (or other patterning device). These apparatus may be generally referred to as lithographic tools. Such a lithographic tool may use vacuum conditions or ambient (non-vacuum) conditions.</p><p id="p-0248" num="0224">Although specific reference may have been made above to the use of embodiments of the invention in the context of optical lithography, it will be appreciated that the invention, where the context allows, is not limited to optical lithography and may be used in other applications, for example imprint lithography. While specific embodiments of the invention have been described above, it will be appreciated that the invention may be practiced otherwise than as described. The descriptions above are intended to be illustrative, not limiting. Thus it will be apparent to one skilled in the art that modifications may be made to the invention as described without departing from the scope of the claims set out below.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230004096A1-20230105-M00001.NB"><img id="EMI-M00001" he="5.25mm" wi="76.20mm" file="US20230004096A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230004096A1-20230105-M00002.NB"><img id="EMI-M00002" he="5.67mm" wi="76.20mm" file="US20230004096A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><claims id="claims"><claim id="CLM-01-15" num="01-15"><claim-text><b>1</b>.-<b>15</b>. (canceled)</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A method comprising:<claim-text>determining, based on dimensional data in a latent space of a parameterized model, a latent space representation of an electric field image for a given input;</claim-text><claim-text>predicting, with the parameterized model, the electric field image based on the latent space representation of the electric field image; and</claim-text><claim-text>determining one or more metrology metrics for a semiconductor manufacturing process based on the predicting.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the electric field image comprises a complex electric field image having an amplitude and a phase.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein:<claim-text>the electric field image comprises a complex electric field image, and</claim-text><claim-text>the given input comprises a measured amplitude associated with the complex electric field image, and</claim-text><claim-text>the amplitude comprises an intensity.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising:<claim-text>adjusting one or more semiconductor manufacturing process parameters based on the determined one or more metrology metrics.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein:<claim-text>the determining the latent space representation of the electric field image comprises minimizing a function constrained by a set of electric field images predicted by the parameterized model based on the dimensional data in the latent space and the given input, and</claim-text><claim-text>the latent space representation of the electric field image comprises a tensor.</claim-text></claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the parameterized model is a machine learning model.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the parameterized model comprises encoder-decoder architecture.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the encoder-decoder architecture comprises variational encoder-decoder architecture and the method further comprises:<claim-text>training the variational encoder-decoder architecture with a probabilistic latent space that generates realizations in an output space.</claim-text></claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the latent space comprises low dimensional encodings.</claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the dimensional data in the latent space is encoded by an encoder of the encoder-decoder architecture.</claim-text></claim><claim id="CLM-00026" num="00026"><claim-text><b>26</b>. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, further comprising:<claim-text>training the parameterized model with a training set of complex electric field images.</claim-text></claim-text></claim><claim id="CLM-00027" num="00027"><claim-text><b>27</b>. The method of <claim-ref idref="CLM-00026">claim 26</claim-ref>, wherein the training comprises:<claim-text>encoding the complex electric field images in the training set into the dimensional data in the latent space,</claim-text><claim-text>transforming the dimensional data in the latent space into recovered versions of the complex electric field images in the training set to facilitate verification of the training, and</claim-text><claim-text>iteratively providing additional complex electric field images as input to the parameterized model, the additional complex electric field images determined based on an extent to that the recovered versions of the complex electric field images match the complex electric field images in the training set.</claim-text></claim-text></claim><claim id="CLM-00028" num="00028"><claim-text><b>28</b>. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the predicting the electric field image based on the latent space representation of the electric field image comprises passing the latent space representation of the electric field image through a decoder of the encoder-decoder architecture.</claim-text></claim><claim id="CLM-00029" num="00029"><claim-text><b>29</b>. A method comprising:<claim-text>determining, based on dimensional data in one or more latent spaces of the parameterized model, a latent space representation of an electric field image for a given input to the parameterized model; and</claim-text><claim-text>predicting the electric field image based on the latent space representation of the electric field image.</claim-text></claim-text></claim><claim id="CLM-00030" num="00030"><claim-text><b>30</b>. A metrology apparatus comprising one or more processors configured to perform operations comprising:<claim-text>determining, based on dimensional data in a latent space of a parameterized model, a latent space representation of an electric field image for a given input;</claim-text><claim-text>predicting, with the parameterized model, the electric field image based on the latent space representation of the electric field image; and</claim-text><claim-text>determining one or more metrology metrics for a semiconductor manufacturing process based on the predicted electric field image.</claim-text></claim-text></claim></claims></us-patent-application>
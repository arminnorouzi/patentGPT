<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004154A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004154</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17782516</doc-number><date>20201130</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>DE</country><doc-number>10 2019 132 759.8</doc-number><date>20191203</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>0038</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>2201</main-group><subgroup>0213</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">METHOD FOR REMOTELY CONTROLLED DRIVING OF A MOTOR VEHICLE COMPRISING A TELEOPERATOR, COMPUTER PROGRAM PRODUCT, AND TELEOPERATION DRIVING SYSTEM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Valeo Schalter und Sensoren GmbH</orgname><address><city>Bietigheim-Bissingen</city><country>DE</country></address></addressbook><residence><country>DE</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Musabini</last-name><first-name>Antonyo</first-name><address><city>Bobigny</city><country>FR</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Valeo Schalter und Sensoren GmbH</orgname><role>03</role><address><city>Bietigheim-Bissingen</city><country>DE</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/EP2020/083870</doc-number><date>20201130</date></document-id><us-371c12-date><date>20220603</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method for remotely controlled driving of a motor vehicle, characterized in that by the motor vehicle a transport travel with at least one passenger in the motor vehicle is performed. The driving of the motor vehicle during the transport drive, at least in phases, is performed in teleoperated manner by an external teleoperator from an operator location. During the teleoperated driving environmental information of the motor vehicle is transmitted to the operator location and displayed at least on one display unit for the teleoperator. During the teleoperated driving a viewing direction of the teleoperator on the display unit is determined, and is displayed on the display unit where the teleoperator gazes. This image region, at which the teleoperator gazes, is visually marked on a display unit in the motor vehicle.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="95.25mm" wi="158.75mm" file="US20230004154A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="194.82mm" wi="159.26mm" orientation="landscape" file="US20230004154A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="191.26mm" wi="131.74mm" orientation="landscape" file="US20230004154A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="236.22mm" wi="155.02mm" file="US20230004154A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><p id="p-0002" num="0001">One aspect of the invention relates to a method for remotely controlled driving of a motor vehicle. A further aspect of the invention relates to a computer program product. Yet a further aspect of the invention relates to an electronic teleoperation driving system for a motor vehicle.</p><p id="p-0003" num="0002">A teleoperated driving of motor vehicles is known. In this connection solutions are known, in which a user of the vehicle himself leaves the vehicle and performs the maneuvering operation of the vehicle with a manually operated remote control, in particular for parking. This, however, is possible only for small and short maneuvering operations, such as for instance parking. Moreover the user performing the remote control needs to be positioned in the immediate environment of the vehicle.</p><p id="p-0004" num="0003">Moreover also already teleoperated operations as remotely controlled driving of a motor vehicle are known. In these an operator is arranged remote from the vehicle. In particular in order to be able to maneuver a vehicle also more comprehensively and longer, also over long distances and in general traffic. Such teleoperated driving operations for driving a motor vehicle are relatively complex. They therefore require a high level of attention in order to be able to safely perform this teleoperated driving of the motor vehicle.</p><p id="p-0005" num="0004">It is the task of the present invention to provide a method, in which a specific remotely controlled driving of a motor vehicle can be performed more safely. Accordingly, it is also the task to provide a computer program product as well as an electronic teleoperation driving system.</p><p id="p-0006" num="0005">One aspect of the invention relates to a method for remotely controlled driving of a motor vehicle. With the motor vehicle a transport travel with a passenger in the motor vehicle is performed. The driving of the motor vehicle during the transport travel or drive at least in phases is performed in teleoperated manner by an external operator, who can also be designated as teleoperator, from an operator location. During the teleoperated driving environmental information of the motor vehicle, which is captured by at least one optical capture unit of the motor vehicle, is transmitted to the operator location. This transmitted environmental information is displayed at least on one display unit at the operator location for the operator. During the teleoperated driving a viewing direction of the operator to the display unit is determined. It is captured at which image region of the image displayed on the display unit the operator gazes. The image region, at which the operator gazes on his display unit, is marked in an image, which is displayed on a display unit in the motor vehicle. By such configuration it is facilitated for the passenger in the motor vehicle to recognize where the operator gazes at the operator location, which is external thereto and remote therefrom, or at which image region he directs his gaze. Thereby for the passenger in the motor vehicle it can be recognized, whether the operator has an attentive gaze for teleoperated driving of the vehicle. Thus, it can also be recognized by the passenger in the motor vehicle whether the teleoperator performs the teleoperated driving of the motor vehicle in an attentive manner. In particular thereby it can also be recognized whether the teleoperator directs his gaze at least to one image region in the image, which is important for the driving of the motor vehicle. In particular thus it can be recognized by the passenger in the motor vehicle whether the teleoperator has an eye on critical subregions of the environmental region or not. In particular has an eye on such image regions, which are relevant to the continued safe driving of the motor vehicle. In particular thus it is also possible that the passenger in the motor vehicle himself can assess whether the teleoperator performs a safely teleoperated driving of the motor vehicle or not. Thus, also a confidence-building measure for the passenger in the motor vehicle is facilitated during such teleoperated driving of a motor vehicle.</p><p id="p-0007" num="0006">In particular also a method for observing a teleoperator is presented as one aspect of the invention. During this observing of the teleoperator his viewing direction is captured at his operator location, which is external to and remote from the motor vehicle, and is evaluated. In this connection in particular the viewing direction on an image, which is displayed on a display unit at the operator location, is determined. In particular therein this viewing direction is captured with an eye-tracking device at the operator location. In particular it is envisaged in this connection that a point of intersection of a vector of the viewing direction of the operator with the image plane is determined. Based on this point of intersection it can then also be determined, which image region the operator has an eye on. In this method for observing a teleoperator then at least one subregion of the image, which is displayed on the display unit at the operator location, is also displayed on the display unit in the motor vehicle. On the image of the display unit of the motor vehicle that image region is visually marked, which the teleoperator on the image displayed on the display unit at the operator location presently has an eye on. This is performed in particular during a transport drive of a passenger with the motor vehicle. In particular thus during the observation of the viewing direction of the teleoperator the image region observed by the viewing direction is displayed on the display unit of the motor vehicle. In particular this is effected in an image, which displays the observed image region of the operator at least partially.</p><p id="p-0008" num="0007">On the whole it is facilitated by the invention to perform a safe teleoperated driving of a motor vehicle.</p><p id="p-0009" num="0008">In the case of a teleoperated driving of a motor vehicle the operator location commonly is within a building. This is usually arranged remote and far away from the motor vehicle to be driven in a teleoperated manner. Consequently the teleoperator cannot see the motor vehicle directly. Here the most varied distances, up to many hundreds or many thousands of kilometers can be given. In particular at one operator location at least one display unit is arranged. Preferably these are several separate display units. It is preferably envisaged that in each case individual images taken by one or several capture units of the motor vehicle are displayed on these several display units. Thus, it may be envisaged that on a display unit the image taken by a first optical capture unit of the motor vehicle is displayed. On a second display unit at the operator location an image can be displayed, which is taken by a second optical capture unit of the motor vehicle. On a third display unit at the operator location an image can be displayed, which is taken by a third optical capture unit of the motor vehicle. For instance it may be envisaged that on a fourth display unit at the operator location an image is represented, which is captured by a fourth optical capture unit of the motor vehicle. In particular the optical capture units can be arranged in such a way on the motor vehicle that circumferentially around the motor vehicle quasi an uninterrupted detection range is generated. Thus, the said environmental region around the motor vehicle can be captured and displayed.</p><p id="p-0010" num="0009">In an advantageous embodiment a teleoperation driving system in addition to the operator location comprises a wireless communication link. For instance in this connection a wireless communication link to a computing unit, in particular a computing center, may be provided. Via same corresponding data can be deposited or exchanged. For instance here also a connection with the internet can be given. Equally it is possible that moreover a wireless communication link between the motor vehicle and the internet is effected. For instance this may be the case via a mobile radio channel. In particular this may be effected on the basis of the 5G mobile radio standard.</p><p id="p-0011" num="0010">At the operator location in particular also a steering device is given. This steering device, which may for instance be a steering wheel, is actuated by the teleoperator. Thereby, a situation is suggested to the teleoperator as if he also actually in the motor vehicle would operate corresponding function components and thus perform a teleoperating close to reality.</p><p id="p-0012" num="0011">In particular it is also envisaged that at the operator location an acoustic communication device is arranged. Thereby an acoustic communication between the teleoperator and the passenger in the motor vehicle can be performed.</p><p id="p-0013" num="0012">It may also be envisaged that at the motor vehicle a further optical capture unit is arranged, which is not a camera. In particular by the at least one camera the taking of at least one image, as it has been set out in the above, is performed. The motor vehicle moreover can comprise at least one laser scanner. By the laser scanner, which may for instance be a LIDAR sensor, the position of an object in the environmental region can be precisely determined. In particular thereby the determination of a position of an object in the environmental region in a more accurate manner than with a camera is possible. Instead of a laser scanner, however, also other sensors can be used in order to determine the position of an object in the environmental region of the motor vehicle.</p><p id="p-0014" num="0013">In particular on the basis of the environmental information obtained through the laser scanner it is also possible to determine that image region more precisely, at which the operator gazes on the image in his display unit. In this way it is possible that respective areas of a field of vision or of a detection range of a capture unit are assigned to respective image regions of the image on the display unit. In the same way also the environmental data provided by the laser scanner can be assigned to corresponding image regions of the image on the display unit. This means if then the teleoperator gazes at a certain region or at a certain position on the display unit, it can easily be determined, which real position in the environmental region of the vehicle corresponds to this position looked at by the teleoperator. Thus, the output of the laser scanner, namely the environmental data, can be projected onto the field of vision or the detection range of the optical capture unit of the motor vehicle, configured as camera, in order to determine which pixels of the image on the display unit correspond to which portions of the objects in the real world in the environmental region of the motor vehicle. Thus an even more precise determination can be performed as to which image region the teleoperator actually gazes at.</p><p id="p-0015" num="0014">Preferably on the display unit in the motor vehicle at least in portions the image is displayed, which is displayed on the display unit at the operator location. In particular an image is displayed on the display unit in the motor vehicle, on which that image region is comprised, at which the operator gazes on his display unit. Thus, at any time during the transport drive it can be recognized by the passenger in the motor vehicle, what the operator presently directs his main visual focus at.</p><p id="p-0016" num="0015">Preferably it is envisaged that the image displayed on the display unit at the operator location is synchronized in time with the image displayed on the display unit in the motor vehicle. By such design a display particularly close to reality and quasi congruent on the two display units is facilitated. In particular the passenger in the motor vehicle thus can recognize where the viewing direction of the operator in the operator location currently is directed. Thus for the passenger it is immediately recognizable where the operator is currently looking. In an advantageous embodiment it is envisaged that an image of the environmental region, which is taken by the optical capture unit of the motor vehicle, is displayed on the display unit at the operator location. This is a further very advantageous embodiment in order to perform a safe teleoperated driving of the motor vehicle. Thus the operator on his display unit by the respective image representations recognizes the environmental region of the motor vehicle in real time. The teleoperated driving of the motor vehicle thereby is possible in such a way as if the teleoperator were sitting directly in the motor vehicle himself. Thereby a very realistic and safe teleoperated driving of the motor vehicle is achieved.</p><p id="p-0017" num="0016">Preferably it is envisaged that an image taken of the environmental region is performed by the optical capture unit as video recording and a display of the video recording is displayed on the display unit of the operator location. Basically, with the formulation that an image is taken and/or an image is displayed, both the representation of static frames as well as the representation of a video is understood. By the representation of a video thus a dynamic representation process can be effected. Thus, the environmental region, which is perceived during the movement of the motor vehicle and which is dynamically changing, can be displayed both to the teleoperator and to the passenger in the motor vehicle on the respective display units. Also thereby a safe and realistic teleoperated driving is facilitated. In particularly advantageous way it is thereby also facilitated to visually mark the dynamic representation of the viewing direction of the teleoperator and/or a change in the viewing direction in real time on the image on the display unit in the motor vehicle. Thus, it is also rendered possible that the observing of the teleoperator is represented to the passenger in the motor vehicle in real time. Rather, quasi indirectly by the visual marking in the image on the display unit of the motor vehicle the looking around of the teleoperator at the operator location is displayed.</p><p id="p-0018" num="0017">Thus a situation is quasi optically represented to the passenger in the motor vehicle, in which he quasi from the image perspective of the teleoperator recognizes those image regions, at which the teleoperator gazes. Thus, it is optically displayed to the passenger in the motor vehicle how a teledriver of the vehicle perceives an environmental region.</p><p id="p-0019" num="0018">In an advantageous embodiment it is envisaged that the viewing direction of the teleoperator during the teleoperated driving of the motor vehicle is permanently captured. In particular also a change in the viewing direction is dynamically captured. In particular this change in the viewing direction and/or the static viewing direction of the teleoperator is permanently displayed on the display unit in the motor vehicle. In particular this is effected in the image, which is displayed on the display unit in the motor vehicle.</p><p id="p-0020" num="0019">It may be envisaged that a marking of the current viewing direction and/or a change in the viewing direction of the teleoperator on a display unit in the motor vehicle is effected in dynamically changeable manner. In particular it may be envisaged here that this dynamic display is effected synchronized with the actual real way of behaviour of the teleoperator at the operator location. In particular here a marking of the current viewing direction and/or a change in the viewing direction is displayed in real time on the image of the display unit in the motor vehicle. Also thereby an immediate recognition of the actual observation situation of the teleoperator in the motor vehicle is easily recognized. Also thereby a high safety for the passenger in the motor vehicle is achieved. He therefore knows, in particular invariably, how the actual mode of observation and way of behaviour of the teleoperator at the quasi presently indicated point in time actually is.</p><p id="p-0021" num="0020">Preferably it is envisaged that the marking of the image region, at which the operator on his display unit currently gazes, in the image displayed on the display unit in the motor vehicle, is signaled in color. Additionally or instead, also a region boundary contour can be visually signaled. A color signaling can be easily recognized by the passenger in the motor vehicle. Thus, it can also very rapidly be recognized whether the teleoperator has an eye on the environmental regions relevant for the safe driving of the motor vehicle by a teleoperation. A color signaling can for instance be performed to the effect that an image region is represented as a surface in one signaling color. In particular it is envisaged that this color signaling is opaque or transparent. This means that the environmental region, which is represented by the image region in the image, continues to be recognizable through the color signaling. Thus the entire displayed image is not undesirably disrupted or rendered incomprehensible by color spots. Rather the entire environmental region to be represented by the image continues to be recognizable. Superimposed thereon is the color signaling. Thus the surface area can unambiguously be visually recognized, which is currently observed by the teleoperator. By displaying only one region boundary contour of the observed image region in an additional or alternative embodiment, in an equally easily comprehensible way and without obstructing other image information, that image region can be marked, at which the teleoperator is currently looking. A boundary contour may for instance be a solid line or a dashed line. In particular if due to environmental influences, such as a corresponding brightness, the color signaling is not suitable, such a display of only the region boundary contour can be effected. Equally this then is possible, if that environmental region, at which the teleoperator in the image is presently gazing and which then is to be signaled in color on the display unit in the motor vehicle, is of such significance and relevance that such, in particular opaque, color superimposition in not desired. Thus in particular depending on specific criteria it can also be decided by the teleoperating driving system how the respective visual marking in the image on the display unit in the motor vehicle should be effected. Equally it is possible that depending on traffic situations and/or objects, which were detected in the environmental region of the motor vehicle and/or depending on a previous viewing direction of the teleoperator and/or depending on the duration of how long the teleoperator has looked in one viewing direction and/or the duration for which the teleoperator presently gazes in one viewing direction, also a change of color signaling and/or a change of region boundary contour occur. For instance here a change in color and/or a dynamic flashing of the color signaling may occur. The same in analogy may happen with a region boundary contour. Thus not only a static optical marking of the viewing direction of the teleoperator is performed. Rather also past and/or current ways of behaviour of the teleoperator and/or current and/or future situations in the environmental region of the motor vehicle with regard to the optical marking of the viewing direction can be taken into consideration. Thus a visual marking of the viewing direction of the teleoperator on the display unit of the vehicle that is better adjusted to the situation is facilitated. Thus different attention states and/or different safety-critical states in driving the motor vehicle can be taken into consideration. In particular thereby possibly the passenger in the motor vehicle can be informed in a more unambiguous way about the degree of attention in the light of these above-named evaluation criteria. In particular the passenger then depending thereon can better decide for himself how to evaluate the attention state of the teleoperator. In particular depending thereon then also a way of acting of the passenger can be better assessed. In particular this relates to a corresponding speech communication with the teleoperator. In particular with regard to his/her viewing direction and/or his/her attention state.</p><p id="p-0022" num="0021">Advantageously in this connection the passenger can also better recognize and/or evaluate whether the teleoperator recognizes and/or correctly assesses information in the environmental region in order to perform a safe teleoperated driving of the motor vehicle.</p><p id="p-0023" num="0022">In particular it can then also be recognized by the passenger whether the teleoperator fails to recognize information in the environmental region and in particular is not provided with same, since they possibly are not or only insufficiently captured by the optical capture units of the motor vehicle.</p><p id="p-0024" num="0023">In an advantageous embodiment it is envisaged that the passenger depending on the marked viewing direction of the operator on the display unit in the motor vehicle transmits an action information to the operator if falling below an attention criterion of the operator. For instance this may be the case with the above-named examples. In particular also with regard to the evaluation, as to how a safe driving of the motor vehicle is to be performed, a change of the teleoperated driving of the motor vehicle is demanded or asked for by the passenger.</p><p id="p-0025" num="0024">In particular it is facilitated that by this visual marking on the image of the display unit of the motor vehicle, in particular by the passenger, it can be recognized whether the teleoperator for the safe driving of the motor vehicle keeps an eye on relevant traffic zones. Such traffic zones can for instance be a pedestrian crossing, a sidewalk, a bike path, or the like. Also confusing intersections or unclear entrances and exits can be considered as such traffic zones.</p><p id="p-0026" num="0025">In an advantageous embodiment it is envisaged that as action information a speech signal is transmitted from the passenger to the teleoperator. This can be effected via a communication link, in particular a wireless communication link. An action information can be a notification information about a corresponding traffic zone, which the teleoperator presently has no eye on. An action information, however, can additionally or instead also be an instruction of the passenger about the way in which the teleoperator is meant to perform the teleoperated driving of the motor vehicle.</p><p id="p-0027" num="0026">It may be envisaged that the safety categories for traffic zones are predetermined by the passenger. This can in particular occur prior to the beginning of the transport travel. In particular same can be effected by a passenger-specific user profile. Same can be deposited with the teleoperation driving system. Additionally a classification of traffic situations of the passenger, in particular prior to the transport travel, can be predetermined. Also it can be deposited in an electronic user profile. This electronic user profile can be communicated to the operator prior to the beginning of the teleoperated driving. Thereby the teleoperator can perform his teleoperated driving of the motor vehicle depending on this user profile. In particular thereby also a correspondingly adapted teleoperated driving can be effected. In particular this information from the user profile of the passenger can be displayed on a display unit at the operator location. Additionally or instead also an optical display in images on a display unit of the operator at the operator location can be effected. In particular the operator is alerted to what is important to the passenger when driving the vehicle. In particular thus a corresponding sense of safety of the passenger during the teleoperated driving of the vehicle can be enhanced.</p><p id="p-0028" num="0027">In particular in instances where the passenger knows the route of the transport travel, in particular possibly also knows the traffic-critical spots, thereby the teleoperator's awareness can also already be raised and he can be better prepared for the teleoperated driving of the vehicle. In particular then the awareness of the teleoperator is raised in this regard for his teleoperated transport travel.</p><p id="p-0029" num="0028">It may also be envisaged that depending on the environmental region captured by the optical capture unit and/or on an environmental region not or not yet captured by the optical capture unit, which, however, is already recognized by the passenger, the environmental region is divided into zones, which are assigned to individual safety categories. Depending on this categorization the optically marked image region is evaluated and in the case of a deviation of the marked image region of a zone with a safety category larger than a safety threshold value an action information is transmitted to the teleoperator. By such design not only the teleoperated driving can be effected more safely. Rather also the subjective sense of safety of the passenger in the motor vehicle can be raised. A driving of the motor vehicle geared to the individual passenger is thereby rendered possible.</p><p id="p-0030" num="0029">A further aspect of the invention relates to a computer program product with instructions, which, if the computer program product is performed by a computer, cause the computer to perform the steps according to the method as it was named in the above or an advantageous implementation thereof.</p><p id="p-0031" num="0030">A further aspect of the invention relates to a teleoperation driving system. This comprises an operator location. Same is arranged external to and remote from a motor vehicle, which is to be driven in a teleoperated manner. It moreover comprises at least one optical capture unit, which is arranged on a motor vehicle. Moreover the teleoperation driving system comprises a display unit in the motor vehicle and a display unit at the operator location. The teleoperation driving system comprises at least one control and/or computing unit, which is configured, to perform a method according to the above-named aspect or an advantageous embodiment thereof. In particular the teleoperation driving system comprises a computer program product as it was named in the above. The control unit in this connection may be the computer.</p><p id="p-0032" num="0031">Preferably this teleoperation driving system comprises at least one eye tracking device, which is arranged at the operator location. By same the viewing direction of the operator can be detected. Additionally or instead, the teleoperation driving system can comprise at least one laser scanner, which is arranged at the motor vehicle, and by which a position of an object in the environmental region of the motor vehicle can be detected. Objects in this connection can be static as well as dynamic objects. These can be other traffic participants, such as pedestrians, cyclists, motorcyclists, or other vehicles. However, it can also be a border stone, a building, a tree, a bush, a parking, a footpath, a cycle path, a pedestrian crossing, or any kind of static object corresponding to traffic signs. This list of potential objects in the environmental region is not to be understood as final.</p><p id="p-0033" num="0032">In particular the teleoperation driving system also comprises at least one microphone, which is arranged at the motor vehicle. By the microphone noises in the environment of the motor vehicle and/or in the interior of the motor vehicle can be captured. These noises can be transmitted to a unit at the operator location. There they can be output as acoustic signals to the operator. Thereby the perception and the comprehension of the image displayed on the display units at the operator location for the operator is improved and closer to reality. Individual traffic situations, which are represented by the images, can then be understood and assessed in an improved way for the operator.</p><p id="p-0034" num="0033">A further aspect of the invention relates to a motor vehicle, which comprises a display unit and at least one communication unit, by means of which the possibility is provided to conduct a communication with an operator location.</p><p id="p-0035" num="0034">Further features of the invention are apparent from the claims, the figures and the description of figures. The features and feature combinations mentioned above in the description as well as the features and feature combinations mentioned below in the description of figures and/or shown in the figures alone are usable not only in the respectively specified combination, but also in other combinations without departing from the scope of the invention. Thus, implementations are also to be considered as encompassed and disclosed by the invention, which are not explicitly shown in the figures and explained, but arise from and can be generated by the separated feature combinations from the explained implementations. Implementations and feature combinations are also to be considered as disclosed, which thus do not comprise all of the features of an originally formulated independent claim. Moreover, implementations and feature combinations are to be considered as disclosed, in particular by the implementations set out above, which extend beyond or deviate from the feature combinations set out in the back-references of the claims.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><p id="p-0036" num="0035">Embodiments of the invention are explained in the following in more detail on the basis of schematic drawings.</p><p id="p-0037" num="0036">These show in:</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>1</b></figref> a schematic representation of an embodiment of a teleoperation driving system;</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>2</b></figref> a schematic representation of an operator location of the teleoperation driving system according to <figref idref="DRAWINGS">FIG. <b>1</b></figref>;</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>3</b></figref> a representation of an image, which is displayed on a display unit of the motor vehicle, which is driven in teleoperated manner; and</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>4</b></figref> a schematic flow diagram for an embodiment of a method according to the invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0042" num="0041">In the figures same elements or elements having the same function are equipped with the same reference signs.</p><p id="p-0043" num="0042">In <figref idref="DRAWINGS">FIG. <b>1</b></figref> in a schematic representation an electronic teleoperation driving system <b>1</b> is shown. With this teleoperation driving system <b>1</b> a motor vehicle <b>2</b> can be driven remotely controlled, namely in a teleoperated way. The motor vehicle <b>2</b> is intended to be provided for the transport of persons. The teleoperation driving system <b>1</b> has an operator location <b>3</b>. This is located in particular in a building. The operator location <b>3</b> comprises at least one display unit. In the embodiment several display units, in particular a display unit <b>4</b>, a further display unit <b>5</b>, yet a further display unit <b>6</b> are provided. In particular at least one fourth display unit <b>7</b> is arranged at the operator location <b>3</b>. The display units <b>4</b> to <b>7</b> are in particular screens. Moreover the operator location <b>3</b> comprises a steering unit, in particular a steering wheel <b>8</b>. Moreover an acoustic communication unit <b>9</b> is arranged at the operator location <b>3</b>. An operator, which is shown merely symbolically in <figref idref="DRAWINGS">FIG. <b>1</b></figref> and which can also be referred to as teleoperator <b>10</b> and is a human, is present at the operator location <b>3</b>. This teleoperator <b>10</b> conducts the teleoperated driving of the motor vehicle <b>2</b>.</p><p id="p-0044" num="0043">The operator location <b>3</b> in an advantageous embodiment can communicate wirelessly via a wireless communication link <b>11</b> with a computing unit <b>12</b>, in particular a server. This computing unit <b>12</b> can be linked via a communication link <b>13</b> for instance to the internet <b>14</b>. Via a further communication link <b>15</b> the motor vehicle <b>2</b> can wirelessly communicate with the internet <b>14</b>. In particular it is possible that here it is communicated via a mobile radio standard, in particular the 5G standard. Also a direct communication link between the motor vehicle <b>2</b> and the operator location <b>3</b> can be provided. In particular the 5G standard.</p><p id="p-0045" num="0044">The motor vehicle <b>2</b> is in particular a fully autonomous vehicle. It has in particular the autonomy level <b>5</b>. It is thus a motor vehicle <b>2</b> driving without driver.</p><p id="p-0046" num="0045">The motor vehicle <b>2</b> comprises at least one capture unit, by which an environmental region <b>16</b> of the motor vehicle <b>2</b> can be captured. In particular the motor vehicle <b>2</b> comprises an optical capture unit for this purpose. In particular in this connection as an optical capture unit a camera <b>17</b> can be provided, which is sensitive in the spectral range visible for human beings. Same is configured for capturing the environmental subregion located in front of the motor vehicle <b>2</b>. Moreover the motor vehicle <b>2</b> can comprise additional optical capture units <b>18</b>, <b>19</b>, and <b>20</b>. These, too, can be cameras. The detection ranges of the optical capture units <b>18</b> and <b>19</b> are arranged at the opposite side regions on the motor vehicle <b>2</b> and are oriented for detection of the lateral environmental subregions of the environmental region <b>16</b>. The optical capture unit <b>20</b> is oriented backward in order to capture the environmental subregion of the environmental region <b>16</b> behind the motor vehicle <b>2</b>.</p><p id="p-0047" num="0046">The motor vehicle <b>2</b> in an advantageous embodiment can additionally comprise at least one laser scanner <b>21</b>. Same detects the environmental subregion in particular in front of the motor vehicle <b>2</b>.</p><p id="p-0048" num="0047">In particular the motor vehicle <b>2</b> also comprises a control unit <b>22</b>.</p><p id="p-0049" num="0048">Symbolically a passenger <b>23</b> is positioned in the motor vehicle <b>2</b>. This passenger <b>23</b> would like to conduct a transport travel with the motor vehicle <b>2</b> or does conduct it with the motor vehicle <b>2</b>. This driving of the motor vehicle <b>2</b> during the transport drive is performed at least in phases, in particular completely, by the external teleoperator <b>10</b> in teleoperated manner from the operator location <b>3</b>. In this teleoperated driving environmental information of the environmental region <b>16</b> of the motor vehicle <b>2</b> are captured by at least one optical capture unit <b>17</b> to <b>20</b>. This captured information, in particular images, in particular videos, are transmitted to the operator location <b>3</b>. At the operator location <b>3</b> these images are displayed at least on one display unit <b>4</b> to <b>7</b>. It may be envisaged that for instance the images captured by the optical capture unit <b>17</b> are transmitted to the operator location <b>3</b> and there displayed on a centrally positioned display unit <b>5</b>. It may be envisaged that the images captured by the optical capture unit <b>18</b> are transmitted to the operator location <b>3</b> and displayed on the display unit <b>6</b> on the right side. It may be envisaged that images captured by the optical capture unit <b>20</b> are displayed on the display unit <b>7</b> arranged at the center and below the display unit <b>5</b>. In particular it is envisaged that images transmitted by the optical capture unit <b>19</b> are transmitted to the operator location <b>3</b> and displayed there on the display unit <b>4</b> arranged on the left side.</p><p id="p-0050" num="0049">During the teleoperated driving of the motor vehicle <b>2</b> a viewing direction <b>24</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) of the teleoperator <b>10</b> is captured. For this purpose in particular an eye-tracking device <b>25</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>), which is arranged at the operator location <b>3</b>, is used. Therein it is detected at which image region <b>26</b> of an image <b>27</b> displayed on the display unit <b>4</b> and/or <b>5</b> and/or <b>6</b> and/or <b>7</b> the gaze of the teleoperator <b>10</b> is directed. In particular therein it is also determined at which place of the image the vector of the viewing direction <b>24</b> intersects or touches this image plane.</p><p id="p-0051" num="0050">In particular based on information of the at least one laser scanner <b>21</b> positions of real objects in the environmental region <b>16</b> can be determined. In addition to this information and the knowledge, which image representation is effected on the display unit <b>5</b>, it can also be determined, at which image region or at which object the teleoperator <b>10</b> is presently gazing.</p><p id="p-0052" num="0051">The motor vehicle <b>2</b> comprises in particular at least one display unit <b>28</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>). On this display unit <b>28</b> an image <b>29</b> is displayed, which in particular comprises a subregion of the image <b>27</b>, at which the teleoperator <b>10</b> presently gazes. This image <b>29</b> on the display unit <b>28</b> advantageously equally shows at least the image region <b>26</b>, at which the teleoperator presently gazes in the image <b>27</b>. In particular it is envisaged that this image region <b>26</b>, at which the teleoperator <b>10</b> presently gazes on his display unit, in the example here the display unit <b>5</b>, is marked on the image <b>29</b> of the display unit <b>28</b> in the motor vehicle <b>2</b>, in particular visually marked. For this purpose in the embodiment it is envisaged that this region <b>26</b> is marked in color or signaled in color. For instance here a surface coloring in a coloring contrasting with the other regions of the image <b>29</b> can be effected. In particular this color signaling is effected to be transparent or opaque. Thereby the actual environmental information of this image region <b>26</b> can also still be recognized through this coloring <b>30</b>. Thus in this connection for instance in <figref idref="DRAWINGS">FIG. <b>3</b></figref> it is recognizable that the teleoperator <b>10</b> gazes at a specific region of a pedestrian way and/or cycle path <b>31</b>. This is marked in the image <b>29</b> by the color signaling or coloring <b>30</b>. Thus the passenger <b>23</b> in the vehicle <b>2</b> can always and currently recognize at which environmental subregion or at which object the teleoperator <b>10</b> presently directs his gaze.</p><p id="p-0053" num="0052">In particular it is envisaged that on the display unit <b>28</b> in the motor vehicle <b>2</b> at least in portions the image <b>27</b> is displayed, which is displayed on the display unit <b>5</b> at the operator location <b>3</b>. In particular this image <b>27</b>, which is displayed on the display unit <b>5</b> at the operator location <b>3</b>, is displayed synchronized in time with the image <b>29</b> displayed on the display unit <b>28</b> in the motor vehicle <b>2</b>. In particular it is envisaged that the image, which is taken by the optical capture unit <b>17</b> and/or <b>18</b> and/or <b>19</b> and/or <b>20</b>, is displayed in real time on the display unit <b>4</b> and/or <b>5</b> and/or <b>6</b> and/or <b>7</b> at the operator location <b>3</b>. In particular the images taken are recorded as videos and also displayed as videos on the corresponding display units <b>4</b> to <b>7</b>, <b>28</b>. In particular the viewing direction <b>24</b> of the operator is permanently captured during the teleoperated driving of the motor vehicle <b>2</b>. In particular thus the respective viewing direction as well as a change in the viewing direction can be captured uninterrupted. Thus also dynamic changes in the viewing direction can be captured without restriction. Also in this regard a color signaling <b>30</b>, which is synchronized and represented in real time, can be effected, in particular also be effected in a dynamically changeable manner. In addition to or instead of the surface color signaling also a region boundary contour of this image region <b>26</b> can be visually signaled. Depending on the specific criteria also a change in color and/or a change of the region boundary contour can be effected. Also in this regard a dynamic change can be effected.</p><p id="p-0054" num="0053">It may be envisaged that the passenger <b>23</b> depending on the marked viewing direction <b>24</b> of the operator <b>10</b> on the display unit <b>28</b> transmits an action information to the operator <b>10</b>. In particular if falling below an attention criterion of the operator <b>10</b>. The action information can be a speech signal. This can be transmitted via a communication link <b>15</b>, <b>13</b>, <b>11</b> to the operator location <b>3</b>. Also a direct transmission from the motor vehicle <b>2</b> to the operator location <b>3</b> can be effected. In particular by this optical marking of the viewing direction <b>24</b> of the teleoperator <b>10</b> on an image in the motor vehicle <b>2</b> it can also be recognized whether the teleoperator <b>10</b> perceives critical traffic situations and/or specific traffic zones as required in order to be able to perform a safe teleoperated driving of the motor vehicle <b>2</b>.</p><p id="p-0055" num="0054">It is also possible that the display on the in particular only one display unit <b>28</b> in the motor vehicle <b>2</b> can dynamically change. This is in particular for instance then the case if the operator <b>10</b> changes a gaze from one display unit <b>4</b> to <b>7</b> to another display <b>4</b> to <b>7</b> at his operator location <b>3</b>. In particular if he for instance according to the representation in <figref idref="DRAWINGS">FIG. <b>2</b></figref> gazes away from the image <b>27</b> on the display unit <b>5</b> and for instance directs his gaze at the image displayed on the display unit <b>4</b>. This, too, can correspondingly be recognized by the eye-tracking device <b>25</b>. Then a change of the representation of the image on the display unit <b>28</b> in the motor vehicle <b>2</b> can then be effected synchronized and in real time. In particular then also the image displayed on the display unit <b>5</b> at the operator location <b>3</b> is displayed there at least partly. In particular the representation of the image of the display unit <b>28</b> is then effected in such a way that again the image region, at which the operator <b>10</b> is presently gazing on the display unit <b>5</b>, is displayed at least partly on the display unit <b>28</b>. Thus, here, too, always an optical marking of the image region on the display unit <b>28</b> can be effected, at which the operator <b>10</b> is presently gazing on the respective display unit.</p><p id="p-0056" num="0055">Generally according to the simplified flow diagram in <figref idref="DRAWINGS">FIG. <b>4</b></figref> it can be envisaged that in a step S<b>1</b> the scenario is started. In this connection according to a step S<b>2</b> it is checked, whether a teleoperated driving is started. If this according to S<b>3</b> is not the case, it is returned to step S<b>1</b>. If, however, a teleoperated driving according to step S<b>4</b> is started, in a further step S<b>5</b> the direction of gaze <b>24</b> of the operator <b>10</b> is determined. If in this regard no intersection of the viewing direction <b>24</b> with an image on a display unit at the operator location <b>3</b> is recognized, according to step S<b>6</b> it is returned to step S<b>1</b>. If such observation is recognized, in which the viewing direction <b>24</b> of the operator <b>10</b> intersects with the image on a display device <b>4</b> to <b>7</b>, according to step S<b>7</b> it is proceeded in such a way that the observed image region on the image of the display unit in the motor vehicle <b>2</b> is visually marked, as it is set out by step S<b>8</b>.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for remotely controlled driving of a motor vehicle, wherein<claim-text>by the motor vehicle a transport travel with at least one passenger in the motor vehicle is performed;</claim-text><claim-text>the driving of the motor vehicle during the transport drive at least in phases is performed in teleoperated manner by an external teleoperator from an operator location,</claim-text></claim-text><claim-text>wherein:<claim-text>during the teleoperated driving environmental information of the motor vehicle, which is captured by at least one optical capture unit of the motor vehicle, is transmitted to the operator location and there displayed at least on one display unit for the teleoperator wherein</claim-text><claim-text>during the teleoperated driving a viewing direction of the teleoperator to the display unit is determined, and it is captured at which image region of the image, which is displayed on the display unit, the teleoperator gazes, and</claim-text><claim-text>this image region, at which the teleoperator gazes on his display unit, is visually marked on a display unit in the motor vehicle.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein on the display unit in the motor vehicle at least in portions an image is displayed, which is displayed on the display unit at the operator location.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the image, which is displayed on the display unit in the operator location, is displayed synchronized in time with the image, which is displayed on the display unit in the motor vehicle.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein an image of the environmental region (<b>16</b>), which is taken by the optical capture unit (<b>17</b> to <b>20</b>) of the motor vehicle (<b>2</b>), is displayed in real time on the display unit (<b>4</b> to <b>7</b>) at the operator location (<b>3</b>).</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein an image taken of the environmental region is performed by the optical capture unit as video recording and a display of the video recording is performed on the display unit of the operator location.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the viewing direction of the teleoperator during the teleoperated driving is permanently captured, in particular also a change in the viewing direction captured dynamically.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein a marking of the current viewing direction and/or a change in the viewing direction on the display unit in the motor vehicle is effected in dynamically changeable manner synchronized in real time.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the marking of the image region, at which the teleoperator is currently gazing on his display unit, in the image, which is displayed on the display unit in the motor vehicle, is signaled in color and/or is signaled by a display of a region boundary contour of this image region.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the passenger depending on the marked viewing direction of the teleoperator on the display unit in the motor vehicle transmits an action information to the teleoperator if falling below an attention criterion of the teleoperator.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein as action information a speech signal is transmitted via a communication link.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein depending on the environmental region captured by the optical capture unit and/or by an environmental subregion of the environmental region, which has not or not yet been captured by the optical capture unit, which however is already recognized by the passenger, the environmental region is subdivided into zones, which are assigned to individual safety categories, wherein depending on this categorization the marked image region is evaluated and in the case of a deviation of the marked image region from a zone with a safety category higher than a safety threshold value, an action information is transmitted to the teleoperator.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a classification of traffic situations and/or traffic zones by the passenger prior to the beginning of the transport drive is predetermined, by an electronic passenger profile, wherein the classification is communicated to the teleoperator prior to the beginning of the teleoperated driving.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A computer program product comprising instructions, which, when the computer program product is executed by a computer, cause the computer to perform the steps of the method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A teleoperation driving system for teleoperated driving of a motor vehicle, comprising:<claim-text>an operator location external to the motor vehicle, comprising at least one optical capture unit of the motor vehicle,</claim-text><claim-text>a display unit of the motor vehicle and at least one display unit at the operator location, and</claim-text><claim-text>at least one control and/or computing unit, which is configured to perform a method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The teleoperation driving system according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, which comprises an eye-tracking device at the operator location, by which the viewing direction of the teleoperator is detectable and/or comprises at least one laser scanner of the motor vehicle, by which a position of an object in the environmental region is detectable.</claim-text></claim></claims></us-patent-application>
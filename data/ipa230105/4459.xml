<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004460A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004460</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17363212</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>07</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>55</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>0787</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>0721</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>552</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>2221</main-group><subgroup>034</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">TECHNOLOGY FOR LOGGING LEVELS AND TRANSACTION LOG FILES</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>International Business Machines Corporation</orgname><address><city>Armonk</city><state>NY</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Nagar</last-name><first-name>Raghuveer Prasad</first-name><address><city>Kota</city><country>IN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Hulugundi</last-name><first-name>Jagadesh Ramaswamy</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Solanki</last-name><first-name>Abhishek</first-name><address><city>Lucknow</city><country>IN</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Tangirala</last-name><first-name>Subba Rayudu</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Dynamic logging includes generating parsed event data by at least one natural language processor responsive to event data of a log for transactions of a target application. In response to the parsed event data, a first classifier classifies context states of the respective transactions of the target application. In response, a second classifier classifies trouble prone states of the respective transactions, wherein the trouble prone states are for respective hierarchical levels. When a logic module determines, for a current one of the trouble prone states for a current transaction, that the current trouble prone state is a higher trouble prone level than for a transaction immediately preceding the current transaction, the logic module sends an increased log detail selection to the target application, so that a greater amount of log detail is logged for at least a next transaction after the current transaction.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="87.12mm" wi="158.75mm" file="US20230004460A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="214.63mm" wi="118.79mm" orientation="landscape" file="US20230004460A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="160.19mm" wi="135.89mm" orientation="landscape" file="US20230004460A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="220.47mm" wi="162.64mm" orientation="landscape" file="US20230004460A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="199.31mm" wi="143.59mm" file="US20230004460A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="119.63mm" wi="113.79mm" orientation="landscape" file="US20230004460A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="179.32mm" wi="132.50mm" orientation="landscape" file="US20230004460A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">Event logs are human readable, i.e., natural language, records of events occurring during program execution for providing a human readable audit trail, which personnel can read to diagnose problems, such as security intrusions, performance slowdowns, crashes and other anomalies. Such event logs may include identity references, user actions, data sets, logic executed and transaction type, category, sequence, date and time, etc.</p><p id="p-0003" num="0002">Loggers that generate event logs are usually provided for database systems and web servers and are often provided in other programs, as well. A database management system (&#x201c;DBMS&#x201d;) (also referred to as a &#x201c;database system&#x201d;) includes software that interacts with a database, applications and users for performing transactions on the database, which includes transactions for storing data of the database. Database transactions also include those that merely analyze and generate reports about the data and others that change the stored data, of course. A web server includes software that provides web pages in response to requests from a user agent, such as a web browser, and that may also receive and store data from the user agent. In production environments handling millions of transactions in a day or even in an hour, event logs are voluminous. In an embodiment of the present invention, a computer system implemented method comprises receiving, by the computer system, course content for a course of study and performing a certain exam question generating procedure for the course content.</p><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0004" num="0003">In an embodiment of the present invention, a computer system implemented method of dynamic logging includes generating parsed event data by at least one natural language processor responsive to event data of a log for transactions of a target application. The method includes classifying, by a first classifier applying a first machine learning model to the parsed event data, context states of the respective transactions of the target application. A second classifier applying a second machine learning model to the parsed event data and the context states, classifies trouble prone states of the respective transactions, wherein the trouble prone states are for respective hierarchical levels. A logic module determines, for a current one of the trouble prone states for a current transaction, that the current trouble prone state is a higher trouble prone level than for a transaction immediately preceding the current transaction. The logic module sends to the target application, an increased log detail selection responsive to the determining that the current trouble prone state is the higher trouble prone level, so that a greater amount of log detail is logged for at least a next transaction after the current transaction.</p><p id="p-0005" num="0004">In other embodiments of the invention, other forms are provided, including a system and a computer program product.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0006" num="0005">Features and advantages of the present invention will be more readily understood with reference to the attached figures and following description, wherein:</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an arrangement for event logging, according to at least one embodiment of the present invention;</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts instructions in source code of a target application, according to at least one embodiment of the present invention;</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow chart illustrating certain actions performed prior to and during production runtime, according to at least one embodiment of the present invention;</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a networked computer environment, according to at least one embodiment of the present invention;</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram of a computer system such as those shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, according to at least one embodiment of the present invention;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts a cloud computing environment, according to at least one embodiment of the present invention; and</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts abstraction model layers, according to at least one embodiment of the present invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0014" num="0013">The descriptions of the various embodiments of the present invention have been presented for purposes of illustration but are not intended to be exhaustive or limited to the embodiments disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the described embodiments. The terminology used herein was chosen to best explain the principles of the embodiments, the practical application or technical improvement over technologies found in the marketplace, or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example computing environment <b>400</b> suitable for embodiments of the present invention. As shown, computing environment <b>400</b> includes computer systems <b>410</b>.<b>1</b>, <b>410</b>.<b>2</b> through <b>410</b>.N connects via network <b>420</b>, which may be a public or private network. Systems <b>410</b>.<b>1</b>, <b>410</b>.<b>2</b>, etc. include modules, which may be program or hardware modules, configured to perform tasks for their own respective systems or for other systems or both, including tasks as described for elements of <figref idref="DRAWINGS">FIGS. <b>1</b> through <b>3</b></figref> herein.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates details of a computer system <b>410</b>.X suitable as computer systems <b>410</b>.<b>1</b>, <b>410</b>.<b>2</b>, etc. according to embodiments of the present invention, wherein system <b>410</b>.X includes at least one central processing unit (CPU) <b>505</b>, network interface <b>515</b>, interconnect (i.e., bus) <b>517</b>, memory <b>520</b>, storage device <b>530</b> and display <b>540</b>. CPU <b>505</b> may retrieve and execute programming instructions stored in memory <b>520</b> for applications. Similarly, CPU <b>505</b> may retrieve and store application data residing in memory <b>520</b>. Interconnect <b>517</b> may facilitate transmission, such as of programming instructions and application data, among CPU <b>505</b>, storage <b>530</b>, network interface <b>515</b>, and memory <b>520</b>. CPU <b>505</b> is representative of a single CPU, multiple CPUs, a single CPU having multiple processing cores, and the like. Additionally, memory <b>520</b> is representative of a random-access memory, which includes data and program modules for run-time execution. It should be understood that system <b>410</b>.X may be implemented by other hardware and that one or more modules thereof may be firmware.</p><p id="p-0017" num="0016">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to an embodiment of the present invention, a logger <b>104</b> may operate in conjunction with an event logging utility <b>124</b> that allows a user to configure various logging levels. For example, logging utility <b>124</b> may be provided by a software program implemented from an open source framework such as &#x201c;Logback&#x201d; or &#x201c;Apache Log4j,&#x201d; for example. The event log <b>106</b> arises from log statements defining what to write to a log <b>106</b>, where the statements are user programmed in source code of a target application <b>102</b>, such as a DBMS. The statements get triggered by events encountered at run time, i.e., during a time when application <b>102</b> is executing transactions. Each log statement also defines a respective log level to which it applies, or is otherwise associated with the log level, such that if a log statement in application <b>102</b> is for high level logging but is encountered when application <b>102</b> is running with a current logging level that is lower, the log statement does not case a log record to be written. That is, the log statement will cause application <b>102</b> to write a log <b>106</b> record only if the log statement is encountered while the current logging level is at least as high as the logging level of the log statement.</p><p id="p-0018" num="0017">A logger may also provide a different kind of log that relates more specifically to transactions. As the term is used herein, a &#x201c;transaction&#x201d; concerns a change in data that must be performed completely, in which case the change is committed, or else not performed at all, in which case a change that has started is rolled back to eliminate the effect of the change. Transaction logs are for maintaining the data in a coherent state, which includes automatic recovery from crashes and other data errors. Accordingly, transaction logs are machine readable. Event logs may include transaction identities and other transaction attributes, such as initiation and completion of transactions. However, event logs differ from transaction logs in that event logs are for more general problems, such as determining the cause of crashes, hang ups and poor performance, rather than merely the problem of maintaining data coherency. Also, event logs are human readable, so that personnel can read to the event logs to diagnose the more general problems.</p><p id="p-0019" num="0018">Embodiments of the present invention involve a recognition that in high throughput data processing environments, data administrators (or other users with requisite authority) often set event logging at reduced levels to avoid adversely impacting performance. That is, an administrator may have a logging utility <b>124</b> set to a reduced logging mode, such as INFO or ERROR mode, rather than a more detailed logging mode, such as DEBUG or VERBOSE mode that provides more details in log <b>106</b> records, which tends to be more helpful for troubleshooting when a problem arises. Examples of log <b>106</b> records are shown in Appendix AA for respective levels of logging detail, according to an embodiment of the present invention.</p><p id="p-0020" num="0019">Disclosed herein is newly provided logic <b>128</b> (&#x201c;dynamic logging level logic&#x201d; or &#x201c;D3L&#x201d;) that employs natural language processing (&#x201c;NLP&#x201d;) and interfaces to machine learning (e.g., models <b>140</b>) to automatically and dynamically increase or decrease a logging level during production runtime for an application <b>102</b>, such as a database system or web server, for example. (Bagging may be used for training data and multiple, ensembled models <b>140</b> may be created to decrease variance and improve accuracy in prediction.)</p><p id="p-0021" num="0020">The increasing or decreasing of logging level is based on real time analysis during application <b>102</b> run time of transaction attributes, context and history from production logs <b>106</b> and other sources <b>108</b>, which are applied as observation data <b>134</b> to trained models <b>140</b> running in an operating mode. Based on data <b>134</b> for a transaction, first classifier <b>142</b> of models <b>140</b> classifies the transaction according to its context state. Second classifier <b>142</b> of models <b>140</b> receives the context state from classifier <b>142</b> and also receives data <b>134</b>. Based on these, classifier <b>142</b> classifies the transaction according to its trouble prone degree. Alternatively, rather than first classifying context and then classifying degree of trouble prone, a single model may classify context and degree of trouble prone in a single classification.</p><p id="p-0022" num="0021">Before models <b>140</b> run in the operating mode to classify transactions, they must be generated, i.e., configured and trained. During model <b>140</b> generation, D3L <b>128</b> causes configuration of machine learning models <b>140</b>, e.g., classifiers <b>142</b> and <b>144</b>. (The models <b>140</b> may be of the support vector machine type or k-nearest neighbor type, for example, which may be implemented by the Watson Studio Natural Language Classifier commercially available from International Business Machines Corporation, for example.) In one alternative, generating models <b>140</b> includes D3L <b>128</b> configuring and initiating training for at least first classifier <b>142</b> to identify contexts for transactions and at least second classifier <b>144</b> to further identify states for the transactions according to their identified contexts. Transaction contexts that at least first classifier <b>142</b> identifies may include functional, technical and security related states, for example. In one alternative, transaction states that at least second classifier <b>144</b> identifies concern likelihood of trouble and may be labeled HOT, WARM, COLD states, for example, wherein transactions in the HOT state are the most trouble prone transactions, transactions in the WARM state are moderately trouble prone and transactions in the COLD state are least trouble prone. The labels may vary in different alternatives. For example, the labels may indicate trouble prone likelihood as HIGH, MEDIUM and LOW.</p><p id="p-0023" num="0022">The following are pseudo code examples of statements for execution of transactions:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0023">Examples for COLD transactions        <ul id="ul0003" list-style="none">            <li id="ul0003-0001" num="0024">Validate customer</li>            <li id="ul0003-0002" num="0025">Check customer return order line item and reason code</li>            <li id="ul0003-0003" num="0026">Call center processing refund as regular return as it is within the return window of 30 days and originating from an authentic customer</li>        </ul>        </li>        <li id="ul0002-0002" num="0027">Examples for WARM transactions        <ul id="ul0004" list-style="none">            <li id="ul0004-0001" num="0028">Validate customer</li>            <li id="ul0004-0002" num="0029">Check customer return order line item and reason code.</li>            <li id="ul0004-0003" num="0030">Call center processing refund as non-regular as it is outside the return window of 30 days and originating from an authentic customer</li>        </ul>        </li>        <li id="ul0002-0003" num="0031">Examples for HOT transactions        <ul id="ul0005" list-style="none">            <li id="ul0005-0001" num="0032">Validate customer</li>            <li id="ul0005-0002" num="0033">Check customer return order line item and reason code</li>            <li id="ul0005-0003" num="0034">Call center processing refund as non-regular as it is outside the return window of 30 days and originating from a fraudulent customer</li>        </ul>        </li>    </ul>    </li></ul></p><p id="p-0024" num="0035">Non-production log <b>106</b> data and data from other sources <b>108</b> may be used for training models <b>140</b> in one supervised learning alternative. Such non-production log <b>106</b> data is generated by application <b>102</b> processing known transactions in a non-production environment, such as during functional testing or security testing. Some trouble prone transactions may be configured by an administrator before testing is begun to intentionally cause trouble prone performance. For example, the administrator may configure trouble prone transactions that will perform override actions, amend service delivery, perform repeatedly by a single requester, etc. Other trouble prone test transactions for use in application <b>102</b> testing and subsequent training of models <b>140</b> may be identified after testing by the administrator from log <b>106</b> data compiled during testing. To render data more suitable for training, raw log <b>106</b> data from the non-production environment (e.g., SIT, QA, Perf, Pre-prod) is parsed by a known log analysis tool <b>114</b>, such as Splunk or Logstash, for example. By parsing, condensing and filtering with such a log analysis tool <b>114</b>, an administrator can analyze event log <b>106</b> data to gain detailed understanding for specific test transactions executed for particular workloads, such that the administrator can derive feature-related rules <b>132</b> for classifying the transactions, where the trouble prone transactions may include outlier parameters and transactions for which processing exceeds predefined limits, for example. That is, the administrator may define rules <b>132</b> relating to degree or likelihood of trouble prone performance such as described herein, for example, and after testing execution identify transactions having parameters and parameter values that match rules <b>132</b>.</p><p id="p-0025" num="0036">The following are examples of some output from NL processing of the logs, where the output provides parsed data that classifiers <b>142</b> and <b>144</b> receive:<ul id="ul0006" list-style="none">    <li id="ul0006-0001" num="0000">    <ul id="ul0007" list-style="none">        <li id="ul0007-0001" num="0037">NLP format example with word tokenization for INFO log:        <ul id="ul0008" list-style="none">            <li id="ul0008-0001" num="0038">[&#x2018;Order Number&#x2019;, &#x2018;SOS7090204&#x2019;]</li>        </ul>        </li>        <li id="ul0007-0002" num="0039">NLP format example with sentence tokenization for VERBOSE log:        <ul id="ul0009" list-style="none">            <li id="ul0009-0001" num="0040">[&#x2018;Calling getCommonCodeList API to read rules from YFS_COMMON_CODE database table&#x2019;]</li>        </ul>        </li>        <li id="ul0007-0003" num="0041">NLP format example with sentence and word tokenization for ERROR log:        <ul id="ul0010" list-style="none">            <li id="ul0010-0001" num="0042">[&#x2018;Error occurred in a transaction while testing a service due to file not available in expected location&#x2019;, &#x2018;&#x3c;location of file expected on the directory folder&#x3e;&#x2019;]</li>        </ul>        </li>    </ul>    </li></ul></p><p id="p-0026" num="0043">Summarizing and expanding on the foregoing, context state and trouble prone degree are known for at least some of the trouble prone transactions included among the test transactions, because prior to testing application <b>102</b> an administrator intentionally configured some transactions to be trouble prone during test execution. Additional trouble prone transactions (and their context state and trouble prone degree) are automatically identified by D3L <b>128</b> after testing application <b>102</b> by comparing parameters and parameter values of those transactions to parameters and parameter values of predetermined rules <b>132</b> that the administrator provides to D3L <b>128</b> for defining trouble prone transactions and contexts. For the comparing to rules <b>132</b>, D3L <b>128</b> obtains the parameters and parameter values of transactions from the testing logs <b>106</b> via the parsing by tool <b>114</b>. D3L <b>128</b> may, if needed, further process the parsed data it receives from tool <b>114</b>. That is, if log analysis tool <b>114</b> does not perform sufficient condensing and filtering to eliminate unwanted lines, comments or statements from logs <b>106</b> and if log analysis tool <b>114</b> does not apply NL processing techniques to obtain clearly defined parameters and parameter values of transactions from the testing logs <b>106</b> for tagging the data with the parameters and parameter values for the transactions, then D3L may perform these functions to the extent they are not done by log analysis tool <b>114</b>. In one alternative, D3L <b>128</b> employs a known NLP tool and known processing methods for this further processing. Rules <b>132</b> are likewise defined by parameters and values. In general, parameters and values may concern reason codes, ATP calls, IP addresses, risk (e.g., credit) scores, etc., as described herein, for example.</p><p id="p-0027" num="0044">The above described parameterizing of log <b>106</b> data and matching to rules <b>132</b> enables D3L <b>128</b> to also tag the derived data for each respective transaction with context and trouble prone state tags that enable model training, for example, tags &#x3c;F, S or T&#x3e; for the first model(s) <b>142</b> and &#x3c;F/C, F/W, F/H, S/C, S/W, S/H, T/C, T/W or T/H&#x3e; for the second model(s) <b>144</b>. D3L <b>128</b> provides the data tagged with context and trouble prone states as sample data <b>136</b> for training. For training first classifier <b>142</b>, tags for context state are applied automatically based on specific rules such as the following, for example:<ul id="ul0011" list-style="none">    <li id="ul0011-0001" num="0000">    <ul id="ul0012" list-style="none">        <li id="ul0012-0001" num="0045">Functional Context: Log indicates rules were overridden to provide an additional order; Log indicates backorder count was increased from a certain fulfillment location.</li>        <li id="ul0012-0002" num="0046">Technical Context: Error code or log indicate connection refused, Error code or log indicate out of memory space; Error code or log indicate certain API timed out after predetermined amount of elapsed time.</li>        <li id="ul0012-0003" num="0047">Security Context: Log indicates order on hold due to fraud detection; Log indicates recurring order with large line items at high frequency using same credit card.<br/>For training second classifier <b>144</b>, tags for trouble prone state are applied automatically based on specific rules such as the following, for example:</li>        <li id="ul0012-0004" num="0048">Transaction API response time&#x3e;200 milli seconds is a performance issue and yields &#x3c;Technical/Hot&#x3e; tags; &#x3e;100 and &#x3c;=200 milli seconds yields &#x3c;Technical/Warm&#x3e; tags; &#x3c;=&#x2018;100 milli seconds&#x2019; yields &#x3c;Technical/Cold&#x3e; tags;</li>        <li id="ul0012-0005" num="0049">Override %&#x3e;10% yields &#x3c;Functional/Hot&#x3e; tags; &#x3e;=&#x2018;5% and &#x3c;=10%&#x2019; yields &#x3c;Functional/Warm&#x3e; tags; &#x3c;'5%' yields &#x3c;Functional/Cold&#x3e; tags;</li>        <li id="ul0012-0006" num="0050">Risk Score&#x3c;=&#x2018;400&#x2019; is a resolution risk and yields &#x3c;Security/Hot&#x3e; tags; &#x3e;400 and &#x3c;=800 yields &#x3c;Security/Warm&#x3e; tags; &#x3e;800 yields a &#x3c;Security/Cold&#x3e; tags.</li>    </ul>    </li></ul></p><p id="p-0028" num="0051">During application <b>102</b> production run time after model <b>140</b> training, models <b>140</b> in an operating mode are provided observation data <b>134</b> that is not already tagged with context and trouble prone states. In the operating mode, models <b>140</b> classify transaction states for application <b>102</b> in real time from observation data <b>134</b> that is obtained in the same way as in testing, but from production logs <b>106</b> instead of non-production logs <b>106</b>. That is, for the operating mode of models <b>140</b>, D3L <b>128</b> still obtains the parameters and parameter values of transactions via the parsing by tool <b>114</b> and further processes the parsed data it receives to tag the received data with the parameters and parameter values for the transaction observation data <b>134</b> that D3L <b>128</b> provides to models <b>140</b>. However, in one alternative for generating data <b>134</b>, D3L <b>128</b> does not compare data received from tool <b>114</b> to rules <b>132</b> and, accordingly, does not tag data <b>134</b> with context and trouble prone states.</p><p id="p-0029" num="0052">Models <b>140</b> classify context and trouble prone states of transactions in the tagged parameters and parameter values of data <b>134</b>, where the models <b>140</b> perform the classifying based on <b>140</b> detecting patterns in the parameters and parameter values that the models <b>140</b> learned through training are associated with the states. Further, models <b>140</b> in operating mode continuously learn new rules <b>132</b> via contextual derivation over time, which adds more data features and dynamically changes tag boundary values. That is, real time observation data <b>134</b> from log <b>106</b> records tend to sometimes have the same, predefined parameters and values, e.g., Transaction API response time&#x3e;200 milli seconds as in sample data <b>136</b>, for example, and sometimes have parameters and values that are not the same as what is predefined in sample data <b>136</b>, and sometimes even have some entirely different parameters and values than the ones that the predefined rules <b>132</b> indicate for the predefined states. Models <b>140</b> can recognize that some real time record(s), although not necessarily having parameter values exactly matching those in any of the predefined rules <b>132</b> (or even having parameters not exactly matching), nevertheless correspond(s) to one of the predefined states. Models <b>140</b> recognize this correspondence during training through automatically detecting a pattern wherein parameters and values of sample data <b>136</b>, while not exactly matching parameters and values of predefined rules <b>132</b>, are nevertheless associated with, e.g., correlated with, parameters and values of sample data <b>136</b>. In this detecting of patterns, models <b>140</b> identify parameters and values that define new &#x201c;rules,&#x201d; so to speak.</p><p id="p-0030" num="0053">When the classifying by trained models <b>140</b> determines that state for an observed transaction changes from COLD to WARM (or, alternatively, from COLD or WARM to HOT) in the context of the transaction's execution, models <b>140</b> responsively notify logging utility <b>124</b> to trigger an increase in logging detail, i.e., logging level. Models <b>140</b> notify utility <b>124</b> to trigger a decrease in logging detail when status for an observed transaction changes to less trouble prone.</p><p id="p-0031" num="0054">Logging utility <b>124</b> may be modified, according to an embodiment of the present invention, to trigger generation of additional log <b>106</b> files in addition to increasing detail of log <b>106</b> content when increasing a log level. For example, utility <b>124</b> may cause a separate log <b>106</b> file to be generated for each transaction identified as sufficiently trouble prone. According to a predetermined threshold, a transaction must be HOT to be sufficiently trouble prone cause a separate log <b>106</b> file in one alternative, whereas WARM may be predetermined as sufficiently trouble prone in another alternative. Further, utility <b>124</b> may be modified to vary its response to trouble prone state change depending also on a transaction's contextual state, e.g., functional, technical, security, etc.</p><p id="p-0032" num="0055">Further, upon detecting a status change to a more trouble prone state, the modified logging utility <b>124</b> may automatically initiate a support ticket for investigation by IT personnel and may trigger a more direct alert of IT and business personnel responsive to transactions turning HOT, such as by email to a predetermined address.</p><p id="p-0033" num="0056">In another aspect, when transactions have turned WARM (or, alternatively, HOT), modified utility <b>124</b> may automatically initiate analysis of the more detailed log <b>106</b> files generated by a machine-based analysis tool to identify a root cause, such as an infinite loop in program code causing a memory leak, in an example instance, and to propose solutions. (For example, the analysis tool may include the Operations Analytics&#x2014;Log Analysis tool commercially available from International Business Machines Corporation.) Upon the analysis tool identifying a cause, modified utility <b>124</b> may determine a solution and update a support ticket with a description of the analysis, predicted cause and predicted solution. This can allow a support team to not only more quickly replicate the issue in a lower environment but also quickly verify that the recommended fix is correct.</p><p id="p-0034" num="0057">D3L <b>128</b> provides any or all of the following as training data <b>136</b> for the first, contextual state model(s), to enable dynamically determining context for specific transactions:<ul id="ul0013" list-style="none">    <li id="ul0013-0001" num="0000">    <ul id="ul0014" list-style="none">        <li id="ul0014-0001" num="0058">Data indicating a functional context for a trouble prone transaction, which concern matters including transaction behavior and related actions violating predefined rules:        <ul id="ul0015" list-style="none">            <li id="ul0015-0001" num="0059">Defined interface constraints that are correct in data structures but breached in terms of data</li>            <li id="ul0015-0002" num="0060">Mismatches at transaction completion compared to transaction initiation</li>            <li id="ul0015-0003" num="0061">Performance of override actions</li>            <li id="ul0015-0004" num="0062">Reason codes, such as used for service delivery amendments, appeasements, etc.</li>            <li id="ul0015-0005" num="0063">Error codes and error descriptions from stack trace</li>        </ul>        </li>        <li id="ul0014-0002" num="0064">Data indicating a technical context for a trouble prone transaction, which concern matters including and specification, including service-defined non-functional requirements for transactions:        <ul id="ul0016" list-style="none">            <li id="ul0016-0001" num="0065">Performance of synchronous calls such as ATP (Available to Promise), reservation from front end channels on normal and peak processing times</li>            <li id="ul0016-0002" num="0066">Throughput of batch jobs that do bulk shifting of transactions for lengthy times (i.e., times exceeding defined thresholds)</li>            <li id="ul0016-0003" num="0067">Actions resulting in lengthy transaction boundary as of one of case</li>            <li id="ul0016-0004" num="0068">Extended database connections, queue connections, hung threads causing system bottlenecks</li>        </ul>        </li>        <li id="ul0014-0003" num="0069">Data indicating a security context for a trouble prone transaction, which concern matters including transaction, activities and profile policies and compliance needs:        <ul id="ul0017" list-style="none">            <li id="ul0017-0001" num="0070">Unusual IP address accessing an application</li>            <li id="ul0017-0002" num="0071">Abnormal request by unknown/guest users, e.g., large number of requested units with large number of lines</li>            <li id="ul0017-0003" num="0072">Resolution risk</li>            <li id="ul0017-0004" num="0073">Repeated transactions performed by single requester such as repeating due to slow performance or non-performance, repeating due to changed resolution means, etc.</li>        </ul>        </li>    </ul>    </li></ul></p><p id="p-0035" num="0074">In addition to obtaining data <b>134</b> and <b>136</b> from logs <b>106</b>, data <b>134</b> and <b>136</b> may be obtained from other sources <b>108</b> in the form of structured database reports, semi-structured files or unstructured raw data that may be parsed for content by known tools. Reason codes, notes, instructions used on documents by personnel are available through an audits engine. Transactions breaching service thresholds and tolerances and hardware sizing constraints are available to through health monitors. Memory, CPU and RAM memory-heap utilization are available through tools on the operating system of application <b>102</b>'s platform. Long running queries (database jobs) or regular batch jobs are available for models <b>140</b> through a combination of process profiles generated at the operating system level. Concurrent users at any given time is available through a count of user active connections to application <b>102</b>. Historical behavior of application <b>102</b> with regard to a specific transaction is available via the pre-production logs <b>106</b> for the encompassing incidents and their respective actions (one or multiple or a combination of actions). History associated with enforced jeopardy management policies is likewise available. This encompasses what jeopardy incidents occurred and what was their treatment in line with policies. In one such example, the archival and backup was not being done real-time in the enterprise. Historical records indicate how this policy violation impacted a Recovery Time Objective (RTO) and Recovery Point Objective (RPO) metrics in the context and what was achieved later to have RPO and RTO well controlled.</p><p id="p-0036" num="0075">Referring now to <figref idref="DRAWINGS">FIG. <b>2</b></figref> together with <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to an embodiment of the present invention, instructions (also known as, or included in, &#x201c;statements&#x201d;) S<b>1</b>, S<b>2</b>, S<b>3</b>, etc. are shown in source code of target application <b>102</b>. Application <b>102</b> executes instructions S<b>1</b>, S<b>2</b>, S<b>3</b>, etc. in sequence S<b>1</b>, S<b>2</b>, S<b>3</b>, etc. Statement S<b>1</b> is an instruction to perform transaction T<b>1</b>. Statement S<b>2</b> is an instruction to generate a log record R<b>1</b> for transaction T<b>1</b>. Statement S<b>3</b> is an instruction to perform transaction T<b>2</b>. Statement S<b>4</b> is an instruction to generate a log record R<b>2</b> for transaction T<b>2</b>. Likewise, statements S<b>5</b> and S<b>6</b> are for transactions T<b>3</b> and log record R<b>3</b>. (Many more statements are included, but not shown. Note that statements S<b>1</b> and S<b>2</b> may be a single statement with instructions for both performing transaction T<b>1</b> and for generating log record R<b>1</b>. Likewise, statements S<b>3</b> and S<b>4</b> may be a single statement for T<b>2</b> and R<b>2</b>, etc.)</p><p id="p-0037" num="0076">At the time when transaction T<b>1</b> is executed responsive to S<b>1</b>, the trouble prone state for application <b>102</b> (and transaction T<b>1</b>) is Low (or Cold). Then log record R<b>1</b> for T<b>1</b> is generated responsive to statement S<b>2</b>, where the logging detail for R<b>1</b> is, correspondingly, low (e.g., Info level of detail). Then classifiers <b>142</b> and <b>144</b> analyze R<b>1</b> and classifier <b>144</b> responsively changes the trouble prone state to Medium (or Warm). Then transaction T<b>2</b> is executed responsive to statement S<b>3</b>. Then log record R<b>2</b> for T<b>2</b> is generated responsive to S<b>4</b>, where the logging detail for R<b>2</b> is now Medium (e.g., Error).</p><p id="p-0038" num="0077">From all of the foregoing, it should be understood that technology is disclosed for a computer system implemented method, system and program product for dynamic logging including actions and structures set out herein. Specifically, as illustrated in flow chart fashion in <figref idref="DRAWINGS">FIG. <b>3</b></figref> according to an embodiment of the present invention, at least the following actions are performed <b>302</b> during production runtime of a target application based on event data in a NL log that is logged during the production runtime responsive to the target application executing event log statements for respective transactions. (In the logging, respective amounts of detail are logged responsive to respective log detail selections received by the target application and passed by the target application to the event log statements.)</p><p id="p-0039" num="0078">In one aspect, the actions performed during the production runtime <b>302</b> include the target application executing <b>310</b> an event log statement for a transaction and generating <b>314</b> parsed event data for a transaction by at least one NL processor responsive to the event data of the log. A first classifier, by applying a first machine learning model to the parsed event data, classifies <b>318</b> a context state of the transaction of the target application. A second classifier, by applying a second machine learning model to the parsed event data and the context states, classifies <b>322</b> a trouble prone state of the transaction, which is one state of respective states that have hierarchical levels. A logic module compares <b>326</b> the trouble prone state for the current transaction to that of a transaction immediately preceding the current transaction. In response, the logic module determines <b>330</b> whether the current trouble prone state is a new trouble prone level, i.e., higher or lower than for the transaction immediately preceding the current transaction. If no, the logic module does not send (&#x201c;no&#x201d; branch) a change in log detail selection to the application, so that for a next <b>334</b> transaction, the application continues logging with the same level of log detail in the same log file and does not generate a new log file.</p><p id="p-0040" num="0079">If the logic module determines <b>330</b> that the trouble prone state is new (&#x201c;yes&#x201d; branch), the logic module does send <b>338</b> a change in log detail selection to the application. For any such new log detail selection, the application passes <b>342</b> the new selection to a log statement for the next transaction <b>334</b> and subsequent transactions until such time as the logic module again changes the log detail selection. The selection sent <b>338</b> is a decreased log detail selection responsive to an instance of determining <b>330</b> that the current trouble prone state is a lower trouble prone level, so that a lesser amount of log detail is logged for at least the next transaction after the current transaction, i.e., for the next transaction and immediately succeeding ones at the same trouble prone level. Conversely, the selection sent <b>338</b> is an increased log detail selection responsive to an instance of determining <b>330</b> that the current trouble prone state is a higher trouble prone level, so that a greater amount of log detail is logged for at least the next transaction after the current transaction, i.e., for the next transaction and immediately succeeding ones at the same trouble prone level.</p><p id="p-0041" num="0080">In one alternative, when increased log detail selection applies, the logic module may also send a selection to the target application directing the target application to generate a separate log file for the next transaction and subsequent transactions of the same, higher detail level. The separate file may be either instead of or else in addition to the log file to which records are currently being written. The logic module may be configured to also apply other criteria for generating separate log files. For example, it may only generate separate log files when the trouble prone state is the highest level.</p><p id="p-0042" num="0081">Still further, it should be understood that generating <b>314</b> the parsed event data by the at least one NL processor may include generating the parsed event data by an NL processor of the logic module. Also, the first and second machine learning models applied for the first and second classifiers at <b>318</b> and <b>322</b>, respectively, may include respective clustering models.</p><p id="p-0043" num="0082">Also from the foregoing, it should be understood that the context states of respective transactions of the target application may include, in an embodiment, a security context for one of the transactions, for example, a technical context for one of the transactions, for example, and a functional context for one of the transactions, for example. The hierarchical levels may include at least a lowest level, a highest level and a level between the lowest and highest levels.</p><p id="p-0044" num="0083">As further illustrated in flow chart fashion in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, according to an embodiment of the present invention, at least the following actions are performed <b>348</b> prior to production runtime of the target application. Sample instructions for transactions are provided <b>350</b> by a user to the target application for training, including for transactions that are known to be for a certain context state and known to have a certain trouble prone level (i.e., trouble prone state). The user also identifies <b>354</b> for the logic module the associations of the known states (context and trouble prone states) and respective sample instructions. Also at <b>354</b>, the user provides rules to the logic module for identifying context and trouble prone states. That is, transactions that match certain ones of the rules are also trouble prone and of a certain context, as has been described in examples herein. The user may also provide sample transaction instructions for training that match ones of the rules but that the user does not otherwise identify to the logic module for tagging.</p><p id="p-0045" num="0084">Once the user has compiled or otherwise provided the application with source code for the sample transactions and their corresponding event log statements, the application executes <b>362</b> all the transaction statements and their log statements, which generates event logs. The event logs are parsed by NL processing, as described previously herein above. The logic module adds context and trouble prone tags <b>366</b> to the parsed event data for applicable transactions based on the known, user identified transactions. Also, due to parsed event data for the transactions matching ones of the rules, the logic module tags <b>370</b> any applicable transactions according to their context and trouble prone states, even though the transactions are not otherwise identified by the user for tagging. The classifiers are then trained <b>374</b> on the tagged, parsed event data, so that the classifiers will recognize context and trouble prone states for untagged, parsed event data for transactions during production runtime.</p><p id="p-0046" num="0085">It should be appreciated that patterns for classifying log <b>106</b> data may differ from feature to feature and based on implementation, which are unique to every workload. Machine learning needs more and more data to be accurate in detection. Embodiments of the present invention involve a recognition that every implementation has unique customization, service rules, nonfunctional requirement needs and security policies. The disclosed technology relies upon logs <b>106</b> to validate the correctness of solutions before use in actual service. In so doing , the context of implementation is factored in for classifying the log <b>106</b> data. Since log <b>106</b> data generated in non-production environments are varied, large and diverse, such data is very useful for training the machine learning models <b>140</b>.</p><p id="p-0047" num="0086">The following provides a detailed description of aspects concerning a cloud computing embodiment of the present invention. It is to be understood that although this disclosure includes this detailed description regarding cloud computing, implementation of the teachings recited throughout this application are not limited to a cloud computing environment. Rather, embodiments of the present invention are capable of being implemented in conjunction with any other type of computing environment now known or later developed.</p><p id="p-0048" num="0087">Cloud computing is a model of service delivery for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, network bandwidth, servers, processing, memory, storage, applications, virtual machines, and services) that can be rapidly provisioned and released with minimal management effort or interaction with a provider of the service. This cloud model may include at least five characteristics, at least three service models, and at least four deployment models.</p><p id="p-0049" num="0088">Characteristics are as follows:</p><p id="p-0050" num="0089">On-demand self-service: a cloud consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with the service's provider.</p><p id="p-0051" num="0090">Broad network access: capabilities are available over a network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, laptops, and PDAs).</p><p id="p-0052" num="0091">Resource pooling: the provider's computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to demand. There is a sense of location independence in that the consumer generally has no control or knowledge over the exact location of the provided resources but may be able to specify location at a higher level of abstraction (e.g., country, state, or datacenter).</p><p id="p-0053" num="0092">Rapid elasticity: capabilities can be rapidly and elastically provisioned, in some cases automatically, to quickly scale out and rapidly released to quickly scale in. To the consumer, the capabilities available for provisioning often appear to be unlimited and can be purchased in any quantity at any time.</p><p id="p-0054" num="0093">Measured service: cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Resource usage can be monitored, controlled, and reported, providing transparency for both the provider and consumer of the utilized service.</p><p id="p-0055" num="0094">Service Models are as follows:</p><p id="p-0056" num="0095">Software as a Service (SaaS): the capability provided to the consumer is to use the provider's applications running on a cloud infrastructure. The applications are accessible from various client devices through a thin client interface such as a web browser (e.g., web-based e-mail). The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited user-specific application configuration settings.</p><p id="p-0057" num="0096">Platform as a Service (PaaS): the capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages and tools supported by the provider. The consumer does not manage or control the underlying cloud infrastructure including networks, servers, operating systems, or storage, but has control over the deployed applications and possibly application hosting environment configurations.</p><p id="p-0058" num="0097">Infrastructure as a Service (IaaS): the capability provided to the consumer is to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can include operating systems and applications. The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, deployed applications, and possibly limited control of select networking components (e.g., host firewalls).</p><p id="p-0059" num="0098">Deployment Models are as follows:</p><p id="p-0060" num="0099">Private cloud: the cloud infrastructure is operated solely for an organization. It may be managed by the organization or a third party and may exist on-premises or off-premises.</p><p id="p-0061" num="0100">Community cloud: the cloud infrastructure is shared by several organizations and supports a specific community that has shared concerns (e.g., mission, security requirements, policy, and compliance considerations). It may be managed by the organizations or a third party and may exist on-premises or off-premises.</p><p id="p-0062" num="0101">Public cloud: the cloud infrastructure is made available to the general public or a large industry group and is owned by an organization selling cloud services.</p><p id="p-0063" num="0102">Hybrid cloud: the cloud infrastructure is a composition of two or more clouds (private, community, or public) that remain unique entities but are bound together by standardized or proprietary technology that enables data and application portility (e.g., cloud bursting for load-balancing between clouds).</p><p id="p-0064" num="0103">A cloud computing environment is service oriented with a focus on statelessness, low coupling, modularity, and semantic interoperability. At the heart of cloud computing is an infrastructure that includes a network of interconnected nodes.</p><p id="p-0065" num="0104">Referring now to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, illustrative cloud computing environment <b>50</b> is depicted. As shown, cloud computing environment <b>50</b> includes one or more cloud computing nodes <b>10</b> with which local computing devices used by cloud consumers, such as, for example, personal digital assistant (PDA) or cellular telephone <b>54</b>A, desktop computer <b>54</b>B, laptop computer <b>54</b>C, and/or automobile computer system <b>54</b>N may communicate. Nodes <b>10</b> may communicate with one another. They may be grouped (not shown) physically or virtually, in one or more networks, such as Private, Community, Public, or Hybrid clouds as described hereinabove, or a combination thereof. This allows cloud computing environment <b>50</b> to offer infrastructure, platforms and/or software as services for which a cloud consumer does not need to maintain resources on a local computing device. It is understood that the types of computing devices <b>54</b>A-N shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> are intended to be illustrative only and that computing nodes <b>10</b> and cloud computing environment <b>50</b> can communicate with any type of computerized device over any type of network and/or network addressable connection (e.g., using a web browser).</p><p id="p-0066" num="0105">Referring now to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, a set of functional abstraction layers provided by cloud computing environment <b>50</b> (<figref idref="DRAWINGS">FIG. <b>6</b></figref>) is shown. It should be understood in advance that the components, layers, and functions shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref> are intended to be illustrative only and embodiments of the invention are not limited thereto. As depicted, the following layers and corresponding functions are provided:</p><p id="p-0067" num="0106">Hardware and software layer <b>60</b> includes hardware and software components. Examples of hardware components include: mainframes <b>61</b>; RISC (Reduced Instruction Set Computer) architecture based servers <b>62</b>; servers <b>63</b>; blade servers <b>64</b>; storage devices <b>65</b>; and networks and networking components <b>66</b>. In some embodiments, software components include network application server software <b>67</b> and database software <b>68</b>.</p><p id="p-0068" num="0107">Virtualization layer <b>70</b> provides an abstraction layer from which the following examples of virtual entities may be provided: virtual servers <b>71</b>; virtual storage <b>72</b>; virtual networks <b>73</b>, including virtual private networks; virtual applications and operating systems <b>74</b>; and virtual clients <b>75</b>.</p><p id="p-0069" num="0108">In one example, management layer <b>80</b> may provide the functions described below. Resource provisioning <b>81</b> provides dynamic procurement of computing resources and other resources that are utilized to perform tasks within the cloud computing environment. Metering and Pricing <b>82</b> provide cost tracking as resources are utilized within the cloud computing environment, and billing or invoicing for consumption of these resources. In one example, these resources may include application software licenses. Security provides identity verification for cloud consumers and tasks, as well as protection for data and other resources. User portal <b>83</b> provides access to the cloud computing environment for consumers and system administrators. Service level management <b>84</b> provides cloud computing resource allocation and management such that required service levels are met. Service Level Agreement (SLA) planning and fulfillment <b>85</b> provide pre-arrangement for, and procurement of, cloud computing resources for which a future requirement is anticipated in accordance with an SLA.</p><p id="p-0070" num="0109">Workloads layer <b>90</b> provides examples of functionality for which the cloud computing environment may be utilized. Examples of workloads and functions which may be provided from this layer include: mapping and navigation <b>91</b>; software development and lifecycle management <b>92</b>; virtual classroom education delivery <b>93</b>; data analytics processing <b>94</b>; transaction processing <b>95</b>; and logging <b>96</b>.</p><p id="p-0071" num="0110">The present invention may be a system, a method, and/or a computer program product at any possible technical detail level of integration. The computer program product may include a computer readable storage medium (or media) having computer readable program instructions thereon for causing a processor to carry out aspects of the present invention.</p><p id="p-0072" num="0111">The computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device. The computer readable storage medium may be, for example, but is not limited to, an electronic storage device, a magnetic storage device, an optical storage device, an electromagnetic storage device, a semiconductor storage device, or any suitable combination of the foregoing. A non-exhaustive list of more specific examples of the computer readable storage medium includes the following: a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), a static random access memory (SRAM), a portable compact disc read-only memory (CD-ROM), a digital versatile disk (DVD), a memory stick, a floppy disk, a mechanically encoded device such as punch-cards or raised structures in a groove having instructions recorded thereon, and any suitable combination of the foregoing. A computer readable storage medium, as used herein, is not to be construed as being transitory signals per se, such as radio waves or other freely propagating electromagnetic waves, electromagnetic waves propagating through a waveguide or other transmission media (e.g., light pulses passing through a fiber-optic cable), or electrical signals transmitted through a wire.</p><p id="p-0073" num="0112">Computer readable program instructions described herein can be downloaded to respective computing/processing devices from a computer readable storage medium or to an external computer or external storage device via a network, for example, the Internet, a local area network, a wide area network and/or a wireless network. The network may comprise copper transmission cables, optical transmission fibers, wireless transmission, routers, firewalls, switches, gateway computers and/or edge servers. A network adapter card or network interface in each computing/processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium within the respective computing/processing device.</p><p id="p-0074" num="0113">Computer readable program instructions for carrying out operations of the present invention may be assembler instructions, instruction-set-architecture (ISA) instructions, machine instructions, machine dependent instructions, microcode, firmware instructions, state-setting data, configuration data for integrated circuitry, or either source code or object code written in any combination of one or more programming languages, including an object oriented programming language such as C++, or the like, and procedural programming languages, such as the &#x201c;C&#x201d; programming language or similar programming languages. Reference herein to a &#x201c;procedure&#x201d; is not necessarily intended to indicate implementation of invention embodiments in a procedural language.</p><p id="p-0075" num="0114">The computer readable program instructions may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider). In some embodiments, electronic circuitry including, for example, programmable logic circuitry, field-programmable gate arrays (FPGA), or programmable logic arrays (PLA) may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to personalize the electronic circuitry, in order to perform aspects of the present invention.</p><p id="p-0076" num="0115">Aspects of the present invention are described herein with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems), and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer readable program instructions.</p><p id="p-0077" num="0116">These computer readable program instructions may be provided to a processor of a computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks. These computer readable program instructions may also be stored in a computer readable storage medium that can direct a computer, a programmable data processing apparatus, and/or other devices to function in a particular manner, such that the computer readable storage medium having instructions stored therein comprises an article of manufacture including instructions which implement aspects of the function/act specified in the flowchart and/or block diagram block or blocks.</p><p id="p-0078" num="0117">The computer readable program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other device to cause a series of operational steps to be performed on the computer, other programmable apparatus or other device to produce a computer implemented process, such that the instructions which execute on the computer, other programmable apparatus, or other device implement the functions/acts specified in the flowchart and/or block diagram block or blocks.</p><p id="p-0079" num="0118">The flowchart and block diagrams in the Figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods, and computer program products according to various embodiments of the present invention. In this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of instructions, which comprises one or more executable instructions for implementing the specified logical function(s). In some alternative implementations, the functions noted in the blocks may occur out of the order noted in the Figures. For example, two blocks shown in succession may, in fact, be accomplished as one step, executed concurrently, substantially concurrently, in a partially or wholly temporally overlapping manner, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.</p><p id="p-0080" num="0119">One or more databases may be included in a host for storing and providing access to data for the various implementations. One skilled in the art will also appreciate that, for security reasons, any databases, systems, or components of the present invention may include any combination of databases or components at a single location or at multiple locations, wherein each database or system includes any of various suitable security features, such as firewalls, access codes, encryption, de-encryption and the like.</p><p id="p-0081" num="0120">The database may be any type of database, such as relational, hierarchical, object-oriented, and/or the like. A database product that may be used to implement the databases is IBM&#xae; DB2&#xae;, or other available database products. (IBM and DB2 are trademarks of International Business Machines Corporation, registered in many jurisdictions worldwide.) The database may be organized in any suitable manner, including as data tables or lookup tables.</p><p id="p-0082" num="0121">Association of certain data may be accomplished through any data association technique known and practiced in the art. For example, the association may be accomplished either manually or automatically. Automatic association techniques may include, for example, a database search, a database merge, GREP, AGREP, SQL, and/or the like. The association step may be accomplished by a database merge function, for example, using a key field in each of the manufacturer and retailer data tables. A key field partitions the database according to the high-level class of objects defined by the key field. For example, a certain class may be designated as a key field in both the first data table and the second data table, and the two data tables may then be merged on the basis of the class data in the key field. In this embodiment, the data corresponding to the key field in each of the merged data tables is preferably the same. However, data tables having similar, though not identical, data in the key fields may also be merged by using AGREP, for example.</p><p id="p-0083" num="0122">While this specification contains many specifics, these should not be construed as limitations on the scope of the invention or of what can be claimed, but rather as descriptions of features specific to particular implementations of the invention. Certain features that are described in this specification in the context of separate implementations can also be implemented in combination in a single implementation. Conversely, various features that are described in the context of a single implementation can also be implemented in multiple implementations separately or in any suitable sub combination. Also, although features can be described above as acting in certain combinations and even initially claimed as such, features from a claimed combination can in some cases be excised from the combination, and the claimed combination directed to a subcombination or variation of a subcombination.</p><p id="p-0084" num="0123">Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. Likewise, the actions recited in the claims can be performed in a different order and still achieve desirable results. In certain circumstances, multitasking and parallel processing can be advantageous. Moreover, the separation of various system components in the implementations described above should not be understood as requiring such separation in all implementations, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.</p><p id="p-0085" num="0124">Benefits, other advantages, and solutions to problems have been described above with regard to specific embodiments. However, the benefits, advantages, solutions to problems, and any element(s) that may cause any benefit, advantage, or solution to occur or become more pronounced are not to be construed as critical, required, or essential features or elements of any or all the claims.</p><p id="p-0086" num="0125">The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the invention. As used herein, the singular forms &#x201c;a&#x201d;, &#x201c;an&#x201d; and &#x201c;the&#x201d; are intended to include the plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms &#x201c;comprises&#x201d; and/or &#x201c;comprising,&#x201d; when used in this specification, specify the presence of stated features, integers, steps, operations, elements, and/or components, but do not preclude the presence or addition of one or more other features, integers, steps, operations, elements, components, and/or groups thereof. Further, no element described herein is required for the practice of the invention unless expressly described as essential or critical.</p><p id="p-0087" num="0126">The corresponding structures, materials, acts, and equivalents of all means or step plus function elements in the claims below are intended to include any structure, material, or act for performing the function in combination with other claimed elements as claimed.</p><p id="p-0088" num="0127">It should be appreciated that the particular implementations shown and described herein are illustrative of the invention and its best mode and are not intended to otherwise limit the scope of the present invention in any way. Other variations are within the scope of the following claims. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the invention. The embodiments presented herein were chosen and described in order to best explain the principles of the invention and the practical application and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated. The description of the present invention has been presented for purposes of illustration and description but is not intended to be exhaustive or limited to the invention in the form disclosed.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer system implemented method of dynamic logging including:<claim-text>generating parsed event data by at least one natural language (NL) processor responsive to event data of a log for transactions of a target application;</claim-text><claim-text>classifying, by a first classifier applying a first machine learning model to the parsed event data, context states of the respective transactions of the target application;</claim-text><claim-text>classifying, by a second classifier applying a second machine learning model to the parsed event data and the context states, trouble prone states of the respective transactions, wherein the trouble prone states are for respective hierarchical levels;</claim-text><claim-text>determining, by a logic module, for a current one of the trouble prone states for a current transaction, that the current trouble prone state is a higher trouble prone level than for a transaction immediately preceding the current transaction; and</claim-text><claim-text>sending, by the logic module to the target application, an increased log detail selection responsive to the determining that the current trouble prone state is the higher trouble prone level, so that a greater amount of log detail is logged for at least a next transaction after the current transaction.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the context states of respective transactions of the target application include a security context.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the context states of respective transactions of the target application include a technical context.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the context states of respective transactions of the target application include a functional context.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the hierarchical levels include at least a lowest level, a highest level and a level between the lowest and highest levels.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising:<claim-text>determining, by the logic module, for a current one of the trouble prone states for a current transaction, that the current trouble prone state is a lower trouble prone level than for a transaction immediately preceding the current transaction; and<claim-text>sending, by the dynamic logging level logic to the target application, a decreased log detail selection responsive to the determining that the current trouble prone state is the lower trouble prone level, so that a decreased amount of log detail is logged for at least a next transaction after the current transaction.</claim-text></claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising:<claim-text>generating the parsed event data by the at least one NL processor includes generating the parsed event data by a NL processor of the logic module.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first and second machine learning models include respective clustering models.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A computer system for dynamic logging, the system comprising:<claim-text>a processor; and</claim-text><claim-text>a computer readable storage medium connected to the processor, wherein the computer readable storage medium has stored thereon a program for controlling the processor, and wherein the processor is operative with the program to execute the program for:<claim-text>generating parsed event data by at least one natural language (NL) processor responsive to event data of a log for transactions of a target application;</claim-text><claim-text>classifying, by a first classifier applying a first machine learning model to the parsed event data, context states of the respective transactions of the target application;</claim-text><claim-text>classifying, by a second classifier applying a second machine learning model to the parsed event data and the context states, trouble prone states of the respective transactions, wherein the trouble prone states are for respective hierarchical levels;</claim-text><claim-text>determining, by a logic module, for a current one of the trouble prone states for a current transaction, that the current trouble prone state is a higher trouble prone level than for a transaction immediately preceding the current transaction; and</claim-text><claim-text>sending, by the logic module to the target application, an increased log detail selection responsive to the determining that the current trouble prone state is the higher trouble prone level, so that a greater amount of log detail is logged for at least a next transaction after the current transaction.</claim-text></claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The computer system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the context states of respective transactions of the target application include a security context, a technical context and a functional context.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The computer system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the hierarchical levels include at least a lowest level, a highest level and a level between the lowest and highest levels.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The computer system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the processor is operative with the program to execute the program for:<claim-text>determining, by the logic module, for a current one of the trouble prone states for a current transaction, that the current trouble prone state is a lower trouble prone level than for a transaction immediately preceding the current transaction; and<claim-text>sending, by the dynamic logging level logic to the target application, a decreased log detail selection responsive to the determining that the current trouble prone state is the lower trouble prone level, so that a decreased amount of log detail is logged for at least a next transaction after the current transaction.</claim-text></claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The computer system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein generating the parsed event data by the at least one NL processor includes generating the parsed event data by a NL processor of the logic module.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The computer system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the first and second machine learning models include respective clustering models.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A computer program product for dynamic logging, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a processor to cause the processor to:<claim-text>generate parsed event data by at least one natural language (NL) processor responsive to event data of a log for transactions of a target application;</claim-text><claim-text>classify, by a first classifier applying a first machine learning model to the parsed event data, context states of the respective transactions of the target application;</claim-text><claim-text>classify, by a second classifier applying a second machine learning model to the parsed event data and the context states, trouble prone states of the respective transactions, wherein the trouble prone states are for respective hierarchical levels;</claim-text><claim-text>determine, by a logic module, for a current one of the trouble prone states for a current transaction, that the current trouble prone state is a higher trouble prone level than for a transaction immediately preceding the current transaction; and</claim-text><claim-text>send, by the logic module to the target application, an increased log detail selection responsive to the determining that the current trouble prone state is the higher trouble prone level, so that a greater amount of log detail is logged for at least a next transaction after the current transaction.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The computer program product of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the context states of respective transactions of the target application include a security context, a technical context and a functional context.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The computer program product of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the hierarchical levels include at least a lowest level, a highest level and a level between the lowest and highest levels.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The computer program product of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the program instructions are executable by a processor to cause the processor to:<claim-text>determine, by the logic module, for a current one of the trouble prone states for a current transaction, that the current trouble prone state is a lower trouble prone level than for a transaction immediately preceding the current transaction; and</claim-text><claim-text>send, by the dynamic logging level logic to the target application, a decreased log detail selection responsive to the determining that the current trouble prone state is the lower trouble prone level, so that a decreased amount of log detail is logged for at least a next transaction after the current transaction.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The computer program product of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein generating the parsed event data by the at least one NL processor includes generating the parsed event data by a NL processor of the logic module.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The computer program product of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the first and second machine learning models include respective clustering models.</claim-text></claim></claims></us-patent-application>
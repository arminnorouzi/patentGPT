<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005258A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005258</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17781841</doc-number><date>20191217</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>20</main-group><subgroup>10</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>73</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>20</main-group><subgroup>182</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>73</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30181</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">PREDICTION METHOD</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>NEC Corporation</orgname><address><city>Minato-ku, Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>SHINODA</last-name><first-name>Shigeki</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>IKEFUJI</last-name><first-name>Daisuke</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>TOMINGA</last-name><first-name>Shin</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>SENDA</last-name><first-name>Yuzo</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>INOUE</last-name><first-name>Hirofumi</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>NEC Corporation</orgname><role>03</role><address><city>Minato-ku, Tokyo</city><country>JP</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2019/049340</doc-number><date>20191217</date></document-id><us-371c12-date><date>20220602</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A prediction device <b>100</b> of the present invention includes a detection means <b>121</b> for, on the basis of a river image that is an image obtained by capturing a river and associated with capturing position information representing a position where the river is captured, detecting river condition information representing a condition of the river at the position where the river image is captured; and a prediction means <b>122</b> for, on the basis of the capturing position information, the river condition information, and topography information representing the topography of the river, predicting a river condition representing a condition of the river at a given point of the river. The given point is different from the position represented by the capturing position information.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="110.66mm" wi="158.75mm" file="US20230005258A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="199.05mm" wi="156.89mm" orientation="landscape" file="US20230005258A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="194.48mm" wi="121.50mm" orientation="landscape" file="US20230005258A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="210.82mm" wi="140.29mm" orientation="landscape" file="US20230005258A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="99.14mm" wi="146.13mm" file="US20230005258A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="167.22mm" wi="144.86mm" file="US20230005258A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="167.22mm" wi="144.86mm" file="US20230005258A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="231.39mm" wi="157.90mm" file="US20230005258A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="231.82mm" wi="157.99mm" file="US20230005258A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="231.82mm" wi="157.99mm" file="US20230005258A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="143.34mm" wi="69.51mm" file="US20230005258A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="172.89mm" wi="146.39mm" orientation="landscape" file="US20230005258A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="98.30mm" wi="126.07mm" file="US20230005258A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="105.75mm" wi="73.07mm" file="US20230005258A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present invention relates to a prediction method, a prediction device, and a program, for predicting river conditions.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">A disaster caused by a flood of a river may occur due to a natural phenomenon such as a typhoon or heavy rain or an artificial factor. In the case of such a disaster, information related to the river is collected by institutions such as national and local governments and professional service providers, and the institutions provide alarm information representing the river conditions to general users by means of street announcement, television, radio, and the Internet using medium such as voice and images. For example, alarm information is information indicating that a river flood may occur.</p><p id="p-0004" num="0003">For example, Patent Literature 1 discloses a system providing alarm information. In the river information management system disclosed in Patent Literature 1, rain amount/water level data is collected from a measurement device provided to the river, and weather data is also collected, and a predicted water level is calculated from the collected data. Then, the river information management system provides users with not only data of the water level of the river but also images of the river.</p><p id="p-0005" num="0004">Patent Literature 1: JP 2007-46918 A</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0006" num="0005">However, the art of Patent Literature 1 described above merely calculates the water level of a river based on the data collected mainly from a measurement device provided to the river. Therefore, at a point of a river away from the place where a measurement device is installed or at a given point of a river where the number of installed measurement devices is not sufficient, it is impossible to improve the accuracy of predicting the water level. Consequently, this causes a problem that it is impossible to improve the accuracy of predicting all conditions including the water level at a given point of a river.</p><p id="p-0007" num="0006">In view of the above, an object of the present invention is to provide a prediction method, a prediction device, and a program capable of solving the above-described problem, that is, a problem that it is impossible to improve the accuracy of predicting the conditions at a given point of a river.</p><p id="p-0008" num="0007">A prediction method, according to one aspect of the present invention, is configured to include</p><p id="p-0009" num="0008">on the basis of a river image that is an image obtained by capturing a river and associated with capturing position information representing a position at which the river is captured, detecting river condition information representing a condition of the river at the position at which the river image is captured, and</p><p id="p-0010" num="0009">on the basis of the capturing position information, the river condition information, and topography information representing the topography of the river, predicting a river condition representing a condition of the river at a given point of the river, the given point being different from the position represented by the capturing position information.</p><p id="p-0011" num="0010">A prediction device, according to one aspect of the present invention, is configured to include</p><p id="p-0012" num="0011">a detection means for, on the basis of a river image that is an image obtained by capturing a river and associated with capturing position information representing a position at which the river is captured, detecting river condition information representing a condition of the river at the position at which the river image is captured; and</p><p id="p-0013" num="0012">a prediction means for, on the basis of the capturing position information, the river condition information, and topography information representing topography of the river, predicting a river condition representing a condition of the river at a given point of the river, the given point being different from the position represented by the capturing position information.</p><p id="p-0014" num="0013">A program, according to one aspect of the present invention, is configured to cause a processor of an information processing device to execute processing to:</p><p id="p-0015" num="0014">on the basis of a river image that is an image obtained by capturing a river and associated with capturing position information representing a position at which the river is captured, detect river condition information representing a condition of the river at the position at which the river image is captured; and</p><p id="p-0016" num="0015">on the basis of the capturing position information, the river condition information, and topography information representing topography of the river, predict a river condition representing a condition of the river at a given point of the river, the given point being different from the position represented by the capturing position information.</p><p id="p-0017" num="0016">Since the present invention is configured as described above, the present invention enables improvements in the accuracy of predicting conditions at a given point of a river.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating a configuration of an information processing system according to a first exemplary embodiment of the present invention.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating the configuration of the information processing system disclosed in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating a configuration of a prediction device and an image collection device disclosed in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an exemplary captured image stored in the image collection device disclosed in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates exemplary topography information stored in the image collection device disclosed in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates exemplary weather information stored in the image collection device disclosed in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an exemplary prediction process performed by the prediction device disclosed in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an exemplary prediction process performed by the prediction device disclosed in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an exemplary prediction process performed by the prediction device disclosed in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart illustrating an operation of the information processing system disclosed in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram illustrating a hardware configuration of an information processing system according to a second exemplary embodiment of the present invention.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a block diagram illustrating a configuration of the information processing system according to the second exemplary embodiment of the present invention.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flowchart illustrating an operation of the information processing system according to the second exemplary embodiment of the present invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">EXEMPLARY EMBODIMENTS</heading><heading id="h-0006" level="1">First Exemplary Embodiment</heading><p id="p-0031" num="0030">A first exemplary embodiment of the present invention will be described with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>10</b></figref>. <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>6</b></figref> are diagrams for explaining a configuration of an information processing system, and <figref idref="DRAWINGS">FIGS. <b>7</b> to <b>10</b></figref> are illustrations for explaining the processing operation of the information processing system.</p><heading id="h-0007" level="1">Configuration</heading><p id="p-0032" num="0031">An information processing system <b>1</b> of the present invention is a system for predicting conditions such as a water level of a river, in order to suppress damages by a flood of the river. As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the information processing system <b>1</b> of the present embodiment is configured to include an image collection device <b>10</b> and a prediction device <b>20</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the information processing system <b>1</b> is connected to user terminals UTa, UTb, and UTc held by users Ua, Ub, and Uc via wireless communication. In particular, the image collection device <b>10</b> included in the information processing system <b>1</b> is connected to the user terminals UTa and UTb held by the users Ua and Ub who capture images of points A and B of a river R, and the prediction device <b>20</b> included in the information processing system <b>1</b> is connected to the user terminal UTc of the user Uc who desires to be provided with notice information representing the conditions of the river at another point C of the river R. Hereinafter, each device will be described in detail.</p><p id="p-0033" num="0032">Each of the user terminals UTa and UTb is configured of an information processing terminal such as a smartphone having a camera function. The user terminals UTa and UTb are held by the users Ua and Ub respectively who capture a point of the river R to obtain a river image. The users Ua and Ub may be persons in charge of monitoring the river conditions in the national or local governments or general users.</p><p id="p-0034" num="0033">The user terminals UTa and UTb each have a function of, when capturing an image of a point of the river R, transmitting the captured river image to the image collection device <b>10</b>. At that time, the user terminals UTa and UTb each transmit capturing position information representing the position of the river whose image is captured, and capturing time information representing the capturing time, to the image collection device <b>10</b> in association with the river image. The user terminals UTa and UTb also transmits, to the image collection device <b>10</b>, capturing person information specifying the users Ua and Ub holding the user terminals UTa and UTb respectively, in association with the river image. Note that in the case where a user is a registered user who has already registered with the image collection device <b>10</b>, the information in which the user can be identified as a registered user may be used as the capturing person information.</p><p id="p-0035" num="0034">In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, it is assumed that at a point A located uppermost stream of the river R, the user Ua captures a river image with the user terminal UTa and transmits it to the image collection device <b>10</b>. Further, it is also assumed that at a point B located relatively upstream of the river R and on the downstream side of the point A, the user Ub captures a river image with the user terminal UTb and transmits it to the image collection device <b>10</b>.</p><p id="p-0036" num="0035">While the present embodiment illustrates the case where the user terminals UTa and UTb are mobile information processing terminals as an example, they may be imaging devices fixedly provided at the points A and B of the river R. In that case, the captured river image is associated with identification information for identifying the capturing device as the capturing person information.</p><p id="p-0037" num="0036">Further, as illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the user terminal UTc that is different from the user terminals UTa and UTb is configured of an information processing terminal such as a smartphone held by the user Uc who is present in a region Rc located around a point C downstream of the river R. At that time, the user Uc is a person who lives in the region Rc or temporarily stays, and has a function of registering, with the prediction device <b>20</b>, information of the user Uc himself/herself so as to acquire notice information of the river conditions at the point C of the river. Specifically, the user terminal UTc has a function of transmitting and registering transmission destination information such as an email address to the prediction device <b>20</b> according to an operation by the user Uc. The user terminal UTc also has a function of transmitting position information of the own terminal to the prediction device <b>20</b> to notify the prediction device <b>20</b> thereof at certain time intervals according to an operation by the user or automatically. Note that the user Uc may be a person who is conducting a rescue operation in the region Rc in the case where inundation occurred in the region Rc around the point C of the river R in the past.</p><p id="p-0038" num="0037">The user terminal UTc of the user Uc also has a function of receiving notice information representing the river conditions at the point C of the river R transmitted from the prediction device <b>20</b>, and outputting it to the user Uc. For example, the user terminal UTc outputs sound information provided as notice information from a loudspeaker, or displays information consisting of text and images on a display screen.</p><p id="p-0039" num="0038">Next, the configuration of the image collection device <b>10</b> will be described. The image collection device <b>10</b> is configured of one or a plurality of information processing devices each having an arithmetic device and a storage device. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the image collection device <b>10</b> includes an image collection unit <b>11</b> that is constructed by execution of a program by the arithmetic device. The image collection device <b>10</b> also includes an image storage unit <b>12</b> formed in the storage device. Hereinafter, each configuration will be described in detail.</p><p id="p-0040" num="0039">The image collection unit <b>11</b> collects river images captured and transmitted by the user terminals UTa and UTb, and stores them in the image storage unit <b>12</b>. At that time, since a river image is associated with capturing position information representing the capturing position of the river, capturing time information representing the capturing time, and capturing person information representing the user who captured the captured image as metadata, the captured image and the meta data are stored in the image storage unit <b>12</b> in association with each other.</p><p id="p-0041" num="0040">While the image collection unit <b>11</b> may collect only river images associated with the capturing person information specifying the users Ua and Ub who have been registered beforehand and store them in the image storage unit <b>12</b>, the image collection unit <b>11</b> may collect river images captured by general users who are not registered and store them in the image storage unit <b>12</b>. For example, the image collection unit <b>11</b> may collect river images disclosed in websites in which images captured and posted by general users are disclosed. In that case, river images are collected on the basis of information specifying the capturing location associated with the river images.</p><p id="p-0042" num="0041">Next, the configuration of the prediction device <b>20</b> will be described. The prediction device <b>20</b> is configured of one or a plurality of information processing devices each having an arithmetic device and a storage device. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the prediction device <b>20</b> includes an acquisition unit <b>21</b>, a detection unit <b>22</b>, a prediction unit <b>23</b>, and a notification unit <b>24</b> that are constructed by execution of a program by the arithmetic device. The prediction device <b>20</b> also includes an acquired image storage unit <b>25</b>, a user information storage unit <b>26</b>, a topography information storage unit <b>27</b>, and a weather information storage unit <b>28</b> that are formed in the storage device. Hereinafter, each configuration will be described in detail.</p><p id="p-0043" num="0042">The acquisition unit <b>21</b> acquires user information transmitted from the user terminal UTc according to registration of the user information by the user Uc who desires to acquire river information of a given point of the river R. For example, as user information, the acquisition unit <b>21</b> acquires point information (position information) specifying a point of the river R that the user Uc desires to acquire notice information, and transmission destination information of the notice information such as an email address that the user terminal UTc can receive. Then, the acquisition unit <b>21</b> stores the acquired user information in the user information storage unit <b>26</b> in association with the point information.</p><p id="p-0044" num="0043">The acquisition unit <b>21</b> also acquires topography information representing the topography of the river R, and stores it in the topography information storage unit <b>27</b>. Here, topography information is information provided by a prescribed institution that creates map information, and is information downloaded from a web server on the Internet or read from a storage medium and stored by the prediction device <b>20</b>. The topography information is information representing positions and shapes of a land L and rivers R and r as illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and also buildings. In particular, topography information includes the position and height of each point of the rivers R and r, the surrounding land, and buildings. With such information, it is possible to recognize the height of an embankment (bank) at each point of the rivers R and r, the width of the river, and the depth of the river.</p><p id="p-0045" num="0044">Further, by referring to the topography information described above, it is possible to recognize the relevance between the main stream and a branch of the river. For example, the example illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows that a river denoted by the reference numeral R is the main stream and a river denoted by the reference numeral r is a branch. Further, by referring to the topography information, it is possible to recognize the similarity in the topography of rivers. For example, when there are a plurality of rivers, in the case where upstream areas of one river and another river are the same area or the widths and depths at respective points of respective rivers are similar according to a preset reference, it can be determined that these rivers are similar in the topography.</p><p id="p-0046" num="0045">The acquisition unit <b>21</b> also acquires weather information and stores it in the weather information storage unit <b>28</b>. Here, weather information is information provided by a prescribed institution that observes and predicts the weather, and is information downloaded from a web server on the Internet or read from a storage medium and stored by the prediction device <b>20</b>. The weather information is information representing all weather conditions such as weather and the amount of rainfall at each point, and information representing the current weather condition and prediction of the future weather condition. As illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the weather information also includes typhoon information representing a predicted path of typhoon T. Therefore, by referring to such weather information, it is possible to recognize the weather at each point of the river.</p><p id="p-0047" num="0046">The acquisition unit <b>21</b> also acquires a river image from the image collection device <b>10</b> and stores it in the acquired image storage unit <b>25</b>. The acquired river image is the same as that described above. As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the acquired river image is associated with the capturing position information, the capturing time information, and the capturing person information. Note that the acquisition unit <b>21</b> may refer to the topography information and acquire only the river information in which each point of particular rivers R and r (including the main stream and a branch) is captured.</p><p id="p-0048" num="0047">The detection unit <b>22</b> uses the acquired river image to detect river condition information representing the river condition at the point (position) where the river image is captured. At that time, the detection unit <b>22</b> uses the topography information and performs image processing on the river image to thereby detect the water level at that point as river condition information. Specifically, the detection unit <b>22</b> performs image processing on the river image to detect the top part of the embankment and the water surface part, and detect a height position Rh of the water surface with respect to a height position Re of the embankment on the image as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> with the reference signs. As an example, the detection unit <b>22</b> detects features on the image in the river image to thereby detect feature parts corresponding to the preset reference as a top part of the embankment and a water surface part. Then, the detection unit <b>22</b> specifies a point on the river image from the capturing position information associated with the river image, and determines the actual height of the top of the embankment (bank) at the point from the topography information of the point. The detection unit <b>22</b> also uses the determined actual height of the top of the embankment to detect the actual height position of the water surface from the height position Rh of the water surface with respect to the height position Re of the embankment on the image detected as described above. However, the detection unit <b>22</b> may detect the height position of the embankment and the height position of the water surface by means of any methods.</p><p id="p-0049" num="0048">As the river condition information representing the river condition at the point (position) where the river image is captured, the detection unit <b>22</b> may use the acquired river image to detect another type of information representing the river condition, without being limited to detection of the height position of the water surface at that point. For example, the detection unit <b>22</b> may specify the width and the depth of the river by using the topography information, and detect the flow rate at the point as the river condition information, from the height position of the water surface detected as describe above. Further, from the relationship between the height position of the water surface and the height position of the embankment detected as described above, the detection unit <b>22</b> may detect the degree of danger (for example, the degree of inundation) at that point, calculated based on a preset reference, as river condition information.</p><p id="p-0050" num="0049">The prediction unit <b>23</b> (prediction means) uses the river condition information detected as described above to predict a river condition representing a condition of the river at another point (given point) of the river. Specifically, the prediction unit <b>23</b> first refers to the topography information, and with respect to the specific point of the river shown in the capturing position information of the river image from which the river condition information is detected, specifies another point located downstream of the same river as a prediction object point for newly predicting the river conditions. For example, in the case of detecting the river condition information by using a river image at the point A of the river R illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the point C located downstream from the point A is specified as a prediction object point. As a prediction object point, the prediction unit <b>23</b> may specify a point where houses are crowded, a point where the river R is curved at a curvature that is equal to or larger than a predetermined value, a point where the river width is smaller than a predetermined value, a point where the embankment is lower than a predetermined value, or the like with use of the topography information, or may specify a point that is set in advance as a point where inundation of the river R is likely to be caused.</p><p id="p-0051" num="0050">Then, from the river condition information of the detection point that is a point where the river condition information is detected, the prediction unit <b>23</b> uses the topography information to predict the river conditions at the prediction object point. For example, when the water level at the detection point is detected as the river condition information, the prediction unit <b>23</b> predicts the water level after a predetermined time has passed at the prediction object point located downstream from the detection point. Hereinafter, a specific example of calculating the water level at a prediction object point by the prediction unit <b>23</b> will be described. Here, description will be given under the assumption that the point A in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a detection point and the point C is a prediction object point.</p><p id="p-0052" num="0051">The prediction unit <b>23</b> calculates the flow rate of the water at the detection point A in the river R, from the water level at the detection point A and the topography information of the river R. Then, the prediction unit <b>23</b> estimates that the water having the flow rate at the detection point A reaches the prediction object point C after a predetermined time has passed, and calculates the water level at the prediction object point C by using the topography information of the river R at the prediction object point C. At that time, the prediction unit <b>23</b> predicts the water level at the prediction object point C according to a predetermined calculation formula by using, as the topography information of the river R, information such as the curvature of the shape, the inclination, and the depth of the river R and the height of the embankment at each point from the detection point A to the prediction object point C.</p><p id="p-0053" num="0052">Further, the prediction unit <b>23</b> determines whether or not there is a branch r in the river R by using the topography information, and when there is a branch r as illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the prediction unit <b>23</b> predicts the water level at the prediction object point C while considering that the water in the branch r flows into the river R that is the main stream. For example, the prediction unit <b>23</b> specifies the flow rate of the wafer flowing through the branch r by detecting it from the river image captured above the branch r as similar to the above description or using a value previously set for the branch r, adds the flow rate of the water flowing with the branch r to the flow rate of the water flowing through the river R, and calculates the water level at the prediction object point C as similar to the above description.</p><p id="p-0054" num="0053">The prediction unit <b>23</b> also reads the weather information from the weather information storage unit <b>28</b>, and calculates the water level at the prediction object point C while considering the weather condition at each point of the river R. In particular, the prediction unit <b>23</b> considers the weather conditions not only at the prediction object point C of the river R but also at the points A and B (including points of branches) located upstream from the prediction object point C in the same river R and a point of the branch r. For example, when it is raining or rain is expected at the prediction object point C of the river R or the upstream side thereof, the prediction unit <b>23</b> calculates the water level at the prediction object point C as similar to that described above by adding the actual rainfall amount or expected rainfall amount to the flow rate of the water flowing through the river R. As an example, as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the prediction unit <b>23</b> calculates the water level at the prediction object point C by using the expected rainfall amount at each point in the upstream of the river R and the branch r, with use of a predicted route of a typhoon T as weather information.</p><p id="p-0055" num="0054">The prediction unit <b>23</b> predicts the river condition (for example, water level) of the prediction object point C as described above, and also predicts the time when the condition at the prediction object point C becomes the predicted river condition, by using the capturing time information at which the river image from which the river condition information at the detection point A is captured. For example, the prediction unit <b>23</b> calculates the time when the water at the detection point A will reach the prediction object point C with a preset calculation formula, by using, as the topography information, information such as the curvature of the shape, the inclination, and the depth of the river R at each point from the detection point A to the prediction object point C, and by using the calculated time, predicts the time when the condition at the prediction object point C becomes the predicted river condition. At that time, the prediction unit <b>23</b> predicts the time when the condition at the prediction object point C becomes the predicted river condition while considering presence of the branch r and an increase in the flow rate of the water due to the weather condition, as described above.</p><p id="p-0056" num="0055">The prediction unit <b>23</b> may predict the river condition that is predicted for the prediction object point C of the river R (predetermined river) as described above as a river condition at a given point of another river. For example, on the basis of the topography information, the prediction unit <b>23</b> specifies a plurality of rivers determined to have similar topography to each other according to a preset reference. As an example, the prediction unit <b>23</b> specifies rivers in which some or all of the items such as a distance between rivers, the total volume based on the river width or depth, and a partial area of the flowing area (for example, upstream area) that can be specified from the topography information are determined to be similar to each other according to a preset reference. Then, the prediction unit <b>23</b> predicts the river condition at the prediction object point C of one river of them, and predicts such a river condition as a river condition at a given point of another one of the specified rivers.</p><p id="p-0057" num="0056">While the case where the prediction unit <b>23</b> predicts the water level as a river condition at the prediction object point C has been described above, the prediction unit <b>23</b> may predict any condition of the river R. For example, the prediction unit <b>23</b> may predict the flow rate of the water at the prediction object point C as a river condition. Further, from the water level at the prediction object point C predicted as described above and the topography information (for example, curvature, width, and depth of the river R and the height of the embankment), the prediction unit <b>23</b> may predict the degree of danger representing the degree of inundation of the river R as a river condition.</p><p id="p-0058" num="0057">Here, an example of predicting a river condition at a prediction object point of the river will be described with reference to <figref idref="DRAWINGS">FIGS. <b>7</b> to <b>9</b></figref>. Here, description will be given on the case of further predicting the degree of danger from the water level predicted at a prediction object point of a river, and predicting the degree of danger as a river condition at the prediction object point of the river.</p><p id="p-0059" num="0058">First, the upper graph of <figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates temporal changes in the degree of danger Gc at the prediction object point C of the river R and the degree of danger Ga at the detection point A located upstream thereof. In this example, first, in a time period t<b>1</b>, a state where the degree of danger Gc is high continues due to a heavy rain at the prediction object point C located downstream of the river R, and then in a time period t<b>2</b>, the degree of danger Gc is lowered. On the other hand, in the time period t<b>2</b> in which the degree of danger Gc at the prediction object point C is low, the degree of danger Ga increases due to a heavy rain at the detection point A. Note that the degree of danger Ga at the detection point A in the time period t<b>2</b> represents the same content as the river condition information detected from the river image of the detection point A. By predicting the degree of danger Gc at the prediction object point C in the subsequent time period t<b>3</b> from the degree of danger Ga representing the river condition at the detection point A in such a condition, it is possible to predict that the degree of danger Gc increases as indicated by a dotted line in the lower graph of <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0060" num="0059">Further, the upper graph in <figref idref="DRAWINGS">FIG. <b>8</b></figref> represents temporal changes in the degree of danger Ga at the detection point Ra of the river R, the degree of danger Ga at the prediction object point C of the river R, and the degree of danger ga at a given point of the branch r joining the river R on the upstream side of the prediction object point C of the river R. In this example, in a time period t<b>11</b>, the degree of danger Ga increases due to a heavy rain at the detection point A of the river R, and similarly, the degree of danger ga also increases due to a heavy rain at the given point of the branch r of the river R. It is assumed that the degree of danger Ga at the detection point A in the time period t<b>11</b> represents the same content as the river condition information detected from the river image of the detection point A. It is also assumed that the degree of danger ga at the given point in the time period t<b>11</b> represents the content that can be predicted from the fact that a heavy rain can be estimated from the weather information. By predicting the degree of danger Gc at the prediction object point C of the river R in the subsequent time period t<b>12</b> from the river condition at the detection point A in such a condition, presence of the branch r, and the weather condition, it is possible to predict that the degree of danger Gc increases as indicated by a dotted line in the lower graph of <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0061" num="0060">Further, the upper graph in <figref idref="DRAWINGS">FIG. <b>9</b></figref> represents temporal changes in the degree of danger Ga at the detection point Ra of the river R, the degree of danger Gc at the prediction object point C of the river R, and the degree of danger G&#x2032;c at a given point of another river R&#x2032; determined to have similar topography to that of the river R. For example, it is assumed that in the other river R, a point on the upstream side of the prediction object point is in the same area as that of the detection point A of the river R. In this example, in a time period t<b>21</b>, the degree of danger Ga increases due to a heavy rain at the detection point A of the river R, and the degree of danger Ga and the degree of danger G&#x2032;c at the prediction object point C of the river R and the prediction object point of the other river R&#x2032; decrease. It is assumed that the degree of danger Ga at the detection point A in the time period t<b>21</b> represents the same content as the river condition information detected from the river image of the detection point A. By predicting the degree of danger Gc at the prediction object point C in the subsequent time period t<b>22</b> from the river condition at the detection point A in such a condition, it is possible to predict that the degree of danger Gc increases as indicated by a dotted line in the lower graph of <figref idref="DRAWINGS">FIG. <b>9</b></figref>. As similar to such prediction, it can also be predicted that the degree of danger G&#x2032;c at the prediction object point of the other river R&#x2032; having the topography similar to that of the river R increases as indicated by a dotted line in the lower graph of <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0062" num="0061">In the above description, the prediction unit <b>23</b> predicts the river condition of the prediction object point C by using one type of river condition information of the detection point A of the river R. However, the prediction unit <b>23</b> may predict the river condition of the prediction object point C by using a plurality of pieces of river condition information of the detection point A. For example, it is possible to detect, from a plurality of river images captured at the detection point A, pieces of river condition information representing the river condition at the detection point A, and predicts the river condition of the prediction object point C by using the pieces of river condition information. At that time, the prediction unit <b>23</b> may use the river images whose capturing time is the same by averaging them, or use them by weighting the river condition information detected from the river images according to the priority previously set by the capturing person. Further, regarding pieces of river condition information detected from river images whose capturing time is different, the prediction unit <b>23</b> may use it while considering a time-series change in such information.</p><p id="p-0063" num="0062">Further, in the above description, the prediction unit <b>23</b> predicts the river condition of the prediction object point C by using the river condition information at the detection point A of the river R. However, the prediction unit <b>23</b> may predict the river condition of the prediction object point C by using pieces of river condition information of a plurality of detection points A and B. For example, the prediction unit <b>23</b> may defect a distance difference or a topographical difference between the detection point A and the detection point B of the river R from the topography information, and in consideration of such a difference, may predict the river condition of the prediction object point C by using the river condition information of each of them.</p><p id="p-0064" num="0063">The notification unit <b>24</b> (notification means) notifies the user terminal UTc of a user located at the prediction object point C of notice information that is information representing the river condition at the prediction object point C of the river R predicted by the prediction unit <b>23</b> as described above. For example, the notification unit <b>24</b> extracts user information associated with the prediction object point C of the river R from the user information storage unit <b>26</b>, sets the email address included in the user information as a transmission destination, and transmits the notice information. At that time, the notice information may be the water level itself at the prediction object point predicted as a river condition, or may be a degree of danger further predicted from the water level. Further, to the notice information, the time that the condition of the river becomes the river condition, predicted along with the river condition, may be added.</p><p id="p-0065" num="0064">However, not limited to notifying the user terminal UTc stored in the user information storage unit <b>26</b> of the notice information, the notification unit <b>24</b> may notify another user terminal. For example, the notification unit <b>24</b> may collect address information (telephone number or email address) of a user terminal such as a mobile telephone terminal and current position information from a server device operated by a mobile telephone service provider, and specify the user terminal located at the prediction object point C of the river R on the basis of the current position information, and send the notice information by using the address information of the specified user terminal as destination. Further, the notification unit <b>24</b> may also output notice information to a user located at the prediction object point C of the river R by means of street announcement, television, radio, the Internet, or the like, or using medium such as sound and images.</p><heading id="h-0008" level="1">Operation</heading><p id="p-0066" num="0065">Next, operation of the information processing system <b>1</b> described above will be described with mainly reference to the flowchart of <figref idref="DRAWINGS">FIG. <b>10</b></figref>. It is assumed that the prediction device <b>20</b> constituting the information processing system <b>1</b> acquires and stores user information of the user Uc who desires to be notified of information of the river R, and acquires and stores the topography information of the river R. It is also assumed that the prediction device <b>20</b> always acquires and stores the latest weather information.</p><p id="p-0067" num="0066">First, as illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the image collection device <b>10</b> constituting the information processing system <b>1</b> collects river images captured by the users Ua and Ub at the detection points A and B located upstream of the river R (step S<b>1</b>). At that time, the image collection device <b>10</b> stores the capturing position information, the capturing time information, and the capturing person information in association with the river images.</p><p id="p-0068" num="0067">Then, the prediction device <b>20</b> constituting the information processing system <b>1</b> acquires river images from the image collection device <b>10</b>, and detects river condition information representing the conditions at the detection points A and B of the river R from the river images (step S<b>2</b>). For example, the prediction device <b>20</b> detects, as the river condition information, the height position Rh of the water surface (water level) at each of the detection points A and B of the river R, as illustrated in the river image of <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0069" num="0068">Then, from the detected river condition information at the detection points A and B of the river R, the prediction device <b>20</b> predicts the river condition at a point that is different from the detection points A and B of the river R, in particular, the prediction object point C on the downstream side of the detection points A and B as illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> (step S<b>3</b>). At that time, the prediction device <b>20</b> uses the topography information of the river R to predict the river condition at the prediction object point C located further downstream, from the river conditions of the detection points A and B. For example, the prediction device <b>20</b> predicts the water level at the prediction object point C after a predetermined time has passed, by using information such as the curvature, the river width, the depth, and the height of the embankment, at the points A, B, and C of the river R included in the topography information. Note that the prediction device <b>20</b> may predict, as the river condition, the degree of danger representing the degree that inundation may occur at the prediction object point C, from the topography information such as a predicted water level and height of the embankment at the prediction object point C of the river R.</p><p id="p-0070" num="0069">Further, the prediction device <b>20</b> may use the topography information to predict the river condition at the prediction object point C of the river R while considering presence of the branch r of the river R. The prediction device <b>20</b> may also predict the water level at the prediction object point C while considering the weather conditions at each point of the river R from the weather information. Further, the prediction device <b>20</b> may predict the time that the condition at the prediction object point C becomes the predicted river condition, by using the capturing time information at which the river image used for detecting the river condition information of the detection point A was captured.</p><p id="p-0071" num="0070">Then, the prediction device <b>20</b> notifies the user terminal UTc of a user located at the prediction object point C as illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> of notice information including the predicted river condition at the prediction object point C of the river R. For example, the prediction device <b>20</b> transmits notice information to the email address of the user Uc registered for desiring river information of the prediction object point C, or detects the user UC located at the region Rc around the prediction object point C and transmits notice information to the user terminal UTc of the user Uc.</p><p id="p-0072" num="0071">As described above, in the present invention, the information processing system <b>1</b> first detects river condition information representing the river conditions at the detection points A and</p><p id="p-0073" num="0072">B from the river images in which the detection points A and B of the river R are captured. Then, from the river condition information of the detection points A and B of the river R, the information processing system <b>1</b> detects the river condition of the prediction object point C that is a given point of the river R different from the detection points A and B. Therefore, it is not necessary to provide a measurement device for measuring the water level or the like to the river R. Further, even when there is a shortage of measurement devices, it is possible to predict the river condition at any point of the river with high accuracy by using river images that can be obtained easily.</p><p id="p-0074" num="0073">Then, by notifying the user Uc who is present in the area Rc around the prediction object point C of the predicted river condition at the prediction object point C of the river R, it is possible to cope with a disaster that may be caused such as inundation of the river R to seek refuge in advance.</p><heading id="h-0009" level="1">Second Exemplary Embodiment</heading><p id="p-0075" num="0074">Next, a second exemplary embodiment of the present invention will be described with reference to <figref idref="DRAWINGS">FIGS. <b>11</b> to <b>13</b></figref>. <figref idref="DRAWINGS">FIGS. <b>11</b> and <b>12</b></figref> are block diagrams illustrating the configuration of a prediction device of the second exemplary embodiment, and <figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flowchart illustrating the operation of the prediction device. Note that the present embodiment shows the outline of the configurations of the information processing system and the prediction method described in the first exemplary embodiment.</p><p id="p-0076" num="0075">First, a hardware configuration of the prediction device <b>100</b> in the present embodiment will be described with reference to <figref idref="DRAWINGS">FIG. <b>11</b></figref>. The prediction device <b>100</b> is configured of at least one typical information processing device, having a hardware configuration as described below as an example.</p><p id="p-0077" num="0000">Central Processing Unit (CPU) <b>101</b> (arithmetic device)<br/>Read Only Memory (ROM) <b>102</b> (storage device)<br/>Random Access Memory (RAM) <b>103</b> (storage device)<br/>Program group <b>104</b> to be loaded to the RAM <b>303</b><br/>Storage device <b>105</b> storing therein the program group <b>304</b><br/>Drive <b>106</b> that performs reading and writing on storage medium <b>110</b> outside the information processing device<br/>Communication interface <b>107</b> connecting to a communication network <b>111</b> outside the information processing device<br/>Input/output interface <b>108</b> for performing input/output of data<br/>Bus <b>109</b> connecting the constituent elements</p><p id="p-0078" num="0076">The prediction device <b>100</b> can construct, and can be equipped with, a detection means <b>121</b> and a prediction means <b>122</b> illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref> through acquisition and execution of the program group <b>104</b> by the CPU <b>101</b>. Note that the program group <b>104</b> is stored in the storage device <b>105</b> or the ROM <b>102</b> in advance, and is loaded to the RAM <b>103</b> by the CPU <b>101</b> as needed. Further, the program group <b>104</b> may be provided to the CPU <b>101</b> via the communication network <b>111</b>, or may be stored on a storage medium <b>110</b> in advance and read out by the drive <b>106</b> and supplied to the CPU <b>101</b>. However, the detection means <b>121</b> and the prediction means <b>122</b> may be constructed by electronic circuits.</p><p id="p-0079" num="0077">Note that <figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates an example of a hardware configuration of the prediction device <b>100</b>. The hardware configuration of the prediction device is not limited to that described above. For example, the prediction device may be configured of part of the configuration described above, such as without the drive <b>106</b>.</p><p id="p-0080" num="0078">The prediction device <b>100</b> performs the prediction method illustrated in the flowchart of <figref idref="DRAWINGS">FIG. <b>13</b></figref>, by the functions of the detection means <b>121</b> and the prediction means <b>122</b> constructed by the program as described above.</p><p id="p-0081" num="0079">As illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the prediction device <b>100</b></p><p id="p-0082" num="0080">detects, on the basis of a river image that is an image obtained by capturing a river and associated with capturing position information representing the position at which the river is captured, river condition information representing the river condition at the position at which the river image is captured (step S<b>101</b>), and</p><p id="p-0083" num="0081">on the basis of the capturing position information, the river condition information, and topography information representing the topography of the river, predicts a river condition representing a river condition at a given point of the river that is different from the position represented by the capturing position information (step S<b>102</b>).</p><p id="p-0084" num="0082">Since the present embodiment is configured as described above, the prediction device <b>100</b> detects, from a captured image obtained by capturing a point of a river, river condition information representing the river condition of the point, and predicts a river condition at a different given point of the river from the river condition information. Therefore, it is not necessary to provide a measurement device for measuring the water level or the like to the river. Further, even when there is a shortage of measurement devices, it is possible to predict the river condition of another desired point from a river image obtained at any point of the river. As a result, it is possible to improve the accuracy of predicting the river condition of a river.</p><heading id="h-0010" level="1">Supplementary Notes</heading><p id="p-0085" num="0083">The whole or part of the exemplary embodiments disclosed above can be described as the following supplementary notes. Hereinafter, outlines of the configurations of a prediction method, a prediction device, and a program, according to the present invention, will be described. However, the present invention is not limited to the configurations described below.</p><heading id="h-0011" level="1">Supplementary Note 1</heading><p id="p-0086" num="0084">A prediction method comprising:</p><p id="p-0087" num="0085">on a basis of a river image that is an image obtained by capturing a river and associated with capturing position information representing a position at which the river is captured, detecting river condition information representing a condition of the river at the position at which the river image is captured; and</p><p id="p-0088" num="0086">on a basis of the capturing position information, the river condition information, and topography information representing topography of the river, predicting a river condition representing a condition of the river at a given point of the river, the given point being different from the position represented by the capturing position information.</p><heading id="h-0012" level="1">Supplementary Note 2</heading><p id="p-0089" num="0087">The prediction method according to supplementary note 1, further comprising</p><p id="p-0090" num="0088">predicting the river condition at the given point of the river, on a basis of capturing time information that represents time when the river image is captured and is associated with the river image, the capturing position information, the river condition information, and the topography information.</p><heading id="h-0013" level="1">Supplementary Note 3</heading><p id="p-0091" num="0089">The prediction method according to supplementary note 2, further comprising</p><p id="p-0092" num="0090">predicting the river condition at the given point of the river and time when the condition becomes the river condition, on a basis of the capturing time information, the capturing position information, the river condition information, and the topography information.</p><heading id="h-0014" level="1">Supplementary Note 4</heading><p id="p-0093" num="0091">The prediction method according to any of supplementary notes 1 to 3, further comprising</p><p id="p-0094" num="0092">predicting the river condition at a point of the river located on a downstream side of the position indicated by the capturing position information.</p><heading id="h-0015" level="1">Supplementary Note 5</heading><p id="p-0095" num="0093">The prediction method according to any of supplementary notes 1 to 4, further comprising</p><p id="p-0096" num="0094">predicting the river condition at the given point of the river including a main stream and a branch, on a basis of the topography information.</p><heading id="h-0016" level="1">Supplementary Note 6</heading><p id="p-0097" num="0095">The prediction method according to any of supplementary notes 1 to 5, further comprising</p><p id="p-0098" num="0096">predicting the river condition at the given point of the river by using weather information at a point on an upstream side of the given point of the river in which the river condition is predicted.</p><heading id="h-0017" level="1">Supplementary Note 7</heading><p id="p-0099" num="0097">The prediction method according to any of supplementary notes <b>1</b> to <b>6</b>, further comprising</p><p id="p-0100" num="0098">predicting the river condition at the given point of the river that is predicted for a predetermined river, as a river condition at a given point of another river determined to have topography that is similar to topography of the predetermined river on a basis of the topography information.</p><heading id="h-0018" level="1">Supplementary Note 8</heading><p id="p-0101" num="0099">The prediction method according to any of supplementary notes <b>1</b> to <b>7</b>, further comprising</p><p id="p-0102" num="0100">notifying an information processing device located at the given point of the river, of the river condition predicted for the given point of the river.</p><heading id="h-0019" level="1">Supplementary Note 9</heading><p id="p-0103" num="0101">The prediction method according to any of supplementary notes 1 to 8, further comprising</p><p id="p-0104" num="0102">acquiring the river image captured by a mobile information processing terminal; and</p><p id="p-0105" num="0103">detecting the river condition at a position at which the river image is captured, on a basis of the river image.</p><heading id="h-0020" level="1">Supplementary Note 10</heading><p id="p-0106" num="0104">The prediction method according to any of supplementary notes <b>1</b> to <b>9</b>, wherein</p><p id="p-0107" num="0105">the condition of the river includes a water level and a flow rate of the river.</p><heading id="h-0021" level="1">Supplementary Note 11</heading><p id="p-0108" num="0106">A prediction device comprising:</p><p id="p-0109" num="0107">detection means for, on a basis of a river image that is an image obtained by capturing a river and associated with capturing position information representing a position at which the river is captured, detecting river condition information representing a condition of the river at the position at which the river image is captured; and</p><p id="p-0110" num="0108">prediction means for, on a basis of the capturing position information, the river condition information, and topography information representing topography of the river, predicting a river condition representing a condition of the river at a given point of the river, the given point being different from the position represented by the capturing position information.</p><heading id="h-0022" level="1">Supplementary Note 12</heading><p id="p-0111" num="0109">The prediction device according to supplementary note 11, wherein</p><p id="p-0112" num="0110">the prediction means predicts the river condition at the given point of the river, on a basis of capturing time information that represents time when the river image is captured and is associated with the river image, the capturing position information, the river condition information, and the topography information.</p><heading id="h-0023" level="1">Supplementary Note 13</heading><p id="p-0113" num="0111">The prediction device according to supplementary note 12, wherein</p><p id="p-0114" num="0112">the prediction means predicts the river condition at the given point of the river and time when the condition becomes the river condition, on a basis of the capturing time information, the capturing position information, the river condition information, and the topography information.</p><heading id="h-0024" level="1">Supplementary Note 14</heading><p id="p-0115" num="0113">The prediction device according to any of supplementary notes <b>11</b> to <b>13</b>, wherein</p><p id="p-0116" num="0114">the prediction means predicts the river condition at a point of the river located on a downstream side of the position indicated by the capturing position information.</p><heading id="h-0025" level="1">Supplementary Note 15</heading><p id="p-0117" num="0115">The prediction device according to any of supplementary notes 11 to 14, wherein</p><p id="p-0118" num="0116">the prediction means predicts the river condition at the given point of the river including a main stream and a branch, on a basis of the topography information.</p><heading id="h-0026" level="1">Supplementary Note 16</heading><p id="p-0119" num="0117">The prediction device according to any of supplementary notes 11 to 15, wherein</p><p id="p-0120" num="0118">the prediction means predicts the river condition at the given point of the river by using weather information at a point on an upstream side of the given point of the river in which the river condition is predicted.</p><heading id="h-0027" level="1">Supplementary Note 17</heading><p id="p-0121" num="0119">The prediction device according to any of supplementary notes 11 to 16, wherein</p><p id="p-0122" num="0120">the prediction means predicts the river condition at the given point of the river that is predicted for a predetermined river, as a river condition at a given point of another river determined to have topography that is similar to topography of the predetermined river on a basis of the topography information.</p><heading id="h-0028" level="1">Supplementary Note 18</heading><p id="p-0123" num="0121">The prediction device according to any of supplementary notes 11 to 17, further comprising</p><p id="p-0124" num="0122">notification means for notifying an information processing device located at the given point of the river, of the river condition predicted for the given point of the river.</p><heading id="h-0029" level="1">Supplementary Note 19</heading><p id="p-0125" num="0123">A program for causing a processor of an information processing device to execute processing to:</p><p id="p-0126" num="0124">on a basis of a river image that is an image obtained by capturing a river and associated with capturing position information representing a position at which the river is captured, detect river condition information representing a condition of the river at the position at which the river image is captured; and</p><p id="p-0127" num="0125">on a basis of the capturing position information, the river condition information, and topography information representing topography of the river, predict a river condition representing a condition of the river at a given point of the river, the given point being different from the position represented by the capturing position information.</p><p id="p-0128" num="0126">Note that the program described above can be stored in a non-transitory computer-readable medium of any type and supplied to a computer. Non-transitory computer-readable media include tangible storage media of various types. Examples of non-transitory computer-readable media include magnetic storage media (for example, flexible disk, magnetic tape, and hard disk drive), magneto-optical storage media (for example, magneto-optical disk), a CD-ROM (Read Only Memory), a CD-R, a CD-R/W, and semiconductor memories (for example, mask ROM, PROM (Programmable ROM), and EPROM (Erasable PROM), a flash ROM, and a RAM (Random Access Memory)). Note that the program may be supplied to a computer by being stored in a transitory computer-readable medium of any type. Examples of transitory computer-readable media include electric signals, optical signals, and electromagnetic waves. A transitory computer-readable medium can be supplied to a computer via a wired communication channel such as a wire and an optical fiber, or a wireless communication channel.</p><p id="p-0129" num="0127">While the present invention has been described with reference to the exemplary embodiments described above, the present invention is not limited to the above-described embodiments. The form and details of the present invention can be changed within the scope of the present invention in various manners that can be understood by those skilled in the art.</p><heading id="h-0030" level="1">REFERENCE SIGNS LIST</heading><p id="p-0130" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0128"><b>1</b> information processing system</li>    <li id="ul0001-0002" num="0129"><b>10</b> image collection device</li>    <li id="ul0001-0003" num="0130"><b>11</b> image collection unit</li>    <li id="ul0001-0004" num="0131"><b>12</b> image storage unit</li>    <li id="ul0001-0005" num="0132"><b>20</b> prediction device</li>    <li id="ul0001-0006" num="0133"><b>21</b> acquisition unit</li>    <li id="ul0001-0007" num="0134"><b>22</b> detection unit</li>    <li id="ul0001-0008" num="0135"><b>23</b> prediction unit</li>    <li id="ul0001-0009" num="0136"><b>24</b> notification unit</li>    <li id="ul0001-0010" num="0137"><b>25</b> acquired image storage unit</li>    <li id="ul0001-0011" num="0138"><b>26</b> user information storage unit</li>    <li id="ul0001-0012" num="0139"><b>27</b> topography information storage unit</li>    <li id="ul0001-0013" num="0140"><b>28</b> weather information storage unit</li>    <li id="ul0001-0014" num="0141">Ua, Ub, Uc user</li>    <li id="ul0001-0015" num="0142">UTa, UTb, UTc user terminal</li>    <li id="ul0001-0016" num="0143"><b>100</b> prediction device</li>    <li id="ul0001-0017" num="0144"><b>101</b> CPU</li>    <li id="ul0001-0018" num="0145"><b>102</b> ROM</li>    <li id="ul0001-0019" num="0146"><b>103</b> RAM</li>    <li id="ul0001-0020" num="0147"><b>104</b> program group</li>    <li id="ul0001-0021" num="0148"><b>105</b> storage device</li>    <li id="ul0001-0022" num="0149"><b>106</b> drive</li>    <li id="ul0001-0023" num="0150"><b>107</b> communication interface</li>    <li id="ul0001-0024" num="0151"><b>108</b> input/output interface</li>    <li id="ul0001-0025" num="0152"><b>109</b> bus</li>    <li id="ul0001-0026" num="0153"><b>110</b> storage medium</li>    <li id="ul0001-0027" num="0154"><b>111</b> communication network</li>    <li id="ul0001-0028" num="0155"><b>121</b> detection means</li>    <li id="ul0001-0029" num="0156"><b>122</b> prediction means</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A prediction method comprising:<claim-text>on a basis of a river image that is an image obtained by capturing a river and associated with capturing position information representing a position at which the river is captured, detecting river condition information representing a condition of the river at the position at which the river image is captured; and</claim-text><claim-text>on a basis of the capturing position information, the river condition information, and topography information representing topography of the river, predicting a river condition representing a condition of the river at a given point of the river, the given point being different from the position represented by the capturing position information.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The prediction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising<claim-text>predicting the river condition at the given point of the river, on a basis of capturing time information that represents time when the river image is captured and is associated with the river image, the capturing position information, the river condition information, and the topography information.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The prediction method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising<claim-text>predicting the river condition at the given point of the river and time when the condition becomes the river condition, on a basis of the capturing time information, the capturing position information, the river condition information, and the topography information.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The prediction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising<claim-text>predicting the river condition at a point of the river located on a downstream side of the position indicated by the capturing position information.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The prediction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising<claim-text>predicting the river condition at the given point of the river including a main stream and a branch, on a basis of the topography information.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The prediction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising<claim-text>predicting the river condition at the given point of the river by using weather information at a point on an upstream side of the given point of the river in which the river condition is predicted.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The prediction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising<claim-text>predicting the river condition at the given point of the river that is predicted for a predetermined river, as a river condition at a given point of another river determined to have topography that is similar to topography of the predetermined river on a basis of the topography information.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The prediction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising<claim-text>notifying an information processing device located at the given point of the river, of the river condition predicted for the given point of the river.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The prediction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising<claim-text>acquiring the river image captured by a mobile information processing terminal; and</claim-text><claim-text>detecting the river condition at a position at which the river image is captured, on a basis of the river image.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The prediction method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the condition of the river includes a water level and a flow rate of the river.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A prediction device comprising:<claim-text>at least one memory configured to store instructions; and</claim-text><claim-text>at least one processor configured to execute instructions to:</claim-text><claim-text>on a basis of a river image that is an image obtained by capturing a river and associated with capturing position information representing a position at which the river is captured, detect river condition information representing a condition of the river at the position at which the river image is captured; and</claim-text><claim-text>on a basis of the capturing position information, the river condition information, and topography information representing topography of the river, predict a river condition representing a condition of the river at a given point of the river, the given point being different from the position represented by the capturing position information.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The prediction device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the at least one processor is configured to execute the instructions to<claim-text>predict the river condition at the given point of the river, on a basis of capturing time information that represents time when the river image is captured and is associated with the river image, the capturing position information, the river condition information, and the topography information.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The prediction device according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the at lest one processor is configured to execute the instructions to<claim-text>predict the river condition at the given point of the river and time when the condition becomes the river condition, on a basis of the capturing time information, the capturing position information, the river condition information, and the topography information.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The prediction device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the at least one processor is configured to execute the instructions to<claim-text>predict the river condition at a point of the river located on a downstream side of the position indicated by the capturing position information.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The prediction device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the at lest one processor is configured to execute the instructions to<claim-text>predict the river condition at the given point of the river including a main stream and a branch, on a basis of the topography information.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The prediction device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the at least one processor is configured to execute the instructions to<claim-text>predict the river condition at the given point of the river by using weather information at a point on an upstream side of the given point of the river in which the river condition is predicted.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The prediction device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the at least one processor is configured to execute the instructions to<claim-text>predict the river condition at the given point of the river that is predicted for a predetermined river, as a river condition at a given point of another river determined to have topography that is similar to topography of the predetermined river on a basis of the topography information.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The prediction device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the at least one processor is configured to execute the instructions to<claim-text>notify an information processing device located at the given point of the river, of the river condition predicted for the given point of the river.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A non-transitory computer-readable medium storing thereon a program comprising instructions for causing a processor of an information processing device to execute processing to:<claim-text>on a basis of a river image that is an image obtained by capturing a river and associated with capturing position information representing a position at which the river is captured, detect river condition information representing a condition of the river at the position at which the river image is captured; and</claim-text><claim-text>on a basis of the capturing position information, the river condition information, and topography information representing topography of the river, predict a river condition representing a condition of the river at a given point of the river, the given point being different from the position represented by the capturing position information.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004303A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004303</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17408031</doc-number><date>20210820</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0613</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0635</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0659</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0679</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">STORAGE DEVICE AND METHOD OF DATA MANAGEMENT ON A STORAGE DEVICE</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63217735</doc-number><date>20210701</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>SAMSUNG ELECTRONICS CO., LTD.</orgname><address><city>Suwon-si</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>YANG</last-name><first-name>Jing</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>YANG</last-name><first-name>Jingpei</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>PITCHUMANI</last-name><first-name>Rekha</first-name><address><city>Oak Hill</city><state>VA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>RYU</last-name><first-name>Sungwook</first-name><address><city>Palo Alto</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A storage device includes non-volatile memory, a storage controller including a first controller processor connected to the non-volatile memory, and a second controller processor connected to the non-volatile memory, and shared memory to store a mapping table. The shared memory may be connected to the first controller processor and the second controller processor to share mapping table information between the first controller processor and the second controller processor. The storage controller may set a power mode of the first controller processor and the second controller processor based on an input/output intensity.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="123.36mm" wi="144.10mm" file="US20230004303A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="144.36mm" wi="146.13mm" file="US20230004303A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="251.04mm" wi="140.97mm" orientation="landscape" file="US20230004303A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="248.33mm" wi="167.72mm" orientation="landscape" file="US20230004303A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="244.52mm" wi="168.40mm" orientation="landscape" file="US20230004303A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="183.98mm" wi="152.32mm" file="US20230004303A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="169.76mm" wi="157.82mm" file="US20230004303A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="117.52mm" wi="121.75mm" orientation="landscape" file="US20230004303A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="161.88mm" wi="164.93mm" orientation="landscape" file="US20230004303A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="238.42mm" wi="167.98mm" orientation="landscape" file="US20230004303A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="166.03mm" wi="141.05mm" file="US20230004303A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION(S)</heading><p id="p-0002" num="0001">This application claims priority to and the benefit of U.S. Provisional Application No. 63/217,735, filed on Jul. 1, 2021, entitled &#x201c;METHOD FOR POWER EFFICIENT DATA MANAGEMENT ON MULTI-FCPU SSD&#x201d; the entire content of which is incorporated by reference herein.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">Aspects of some embodiments of the present disclosure relate to a storage device and a method of data management on a storage device.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Generally, as the amount of data stored or to be stored in storage devices increases, storage devices handle a growing number of user requests. A larger number of user requests within a shorter time frame may result in increased workloads. Further, due to the wide variety of user requests received under varying conditions, allocation of the user requests in a storage device may result in uneven workloads. As the imbalance between workloads increases, issues with the storage devices may be exacerbated.</p><p id="p-0005" num="0004">The above information disclosed in this Background section is for enhancement of understanding of the background of the present disclosure, and therefore, it may contain information that does not constitute prior art.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0006" num="0005">Storage devices may include multiple embedded cores. Each embedded core may control a set number of memory channels using separate mapping tables. Workloads may be distributed among the embedded cores using a particular approach to estimate even workload distribution across all of the embedded cores. For example, a round robin approach may be used.</p><p id="p-0007" num="0006">While a round robin approach may be appropriate for a uniform, random distribution of incoming user requests, such a pattern of incoming requests may not always be present. Depending on the pattern of incoming requests and the distribution approach, some of the embedded cores may be active while other embedded cores may be idle. However, all of the embedded cores may be awake regardless of device status even if the embedded cores are idle, which may lead to excessive power consumption.</p><p id="p-0008" num="0007">One or more embodiments of the present disclosure are directed to a storage device with improved power-efficiency, resource utilization, and/or dynamic management of input/output (IO) operations, and a method including the same.</p><p id="p-0009" num="0008">According to some embodiments of the present disclosure, a storage device includes non-volatile memory, a storage controller including a first controller processor connected to the non-volatile memory, and a second controller processor connected to the non-volatile memory, and shared memory to store a mapping table (e.g., to store a logical to physical address mapping table and controller processor information), the shared memory being connected to the first controller processor and the second controller processor to share mapping table information between the first controller processor and the second controller processor. The storage controller may set a power mode of the first controller processor and the second controller processor based on an input/output intensity.</p><p id="p-0010" num="0009">In an embodiment, the non-volatile memory may include a first memory chip connected to a first channel, and a second memory chip connected to a second channel. The first controller processor and the second controller processor may be connected to the first memory chip via the first channel and the second memory chip via the second channel.</p><p id="p-0011" num="0010">In an embodiment, the storage controller may adjust the channels controlled by the first controller processor and the second controller processor.</p><p id="p-0012" num="0011">In an embodiment, the storage controller may assign a first number of channels to the first controller processor and a second number of channels to the second controller processor during a first time period, the first number of channels being different from the second number of channels.</p><p id="p-0013" num="0012">In an embodiment, the IO intensity may correspond to IO per second (IOPS).</p><p id="p-0014" num="0013">In an embodiment, the storage controller may put the first controller processor or the second controller processor in a sleep mode (e.g., a state in which activities are suspended to save power) or a lower frequency mode in response to the IOPS being below a first threshold.</p><p id="p-0015" num="0014">In an embodiment, the storage controller may put the controller processor having a lower number of queued IO requests from among the first controller processor and the second controller processor in the sleep mode (e.g., the state in which activities are suspended to save power) or the lower frequency mode in response to IOPS being below the first threshold.</p><p id="p-0016" num="0015">In an embodiment, the storage controller may assign a background task to the first controller processor in response to IOPS being below a first threshold.</p><p id="p-0017" num="0016">In an embodiment, the storage controller may reduce the first threshold in response to assigning the background task to the first controller processor.</p><p id="p-0018" num="0017">In an embodiment, the storage controller is configured to set the power mode of the first controller processor and the second controller processor based on IO intensity in accordance with a command received from a power manager of a host based on the IO intensity detected by a workload detector of the host.</p><p id="p-0019" num="0018">According to some embodiments of the present disclosure, a method of data management includes receiving, at a host interface layer of a storage controller, an IO request from a host device, determining, by the storage controller, an IO intensity, determining, by the storage controller, a group of controller processors for the IO request, the group of controller processors being connected to non-volatile memory corresponding to the IO request and being connected to shared memory to share mapping table information, and changing, by the storage controller, a first controller processor from among the group of controller processors to operate at a set power mode based on the IO intensity.</p><p id="p-0020" num="0019">In an embodiment, the first controller processor and a second controller processor of the group of controller processors may be connected to a first memory chip of the non-volatile memory via a first channel and a second memory chip of the non-volatile memory via a second channel.</p><p id="p-0021" num="0020">In an embodiment, the method may include adjusting, by the storage controller, the channels controlled by the first controller processor and the second controller processor.</p><p id="p-0022" num="0021">In an embodiment, the method may include assigning, by the storage controller, a first number of channels to the first controller processor during a first time period and a second number of channels to the second controller processor during the first time period, the first number of channels being different from the second number of channels.</p><p id="p-0023" num="0022">In an embodiment, the IO intensity may correspond to IOPS.</p><p id="p-0024" num="0023">In an embodiment, the method may include putting, by the storage controller, the first controller processor or a second controller processor of the group of controller processors in a sleep mode (e.g., a state in which activities are suspended to save power) or a lower frequency mode in response to IOPS being below a first threshold.</p><p id="p-0025" num="0024">In an embodiment, the putting, by the storage controller, the first controller processor or the second controller processor in the sleep mode (e.g., the state in which activities are suspended to save power) or the lower frequency mode in response to IOPS being below the first threshold comprises putting the controller processor having a lower number of queued IO requests from among the first controller processor and the second controller processor in the sleep mode (e.g., the state in which activities are suspended to save power) or the lower frequency mode.</p><p id="p-0026" num="0025">In an embodiment, the method may include assigning, by the storage controller, a background task to the first controller processor of the group of controller processors in response to IOPS being below a first threshold.</p><p id="p-0027" num="0026">In an embodiment, the method may include reducing, by the storage controller, the first threshold in response to the assigning, by the storage controller, the background task to the first controller processor.</p><p id="p-0028" num="0027">According to some embodiments of the present disclosure, a storage device includes non-volatile memory, a first controller processor connected to the non-volatile memory, a second controller processor connected to the non-volatile memory, a workload detector configured to detect IO intensity, a power manager configured to set a power mode of the first controller processor and the second controller processor based on the IO intensity, to change the first controller processor and the second controller processor to operate in a low power mode in response to the workload detector detecting an IO intensity between a first threshold and a second threshold for a first period of time, the second threshold being lower than the first threshold, and to put the first controller processor in a sleep mode (e.g., a state in which activities are suspended to save power) in response to the workload detector detecting the IO intensity below the second threshold for a second period of time different from the first period of time, and shared memory to store a mapping table (e.g., to store a logical to physical address mapping table and controller processor information), the shared memory being connected to the first controller processor and the second controller processor to share mapping table information between the first controller processor and the second controller processor.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0029" num="0028">The above and other aspects and features of the present disclosure will be more clearly understood from the following detailed description of the illustrative, non-limiting example embodiments with reference to the accompanying drawings.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a storage system, according to some embodiments of the present disclosure.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a host device and a storage device included in a storage system, according to some embodiments of the present disclosure.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a host device and a storage device included in a storage system, according to some embodiments of the present disclosure.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a host device and a storage device included in a storage system, according to some embodiments of the present disclosure.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a flow chart of various processes of a method of data management, according to some embodiments of the present disclosure.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a flow chart of various processes of a method of data management according to the method of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, according to some embodiments of the present disclosure.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> illustrates a flow chart of various processes of a method of data management according to the method of <figref idref="DRAWINGS">FIG. <b>5</b></figref> where a processor may be put in sleep mode, according to some embodiments of the present disclosure.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> illustrates a flow chart of various processes of a method of data management according to the method of <figref idref="DRAWINGS">FIG. <b>5</b></figref> where pending offline tasks may be performed, according to some embodiments of the present disclosure.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>7</b>C</figref> illustrate flow charts of various processes of methods of data management according to the method of <figref idref="DRAWINGS">FIG. <b>5</b></figref> where processors may be changed to operate at a lower frequency/power mode, according to some embodiments of the present disclosure.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a flow chart of a method of handling commands from a host device, according to some embodiments of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0040" num="0039">Hereinafter, example embodiments will be described in more detail with reference to the accompanying drawings, in which like reference numbers refer to like elements throughout. The present disclosure, however, may be embodied in various different forms, and should not be construed as being limited to only the illustrated embodiments herein. Rather, these embodiments are provided as examples so that this disclosure will be thorough and complete, and will fully convey the aspects and features of the present disclosure to those skilled in the art. Accordingly, processes, elements, and techniques that are not necessary to those having ordinary skill in the art for a complete understanding of the aspects and features of the present disclosure may not be described. Unless otherwise noted, like reference numerals denote like elements throughout the attached drawings and the written description, and thus, description thereof may not be repeated.</p><p id="p-0041" num="0040">Generally, a storage device including multiple embedded cores may perform data management tasks (e.g., read/write operations) in non-volatile memory, where each core may be connected to the non-volatile memory through a same number of dedicated channels that are managed via its own flash translation layer mapping table. Depending on a data access pattern and data block distribution algorithms, some embedded cores may be idle while other embedded cores may be busy performing the data management tasks. In this case, however, because the idle cores may still be active, power consumption of the storage device may be unnecessarily increased.</p><p id="p-0042" num="0041">According to some embodiments of the present disclosure, a storage device may include a plurality of controller processors that are connected to the same channels as each other to access the non-volatile memory via a shared flash translation layer mapping table that is stored in shared memory (e.g., a shared random access memory (RAM), for example, such as a dual-port RAM). By sharing the flash translation layer mapping table in the shared memory, the plurality of controller processors may, at different time periods from each other, manage IO requests transmitted through the same channels. Further, the power/frequency mode of the plurality of controller processors, tasks assigned to each of the plurality of controller processors, and channels controlled by the plurality controller processors may be selectively adjusted by a storage controller according to (e.g., based on) various suitable configurations and evaluations, for example, such as user configurations, capabilities, power modes, IO intensity (e.g., IO per second (IOPS) or any other suitable measure of IOs over a time period), offline tasks (e.g., background tasks, pre-processing of data for a host, and/or the like), and availability of other hardware automation routes (e.g., other available controller processors) to serve the user request.</p><p id="p-0043" num="0042">For example, the storage device may include a storage controller that evaluates the status and capabilities of the controller processors, IO intensity, and/or the like to selectively change the frequency and/or power modes of the controller processors to increase power efficiency. For example, the storage controller may determine that a sleep mode (e.g., a mode in which activities are suspended to save power) or a low frequency/power mode may be appropriate in the case of low IO intensity to increase power efficiency, and a high frequency/power mode may be appropriate in the case of high IO intensity to increase throughput. The storage controller may also adjust (e.g., logically adjust) the number of channels controlled by a particular one of the controller processors sharing the flash translation layer mapping table to reduce latency, avoid flash contention, and/or the like, while also providing flexibility associated with multiple controller processors managing non-volatile memory (e.g., flash memory) via the same channels based on the shared flash translation layer mapping table.</p><p id="p-0044" num="0043">Further, when IO intensity is relatively low, the storage controller may assign a controller processor (e.g., an idle controller processor) offline tasks (e.g., background tasks such as wear-leveling and garbage collection) while another controller processor (e.g., an active controller processor) handles inbound IO requests. By performing background tasks during a relatively low IO intensity period, storage device performance may be improved. As another example, when IO intensity is relatively low, the storage controller may assign a controller processor (e.g., an idle controller processor) data pre-processing tasks that would otherwise be performed by the host device thereby enabling additional functionality for the controller processors (e.g., providing multi-functional controller processors), or may put the idle controller processor to sleep.</p><p id="p-0045" num="0044">Moreover, according to some embodiments of the present disclosure, the above-described IO intensity detection and decision-making functionality of the storage controller may be offloaded to the host device, thereby reducing the form factor of the storage controller. As used herein, IO intensity may refer to a number of IO requests per unit time.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a storage system, according to some embodiments of the present disclosure.</p><p id="p-0047" num="0046">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a storage system <b>100</b> may include a host device <b>102</b> and a storage device <b>104</b>. In some embodiments, the host device <b>102</b> may be housed with the storage device <b>104</b>, and in other embodiments, the host device <b>102</b> may be separate from the storage device <b>104</b>. The host device <b>102</b> may include any suitable computing device connected to a storage device <b>104</b> such as, for example, a personal computer (PC), a portable electronic device, a hand-held device, a laptop computer, or the like.</p><p id="p-0048" num="0047">The host device <b>102</b> may be connected to the storage device <b>104</b> over a host interface <b>106</b>. The host device <b>102</b> may issue data request commands or IO commands (e.g., READ/WRITE commands) to the storage device <b>104</b> over the host interface <b>106</b>, and may receive responses from the storage device <b>104</b> over the host interface <b>106</b>.</p><p id="p-0049" num="0048">The host device <b>102</b> may include a host processor <b>108</b> and host memory <b>110</b>. The host processor <b>108</b> may be a processing circuit, for example, such as a general purpose processor or a central processing unit (CPU) core of the host device <b>102</b>. The host processor <b>108</b> may be connected to other components via an address bus, a control bus, a data bus, and/or the like. The host memory <b>110</b> may be considered as high performing main memory (e.g., primary memory) of the host device <b>102</b>. For example, in some embodiments, the host memory <b>110</b> may include (or may be) volatile memory, for example, such as dynamic random-access memory (DRAM). However, the present disclosure is not limited thereto, and the host memory <b>110</b> may include (or may be) any suitable high performing main memory (e.g., primary memory) replacement for the host device <b>102</b> as would be known to those skilled in the art. For example, in other embodiments, the host memory <b>110</b> may be relatively high performing non-volatile memory, such as NAND flash memory, Phase Change Memory (PCM), Resistive RAM, Spin-transfer Torque RAM (STTRAM), any suitable memory based on PCM technology, memristor technology, and/or resistive random access memory (ReRAM), and can include, for example, chalcogenides, and/or the like.</p><p id="p-0050" num="0049">The storage device <b>104</b> may be considered as secondary memory that may persistently store data accessible by the host device <b>102</b>. In this context, the storage device <b>104</b> may include relatively slower memory when compared to the high performing memory of the host memory <b>110</b>. For example, in some embodiments, the storage device <b>104</b> may be secondary memory of the host device <b>102</b>, for example, such as a Solid-State Drive (SSD). However, the present disclosure is not limited thereto, and in other embodiments, the storage device <b>104</b> may include (or may be) any suitable storage device such as, for example, a magnetic storage device (e.g., a hard disk drive (HDD), and the like), an optical storage device (e.g., a Blue-ray disc drive, a compact disc (CD) drive, a digital versatile disc (DVD) drive, and the like), other kinds of flash memory devices (e.g., a USB flash drive, and the like), and/or the like. In various embodiments, the storage device <b>104</b> may conform to a large form factor standard (e.g., a 3.5 inch hard drive form-factor), a small form factor standard (e.g., a 2.5 inch hard drive form-factor), an M.2 form factor, an E1.S form factor, and/or the like. In other embodiments, the storage device <b>104</b> may conform to any suitable or desired derivative of these form factors. For convenience, the storage device <b>104</b> may be described hereinafter in the context of an SSD, but the present disclosure is not limited thereto.</p><p id="p-0051" num="0050">The storage device <b>104</b> may be communicably connected to the host device <b>102</b> over the host interface <b>106</b>. The host interface <b>106</b> may facilitate communications (e.g., using a connector and a protocol) between the host device <b>102</b> and the storage device <b>104</b>. In some embodiments, the host interface <b>106</b> may facilitate the exchange of storage requests and responses between the host device <b>102</b> and the storage device <b>104</b>. In some embodiments, the host interface <b>106</b> may facilitate data transfers by the storage device <b>104</b> to and from the host memory <b>110</b> of the host device <b>102</b>. For example, in various embodiments, the host interface <b>106</b> (e.g., the connector and the protocol thereof) may include (or may conform to) Small Computer System Interface (SCSI), Non Volatile Memory Express (NVMe), Peripheral Component Interconnect Express (PCIe), remote direct memory access (RDMA) over Ethernet, Serial Advanced Technology Attachment (SATA), Fiber Channel, Serial Attached SCSI (SAS), NVMe over Fabric (NVMe-oF), and/or the like. In other embodiments, the host interface <b>106</b> (e.g., the connector and the protocol thereof) may include (or may conform to) various general-purpose interfaces, for example, such as Ethernet, Universal Serial Bus (USB), and/or the like.</p><p id="p-0052" num="0051">In some embodiments, the storage device <b>104</b> may include a storage controller <b>112</b>, storage memory <b>114</b>, non-volatile memory (NVM) <b>116</b>, and a storage interface <b>118</b>. The storage memory <b>114</b> may be high-performing memory of the storage device <b>104</b>, and may include (or may be) volatile memory, for example, such as DRAM, but the present disclosure is not limited thereto, and the storage memory <b>114</b> may be any suitable kind of high-performing volatile or non-volatile memory. The NVM <b>116</b> may persistently store data received, for example, from the host device <b>102</b>. The NVM <b>116</b> may include, for example, NAND flash memory, but the present disclosure is not limited thereto, and the NVM <b>116</b> may include any suitable kind of memory for persistently storing the data according to an implementation of the storage device <b>104</b> (e.g., magnetic disks, tape, optical disks, and/or the like).</p><p id="p-0053" num="0052">The storage controller <b>112</b> may be connected to the NVM <b>116</b> over the storage interface <b>118</b>. In the context of the SSD, the storage interface <b>118</b> may be referred to flash channel, and may be an interface with which the NVM <b>116</b> (e.g., NAND flash memory) may communicate with a processing component (e.g., the storage controller <b>112</b>) or other device. Commands such as reset, write enable, control signals, clock signals, and/or the like may be transmitted over the storage interface <b>118</b>. Further, a software interface may be used in combination with a hardware element that may be used to test/verify the workings of the storage interface <b>118</b>. The software may be used to read data from and write data to the NVM <b>116</b> via the storage interface <b>118</b>. Further, the software may include firmware that may be downloaded onto hardware elements (e.g., for controlling write, erase, and read operations).</p><p id="p-0054" num="0053">The storage controller <b>112</b> may be connected to the host interface <b>106</b>, and may manage signaling over the host interface <b>106</b>. In some embodiments, the storage controller <b>112</b> may include an associated software layer (e.g., a host interface layer) to manage the physical connector of the host interface <b>106</b>. The storage controller <b>112</b> may respond to IO requests received from the host device <b>102</b> over the host interface <b>106</b>. The storage controller <b>112</b> may also manage the storage interface <b>118</b> to control, and to provide access to and from, the NVM <b>116</b>. For example, the storage controller <b>112</b> may include at least one processing component embedded thereon for interfacing with the host device <b>102</b> and the NVM <b>116</b>. The processing component may include, for example, a digital circuit (e.g., a microcontroller, a microprocessor, a digital signal processor, or a logic device (e.g., a field programmable gate array (FPGA), an application-specific integrated circuit (ASIC), and/or the like)) capable of executing data access instructions (e.g., via firmware and/or software) to provide access to and from the data stored in the NVM <b>116</b> according to the data access instructions. For example, the data access instructions may correspond to the data request commands, and may include any suitable data storage and retrieval algorithm (e.g., READ/WRITE/ERASE) instructions, and/or the like.</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a host device and a storage device included in a storage system <b>200</b>, according to some embodiments of the present disclosure.</p><p id="p-0056" num="0055">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the storage device <b>104</b> may include a storage controller <b>112</b>, NVM <b>116</b>, and shared memory <b>202</b>. The shared memory <b>202</b> may include any suitable RAM (e.g., DRAM, SRAM, or the like). In some embodiments, the shared memory <b>202</b> may be part of the storage memory <b>114</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. However, the present disclosure is not limited thereto. For example, the shared memory <b>202</b> may be memory separate from the storage memory <b>114</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0057" num="0056">The storage controller <b>112</b> may include a plurality of processors (e.g., a plurality of embedded cores) including a host interface processor (H core) <b>204</b> and two or more controller processors or flash translation layer processors (F cores) including a first F core <b>206</b> and a second F core <b>208</b>. In some embodiments, the two or more controller processors or F cores may include homogenous processors (e.g., processors of the same type as each other) and/or heterogenous processors (e.g., processors of a different type from each other such that one processor is more powerful processor than another processor). For example, the first F core <b>206</b> and the second F core <b>208</b> may be the same type of processor as each other or may be different types of processors from each other. The H core <b>204</b> may manage the host interface layer <b>214</b>, and may correspond to software/firmware configured to process commands received from the host device <b>102</b> over the host interface <b>106</b>. The first F core <b>206</b> and the second F core <b>208</b> may include the same or substantially similar software and/or firmware, and may manage the storage interface <b>118</b> (e.g., the flash translation layer) by executing data access requests from the host device <b>102</b> in the NVM <b>116</b>, and mapping logical block addresses to physical addresses of the NVM <b>116</b> (e.g., flash memory). The first F core <b>206</b> and/or the second F core <b>208</b> may also manage data storage by performing garbage collection, wear-leveling, bad block management, and/or the like.</p><p id="p-0058" num="0057">In some embodiments, the H core <b>204</b> may include, at the host interface layer <b>214</b>, a power manager <b>216</b> and a workload detector <b>218</b>. The workload detector <b>218</b> may determine IO intensity by detecting, individually and/or in combination, an input-output (IO) intensity or rate (e.g., IO per second (IOPS)) of the F cores (e.g., the first F core <b>206</b> and the second F core <b>208</b>) of the storage controller <b>112</b>. Based on the IO intensity determined by the workload detector <b>218</b>, the power manager <b>216</b> may compare the IO intensity to one or more thresholds to determine whether one or more F cores (e.g., the first F core <b>206</b> and/or the second F core <b>208</b>) should be in a sleep mode, a low frequency/power mode, a high frequency/power mode, or the like to improve power-efficiency.</p><p id="p-0059" num="0058">In addition, the power manager <b>216</b> may distribute IO requests in accordance with the power/frequency mode of one or more F cores. For example, the power manager <b>216</b> may distribute IO requests among particular F cores (e.g., selectively distribute IO requests among awake F cores as opposed to sleeping F cores) and, in some embodiments, the power manager <b>216</b> may redistribute queued IO requests between the F cores (e.g., redistribute IO requests from F cores put to sleep to the awake F cores). Accordingly, because the power manager <b>216</b> may have access to IO intensity via the workload detector <b>218</b>, may have access to the status and capabilities of the one or more F cores (e.g., the first F core <b>206</b> and/or the second F core <b>208</b>), and may control IO request distribution, the power manager <b>216</b> may effectively coordinate data management between the F cores (e.g., the first F core <b>206</b> and/or the second F core <b>208</b>) to provide improved power-efficiency.</p><p id="p-0060" num="0059">For example, in some embodiments, when the IO intensity is below a first threshold for a period of time, the power manager <b>216</b> may put the F core having a lower number of queued IO requests (e.g., the fewest queued IO requests) from among a group of F cores to sleep (e.g., the power manager <b>216</b> may put a first F core <b>206</b> in sleep mode while the second F core <b>208</b> remains awake). In this case, prior to putting the first F core <b>206</b> to sleep, the power manager <b>216</b> may either redistribute the IO requests queued for the first F core <b>206</b> to the second F core <b>208</b> or may put the first F core <b>206</b> in the sleep mode after all of its queued IO requests are completed. In another embodiment, when the IO intensity is below a first threshold for a period of time, the power manager <b>216</b> may assign background tasks to the F core having the fewest queued IO requests from among a group of F cores, for example, such as, wear-leveling, resolving data retention, advanced garbage collection activity, and data re-balancing, as discussed in more detail below. The power manager <b>216</b> may further distribute inbound IO requests to F cores from among the group of F cores that may be awake (e.g., the second F core <b>208</b>). Accordingly, power may be saved relative to a comparative example where the first F core <b>206</b> has idle periods in accordance with the IO intensity being below the first threshold.</p><p id="p-0061" num="0060">During a subsequent time period, when inbound IO requests are above the first threshold for a period of time, the power manager <b>216</b> may wake up the first F core <b>206</b> to start receiving IO requests. In some embodiments, after waking up the first F core <b>206</b> from the sleep mode, the power manager <b>216</b> may begin to assign inbound IO requests to the first F core <b>206</b>. For example, the power manager <b>216</b> may assign inbound IO requests to the first F core <b>206</b> (e.g., assign more of the inbound IO requests to the first F core <b>206</b> compared to the second F core <b>208</b> to balance the workload), may redistribute tasks from the second F core <b>208</b> to the first F core <b>206</b>, and/or the like.</p><p id="p-0062" num="0061">The power manager <b>216</b> also has the option to set the first F core <b>206</b> and the second F core <b>208</b> to operate at different power/frequency modes in accordance with the IO intensity relative to one or more thresholds. For example, the power manager <b>216</b> may set the first F core <b>206</b> to operate at a low power/frequency mode and the second F core <b>208</b> to operate at a high power/frequency mode, set both the first F core <b>206</b> and the second F core <b>208</b> to operate at the low power/frequency mode, or set both the first F core <b>206</b> and the second F core <b>208</b> to operate at the high power/frequency mode depending on the IO intensity relative to a plurality of thresholds.</p><p id="p-0063" num="0062">In some embodiments, the power manager <b>216</b> may further coordinate shared data management activities between the F cores. For example, the power manager <b>216</b> may assign offline tasks (e.g., background tasks) other than data mapping (e.g., tasks other than host command driven tasks) to an F core. Some non-limiting examples of background tasks include, for example, wear-leveling, resolving data retention, advanced garbage collection activity, and re-balancing data among F cores (e.g., the first F core <b>206</b> and/or the second F core <b>208</b>) for reduced tail latency, balanced GC overhead, improved parallelism, and/or the like.</p><p id="p-0064" num="0063">In some embodiments, when the IO intensity is below the first threshold for a period of time, the power manager <b>216</b> may check whether any offline tasks should be performed to potentially improve performance of the storage device, and may assign such tasks to the first F core <b>206</b> instead of putting the first F core <b>206</b> to sleep or letting the first F core <b>206</b> idle for a period of time. Because the power manager <b>216</b> assigns offline tasks (e.g., background tasks) to one or more F cores (e.g., the first F core <b>206</b> and/or the second F core <b>208</b>) based on the IO intensity, offline tasks (e.g., background tasks) may be performed during a time period reducing disruption of data mapping.</p><p id="p-0065" num="0064">For example, garbage collection in a comparative storage device may simply occur when available space in the comparative storage device is running out. Because the comparative storage device may not be aware of future IO requests, a user experience may be adversely affected when garbage collection occurs at the same time or concurrently with a period of increased IO intensity as throughput thereof may be reduced while the garbage collection is being performed.</p><p id="p-0066" num="0065">In some embodiments, when the IO intensity is below the first threshold for a period of time, the power manager <b>216</b> may identify and assign data pre-processing tasks to the first F core <b>206</b> to offload processing from the host device <b>102</b>, thereby providing an opportunity for expanded functionality of the first F core <b>206</b>. For example, if the host device <b>102</b> requests the combined result of two data entries, the F core that is assigned the corresponding data pre-processing task may perform an add function of the two data entries prior to sending the result to the host device <b>102</b>. In contrast, in a comparative example, the host device <b>102</b> may perform the add function after receiving the raw data from the F core. Accordingly, a computing burden of the host device <b>102</b> may be reduced by using the computing power of the F core.</p><p id="p-0067" num="0066">As used herein, a &#x201c;channel&#x201d; such as one of CH0 to CH(Y) shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> refers to an interface (e.g., the storage interface <b>118</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>) between the F cores of the storage controller <b>112</b> and the NVM <b>116</b>. Generally, the power manager <b>216</b> may coordinate data management activities between two or more F cores (e.g., the first F core <b>206</b> and the second F core <b>208</b>) in accordance with two or more F cores being connected to the same plurality of channels.</p><p id="p-0068" num="0067">For example, the first F core <b>206</b> and the second F core <b>208</b> of the storage controller <b>112</b> may be connected to the NVM <b>116</b> via the same plurality of channels CH0 to CH(Y) (e.g., a same plurality of memory channels) of the storage interface <b>118</b>. Each channel may be connected to one or more memory chips of the NVM (e.g., one or more NAND chips) <b>116</b>. Therefore, the first F core <b>206</b> and the second F core <b>208</b> may be connected to and may share control of the same channels (e.g., share control of the channels CH0 . . . CH(Y) at different points in time) or different ones from among the channels CH0 . . . CH(Y).</p><p id="p-0069" num="0068">As used herein, &#x201c;channels CH0 . . . CH(Y)&#x201d; indicates that the first F core <b>206</b> and the second F core <b>208</b> may be connected to and share control of any suitable number of channels (e.g., Y number of channels). In some embodiments, the first F core <b>206</b> and the second F core <b>208</b> may be connected to and share control of eight channels CH0 to CH7. In other embodiments, the first F core <b>206</b> and the second F core <b>208</b> may be connected to and share control of more or less than eight channels.</p><p id="p-0070" num="0069">Although <figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts the first F core <b>206</b> and the second F core <b>208</b> as connected to channels CH0 . . . CH(Y), the first F core <b>206</b> and the second F core <b>208</b> may be adjusted (e.g., dynamically adjusted), by the power manager <b>216</b>, to control different ones of the channels CH0 . . . CH(Y) for a period of time depending on the power mode of the first F core <b>206</b> and the second F core <b>208</b>. For example, if the first F core <b>206</b> is in sleep mode and the second F core <b>208</b> is awake, then the second F core <b>208</b> may control all of the channels CH0 . . . CH(Y). As another example, if the first F core <b>206</b> is awake and the second F core <b>208</b> is in sleep mode, then the first F core <b>206</b> may control all of the channels CH0 . . . CH(Y). As an additional example, if both the first F core <b>206</b> and the second F core <b>208</b> are awake, the first F core <b>206</b> and the second F core <b>208</b> may control separate ones of the channels CH0 . . . CH(Y) (e.g., the control of the channels CH0 . . . CH(Y) may be divided (e.g., may be evenly divided) amongst the number of awake F cores connected to the same shared memory <b>202</b>) to work independently and avoid or reduce flash channel contention. For example, in the case of eight channels where both the first F core <b>206</b> and the second F core <b>208</b> are awake, the first F core <b>206</b> may control a first set of channels CH0 . . . CH3 and the second F core <b>208</b> may control a second set of channels CH4 . . . CH7. However, the present disclosure is not limited thereto. In some embodiments, the first F core <b>206</b> and the second F core <b>208</b> may control different numbers of channels from each other as set by the power manager <b>216</b> even when the first F core <b>206</b> and the second F core <b>208</b> are both awake. Accordingly, because each channel is controlled by a single F core at a given time, there may be reduced latency overhead as flash contention may be avoided or reduced.</p><p id="p-0071" num="0070">Although flash channel contention may be reduced by the power manager <b>216</b> designating each channel to be controlled by a single F core at a given time, in some embodiments, flash contention may still occur when, for example, a first F core <b>206</b> is running offline tasks (e.g., background tasks) and a second F core <b>208</b> is handling IO requests. In this case, because the first F core <b>206</b> is instructed to perform offline tasks (e.g., background tasks) when IO intensity (e.g., IO per second (IOPS) or any other suitable measure of IOs over a time period) is below a threshold, latency overhead (e.g., due to flash contention) may be relatively low because the currently detected workload is relatively light as indicated by the IO intensity being below the threshold.</p><p id="p-0072" num="0071">Because the first F core <b>206</b> and the second F core <b>208</b> may share control over the same channels CH0 . . . CH(Y) at different times, the first F core <b>206</b> and the second F core <b>208</b> may share data with each other. For example, as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the first F core <b>206</b> and the second F core <b>208</b> may be connected to separate ports of the shared memory <b>202</b>. In this case, the shared memory <b>202</b> may be dual-port RAM. However, the present disclosure is not limited thereto. For example, in some embodiments, the shared memory <b>202</b> may contain additional ports such as, for example, three, four, or more ports for connection to more than two F cores.</p><p id="p-0073" num="0072">In more detail, the first F core <b>206</b> and the second F core <b>208</b> may share a mapping table stored in the shared memory <b>202</b>. The mapping table <b>220</b> provides flash translation layer data access, synchronization, and sharing between the first F core <b>206</b> and the second F core <b>208</b>. For example, when the first F core <b>206</b> or the second F core <b>208</b> receives a command (e.g., a write command) from the host device <b>102</b>, data may be written to an address of the NVM <b>116</b>. Upon completion of the command (e.g., the write command), metadata (e.g., metadata including the physical locations corresponding to logical locations specified by the write command of the host device <b>102</b>) is stored in the mapping table <b>220</b>. Therefore, the mapping table <b>220</b> include metadata entries identifying logical to physical locations to be shared between F cores connected to the same shared memory <b>202</b>. As such, because the first F core <b>206</b> and the second F core <b>208</b> share the mapping table <b>220</b>, the metadata may not need to be migrated or separately communicated from the first F core <b>206</b> to the second F core <b>208</b> and vice versa.</p><p id="p-0074" num="0073">Although only two F cores are depicted as connected to the shared memory <b>202</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, depending on the number of ports of the shared memory <b>202</b>, more than two F cores may be connected to the shared memory <b>202</b>, and therefore, more than two F cores may be connected to and share control of channels CH0 . . . CH(Y). Further, any suitable number of F cores and shared memory chips may be present in the storage device <b>104</b> with suitable changes to the interfaces between the components.</p><p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a host device and a storage device included in a storage system <b>300</b>, according to some embodiments of the present disclosure.</p><p id="p-0076" num="0075">Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the storage device <b>104</b> may include a storage controller <b>112</b> including a plurality of F cores including a first F core <b>206</b><i>a</i>, a second F core <b>208</b><i>a</i>, a third F core <b>206</b><i>b</i>, and a fourth F core <b>208</b><i>b</i>. The first F core <b>206</b><i>a </i>and the third F core <b>206</b><i>b </i>may operate in the same or a substantially similar manner to the first F core <b>206</b> described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and redundant description thereof may not be repeated. Similarly, the second F core <b>208</b><i>a </i>and the fourth F core <b>208</b><i>b </i>may operate in the same or a substantially similar manner to the second F core <b>208</b> described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and redundant description thereof may not be repeated.</p><p id="p-0077" num="0076">As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the workload detector may detect, individually and/or in combination, the IO intensity (e.g., IOPS) of the first F core <b>206</b><i>a</i>, the second F core <b>208</b><i>a</i>, the third F core <b>206</b><i>b</i>, and the fourth F core <b>208</b><i>b</i>, and the power manager <b>216</b> may distribute IO requests and set power/frequency modes of the first F core <b>206</b><i>a</i>, the second F core <b>208</b><i>a</i>, the third F core <b>206</b><i>b</i>, and the fourth F core <b>208</b><i>b. </i></p><p id="p-0078" num="0077">The first F core <b>206</b><i>a </i>and the second F core <b>208</b><i>a </i>may form a first group of F cores, and may be connected to and share control of a first group of channels CH0 . . . CH7. The third F core <b>206</b><i>b </i>and the fourth F core <b>208</b><i>b </i>may form a second group of F cores, and be connected to and share control of a second group of channels CH8 . . . CH15.</p><p id="p-0079" num="0078">As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the storage device <b>104</b> may include a plurality of shared memory including first shared memory <b>202</b><i>a </i>and second shared memory <b>202</b><i>b</i>. The first shared memory <b>202</b><i>a </i>may store a first mapping table, and be connected to the first F core <b>206</b><i>a </i>and the second F core <b>208</b><i>a</i>. The second shared memory <b>202</b><i>b </i>may store a second mapping table, and be connected to the third F core <b>206</b><i>b </i>and the fourth F core <b>208</b><i>b</i>. The first mapping table and the second mapping table may operate in the same or a substantially similar manner to the mapping table <b>220</b> described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and redundant description thereof may not be repeated. Similarly, the first shared memory <b>202</b><i>a </i>and the second shared memory <b>202</b><i>b </i>may operate in the same or a substantially similar manner to the shared memory <b>202</b> described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and redundant description thereof may not be repeated.</p><p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a host device and a storage device included in a storage system <b>400</b>, according to some embodiments of the present disclosure.</p><p id="p-0081" num="0080">Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a host device <b>102</b> may include a host power manager <b>210</b> and a host workload detector <b>212</b>. The host power manager <b>210</b> and the host workload detector <b>212</b> of the host device <b>102</b> may include the detection and decision-making functions of the power manager <b>216</b> and the workload detector <b>218</b> described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>. In other words, the detection and decision-making functions of the power manager <b>216</b> and the workload detector <b>218</b> described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref> may be offloaded to the host device <b>102</b>. Accordingly, redundant description thereof may not be repeated.</p><p id="p-0082" num="0081">In this case, the storage device <b>104</b> may include a command handler <b>224</b>. The command handler may transfer or transmit a command received from the host power manager <b>210</b> to one or more F cores (e.g., a first F core <b>206</b><i>a</i>, a second F core <b>208</b><i>a</i>, a third F core <b>206</b><i>b</i>, and/or a fourth F core <b>208</b><i>b</i>) to put the F cores to sleep, to change frequency/power of the F cores, or to wake up the F cores. After transmitting the command received from the host power manager <b>210</b> to the one or more F cores (e.g., a first F core <b>206</b><i>a</i>, a second F core <b>208</b><i>a</i>, a third F core <b>206</b><i>b</i>, and/or a fourth F core <b>208</b><i>b</i>), the command handler <b>224</b> may send a response to the host device <b>102</b> indicating which ones of the F cores have been set to a particular power mode (e.g., a sleep mode, awake, or operating at a set frequency). The command handler <b>224</b> may also transmit IO requests as designated by the host device <b>102</b> to particular ones of the one or more F cores (e.g., a first F core <b>206</b><i>a</i>, a second F core <b>208</b><i>a</i>, a third F core <b>206</b><i>b</i>, and/or a fourth F core <b>208</b><i>b</i>), and transmit confirmation of the IO request transmission to the host device <b>102</b>.</p><p id="p-0083" num="0082">By offloading the detection and decision-making of the workload detector <b>218</b> and/or the power manager <b>216</b> of the storage controller <b>112</b> (e.g., as shown in <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>) to the host device <b>102</b>, the storage device <b>104</b> may have a smaller form factor.</p><p id="p-0084" num="0083">In various embodiments, the command handler <b>224</b> may be a part of the storage controller <b>112</b>, an accelerator, or an FPGA separate from the storage controller <b>112</b> with suitable changes to communication interfaces of the command handler <b>224</b>.</p><p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a flow chart of various processes of a method <b>500</b> of data management, according to some embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a flow chart of various processes of a method <b>600</b> of data management according to the method of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, according to some embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> illustrates a flow chart of various processes of a method of data management according to the method of <figref idref="DRAWINGS">FIG. <b>5</b></figref> where a processor may be put in sleep mode, according to some embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> illustrates a flow chart of various processes of a method of data management according to the method of <figref idref="DRAWINGS">FIG. <b>5</b></figref> where pending offline tasks may be performed, according to some embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>7</b>C</figref> illustrate flow charts of various processes of methods of data management according to the method of <figref idref="DRAWINGS">FIG. <b>5</b></figref> where processors may be changed to operate at a lower frequency/power mode, according to some embodiments of the present disclosure.</p><p id="p-0086" num="0085">The various processes of the methods <b>500</b>, <b>600</b>, <b>700</b><i>a</i>, <b>700</b><i>b</i>, and <b>700</b><i>c </i>of data management shown in <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>7</b>C</figref> may be performed, for example, by the storage device <b>104</b> (e.g., the storage controller <b>112</b>) of the storage systems <b>200</b> and/or <b>300</b> shown in <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>. However, the present disclosure is not limited thereto, and the operations shown in the various processes of the methods <b>500</b>, <b>600</b>, <b>700</b><i>a</i>, <b>700</b><i>b</i>, and <b>700</b><i>c </i>of data management may be performed by any suitable one of the components and elements or any suitable combination of the components and elements of one or more example embodiments described above. Further, the present disclosure is not limited to the sequence or number of the operations of the various processes of the methods <b>500</b>, <b>600</b>, <b>700</b><i>a</i>, <b>700</b><i>b</i>, and <b>700</b><i>c </i>of data management shown in <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>7</b>C</figref>, and can be altered into any desired sequence or number of operations as recognized by a person having ordinary skill in the art. For example, in some embodiments, the order may vary, or the various processes of the methods <b>500</b>, <b>600</b>, <b>700</b><i>a</i>, <b>700</b><i>b</i>, and <b>700</b><i>c </i>of data management may include fewer or additional operations. Further, the operations shown in the various processes of the methods <b>500</b>, <b>600</b>, <b>700</b><i>a</i>, <b>700</b><i>b</i>, and <b>700</b><i>c </i>of data management may be performed sequentially, or at least some of the operations thereof may be performed concurrently (e.g., simultaneously or substantially simultaneously).</p><p id="p-0087" num="0086">Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, a method <b>500</b> of data management may include receiving, at the host interface layer <b>214</b> of a storage controller <b>112</b>, an IO request from a host device <b>102</b> (<b>502</b>). The storage controller <b>112</b> (e.g., a workload detector <b>218</b>) may determine an IO intensity (e.g., IOPS) when the IO request is received (<b>504</b>). The storage controller <b>112</b> (e.g., a power manager <b>216</b>) may further determine (e.g., evaluate) the availability and capabilities of F cores (e.g., a first F core <b>206</b><i>a</i>, a second F core <b>208</b><i>a</i>, a third F core <b>206</b><i>b</i>, and/or a fourth F core <b>208</b><i>b</i>) of the storage device <b>104</b> (<b>506</b>).</p><p id="p-0088" num="0087">In some embodiments, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may further determine a group (or an assigned group) to receive the IO request based on the determination (e.g., evaluation) of the availability and capabilities of the F cores (<b>508</b>). For example, a first group of F cores may include the first F core <b>206</b><i>a </i>and the second F core <b>208</b><i>a</i>, and a second group of F cores may include the third F core <b>206</b><i>b </i>and the fourth F core <b>208</b><i>b</i>. The first group of F cores may be connected to the same channels (e.g., a first group of channels CH0 . . . CH7) as each other and the second group of F cores may be connected to the same channels (e.g., a second group of channels CH8 . . . CH15) as each other. As such, the first group of F cores and the second group of F cores may have access to different physical pages from each other to handle IO requests. Therefore, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may determine whether the data access command belongs to the first group of F cores or the second group of F cores. Although the group of F cores may be connected to and share a corresponding group of channels, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may logically adjust F cores within the group of F cores to control different channels of the corresponding group of channels to reduce latency overhead by, for example, avoiding or reducing flash contention.</p><p id="p-0089" num="0088">The storage controller <b>112</b> (e.g., the power manager <b>216</b>) may determine whether the IO intensity (e.g., based on IOPS determined by the workload detector) is greater than a first threshold for a period of time (<b>510</b>). In some embodiments, the first threshold may be a total of 10,000 IOPS for a group of F cores (e.g., a first group of F cores including the first F core <b>206</b><i>a </i>and the second F core <b>208</b><i>a </i>and/or a second group of F cores including the third F core <b>206</b><i>b </i>and the fourth F core <b>208</b><i>b</i>). However, the present disclosure is not limited thereto and any suitable threshold value may be used.</p><p id="p-0090" num="0089">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, in response to the storage controller <b>112</b> (e.g., the power manager <b>216</b>) determining that the IO intensity is greater than a first threshold for a period of time (<b>510</b>), the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may determine whether any of the F cores in the assigned group is in sleep mode (<b>602</b>). In response to determining that one or more of F cores in the assigned group are in sleep mode (<b>602</b>), the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may wake up the sleeping F cores (<b>604</b>). Alternatively, in the case where none of the F cores in the assigned group are in sleep mode (<b>602</b>), the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may not wake up any sleeping F cores.</p><p id="p-0091" num="0090">The storage controller <b>112</b> (e.g., the power manager <b>216</b>) may further determine whether the F cores in the assigned group are operating at a desired frequency/power mode (<b>606</b>) (e.g., a higher frequency/power mode corresponding to the IOPS being above the first threshold). In accordance with the F cores being at the desired frequency/power mode, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may transmit the IO request received from the host device (<b>502</b>) to an F core in the assigned group (<b>610</b>) in accordance with any suitable IO distribution method.</p><p id="p-0092" num="0091">In the case where any F cores are operating at a frequency/power mode different from the desired mode, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may change the F cores to operate at the desired frequency/power mode (<b>608</b>) (e.g., the higher frequency/power mode) and transmit the IO request received from the host device (<b>502</b>) to an F core in the assigned group (<b>610</b>) in accordance with any suitable <b>10</b> distribution method. For example, storage controller <b>112</b> (e.g., the power manager <b>216</b>) may assign or transmit the IO request received from the host device to the F core in the assigned group having the fewest IO requests. In some embodiments, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may, after waking up one or more F cores and/or increasing a frequency/power mode of one or more F cores, redistribute tasks from other F cores to the F cores that recently changed modes to balance the workload.</p><p id="p-0093" num="0092">Referring to <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, in response to the storage controller <b>112</b> (e.g., the power manager <b>216</b>) determining that the IO intensity is below the first threshold for a period of time (<b>510</b>), the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may put the F core in the assigned group having the fewest IO requests to sleep (<b>702</b>). In this case, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may redistribute the IO requests queued for the F core to be put to sleep or postpone putting the F core in sleep mode until the F core completes all of its queued IO requests. The storage controller <b>112</b> (e.g., the power manager <b>216</b>) may further transmit the IO request to another F core in the assigned group (<b>704</b>) (e.g., an F core in the assigned group that is awake) in accordance with any suitable IO distribution method.</p><p id="p-0094" num="0093">Referring to <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, in some embodiments, in response to the storage controller <b>112</b> (e.g., the power manager <b>216</b>) determining that the IO intensity is greater than the first threshold for a period of time (<b>510</b>), the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may further determine (e.g., consider) whether there any offline tasks (e.g., background tasks) pending (<b>706</b>).</p><p id="p-0095" num="0094">In the case where no offline tasks (e.g., background tasks) pending, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may put the F core in the assigned group having the fewest IO requests to sleep (<b>702</b>) and the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may transmit the IO request to another F core in the assigned group (<b>704</b>) (e.g., an F core in the assigned group that is awake) as described with reference to <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>.</p><p id="p-0096" num="0095">In the case where offline tasks (e.g., background tasks) are pending, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may assign one or more offline tasks (e.g., background tasks) to the F core having the fewest IO requests (<b>708</b>). In some embodiments, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may reduce the value (e.g., reduce the IOPS value) of the first threshold while the one or more assigned offline tasks are being performed (<b>710</b><i>a</i>), and may transmit the IO request to another F core in the assigned group (<b>704</b>). Accordingly, the first threshold may reflect the reduction in F cores available to process IO requests due to the F core performing one or more assigned offline tasks.</p><p id="p-0097" num="0096">Referring to <figref idref="DRAWINGS">FIG. <b>7</b>C</figref>, in some embodiments, in response to the storage controller <b>112</b> (e.g., the power manager <b>216</b>) determining that the IO intensity is greater than the first threshold for a period of time (<b>510</b>), the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may further determine (e.g., consider) whether the IO intensity (e.g., IOPS) is lower than a second threshold that is below the first threshold (<b>712</b>).</p><p id="p-0098" num="0097">As shown in <figref idref="DRAWINGS">FIG. <b>7</b>C</figref>, in the case where the IO intensity is greater than the second threshold that is below the first threshold (<b>712</b>), operations or processes that are the same or substantially similar to those described above with reference to <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> may occur, and thus, redundant description thereof may not be repeated. In contrast to operation or process (<b>710</b><i>a</i>) of <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may reduce the value of the first threshold and/or the second threshold while the one or more assigned offline tasks are being performed (<b>710</b><i>b</i>). Accordingly, the first threshold and/or the second threshold may reflect the reduction in F cores available to process IO requests due to the F core performing one or more assigned offline tasks.</p><p id="p-0099" num="0098">In the case where the IO intensity is lower than the second threshold that is below the first threshold (<b>712</b>), the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may further determine whether the F cores in the assigned group are operating at a desired frequency/power mode (<b>714</b>) (e.g., a lower frequency/power mode corresponding to the IOPS being above the second threshold and below the first threshold).</p><p id="p-0100" num="0099">In accordance with the F cores being at the desired frequency/power mode, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may transmit the IO request received from the host device (<b>502</b>) to an F core in the assigned group (<b>718</b>) in accordance with any suitable IO distribution method.</p><p id="p-0101" num="0100">In the case where the desired frequency/power mode is set at a mode other than the desired mode, the storage controller <b>112</b> (e.g., the power manager <b>216</b>) may change one or more F cores in the group to operate at the desired frequency/power mode (<b>716</b>) (e.g., a lower frequency/power mode corresponding to IOPS being below the second threshold), and transmit the IO request received from the host device (<b>502</b>) to an F core in the assigned group (<b>718</b>) in accordance with any suitable IO distribution method.</p><p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a flow chart of a method <b>800</b> of handling commands from a host device, according to some embodiments of the present disclosure.</p><p id="p-0103" num="0102">The method <b>800</b> of handling commands from a host device shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref> may be performed, for example, by the storage device <b>104</b> (e.g., the storage controller <b>112</b>) of the storage system <b>400</b> shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. However, the present disclosure is not limited thereto, and the operations shown in the method <b>800</b> of data management may be performed by any suitable one of the components and elements or any suitable combination of the components and elements of those of one or more example embodiments described above. Further, the present disclosure is not limited to the sequence or number of the operations of the method <b>800</b> shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, and can be altered into any desired sequence or number of operations as recognized by a person having ordinary skill in the art. For example, in some embodiments, the order may vary, or the method <b>800</b> may include fewer or additional operations. Further, the operations shown in the method <b>800</b> may be performed sequentially, or at least some of the operations thereof may be performed concurrently (e.g., simultaneously or substantially simultaneously).</p><p id="p-0104" num="0103">The method <b>800</b> of handling commands from the host device may include receiving, by the storage controller <b>112</b> (e.g., a command handler <b>224</b>), an IO request and/or a host command including power modes and/or IO distribution instructions for one or more F cores (<b>802</b>).</p><p id="p-0105" num="0104">The method <b>800</b> may further include transmitting, by the storage controller <b>112</b> (e.g., the command handler <b>224</b>), the IO request and the frequency/power mode to corresponding ones of the one or more F cores (<b>804</b>).</p><p id="p-0106" num="0105">The method <b>800</b> may further include receiving, by the storage controller <b>112</b> (e.g., the command handler <b>224</b>), confirmation of receipt of the IO request and/or distribution instructions from the corresponding F cores (<b>806</b>), and the storage controller <b>112</b> (e.g., the command handler <b>224</b>) may transmit a response to a host device <b>102</b> confirming transmission of the IO request and/or the host command to corresponding ones of the one or more F cores (<b>808</b>).</p><p id="p-0107" num="0106">Accordingly, the detection and decision-making functions of the power manager <b>216</b> and the workload detector <b>218</b> may be offloaded to the host device <b>102</b> and the storage device <b>104</b> may have a smaller form factor by using the command handler <b>224</b> instead of fully incorporating a power manager <b>216</b> and/or a workload detector <b>218</b> into the storage device <b>104</b>.</p><p id="p-0108" num="0107">According to some embodiments of the present disclosure, a storage device includes a workload detector, a power manager, and/or a command handler to improve power-efficiency, resource utilization, and dynamically manage IO operations. Further, according to some embodiments of the present disclosure, the power manager determines suitable frequency/power modes for one or more cores based on a user configuration, core capabilities and available power modes, user IO traffic and learnt thresholds, offline tasks, and/or if another hardware automation route is available to serve a user request.</p><p id="p-0109" num="0108">While various methods according to some embodiments of the present disclosure has been described according to various processes having a certain process order, the present disclosure is not limited thereto. For example, when a certain embodiment may be implemented differently, a specific process order may be different from the described order. For example, two consecutively described processes may be performed at the same or substantially at the same time, or may be performed in an order opposite to the described order.</p><p id="p-0110" num="0109">It will be understood that, although the terms &#x201c;first,&#x201d; &#x201c;second,&#x201d; &#x201c;third,&#x201d; etc., may be used herein to describe various elements, components, regions, layers and/or sections, these elements, components, regions, layers and/or sections should not be limited by these terms. These terms are used to distinguish one element, component, region, layer or section from another element, component, region, layer or section. Thus, a first element, component, region, layer or section described below could be termed a second element, component, region, layer or section, without departing from the spirit and scope of the present disclosure.</p><p id="p-0111" num="0110">It will be understood that when an element or layer is referred to as being &#x201c;on,&#x201d; &#x201c;connected to,&#x201d; or &#x201c;coupled to&#x201d; another element or layer, it can be directly on, connected to, or coupled to the other element or layer, or one or more intervening elements or layers may be present. In addition, it will also be understood that when an element or layer is referred to as being &#x201c;between&#x201d; two elements or layers, it can be the only element or layer between the two elements or layers, or one or more intervening elements or layers may also be present.</p><p id="p-0112" num="0111">The terminology used herein is for the purpose of describing particular embodiments and is not intended to be limiting of the present disclosure. As used herein, the singular forms &#x201c;a&#x201d; and &#x201c;an&#x201d; are intended to include the plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms &#x201c;comprises,&#x201d; &#x201c;comprising,&#x201d; &#x201c;includes,&#x201d; &#x201c;including,&#x201d; &#x201c;has,&#x201d; &#x201c;have,&#x201d; and &#x201c;having,&#x201d; when used in this specification, specify the presence of the stated features, integers, steps, operations, elements, and/or components, but do not preclude the presence or addition of one or more other features, integers, steps, operations, elements, components, and/or groups thereof. As used herein, the term &#x201c;and/or&#x201d; includes any and all combinations of one or more of the associated listed items. For example, the expression &#x201c;A and/or B&#x201d; denotes A, B, or A and B. Expressions such as &#x201c;at least one of,&#x201d; when preceding a list of elements, modify the entire list of elements and do not modify the individual elements of the list. For example, the expression &#x201c;at least one of a, b, or c&#x201d; indicates only a, only b, only c, both a and b, both a and c, both b and c, all of a, b, and c, or variations thereof.</p><p id="p-0113" num="0112">As used herein, the term &#x201c;substantially,&#x201d; &#x201c;about,&#x201d; and similar terms are used as terms of approximation and not as terms of degree, and are intended to account for the inherent variations in measured or calculated values that would be recognized by those of ordinary skill in the art. Further, the use of &#x201c;may&#x201d; when describing embodiments of the present disclosure refers to &#x201c;some embodiments of the present disclosure.&#x201d; As used herein, the terms &#x201c;use,&#x201d; &#x201c;using,&#x201d; and &#x201c;used&#x201d; may be considered synonymous with the terms &#x201c;utilize,&#x201d; &#x201c;utilizing,&#x201d; and &#x201c;utilized,&#x201d; respectively.</p><p id="p-0114" num="0113">The electronic or electric devices and/or any other relevant devices (e.g., the storage controller, the shared memory, and the host device) or components thereof (e.g., an H core and a controller processor or F Core) according to embodiments of the present disclosure described herein may be implemented utilizing any suitable hardware, firmware (e.g. an application-specific integrated circuit), software, or a combination of software, firmware, and hardware. For example, the various components of these devices may be formed on one integrated circuit (IC) chip or on separate IC chips. Further, the various components of these devices may be implemented on a flexible printed circuit film, a tape carrier package (TCP), a printed circuit board (PCB), or formed on one substrate. Further, the various components of these devices may be a process or thread, running on one or more processors, in one or more computing devices, executing computer program instructions and interacting with other system components for performing the various functionalities described herein. The computer program instructions are stored in a memory which may be implemented in a computing device using a standard memory device, such as, for example, RAM. The computer program instructions may also be stored in other non-transitory computer readable media such as, for example, a CD-ROM, flash drive, or the like. Also, a person of skill in the art should recognize that the functionality of various computing devices may be combined or integrated into a single computing device, or the functionality of a particular computing device may be distributed across one or more other computing devices without departing from the spirit and scope of the example embodiments of the present disclosure.</p><p id="p-0115" num="0114">Unless otherwise defined, all terms (including technical and scientific terms) used herein have the same meaning as commonly understood by one of ordinary skill in the art to which the present disclosure belongs. It will be further understood that terms, such as those defined in commonly used dictionaries, should be interpreted as having a meaning that is consistent with their meaning in the context of the relevant art and/or the present specification, and should not be interpreted in an idealized or overly formal sense, unless expressly so defined herein.</p><p id="p-0116" num="0115">Although some example embodiments have been described, those skilled in the art will readily appreciate that various modifications are possible in the example embodiments without departing from the spirit and scope of the present disclosure. It will be understood that descriptions of features or aspects within each embodiment should typically be considered as available for other similar features or aspects in other embodiments, unless otherwise described. Thus, as would be apparent to one of ordinary skill in the art, features, characteristics, and/or elements described in connection with a particular embodiment may be used singly or in combination with features, characteristics, and/or elements described in connection with other embodiments unless otherwise specifically indicated. Therefore, it is to be understood that the foregoing is illustrative of various example embodiments and is not to be construed as limited to the specific example embodiments disclosed herein, and that various modifications to the disclosed example embodiments, as well as other example embodiments, are intended to be included within the spirit and scope of the present disclosure as defined in the appended claims, and their equivalents.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A storage device comprising:<claim-text>non-volatile memory;</claim-text><claim-text>a storage controller comprising:<claim-text>a first controller processor connected to the non-volatile memory; and</claim-text><claim-text>a second controller processor connected to the non-volatile memory; and</claim-text></claim-text><claim-text>shared memory to store a mapping table, the shared memory being connected to the first controller processor and the second controller processor to share mapping table information between the first controller processor and the second controller processor,</claim-text><claim-text>wherein the storage controller is configured to change a power mode of the first controller processor and the second controller processor from a first power mode to a second power mode based on an input/output (IO) intensity.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The storage device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the non-volatile memory comprises:<claim-text>a first memory chip connected to a first channel; and</claim-text><claim-text>a second memory chip connected to a second channel, and</claim-text><claim-text>wherein the first controller processor and the second controller processor are connected to the first memory chip via the first channel and the second memory chip via the second channel.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The storage device of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the storage controller is further configured to adjust the channels controlled by the first controller processor and the second controller processor.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The storage device of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the storage controller is further configured to assign a first number of channels to the first controller processor and a second number of channels to the second controller processor during a first time period, the first number of channels being different from the second number of channels.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The storage device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the IO intensity corresponds to IO per second (IOPS).</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The storage device of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the storage controller is further configured to put the first controller processor or the second controller processor in a state in which activities are suspended to save power or a lower frequency mode in response to the IOPS being below a first threshold.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The storage device of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the storage controller is further configured to put the controller processor having a lower number of queued IO requests from among the first controller processor and the second controller processor in the state in which activities are suspended to save power or the lower frequency mode in response to IOPS being below the first threshold.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The storage device of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the storage controller is further configured to assign a background task to the first controller processor in response to IOPS being below a first threshold.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The storage device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the storage controller is further configured to reduce the first threshold in response to assigning the background task to the first controller processor.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The storage device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the storage controller is configured to set the power mode of the first controller processor and the second controller processor based on IO intensity in accordance with a command received from a power manager of a host based on the IO intensity detected by a workload detector of the host.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A method of data management, the method comprising:<claim-text>receiving, at a host interface layer of a storage controller, an IO request from a host device;</claim-text><claim-text>determining, by the storage controller, an IO intensity;</claim-text><claim-text>determining, by the storage controller, a group of controller processors for the IO request, the group of controller processors being connected to non-volatile memory corresponding to the IO request and being connected to shared memory to share mapping table information; and</claim-text><claim-text>changing, by the storage controller from a first power mode, a first controller processor from among the group of controller processors to operate at a second power mode based on the IO intensity.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the first controller processor and a second controller processor of the group of controller processors are connected to a first memory chip of the non-volatile memory via a first channel and a second memory chip of the non-volatile memory via a second channel.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, the method further comprising:<claim-text>adjusting, by the storage controller, the channels controlled by the first controller processor and the second controller processor.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, the method further comprising:<claim-text>assigning, by the storage controller, a first number of channels to the first controller processor during a first time period and a second number of channels to the second controller processor during the first time period, the first number of channels being different from the second number of channels.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the IO intensity corresponds to IOPS.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, the method further comprising:<claim-text>putting, by the storage controller, the first controller processor or a second controller processor of the group of controller processors in a state in which activities are suspended to save power or a lower frequency mode in response to IOPS being below a first threshold.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the putting, by the storage controller, the first controller processor or the second controller processor in the state in which activities are suspended to save power or the lower frequency mode in response to IOPS being below the first threshold comprises putting the controller processor having a lower number of queued IO requests from among the first controller processor and the second controller processor in the state in which activities are suspended to save power or the lower frequency mode.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, the method further comprising:<claim-text>assigning, by the storage controller, a background task to the first controller processor of the group of controller processors in response to IOPS being below a first threshold.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, the method further comprising:<claim-text>reducing, by the storage controller, the first threshold in response to the assigning, by the storage controller, the background task to the first controller processor.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A storage device comprising:<claim-text>non-volatile memory;</claim-text><claim-text>a first controller processor connected to the non-volatile memory;</claim-text><claim-text>a second controller processor connected to the non-volatile memory;</claim-text><claim-text>a workload detector configured to detect IO intensity;</claim-text><claim-text>a power manager configured:<claim-text>to change a power mode of the first controller processor and the second controller processor from a first power mode to a low power mode based on the IO intensity,</claim-text><claim-text>to change the first controller processor and the second controller processor to operate in the low power mode in response to the workload detector detecting an IO intensity between a first threshold and a second threshold for a first period of time, the second threshold being lower than the first threshold, and</claim-text><claim-text>to put the first controller processor in a state in which activities are suspended to save power in response to the workload detector detecting the IO intensity below the second threshold for a second period of time different from the first period of time; and</claim-text></claim-text><claim-text>shared memory to store a mapping table, the shared memory being connected to the first controller processor and the second controller processor to share mapping table information between the first controller processor and the second controller processor.</claim-text></claim-text></claim></claims></us-patent-application>
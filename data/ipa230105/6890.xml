<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230006891A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230006891</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17931310</doc-number><date>20220912</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>41</main-group><subgroup>14</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>43</main-group><subgroup>0876</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>47</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>41</main-group><subgroup>14</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>43</main-group><subgroup>0876</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>47</main-group><subgroup>823</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>47</main-group><subgroup>822</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">TECHNIQUES AND ARCHITECTURES FOR EFFICIENT ALLOCATION OF UNDER-UTILIZED RESOURCES</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15282322</doc-number><date>20160930</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11489731</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17931310</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>salesforce.com, inc.</orgname><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Walsh</last-name><first-name>James E.</first-name><address><city>Woodinville</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Tiwari</last-name><first-name>Sameer</first-name><address><city>Fremont</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>salesforce.com, inc.</orgname><role>02</role><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">In a computing environment, a set of executing processes each having associated resources are provided. Aggregate resources for the computing environment include multiple different types of resources. A utilization level for each of the resources within the computing environment is evaluated to determine an unconsumed capacity for each of the resources below a utilization threshold. The utilization threshold is resource-dependent. An indication of at least a portion of unconsumed capacity for each of the resources below the utilization threshold is gathered. The unconsumed portion for each of the resources below the utilization threshold is exposed for consumption by other executing processes.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="104.31mm" wi="158.75mm" file="US20230006891A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="218.52mm" wi="156.21mm" orientation="landscape" file="US20230006891A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="164.76mm" wi="156.04mm" file="US20230006891A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="232.49mm" wi="144.53mm" file="US20230006891A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="232.41mm" wi="142.24mm" file="US20230006891A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="196.34mm" wi="136.14mm" file="US20230006891A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="218.78mm" wi="157.31mm" file="US20230006891A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">INCORPORATION BY REFERENCE</heading><p id="p-0002" num="0001">An Application Data Sheet is filed concurrently with this specification as part of the present application. Each application that the present application claims benefit of or priority to as identified in the concurrently filed Application Data Sheet is incorporated by reference herein in its entirety and for all purposes.</p><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">Embodiments relate to efficient utilization of resources. More particularly, embodiments relate to techniques for efficiently identifying non-utilized (or under-utilized) resources to be allocated for more efficient utilization. For example, in a multitenant environment, systems may be designed to satisfy peak loads</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Computing environments often include resources that are not fully utilized during normal operating conditions. For example, in a multitenant environment resources (e.g., processor capacity, memory space, bandwidth, cache memory access, database service) can be designed based on anticipated peak loads. However, during normal operation, many of these resources may be unused or lightly used. Thus, there may exist valuable resources that are not utilized as efficiently as possible.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0005" num="0004">Embodiments of the invention are illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings in which like reference numerals refer to similar elements.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of one embodiment of an architecture that can provide efficient allocation of under-utilized resources as described herein.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flow diagram of one embodiment of a technique for monitoring under-utilized resources.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow diagram of one embodiment of a technique for performing load prediction analytics.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram of one embodiment of a scavenger agent that can operate as described herein.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram of one embodiment of an aggregation agent that can operate as described herein.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram of one embodiment of a prediction agent that can operate as described herein.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram of one embodiment of an allocation agent that can operate as described herein.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a block diagram of an environment where an on-demand database service might be used.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a block diagram of another environment where an on-demand database service might be used.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0015" num="0014">In the following description, numerous specific details are set forth. However, embodiments of the invention may be practiced without these specific details. In other instances, well-known circuits, structures and techniques have not been shown in detail in order not to obscure the understanding of this description.</p><p id="p-0016" num="0015">In data centers and other environments in which computing resources are provided, maximizing host utilization is important for running a highly efficient service/business. While the examples that follow may focus on four main components (processor, memory, storage, network), the techniques described herein are applicable to other resources as well. During normal operation, there may be unutilized capacity across one or more resources.</p><p id="p-0017" num="0016">Described herein are techniques to make unused and/or underutilized resources available for other purposes. In various embodiments, this can be accomplished without impacting the native/existing processes running on the host. In one embodiment, the host can both allocate and free resources based on monitoring, projection and/or back off strategies.</p><p id="p-0018" num="0017">In one embodiment, the system predicts a load on a host based on, for example, ad hoc and/or machine learned data. In one embodiment, this is performed by a load predictor or other entity. In one embodiment, the system can take inputs from the load predictor to allocate and/or free resources without impacting native processes. In one embodiment, this is performed by a resource allocator or other entity.</p><p id="p-0019" num="0018">As an example, a typical website is provided by servers backed by a database. Under normal operating conditions, the servers function to serve many HTTP request, but may not be accessing local storage devices (e.g., hard drives, SSD drives) at a high level. With web servers, the traffic tends to be bursty and mostly network bound, though some processor capacity will be used. In this example, local storage devices can exposed as available for other processes to utilize.</p><p id="p-0020" num="0019">In one embodiment, monitoring and/or exposing of underutilized and/or unutilized resources can be run as a service agent on each host, which could be spread across one of multiple processes to expose available resources for other systems/processes to consume.</p><p id="p-0021" num="0020">In one embodiment, a load predictor (load prediction agent) operates on a per host basis and uses both offline and online analytics and machine learning techniques to predict resource usage of the host for a finite interval in the future. In one embodiment, these metrics are sent to another system that is capable of providing analytics analysis functionality. In one embodiment, one or more application program interfaces (APIs) can be provided to share data. In one embodiment, the usage can be predicted based on this analysis.</p><p id="p-0022" num="0021">In one embodiment, each host can run a daemon/thread that is a resource allocator that can function to allocate resources based on pre-configured heuristics, lookup tables, and/or configurations, etc. In one embodiment, resource allocation can be provided by an agent on each host, which can function as building blocks upon which large scale resource systems can be built.</p><p id="p-0023" num="0022">In one embodiment, the resource allocator takes inputs from the load predictor (discussed above) and allocates, frees and/or otherwise makes available resources to higher level consumers. In one embodiment, this can include taking resources from lower level consumers and providing those resources to higher level consumers. This architecture is capable of gracefully handling unpredicted loads on the host system with minimal (or no) impact on the native processes/threads.</p><p id="p-0024" num="0023">In one embodiment, each resource allocator receives input from the load prediction mechanism(s) at regular intervals. The resource allocators also validate resource availability for the resources corresponding to the resource allocator. The resource allocator can then allocate resources (e.g., storage, cache, processing, bandwidth).</p><p id="p-0025" num="0024">The resources that are to be allocated to remote threads/processes are then exposed in a well-defined way. Various techniques for exposing available resources are discussed in greater detail below. In one embodiment, there is provided a back off feature that can be based on inputs from the prediction agent and/or an explicit call/input that can cause this allocation to be backed off.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of one embodiment of an architecture that can provide efficient allocation of under-utilized resources as described herein. The example of <figref idref="DRAWINGS">FIG. <b>1</b></figref> includes three host systems (<b>110</b>, <b>120</b>, <b>130</b>); however, any number of host systems can be supported. Further, the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates only memory/storage resources that can be exposed for consumption by other systems; however, the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref> provides a basic example of the techniques described herein and not an exhaustive listing of possible uses. As described elsewhere in the present description, many types of resources can be exposed and/or reallocated as described herein.</p><p id="p-0027" num="0026">Host systems <b>110</b>, <b>120</b>, <b>130</b> can be any type of computing platform having one or more resources that may be under-utilized. Host systems <b>11</b>,<b>0</b>, <b>120</b>, <b>130</b> can be interconnected by one or more networks <b>160</b> that can be any combination of wired and/or wireless networks.</p><p id="p-0028" num="0027">While the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates three systems that appear the same, the various resources may have different characteristics in different host systems. For example, the disk drives <b>112</b> of host <b>110</b> may have different characteristics (e.g., storage capacity, speed, bandwidth, reliability, energy consumption, available capacity), which may be the same or different than the disk drives (<b>122</b>, <b>132</b>, respectively) of hosts <b>120</b>, <b>130</b>. Similarly, cache memory (<b>114</b>, <b>124</b>, <b>134</b>) and solid state drives (SSDs) <b>116</b>, <b>126</b>, <b>136</b> can have varying characteristics.</p><p id="p-0029" num="0028">In one embodiment, each host system has an embedded scavenger agent (<b>118</b>, <b>128</b>, <b>138</b>) that functions to monitor and/or evaluate the utilization of one or more resources within the corresponding host system. In one embodiment, scavenger agents <b>118</b>, <b>128</b>, <b>138</b> have some control or influence over allocation of resources within the respective host systems. For example, if scavenger agent <b>128</b> determines that 50% of cache memory <b>124</b> is being utilized by host system <b>120</b>, scavenger agent <b>128</b> can 50% (plus some buffer amount, for example, +5%, +10%) to be allocated to host system <b>120</b> and the remaining portion (e.g., 45%, 40%) can be exposed for use by other systems, for example, host <b>110</b> and/or host <b>130</b>.</p><p id="p-0030" num="0029">In one embodiment, each scavenger agent further functions to expose, advertise and/or otherwise indicate resources that are available in the host systems monitored by the respective scavenger agents. In one embodiment, a monitoring agent/entity <b>170</b> external to the host systems can collect information from one or more of the scavenger agents. In alternate embodiments, monitoring agent <b>170</b> can be provided by one or more of the host systems.</p><p id="p-0031" num="0030">In one embodiment, unused resources and/or under-utilized resources can be exposed by the scavenger agents to allow other host systems to use these resources. Various techniques can be utilized to expose/advertise the availability of these resources. For example, a single listing or entity can provide identification and/or capacity available from other resources. A listing can be, for example, a table in a database, an XML file, etc. An agent/daemon/thread/entity can be responsible for managing information related to available scavenged resources and/or matching the resources to requests for additional resources.</p><p id="p-0032" num="0031">In one embodiment, monitoring agent <b>170</b> can function to collect information from the various scavenging agents to expose all available resources to all (or a subset) of the host systems within a larger environment. For example, host systems <b>110</b>, <b>120</b>, <b>130</b> can be part of an on-demand services environment that functions to provide services to various users. An on-demand services environment can be, for example, a multitenant database environment, a customer relationship management (CRM) environment, etc. Various embodiments of on-demand service environments are described below.</p><p id="p-0033" num="0032">In one embodiment, analytics agent <b>180</b> functions to gather utilization information from various hosts and can use this information to make load predications and/or provide this information to one or more load prediction agents to be used in making load predictions. Information can include, for example, historical statistical information such as cache utilization tracked by time of day. Any type of analytics can be utilized by analytics agent <b>180</b>.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flow diagram of one embodiment of a technique for monitoring under-utilized resources. The operations described with respect to <figref idref="DRAWINGS">FIG. <b>2</b></figref> can be performed by one or more scavenger agents and/or one or more aggregating allocation agents. Resource utilization is evaluated, <b>210</b>. As discussed above, scavenger agents and/or other entities evaluate or determine utilization levels for one or more resources of a host system. Resources can include, for example, memory/storage/cache capacity, processor bandwidth, memory system bandwidth, network (wired or wireless) bandwidth, battery power, cryptographic processing, etc.</p><p id="p-0035" num="0034">The unconsumed portion/capacity of the one or more resources can be determined, <b>220</b>. For example, the scavenger agent can determine that the host hard drive is 30% used and that drive accesses occur infrequently. With that type of information, the scavenger agent can determine that the hard drive is 70% unutilized and that some percentage of memory bandwidth is unutilized. Similar types of information can be determined for various resources within the host system.</p><p id="p-0036" num="0035">The unconsumed/available resource capacity can be exposed or advertised, <b>230</b>. In one embodiment, this information is provided to a single agent that gathers resource utilization information from multiple host systems. In another embodiment, the scavenging agent can provide information for the local host system to one or more scavenging agents of other host systems.</p><p id="p-0037" num="0036">Information for unconsumed resources from multiple hosts can be gathered, <b>240</b>. As discussed above, this information can be gathered by one coordinating/aggregating agent or can be gathered by multiple agents (e.g., the scavenging agents). The unconsumed resource information from multiple hosts can be aggregated (or otherwise organized) and exposed or advertised to one or more of the host systems, <b>250</b>.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow diagram of one embodiment of a technique for performing load prediction analytics. In one embodiment, the operations of <figref idref="DRAWINGS">FIG. <b>3</b></figref> are performed by an analytics agent that gathers resource utilization information from multiple scavenger agents; however, other configurations can also be supported.</p><p id="p-0039" num="0038">Resource load and/or consumption and/or utilization statistical information are gathered, <b>310</b>. In one embodiment, the statistical information can be gathered from multiple host systems; however, in other embodiments, statistical gathering and/or analysis can be done on a host-by-host basis.</p><p id="p-0040" num="0039">Prediction modeling can be applied to load information, <b>320</b>. In one embodiment, machine learning techniques (e.g., predictive analytics) can be utilized to predict loads for one or more resources for a selected period of time.</p><p id="p-0041" num="0040">Load prediction information is generated based on the modeling results, <b>330</b>. In one embodiment, load predications are made for resources corresponding to multiple host systems within the environment.</p><p id="p-0042" num="0041">Resources are allocated for the selected period of time based on the load predictions, <b>340</b>. For example, storage capacity on a hard drive of one host system can have a portion allocated to another host system for use until the first host system requires more storage capacity. Multiple types of resources can be managed and allocated in a similar manner. Allocation can be performed by a single coordinating agent or can be determined by host systems as they receive load prediction information.</p><p id="p-0043" num="0042">Allocation information can be distributed, <b>350</b>. If allocations are managed by a single coordinating agent, assignments and corresponding instructions/directions can be distributed by the coordinating agent. If allocations are performed in a distributed manner, host systems may claim resources of other host systems and then notify one or more host systems of the claim. Other strategies can also be employed. Allocations can be applied, <b>350</b> for some period of time.</p><p id="p-0044" num="0043">In one embodiment, the techniques described herein can be performed within an on-demand database service environment. The techniques can also be performed across, for example, disparate heterogeneous environment.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram of one embodiment of a scavenger agent that can operate as described herein. Scavenger agent <b>400</b> includes control logic <b>410</b>, which implements logical functional control to direct operation of scavenger agent <b>400</b>, and/or hardware associated with directing operation of scavenger agent <b>400</b>. Logic may be hardware logic circuits and/or software routines. In one embodiment, scavenger agent <b>400</b> includes one or more applications <b>412</b>, which represent code sequence and/or programs that provide instructions to control logic <b>410</b>.</p><p id="p-0046" num="0045">Scavenger agent <b>400</b> includes memory <b>414</b>, which represents a memory device and/or access to a memory resource for storing data and/or instructions. Memory <b>414</b> may include memory local to scavenger agent <b>400</b>, as well as, or alternatively, including memory of the host system on which scavenger agent <b>400</b> resides. Scavenger agent <b>400</b> also includes one or more interfaces <b>416</b>, which represent access interfaces to/from (an input/output interface) scavenger agent <b>400</b> with regard to entities (electronic or human) external to scavenger agent <b>400</b>.</p><p id="p-0047" num="0046">Scavenger agent <b>400</b> also includes scavenger engine <b>420</b>, which represents one or more functions or module that enable scavenger agent <b>400</b> to provide the scavenging functionality as described above. The example of <figref idref="DRAWINGS">FIG. <b>4</b></figref> provides several modules that may be included in scavenger engine <b>420</b>; however, different and/or additional modules may also be included. Example modules that may be involved in providing the resource scavenging functionality include resource monitor(s) <b>440</b>, evaluation module(s) <b>450</b> and evaluation coordinator <b>460</b>.</p><p id="p-0048" num="0047">In one embodiment, resource monitor(s) <b>440</b> operate to monitor/check utilization of one or more resources including, for example, memory/storage/cache capacity, processor bandwidth, memory system bandwidth, network (wired or wireless) bandwidth, battery power, cryptographic processing, etc. Resource monitor(s) <b>440</b> can be utilized to monitor any number or combination of host systems having resources that can be scavenged as described herein.</p><p id="p-0049" num="0048">In one embodiment, evaluation module(s) <b>450</b> is/are communicatively coupled with resource monitor(s) <b>440</b> to receive utilization information from resource monitor(s) <b>440</b>. Resource monitor(s) <b>440</b> can perform various types of analysis on the utilization information that can be used to provide relevant utilization metrics. For example, evaluation monitor(s) <b>440</b> can determine a utilization percentage by a thread/process running on the host system for a memory device. Other types of analysis can also be performed.</p><p id="p-0050" num="0049">In one embodiment, evaluation module(s) <b>460</b> is/are communicatively coupled with at least evaluation module(s) <b>450</b> to receive utilization and/or other information about resource utilization. In one embodiment, evaluation module(s) <b>460</b> operate to provide consistent resource utilization information by coordinating resource information gathering and evaluation by scavenger agent <b>400</b>.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram of one embodiment of an aggregation agent that can operate as described herein. Aggregation agent <b>500</b> includes control logic <b>510</b>, which implements logical functional control to direct operation of aggregation agent <b>500</b>, and/or hardware associated with directing operation of aggregation agent <b>500</b>. Logic may be hardware logic circuits and/or software routines. In one embodiment, aggregation agent <b>500</b> includes one or more applications <b>512</b>, which represent code sequence and/or programs that provide instructions to control logic <b>510</b>.</p><p id="p-0052" num="0051">Aggregation agent <b>500</b> includes memory <b>514</b>, which represents a memory device and/or access to a memory resource for storing data and/or instructions. Memory <b>514</b> may include memory local to aggregation agent <b>500</b>, as well as, or alternatively, including memory of the host system on which aggregation agent <b>500</b> resides. Aggregation agent <b>500</b> also includes one or more interfaces <b>516</b>, which represent access interfaces to/from (an input/output interface) aggregation agent <b>500</b> with regard to entities (electronic or human) external to aggregation agent <b>500</b>.</p><p id="p-0053" num="0052">Aggregation agent <b>500</b> also includes aggregation engine <b>520</b>, which represents one or more functions or modules that enable aggregation agent <b>500</b> to provide the scavenging and/or aggregation functionality as described above. The example of <figref idref="DRAWINGS">FIG. <b>5</b></figref> provides several modules that may be included in aggregation engine <b>520</b>; however, different and/or additional modules may also be included. Example modules that may be involved in providing the resource scavenging and/or aggregation functionality include utilization gathering module(s) <b>530</b>, aggregation module(s) <b>540</b> and exposure module(s) <b>550</b>.</p><p id="p-0054" num="0053">In one embodiment, utilization gathering module(s) <b>530</b> are coupled to request and/or receive utilization information from one or more scavenger agents (e.g., scavenger agent <b>400</b>). This information can be gathered continuously or periodically (e.g., hourly, daily).</p><p id="p-0055" num="0054">In one embodiment, aggregation module(s) <b>540</b> is/are communicatively coupled with utilization gathering module(s) <b>530</b>. Aggregation module(s) <b>540</b> operate to aggregate utilization and/or availability information for resources (or types of resources). In one embodiment, utilization and/or availability information can be aggregated for resource types (e.g., hard drives, processors). In another embodiment, utilization and/or availability information can be aggregated for classes of resources within the resource types. For example, utilization and/or availability information can be aggregated for 5400 RPM hard disks or 2.5+ GHz processors. Aggregating functionality is described in greater detail in U.S. Patent Application No. __/______, filed ______, 2016 and entitled &#x201c;TECHNIQUES AND ARCHITECTURES FOR EFFICIENT ALLOCATION OF UNDER-UTILIZED RESOURCES,&#x201d; by James Walsh and Sameer Tiwari, which is incorporated by reference herein.</p><p id="p-0056" num="0055">In one embodiment, exposure module(s) <b>550</b> is/are coupled with at least aggregation module(s) <b>540</b>. Exposure module(s) <b>550</b> operate to provide availability information outside of aggregation agent <b>500</b>, for example, to one or more computing devices within a larger computing platform/environment.</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram of one embodiment of a prediction agent that can operate as described herein. Prediction agent <b>600</b> includes control logic <b>610</b>, which implements logical functional control to direct operation of prediction agent <b>600</b>, and/or hardware associated with directing operation of prediction agent <b>600</b>. Logic may be hardware logic circuits and/or software routines. In one embodiment, prediction agent <b>600</b> includes one or more applications <b>612</b>, which represent code sequence and/or programs that provide instructions to control logic <b>610</b>.</p><p id="p-0058" num="0057">Prediction agent <b>600</b> includes memory <b>614</b>, which represents a memory device and/or access to a memory resource for storing data and/or instructions. Memory <b>614</b> may include memory local to prediction agent <b>600</b>, as well as, or alternatively, including memory of the host system on which prediction agent <b>600</b> resides. Prediction agent <b>600</b> also includes one or more interfaces <b>616</b>, which represent access interfaces to/from (an input/output interface) prediction agent <b>600</b> with regard to entities (electronic or human) external to prediction agent <b>600</b>.</p><p id="p-0059" num="0058">Prediction agent <b>600</b> also includes prediction engine <b>620</b>, which represents one or more functions or modules that enable prediction agent <b>600</b> to provide the scavenging and/or aggregation functionality as described above. The example of <figref idref="DRAWINGS">FIG. <b>6</b></figref> provides several modules that may be included in prediction engine <b>620</b>; however, different and/or additional modules may also be included. Example modules that may be involved in providing the resource prediction functionality include historical statistics module(s) <b>630</b>, prediction modeler(s) <b>640</b> and prediction distributor(s) <b>650</b>.</p><p id="p-0060" num="0059">In one embodiment, historical statistics module(s) <b>630</b> gather and/or generate statistical information related to resource availability and/or utilization. Statistical information can be stored in statistics database <b>635</b>. Statistical information can be gathered from, for example, scavenger agent <b>400</b> and/or aggregation agent <b>500</b>.</p><p id="p-0061" num="0060">Prediction modeler(s) <b>640</b> operate to utilize historical statistical information and current information to generate predictions of resource utilization and/or resource availability. Various predictive analytics techniques can be utilized to perform this operation.</p><p id="p-0062" num="0061">Prediction distributor(s) <b>650</b> operate to distribute prediction information to one or more destinations including, for example, computing platforms that may attempt to utilize available resources from other systems within the computing environment.</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram of one embodiment of an allocation agent that can operate as described herein. Allocation agent <b>700</b> includes control logic <b>710</b>, which implements logical functional control to direct operation of allocation agent <b>700</b>, and/or hardware associated with directing operation of allocation agent <b>700</b>. Logic may be hardware logic circuits and/or software routines. In one embodiment, allocation agent <b>700</b> includes one or more applications <b>712</b>, which represent code sequence and/or programs that provide instructions to control logic <b>710</b>.</p><p id="p-0064" num="0063">Allocation agent <b>700</b> includes memory <b>714</b>, which represents a memory device and/or access to a memory resource for storing data and/or instructions. Memory <b>714</b> may include memory local to allocation agent <b>700</b>, as well as, or alternatively, including memory of the host system on which allocation agent <b>700</b> resides. Allocation agent <b>700</b> also includes one or more interfaces <b>716</b>, which represent access interfaces to/from (an input/output interface) allocation agent <b>700</b> with regard to entities (electronic or human) external to allocation agent <b>700</b>.</p><p id="p-0065" num="0064">Allocation agent <b>700</b> also includes allocation engine <b>720</b>, which represents one or more functions or modules that enable allocation agent <b>700</b> to provide the scavenging and/or aggregation functionality as described above. The example of <figref idref="DRAWINGS">FIG. <b>7</b></figref> provides several modules that may be included in allocation engine <b>720</b>; however, different and/or additional modules may also be included. Example modules that may be involved in providing the resource allocation functionality include prediction gathering module(s) <b>730</b>, allocation module(s) <b>740</b> and allocation distributor(s) <b>750</b>.</p><p id="p-0066" num="0065">In one embodiment, prediction gathering module(s) <b>730</b> operate to gather prediction information from, for example, prediction agent <b>600</b>. Prediction information can be gathered from any number of sources capable of providing prediction information.</p><p id="p-0067" num="0066">In one embodiment, allocation module(s) <b>740</b> is/are coupled with prediction gathering module(s) <b>730</b> to receive prediction information for various resources within the host environment. In one embodiment, allocation module9s) <b>740</b> operate to allocate underutilized and/or unutilized resources to other hosts/systems as described in greater detail above.</p><p id="p-0068" num="0067">Allocation distributor(s) <b>750</b> operate to distribute allocation information to one or more destinations including, for example, computing platforms that may attempt to utilize available resources from other systems within the computing environment. In one embodiment, platforms that receive the allocation information follow the allocations for a specific length of time by either providing resources to other platforms/hosts or utilizing resources of other platforms/hosts.</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a block diagram of an environment <b>810</b> wherein an on-demand database service might be used. Environment <b>810</b> may include user systems <b>812</b>, network <b>814</b>, system <b>816</b>, processor system <b>817</b>, application platform <b>818</b>, network interface <b>820</b>, tenant data storage <b>822</b>, system data storage <b>824</b>, program code <b>826</b>, and process space <b>828</b>. In other embodiments, environment <b>810</b> may not have all of the components listed and/or may have other elements instead of, or in addition to, those listed above.</p><p id="p-0070" num="0069">Environment <b>810</b> is an environment in which an on-demand database service exists. User system <b>812</b> may be any machine or system that is used by a user to access a database user system. For example, any of user systems <b>812</b> can be a handheld computing device, a mobile phone, a laptop computer, a work station, and/or a network of computing devices. As illustrated in herein <figref idref="DRAWINGS">FIG. <b>8</b></figref> (and in more detail in <figref idref="DRAWINGS">FIG. <b>9</b></figref>) user systems <b>812</b> might interact via a network <b>814</b> with an on-demand database service, which is system <b>816</b>.</p><p id="p-0071" num="0070">An on-demand database service, such as system <b>816</b>, is a database system that is made available to outside users that do not need to necessarily be concerned with building and/or maintaining the database system, but instead may be available for their use when the users need the database system (e.g., on the demand of the users). Some on-demand database services may store information from one or more tenants stored into tables of a common database image to form a multi-tenant database system (MTS). Accordingly, &#x201c;on-demand database service <b>816</b>&#x201d; and &#x201c;system <b>816</b>&#x201d; will be used interchangeably herein. A database image may include one or more database objects. A relational database management system (RDMS) or the equivalent may execute storage and retrieval of information against the database object(s). Application platform <b>818</b> may be a framework that allows the applications of system <b>816</b> to run, such as the hardware and/or software, e.g., the operating system. In an embodiment, on-demand database service <b>816</b> may include an application platform <b>818</b> that enables creation, managing and executing one or more applications developed by the provider of the on-demand database service, users accessing the on-demand database service via user systems <b>812</b>, or third party application developers accessing the on-demand database service via user systems <b>812</b>.</p><p id="p-0072" num="0071">The users of user systems <b>812</b> may differ in their respective capacities, and the capacity of a particular user system <b>812</b> might be entirely determined by permissions (permission levels) for the current user. For example, where a salesperson is using a particular user system <b>812</b> to interact with system <b>816</b>, that user system has the capacities allotted to that salesperson. However, while an administrator is using that user system to interact with system <b>816</b>, that user system has the capacities allotted to that administrator. In systems with a hierarchical role model, users at one permission level may have access to applications, data, and database information accessible by a lower permission level user, but may not have access to certain applications, database information, and data accessible by a user at a higher permission level. Thus, different users will have different capabilities with regard to accessing and modifying application and database information, depending on a user's security or permission level.</p><p id="p-0073" num="0072">Network <b>814</b> is any network or combination of networks of devices that communicate with one another. For example, network <b>814</b> can be any one or any combination of a LAN (local area network), WAN (wide area network), telephone network, wireless network, point-to-point network, star network, token ring network, hub network, or other appropriate configuration. As the most common type of computer network in current use is a TCP/IP (Transfer Control Protocol and Internet Protocol) network, such as the global internetwork of networks often referred to as the &#x201c;Internet&#x201d; with a capital &#x201c;I,&#x201d; that network will be used in many of the examples herein. However, it should be understood that the networks that one or more implementations might use are not so limited, although TCP/IP is a frequently implemented protocol.</p><p id="p-0074" num="0073">User systems <b>812</b> might communicate with system <b>816</b> using TCP/IP and, at a higher network level, use other common Internet protocols to communicate, such as HTTP, FTP, AFS, WAP, etc. In an example where HTTP is used, user system <b>812</b> might include an HTTP client commonly referred to as a &#x201c;browser&#x201d; for sending and receiving HTTP messages to and from an HTTP server at system <b>816</b>. Such an HTTP server might be implemented as the sole network interface between system <b>816</b> and network <b>814</b>, but other techniques might be used as well or instead. In some implementations, the interface between system <b>816</b> and network <b>814</b> includes load sharing functionality, such as round-robin HTTP request distributors to balance loads and distribute incoming HTTP requests evenly over a plurality of servers. At least as for the users that are accessing that server, each of the plurality of servers has access to the MTS' data; however, other alternative configurations may be used instead.</p><p id="p-0075" num="0074">In one embodiment, system <b>816</b>, shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, implements a web-based customer relationship management (CRM) system. For example, in one embodiment, system <b>816</b> includes application servers configured to implement and execute CRM software applications as well as provide related data, code, forms, webpages and other information to and from user systems <b>812</b> and to store to, and retrieve from, a database system related data, objects, and Webpage content. With a multi-tenant system, data for multiple tenants may be stored in the same physical database object, however, tenant data typically is arranged so that data of one tenant is kept logically separate from that of other tenants so that one tenant does not have access to another tenant's data, unless such data is expressly shared. In certain embodiments, system <b>816</b> implements applications other than, or in addition to, a CRM application. For example, system <b>816</b> may provide tenant access to multiple hosted (standard and custom) applications, including a CRM application. User (or third party developer) applications, which may or may not include CRM, may be supported by the application platform <b>818</b>, which manages creation, storage of the applications into one or more database objects and executing of the applications in a virtual machine in the process space of the system <b>816</b>.</p><p id="p-0076" num="0075">One arrangement for elements of system <b>816</b> is shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, including a network interface <b>820</b>, application platform <b>818</b>, tenant data storage <b>822</b> for tenant data <b>823</b>, system data storage <b>824</b> for system data <b>825</b> accessible to system <b>816</b> and possibly multiple tenants, program code <b>826</b> for implementing various functions of system <b>816</b>, and a process space <b>828</b> for executing MTS system processes and tenant-specific processes, such as running applications as part of an application hosting service. Additional processes that may execute on system <b>816</b> include database indexing processes.</p><p id="p-0077" num="0076">Several elements in the system shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref> include conventional, well-known elements that are explained only briefly here. For example, each user system <b>812</b> could include a desktop personal computer, workstation, laptop, PDA, cell phone, or any wireless access protocol (WAP) enabled device or any other computing device capable of interfacing directly or indirectly to the Internet or other network connection. User system <b>812</b> typically runs an HTTP client, e.g., a browsing program, such as Microsoft's Internet Explorer browser, Netscape's Navigator browser, Opera's browser, or a WAP-enabled browser in the case of a cell phone, PDA or other wireless device, or the like, allowing a user (e.g., subscriber of the multi-tenant database system) of user system <b>812</b> to access, process and view information, pages and applications available to it from system <b>816</b> over network <b>814</b>. Each user system <b>812</b> also typically includes one or more user interface devices, such as a keyboard, a mouse, trackball, touch pad, touch screen, pen or the like, for interacting with a graphical user interface (GUI) provided by the browser on a display (e.g., a monitor screen, LCD display, etc.) in conjunction with pages, forms, applications and other information provided by system <b>816</b> or other systems or servers. For example, the user interface device can be used to access data and applications hosted by system <b>816</b>, and to perform searches on stored data, and otherwise allow a user to interact with various GUI pages that may be presented to a user. As discussed above, embodiments are suitable for use with the Internet, which refers to a specific global internetwork of networks. However, it should be understood that other networks can be used instead of the Internet, such as an intranet, an extranet, a virtual private network (VPN), a non-TCP/IP based network, any LAN or WAN or the like.</p><p id="p-0078" num="0077">According to one embodiment, each user system <b>812</b> and all of its components are operator configurable using applications, such as a browser, including computer code run using a central processing unit such as an Intel Pentium&#xae; processor or the like. Similarly, system <b>816</b> (and additional instances of an MTS, where more than one is present) and all of their components might be operator configurable using application(s) including computer code to run using a central processing unit such as processor system <b>817</b>, which may include an Intel Pentium&#xae; processor or the like, and/or multiple processor units. A computer program product embodiment includes a machine-readable storage medium (media) having instructions stored thereon/in which can be used to program a computer to perform any of the processes of the embodiments described herein. Computer code for operating and configuring system <b>816</b> to intercommunicate and to process webpages, applications and other data and media content as described herein are preferably downloaded and stored on a hard disk, but the entire program code, or portions thereof, may also be stored in any other volatile or non-volatile memory medium or device as is well known, such as a ROM or RAM, or provided on any media capable of storing program code, such as any type of rotating media including floppy disks, optical discs, digital versatile disk (DVD), compact disk (CD), microdrive, and magneto-optical disks, and magnetic or optical cards, nanosystems (including molecular memory ICs), or any type of media or device suitable for storing instructions and/or data. Additionally, the entire program code, or portions thereof, may be transmitted and downloaded from a software source over a transmission medium, e.g., over the Internet, or from another server, as is well known, or transmitted over any other conventional network connection as is well known (e.g., extranet, VPN, LAN, etc.) using any communication medium and protocols (e.g., TCP/IP, HTTP, HTTPS, Ethernet, etc.) as are well known. It will also be appreciated that computer code for implementing embodiments can be implemented in any programming language that can be executed on a client system and/or server or server system such as, for example, C, C++, HTML, any other markup language, Java&#x2122;, JavaScript, ActiveX, any other scripting language, such as VBScript, and many other programming languages as are well known may be used. (Java&#x2122; is a trademark of Sun Microsystems, Inc.).</p><p id="p-0079" num="0078">According to one embodiment, each system <b>816</b> is configured to provide webpages, forms, applications, data and media content to user (client) systems <b>812</b> to support the access by user systems <b>812</b> as tenants of system <b>816</b>. As such, system <b>816</b> provides security mechanisms to keep each tenant's data separate unless the data is shared. If more than one MTS is used, they may be located in close proximity to one another (e.g., in a server farm located in a single building or campus), or they may be distributed at locations remote from one another (e.g., one or more servers located in city A and one or more servers located in city B). As used herein, each MTS could include one or more logically and/or physically connected servers distributed locally or across one or more geographic locations. Additionally, the term &#x201c;server&#x201d; is meant to include a computer system, including processing hardware and process space(s), and an associated storage system and database application (e.g., OODBMS or RDBMS) as is well known in the art. It should also be understood that &#x201c;server system&#x201d; and &#x201c;server&#x201d; are often used interchangeably herein. Similarly, the database object described herein can be implemented as single databases, a distributed database, a collection of distributed databases, a database with redundant online or offline backups or other redundancies, etc., and might include a distributed database or storage network and associated processing intelligence.</p><p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. <b>9</b></figref> also illustrates environment <b>810</b>. However, in <figref idref="DRAWINGS">FIG. <b>9</b></figref> elements of system <b>816</b> and various interconnections in an embodiment are further illustrated.</p><p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows that user system <b>812</b> may include processor system <b>812</b>A, memory system <b>812</b>B, input system <b>812</b>C, and output system <b>812</b>D. <figref idref="DRAWINGS">FIG. <b>9</b></figref> shows network <b>814</b> and system <b>816</b>. <figref idref="DRAWINGS">FIG. <b>9</b></figref> also shows that system <b>816</b> may include tenant data storage <b>822</b>, tenant data <b>823</b>, system data storage <b>824</b>, system data <b>825</b>, User Interface (UI) <b>930</b>, Application Program Interface (API) <b>932</b>, PL/SOQL <b>934</b>, save routines <b>936</b>, application setup mechanism <b>938</b>, applications servers <b>900</b><sub>1</sub>-<b>900</b><sub>N</sub>, system process space <b>902</b>, tenant process spaces <b>904</b>, tenant management process space <b>910</b>, tenant storage area <b>912</b>, user storage <b>914</b>, and application metadata <b>916</b>. In other embodiments, environment <b>810</b> may not have the same elements as those listed above and/or may have other elements instead of, or in addition to, those listed above.</p><p id="p-0082" num="0081">User system <b>812</b>, network <b>814</b>, system <b>816</b>, tenant data storage <b>822</b>, and system data storage <b>824</b> were discussed above in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. Regarding user system <b>812</b>, processor system <b>812</b>A may be any combination of one or more processors. Memory system <b>812</b>B may be any combination of one or more memory devices, short term, and/or long term memory. Input system <b>812</b>C may be any combination of input devices, such as one or more keyboards, mice, trackballs, scanners, cameras, and/or interfaces to networks. Output system <b>812</b>D may be any combination of output devices, such as one or more monitors, printers, and/or interfaces to networks. As shown by <figref idref="DRAWINGS">FIG. <b>9</b></figref>, system <b>816</b> may include a network interface <b>820</b> (of <figref idref="DRAWINGS">FIG. <b>8</b></figref>) implemented as a set of HTTP application servers <b>900</b>, an application platform <b>818</b>, tenant data storage <b>822</b>, and system data storage <b>824</b>. Also shown is system process space <b>902</b>, including individual tenant process spaces <b>904</b> and a tenant management process space <b>910</b>. Each application server <b>900</b> may be configured to tenant data storage <b>822</b> and the tenant data <b>823</b> therein, and system data storage <b>824</b> and the system data <b>825</b> therein to serve requests of user systems <b>812</b>. The tenant data <b>823</b> might be divided into individual tenant storage areas <b>912</b>, which can be either a physical arrangement and/or a logical arrangement of data. Within each tenant storage area <b>912</b>, user storage <b>914</b> and application metadata <b>916</b> might be similarly allocated for each user. For example, a copy of a user's most recently used (MRU) items might be stored to user storage <b>914</b>. Similarly, a copy of MRU items for an entire organization that is a tenant might be stored to tenant storage area <b>912</b>. A UI <b>930</b> provides a user interface and an API <b>932</b> provides an application programmer interface to system <b>816</b> resident processes to users and/or developers at user systems <b>812</b>. The tenant data and the system data may be stored in various databases, such as one or more Oracle&#x2122; databases.</p><p id="p-0083" num="0082">Application platform <b>818</b> includes an application setup mechanism <b>938</b> that supports application developers' creation and management of applications, which may be saved as metadata into tenant data storage <b>822</b> by save routines <b>936</b> for execution by subscribers as one or more tenant process spaces <b>904</b> managed by tenant management process <b>910</b> for example. Invocations to such applications may be coded using PL/SOQL <b>934</b> that provides a programming language style interface extension to API <b>932</b>. A detailed description of some PL/SOQL language embodiments is discussed in commonly owned U.S. Pat. No. 7,730,478 entitled, &#x201c;Method and System for Allowing Access to Developed Applicants via a Multi-Tenant Database On-Demand Database Service&#x201d;, issued Jun. 1, 2010 to Craig Weissman, which is incorporated in its entirety herein for all purposes. Invocations to applications may be detected by one or more system processes, which manage retrieving application metadata <b>916</b> for the subscriber making the invocation and executing the metadata as an application in a virtual machine.</p><p id="p-0084" num="0083">Each application server <b>900</b> may be communicably coupled to database systems, e.g., having access to system data <b>825</b> and tenant data <b>823</b>, via a different network connection. For example, one application server <b>900</b><sub>1 </sub>might be coupled via the network <b>814</b> (e.g., the Internet), another application server <b>900</b><sub>N-1 </sub>might be coupled via a direct network link, and another application server <b>900</b><sub>N </sub>might be coupled by yet a different network connection. Transfer Control Protocol and Internet Protocol (TCP/IP) are typical protocols for communicating between application servers <b>900</b> and the database system. However, it will be apparent to one skilled in the art that other transport protocols may be used to optimize the system depending on the network interconnect used.</p><p id="p-0085" num="0084">In certain embodiments, each application server <b>900</b> is configured to handle requests for any user associated with any organization that is a tenant. Because it is desirable to be able to add and remove application servers from the server pool at any time for any reason, there is preferably no server affinity for a user and/or organization to a specific application server <b>900</b>. In one embodiment, therefore, an interface system implementing a load balancing function (e.g., an F5 Big-IP load balancer) is communicably coupled between the application servers <b>900</b> and the user systems <b>812</b> to distribute requests to the application servers <b>900</b>. In one embodiment, the load balancer uses a least connections algorithm to route user requests to the application servers <b>900</b>. Other examples of load balancing algorithms, such as round robin and observed response time, also can be used. For example, in certain embodiments, three consecutive requests from the same user could hit three different application servers <b>900</b>, and three requests from different users could hit the same application server <b>900</b>. In this manner, system <b>816</b> is multi-tenant, wherein system <b>816</b> handles storage of, and access to, different objects, data and applications across disparate users and organizations.</p><p id="p-0086" num="0085">As an example of storage, one tenant might be a company that employs a sales force where each salesperson uses system <b>816</b> to manage their sales process. Thus, a user might maintain contact data, leads data, customer follow-up data, performance data, goals and progress data, etc., all applicable to that user's personal sales process (e.g., in tenant data storage <b>822</b>). In an example of a MTS arrangement, since all of the data and the applications to access, view, modify, report, transmit, calculate, etc., can be maintained and accessed by a user system having nothing more than network access, the user can manage his or her sales efforts and cycles from any of many different user systems. For example, if a salesperson is visiting a customer and the customer has Internet access in their lobby, the salesperson can obtain critical updates as to that customer while waiting for the customer to arrive in the lobby.</p><p id="p-0087" num="0086">While each user's data might be separate from other users' data regardless of the employers of each user, some data might be organization-wide data shared or accessible by a plurality of users or all of the users for a given organization that is a tenant. Thus, there might be some data structures managed by system <b>816</b> that are allocated at the tenant level while other data structures might be managed at the user level. Because an MTS might support multiple tenants including possible competitors, the MTS should have security protocols that keep data, applications, and application use separate. Also, because many tenants may opt for access to an MTS rather than maintain their own system, redundancy, up-time, and backup are additional functions that may be implemented in the MTS. In addition to user-specific data and tenant specific data, system <b>816</b> might also maintain system level data usable by multiple tenants or other data. Such system level data might include industry reports, news, postings, and the like that are sharable among tenants.</p><p id="p-0088" num="0087">In certain embodiments, user systems <b>812</b> (which may be client systems) communicate with application servers <b>900</b> to request and update system-level and tenant-level data from system <b>816</b> that may require sending one or more queries to tenant data storage <b>822</b> and/or system data storage <b>824</b>. System <b>816</b> (e.g., an application server <b>900</b> in system <b>816</b>) automatically generates one or more SQL statements (e.g., one or more SQL queries) that are designed to access the desired information. System data storage <b>824</b> may generate query plans to access the requested data from the database.</p><p id="p-0089" num="0088">Each database can generally be viewed as a collection of objects, such as a set of logical tables, containing data fitted into predefined categories. A &#x201c;table&#x201d; is one representation of a data object, and may be used herein to simplify the conceptual description of objects and custom objects. It should be understood that &#x201c;table&#x201d; and &#x201c;object&#x201d; may be used interchangeably herein. Each table generally contains one or more data categories logically arranged as columns or fields in a viewable schema. Each row or record of a table contains an instance of data for each category defined by the fields. For example, a CRM database may include a table that describes a customer with fields for basic contact information such as name, address, phone number, fax number, etc. Another table might describe a purchase order, including fields for information such as customer, product, sale price, date, etc. In some multi-tenant database systems, standard entity tables might be provided for use by all tenants. For CRM database applications, such standard entities might include tables for Account, Contact, Lead, and Opportunity data, each containing pre-defined fields. It should be understood that the word &#x201c;entity&#x201d; may also be used interchangeably herein with &#x201c;object&#x201d; and &#x201c;table&#x201d;.</p><p id="p-0090" num="0089">In some multi-tenant database systems, tenants may be allowed to create and store custom objects, or they may be allowed to customize standard entities or objects, for example by creating custom fields for standard objects, including custom index fields. U.S. patent application Ser. No. 10/817,161, filed Apr. 2, 2004, entitled &#x201c;Custom Entities and Fields in a Multi-Tenant Database System&#x201d;, and which is hereby incorporated herein by reference, teaches systems and methods for creating custom objects as well as customizing standard objects in a multi-tenant database system. In certain embodiments, for example, all custom entity data rows are stored in a single multi-tenant physical table, which may contain multiple logical tables per organization. It is transparent to customers that their multiple &#x201c;tables&#x201d; are in fact stored in one large table or that their data may be stored in the same table as the data of other customers.</p><p id="p-0091" num="0090">Reference in the specification to &#x201c;one embodiment&#x201d; or &#x201c;an embodiment&#x201d; means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the invention. The appearances of the phrase &#x201c;in one embodiment&#x201d; in various places in the specification are not necessarily all referring to the same embodiment.</p><p id="p-0092" num="0091">While the invention has been described in terms of several embodiments, those skilled in the art will recognize that the invention is not limited to the embodiments described, but can be practiced with modification and alteration within the spirit and scope of the appended claims. The description is thus to be regarded as illustrative instead of limiting.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method, comprising:<claim-text>determining, by one or more servers based at least in part on a first message transmitted by a first computing system, a first utilization level for a first individual resource within the first computing system, the first utilization level indicating an unconsumed capacity for the first individual resource;</claim-text><claim-text>determining, by the one or more servers, predicted load information associated with the first computing system based, at least in part, on the first utilization level for the first individual resource, the predicted load information indicating a predicted load for the first individual resource; and</claim-text><claim-text>allocating, by the one or more servers, a portion of the first individual resource to a second computing system based, at least in part, on the predicted load information,</claim-text><claim-text>wherein allocating the portion of the first individual resource to the second computing system is performed responsive to processing a request from the second computing system, the portion of the first individual resource being allocated to the second computing system until it is needed by the first computing system.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the first individual resource comprises at least virtual memory capacity.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the first individual resource comprises at least physical memory capacity.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the first individual resource comprises at least virtual processor capacity.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the first individual resource comprises at least physical processor capacity.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the first individual resource comprises at least cache memory capacity.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the first individual resource comprises at least database capacity.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A non-transitory computer-readable medium having stored thereon instructions that, when executed by one or more processors, are configurable to cause the one or more processors to:<claim-text>determine, by one or more servers based at least in part on a first message transmitted by a first computing system, a first utilization level for a first individual resource within the first computing system, the first utilization level indicating an unconsumed capacity for the first individual resource;</claim-text><claim-text>determine, by the one or more servers, predicted load information associated with the first computing system based, at least in part, on the first utilization level for the first individual resource, the predicted load information indicating a predicted load for the first individual resource; and</claim-text><claim-text>allocate, by the one or more servers, a portion of the first individual resource to a second computing system based, at least in part, on the predicted load information,</claim-text><claim-text>wherein allocating the portion of the first individual resource to the second computing system is performed responsive to processing a request from the second computing system, the portion of the first individual resource being allocated to the second computing system until it is needed by the first computing system.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the first individual resource comprises at least virtual memory capacity.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the first individual resource comprises at least physical memory capacity.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the first individual resource comprises at least virtual processor capacity.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the first individual resource comprises at least physical processor capacity.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the first individual resource comprises at least cache memory capacity.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref> wherein the first individual resources comprises at least database capacity.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A system comprising:<claim-text>at least one hardware memory device;</claim-text><claim-text>one or more hardware processors coupled with the at least one hardware memory device, the one or more hardware processors configured to:</claim-text><claim-text>determine, by one or more servers based at least in part on a first message transmitted by a first computing system, a first utilization level for a first individual resource within the first computing system, the first utilization level indicating an unconsumed capacity for the first individual resource;</claim-text><claim-text>determine, by the one or more servers, predicted load information associated with the first computing system based, at least in part, on the first utilization level for the first individual resource, the predicted load information indicating a predicted load for the first individual resource; and</claim-text><claim-text>allocate, by the one or more servers, a portion of the first individual resource to a second computing system based, at least in part, on the predicted load information,</claim-text><claim-text>wherein allocating the portion of the first individual resource to the second computing system is performed responsive to processing a request from the second computing system, the portion of the first individual resource being allocated to the second computing system until it is needed by the first computing system.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the first individual resource comprises at least virtual memory capacity.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the first individual resource comprises at least physical memory capacity.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the first individual resource comprises at least virtual processor capacity.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the first individual resource comprises at least physical processor capacity.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the first individual resource comprises at least cache memory capacity.</claim-text></claim></claims></us-patent-application>
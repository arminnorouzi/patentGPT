<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004825A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004825</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17782678</doc-number><date>20191213</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>02</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>022</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><invention-title id="d2e43">COGNITIVE ENGINEERING GRAPH</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Siemens Aktiengesellschaft</orgname><address><city>Munich</city><country>DE</country></address></addressbook><residence><country>DE</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Quiros Araya</last-name><first-name>Gustavo Arturo</first-name><address><city>Princeton</city><state>NJ</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Muenzel</last-name><first-name>Georg</first-name><address><city>Waischenfeld</city><country>DE</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Martinez Canedo</last-name><first-name>Arquimedes</first-name><address><city>Plainsboro</city><state>NJ</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Heindl</last-name><first-name>Elisabeth</first-name><address><city>Cadolzburg</city><country>DE</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Neidig</last-name><first-name>J&#xf6;rg</first-name><address><city>N&#xfc;rnberg</city><country>DE</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/US2019/066138</doc-number><date>20191213</date></document-id><us-371c12-date><date>20220606</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method for representing knowledge in a cognitive engineering system (CES) includes receiving information relating to an automation engineering project from an engineering tool, storing the received information in a cognitive engineering graph (CEG) storing a plurality of previously generated CEGs for previous automation engineering projects, and establishing a communication path between the CEG storing the received information and the plurality of previously generated CEGs. The method may further include applying machine learning to the stored CEG based on the received information and the stored plurality of previously generated CEGs. The machine learning may analyze the CEG to identify at least one pattern that is representative of a given object from the automation engineering project. The CES may automatically add an element to the CEG based on the received information and a query from a user. Further, the user may request a change made by the CES be reversed.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="125.98mm" wi="158.75mm" file="US20230004825A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="254.08mm" wi="182.20mm" orientation="landscape" file="US20230004825A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="134.20mm" wi="154.18mm" file="US20230004825A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="213.02mm" wi="187.03mm" file="US20230004825A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="165.52mm" wi="160.02mm" file="US20230004825A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="215.98mm" wi="176.70mm" file="US20230004825A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="160.95mm" wi="186.44mm" file="US20230004825A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="157.90mm" wi="188.89mm" file="US20230004825A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="208.03mm" wi="179.58mm" file="US20230004825A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="236.81mm" wi="199.90mm" file="US20230004825A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="214.80mm" wi="176.28mm" orientation="landscape" file="US20230004825A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="173.14mm" wi="190.67mm" file="US20230004825A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="150.11mm" wi="150.71mm" file="US20230004825A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">This application relates to automation engineering. More particularly, the application relates to cognitive engineering for automation systems.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Performing automation engineering tasks requires a high level of human technical and domain expertise due to the complexity and critically of modern automation systems in manufacturing and assembly, chemical, pharmaceutical, food and beverage, paper, electronics, etc.) The growing complexity of automated systems, the increasing requirements for high productivity and quality of the engineering tasks, and the increasing demands for safety and high availability of the automation make it very difficult for teams of human experts to write automation programs fast enough. Rotation of staff aggravates this problem for organizations. Improved systems and methods to address these challenges is desired.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">According to some embodiments of this disclosure, a method for representing knowledge in a cognitive engineering system (CES) includes receiving information relating to an automation engineering project from an engineering tool, storing the received information in a cognitive engineering graph (CEG) comprising a plurality of nodes representative of an element of the automation engineering project and at least on edge connecting two of the nodes, the at least one edge representative of a relationship between the connected nodes, storing a plurality of previously generated CEGs representative of other prior automation engineering projects, and establishing a communication path between the CEG storing the received information and the plurality of previously generated CEGs. In some embodiments, the method may further include applying machine learning to the stored CEG based on the received information and the stored plurality of previously generated CEGs. The machine learning may be used to analyze the CEG based on the received information to identify at least one pattern that is representative of a given object of interest from the automation engineering project. In some embodiments the CES may automatically add an element to the CEG based on the received information and on a query from a user. According to an embodiment, the user may request that a change made by the CES be reversed. An undo action may be performed where the system identifies any recent automatic changes and any associated dependencies and removes those changes returning the system to the state it was in prior the automatic changes being performed.</p><p id="p-0005" num="0004">The knowledge representation in the form of the CEG may include nodes that represent physical objects in the automation engineering project or an automation program for controlling a corresponding physical object in the automation engineering program. The CEG may include a representation of a human machine interface and/or a programmable logic controller. The CEG may be used to validate a design for the automation engineering project by comparing the CEG to a plurality of previously generated CEGs. I some embodiments the generated CEG can be compared to previously generated CEGs and provide a suggested course of action to a user.</p><p id="p-0006" num="0005">According to some embodiments of the present disclosure, a system for providing a knowledge representation in a cognitive engineering system (CES) includes a computer-based engineering tool for providing at least one of designing, programming simulation and testing of an automation system, a cognitive system in communication with the computer-based engineering tool comprising: a knowledge extraction module for identifying and storing information contained in a project of the computer-based engineering tool and from data received from a physical automation system, a machine learning module for analyzing knowledge extracted by the knowledge extraction module and identifying characteristics of the automation system; an inductive programming module of automatically generating control programs for the automation system based on the stored information from the knowledge extraction module, and a knowledge representation comprising a cognitive engineering graph (CEG), the CEG comprising a plurality of nodes representative of an element of the automation engineering project and at least on edge connecting two of the nodes, the at least one edge representative of a relationship between the connected nodes.</p><p id="p-0007" num="0006">The system may include a computer memory that stores a plurality of CEGs from previously designed projects in communication with the machine learning module for analyzing past knowledge. Based on analysis of the CEG of a current design in view of the previously designed projects, a feedback module may be provided to give information to the user. For example, a user may be provided with feedback relating to the validation of the project being designed. In other embodiments, the feedback module may provide a user with a recommended course of action based in part on the actions taken in previous projects.</p><p id="p-0008" num="0007">A communications channel may be established between the knowledge extraction module and a physical automation system. The physical automation system generates data relating to the operating state of the automation system and provides the information in the data to the knowledge representation.</p><p id="p-0009" num="0008">An automated reasoning module may be in communication with the engineering tool and the knowledge representation and may be configured to make certain design decisions including the automatic addition of a component to an engineering project in the engineering tool.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0009">The foregoing and other aspects of the present invention are best understood from the following detailed description when read in connection with the accompanying drawings. For the purpose of illustrating the invention, there is shown in the drawings embodiments that are presently preferred, it being understood, however, that the invention is not limited to the specific instrumentalities disclosed. Included in the drawings are the following Figures:</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of a cognitive automation engineering system according to aspects of embodiments of this description.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a representative example of a display screen that may be used as part of an automation engineering tool for designing a cognitive automation engineering system according to aspects of embodiments of this description.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a cognitive engineering graph for an automation system according to aspects of embodiments of this description.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a pattern extracted from a cognitive engineering graph for an automation system according to aspects of embodiments of this description.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is the pattern of <figref idref="DRAWINGS">FIG. <b>4</b></figref> with added nodes to represent a new element of an automation system according to aspects of embodiments of this description.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is the simplified pattern of <figref idref="DRAWINGS">FIG. <b>5</b></figref> for display to a user according to aspects of embodiments of this description.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is the simplified view of <figref idref="DRAWINGS">FIG. <b>6</b></figref> with new user-defined properties according to aspects of embodiments of this description.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows an updated pattern of <figref idref="DRAWINGS">FIG. <b>5</b></figref> including new user-defined properties according to aspects of embodiments of this description.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows an updated cognitive engineering graph for a system including new user-defined properties according to aspects of embodiments of this description.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram of a computer system that may be used to implement a cognitive engineering system and cognitive engineering graph according to aspects of embodiments of the present disclosure.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram of a cognitive engineering graph that provides varying level of detail for objects represented by the cognitive engineering graph</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a block diagram for a method of representing knowledge in a cognitive engineering system according to aspects of embodiments of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0023" num="0022">Embodiments described in this disclosure address bringing artificial intelligence (AI) to automation engineering tools to assist humans in design while increasing their productivity and ensuring high quality. The result is generating automation programs that provide higher reliability, availability and safety. Typically, if the complexity of an automation engineering task is significant, additional human engineers are added to the design team with the hope of providing solutions to the problem that are timely and contain high quality. Unfortunately, adding more humans to the teams does not scale in practice due to the increased overhead in communication and management.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a high-level diagram of a Cognitive Automation Engineering System (CES) <b>110</b> configured to solve the problem that conventional automation engineering systems fail to leverage machine intelligence to improve decisions. In the CES <b>110</b>, the engineer <b>101</b> provides human input <b>103</b> using an engineering tool <b>111</b>, denoted as automation engineering system. The engineering tool <b>111</b> allows the engineer <b>101</b> to provide functionality including but not limited to design, configuration, programming, simulation and testing. When a design is complete, the engineering tool <b>111</b> allows the design to be deployed <b>125</b> in a physical automation system <b>120</b>.</p><p id="p-0025" num="0024">Cognitive engineering utilizes machine learning to allow the cognitive engineering system <b>110</b> to assist the engineer <b>101</b>. Through machine learning, the CES <b>110</b> can recognize aspects of the physical automation system <b>120</b>, along with past engineering actions previously taken and use this knowledge to assist the engineer <b>101</b> during design. For example, the CES <b>110</b> may observe an action the engineer <b>101</b> performs in the engineering tool <b>111</b> and associate the action with an action previously taken by the same or another engineer. Based on this recognition, the CES <b>110</b> may suggest to the engineer <b>101</b> that some or all of the project could be preloaded by the CES <b>110</b> into the workspace of the engineering tool <b>111</b>. In some embodiments, the CES may make suggestions to the Engineer <b>101</b> regarding future design actions. For example, the CES <b>110</b> may observe the engineer <b>101</b> adding a system component to the engineering tool. The CES <b>110</b> may compare the action to actions taken by other engineers in the past who were working on the same problem or in a similar system. If the engineer's action is aligned with actions the CES <b>110</b> has seen as typical in the past, the CES <b>110</b> may suggest to the engineer <b>111</b> that a different course of action may be considered. The engineer has the option of accepting the CES suggestion or continuing with the original action of the engineer <b>101</b>.</p><p id="p-0026" num="0025">The cognitive system <b>113</b> leverages captured knowledge to assist the engineer <b>101</b>. The cognitive system <b>113</b> functions to extract knowledge <b>119</b> from the system via system input <b>127</b> and provide a stored representation of the collected knowledge <b>117</b>. Machine learning <b>114</b> is performed on the stored extracted knowledge to identify and exploit relationships in the data. In some embodiments the knowledge may be used to provide inductive programming <b>112</b> for components or control of the system. Automated reasoning <b>115</b> is applied to the knowledge representation <b>117</b> and may be used to analyze the knowledge representation <b>117</b> and provide feedback to the engineer <b>101</b> based on the analysis.</p><p id="p-0027" num="0026">With reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, embodiments of the present invention are directed to achieving a realization of the &#x201c;Knowledge Representation&#x201d; component <b>117</b> of the Cognitive Automation Engineering System <b>110</b>. Through the reuse of engineering knowledge in the knowledge representation <b>117</b>, a Cognitive Automation Engineering system <b>110</b> can improve the productivity and the quality of automation engineering projects.</p><p id="p-0028" num="0027">The representation of knowledge has long been a topic of research with early attempts focusing on maintaining knowledge in a standard or specialized database, such as a relational database using database languages such as SQL. These databases store information in the form of rules and facts. In later research, the use of knowledge graphs has become popular for representing and analyzing linked information from communication networks, social network logistics, marketing systems and geographical information.</p><p id="p-0029" num="0028">This disclosure presents a Cognitive Engineering Graph (CEG) as the main building block of a Cognitive Engineering System (CES), responsible for the knowledge representation <b>117</b> of the system. The CEG represents all relevant information about the engineering process in the form of a graph, in accordance with the techniques used by today's graph databases (e.g., Neo4j, BlazeGraph).</p><p id="p-0030" num="0029">The CEG is created and subsequently updated with information obtained from engineering tools such as TIA Portal. Other related engineering tools such as computer assisted design (CAD)/computer aided engineering (CAE)/computer assisted manufacturing (CAM) may also provide information to the CEG. The information is analyzed and represented in the CEG in the form of nodes, edges and properties. The nodes represent the objects and data elements, while the edges connect two or more nodes and represent relationships between the connected nodes. Both nodes and edges may have properties that describe a particular instance in detail. The CEG may be displayed to the engineer at different levels of detail. The following examples will be explained with reference to an engineering design depicted in a view of an engineering tool as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is an example of a screen display of an engineering tool according to aspects of embodiments of the present disclosure. The display <b>210</b> depicts the interface provided to an operator as a human-machine interface (HMI) used to control a manufacturing system. The engineering project developed in the engineering tool also provides control functionality for the automation system. The interface provides display elements that serve to operate control functions <b>207</b> to allow the operator to control the system. The display <b>210</b> may be a touch display allowing the operator to interact directly with the screen elements to perform functions such as starting and stopping the system or selecting automatic or manual operating modes. In other embodiments, interaction with the control elements may occur through input devices, such as a mouse, trackball, trackpad and the like.</p><p id="p-0032" num="0031">Navigation buttons <b>211</b> provide additional functionality to assist in operation of the system. Objects that make up physical components of the automation system may be displayed in a workspace region of the display <b>210</b>. Objects may include an industrial robot <b>201</b>, a conveyor <b>203</b>, a light tower <b>205</b> and an object of manufacture <b>209</b>. Light tower <b>205</b> provides an indication of the current operating status of the system. For example, if the green portion of the light tower is illuminated, it may indicate that the system is currently actively operating. The light tower alerts a user or bystander to the fact that the robot <b>201</b> or the conveyor <b>203</b> may be in motion and present a danger to health and safety. Conveyor <b>203</b> is used to transport the object of manufacture <b>209</b> throughout the plant. For example, conveyor <b>203</b> may transport the object of manufacture <b>209</b> to a workstation &#x201c;manned&#x201d; by industrial robot <b>201</b>. Industrial robot <b>201</b> may then perform manufacturing actions on the object of manufacture <b>209</b>. When the actions of the industrial robot <b>201</b> are complete, conveyor <b>303</b> may transport the object of manufacture <b>209</b> to another workstation for further processing, or if manufacturing is complete, may transport the object of manufacture <b>209</b> for final inspection or shipping.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram of a cognitive engineering graph that is representative of a graph that the cognitive engineering system may generate based on the design project depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Arrows between the nodes define relationships between connected nodes. Information from the engineering tool, provided in this example as TIA portal <b>111</b>, is used to generate the CEG <b>300</b>. The engineering tool <b>111</b> includes a design project <b>200</b> such as the project illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The project <b>200</b> defines an automation application for a robot with a conveyor. The project <b>200</b> comprises components that define functionality for a human machine interface (HMI) <b>310</b>, which provides interaction between the automation system with a human user or operator. The project <b>200</b> also provides functionality for a programmable logic controller (PLC) <b>320</b> for control of the automation system. The PLC <b>320</b> monitors operation of the automation system and provides control of the system through various signals and can generate alerts that guide operation of the components of the system.</p><p id="p-0034" num="0033">The HMI <b>310</b> provides a root screen <b>330</b> that is displayed to the user. Objects displayed on the screen are elements of the root screen <b>330</b>. For example, the robot <b>201</b> display shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, is constructed from geometric shapes <b>331</b> including circles, ellipses, and rectangles. Buttons <b>333</b> for control of the system are also included in the root screen <b>330</b>. The light tower <b>205</b> shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> includes three colored rectangles: a red rectangle <b>335</b><i>a</i>, a yellow rectangle <b>335</b><i>b </i>and a green rectangle <b>335</b><i>c. </i></p><p id="p-0035" num="0034">PLC <b>320</b> provides blocks for monitoring data and providing control to the automation system. There is a first function block (FB) <b>321</b> containing the logic required to control the robot <b>201</b> and a second FB <b>325</b> for controlling the conveyor. Data blocks (DB) <b>325</b>, <b>327</b> store data relating to the robot and the conveyor, respectively. The PLC <b>320</b> uses labels that identify the functions and properties of the components of the automation system. The labels or tags are stored in a tag table <b>340</b>. The tags aid the PLC <b>320</b> in interacting with the display of the HMI <b>310</b> through an organization block (OB) <b>329</b>. Via the OB <b>329</b>, the values of the light tower lights can be controlled and displayed to the user. Using tags <b>345</b><i>a </i>for the red light, <b>345</b><i>b </i>for the yellow light and <b>345</b><i>c </i>for the green light, the OB <b>329</b> sets the value at each tag. For example, the value may be a binary value indicating whether the associated light is illuminated or dim. Using the tags <b>345</b><i>a</i>, <b>345</b><i>b</i>, <b>345</b><i>c</i>, the color of the associated rectangle <b>335</b><i>a</i>, <b>335</b><i>b</i>, <b>335</b><i>c </i>may be set to indicate each lights status. To display the light status to the user, for example, a darker shade may be used to indicate when the light is not illuminated, while a lighter, more vibrant shade of color may be used to indicate a light that is illuminated.</p><p id="p-0036" num="0035">The structure of the CEG is constructed to include knowledge based on historical data from projects that have been previously designed and analyzed by the CEG. The past knowledge obtained by the CEG may be analyzed to discover useful patterns. For example, through logic-based pattern-matching or statistical machine learning, patterns may be identified that identify certain objects or processes that may be of use in the future. When a pattern is identified, either in a supervised or unsupervised manner, it can be applied to new contexts for various purposes including:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0036">validating existing designs by comparing the existing solution with the known pattern; and/or</li>        <li id="ul0002-0002" num="0037">modifying or extending existing designs or creating new designs by applying the pattern for transforming the CEG.</li>    </ul>    </li></ul></p><p id="p-0037" num="0038">An example will now be illustrated where the discovery and use of a light tower such as the light tower <b>205</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is used to explain how the CEG may be employed for cognitive automation engineering. A light tower <b>205</b> is a high-level concept not represented explicitly in the engineering tool <b>111</b>. Nevertheless, the engineer must understand this concept in order to perform corresponding automation engineering tasks. To this purpose, the CEG may be used to represent the high-level concept of the light tower and work with the concept directly. To achieve this, a first step involves the user querying the CES to determine if a light tower is included in the engineering project <b>200</b>. The CES has analyzed multiple engineering projects from the past and stores this in a repository of past knowledge. Accordingly, the CES has learned patterns that identify a light tower. The CES may refer to the pattern attributable to a light tower in a query provided by a user that is structured in a language such as Cypher as follows:</p><p id="p-0038" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="217pt" align="left"/><thead><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>MATCH</entry></row><row><entry>(n:TIA_Portal)-[rProject:Project]-&#x3e;&#x2003;(project),</entry></row><row><entry>&#x2003;(project)-[rPLC:PLC]-&#x3e;(plc),</entry></row><row><entry>&#x2003;(plc)-[rBlock:Block]-&#x3e;(block),</entry></row><row><entry>&#x2003;(plc)-[rTagTable:TagTable]-&#x3e;(tagtable),</entry></row><row><entry>&#x2003;(tagtable)-[rTag:Tag]-&#x3e;(tag{dir:&#x2018;Out&#x2018;}),</entry></row><row><entry>&#x2003;(project)-[rHMI:HMI]-&#x3e;(hmi),</entry></row><row><entry>&#x2003;(hmi)-[rScreen:Screen]-&#x3e;(screen),</entry></row><row><entry>&#x2003;(screen)-[rElement:Element]-&#x3e;(rectangle{type:&#x2018;Rectangle&#x2018;}),</entry></row><row><entry>&#x2003;(tag)-[rChangeColor:ChangeColor]-&#x3e;(rectangle),</entry></row><row><entry>&#x2003;(block)-[rSetValue:SetValue]-&#x3e;(tag)</entry></row><row><entry>RETURN*</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0039" num="0039">It should be noted that other formats or query languages may be used. The CES identifies the pattern associated with the user's request and searches for the light tower pattern in the current CEG to find a match. In this example, a match is found. The elements of this match are shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0040" num="0040"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a pattern <b>400</b> contained in a CEG as identified in the query above. The pattern includes the project <b>200</b> and its implementation of an HMI <b>310</b> and PLC <b>320</b>. In addition, the components that represent the light tower including the labels <b>345</b><i>a</i>, <b>345</b><i>b</i>, <b>345</b><i>c </i>from the organization block <b>329</b> and the rectangles <b>335</b><i>a</i>, <b>335</b><i>b</i>, <b>335</b><i>c </i>that are used in the display screen <b>330</b> of the HMI <b>310</b> are included in the pattern. Any project that contains these elements connecting in a similar manner would be indicative that the project contains a light tower.</p><p id="p-0041" num="0041"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is an illustration of a portion of a CEG that is representative of a light tower object. The CES creates new high-level nodes and edges (denoted by borders having broken lines) for representing the concept of the light tower. The new nodes include a LightTower object <b>501</b> that is associated with a LightTowerView <b>503</b>, LightTowerTags <b>505</b>, and LightTowerLogic <b>507</b>. The LightTowerLogic <b>507</b> is contained in the OB <b>329</b>. LightTowerView <b>503</b> contains red rectangle <b>335</b><i>a</i>, yellow rectangle <b>335</b><i>b </i>and green rectangle <b>335</b><i>c</i>. LightTowerTags <b>505</b> contains the labels for red_light <b>345</b><i>a</i>, yellow_light <b>345</b><i>b </i>and green_light <b>345</b><i>c</i>. These new structures <b>501</b>, <b>503</b>, <b>505</b> and <b>507</b> are created to represent the concept of the light tower in an explicit manner within the CEG. This allows both the user and the CES to conceive the same concepts and communicate effectively about them.</p><p id="p-0042" num="0042">The CES analyzes the CEG and infers properties about the high-level concept of the light tower. These properties are presented to the engineer, and he/she can request the CES to modify them. The CES can determine the steps to carry out these modifications and can also warn the engineer about possible problems that can arise. For the light tower, the CES determines the number and colors of the lights in the light tower as a property: red, yellow and green. This property may be shown to the user in a simplified form as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0043" num="0043"><figref idref="DRAWINGS">FIG. <b>6</b></figref>. is a simplified high-level view <b>600</b> of the conceptual light tower from a CEG that can be displayed to a user. This view only shows the most basic relevant nodes and edges in the CEG that relate to the light tower while hiding all other information. This allows the user to concentrate on the current task of working with the light tower. According to embodiments of this disclosure, the user may work with the concept of the light tower by requesting the CES to add a new blue light to the light tower. This may be accomplished simply by adding a new item &#x201c;blue&#x201d; to the &#x201c;Lights&#x201d; property of the high-level light tower element as shown in <b>701</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0044" num="0044"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is an illustration of an updated CEG generated automatically by the CES according to aspects of embodiments of the present disclosure. The user requests the addition of a blue light to the light tower. The CES having previously analyzed the CEG, includes functionality to implement the new property automatically. The CES proceeds to add a new output signal for the new blue light <b>703</b> adding a new graphical element <b>705</b> to the view of the light tower <b>501</b> and adding control logic to the Main_OB <b>329</b> program block for setting the value of the blue light signal. The names of the new elements are inferred by the CES based on the naming conventions of the existing elements: &#x3c;COLOR&#x3e;_light for the signal (e.g. blue_light <b>703</b>), and &#x3c;COLOR&#x3e;_Rectangle&#x3c;NUM&#x3e; for the graphical element (e.g., BlueRectangle1 <b>705</b>). The CES displays the changes to be performed in the CEG: including the updated property <b>701</b>, new nodes <b>703</b>, <b>705</b>, and new edges for the new relationships containing the new nodes <b>703</b>, <b>705</b>. The user may review the updated CEG and decide if the changes are to be applied. If so, the CES updates the CEG and executes all required engineering steps in the engineering system. The updated CEG is shown to the user (<figref idref="DRAWINGS">FIG. <b>8</b></figref>). For illustrative purposes, the newly created nodes are shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref> as hatched ovals.</p><p id="p-0045" num="0045">The pattern for transforming the CEG to add the new light may alternatively be expressed as a query for the graph database. This time with instructions that match the context where the transformation will occur. The instructions that create new nodes and edges in the graph may be expressed as follows:</p><p id="p-0046" num="0000"><tables id="TABLE-US-00002" num="00002"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="217pt" align="left"/><thead><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>MATCH</entry></row><row><entry>&#x2003;(tia:TIA_Portal)-[rProject:Project]-&#x3e;(project),</entry></row><row><entry>&#x2003;(project)-[rPLC:PLC]-&#x3e;(plc),</entry></row><row><entry>&#x2003;(plc)-[rBlock:Block]-&#x3e;(block),</entry></row><row><entry>&#x2003;(plc)-[rTagTable:TagTable]-&#x3e;(tagtable),</entry></row><row><entry>&#x2003;(tagtable)-[rTag:Tag]-&#x3e;(tag{dir:&#x2018;Out&#x2018;}),</entry></row><row><entry>&#x2003;(project)-[rHMI:HMI]-&#x3e;(hmi),</entry></row><row><entry>&#x2003;(hmi)-[rScreen:Screen]-&#x3e;(screen),</entry></row><row><entry>&#x2003;(pattern:LightTower)-[rLightTowerTags]-&#x3e;(tags:LightTowerTags),</entry></row><row><entry>&#x2003;(pattern:LightTower)-[rLightTowerView]-&#x3e;(tags:LightTowerView),</entry></row><row><entry>&#x2003;(pattern:LightTower)-[rLightTowerLogic]-&#x3e;(tags:LightTowerLogic),</entry></row><row><entry>MERGE(newtag:blue_light{name:&#x2018;blue_light&#x2018;, dir:&#x2018;Out;, kind: &#x2018;created&#x2019;})</entry></row><row><entry>MERGE (newrectangle:BlueRectangle1 {name:&#x2018;BlueRectangle1&#x2018;, type:</entry></row><row><entry>&#x2018;Rectangle&#x2019;, kind: &#x2018;created&#x2019;})</entry></row><row><entry>MERGE (tagtable)-[rTag2:Tag]-&#x3e;(newTag)</entry></row><row><entry>MERGE (screen)-[rElement:Element]-&#x3e;(newretangle)</entry></row><row><entry>MERGE (newtag)-[rChangeColor:ChangeColor]-&#x3e;(newrectangle)</entry></row><row><entry>MERGE (block)-[rSetValue:SetValue]-&#x3e;(newtag)</entry></row><row><entry>MERGE (tags)-[rContains1:Contains]-&#x3e;(newtag)</entry></row><row><entry>MERGE *view)-[rContains2:Contains]-&#x3e;(newrectangle)</entry></row><row><entry>RETURN *</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is an updated portion of a CEG after adding the new blue light to the light tower. The updated light tower elements in the CEG are shown to the user. In this manner, the multiple effects of adding a single light may be easily observed:<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0047">the new output signal has been added to the default tag table <b>703</b>;</li>        <li id="ul0004-0002" num="0048">the new graphical element for the light (BlueRectangle1) <b>705</b> has been added to the root screen;</li>        <li id="ul0004-0003" num="0049">the Main_OB program block <b>329</b> now has code for setting the value of the new output signal <b>703</b>.</li>        <li id="ul0004-0004" num="0050">The output signal is now set to change the color of the blue light in the HMI screen based on its signal value. (The colors in the HMI have been chosen to represent an on/off blue light, now shown in this view of the CEG);</li>    </ul>    </li></ul></p><p id="p-0048" num="0051">Referring now to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, a diagram of an entire CEG after the addition of a new blue light to the light tower is shown according to aspects of embodiments of the present disclosure. After adding the high-level concept structures for the light tower and the new blue light, the entire CEG is shown to the user as illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>. Additional discovery of patterns and high-level modifications may be requested by the engineer. Also, all changes to the CEG are tracked by the CES, and the user can request to undo or modify previous decisions. For example, the user may undo automatic changes made by the CES. The changes to be undone may reside in multiple places throughout the CES. A history of the changes made can be stored, and the user can request that the changes be rolled back to a previous point in time. When changes The CES will then analyze the CEG, identify the necessary changes and apply them accordingly to the CEG and to the engineering tools.</p><p id="p-0049" num="0052">In addition to the general information stored in the CEG regarding the various components of the system, the CES may require additional information in order to make reasoning decisions about the automation problems to be solved by the system being designed. In order to allow comprehensive reasoning regarding the problems faced, the system needs an understanding of the physical world and not just the general terms of the task to be solved. A typical automation program may include input modules for various sensors, output modules for various actuators and if used, one or more drive modules to control electric motors. However, this approach is missing a connection of these modules to the actual physical devices that are the subject of the automation program. Even if these connections were included in some textual form in the comments of the program, this would not provide a reliable source of information. According to some embodiments of the present disclosure, the CEG is developed to accommodate the representation of objects with varying levels of detail.</p><p id="p-0050" num="0053"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram of a CEG that provides varying level of detail for objects represented by the CEG. In a general sense, the CEG may contain nodes that are placeholders for physical objects. For example, a conveyor, an industrial robot or a product of manufacture may be represented by a node that does little more than identify the generic nature of the object. When the graph includes more information relating to these objects, the system can be trained to provide analysis and recommendations at the more precise level of detail. Considering the engineer and the CES have a true understanding of what a &#x201c;conveyor&#x201d; is, they can communicate more effectively about it. To this end, the CEG may be configured to store information including the physical properties of the conveyor (e.g., from a 3D model), the kinematics of the conveyor (e.g., joins, friction), the electrical connections and the connection to the industrial controller (e.g., PLC) along with knowledge of how a typical automation program is structured. Referring now to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, a conveyor <b>1101</b> is represented as a generic concept, a conveyor in general terms is identified by a skill is provides, namely, transport <b>1140</b>. As may be seen in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, a conveyor <b>1101</b> may be further defined to include sub-classes of a conveyor including a belt conveyor <b>1103</b> and a magnetic conveyor <b>1105</b>. The subclass may be defined to contain more specific information pertaining to a belt conveyor as opposed to a magnetic conveyor. For instance, a belt conveyor may be represented as containing parts <b>1107</b> that include a belt <b>1102</b>, a first roller <b>1104</b>, a second roller <b>1106</b> and a motor <b>1109</b>. In addition, if the layer of detail defines the conveyor <b>1101</b> as a belt conveyor <b>1103</b>, without further information, the CEG may be configured to deploy a generic automation program <b>1110</b> that is associated with a belt conveyor. However, the belt conveyor subclass <b>1103</b> may be represented in greater detail by defining a belt conveyor of a given type that is acquired from a given vendor <b>1130</b>. In this case, the CEG may be configured to include a specific automation program <b>1120</b> for the specific conveyor of the given type and vendor <b>1130</b>. Further still, the CEG can be configured to represent one or more instances of a belt conveyor of the given type from the given vendor <b>1131</b>. By allowing for a varying degree of detail when representing objects within the CEG, the system is able to perform more in-depth analysis through machine learning techniques.</p><p id="p-0051" num="0054">The varying detail level of the CEG can be achieved through the following elements:<ul id="ul0005" list-style="none">    <li id="ul0005-0001" num="0000">    <ul id="ul0006" list-style="none">        <li id="ul0006-0001" num="0055">Abstraction and Refinement&#x2014;Each class of object will be available on several layers of abstraction. Depending on the amount of available context information, a more generic/abstract or a more specific/concreate variant of the object will be used. This approach applies not only to physical objects, but for other concepts as well, such as skills. The term skill may be interpreted to mean just a service that some physical object can perform for the user. For example, a conveyor can transport things from point a to point b. Accordingly, a conveyor should have a transport skill. In contrast, a pick-and-place robot may also provide a transport skill but may simultaneously flip an object over by 180 degrees.</li>        <li id="ul0006-0002" num="0056">Classes and Instances&#x2014;If an object is used in a specific project, an instance of the class object will be created in the CEG. The instance may come from a class higher up in the derivation hierarchy and only over time when more information is available, will be the instance of a more and more specific class and eventually represent the concrete physical object in the shop floor.</li>        <li id="ul0006-0003" num="0057">Control and Simulation Behavior&#x2014;Objects in the CEGH have not only an ontological description, but at the same time an executable description of their behavior. In the case where the engineering system which hosts the CEG also has a simulation environment, this behavior could also be executed in simulation mode.</li>    </ul>    </li></ul></p><p id="p-0052" num="0058">Some embodiments may be realized in the form of a graph database and accompanying software interfaces, which implement the knowledge representation functionality of the CEG while adhering to the principles above. While object-oriented databases and programming languages exist, they follow a basic design principle by which all objects are fully defined at their creation meaning that they lack the flexibility of being able to represent objects with increasing level of detail throughout the object's lifecycle.</p><p id="p-0053" num="0059"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a block diagram for representing knowledge in a cognitive engineering system. Information <b>1205</b> is received from an engineering tool <b>1201</b>. The engineering tool <b>1201</b> may receive input from a user <b>1203</b> and additionally generates information in an engineering design project based in part on the user input <b>1203</b>. The information <b>1205</b> from the engineering tool <b>1201</b> may include information relating to physical objects of an automation system, control objects in an automation system, and control programs for operating control objects and other physical objects in the automation system. Any information relating to the automation system, including components contained in the system and information relating to the relationships between two or more components may be included the information <b>1205</b> received from the engineering tool <b>1201</b>.</p><p id="p-0054" num="0060">A historical record of previously designed projects may be stored in the form of a CEG. Multiple instances of previously generated CEGs <b>1209</b> may be stored. A communications link <b>1211</b> between the stored previously CEGs <b>1209</b> and the current CEG <b>1207</b> generated from on the information <b>1205</b>. The information in the current CEG <b>1207</b> and the previously generated CEGs <b>1209</b> are included in the knowledge representation <b>1213</b> of the system. The knowledge representation contains stored knowledge gained from the experience of designers of varying experience and skill levels through the design on the current project and previously designed projects.</p><p id="p-0055" num="0061">Machine learning <b>1215</b> may be applied to the knowledge representation to determine design choices and practices that have been determined to be successful, or conversely, design choices and practices that were determined to be unsuccessful. Machine learning <b>1215</b> may use the knowledge representation <b>1213</b> to make recommendations to a user via engineering tool <b>1201</b>. Additionally, machine learning <b>1215</b> may examine an engineering project in the engineering tool <b>1201</b> and validate <b>1217</b> the design based on prior knowledge contained in the knowledge representation <b>1213</b>.</p><p id="p-0056" num="0062"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates an exemplary computing environment <b>1000</b> within which embodiments of the invention may be implemented. Computers and computing environments, such as computer system <b>1010</b> and computing environment <b>1000</b>, are known to those of skill in the art and thus are described briefly here.</p><p id="p-0057" num="0063">As shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the computer system <b>1010</b> may include a communication mechanism such as a system bus <b>1021</b> or other communication mechanism for communicating information within the computer system <b>1010</b>. The computer system <b>1010</b> further includes one or more processors <b>1020</b> coupled with the system bus <b>1021</b> for processing the information.</p><p id="p-0058" num="0064">The processors <b>1020</b> may include one or more central processing units (CPUs), graphical processing units (GPUs), or any other processor known in the art. More generally, a processor as used herein is a device for executing machine-readable instructions stored on a computer readable medium, for performing tasks and may comprise any one or combination of, hardware and firmware. A processor may also comprise memory storing machine-readable instructions executable for performing tasks. A processor acts upon information by manipulating, analyzing, modifying, converting or transmitting information for use by an executable procedure or an information device, and/or by routing the information to an output device. A processor may use or comprise the capabilities of a computer, controller or microprocessor, for example, and be conditioned using executable instructions to perform special purpose functions not performed by a general-purpose computer. A processor may be coupled (electrically and/or as comprising executable components) with any other processor enabling interaction and/or communication there-between. A user interface processor or generator is a known element comprising electronic circuitry or software or a combination of both for generating display images or portions thereof. A user interface comprises one or more display images enabling user interaction with a processor or other device.</p><p id="p-0059" num="0065">Continuing with reference to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the computer system <b>1010</b> also includes a system memory <b>1030</b> coupled to the system bus <b>1021</b> for storing information and instructions to be executed by processors <b>1020</b>. The system memory <b>1030</b> may include computer readable storage media in the form of volatile and/or nonvolatile memory, such as read only memory (ROM) <b>1031</b> and/or random-access memory (RAM) <b>1032</b>. The RAM <b>1032</b> may include other dynamic storage device(s) (e.g., dynamic RAM, static RAM, and synchronous DRAM). The ROM <b>1031</b> may include other static storage device(s) (e.g., programmable ROM, erasable PROM, and electrically erasable PROM). In addition, the system memory <b>1030</b> may be used for storing temporary variables or other intermediate information during the execution of instructions by the processors <b>1020</b>. A basic input/output system <b>1033</b> (BIOS) containing the basic routines that help to transfer information between elements within computer system <b>1010</b>, such as during start-up, may be stored in the ROM <b>1031</b>. RAM <b>1032</b> may contain data and/or program modules that are immediately accessible to and/or presently being operated on by the processors <b>1020</b>. System memory <b>1030</b> may additionally include, for example, operating system <b>1034</b>, application programs <b>1035</b>, other program modules <b>1036</b> and program data <b>1037</b>.</p><p id="p-0060" num="0066">The computer system <b>1010</b> also includes a disk controller <b>1040</b> coupled to the system bus <b>1021</b> to control one or more storage devices for storing information and instructions, such as a magnetic hard disk <b>1041</b> and a removable media drive <b>1042</b> (e.g., floppy disk drive, compact disc drive, tape drive, and/or solid state drive). Storage devices may be added to the computer system <b>1010</b> using an appropriate device interface (e.g., a small computer system interface (SCSI), integrated device electronics (IDE), Universal Serial Bus (USB), or FireWire).</p><p id="p-0061" num="0067">The computer system <b>1010</b> may also include a display controller <b>1065</b> coupled to the system bus <b>1021</b> to control a display or monitor <b>1066</b>, such as a cathode ray tube (CRT) or liquid crystal display (LCD), for displaying information to a computer user. The computer system includes an input interface <b>1060</b> and one or more input devices, such as a keyboard <b>1062</b> and a pointing device <b>1061</b>, for interacting with a computer user and providing information to the processors <b>1020</b>. The pointing device <b>1061</b>, for example, may be a mouse, a light pen, a trackball, or a pointing stick for communicating direction information and command selections to the processors <b>1020</b> and for controlling cursor movement on the display <b>1066</b>. The display <b>1066</b> may provide a touch screen interface which allows input to supplement or replace the communication of direction information and command selections by the pointing device <b>1061</b>. In some embodiments, an augmented reality device <b>1067</b> that is wearable by a user, may provide input/output functionality allowing a user to interact with both a physical and virtual world. The augmented reality device <b>1067</b> is in communication with the display controller <b>1065</b> and the user input interface <b>1060</b> allowing a user to interact with virtual items generated in the augmented reality device <b>1067</b> by the display controller <b>1065</b>. The user may also provide gestures that are detected by the augmented reality device <b>1067</b> and transmitted to the user input interface <b>1060</b> as input signals.</p><p id="p-0062" num="0068">The computer system <b>1010</b> may perform a portion or all of the processing steps of embodiments of the invention in response to the processors <b>1020</b> executing one or more sequences of one or more instructions contained in a memory, such as the system memory <b>1030</b>. Such instructions may be read into the system memory <b>1030</b> from another computer readable medium, such as a magnetic hard disk <b>1041</b> or a removable media drive <b>1042</b>. The magnetic hard disk <b>1041</b> may contain one or more datastores and data files used by embodiments of the present invention. Datastore contents and data files may be encrypted to improve security. The processors <b>1020</b> may also be employed in a multi-processing arrangement to execute the one or more sequences of instructions contained in system memory <b>1030</b>. In alternative embodiments, hard-wired circuitry may be used in place of or in combination with software instructions. Thus, embodiments are not limited to any specific combination of hardware circuitry and software.</p><p id="p-0063" num="0069">As stated above, the computer system <b>1010</b> may include at least one computer readable medium or memory for holding instructions programmed according to embodiments of the invention and for containing data structures, tables, records, or other data described herein. The term &#x201c;computer readable medium&#x201d; as used herein refers to any medium that participates in providing instructions to the processors <b>1020</b> for execution. A computer readable medium may take many forms including, but not limited to, non-transitory, non-volatile media, volatile media, and transmission media. Non-limiting examples of non-volatile media include optical disks, solid state drives, magnetic disks, and magneto-optical disks, such as magnetic hard disk <b>1041</b> or removable media drive <b>1042</b>. Non-limiting examples of volatile media include dynamic memory, such as system memory <b>1030</b>. Non-limiting examples of transmission media include coaxial cables, copper wire, and fiber optics, including the wires that make up the system bus <b>1021</b>. Transmission media may also take the form of acoustic or light waves, such as those generated during radio wave and infrared data communications.</p><p id="p-0064" num="0070">The computing environment <b>1000</b> may further include the computer system <b>1010</b> operating in a networked environment using logical connections to one or more remote computers, such as remote computing device <b>1080</b>. Remote computing device <b>1080</b> may be a personal computer (laptop or desktop), a mobile device, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to computer system <b>1010</b>. When used in a networking environment, computer system <b>1010</b> may include modem <b>1072</b> for establishing communications over a network <b>1071</b>, such as the Internet. Modem <b>1072</b> may be connected to system bus <b>1021</b> via user network interface <b>1070</b>, or via another appropriate mechanism.</p><p id="p-0065" num="0071">Network <b>1071</b> may be any network or system generally known in the art, including the Internet, an intranet, a local area network (LAN), a wide area network (WAN), a metropolitan area network (MAN), a direct connection or series of connections, a cellular telephone network, or any other network or medium capable of facilitating communication between computer system <b>1010</b> and other computers (e.g., remote computing device <b>1080</b>). The network <b>1071</b> may be wired, wireless or a combination thereof. Wired connections may be implemented using Ethernet, Universal Serial Bus (USB), RJ-6, or any other wired connection generally known in the art. Wireless connections may be implemented using Wi-Fi, WiMAX, and Bluetooth, infrared, cellular networks, satellite or any other wireless connection methodology generally known in the art. Additionally, several networks may work alone or in communication with each other to facilitate communication in the network <b>1071</b>.</p><p id="p-0066" num="0072">An executable application, as used herein, comprises code or machine-readable instructions for conditioning the processor to implement predetermined functions, such as those of an operating system, a context data acquisition system or other information processing system, for example, in response to user command or input. An executable procedure is a segment of code or machine-readable instruction, sub-routine, or other distinct section of code or portion of an executable application for performing one or more particular processes. These processes may include receiving input data and/or parameters, performing operations on received input data and/or performing functions in response to received input parameters, and providing resulting output data and/or parameters.</p><p id="p-0067" num="0073">A graphical user interface (GUI), as used herein, comprises one or more display images, generated by a display processor and enabling user interaction with a processor or other device and associated data acquisition and processing functions. The GUI also includes an executable procedure or executable application. The executable procedure or executable application conditions the display processor to generate signals representing the GUI display images. These signals are supplied to a display device which displays the image for viewing by the user. The processor, under control of an executable procedure or executable application, manipulates the GUI display images in response to signals received from the input devices. In this way, the user may interact with the display image using the input devices, enabling user interaction with the processor or other device.</p><p id="p-0068" num="0074">The functions and process steps herein may be performed automatically or wholly or partially in response to user command. An activity (including a step) performed automatically is performed in response to one or more executable instructions or device operation without user direct initiation of the activity.</p><p id="p-0069" num="0075">The system and processes of the figures are not exclusive. Other systems, processes and menus may be derived in accordance with the principles of the invention to accomplish the same objectives. Although this invention has been described with reference to particular embodiments, it is to be understood that the embodiments and variations shown and described herein are for illustration purposes only. Modifications to the current design may be implemented by those skilled in the art, without departing from the scope of the invention. As described herein, the various systems, subsystems, agents, managers and processes can be implemented using hardware components, software components, and/or combinations thereof.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for representing knowledge in a cognitive engineering system (CES) comprising:<claim-text>receiving information relating to an automation engineering project from an engineering tool;</claim-text><claim-text>storing the received information in a cognitive engineering graph (CEG) comprising a plurality of nodes representative of an element of the automation engineering project and at least on edge connecting two of the nodes, the at least one edge representative of a relationship between the connected nodes; and</claim-text><claim-text>storing a plurality of previously generated CEGs representative of other prior automation engineering projects; and</claim-text><claim-text>establishing a communication path between the CEG storing the received information and the plurality of previously generated CEGs.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>applying machine learning to the stored CEG based on the received information and the stored plurality of previously generated CEGs.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>analyzing the CEG based on the received information to identify at least one pattern that is representative of a given object of interest from the automation engineering project.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>automatically by the CES, adding an element to the CEG based on the received information and on a query from a user.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising:<claim-text>performing an undo action by the CES at a request of a user that removes the element that was automatically added to the CEG.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the CEG from the received information includes nodes that represent physical objects in the automation engineering project.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the CEG from the received information includes nodes that represent an automation program for controlling a corresponding physical object in the automation engineering project.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the CEG from the received information includes at least one node that represents a human machine interface (HMI).</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the CEG from the received information includes at least one node that represents a programmable logic controller (PLC).</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>comparing the CEG based on the received information and the stored plurality of previously generated CEGs; and</claim-text><claim-text>validating a design for the automation engineering project based on the comparison.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>comparing the CEG based on the received information and the stored plurality of previously generated CEGs; and</claim-text><claim-text>determining a proposed course of action for the user to perform in the automation engineering project based on the comparison; and</claim-text><claim-text>communicating the propose course of action to the user.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A system for providing a knowledge representation in a cognitive engineering system (CES) comprising:<claim-text>a computer-based engineering tool for providing at least one of designing, programming simulation and testing of an automation system;</claim-text><claim-text>a cognitive system in communication with the computer-based engineering tool comprising:<claim-text>a knowledge extraction module for identifying and storing information contained in a project of the computer-based engineering tool and from data received from a physical automation system;</claim-text><claim-text>a machine learning module for analyzing knowledge extracted by the knowledge extraction module and identifying characteristics of the automation system;</claim-text><claim-text>an inductive programming module of automatically generating control programs for the automation system based on the stored information from the knowledge extraction module; and</claim-text><claim-text>a knowledge representation comprising a cognitive engineering graph (CEG), the CEG comprising a plurality of nodes representative of an element of the automation engineering project and at least on edge connecting two of the nodes, the at least one edge representative of a relationship between the connected nodes.</claim-text></claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref> further comprising:<claim-text>a computer memory storing a plurality of CEGs from previously designed projects in communication with the machine learning module for analyzing past knowledge.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref> further comprising:<claim-text>a feedback module for providing information from the cognitive system to a user.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the feedback module is configured to provide the user with a design recommendation for the automation engineering project based on an output from the machine learning module.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising:<claim-text>a communication channel between a physical automation system and the knowledge extraction module for extracting operations data from the automation system for analysis by the cognitive system.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising an automated reasoning module in communication with the knowledge representation and the machine learning module, the automated reasoning module configured to automatically add a component to the automation engineering project based on the knowledge representation and the machine learning module.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, the CEG comprising:<claim-text>at least one node representative of a physical element of an automation system.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, the CEG comprising:<claim-text>at least one node representative of a human machine interface (HMI) for an automation system.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, the CEG comprising:<claim-text>at least one node representative of a programmable logic controller (PLC) for an automation system.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005327A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005327</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17945165</doc-number><date>20220915</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>07</class><subclass>F</subclass><main-group>17</main-group><subgroup>32</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>07</class><subclass>F</subclass><main-group>17</main-group><subgroup>3227</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>07</class><subclass>F</subclass><main-group>17</main-group><subgroup>3223</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>07</class><subclass>F</subclass><main-group>17</main-group><subgroup>322</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">GAMING  ENVIRONMENT TRACKING SYSTEM CALIBRATION</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17319904</doc-number><date>20210513</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11495085</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17945165</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>63050944</doc-number><date>20200713</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>SG Gaming, Inc.</orgname><address><city>Las Vegas</city><state>NV</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>LYONS</last-name><first-name>Martin S.</first-name><address><city>Henderson</city><state>NV</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>KELLY</last-name><first-name>Bryan</first-name><address><city>Rancho Santa Margarita</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method and apparatus to automatically modify one or more presentation attributes of a gaming system. For instance, the gaming system detects, via analysis of an image data by a neural network model, an appearance of one or more features of a gaming surface. The gaming system further automatically modifies, via the neural network model in response to detecting the appearance of the one or more features, a presentation attribute associated with presentation of gaming content via a designated area of the gaming surface. The gaming system further projects, via a projection system based on the modified presentation attribute, the gaming content onto the designated area of the gaming surface.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="118.19mm" wi="141.65mm" file="US20230005327A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="241.22mm" wi="171.11mm" file="US20230005327A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="215.82mm" wi="154.52mm" file="US20230005327A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="233.68mm" wi="153.16mm" file="US20230005327A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="240.54mm" wi="175.94mm" file="US20230005327A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="244.69mm" wi="152.57mm" file="US20230005327A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="240.37mm" wi="173.48mm" file="US20230005327A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="222.76mm" wi="173.74mm" file="US20230005327A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="224.28mm" wi="154.52mm" file="US20230005327A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="238.00mm" wi="163.49mm" file="US20230005327A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="198.12mm" wi="143.68mm" file="US20230005327A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="224.03mm" wi="135.72mm" file="US20230005327A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="186.01mm" wi="155.19mm" file="US20230005327A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="195.66mm" wi="150.71mm" file="US20230005327A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="228.77mm" wi="146.56mm" file="US20230005327A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="235.12mm" wi="155.28mm" file="US20230005327A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="207.43mm" wi="144.86mm" file="US20230005327A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="195.92mm" wi="153.92mm" file="US20230005327A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 17/319,904, filed May 13, 2021, which claims the priority benefit of U.S. Provisional Patent Application No. 63/050,944 filed Jul. 13, 2020, which Ser. No. 17/319,904 application and 63/050,944 application are each incorporated by reference herein in their respective entireties.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">COPYRIGHT</heading><p id="p-0003" num="0002">A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent disclosure, as it appears in the Patent and Trademark Office patent files or records, but otherwise reserves all copyright rights whatsoever. Copyright 2022 SG Gaming, Inc.</p><heading id="h-0003" level="1">FIELD OF THE INVENTION</heading><p id="p-0004" num="0003">The present invention relates generally to gaming systems, apparatus, and methods and, more particularly, to image analysis and tracking of physical objects in a gaming environment.</p><heading id="h-0004" level="1">BACKGROUND</heading><p id="p-0005" num="0004">Casino gaming environments are dynamic environments in which people, such as players, casino patrons, casino staff, etc., take actions that affect the state of the gaming environment, the state of players, etc. For example, a player may use one or more physical tokens to place wagers on the wagering game. A player may perform hand gestures to perform gaming actions and/or to communicate instructions during a game, such as making gestures to hit, stand, fold, etc. Further, a player may move physical cards, dice, gaming props, etc. A multitude of other actions and events may occur at any given time. To effectively manage such a dynamic environment, the casino operators may employ one or more tracking systems or techniques to monitor aspects of the casino gaming environment, such as credit balance, player account information, player movements, game play events, and the like. The tracking systems may generate a historical record of these monitored aspects to enable the casino operators to facilitate, for example, a secure gaming environment, enhanced game features, and/or enhanced player features (e.g., rewards and benefits to known players with a player account).</p><p id="p-0006" num="0005">Some gaming systems can perform object tracking in a gaming environment. For example, a gaming system with a camera can capture an image feed of a gaming area to identify certain physical objects or to detect certain activities such as betting actions, payouts, player actions, etc.</p><p id="p-0007" num="0006">Some gaming systems also incorporate projectors. For example, a gaming system with a camera and a projector can use the camera to capture images of a gaming area to electronically analyze to detect objects/activities in the gaming area. The gaming system can further use the projector to project related content into the gaming area. A gaming system that can perform object tracking and related projections of content can provide many benefits, such as better customer service, greater security, improved game features, faster game play, and so forth.</p><p id="p-0008" num="0007">However, one challenge to such a gaming system is coordinating the complexity of the system elements. For example, a camera may take a picture of a gaming table from one perspective (i.e., from the perspective of the camera lens) while a projector projects images from a different perspective (i.e., from the perspective of the projector lens). Neither of those perspectives can be aligned with each other perfectly because the camera and projector are separate devices. To add to the complexity, the camera and projector may need to be positioned in a way that is not directly facing the surface of the gaming table. Thus, the camera perspective and the projector perspective are not orthogonal to the plane of the surface, and thus are unaligned with the projection surface. To further add to this challenge, sometimes, in a busy gaming environment, casino patrons, casino staff, or others may move a camera or a projector (whether purposefully or accidentally), thus altering relative perspectives. If the camera and projector are used for tracking gaming activities at a gaming table, the camera and projector would need to be reconfigured to each other be able to return to precise and reliable service.</p><p id="p-0009" num="0008">Accordingly, a new tracking system that is adaptable to the challenges of dynamic casino gaming environments is desired.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0010" num="0009">According to one aspect of the present disclosure, a gaming system is provided for automatically modifying one or more presentation attributes of a gaming system. For instance, the gaming system detects, via analysis of an image data by a neural network model, an appearance of one or more features of a gaming surface. The gaming system further automatically modifies, via the neural network model in response to detecting the appearance of the one or more features, a presentation attribute associated with presentation of gaming content via a designated area of the gaming surface. The gaming system further projects, via a projection system based on the modified presentation attribute, the gaming content onto the designated area of the gaming surface.</p><p id="p-0011" num="0010">Additional aspects of the invention will be apparent to those of ordinary skill in the art in view of the detailed description of various embodiments, which is made with reference to the drawings, a brief description of which is provided below.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram of an example gaming system according to one or more embodiments of the present disclosure.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram of an exemplary gaming system according to one or more embodiments of the present disclosure.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow diagram of an example method according to one or more embodiments of the present disclosure.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIGS. <b>4</b>, <b>5</b>A, <b>5</b>B, <b>5</b>C, <b>6</b>, <b>7</b>, <b>8</b>A, <b>8</b>B, <b>9</b>A and <b>9</b>B</figref> are diagrams of an exemplary gaming system associated with the data flow shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> according to one or more embodiments of the present disclosure.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a perspective view of a gaming table configured for implementation of embodiments of wagering games in accordance with this disclosure.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a perspective view of an individual electronic gaming device configured for implementation of embodiments of wagering games in accordance with this disclosure.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a top view of a table configured for implementation of embodiments of wagering games in accordance with this disclosure.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a perspective view of another embodiment of a table configured for implementation of embodiments of wagering games in accordance with this disclosure, wherein the implementation includes a virtual dealer.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a schematic block diagram of a gaming system for implementing embodiments of wagering games in accordance with this disclosure.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a schematic block diagram of a gaming system for implementing embodiments of wagering games including a live dealer feed.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a block diagram of a computer for acting as a gaming system for implementing embodiments of wagering games in accordance with this disclosure.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>17</b></figref> illustrates an embodiment of data flows between various applications/services for supporting the game, feature or utility of the present disclosure for mobile/interactive gaming.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0024" num="0023">While the invention is susceptible to various modifications and alternative forms, specific embodiments have been shown by way of example in the drawings and will be described in detail herein. It should be understood, however, that the invention is not intended to be limited to the particular forms disclosed. Rather, the invention is to cover all modifications, equivalents, and alternatives falling within the spirit and scope of the invention as defined by the appended claims.</p><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0025" num="0024">While this invention is susceptible of embodiment in many different forms, there is shown in the drawings, and will herein be described in detail, preferred embodiments of the invention with the understanding that the present disclosure is to be considered as an exemplification of the principles of the invention and is not intended to limit the broad aspect of the invention to the embodiments illustrated. For purposes of the present detailed description, the singular includes the plural and vice versa (unless specifically disclaimed); the words &#x201c;and&#x201d; and &#x201c;or&#x201d; shall be both conjunctive and disjunctive; the word &#x201c;all&#x201d; means &#x201c;any and all&#x201d;; the word &#x201c;any&#x201d; means &#x201c;any and all&#x201d;; and the word &#x201c;including&#x201d; means &#x201c;including without limitation.&#x201d;</p><p id="p-0026" num="0025">For purposes of the present detailed description, the terms &#x201c;wagering game,&#x201d; &#x201c;casino wagering game,&#x201d; &#x201c;gambling,&#x201d; &#x201c;slot game,&#x201d; &#x201c;casino game,&#x201d; and the like include games in which a player places at risk a sum of money or other representation of value, whether or not redeemable for cash, on an event with an uncertain outcome, including without limitation those having some element of skill. In some embodiments, the wagering game involves wagers of real money, as found with typical land-based or online casino games. In other embodiments, the wagering game additionally, or alternatively, involves wagers of non-cash values, such as virtual currency, and therefore may be considered a social or casual game, such as would be typically available on a social networking web site, other web sites, across computer networks, or applications on mobile devices (e.g., phones, tablets, etc.). When provided in a social or casual game format, the wagering game may closely resemble a traditional casino game, or it may take another form that more closely resembles other types of social/casual games.</p><p id="p-0027" num="0026">Some embodiments described herein facilitate electronically detecting one or more objects within a gaming area, such as objects on a surface of a gaming table, and calibrating an attribute of the system accordingly. In some instances, a gaming system may capture image data of a gaming table and an associated environment around the gaming table, including an image of a surface of the gaming table. The gaming system can further analyze the captured image data (e.g., using one or more imaging neural networks models and/or other imaging analysis tools) to identify one or more locations in the captured image data that depict one or more specific points of interest related to physical objects (e.g., marker(s)). The systems and methods can further associate the one or more locations with identifier value(s), which can be used as a reference to automatically calibrate any attributes of the system associated with performance of one or more gaming features. The one or more gaming features may include, but are not limited to, a gaming mode, a gaming operation, a gaming function, gaming content selection, gaming content placement/orientation, gaming animation, sensor/camera settings, projector settings, virtual scene aspects, etc. In some instances, the gaming system can project, at the gaming table surface, one or more markers, such as a board or grid of markers, and can determine the identifier value(s) based on electronic analysis of one or more images of the markers (e.g., via transformation(s) between camera perspective and virtual scene perspective, via incremental image property modification, etc.). In some instances, the gaming system can analyze the image(s) by decoding information (e.g., symbols, codes, etc.) presented on a marker. In some examples, the identifier value(s) are stored in memory as coordinate locations in relation to locations in a grid structure. In some examples, the gaming system automatically calibrates the system attribute(s) based on the identifier values. For instance, in some embodiments, the gaming system calibrates the presentation (e.g., placement, orientation, etc.) of gaming content, such as by generating a virtual mesh using detected center points of the markers for polygonal triangulation, and orienting placement of content in a virtual scene relative to the detected center points. Furthermore, in some instances the gaming system can deduce, based on the electronic analysis, a perceived function, purpose, location, appearance, orientation, etc. of the marker and, based on the deduction, calibrate an aspect of the gaming system.</p><p id="p-0028" num="0027">A self-referential gaming table system for automatic calibration (as disclosed herein) is a significant advancement in gaming technology. It resolves many of the challenges of a gaming system by coordinating the complexity of the perspectives and interactivity of a camera, a projector, and a dynamic gaming environment. It permits a camera and/or a projector to be positioned in a way that is not directly facing the surface of a gaming table (e.g., positioned non-orthogonally to a plane of the surface), yet have content be aligned (e.g., orthogonally) to the projection surface. Proper alignment of gaming content ensures that projections of gaming animations clearly indicate a gaming outcome, thus reducing the chance of any disputes between patrons and casino operators regarding the outcome. Furthermore, the gaming system can calibrate itself rapidly and reliably, for instance, if the camera and/or a projector is moved or if a gaming table surface is changed (e.g., if a surface covering is replaced due to wear, if surface objects are rearranged for different game purposes, etc.). Fast and accurate self-calibration permits a gaming table to function precisely and stay in service more reliably, without the need for highly trained technicians.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram of an example gaming system <b>100</b> according to one or more embodiments of the present disclosure. The gaming system <b>100</b> includes a gaming table <b>101</b>, a camera <b>102</b> and a projector <b>103</b>. The camera <b>102</b> captures a stream of images of a gaming area, such as an area encompassing a top surface <b>104</b> of the gaming table <b>101</b>. The stream comprises a frame of image data (e.g., image <b>120</b>). The projector <b>103</b> is configured to project images of gaming content. The projector <b>103</b> projects the images of the gaming content toward the surface <b>104</b> relative to objects in the gaming area. The camera <b>102</b> is positioned above the surface <b>104</b> and to the left of a first player area <b>105</b>. The camera <b>102</b> has a first perspective (e.g., field of view or angle of view) of the gaming area. The first perspective may be referred to in this disclosure more succinctly as a camera perspective or viewing perspective. For example, the camera <b>102</b> has a lens that is pointed at the gaming table <b>101</b> in a way that views portions of the surface <b>104</b> relevant to game play and that views game participants (e.g., players, dealer, back-betting patrons, etc.) positioned around the gaming table <b>101</b>. The projector <b>103</b> is also positioned above the gaming table <b>101</b>, and also to the left of the first player area <b>105</b>. The projector <b>103</b> has a second perspective (e.g., projection direction, projection angle, projection view, or projection cone) of the gaming area. The second perspective may be referred to in this disclosure more succinctly as a projection perspective. For example, the projector <b>103</b> has a lens that is pointed at the gaming table <b>101</b> in a way that projects (or throws) images of gaming content onto substantially similar portions of the gaming area that the camera <b>102</b> views. Because the lenses for the camera <b>102</b> and the projector <b>103</b> are not in the same location, the camera perspective is different from the projection perspective. The gaming system <b>100</b>, however, is a self-referential gaming table system that adjusts for the difference in perspectives. For instance, the gaming system <b>100</b> is configured to detect, in response to electronic analysis of the image <b>120</b>, one or more points of interest that are substantially planar with the surface of a gaming table <b>101</b>. The gaming system <b>100</b> can further automatically transform locations values for the detected point(s) from the camera perspective to the projection perspective, and vice versa, such that they substantially, and accurately, correspond to each other. Furthermore, the gaming system <b>100</b> can, based on the transforming, automatically calibrate one or more attributes of the gaming table <b>101</b>, the camera <b>102</b>, the projector <b>103</b>, or any other aspect of the gaming system <b>100</b>. For instance, the gaming system can automatically calibrate gaming modes, game operations, gaming functions, game-related features, gaming content placement/orientation, sensor/camera settings, projector settings, virtual scene aspects, etc. As an example, gaming system <b>100</b> can associate a set of points of interest with one or more locations for a target area for observation by the neural network model of one or more events related to a game aspect. In some instances, the gaming system <b>100</b> associates the location with a target area for projection of wagering game content related to the game aspect (e.g., related to a game mode). For example, in some embodiments, the gaming system <b>100</b> automatically associates one or more locations of the one or more objects in the image with one or more identifier values associated with a point of interest on the surface <b>104</b>. In some instances, the object <b>130</b> has visibly detectable information, such as a visible code associated with a unique identifier value. In some examples, the gaming system <b>100</b> determines an identifier <b>171</b> related to the object <b>130</b> (e.g., coordinate values related to a grid structure for the object <b>130</b>, a key linking the object <b>130</b> to content <b>173</b> via a database <b>170</b>, etc.). The gaming system <b>100</b> can use the identifier value to configure a gaming aspect associated with the point of interest. For instance, the gaming system <b>100</b> can use the identifier value to orient, size, and position the content <b>173</b> relative to a location and/or orientation of the object <b>130</b> on the gaming table <b>101</b> (e.g. configure a position and/or orientation of wagering game content for a game mode associated with the point of interest).</p><p id="p-0030" num="0029">In some embodiments, the gaming system <b>100</b> automatically detects physical objects as points of interest based on electronic analysis of the image <b>120</b>, such as via feature set extraction, object classification, etc. performed by a neural network model (e.g., via tracking controller <b>204</b>). For example, the gaming system <b>100</b> can detect one or more points of interest by detecting, via a neural network model, physical features of the image <b>120</b> that appear to be co-planar with the surface <b>104</b>. For example, the gaming system <b>100</b> includes a tracking controller <b>204</b> (described in more detail in <figref idref="DRAWINGS">FIG. <b>2</b></figref>). The tracking controller <b>204</b> is configured to monitor the gaming area (e.g., physical objects within the gaming area), and determine a relationship between one or more of the objects. The tracking controller <b>204</b> can further receive and analyze collected sensor data (e.g., receives and analyzes the captured image data from the camera <b>102</b>) to detect and monitor physical objects. The tracking controller <b>204</b> can establish data structures relating to various physical objects detected in the image data. For example, the tracking controller <b>204</b> can apply one or more image neural network models during image analysis that are trained to detect aspects of physical objects. In at least some embodiments, each model applied by the tracking controller <b>204</b> may be configured to identify a particular aspect of the image data and provide different outputs for any physical objected identified such that the tracking controller <b>204</b> may aggregate the outputs of the neural network models together to identify physical objects as described herein. The tracking controller <b>204</b> may generate data objects for each physical object identified within the captured image data. The data objects may include identifiers that uniquely identify the physical objects such that the data stored within the data objects is tied to the physical objects. The tracking controller <b>204</b> can further store data in a database, such as database system <b>208</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, or, as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in database <b>170</b>.</p><p id="p-0031" num="0030">In some embodiments, the gaming system <b>100</b> automatically detects an automorphing relationship (e.g., a homography or isomorphism relationship) between observed points of interest to transform between projection spaces and linear spaces. For instance, the gaming system <b>100</b> can detect points of interest that are physically on the surface <b>104</b> and deduce a spatial relationship between the points of interest. For instance, the gaming system <b>100</b>, can detect one or more physical objects resting, printed, or otherwise physically positioned on the surface <b>104</b>, such as objects placed at specific locations on the surface <b>104</b> in a certain pattern, or for a specific purpose. In some instances, the tracking controller <b>204</b> determines, via electronic analysis, features of the objects, such as their shapes, visual patterns, sizes, relative locations, numbers, displayed identifiers, etc. In some instances, the gaming system <b>100</b> can detect at least three points of interest, substantially planar with the surface <b>104</b>, which have a known homography relationship (e.g., a triangle, a parallelogram, etc.). Thus, the gaming system <b>100</b> can use an isomorphic or homography transformation on the detected objects, such as a linear transformation, an affine transformation, a projection transformation, a barycentric transformation, etc.</p><p id="p-0032" num="0031">In some embodiments, the gaming system <b>100</b> deduces a relationship (e.g., a spatial relationship) for a plurality of objects (e.g., representing a plurality of related points) on the surface of the gaming table based on classifications of detected objects (particularly, objects or features for automorphism opportunities, such as objects that, by their determined features., are objects that have rigid transformation relationships, affine transformation relationships, or projective transformation relationships). For instance, the gaming system <b>100</b> can detect a unique configuration of objects on the surface <b>104</b>, such as a logo for a manufacturer of a gaming table, a number of printed bet spots on a fabric that covers a gaming table, dimensions of a chip tray <b>113</b>, etc. For example, the gaming system <b>100</b> may detect, within the captured image, a logo (not shown) that identifies Scientific Games Inc. as the game manufacturer of the gaming table <b>101</b> or of the covering for the surface <b>104</b>. The gaming system <b>100</b> may further identify a set of ellipses in the captured image and deduce that they are betting circles. For instance, as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, there are twelve bet spots with betting circles (e.g., main betting circles <b>105</b>A, <b>106</b>A, <b>107</b>A, <b>108</b>A, <b>109</b>A, and <b>110</b>A (&#x201c;<b>105</b>A-<b>110</b>A&#x201d;) and secondary betting circles <b>105</b>B, <b>106</b>B, <b>107</b>B, <b>108</b>B, <b>109</b>B, and <b>110</b>B (&#x201c;<b>105</b>B-<b>110</b>B&#x201d;)). Based on that information, the gaming system may look up a library of gaming table layouts of a detected manufacturer and obtain, in response to detecting the configuration, a template that has precise distances and positions of printed features on a gaming surface fabric, such as a fabric that has the given number of detected bet spots arranged in an arc shape. Thus the positions and orientations of the printed objects have a known relationship in a geometric plane (i.e., of the surface <b>104</b>) that occurs when the fabric is placed and affixed to the top of the gaming table (such as when a gaming fabric top is placed or replaced within the casino (e.g., for initial setup, when it becomes soiled or damaged, etc.)). Thus, the gaming system <b>100</b> detects and identifies the printed features and uses them as identifiers due to their shape and pattern which relates to a known relationship in spatial dimensions and in purpose (e.g., different bet circles represent different points of interest on the plane of the gaming surface, each with a different label and function during the wagering game).</p><p id="p-0033" num="0032">As mentioned, one example of objects associated with points of interest include printed betting circles (e.g., main betting circles <b>105</b>A, <b>106</b>A, <b>107</b>A, <b>108</b>A, <b>109</b>A, and <b>110</b>A (&#x201c;<b>105</b>A-<b>110</b>A&#x201d;) and secondary betting circles <b>105</b>B, <b>106</b>B, <b>107</b>B, <b>108</b>B, <b>109</b>B, and <b>110</b>B (&#x201c;<b>105</b>B-<b>110</b>B&#x201d;). The printed betting circles are related to six different player areas <b>105</b>, <b>106</b>, <b>107</b>, <b>108</b>, <b>109</b>, and <b>110</b> are arranged symmetrically around a dealer area <b>111</b>. For example, main betting circle <b>105</b>A and secondary betting circle <b>105</b>B are associated with the first player area <b>105</b> at a far left end of a rounded table edge <b>112</b>; main betting circle <b>106</b>A and <b>106</b>B are associated with the second player area <b>106</b> situated to the right of the first player area <b>105</b>; and so forth for additional player areas <b>107</b>-<b>110</b> around the gaming table <b>101</b> until reaching an opposing far right end of the rounded table edge <b>112</b> (i.e., main betting circle <b>107</b>A and secondary betting circle <b>107</b>B are associated with the third player area <b>107</b>, main betting circle <b>108</b>A and secondary betting circle <b>108</b>B are associated with the fourth player area <b>108</b>, main betting circle <b>109</b>A and secondary betting circle <b>109</b>B are associated with the fifth player area <b>109</b>, and main betting circle <b>110</b>A and secondary betting circle <b>110</b>B are associated with the sixth player area <b>110</b>). In some instances, the gaming system <b>100</b> detects, or in some instances estimates, a centroid for any of detected objects/points of interest (e.g., the gaming system <b>100</b> can estimate centroids for the chip tray <b>113</b> and/or for the betting circles <b>105</b>A<b>0</b>-<b>11</b>A and <b>105</b>B-<b>110</b>B). In some instances, the gaming system <b>100</b> can detect, or estimate, the centroid of each of the ellipses in the image <b>120</b> by binarizing the digitalized image of the ellipse (e.g. converting the pixels of the image of the ellipse from an 8-bit grayscale image to a 1-bit black and white image) and determining the centroid by using a weighted average of image pixel intensities. The gaming system <b>100</b> can use the centroids of the ellipses as references points.</p><p id="p-0034" num="0033">In some instances, the gaming system <b>100</b> can automatically detect, as points of interest, native topological features of the surface <b>104</b>. For instance, the gaming system <b>100</b> can detect one or more points of interest associated with the chip tray <b>113</b> positioned at the dealer area <b>111</b>. The chip tray <b>113</b> can hold gaming tokens, such as gaming chips, tiles, etc., which a dealer can use to exchange a player's money for physical gaming tokens. Some objects may be included at the gaming table <b>101</b>, such as gaming tokens, cards, a card shoe, dice, etc. but are not shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> for simplicity of description. An additional area <b>114</b> is available for presenting (e.g., projecting) gaming content relevant to some elements of a wagering game that are common, or related, to any or all participants. In some instances, the gaming system <b>100</b> utilizes any additional identified features (e.g., a center of the chip tray <b>113</b>), gathering as much information as possible to deduce a proper layout relationship for the content.</p><p id="p-0035" num="0034">In one example, the gaming system <b>100</b> detects the chip tray <b>113</b> based on its visible features (e.g., its rectangular shape, its parallel lines of evenly spaced slats <b>116</b>, its position relative to the shape of the table <b>101</b>, etc.). For example, the gaming system <b>100</b> detects a first upper corner point <b>151</b> and a second upper corner point <b>153</b> of the chip tray <b>113</b>. The gaming system <b>100</b> also determines a center point <b>152</b> on a line <b>161</b> that follows an upper edge <b>115</b> of the chip tray <b>113</b>. The gaming system <b>100</b> can determine the center point <b>152</b> by detecting the number of slats <b>116</b> within the chip tray <b>113</b> (e.g., the chip tray <b>113</b> has ten evenly spaced slats <b>116</b>), detecting a center divider <b>117</b> for a central slat, and detecting a top point of the center divider that connects with the upper edge <b>115</b> (i.e., the center point <b>152</b>). The gaming system <b>100</b> can utilize the center point <b>152</b> (as well as the orientation of the center divider <b>117</b>) as a references to construct a center dividing line <b>164</b> (also referred to herein as an axis of symmetry for a layout of the surface <b>104</b> of the gaming table <b>101</b>). Furthermore, the gaming system <b>100</b> detects the features of the betting circles <b>105</b>A-<b>110</b>A and <b>105</b>B-<b>110</b>B. For instance, the gaming system <b>100</b> detects a number of ellipses that appear in the image <b>120</b> as the betting circles <b>105</b>A-<b>110</b>A and <b>105</b>B-<b>110</b>B. The gaming system <b>100</b> can also detect the ellipses relative sizes, their arrangement relative to the chip tray <b>113</b>, their locations relative to each other, etc. The gaming system <b>100</b> can thus deduce that the center dividing line <b>164</b> is an axis of symmetry for a layout of the table, and that each of the ellipses seen are actually circles having equivalent sizes to each other. In some instances, the gaming system <b>100</b> is configured to determine, based on the electronic analysis, that a homography relationship exists between two circles on the same geometric plane. More specifically, a line <b>162</b> can be determined between two intersecting perimeter points of the ellipses, such as the point <b>154</b> on the perimeter of the betting circle <b>105</b>A and point <b>155</b> on the perimeter of the betting circle <b>110</b>A. Because of the nature of the homography relationship, and the detected orientation of the betting circles <b>105</b>A and <b>110</b>A relative to the chip tray <b>113</b>, the gaming system <b>100</b> determines that the line <b>162</b> is parallel to the line <b>161</b>. Furthermore, the gaming system <b>100</b> can access information about the required presentation parameters for the content <b>173</b>. For instance, the gaming system <b>100</b> accesses layout information about the content <b>173</b> stored in the database <b>170</b> and determines that a centroid of the content <b>173</b> is supposed to be anchored in section <b>114</b> half-way between the betting circle <b>105</b>A and betting circle <b>110</b>A. Therefore, using all of the acquired information (including the detected homography relationships), the gaming system <b>100</b> determines that an intersection of the center dividing line <b>164</b> and the line <b>162</b> is an anchor point for the centroid of the content <b>173</b>. In some instances, the gaming system <b>100</b> can further position the object <b>130</b> (e.g., automatically move it) until it is aligned with the intersection. The gaming system <b>100</b> can store the location values and orientation values of the object <b>130</b> as calibration values, thus ensuring automatic positioning and orientation of the content <b>173</b> when projected into the area <b>114</b> during game play.</p><p id="p-0036" num="0035">As mentioned, in some instances, the gaming system <b>100</b> can automatically detect one or more points of interest that are projected onto the surface <b>104</b> by the projector <b>103</b>. In one example, the gaming system <b>100</b> can automatically triangulate a projection space based on known spatial relationships of points of interest on the surface <b>104</b>. For example, in some embodiments, the gaming system <b>100</b> utilizes polygon triangulation of the detected points of interest to generate a virtual mesh associated with a virtual scene modeled to the projection perspective. More specifically, the gaming system <b>100</b> can project images of a set of one or more specific objects or markers (as points of interest) onto the surface <b>104</b> and use the marker(s) for self-reference and auto-calibration. For example, the gaming system <b>100</b> may project the object <b>130</b> at the surface <b>104</b>. The object <b>130</b> has an appearance that is uniquely identifiable when analyzed, electronically, from any viewing angle. Throwing a projected image of the object <b>130</b> into the gaming area will cause the object <b>130</b> to naturally appear on the surface <b>104</b> because the photons of light for the projected object <b>103</b> only become visible (thus detectable by gaming system <b>100</b>), when they appear on the reflective material of the surface <b>104</b>. As such, the surface <b>104</b> should be covered with a material that adequately reflects the light that is projected at its surface by the projector <b>103</b>. Thus, in some instances, the gaming system <b>100</b> determines that projected objects are planar with the surface of the gaming table <b>103</b> when it identifies, via the neural network model, the features of the projected objects with sufficient confidence that it is a projected object used for calibration. In some instances, the object <b>130</b> has an isomorphic shape, or in other words, the shape of the object <b>130</b> can be isomorphically transformed (e.g., via a homography matrix) to a known reference shape(s) (e.g., a square, a parallelogram, a triangle, a set of planar circles, etc.). Thus, the gaming system <b>100</b>, using the isomorphic quality of the object <b>130</b>, transforms the appearance of the object <b>130</b> until it is recognizable as a point of reference for calibration. The object <b>130</b> may be referred to herein as a fiducial, or a fiducial marker. In other words, the gaming system <b>100</b> can place the object <b>130</b> in the field of view of the camera <b>102</b> as a point of reference or a measure for calibration of the gaming system <b>100</b>. The object <b>130</b> also has contrasting color/tone features that the gaming system <b>100</b> uses to binarize and identify the object <b>130</b> (e.g., the object <b>130</b> is projected in black and white to cause the appearance of the object <b>130</b> have a high contrast between its light and dark elements, thus improving detectability via binarization). Because the object <b>130</b> has a unique shape, with isometric properties, the gaming system <b>100</b> can determine an orientation of the object <b>130</b> within the image <b>120</b> and, in response, orient the placement of the content <b>173</b> accordingly. For instance, in the database <b>170</b>, the marker <b>130</b> has a specific orientation. The content <b>173</b> also has a specific orientation indicated by the database <b>170</b>. The gaming system <b>100</b> can thus replace the object <b>130</b> with the content <b>173</b> using their related orientations indicated by the database <b>170</b>. The gaming system <b>100</b> can further observe a projected appearance of the content <b>173</b> (after it has been initially positioned), and can automatically make any additional adjustments necessary to its size, shape, location, etc. and/or can present (e.g., project) calibration features to make any additional adjustments to the appearance of the content <b>173</b>.</p><p id="p-0037" num="0036">In some examples, the gaming system <b>100</b> detects a combination of non-projected objects (e.g., objects physically placed or positioned on the gaming table <b>101</b>) and projected objects (e.g., objects thrown via light projection onto the surface <b>104</b>). For example, the gaming system <b>100</b> detects when an object(s) is/are placed at a specific location(s) on the surface <b>104</b> during a setup procedure. The gaming system <b>100</b> stores the location(s) of object(s) relative to each other (e.g., as multiple objects captured in a single image or as a composition of multiple images of the same object that is positioned at different locations during the setup). The gaming system <b>100</b> detects the location(s) of the object(s) as the area of interest on a virtual scene that overlays the image <b>120</b>. The gaming system <b>100</b> can further present calibration options for manual mapping the placement of gaming content within the virtual scene, so that the positioning of the content corresponds to the detected location(s).</p><p id="p-0038" num="0037">As mentioned, the gaming system <b>100</b> using a variety of points of interest including topological features and a fiducial object (e.g., object <b>130</b>). In some embodiments, the gaming system <b>100</b> projects a set of fiducial objects, similar to object <b>130</b>, each having a unique individual appearance that relates (e.g., via a binary code) to an identifier value (e.g., see <figref idref="DRAWINGS">FIG. <b>3</b></figref> for more detail). The identifier value identifies the individual object (or &#x201c;marker&#x201d;) within a spatial relationship of the set of objects as a group, such as a grid relationship arranged as a board pattern, where a location of each marker on the board is a different identifier/coordinate point in the grid. In some embodiments, the board is an isomorphic shape (e.g., a parallelogram or a square) and/or has some identifiable homography quality, such as a known symmetry, a known geometric relationship of at least three points in a single plane, etc. Thus the gaming system <b>100</b> can transform, via a projection transformation, an appearance of the markers from the projection space visible in the image <b>120</b> to a known linear (e.g., Euclidean) space associated with the grid, such as a virtual, or augmented reality layer depicting a virtual scene with gaming content mapped relative to locations in the grid. In some instances, the board is a set of binary square fiducial markers (e.g., barcode markers, aruco markers). In some examples, a square fiducial comprises a black square box (set against a white background) with a unique image or pattern inside of the black box (e.g., see object <b>130</b>). The pattern can be used to uniquely identify the fiducial and determine its orientation. Binary fiducials can be generated in sets, with each member of the set having a binary- coded image, from a Bose-Chaudhuri-Hocquenghem (BCH) code generator, thus generating sets of patterns with error-correcting capability. In some embodiments, the gaming system <b>100</b> uses a board having binary square fiducial markers positioned in each intersection of a grid structure. In some embodiments, the set of markers are placed on a checkboard, with the markers positioned on the alternating light-colored (e.g., white) squares. The shape and position of the dark-colored (e.g., black) squares in alternating contrast to the light-colored squares provides a detectable feature that the gaming system <b>100</b> can utilize to precisely find the corners of the markers.</p><p id="p-0039" num="0038">Furthermore, in some instances, (e.g., see <figref idref="DRAWINGS">FIG. <b>3</b></figref> for more detail) the gaming system <b>100</b> includes a feature to analyze the image <b>120</b> in stages via an incremental thresholding process, thus ensuring electronic identification of a set of objects within the image <b>120</b> despite darkened and inconsistent lighting conditions within a gaming environment that affect the quality of the image <b>120</b>. Specifically, gaming system <b>100</b> may not be able to adjust the lighting of the gaming environment in which the gaming table <b>101</b> exists. As a result, when the camera <b>102</b> captures the image <b>120</b>, the size of the gaming table <b>101</b>, and the various distances of each point of interest to the camera <b>102</b>, causes the digitized pixels of the image <b>120</b> to have pixel intensity values that can vary in actual values based on their relative location on the surface <b>104</b>. For example, sections of the gaming table <b>101</b> that are close to the camera <b>102</b> may have brighter pixel intensity values than sections of the gaming table <b>101</b> that are far from the camera <b>102</b>. In another example, lighting conditions at one end of the gaming table <b>101</b> may be different from lighting conditions at another rend of the gaming table <b>101</b>. Consequently, when the gaming system <b>100</b> electronically analyzes the image <b>120</b>, pixel intensity values for the different sections of the table can vary widely. As a result, binarization of the image <b>120</b> with a single thresholding value would cause the gaming system <b>100</b> to detect features of depicted objects in one section of the image <b>120</b> but not in other sections. To overcome this challenge, the gaming system <b>100</b> performs an incremental thresholding of the image <b>120</b> during binarization. For example, the gaming system <b>100</b> increases the threshold value of the image <b>120</b> incrementally, and gradually, from a range of selected values (e.g., from a low threshold value to a high threshold value (or vice versa)), causing features of individual sections of the image <b>120</b> to increase in value incrementally across the range of possible values. After each progressive incrementing of the thresholding value, the gaming system <b>100</b> electronically analyzes the image <b>120</b> again to detect additional possible points of interest in sections having similar pixel intensity values (based on their relative locations in the image <b>120</b>, based on the lighting conditions at the different sections, etc.). Thus, when the thresholding value increments across the range, object features across the entire gaming table <b>101</b> become visually detectable in the image <b>120</b> by the neural network model and, thus, extractable and classifiable.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram of an example gaming system <b>200</b> for tracking aspects of a wagering game in a gaming area <b>201</b>. In the example embodiment, the gaming system <b>200</b> includes a game controller <b>202</b>, a tracking controller <b>204</b>, a sensor system <b>206</b>, and a tracking database system <b>208</b>. In other embodiments, the gaming system <b>200</b> may include additional, fewer, or alternative components, including those described elsewhere herein.</p><p id="p-0041" num="0040">The gaming area <b>201</b> is an environment in which one or more casino wagering games are provided. In the example embodiment, the gaming area <b>201</b> is a casino gaming table and the area surrounding the table (e.g., as in <figref idref="DRAWINGS">FIG. <b>1</b>A-<b>1</b>D</figref>). In other embodiments, other suitable gaming areas <b>201</b> may be monitored by the gaming system <b>200</b>. For example, the gaming area <b>201</b> may include one or more floor-standing electronic gaming machines. In another example, multiple gaming tables may be monitored by the gaming system <b>200</b>. Although the description herein may reference a gaming area (such as gaming area <b>201</b>) to be a single gaming table and the area surrounding the gaming table, it is to be understood that other gaming areas <b>201</b> may be used with the gaming system <b>200</b> by employing the same, similar, and/or adapted details as described herein.</p><p id="p-0042" num="0041">The game controller <b>202</b> is configured to facilitate, monitor, manage, and/or control gameplay of the one or more games at the gaming area <b>201</b>. More specifically, the game controller <b>202</b> is communicatively coupled to at least one or more of the tracking controller <b>204</b>, the sensor system <b>206</b>, the tracking database system <b>208</b>, a gaming device <b>210</b>, an external interface <b>212</b>, and/or a server system <b>214</b> to receive, generate, and transmit data relating to the games, the players, and/or the gaming area <b>201</b>. The game controller <b>202</b> may include one or more processors, memory devices, and communication devices to perform the functionality described herein. More specifically, the memory devices store computer-readable instructions that, when executed by the processors, cause the game controller <b>202</b> to function as described herein, including communicating with the devices of the gaming system <b>200</b> via the communication device(s).</p><p id="p-0043" num="0042">The game controller <b>202</b> may be physically located at the gaming area <b>201</b> as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> or remotely located from the gaming area <b>201</b>. In certain embodiments, the game controller <b>202</b> may be a distributed computing system. That is, several devices may operate together to provide the functionality of the game controller <b>202</b>. In such embodiments, at least some of the devices (or their functionality) described in <figref idref="DRAWINGS">FIG. <b>2</b></figref> may be incorporated within the distributed game controller <b>202</b>.</p><p id="p-0044" num="0043">The gaming device <b>210</b> is configured to facilitate one or more aspects of a game. For example, for card-based games, the gaming device <b>210</b> may be a card shuffler, shoe, or other card-handling device. The external interface <b>212</b> is a device that presents information to a player, dealer, or other user and may accept user input to be provided to the game controller <b>202</b>. In some embodiments, the external interface <b>212</b> may be a remote computing device in communication with the game controller <b>202</b>, such as a player's mobile device. In other examples, the gaming device <b>210</b> and/or external interface <b>212</b> includes one or more projectors. The server system <b>214</b> is configured to provide one or more backend services and/or gameplay services to the game controller <b>202</b>. For example, the server system <b>214</b> may include accounting services to monitor wagers, payouts, and jackpots for the gaming area <b>201</b>. In another example, the server system <b>214</b> is configured to control gameplay by sending gameplay instructions or outcomes to the game controller <b>202</b>. It is to be understood that the devices described above in communication with the game controller <b>202</b> are for exemplary purposes only, and that additional, fewer, or alternative devices may communicate with the game controller <b>202</b>, including those described elsewhere herein.</p><p id="p-0045" num="0044">In the example embodiment, the tracking controller <b>204</b> is in communication with the game controller <b>202</b>. In other embodiments, the tracking controller <b>204</b> is integrated with the game controller <b>202</b> such that the game controller <b>202</b> provides the functionality of the tracking controller <b>204</b> as described herein. Like the game controller <b>202</b>, the tracking controller <b>204</b> may be a single device or a distributed computing system. In one example, the tracking controller <b>204</b> may be at least partially located remotely from the gaming area <b>201</b>. That is, the tracking controller <b>204</b> may receive data from one or more devices located at the gaming area <b>201</b> (e.g., the game controller <b>202</b> and/or the sensor system <b>206</b>), analyze the received data, and/or transmit data back based on the analysis.</p><p id="p-0046" num="0045">In the example embodiment, the tracking controller <b>204</b>, similar to the example game controller <b>202</b>, includes one or more processors, a memory device, and at least one communication device. The memory device is configured to store computer-executable instructions that, when executed by the processor(s), cause the tracking controller <b>204</b> to perform the functionality of the tracking controller <b>204</b> described herein. The communication device is configured to communicate with external devices and systems using any suitable communication protocols to enable the tracking controller <b>204</b> to interact with the external devices and integrates the functionality of the tracking controller <b>204</b> with the functionality of the external devices. The tracking controller <b>204</b> may include several communication devices to facilitate communication with a variety of external devices using different communication protocols.</p><p id="p-0047" num="0046">The tracking controller <b>204</b> is configured to monitor at least one or more aspects of the gaming area <b>201</b>. In the example embodiment, the tracking controller <b>204</b> is configured to monitor physical objects within the area <b>201</b>, and determine a relationship between one or more of the objects. Some objects may include gaming tokens. The tokens may be any physical object (or set of physical objects) used to place wagers. As used herein, the term &#x201c;stack&#x201d; refers to one or more gaming tokens physically grouped together. For circular tokens typically found in casino gaming environments (e.g., gaming chips), these may be grouped together into a vertical stack. In another example in which the tokens are monetary bills and coins, a group of bills and coins may be considered a &#x201c;stack&#x201d; based on the physical contact of the group with each other and other factors as described herein.</p><p id="p-0048" num="0047">In the example embodiment, the tracking controller <b>204</b> is communicatively coupled to the sensor system <b>206</b> to monitor the gaming area <b>201</b>. More specifically, the sensor system <b>206</b> includes one or more sensors configured to collect sensor data associated with the gaming area <b>201</b>, and the tracking controller <b>204</b> receives and analyzes the collected sensor data to detect and monitor physical objects. The sensor system <b>206</b> may include any suitable number, type, and/or configuration of sensors to provide sensor data to the game controller <b>202</b>, the tracking controller <b>204</b>, and/or another device that may benefit from the sensor data.</p><p id="p-0049" num="0048">In the example embodiment, the sensor system <b>206</b> includes at least one image sensor that is oriented to capture image data of physical objects in the gaming area <b>201</b>. In one example, the sensor system <b>206</b> may include a single image sensor that monitors the gaming area <b>201</b>. In another example, the sensor system <b>206</b> includes a plurality of image sensors that monitor subdivisions of the gaming area <b>201</b>. The image sensor may be part of a camera unit of the sensor system <b>206</b> or a three-dimensional (3D) camera unit in which the image sensor, in combination with other image sensors and/or other types of sensors, may collect depth data related to the image data, which may be used to distinguish between objects within the image data. The image data is transmitted to the tracking controller <b>204</b> for analysis as described herein. In some embodiments, the image sensor is configured to transmit the image data with limited image processing or analysis such that the tracking controller <b>204</b> and/or another device receiving the image data performs the image processing and analysis. In other embodiments, the image sensor may perform at least some preliminary image processing and/or analysis prior to transmitting the image data. In such embodiments, the image sensor may be considered an extension of the tracking controller <b>204</b>, and as such, functionality described herein related to image processing and analysis that is performed by the tracking controller <b>204</b> may be performed by the image sensor (or a dedicated computing device of the image sensor). In certain embodiments, the sensor system <b>206</b> may include, in addition to or instead of the image sensor, one or more sensors configured to detect objects, such as time-of-flight sensors, radar sensors (e.g., LIDAR), thermographic sensors, and the like.</p><p id="p-0050" num="0049">The tracking controller <b>204</b> is configured to establish data structures relating to various physical objects detected in the image data from the image sensor. For example, the tracking controller <b>204</b> applies one or more image neural network models during image analysis that are trained to detect aspects of physical objects. Neural network models are analysis tools that classify &#x201c;raw&#x201d; or unclassified input data without requiring user input. That is, in the case of the raw image data captured by the image sensor, the neural network models may be used to translate patterns within the image data to data object representations of, for example, tokens, faces, hands, etc., thereby facilitating data storage and analysis of objects detected in the image data as described herein.</p><p id="p-0051" num="0050">At a simplified level, neural network models are a set of node functions that have a respective weight applied to each function. The node functions and the respective weights are configured to receive some form of raw input data (e.g., image data), establish patterns within the raw input data, and generate outputs based on the established patterns. The weights are applied to the node functions to facilitate refinement of the model to recognize certain patterns (i.e., increased weight is given to node functions resulting in correct outputs), and/or to adapt to new patterns. For example, a neural network model may be configured to receive input data, detect patterns in the image data representing human body parts, perform image segmentation, and generate an output that classifies one or more portions of the image data as representative of segments of a player's body parts (e.g., a box having coordinates relative to the image data that encapsulates a face, an arm, a hand, etc. and classifies the encapsulated area as a &#x201c;human,&#x201d; &#x201c;face,&#x201d; &#x201c;arm,&#x201d; &#x201c;hand,&#x201d; etc.).</p><p id="p-0052" num="0051">For instance, to train a neural network to identify the most relevant guesses for identifying a human body part, for example, a predetermined dataset of raw image data including image data of human body parts, and with known outputs, is provided to the neural network. As each node function is applied to the raw input of a known output, an error correction analysis is performed such that node functions that result in outputs near or matching the known output may be given an increased weight while node functions having a significant error may be given a decreased weight. In the example of identifying a human face, node functions that consistently recognize image patterns of facial features (e.g., nose, eyes, mouth, etc.) may be given additional weight. Similarly, in the example of identifying a human hand, node functions that consistently recognize image patterns of hand features (e.g., wrist, fingers, palm, etc.) may be given additional weight. The outputs of the node functions (including the respective weights) are then evaluated in combination to provide an output such as a data structure representing a human face. Training may be repeated to further refine the pattern-recognition of the model, and the model may still be refined during deployment (i.e., raw input without a known data output).</p><p id="p-0053" num="0052">At least some of the neural network models applied by the tracking controller <b>204</b> may be deep neural network (DNN) models. DNN models include at least three layers of node functions linked together to break the complexity of image analysis into a series of steps of increasing abstraction from the original image data. For example, for a DNN model trained to detect human faces from an image, a first layer may be trained to identify groups of pixels that represent the boundary of facial features, a second layer may be trained to identify the facial features as a whole based on the identified boundaries, and a third layer may be trained to determine whether or not the identified facial features form a face and distinguish the face from other faces. The multi-layered nature of the DNN models may facilitate more targeted weights, a reduced number of node functions, and/or pipeline processing of the image data (e.g., for a three-layered DNN model, each stage of the model may process three frames of image data in parallel).</p><p id="p-0054" num="0053">In at least some embodiments, each model applied by the tracking controller <b>204</b> may be configured to identify a particular aspect of the image data and provide different outputs such that the tracking controller <b>204</b> may aggregate the outputs of the neural network models together to identify physical objects as described herein. For example, one model may be trained to identify human faces, while another model may be trained to identify the bodies of players. In such an example, the tracking controller <b>204</b> may link together a face of a player to a body of the player by analyzing the outputs of the two models. In other embodiments, a single DNN model may be applied to perform the functionality of several models.</p><p id="p-0055" num="0054">As described in further detail below, the tracking controller <b>204</b> may generate data objects for each physical object identified within the captured image data by the DNN models. The data objects are data structures that are generated to link together data associated with corresponding physical objects. For example, the outputs of several DNN models associated with a player may be linked together as part of a player data object.</p><p id="p-0056" num="0055">It is to be understood that the underlying data storage of the data objects may vary in accordance with the computing environment of the memory device or devices that store the data object. That is, factors such as programming language and file system may vary the where and/or how the data object is stored (e.g., via a single block allocation of data storage, via distributed storage with pointers linking the data together, etc.). In addition, some data objects may be stored across several different memory devices or databases.</p><p id="p-0057" num="0056">In some embodiments, the player data objects include a player identifier, and data objects of other physical objects include other identifiers. The identifiers uniquely identify the physical objects such that the data stored within the data objects is tied to the physical objects. In some embodiments, the identifiers may be incorporated into other systems or subsystems. For example, a player account system may store player identifiers as part of player accounts, which may be used to provide benefits, rewards, and the like to players. In certain embodiments, the identifiers may be provided to the tracking controller <b>204</b> by other systems that may have already generated the identifiers.</p><p id="p-0058" num="0057">In at least some embodiments, the data objects and identifiers may be stored by the tracking database system <b>208</b>. The tracking database system <b>208</b> includes one or more data storage devices (e.g., one or more databases) that store data from at least the tracking controller <b>204</b> in a structured, addressable manner. That is, the tracking database system <b>208</b> stores data according to one or more linked metadata fields that identify the type of data stored and can be used to group stored data together across several metadata fields. The stored data is addressable such that stored data within the tracking database system <b>208</b> may be tracked after initial storage for retrieval, deletion, and/or subsequent data manipulation (e.g., editing or moving the data). The tracking database system <b>208</b> may be formatted according to one or more suitable file system structures (e.g., FAT, exFAT, ext4, NTFS, etc.).</p><p id="p-0059" num="0058">The tracking database system <b>208</b> may be a distributed system (i.e., the data storage devices are distributed to a plurality of computing devices) or a single device system. In certain embodiments, the tracking database system <b>208</b> may be integrated with one or more computing devices configured to provide other functionality to the gaming system <b>200</b> and/or other gaming systems. For example, the tracking database system <b>208</b> may be integrated with the tracking controller <b>204</b> or the server system <b>214</b>.</p><p id="p-0060" num="0059">In the example embodiment, the tracking database system <b>208</b> is configured to facilitate a lookup function on the stored data for the tracking controller <b>204</b>. The lookup function compares input data provided by the tracking controller <b>204</b> to the data stored within the tracking database system <b>208</b> to identify any &#x201c;matching&#x201d; data. It is to be understood that &#x201c;matching&#x201d; within the context of the lookup function may refer to the input data being the same, substantially similar, or linked to stored data in the tracking database system <b>208</b>. For example, if the input data is an image of a player's face, the lookup function may be performed to compare the input data to a set of stored images of historical players to determine whether or not the player captured in the input data is a returning player. In this example, one or more image comparison techniques may be used to identify any &#x201c;matching&#x201d; image stored by the tracking database system <b>208</b>. For example, key visual markers for distinguishing the player may be extracted from the input data and compared to similar key visual markers of the stored data. If the same or substantially similar visual markers are found within the tracking database system <b>208</b>, the matching stored image may be retrieved. In addition to or instead of the matching image, other data linked to the matching stored image may be retrieved during the lookup function, such as a player account number, the player's name, etc. In at least some embodiments, the tracking database system <b>208</b> includes at least one computing device that is configured to perform the lookup function. In other embodiments, the lookup function is performed by a device in communication with the tracking database system <b>208</b> (e.g., the tracking controller <b>204</b>) or a device in which the tracking database system <b>208</b> is integrated within.</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow diagram of an example method according to one or more embodiments of the present disclosure. <figref idref="DRAWINGS">FIGS. <b>4</b>, <b>5</b>A, <b>5</b>B, <b>5</b>C, <b>6</b>, <b>7</b>, <b>8</b>A, <b>8</b>B, <b>9</b>A and <b>9</b>B</figref> are diagrams of an exemplary gaming system associated with the data flow shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> according to one or more embodiments of the present disclosure. FIG. <figref idref="DRAWINGS">FIGS. <b>4</b>, <b>5</b>A, <b>5</b>B, <b>5</b>C, <b>6</b>, <b>7</b>, <b>8</b>A, <b>8</b>B, <b>9</b>A and <b>9</b>B</figref> will be referenced in the description of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0062" num="0061">In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a flow <b>300</b> begins at processing block <b>302</b> with projecting a plurality of markers at a surface of a gaming table. In one example, as in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a gaming system <b>400</b> is similar to gaming system <b>100</b>. The gaming system <b>400</b> includes a gaming table <b>401</b>, a camera <b>402</b>, a projector <b>403</b>, a chip tray <b>413</b>, main betting circles <b>405</b>A-<b>410</b>A, and secondary betting circles <b>405</b>B-<b>410</b>B. The gaming system <b>400</b> is further similar to the gaming system <b>200</b> described in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and, as such, may utilize the tracking controller <b>204</b> to perform one or more operations described. In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the gaming system <b>400</b> projects (via projector <b>403</b>) a board of coded square fiducial markers (&#x201c;board <b>425</b>&#x201d;). A portion of the markers become visible to the camera <b>402</b> when projected onto a surface <b>404</b> of the gaming table <b>401</b>. A portion of the markers that do not land on the surface <b>404</b> (when thrown by the projector <b>403</b>) are not visible to the camera <b>402</b>. The markers that are visible are depicted in the image <b>420</b> taken by the camera <b>402</b>. In some embodiments, the board <b>425</b> is configured to be larger than the surface <b>404</b> of the gaming table <b>401</b>. Thus, when the board <b>420</b> is projected into the gaming area at the general direction of the gaming table <b>401</b>, at least some portion of the board <b>425</b> appears on the surface <b>404</b>, ensuring adequate coverage of the gaming table <b>401</b> with markers. At some point, if the projector <b>403</b> is moved, the gaming system <b>400</b> can recapture the image <b>420</b>. Because the projector <b>403</b> had been moved, different markers from the board <b>425</b> would fall on different parts of the surface <b>404</b>. However, because the markers are organized into a common grid structure, and because each marker is proportionately spaced, the gaming system <b>400</b> can recapture the image <b>420</b> and re-calibrate (e.g., repeat one or more portions of the flow <b>300</b>), using the new fiducial marker identifier values that correspond to the different markers that fall on the different parts of the surface <b>404</b>. Thus, the board <b>425</b> becomes a floating grid, any part of which can be moored to any part of the surface <b>404</b>, and thus provides a margin of acceptable shift in the physical location of the projector <b>403</b> for calibration purposes.</p><p id="p-0063" num="0062">The number of markers in the board <b>425</b> can vary. More markers represent more grid points that can be used as more interior points of a convex hull during polygon triangulation (e.g., at processing block <b>318</b>), thus producing a denser virtual mesh. A denser virtual mesh has more points for calibrating the presentation of gaming content (e.g., at processing block <b>320</b>). Thus, according to some embodiments, more markers in the board <b>425</b> is preferable so long as the markers are of sufficient size to be recognizable to the neural network model (given the input requirement of the neural network model, the distance of the camera <b>402</b> to the gaming table <b>401</b>, the lighting in the gaming area, etc.). At the very least the board <b>425</b> should include enough markers to cover the portions of the gaming table <b>401</b> that need to be observed for object detection and/or for accurate position of content projection. In some instances, a grid can include any plurality of markers, such as two or more. In some embodiments, the markers are in a known spatial relationship to each other in distance and orientation according to a uniform grid structure. Consequently, if the gaming system <b>400</b> detects locations for some of the markers, the gaming system <b>400</b> can extrapolate locations of obscured markers based on the known spatial relationship of all markers to each other via the grid structure for the board <b>425</b>. For example, as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, some of the markers projected at the surface <b>404</b> may be obscured by, or may be non-viewable due to a presence of, one or more additional objects on the surface <b>404</b>, such as the betting circles <b>405</b>A-<b>410</b>A and <b>405</b>B-<b>410</b>B. However, the gaming system <b>400</b> can detect other visible markers around the betting circles <b>405</b>A-<b>410</b>A and <b>405</b>B-<b>410</b>B. After detecting the markers that surround the betting circles <b>405</b>A-<b>410</b>A and <b>405</b>B-<b>410</b>B, the gaming system <b>400</b> can extrapolate location values for the obscured markers. For instance, each of the visible markers has a unique identifier value that represents a coordinate in the organized grid. The gaming system <b>400</b> knows dimensions for spacing of the coordinate points in the grid. Thus, the gaming system <b>400</b> can extrapolate the locations of the obscured markers relative to the locations of the surrounding visible markers using the known dimensions for the spacing of the coordinate points relative to each other in the grid.</p><p id="p-0064" num="0063">Referring back to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the flow <b>300</b> continues at processing block <b>304</b> with capturing an image of the surface of the gaming table. For example, as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the system <b>400</b> can capture, from a perspective of the camera <b>402</b> (&#x201c;camera perspective&#x201d;) the image <b>420</b> of the gaming area, which includes an image of the gaming table <b>401</b>. In one embodiment, the gaming system <b>400</b> captures a single frame of a video stream of image data by the camera <b>402</b> and sends the single frame of image data (e.g., image <b>420</b>) to a tracking controller (e.g., tracking controller <b>204</b> shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) for image processing and analysis to identify physical objects in the gaming area. As mentioned previously, the portion of the markers on the board <b>425</b> that land on the surface <b>404</b> become visible to the camera <b>402</b> and, thus, are visible in the image <b>420</b> taken by the camera <b>402</b>.</p><p id="p-0065" num="0064">Referring back to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the flow <b>300</b> continues at processing block <b>306</b> with a looping, or repeating, operation that iteratively modifies an image property value of the captured image until reaching an image property value limit. In some instances a gaming system modifies graphical properties of the image, such as resolution, contrast, brightness, color, vibrancy, sharpness, threshold, exposure, etc. As those properties are modified incrementally (either alone or in different combinations), additional information becomes visible in the image. In one example, as shown in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, the gaming system <b>400</b> performs a threshold algorithm to the entire image <b>420</b>. The threshold algorithm sets an initial threshold value. The threshold value is a pixel intensity value. In other words, any pixel in the image <b>420</b> having a pixel intensity above the pixel intensity threshold value will appear as white in the modified image, whereas any pixel having a pixel intensity below the pixel intensity threshold value will appear as black. For example, the gaming system <b>400</b> sets a threshold value to a low setting, such as the number &#x201c;32.&#x201d; This means that any pixel with an intensity level lower than &#x201c;32&#x201d; will appear as black, and anything with a higher intensity level will appear as white. Consequently, as shown in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, a first section <b>501</b> of the set of visible markers on the table <b>401</b> becomes detectable (i.e., first marker set <b>511</b>).</p><p id="p-0066" num="0065">The flow <b>300</b> continues at processing block <b>308</b> with identifying, via analysis of the image by neural network model, detectable ones of the markers. For example, as shown in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, the gaming system <b>400</b> auto-morphs, via a neural network model, each object within the image <b>420</b> having detectable features. Because of the initial threshold value (e.g., the lower value of &#x201c;32&#x201d;), section <b>501</b> includes objects (e.g., the first set of markers <b>511</b>) with pixel intensity values that cause a digitized version of the first set of markers <b>511</b> to become sufficiently binary for identification (e.g., the light pixels of the first set of markers <b>511</b> change to a pixel intensity value corresponding to the color white and the dark pixels of the first set of markers <b>511</b> change to a pixel intensity value correspond to the color black). The gaming system <b>400</b> transforms each of the first set of markers <b>511</b> shown in the image <b>420</b> via an isomorphic transformation (e.g., a projection transformation) until it is in detectable as a marker. The gaming system <b>400</b> can thus identify the unique pattern (e.g., a coded value) of each detected marker to determine a unique identifier value assigned to the marker (e.g., a coordinate value corresponding to a location of the marker in the grid structure of the board <b>425</b>). The gaming system <b>400</b> can further perform a centroid detection algorithm on the detected marker to indicate a center point of the square shape of the detected marker. The center point of the square shape becomes a location reference point to which the gaming system <b>400</b> can associate the identifier for the detected marker.</p><p id="p-0067" num="0066">The flow <b>300</b> continues at processing block <b>310</b> with determining whether there are any undetected markers. If there are still undetected markers, the gaming system continues to processing block <b>312</b>. If, however, all possible markers that are detectable on the surface of the gaming table have been detected, the loop ends <b>314</b> and the process continues at processing block <b>316</b>.</p><p id="p-0068" num="0067">For example, in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, the gaming system <b>400</b> determines that only a portion of the image <b>420</b> (i.e., section <b>501</b>) included any detectable markers. A large section of the gaming table <b>401</b> did not. Thus, the gaming system <b>400</b> determines that more markers may be detectable. As a result, the gaming system <b>400</b> modifies the threshold value incrementally (e.g., increases the threshold value from the initial value (e.g., &#x201c;32&#x201d;) to a next incremental value (e.g., &#x201c;40&#x201d;) according to a threshold increment amount set at &#x201c;8&#x201d;), then the gaming system <b>400</b> repeats processing blocks <b>308</b> and <b>310</b>. For instance, as shown in <figref idref="DRAWINGS">FIG. <b>5</b>B</figref>, after the gaming system <b>400</b> increases the threshold value, a second section <b>502</b> of the set of visible markers on the surface <b>404</b> becomes detectable (i.e., second marker set <b>512</b>). The gaming system <b>400</b> further determines that more markers can be detected and so increases the threshold value again (e.g., increases the threshold value from &#x201c;40&#x201d; to &#x201c;48&#x201d;). After the additional increase, as shown in <figref idref="DRAWINGS">FIG. <b>5</b>C</figref>, a third section <b>503</b> of the set of visible markers on the table <b>401</b> becomes detectable (i.e., third marker set <b>513</b>). After the series of increments, the gaming system <b>400</b> determines that there are no more visible sections of the table <b>410</b> left to electronically analyze for the presence of markers, and thus the gaming system <b>400</b> ends the &#x201c;for&#x201d; loop at processing block <b>314</b>. The &#x201c;for&#x201d; loop shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may also be referred to herein, according to some embodiments, as a &#x201c;marker detection loop&#x201d; for sake of brevity. In some embodiments, the gaming system <b>400</b> may repeat the marker detection loop until the threshold value reaches a limit (e.g., until the threshold value is so high that all pixels would appear completely black, thus revealing no markers).</p><p id="p-0069" num="0068">The example shown in <figref idref="DRAWINGS">FIG. <b>5</b>A-<b>5</b>C</figref> showed only three iterations of the marker detection loop over a specific range of threshold values. In other instances, however, the gaming system <b>400</b> may perform the marker detection loop less than three times or more than three times, with each iteration causing differing sections of the visible set of markers to become detectable. The number of iterations required may vary based on the environmental lighting to which the gaming table <b>401</b> is exposed. In some instances, the gaming system <b>400</b> may reach a maximum limit for the range of threshold values (e.g., reaches the maximum pixel intensity limit of &#x201c;255&#x201d; for an 8-bit grayscale image). If so, then the gaming system <b>400</b> also ends the marker detection loop.</p><p id="p-0070" num="0069">In some instances, if the gaming system <b>400</b> reaches the maximum limit, and if the gaming system <b>400</b> also determines that portions of the gaming table <b>401</b> may include detectable markers (e.g., if the gaming system <b>400</b> determines that no markers were found over any portions of the gaming table <b>401</b> where markers would be expected to appear), then the gaming system <b>400</b> can repeat the marker detection loop using a smaller threshold increment amount for the threshold value. Furthermore, in some embodiments, the gaming system <b>400</b> can automatically modify the threshold increment amount to be larger or smaller based on an amount of visible markers that were detected for any iteration of the marker detection loop. For instance, the gaming system <b>400</b> may determine that an initial threshold increment amount of &#x201c;8&#x201d; may detect markers very slowly (multiple iterations may detect few or no markers), and thus the gaming system <b>400</b> may increase the threshold increment amount to a larger number. If, in response to the increase of the threshold increment amount, the gaming system <b>400</b> detects a larger number of markers, then the gaming system <b>400</b> may continue to utilize the new threshold increment amount for a remainder of iterations or until the gaming system <b>400</b> begins to detect few or no markers again (at which time the gaming system <b>400</b> can modify the threshold increment amount again). In some instances, however, if the increase in the threshold increment amount continues to result in few or no detected makers, the gaming system <b>400</b> may instead reduce the threshold increment amount to be lower than the initial value (e.g., lower than the initial threshold increment amount of &#x201c;8&#x201d;). Furthermore, in some embodiments, the gaming system <b>400</b> can roll back the threshold value to an initial range value and repeat the marker detection loop using the modified threshold increment amount.</p><p id="p-0071" num="0070">Referring back to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the flow <b>300</b> continues at processing block <b>316</b> with associating a location of each detected marker in the image to identifier value(s) for each detected marker. In one example, as in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the gaming system <b>400</b>, via one or more isomorphic transformations of the image <b>420</b>, overlays the grid structure of the board <b>425</b> onto a virtual representation <b>601</b> of the gaming table <b>401</b> within a virtual scene <b>620</b>. In some embodiments, the gaming system <b>400</b> determines the dimensions of the virtual representation <b>601</b> of the gaming table <b>401</b> based on one or more of dimensions of an outline <b>621</b> of the detected markers, known dimensions of the grid structure for board <b>425</b>, a known position of the projector <b>403</b> relative to the projected board <b>425</b>, as well as any additional reference points of interest detectable on the gaming table <b>425</b> (e.g., detected locations of a chip tray, betting circles, etc.). The grid structure of the board <b>425</b> has corresponding coordinate values at each location of each marker. Thus, the gaming system <b>400</b> modifies the virtual scene <b>620</b> to associate the relative locations of the detected markers to the coordinate values for each detected marker in the grid structure of the board <b>425</b>. Over several iterations of the marker detection loop (shown in <figref idref="DRAWINGS">FIG. <b>5</b>A-<b>5</b>C</figref>), the gaming system <b>400</b> associates the locations for the first marker set <b>511</b>, the second marker set <b>512</b>, and the third marker set <b>513</b> with their corresponding coordinate value identifiers. In some instances, the gaming system <b>400</b> can modify the number of markers on the board <b>425</b> based on detected characteristics of the outline <b>621</b>. For example, the gaming system <b>400</b> can detect the shape of the outline <b>621</b>. If the number of the markers on the board <b>425</b> are too few and/or are spaced too far apart, the shape of the outline <b>621</b> may appear amorphous, thus making the details of the shape of the gaming table <b>401</b> difficult to detect, thus making orientation of the gaming table <b>401</b> difficult to ascertain. Consequently, the gaming system <b>400</b> can regenerate the board <b>425</b> with a greater number of markers (e.g., smaller and more densely packed together), until the detected shape of the outline <b>621</b> has a shape that sufficiently resembles the gaming table <b>401</b> and/or has sufficient detail for accurate identification of specific characteristics of the gaming table <b>401</b> (e.g., accurate identification of objects, edges, sections, areas, ridges, corners, etc.).</p><p id="p-0072" num="0071">Referring back to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the flow <b>300</b> continues at processing block <b>318</b> with generating a virtual mesh aligned to the surface of gaming table using identifier value(s) as polygon triangulation points. In one example, as in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the gaming system <b>400</b> performs polygon triangulation, such as a point set triangulation, a Delaunay triangulation, etc. For instance, the gaming system selects a first set of location values for markers on the outline <b>621</b> as points on a convex hull of a simple polygon shape (i.e. the shape of the outline <b>621</b> is a simple polygon shape, meaning that the shape does not intersect itself and has no holes, or in other words is a flat shape consisting of straight, non-intersecting line segments or &#x201c;sides&#x201d; that are joined pairwise to form a single closed path). In response to detecting the points on the convex hull for the outline <b>621</b>, the gaming system <b>400</b> draws a mesh of triangles that connect interior points (i.e., the detected markers inside of the outline <b>621</b>) with the points on the convex hull. Further, the gaming system <b>400</b> draws the mesh of triangles to connect the interior points with each other. The polygon triangulation forms a two-dimensional finite element mesh, or graph, of a portion of the plane of the surface <b>404</b> of the gaming table <b>401</b> at which the projected markers were detected. One example of a polygon triangulation algorithm is &#x201c;Triangle.Net,&#x201d; found at the following internet address: https://archive.codeplex.com/?p=triangle. Thus, as shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the gaming system <b>400</b> generates a virtual mesh <b>701</b> having interconnected virtual triangles.</p><p id="p-0073" num="0072">Referring back to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the flow <b>300</b> continues at processing block <b>320</b> with calibrating presentation of gaming content using the virtual mesh. For example, referring back to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the gaming system <b>400</b> identifies locations of additional detected objects from the gaming table <b>401</b>, such as the chip tray <b>413</b> and/or the betting circles <b>405</b>A-<b>410</b>A and <b>405</b>B-<b>410</b>B. The gaming system <b>400</b> uses the coordinate identity values for the points on the virtual mesh <b>701</b> to place gaming content within the virtual scene <b>620</b>. For instance, the gaming system <b>400</b> overlays representations of the chip tray <b>413</b> and the betting circles at corresponding locations within the virtual scene <b>620</b> relative to the approximate locations of the detected objects on the gaming table <b>401</b>. In <figref idref="DRAWINGS">FIG. <b>8</b>A</figref>, the gaming system <b>400</b> can project grid lines <b>815</b> for the virtual mesh <b>701</b> in relation to the visible markers. The grid lines <b>815</b> are shown depicted in an additional image <b>820</b> taken by the camera <b>402</b>. <figref idref="DRAWINGS">FIG. <b>8</b>B</figref> shows the grid lines <b>815</b> (via image <b>821</b>) with the visible markers removed.</p><p id="p-0074" num="0073">The gaming system <b>400</b> can further determine, based on the relative positions of the detected objects within the mapped coordinates, where to position gaming content (on the virtual mesh <b>701</b>) relative to the detected objects. For instance, knowing the location of the detected object (e.g., chip tray locations, betting circle locations, player station locations, etc.) within the mapping, the gaming system <b>400</b> can position graphical content within the virtual scene <b>620</b> relative to the respective object. The gaming system can use the positions of the detected objects as reference points for positioning of content. For example, as shown in <figref idref="DRAWINGS">FIG. <b>9</b>A</figref>, the gaming system <b>400</b> positions a virtual wheel graphic <b>973</b> (e.g., similar to content <b>173</b> depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>) and one or more bet indicator graphics (e.g., secondary-bet, indicator graphic <b>975</b>) within the virtual scene <b>620</b> relative to grid point coordinates as well as any other points of interest on the gaming table <b>410</b> (e.g., points <b>913</b> associated with the chip tray <b>413</b>, one or more centroid points of the betting circles <b>405</b>A-<b>410</b>A and <b>410</b>B-<b>410</b>B, points associated with a detected axis of symmetry <b>964</b>, etc.). For instance, the gaming system <b>400</b> positions the secondary-bet, indicator graphic <b>975</b> (referred to also as &#x201c;graphic <b>975</b>&#x201d;) based on a detected spatial relationship to a closest acceptable grid point to the associated point of interest. For example, an acceptable placement of the graphic <b>975</b> for secondary betting circle <b>407</b>B includes detecting an offset (e.g., a difference in position, orientation, etc.) between a coordinate point for the centroid <b>923</b> for secondary betting circle <b>407</b>B and a nearest coordinate point (e.g., triangle point on the virtual mesh <b>701</b>) at which an anchor (e.g., a centroid) for the graphic <b>975</b> can be placed, when oriented appropriately, without overlapping (or otherwise obstructing a detected surface area occupied by) the secondary betting circle <b>407</b>B. The gaming system <b>400</b> can store the offset in memory and use it for projecting content at a later time. <figref idref="DRAWINGS">FIG. <b>9</b>B</figref>, illustrates a calibration of the positioning of the gaming content (e.., virtual wheel graphic <b>973</b> and bet indicator graphic(s) <b>975</b>) within an image <b>920</b> taken by the camera <b>402</b> after calibration. In <figref idref="DRAWINGS">FIG. <b>9</b>B</figref>, the grid lines <b>815</b> for the virtual mesh <b>701</b> are shown as reference, however in some embodiments, the grid lines <b>815</b> can be transparent from view.</p><p id="p-0075" num="0074">The embodiments described in <figref idref="DRAWINGS">FIGS. <b>1</b>, <b>2</b>, <b>3</b>, <b>4</b>, <b>5</b>A, <b>5</b>B, <b>5</b>C, <b>6</b>, <b>7</b>, <b>8</b>A, <b>8</b>B, <b>9</b>A and <b>9</b>B</figref> are some examples of a self-referential gaming system. Additional embodiments are described further below of a gaming system similar to gaming system <b>100</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>), gaming system <b>200</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) gaming system <b>400</b> (<figref idref="DRAWINGS">FIG. <b>4</b></figref>), etc. or any element of the gaming system.</p><p id="p-0076" num="0075">In some embodiments, the gaming system automatically modifies properties of a camera (e.g., exposure, light sensitivity, aperture size, shutter speed, focus, zoom, ISO, image sensor settings, etc.) to provide the best quality images from which to analyze objects (e.g., gaming tokens, cards, projected markers, non-projected objects, etc.) for information that could identify values (e.g., chip values, card face values, symbol values, coordinate values, fiducial orientations, manufacturer settings, layout dimensions, presentation requirement settings, barcode values, etc.).</p><p id="p-0077" num="0076">In some embodiments, the gaming system modifies camera properties based on a mode. For example, for a bet mode, the gaming system automatically sets the camera settings to the highest quality possible so as to ensure proper identification of placed bets. For example, the gaming system modifies the camera settings to longer exposure times and greater light sensitivity. On the other hand, in a second mode, such as a play mode, the gaming system modifies the camera settings to different values to optimize for quick motion, such as movement of hands, cards, etc. For example, the gaming system modifies the camera settings for shorter exposure times and lower light sensitivity.</p><p id="p-0078" num="0077">In some instances, the gaming system incrementally modifies camera settings. As those settings are modified incrementally, multiple images are taken from the same camera using the different camera settings. From the multiple images, the gaming system can identify additional features of objects, such as additional portions of a projected board of markers. For instance, in a low-lighting environment, such as a casino floor, a camera at a gaming table may take a picture of the projected board of markers at a given light sensitivity setting that results in a first image. The gaming system analyzes the first image and identifies markers (or other objects) that are located close to the camera. However, the objects in the first image that are far from the camera appear dark. In other words, in the first image, projected markers beyond a certain distance from the camera are unidentifiable by the gaming system (e.g., by a neural network model), resulting in an incomplete view of the portion of the board of markers that appears on the surface of the gaming table. According to some embodiments, the gaming system can modify the properties of the first image, such as by modifying camera settings (e.g., modifying a camera exposure setting, modifying a brightness and/or contrast setting, etc.), resulting in at least one additional version of the first image (e.g., a second image). The gaming system then analyzes the second image to detect additional objects far from the camera. In some instances, the gaming system determines whether the change that was made resulted in a detection of image details of additional objects that were previously undetected. For instance, if more details of an object, or group of objects, are visible in the second image, then the gaming system determines that the change to the particular graphical property (e.g., via the change to the camera's optical settings) was useful and adjusts a subsequent iteration of the modifying step according to the determination. For example, if the image quality results in identification (by the neural network model) of additional ones of the markers, then the gaming system can increase the value for the graphic property that was changed in the previous iteration to a greater degree, until no more markers can be identified. On the other hand, if the image quality was worse, or no better than before (e.g., no additional barcodes are detected), the gaming system can adjust the value in a different way (e.g., reduces a camera setting value instead of increasing it).</p><p id="p-0079" num="0078">In another example, the gaming system modifies a plurality of different graphical properties and/or settings concurrently. In yet another example, the gaming system automatically modifies an exposure setting to an optimal point for any given gaming mode, any gaming environment condition, etc. (e.g., varying a modification of the exposure setting upward and downward sequentially to determine which setting reveals the desired image quality given a specific frame rate requirement for a stream of image data given a specific game mode or environmental condition). In some embodiments, such as for flow <b>300</b> mentioned in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the gaming system can automatically change the exposure setting at the start of (or during) each of the iterations of the loop (e.g., before or during the marker detection loop). In some instances, the gaming system determines how many markers are detectable based on the exposure changes. The gaming system can then set the exposure for the camera to a setting that results in the most detected markers.</p><p id="p-0080" num="0079">In another embodiment, the gaming system provides an option for a manual adjustment to a camera setting. For example, the gaming system can pause and request an operator to manually inspect an image for the best quality and to manually change a setting (e.g., an exposure setting) based on the inspection. The gaming system can then capture an image in response to a user input indicating that the settings were manually adjusted.</p><p id="p-0081" num="0080">In some embodiments, the gaming system automatically modifies projection aspects, such as properties, settings, modes, etc. of a projector (e.g., brightness or luminosity levels, contrast settings, color vibrancy settings, color space settings, focus, zoom, power usage, network connectivity settings, mode settings, etc.) or other aspects of the system related to projection (e.g., aspects of graphical rendering of content in a virtual scene to aid in calibration).</p><p id="p-0082" num="0081">In some embodiments, the gaming system uses the projector to assist in optimal image capture by providing optimal lighting for various parts of a gaming table. For instance, the projector light settings can be modified to project certain amounts of light to different portions of the table to balance out lighting imbalances from ambient lighting. For instance, the gaming system can project a solid color, such as white light, to illuminate specifically selected areas, objects, etc. associated with a gaming table surface. For example, the gaming system can project white light at a front face of chip stacks to get the best possible light conditions for image capture so that neural network model can detect chip edges, colors, shapes, etc.</p><p id="p-0083" num="0082">In some embodiments, the gaming system projects white light and/or other identifiers at edges of objects (e.g., at fingers, chips, etc.) that are near the surface of the gaming table. In some embodiments, the gaming system projects bright light at an object to determine, via electronic analysis of an image, whether a shadow appears underneath the object. The gaming system can use the detection of the shadow to infer that the object is not touching the surface. In some embodiments, the gaming system projects an object with a structure or element that, if it appears on the object and/or if it shows sufficient continuity with a pattern projected onto the surface, means that the object was close enough to the surface to be touching. For instance, if a color and/or pattern shows clearly on the fingernail in a way that would only appear if the finger tip was a certain distance to the surface material (e.g., a small diamond shape that is projected by the projector appears on the finger nail), then the gaming system can predict that the finger was touching the surface. In another example, if the color and/or pattern is detectable on a bottom edge of a gaming chip and has continuity with the projected portion of the identifier projected onto the table surface right next the chip, or in other words the pattern appears continuous from the surface to the chip, without a dark gap between, then the gaming system infers that the chip is touching the surface.</p><p id="p-0084" num="0083">In some embodiments, the gaming system can modify projection aspects per mode. For example, in a betting mode, the gaming system may need higher image quality for detection of certain values of chips, chip stacks, etc. Thus, the gaming system modifies projection properties to provide lighting that produces the highest quality images for the conditions of the gaming environment (e.g., continuous, diffused light). On the other hand, in a second mode, such as a play mode, the projection properties may be set to different settings or values (e.g., a focused lighting mode, a flash lighting mode, etc.), such as to optimize image quality (e.g., reduce possible blur) that may be caused by a quick movement of hands, cards, etc.</p><p id="p-0085" num="0084">In some embodiments, the gaming system can optimize projection aspects to compensate for shadows. For instance, if a projected light is casting harsh shadows, the gaming system can auto-mask specific objects within a virtual scene and auto adjust the specific amount of light thrown at the object by modifying the projected content on the mask. For example, the gaming system can, in a virtual scene for the content, overlay a graphical mask at a location of a detected object and render a graphic of the light color and/or identifier onto the mask. In addition, the mask can have a transparency/opacity property, such that the gaming system can reduce an opacity of the layer, thus reducing the potential brightness and/or detail of the projected content, thus allowing it to carefully determine a degree of darkness of shadows being generated by the projected content.</p><p id="p-0086" num="0085">In some embodiments, the gaming system modifies graphical properties of projected identifiers to allow for detectability. For example, the gaming system changes a color of all, or parts, of projected objects (e.g., markers, boards, etc.) based on detected background colors. By changing the colors of the projected objects to have high contrast with the background, the gaming system provides an image that visibly depicts the best contrast of a projected object against the surrounding portions of the surface shown in an image.</p><p id="p-0087" num="0086"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a perspective view of an embodiment of a gaming table <b>1200</b> (which may be configured as the gaming table <b>101</b> or the gaming table <b>401</b>) for implementing wagering games in accordance with this disclosure. The gaming table <b>1200</b> may be a physical article of furniture around which participants in the wagering game may stand or sit and on which the physical objects used for administering and otherwise participating in the wagering game may be supported, positioned, moved, transferred, and otherwise manipulated. For example, the gaming table <b>1200</b> may include a gaming surface <b>1202</b> (e.g., a table surface) on which the physical objects used in administering the wagering game may be located. The gaming surface <b>1202</b> may be, for example, a felt fabric covering a hard surface of the table, and a design, conventionally referred to as a &#x201c;layout,&#x201d; specific to the game being administered may be physically printed on the gaming surface <b>1202</b>. As another example, the gaming surface <b>1202</b> may be a surface of a transparent or translucent material (e.g., glass or plexiglass) onto which a projector <b>1203</b>, which may be located, for example, above or below the gaming surface <b>1202</b>, may illuminate a layout specific to the wagering game being administered. In such an example, the specific layout projected onto the gaming surface <b>1202</b> may be changeable, enabling the gaming table <b>1200</b> to be used to administer different variations of wagering games within the scope of this disclosure or other wagering games. In either example, the gaming surface <b>1202</b> may include, for example, designated areas for player positions; areas in which one or more of player cards, dealer cards, or community cards may be dealt; areas in which wagers may be accepted; areas in which wagers may be grouped into pots; and areas in which rules, pay tables, and other instructions related to the wagering game may be displayed. As a specific, nonlimiting example, the gaming surface <b>1202</b> may be configured as any table surface described herein.</p><p id="p-0088" num="0087">In some embodiments, the gaming table <b>1200</b> may include a display <b>1210</b> separate from the gaming surface <b>1202</b>. The display <b>1210</b> may be configured to face players, prospective players, and spectators and may display, for example, information randomly selected by a shuffler device and also displayed on a display of the shuffler device; rules; pay tables; real-time game status, such as wagers accepted and cards dealt; historical game information, such as amounts won, amounts wagered, percentage of hands won, and notable hands achieved; the commercial game name, the casino name, advertising and other instructions and information related to the wagering game. The display <b>1210</b> may be a physically fixed display, such as an edge lit sign, in some embodiments. In other embodiments, the display <b>1210</b> may change automatically in response to a stimulus (e.g., may be an electronic video monitor).</p><p id="p-0089" num="0088">The gaming table <b>1200</b> may include particular machines and apparatuses configured to facilitate the administration of the wagering game. For example, the gaming table <b>1200</b> may include one or more card-handling devices <b>1204</b>A, <b>1204</b>B. The card-handling device <b>1204</b>A may be, for example, a shoe from which physical cards <b>1206</b> from one or more decks of intermixed playing cards may be withdrawn, one at a time. Such a card-handling device <b>1204</b>A may include, for example, a housing in which cards <b>1206</b> are located, an opening from which cards <b>1206</b> are removed, and a card-presenting mechanism (e.g., a moving weight on a ramp configured to push a stack of cards down the ramp) configured to continually present new cards <b>1206</b> for withdrawal from the shoe.</p><p id="p-0090" num="0089">In some embodiments in which the card-handling device <b>1204</b>A is used, the card-handling device <b>1204</b>A may include a random number generator <b>151</b> and the display <b>152</b>, in addition to or rather than such features being included in a shuffler device. In addition to the card-handling device <b>1204</b>A, the card-handling device <b>1204</b>B may be included. The card-handling device <b>1204</b>B may be, for example, a shuffler configured to select information (using a random number generator), to display the selected information on a display of the shuffler, to reorder (either randomly or pseudo-randomly) physical playing cards <b>1206</b> from one or more decks of playing cards, and to present randomized cards <b>1206</b> for use in the wagering game. Such a card-handling device <b>1204</b>B may include, for example, a housing, a shuffling mechanism configured to shuffle cards, and card inputs and outputs (e.g., trays). Shufflers may include card recognition capability that can form a randomly ordered set of cards within the shuffler. The card-handling device <b>1204</b> may also be, for example, a combination shuffler and shoe in which the output for the shuffler is a shoe.</p><p id="p-0091" num="0090">In some embodiments, the card-handling device <b>1204</b> may be configured and programmed to administer at least a portion of a wagering game being played utilizing the card-handling device <b>1204</b>. For example, the card-handling device <b>1204</b> may be programmed and configured to randomize a set of cards and deliver cards individually for use according to game rules and player and or dealer game play elections. More specifically, the card-handling device <b>1204</b> may be programmed and configured to, for example, randomize a set of six complete decks of cards including one or more standard 52-card decks of playing cards and, optionally, any specialty cards (e.g., a cut card, bonus cards, wild cards, or other specialty cards). In some embodiments, the card-handling device <b>1204</b> may present individual cards, one at a time, for withdrawal from the card-handling device <b>1204</b>. In other embodiments, the card-handling device <b>1204</b> may present an entire shuffled block of cards that are transferred manually or automatically into a card dispensing shoe <b>1204</b>. In some such embodiments, the card-handling device <b>1204</b> may accept dealer input, such as, for example, a number of replacement cards for discarded cards, a number of hit cards to add, or a number of partial hands to be completed. In other embodiments, the device may accept a dealer input from a menu of game options indicating a game selection, which will select programming to cause the card-handling device <b>1204</b> to deliver the requisite number of cards to the game according to game rules, player decisions and dealer decisions. In still other embodiments, the card-handling device <b>1204</b> may present the complete set of randomized cards for manual or automatic withdrawal from a shuffler and then insertion into a shoe. As specific, nonlimiting examples, the card-handling device <b>1204</b> may present a complete set of cards to be manually or automatically transferred into a card dispensing shoe, or may provide a continuous supply of individual cards.</p><p id="p-0092" num="0091">In another embodiment, the card handling device may be a batch shuffler, such as by randomizing a set of cards using a gripping, lifting, and insertion sequence.</p><p id="p-0093" num="0092">In some embodiments, the card-handling device <b>1204</b> may employ a random number generator device to determine card order, such as, for example, a final card order or an order of insertion of cards into a compartment configured to form a packet of cards. The compartments may be sequentially numbered, and a random number assigned to each compartment number prior to delivery of the first card. In other embodiments, the random number generator may select a location in the stack of cards to separate the stack into two sub-stacks, creating an insertion point within the stack at a random location. The next card may be inserted into the insertion point. In yet other embodiments, the random number generator may randomly select a location in a stack to randomly remove cards by activating an ejector.</p><p id="p-0094" num="0093">Regardless of whether the random number generator (or generators) is hardware or software, it may be used to implement specific game administrations methods of the present disclosure.</p><p id="p-0095" num="0094">The card-handling device <b>1204</b> may simply be supported on the gaming surface <b>1202</b> in some embodiments. In other embodiments, the card-handling device <b>1204</b> may be mounted into the gaming table <b>1202</b> such that the card-handling device <b>1204</b> is not manually removable from the gaming table <b>1202</b> without the use of tools. In some embodiments, the deck or decks of playing cards used may be standard, 52-card decks. In other embodiments, the deck or decks used may include cards, such as, for example, jokers, wild cards, bonus cards, etc. The shuffler may also be configured to handle and dispense security cards, such as cut cards.</p><p id="p-0096" num="0095">In some embodiments, the card-handling device <b>1204</b> may include an electronic display <b>1207</b> for displaying information related to the wagering game being administered. The electronic display <b>1207</b> may display a menu of game options, the name of the game selected, the number of cards per hand to be dispensed, acceptable amounts for other wagers (e.g., maximums and minimums), numbers of cards to be dealt to recipients, locations of particular recipients for particular cards, winning and losing wagers, pay tables, winning hands, losing hands, and payout amounts. In other embodiments, information related to the wagering game may be displayed on another electronic display, such as, for example, the display <b>1210</b> described previously.</p><p id="p-0097" num="0096">The type of card-handling device <b>1204</b> employed to administer embodiments of the disclosed wagering game, as well as the type of card deck employed and the number of decks, may be specific to the game to be implemented. Cards used in games of this disclosure may be, for example, standard playing cards from one or more decks, each deck having cards of four suits (clubs, hearts, diamonds, and spades) and of rankings ace, king, queen, jack, and ten through two in descending order. As a more specific example, six, seven, or eight standard decks of such cards may be intermixed. Typically, six or eight decks of 52 standard playing cards each may be intermixed and formed into a set to administer a blackjack or blackjack variant game. After shuffling, the randomized set may be transferred into another portion of the card-handling device <b>1204</b>B or another card-handling device <b>1204</b>A altogether, such as a mechanized shoe capable of reading card rank and suit.</p><p id="p-0098" num="0097">The gaming table <b>1200</b> may include one or more chip racks <b>1208</b> configured to facilitate accepting wagers, transferring lost wagers to the house, and exchanging monetary value for wagering elements <b>1212</b> (e.g., chips). For example, the chip rack <b>1208</b> may include a series of token support rows, each of which may support tokens of a different type (e.g., color and denomination). In some embodiments, the chip rack <b>1208</b> may be configured to automatically present a selected number of chips using a chip-cutting-and-delivery mechanism. In some embodiments, the gaming table <b>1200</b> may include a drop box <b>1214</b> for money that is accepted in exchange for wagering elements or chips <b>1212</b>. The drop box <b>1214</b> may be, for example, a secure container (e.g., a safe or lockbox) having a one-way opening into which money may be inserted and a secure, lockable opening from which money may be retrieved. Such drop boxes <b>1214</b> are known in the art, and may be incorporated directly into the gaming table <b>1200</b> and may, in some embodiments, have a removable container for the retrieval of money in a separate, secure location.</p><p id="p-0099" num="0098">When administering a wagering game in accordance with embodiments of this disclosure, a dealer <b>1216</b> may receive money (e.g., cash) from a player in exchange for wagering elements <b>1212</b>. The dealer <b>1216</b> may deposit the money in the drop box <b>1214</b> and transfer physical wagering elements <b>1212</b> to the player. As part of the method of administering the game, the dealer <b>1216</b> may accept one or more initial wagers from the player, which may be reflected by the dealer <b>1216</b> permitting the player to place one or more wagering elements <b>1212</b> or other wagering tokens (e.g., cash) within designated areas on the gaming surface <b>1202</b> associated with the various wagers of the wagering game. Once initial wagers have been accepted, the dealer <b>1216</b> may remove physical cards <b>1206</b> from the card-handling device <b>1204</b> (e.g., individual cards, packets of cards, or the complete set of cards) in some embodiments. In other embodiments, the physical cards <b>1206</b> may be hand-pitched (i.e., the dealer <b>1216</b> may optionally shuffle the cards <b>1206</b> to randomize the set and may hand-deal cards <b>1206</b> from the randomized set of cards). The dealer <b>1216</b> may position cards <b>1206</b> within designated areas on the gaming surface <b>1202</b>, which may designate the cards <b>1206</b> for use as individual player cards, community cards, or dealer cards in accordance with game rules. House rules may require the dealer to accept both main and secondary wagers before card distribution. House rules may alternatively allow the player to place only one wager (i.e., the second wager) during card distribution and after the initial wagers have been placed, or after card distribution but before all cards available for play are revealed.</p><p id="p-0100" num="0099">In some embodiments, after dealing the cards <b>1206</b>, and during play, according to the game rules, any additional wagers (e.g., the play wager) may be accepted, which may be reflected by the dealer <b>1216</b> permitting the player to place one or more wagering elements <b>1212</b> within the designated area (i.e., area <b>124</b>) on the gaming surface <b>1202</b> associated with the play wager of the wagering game. The dealer <b>1216</b> may perform any additional card dealing according to the game rules. Finally, the dealer <b>1216</b> may resolve the wagers, award winning wagers to the players, which may be accomplished by giving wagering elements <b>1212</b> from the chip rack <b>1208</b> to the players, and transferring losing wagers to the house, which may be accomplished by moving wagering elements <b>1212</b> from the player designated wagering areas to the chip rack <b>1208</b>.</p><p id="p-0101" num="0100"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a perspective view of an individual electronic gaming device <b>1300</b> (e.g., an electronic gaming machine (EGM)) configured for implementing wagering games according to this disclosure. The individual electronic gaming device <b>1300</b> may include an individual player position <b>1314</b> including a player input area <b>1332</b> configured to enable a player to interact with the individual electronic gaming device <b>1300</b> through various input devices (e.g., buttons, levers, touchscreens). The player input area <b>1332</b> may further includes a cash- or ticket-in receptor, by which cash or a monetary-valued ticket may be fed, by the player, to the individual electronic gaming device <b>1300</b>, which may then detect, in association with game-logic circuitry in the individual electronic gaming device <b>1300</b>, the physical item (cash or ticket) associated with the monetary value and then establish a credit balance for the player. In other embodiments, the individual electronic gaming device <b>1300</b> detects a signal indicating an electronic wager was made. Wagers may then be received, and covered by the credit balance, upon the player using the player input area <b>1332</b> or elsewhere on the machine (such as through a touch screen). Won payouts and pushed or returned wagers may be reflected in the credit balance at the end of the round, the credit balance being increased to reflect won payouts and pushed or returned wagers and/or decreased to reflect lost wagers.</p><p id="p-0102" num="0101">The individual electronic gaming device <b>1300</b> may further include, in the individual player position <b>1312</b>, a ticket-out printer or monetary dispenser through which a payout from the credit balance may be distributed to the player upon receipt of a cashout instruction, input by the player using the player input area <b>1332</b>.</p><p id="p-0103" num="0102">The individual electronic gaming device <b>1300</b> may include a gaming screen <b>1374</b> configured to display indicia for interacting with the individual electronic gaming device <b>1300</b>, such as through processing one or more programs stored in game-logic circuitry providing memory <b>1340</b> to implement the rules of game play at the individual electronic gaming device <b>1300</b>. Accordingly, in some embodiments, game play may be accommodated without involving physical playing cards, chips or other wagering elements, and live personnel. The action may instead be simulated by a control processor <b>1350</b> operably coupled to the memory <b>1340</b> and interacting with and controlling the individual electronic gaming device <b>1300</b>. For example, the processor may cause the display <b>1374</b> to display cards, including virtual player and virtual dealer cards for playing games of the present disclosure.</p><p id="p-0104" num="0103">Although the individual electronic gaming device <b>1300</b> displayed in <figref idref="DRAWINGS">FIG. <b>11</b></figref> has an outline of a traditional gaming cabinet, the individual electronic gaming device <b>1300</b> may be implemented in other ways, such as, for example, on a bartop gaming terminal, through client software downloaded to a portable device, such as a smart phone, tablet, or laptop computer. The individual electronic gaming device <b>1300</b> may also be a non-portable personal computer (e.g., a desktop or all-in-one computer) or other computing device. In some embodiments, client software is not downloaded but is native to the device or is otherwise delivered with the device when distributed. In such embodiments, the credit balance may be established by receiving payment via credit card or player's account information input into the system by the player. Cashouts of the credit balance may be allotted to a player's account or card.</p><p id="p-0105" num="0104">A communication device <b>1360</b> may be included and operably coupled to the processor <b>1350</b> such that information related to operation of the individual electronic gaming device <b>1300</b>, information related to the game play, or combinations thereof may be communicated between the individual electronic gaming device <b>1300</b> and other devices, such as a server, through a suitable communication medium, such, as, for example, wired networks, Wi-Fi networks, and cellular communication networks.</p><p id="p-0106" num="0105">The gaming screen <b>1374</b> may be carried by a generally vertically extending cabinet <b>1376</b> of the individual electronic gaming device <b>1300</b>. The individual electronic gaming device <b>1300</b> may further include banners to communicate rules of game play, instructions, game play advice or hints and the like, such as along a top portion <b>1378</b> of the cabinet <b>1376</b> of the individual electronic gaming device <b>1300</b>. The individual electronic gaming device <b>1300</b> may further include additional decorative lights (not shown), and speakers (not shown) for transmitting and optionally receiving sounds during game play.</p><p id="p-0107" num="0106">Some embodiments may be implemented at locations including a plurality of player stations. Such player stations may include an electronic display screen for display of game information (e.g., cards, wagers, and game instructions) and for accepting wagers and facilitating credit balance adjustments. Such player stations may, optionally, be integrated in a table format, may be distributed throughout a casino or other gaming site, or may include both grouped and distributed player stations.</p><p id="p-0108" num="0107"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a top view of a suitable table <b>1010</b> configured for implementing wagering games according to this disclosure. The table <b>1010</b> may include a playing surface <b>1404</b>. The table <b>1010</b> may include electronic player stations <b>1412</b>. Each player station <b>1412</b> may include a player interface <b>1416</b>, which may be used for displaying game information (e.g., graphics illustrating a player layout, game instructions, input options, wager information, game outcomes, etc.) and accepting player elections. The player interface <b>1416</b> may be a display screen in the form of a touch screen, which may be at least substantially flush with the playing surface <b>1404</b> in some embodiments. Each player interface <b>1416</b> may be operated by its own local game processor <b>1414</b> (shown in dashed lines), although, in some embodiments, a central game processor <b>1428</b> (shown in dashed lines) may be employed and may communicate directly with player interfaces <b>1416</b>. In some embodiments, a combination of individual local game processors <b>1414</b> and the central game processor <b>1428</b> may be employed. Each of the processors <b>1414</b> and <b>1428</b> may be operably coupled to memory including one or more programs related to the rules of game play at the table <b>1010</b>.</p><p id="p-0109" num="0108">A communication device <b>1460</b> may be included and may be operably coupled to one or more of the local game processors <b>1414</b>, the central game processor <b>1428</b>, or combinations thereof, such that information related to operation of the table <b>1010</b>, information related to the game play, or combinations thereof may be communicated between the table <b>1010</b> and other devices through a suitable communication medium, such as, for example, wired networks, Wi-Fi networks, and cellular communication networks.</p><p id="p-0110" num="0109">The table <b>1010</b> may further include additional features, such as a dealer chip tray <b>1420</b>, which may be used by the dealer to cash players in and out of the wagering game, whereas wagers and balance adjustments during game play may be performed using, for example, virtual chips (e.g., images or text representing wagers). For embodiments using physical cards <b>1406</b><i>a </i>and <b>1406</b><i>b, </i>the table <b>1010</b> may further include a card-handling device <b>1422</b> such as a card shoe configured to read and deliver cards that have already been randomized. For embodiments using virtual cards, the virtual cards may be displayed at the individual player interfaces <b>1416</b>. Physical playing cards designated as &#x201c;common cards&#x201d; may be displayed in a common card area.</p><p id="p-0111" num="0110">The table <b>1010</b> may further include a dealer interface <b>1418</b>, which, like the player interfaces <b>1416</b>, may include touch screen controls for receiving dealer inputs and assisting the dealer in administering the wagering game. The table <b>1010</b> may further include an upright display <b>1430</b> configured to display images that depict game information, pay tables, hand counts, historical win/loss information by player, and a wide variety of other information considered useful to the players. The upright display <b>1430</b> may be double sided to provide such information to players as well as to casino personnel.</p><p id="p-0112" num="0111">Although an embodiment is described showing individual discrete player stations, in some embodiments, the entire playing surface <b>1404</b> may be an electronic display that is logically partitioned to permit game play from a plurality of players for receiving inputs from, and displaying game information to, the players, the dealer, or both.</p><p id="p-0113" num="0112"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a perspective view of another embodiment of a suitable electronic multi-player table <b>1500</b> configured for implementing wagering games according to the present disclosure utilizing a virtual dealer. The table <b>1500</b> may include player positions <b>1514</b> arranged in a bank about an arcuate edge <b>1520</b> of a video device <b>1558</b> that may comprise a card screen <b>1564</b> and a virtual dealer screen <b>1560</b>. The dealer screen <b>1560</b> may display a video simulation of the dealer (i.e., a virtual dealer) for interacting with the video device <b>1558</b>, such as through processing one or more stored programs stored in memory <b>1595</b> to implement the rules of game play at the video device <b>1558</b>. The dealer screen <b>1560</b> may be carried by a generally vertically extending cabinet <b>1562</b> of the video device <b>1558</b>. The substantially horizontal card screen <b>1564</b> may be configured to display at least one or more of the dealer's cards, any community cards, and each player's cards dealt by the virtual dealer on the dealer screen <b>1560</b>.</p><p id="p-0114" num="0113">Each of the player positions <b>1514</b> may include a player interface area <b>1532</b> configured for wagering and game play interactions with the video device <b>1558</b> and virtual dealer. Accordingly, game play may be accommodated without involving physical playing cards, poker chips, and live personnel. The action may instead be simulated by a control processor <b>1597</b> interacting with and controlling the video device <b>1558</b>. The control processor <b>1597</b> may be programmed, by known techniques, to implement the rules of game play at the video device <b>1558</b>. As such, the control processor <b>1597</b> may interact and communicate with display/input interfaces and data entry inputs for each player interface area <b>1532</b> of the video device <b>1558</b>. Other embodiments of tables and gaming devices may include a control processor that may be similarly adapted to the specific configuration of its associated device.</p><p id="p-0115" num="0114">A communication device <b>1599</b> may be included and operably coupled to the control processor <b>1597</b> such that information related to operation of the table <b>1500</b>, information related to the game play, or combinations thereof may be communicated between the table <b>1500</b> and other devices, such as a central server, through a suitable communication medium, such, as, for example, wired networks, Wi-Fi networks, and cellular communication networks.</p><p id="p-0116" num="0115">The video device <b>1558</b> may further include banners communicating rules of play and the like, which may be located along one or more walls <b>1570</b> of the cabinet <b>1562</b>. The video device <b>1558</b> may further include additional decorative lights and speakers, which may be located on an underside surface <b>1566</b>, for example, of a generally horizontally extending top <b>1568</b> of the cabinet <b>1562</b> of the video device <b>1558</b> generally extending toward the player positions <b>1514</b>.</p><p id="p-0117" num="0116">Although an embodiment is described showing individual discrete player stations, in some embodiments, the entire playing surface (e.g., player interface areas <b>1532</b>, card screen <b>1564</b>, etc.) may be a unitary electronic display that is logically partitioned to permit game play from a plurality of players for receiving inputs from, and displaying game information to, the players, the dealer, or both.</p><p id="p-0118" num="0117">In some embodiments, wagering games in accordance with this disclosure may be administered using a gaming system employing a client&#x2014;server architecture (e.g., over the Internet, a local area network, etc.). <figref idref="DRAWINGS">FIG. <b>14</b></figref> is a schematic block diagram of an illustrative gaming system <b>1600</b> for implementing wagering games according to this disclosure. The gaming system <b>1600</b> may enable end users to remotely access game content. Such game content may include, without limitation, various types of wagering games such as card games, dice games, big wheel games, roulette, scratch off games (&#x201c;scratchers&#x201d;), and any other wagering game where the game outcome is determined, in whole or in part, by one or more random events. This includes, but is not limited to, Class II and Class III games as defined under 25 U.S.C. &#xa7; 2701 et seq. (&#x201c;Indian Gaming Regulatory Act&#x201d;). Such games may include banked and/or non-banked games.</p><p id="p-0119" num="0118">The wagering games supported by the gaming system <b>1600</b> may be operated with real currency or with virtual credits or other virtual (e.g., electronic) value indicia. For example, the real currency option may be used with traditional casino and lottery-type wagering games in which money or other items of value are wagered and may be cashed out at the end of a game session. The virtual credits option may be used with wagering games in which credits (or other symbols) may be issued to a player to be used for the wagers. A player may be credited with credits in any way allowed, including, but not limited to, a player purchasing credits; being awarded credits as part of a contest or a win event in this or another game (including non-wagering games); being awarded credits as a reward for use of a product, casino, or other enterprise, time played in one session, or games played; or may be as simple as being awarded virtual credits upon logging in at a particular time or with a particular frequency, etc. Although credits may be won or lost, the ability of the player to cash out credits may be controlled or prevented. In one example, credits acquired (e.g., purchased or awarded) for use in a play-for-fun game may be limited to non-monetary redemption items, awards, or credits usable in the future or for another game or gaming session. The same credit redemption restrictions may be applied to some or all of credits won in a wagering game as well.</p><p id="p-0120" num="0119">An additional variation includes web-based sites having both play-for-fun and wagering games, including issuance of free (non-monetary) credits usable to play the play-for-fun games. This feature may attract players to the site and to the games before they engage in wagering. In some embodiments, a limited number of free or promotional credits may be issued to entice players to play the games. Another method of issuing credits includes issuing free credits in exchange for identifying friends who may want to play. In another embodiment, additional credits may be issued after a period of time has elapsed to encourage the player to resume playing the game. The gaming system <b>1600</b> may enable players to buy additional game credits to allow the player to resume play. Objects of value may be awarded to play-for-fun players, which may or may not be in a direct exchange for credits. For example, a prize may be awarded or won for a highest scoring play-for-fun player during a defined time interval. All variations of credit redemption are contemplated, as desired by game designers and game hosts (the person or entity controlling the hosting systems).</p><p id="p-0121" num="0120">The gaming system <b>1600</b> may include a gaming platform to establish a portal for an end user to access a wagering game hosted by one or more gaming servers <b>1610</b> over a network <b>1630</b>. In some embodiments, games are accessed through a user interaction service <b>1612</b>. The gaming system <b>1600</b> enables players to interact with a user device <b>1620</b> through a user input device <b>1624</b> and a display <b>1622</b> and to communicate with one or more gaming servers <b>1610</b> using a network <b>1630</b> (e.g., the Internet). Typically, the user device is remote from the gaming server <b>1610</b> and the network is the word-wide web (i.e., the Internet).</p><p id="p-0122" num="0121">In some embodiments, the gaming servers <b>1610</b> may be configured as a single server to administer wagering games in combination with the user device <b>1620</b>. In other embodiments, the gaming servers <b>1610</b> may be configured as separate servers for performing separate, dedicated functions associated with administering wagering games. Accordingly, the following description also discusses &#x201c;services&#x201d; with the understanding that the various services may be performed by different servers or combinations of servers in different embodiments. As shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, the gaming servers <b>1610</b> may include a user interaction service <b>1612</b>, a game service <b>1616</b>, and an asset service <b>1614</b>. In some embodiments, one or more of the gaming servers <b>1610</b> may communicate with an account server <b>1632</b> performing an account service <b>1632</b>. As explained more fully below, for some wagering type games, the account service <b>1632</b> may be separate and operated by a different entity than the gaming servers <b>1610</b>; however, in some embodiments the account service <b>1632</b> may also be operated by one or more of the gaming servers <b>1610</b>.</p><p id="p-0123" num="0122">The user device <b>1620</b> may communicate with the user interaction service <b>1612</b> through the network <b>1630</b>. The user interaction service <b>1612</b> may communicate with the game service <b>1616</b> and provide game information to the user device <b>1620</b>. In some embodiments, the game service <b>1616</b> may also include a game engine. The game engine may, for example, access, interpret, and apply game rules. In some embodiments, a single user device <b>1620</b> communicates with a game provided by the game service <b>1616</b>, while other embodiments may include a plurality of user devices <b>1620</b> configured to communicate and provide end users with access to the same game provided by the game service <b>1616</b>. In addition, a plurality of end users may be permitted to access a single user interaction service <b>1612</b>, or a plurality of user interaction services <b>1612</b>, to access the game service <b>1616</b>. The user interaction service <b>1612</b> may enable a user to create and access a user account and interact with game service <b>1616</b>. The user interaction service <b>1612</b> may enable users to initiate new games, join existing games, and interface with games being played by the user.</p><p id="p-0124" num="0123">The user interaction service <b>1612</b> may also provide a client for execution on the user device <b>1620</b> for accessing the gaming servers <b>1610</b>. The client provided by the gaming servers <b>1610</b> for execution on the user device <b>1620</b> may be any of a variety of implementations depending on the user device <b>1620</b> and method of communication with the gaming servers <b>1610</b>. In one embodiment, the user device <b>1620</b> may connect to the gaming servers <b>1610</b> using a web browser, and the client may execute within a browser window or frame of the web browser. In another embodiment, the client may be a stand-alone executable on the user device <b>1620</b>.</p><p id="p-0125" num="0124">For example, the client may comprise a relatively small amount of script (e.g., JAVASCRIPT&#xae;), also referred to as a &#x201c;script driver,&#x201d; including scripting language that controls an interface of the client. The script driver may include simple function calls requesting information from the gaming servers <b>1610</b>. In other words, the script driver stored in the client may merely include calls to functions that are externally defined by, and executed by, the gaming servers <b>1610</b>. As a result, the client may be characterized as a &#x201c;thin client.&#x201d; The client may simply send requests to the gaming servers <b>1610</b> rather than performing logic itself. The client may receive player inputs, and the player inputs may be passed to the gaming servers <b>1610</b> for processing and executing the wagering game. In some embodiments, this may involve providing specific graphical display information for the display <b>1622</b> as well as game outcomes.</p><p id="p-0126" num="0125">As another example, the client may comprise an executable file rather than a script. The client may do more local processing than does a script driver, such as calculating where to show what game symbols upon receiving a game outcome from the game service <b>1616</b> through user interaction service <b>1612</b>. In some embodiments, portions of an asset service <b>1614</b> may be loaded onto the client and may be used by the client in processing and updating graphical displays. Some form of data protection, such as end-to-end encryption, may be used when data is transported over the network <b>1630</b>. The network <b>1630</b> may be any network, such as, for example, the Internet or a local area network.</p><p id="p-0127" num="0126">The gaming servers <b>1610</b> may include an asset service <b>1614</b>, which may host various media assets (e.g., text, audio, video, and image files) to send to the user device <b>1620</b> for presenting the various wagering games to the end user. In other words, the assets presented to the end user may be stored separately from the user device <b>1620</b>. For example, the user device <b>1620</b> requests the assets appropriate for the game played by the user; as another example, especially relating to thin clients, just those assets that are needed for a particular display event will be sent by the gaming servers <b>1610</b>, including as few as one asset. The user device <b>1620</b> may call a function defined at the user interaction service <b>1612</b> or asset service <b>1614</b>, which may determine which assets are to be delivered to the user device <b>1620</b> as well as how the assets are to be presented by the user device <b>1620</b> to the end user. Different assets may correspond to the various user devices <b>1620</b> and their clients that may have access to the game service <b>1616</b> and to different variations of wagering games.</p><p id="p-0128" num="0127">The gaming servers <b>1610</b> may include the game service <b>1616</b>, which may be programmed to administer wagering games and determine game play outcomes to provide to the user interaction service <b>1612</b> for transmission to the user device <b>1620</b>. For example, the game service <b>1616</b> may include game rules for one or more wagering games, such that the game service <b>1616</b> controls some or all of the game flow for a selected wagering game as well as the determined game outcomes. The game service <b>1616</b> may include pay tables and other game logic. The game service <b>1616</b> may perform random number generation for determining random game elements of the wagering game. In one embodiment, the game service <b>1616</b> may be separated from the user interaction service <b>1612</b> by a firewall or other method of preventing unauthorized access to the game service <b>1612</b> by the general members of the network <b>1630</b>.</p><p id="p-0129" num="0128">The user device <b>1620</b> may present a gaming interface to the player and communicate the user interaction from the user input device <b>1624</b> to the gaming servers <b>1610</b>. The user device <b>1620</b> may be any electronic system capable of displaying gaming information, receiving user input, and communicating the user input to the gaming servers <b>1610</b>. For example, the user device <b>1620</b> may be a desktop computer, a laptop, a tablet computer, a set-top box, a mobile device (e.g., a smartphone), a kiosk, a terminal, or another computing device. As a specific, nonlimiting example, the user device <b>1620</b> operating the client may be an interactive electronic gaming system <b>1300</b>. The client may be a specialized application or may be executed within a generalized application capable of interpreting instructions from an interactive gaming system, such as a web browser.</p><p id="p-0130" num="0129">The client may interface with an end user through a web page or an application that runs on a device including, but not limited to, a smartphone, a tablet, or a general computer, or the client may be any other computer program configurable to access the gaming servers <b>1610</b>. The client may be illustrated within a casino webpage (or other interface) indicating that the client is embedded into a webpage, which is supported by a web browser executing on the user device <b>1620</b>.</p><p id="p-0131" num="0130">In some embodiments, components of the gaming system <b>1600</b> may be operated by different entities. For example, the user device <b>1620</b> may be operated by a third party, such as a casino or an individual, that links to the gaming servers <b>1610</b>, which may be operated, for example, by a wagering game service provider. Therefore, in some embodiments, the user device <b>1620</b> and client may be operated by a different administrator than the operator of the game service <b>1616</b>. In other words, the user device <b>1620</b> may be part of a third-party system that does not administer or otherwise control the gaming servers <b>1610</b> or game service <b>1616</b>. In other embodiments, the user interaction service <b>1612</b> and asset service <b>1614</b> may be operated by a third-party system. For example, a gaming entity (e.g., a casino) may operate the user interaction service <b>1612</b>, user device <b>1620</b>, or combination thereof to provide its customers access to game content managed by a different entity that may control the game service <b>1616</b>, amongst other functionality. In still other embodiments, all functions may be operated by the same administrator. For example, a gaming entity (e.g., a casino) may elect to perform each of these functions in-house, such as providing access to the user device <b>1620</b>, delivering the actual game content, and administering the gaming system <b>1600</b>.</p><p id="p-0132" num="0131">The gaming servers <b>1610</b> may communicate with one or more external account servers <b>1632</b> (also referred to herein as an account service <b>1632</b>), optionally through another firewall. For example, the gaming servers <b>1610</b> may not directly accept wagers or issue payouts. That is, the gaming servers <b>1610</b> may facilitate online casino gaming but may not be part of self-contained online casino itself Another entity (e.g., a casino or any account holder or financial system of record) may operate and maintain its external account service <b>1632</b> to accept bets and make payout distributions. The gaming servers <b>1610</b> may communicate with the account service <b>1632</b> to verify the existence of funds for wagering and to instruct the account service <b>1632</b> to execute debits and credits. As another example, the gaming servers <b>1610</b> may directly accept bets and make payout distributions, such as in the case where an administrator of the gaming servers <b>1610</b> operates as a casino.</p><p id="p-0133" num="0132">Additional features may be supported by the gaming servers <b>1610</b>, such as hacking and cheating detection, data storage and archival, metrics generation, messages generation, output formatting for different end user devices, as well as other features and operations.</p><p id="p-0134" num="0133"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a schematic block diagram of a table <b>1682</b> for implementing wagering games including a live dealer video feed. Features of the gaming system <b>1600</b> (see <figref idref="DRAWINGS">FIG. <b>14</b></figref>) described above in connection with <figref idref="DRAWINGS">FIG. <b>14</b></figref> may be utilized in connection with this embodiment, except as further described. Rather than cards being determined by computerized random processes, physical cards (e.g., from a standard, 52-card deck of playing cards) may be dealt by a live dealer <b>1680</b> at a table <b>1682</b> from a card-handling system <b>1684</b> located in a studio or on a casino floor. A table manager <b>1686</b> may assist the dealer <b>1680</b> in facilitating play of the game by transmitting a live video feed of the dealer's actions to the user device <b>1620</b> and transmitting remote player elections to the dealer <b>1680</b>. As described above, the table manager <b>1686</b> may act as or communicate with a gaming system <b>1600</b> (see <figref idref="DRAWINGS">FIG. <b>14</b></figref>) (e.g., acting as the gaming system <b>1600</b> (see <figref idref="DRAWINGS">FIG. <b>14</b></figref>) itself or as an intermediate client interposed between and operationally connected to the user device <b>1620</b> and the gaming system <b>1600</b> (see <figref idref="DRAWINGS">FIG. <b>14</b></figref>)) to provide gaming at the table <b>1682</b> to users of the gaming system <b>1600</b> (see <figref idref="DRAWINGS">FIG. <b>14</b></figref>). Thus, the table manager <b>1686</b> may communicate with the user device <b>1620</b> through a network <b>1630</b> (see <figref idref="DRAWINGS">FIG. <b>14</b></figref>), and may be a part of a larger online casino, or may be operated as a separate system facilitating game play. In various embodiments, each table <b>1682</b> may be managed by an individual table manager <b>1686</b> constituting a gaming device, which may receive and process information relating to that table. For simplicity of description, these functions are described as being performed by the table manager <b>1686</b>, though certain functions may be performed by an intermediary gaming system <b>1600</b> (see <figref idref="DRAWINGS">FIG. <b>14</b></figref>), such as the one shown and described in connection with <figref idref="DRAWINGS">FIG. <b>14</b></figref>. In some embodiments, the gaming system <b>1600</b> (see <figref idref="DRAWINGS">FIG. <b>14</b></figref>) may match remotely located players to tables <b>1682</b> and facilitate transfer of information between user devices <b>1620</b> and tables <b>1682</b>, such as wagering amounts and player option elections, without managing gameplay at individual tables. In other embodiments, functions of the table manager <b>1686</b> may be incorporated into a gaming system <b>1600</b> (see <figref idref="DRAWINGS">FIG. <b>14</b></figref>).</p><p id="p-0135" num="0134">The table <b>1682</b> includes a camera <b>1670</b> and optionally a microphone <b>1672</b> to capture video and audio feeds relating to the table <b>1682</b>. The camera <b>1670</b> may be trained on the live dealer <b>1680</b>, play area <b>1687</b>, and card-handling system <b>1684</b>. As the game is administered by the live dealer <b>1680</b>, the video feed captured by the camera <b>1670</b> may be shown to the player remotely using the user device <b>1620</b>, and any audio captured by the microphone <b>1672</b> may be played to the player remotely using the user device <b>1620</b>. In some embodiments, the user device <b>1620</b> may also include a camera, microphone, or both, which may also capture feeds to be shared with the dealer <b>1680</b> and other players. In some embodiments, the camera <b>1670</b> may be trained to capture images of the card faces, chips, and chip stacks on the surface of the gaming table. Known image extraction techniques may be used to obtain card count and card rank and suit information from the card images.</p><p id="p-0136" num="0135">Card and wager data in some embodiments may be used by the table manager <b>1686</b> to determine game outcome. The data extracted from the camera <b>1670</b> may be used to confirm the card data obtained from the card-handling system <b>1684</b>, to determine a player position that received a card, and for general security monitoring purposes, such as detecting player or dealer card switching, for example. Examples of card data include, for example, suit and rank information of a card, suit and rank information of each card in a hand, rank information of a hand, and rank information of every hand in a round of play.</p><p id="p-0137" num="0136">The live video feed permits the dealer to show cards dealt by the card-handling system <b>1684</b> and play the game as though the player were at a gaming table, playing with other players in a live casino. In addition, the dealer can prompt a user by announcing a player's election is to be performed. In embodiments where a microphone <b>1672</b> is included, the dealer <b>1680</b> can verbally announce action or request an election by a player. In some embodiments, the user device <b>1620</b> also includes a camera or microphone, which also captures feeds to be shared with the dealer <b>1680</b> and other players.</p><p id="p-0138" num="0137">The card-handling system <b>1684</b> may be as shown and was described previously. The play area <b>1686</b> depicts player layouts for playing the game. As determined by the rules of the game, the player at the user device <b>1620</b> may be presented options for responding to an event in the game using a client as described with reference to <figref idref="DRAWINGS">FIG. <b>14</b></figref>.</p><p id="p-0139" num="0138">Player elections may be transmitted to the table manager <b>1686</b>, which may display player elections to the dealer <b>1680</b> using a dealer display <b>1688</b> and player action indicator <b>1690</b> on the table <b>1682</b>. For example, the dealer display <b>1688</b> may display information regarding where to deal the next card or which player position is responsible for the next action.</p><p id="p-0140" num="0139">In some embodiments, the table manager <b>1686</b> may receive card information from the card-handling system <b>1684</b> to identify cards dealt by the card-handling system <b>1684</b>. For example, the card-handling system <b>1684</b> may include a card reader to determine card information from the cards. The card information may include the rank and suit of each dealt card and hand information.</p><p id="p-0141" num="0140">The table manager <b>1686</b> may apply game rules to the card information, along with the accepted player decisions, to determine gameplay events and wager results. Alternatively, the wager results may be determined by the dealer <b>1680</b> and input to the table manager <b>1686</b>, which may be used to confirm automatically determined results by the gaming system.</p><p id="p-0142" num="0141">Card and wager data in some embodiments may be used by the table manager <b>1686</b> to determine game outcome. The data extracted from the camera <b>1670</b> may be used to confirm the card data obtained from the card-handling system <b>1684</b>, to determine a player position that received a card, and for general security monitoring purposes, such as detecting player or dealer card switching, for example.</p><p id="p-0143" num="0142">The live video feed permits the dealer to show cards dealt by the card-handling system <b>1684</b> and play the game as though the player were at a live casino. In addition, the dealer can prompt a user by announcing a player's election is to be performed. In embodiments where a microphone <b>1672</b> is included, the dealer <b>1680</b> can verbally announce action or request an election by a player. In some embodiments, the user device <b>1620</b> also includes a camera or microphone, which also captures feeds to be shared with the dealer <b>1680</b> and other players.</p><p id="p-0144" num="0143"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a simplified block diagram showing elements of computing devices that may be used in systems and apparatuses of this disclosure. A computing system <b>1640</b> may be a user-type computer, a file server, a computer server, a notebook computer, a tablet, a handheld device, a mobile device, or other similar computer system for executing software. The computing system <b>1640</b> may be configured to execute software programs containing computing instructions and may include one or more processors <b>1642</b>, memory <b>1646</b>, one or more displays <b>1658</b>, one or more user interface elements <b>1644</b>, one or more communication elements <b>1656</b>, and one or more storage devices <b>1648</b> (also referred to herein simply as storage <b>1648</b>).</p><p id="p-0145" num="0144">The processors <b>1642</b> may be configured to execute a wide variety of operating systems and applications including the computing instructions for administering wagering games of the present disclosure.</p><p id="p-0146" num="0145">The processors <b>1642</b> may be configured as a general-purpose processor such as a microprocessor, but in the alternative, the general-purpose processor may be any processor, controller, microcontroller, or state machine suitable for carrying out processes of the present disclosure. The processor <b>1642</b> may also be implemented as a combination of computing devices, such as a combination of a DSP and a microprocessor, a plurality of microprocessors, one or more microprocessors in conjunction with a DSP core, or any other such configuration.</p><p id="p-0147" num="0146">A general-purpose processor may be part of a general-purpose computer. However, when configured to execute instructions (e.g., software code) for carrying out embodiments of the present disclosure the general-purpose computer should be considered a special-purpose computer. Moreover, when configured according to embodiments of the present disclosure, such a special-purpose computer improves the function of a general-purpose computer because, absent the present disclosure, the general-purpose computer would not be able to carry out the processes of the present disclosure. The processes of the present disclosure, when carried out by the special-purpose computer, are processes that a human would not be able to perform in a reasonable amount of time due to the complexities of the data processing, decision making, communication, interactive nature, or combinations thereof for the present disclosure. The present disclosure also provides meaningful limitations in one or more particular technical environments that go beyond an abstract idea. For example, embodiments of the present disclosure provide improvements in the technical field related to the present disclosure.</p><p id="p-0148" num="0147">The memory <b>1646</b> may be used to hold computing instructions, data, and other information for performing a wide variety of tasks including administering wagering games of the present disclosure. By way of example, and not limitation, the memory <b>1646</b> may include Synchronous Random Access Memory (SRAM), Dynamic RAM (DRAM), Read-Only Memory (ROM), Flash memory, and the like.</p><p id="p-0149" num="0148">The display <b>1658</b> may be a wide variety of displays such as, for example, light-emitting diode displays, liquid crystal displays, cathode ray tubes, and the like. In addition, the display <b>1658</b> may be configured with a touch-screen feature for accepting user input as a user interface element <b>1644</b>.</p><p id="p-0150" num="0149">As nonlimiting examples, the user interface elements <b>1644</b> may include elements such as displays, keyboards, push-buttons, mice, joysticks, haptic devices, microphones, speakers, cameras, and touchscreens.</p><p id="p-0151" num="0150">As nonlimiting examples, the communication elements <b>1656</b> may be configured for communicating with other devices or communication networks. As nonlimiting examples, the communication elements <b>1656</b> may include elements for communicating on wired and wireless communication media, such as for example, serial ports, parallel ports, Ethernet connections, universal serial bus (USB) connections, IEEE 1394 (&#x201c;firewire&#x201d;) connections, THUNDERBOLT&#x2122; connections, BLUETOOTH&#xae; wireless networks, ZigBee wireless networks, 802.11 type wireless networks, cellular telephone/data networks, fiber optic networks and other suitable communication interfaces and protocols.</p><p id="p-0152" num="0151">The storage <b>1648</b> may be used for storing relatively large amounts of nonvolatile information for use in the computing system <b>1640</b> and may be configured as one or more storage devices. By way of example and not limitation, these storage devices may include computer-readable media (CRM). This CRM may include, but is not limited to, magnetic and optical storage devices such as disk drives, magnetic tape, CDs (compact discs), DVDs (digital versatile discs or digital video discs), and semiconductor devices such as RAM, DRAM, ROM, EPROM, Flash memory, and other equivalent storage devices.</p><p id="p-0153" num="0152">A person of ordinary skill in the art will recognize that the computing system <b>1640</b> may be configured in many different ways with different types of interconnecting buses between the various elements. Moreover, the various elements may be subdivided physically, functionally, or a combination thereof. As one nonlimiting example, the memory <b>1646</b> may be divided into cache memory, graphics memory, and main memory. Each of these memories may communicate directly or indirectly with the one or more processors <b>1642</b> on separate buses, partially combined buses, or a common bus.</p><p id="p-0154" num="0153">As a specific, nonlimiting example, various methods and features of the present disclosure may be implemented in a mobile, remote, or mobile and remote environment over one or more of Internet, cellular communication (e.g., Broadband), near field communication networks and other communication networks referred to collectively herein as an iGaming environment. The iGaming environment may be accessed through social media environments such as FACEBOOK&#xae; and the like. DragonPlay Ltd, acquired by Bally Technologies Inc., provides an example of a platform to provide games to user devices, such as cellular telephones and other devices utilizing ANDROID&#xae;, iPHONE&#xae; and FACEBOOK&#xae; platforms. Where permitted by jurisdiction, the iGaming environment can include pay-to-play (P2P) gaming where a player, from their device, can make value based wagers and receive value based awards. Where P2P is not permitted the features can be expressed as entertainment only gaming where players wager virtual credits having no value or risk no wager whatsoever such as playing a promotion game or feature.</p><p id="p-0155" num="0154"><figref idref="DRAWINGS">FIG. <b>17</b></figref> illustrates an illustrative embodiment of information flows in an iGaming environment. At a player level, the player or user accesses a site hosting the activity such as a website <b>1700</b>. The website <b>1700</b> may functionally provide a web game client <b>1702</b>. The web game client <b>1702</b> may be, for example, represented by a game client <b>1708</b> downloadable at information flow <b>1710</b>, which may process applets transmitted from a gaming server <b>1714</b> at information flow <b>1711</b> for rendering and processing game play at a player's remote device. Where the game is a P2P game, the gaming server <b>1714</b> may process value-based wagers (e.g., money wagers) and randomly generate an outcome for rendition at the player's device. In some embodiments, the web game client <b>1702</b> may access a local memory store to drive the graphic display at the player's device. In other embodiments, all or a portion of the game graphics may be streamed to the player's device with the web game client <b>1702</b> enabling player interaction and display of game features and outcomes at the player's device.</p><p id="p-0156" num="0155">The website <b>1700</b> may access a player-centric, iGaming-platform-level account module <b>1704</b> at information flow <b>1706</b> for the player to establish and confirm credentials for play and, where permitted, access an account (e.g., an eWallet) for wagering. The account module <b>1704</b> may include or access data related to the player's profile (e.g., player-centric information desired to be retained and tracked by the host), the player's electronic account, deposit, and withdrawal records, registration and authentication information, such as username and password, name and address information, date of birth, a copy of a government issued identification document, such as a driver's license or passport, and biometric identification criteria, such as fingerprint or facial recognition data, and a responsible gaming module containing information, such as self-imposed or jurisdictionally imposed gaming restraints, such as loss limits, daily limits and duration limits. The account module <b>1704</b> may also contain and enforce geo-location limits, such as geographic areas where the player may play P2P games, user device IP address confirmation, and the like.</p><p id="p-0157" num="0156">The account module <b>1704</b> communicates at information flow <b>1705</b> with a game module <b>1716</b> to complete log-ins, registrations, and other activities. The game module <b>1716</b> may also store or access a player's gaming history, such as player tracking and loyalty club account information. The game module <b>1716</b> may provide static web pages to the player's device from the game module <b>1716</b> through information flow <b>1718</b>, whereas, as stated above, the live game content may be provided from the gaming server <b>1714</b> to the web game client through information flow <b>1711</b>.</p><p id="p-0158" num="0157">The gaming server <b>1714</b> may be configured to provide interaction between the game and the player, such as receiving wager information, game selection, inter-game player selections or choices to play a game to its conclusion, and the random selection of game outcomes and graphics packages, which, alone or in conjunction with the downloadable game client <b>1708</b>/web game client <b>1702</b> and game module <b>1716</b>, provide for the display of game graphics and player interactive interfaces. At information flow <b>1718</b>, player account and log-in information may be provided to the gaming server <b>1714</b> from the account module <b>1704</b> to enable gaming. Information flow <b>1720</b> provides wager/credit information between the account module <b>1704</b> and gaming server <b>1714</b> for the play of the game and may display credits and eWallet availability. Information flow <b>1722</b> may provide player tracking information for the gaming server <b>1714</b> for tracking the player's play. The tracking of play may be used for purposes of providing loyalty rewards to a player, determining preferences, and the like.</p><p id="p-0159" num="0158">All or portions of the features of <figref idref="DRAWINGS">FIG. <b>17</b></figref> may be supported by servers and databases located remotely from a player's mobile device and may be hosted or sponsored by regulated gaming entity for P2P gaming or, where P2P is not permitted, for entertainment only play.</p><p id="p-0160" num="0159">In some embodiments, wagering games may be administered in an at least partially player-pooled format, with payouts on pooled wagers being paid from a pot to players and losses on wagers being collected into the pot and eventually distributed to one or more players. Such player-pooled embodiments may include a player-pooled progressive embodiment, in which a pot is eventually distributed when a predetermined progressive-winning hand combination or composition is dealt. Player-pooled embodiments may also include a dividend refund embodiment, in which at least a portion of the pot is eventually distributed in the form of a refund distributed, e.g., pro-rata, to the players who contributed to the pot.</p><p id="p-0161" num="0160">In some player-pooled embodiments, the game administrator may not obtain profits from chance-based events occurring in the wagering games that result in lost wagers. Instead, lost wagers may be redistributed back to the players. To profit from the wagering game, the game administrator may retain a commission, such as, for example, a player entrance fee or a rake taken on wagers, such that the amount obtained by the game administrator in exchange for hosting the wagering game is limited to the commission and is not based on the chance events occurring in the wagering game itself. The game administrator may also charge a rent of flat fee to participate.</p><p id="p-0162" num="0161">It is noted that the methods described herein can be played with any number of standard decks of 52 cards (e.g., 1 deck to 10 decks). A standard deck is a collection of cards comprising an Ace, two, three, four, five, six, seven, eight, nine, ten, jack, queen, king, for each of four suits (comprising spades, diamonds, clubs, hearts) totaling 52 cards. Cards can be shuffled or a continuous shuffling machine (CSM) can be used. A standard deck of 52 cards can be used, as well as other kinds of decks, such as Spanish decks, decks with wild cards, etc. The operations described herein can be performed in any sensible order. Furthermore, numerous different variants of house rules can be applied.</p><p id="p-0163" num="0162">Note that in the embodiments played using computers (a processor/processing unit), &#x201c;virtual deck(s)&#x201d; of cards are used instead of physical decks. A virtual deck is an electronic data structure used to represent a physical deck of cards which uses electronic representations for each respective card in the deck. In some embodiments, a virtual card is presented (e.g., displayed on an electronic output device using computer graphics, projected onto a surface of a physical table using a video projector, etc.) and is presented to mimic a real life image of that card.</p><p id="p-0164" num="0163">Methods described herein can also be played on a physical table using physical cards and physical chips used to place wagers. Such physical chips can be directly redeemable for cash. When a player wins (dealer loses) the player's wager, the dealer will pay that player a respective payout amount. When a player loses (dealer wins) the player's wager, the dealer will take (collect) that wager from the player and typically place those chips in the dealer's chip rack. All rules, embodiments, features, etc. of a game being played can be communicated to the player (e.g., verbally or on a written rule card) before the game begins.</p><p id="p-0165" num="0164">Initial cash deposits can be made into the electronic gaming machine which converts cash into electronic credits. Wagers can be placed in the form of electronic credits, which can be cashed out for real coins or a ticket (e.g., ticket-in-ticket-out) which can be redeemed at a casino cashier or kiosk for real cash and/or coins.</p><p id="p-0166" num="0165">Any component of any embodiment described herein may include hardware, software, or any combination thereof.</p><p id="p-0167" num="0166">Further, the operations described herein can be performed in any sensible order. Any operations not required for proper operation can be optional. Further, all methods described herein can also be stored as instructions on a computer readable storage medium, which instructions are operable by a computer processor. All variations and features described herein can be combined with any other features described herein without limitation. All features in all documents incorporated by reference herein can be combined with any feature(s) described herein, and also with all other features in all other documents incorporated by reference, without limitation.</p><p id="p-0168" num="0167">Features of various embodiments of the inventive subject matter described herein, however essential to the example embodiments in which they are incorporated, do not limit the inventive subject matter as a whole, and any reference to the invention, its elements, operation, and application are not limiting as a whole, but serve only to define these example embodiments. This detailed description does not, therefore, limit embodiments which are defined only by the appended claims. Further, since numerous modifications and changes may readily occur to those skilled in the art, it is not desired to limit the inventive subject matter to the exact construction and operation illustrated and described, and accordingly all suitable modifications and equivalents may be resorted to, falling within the scope of the inventive subject matter.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method comprising:<claim-text>detecting, by a processor in response to analysis of image data by a neural network model, an appearance of one or more features of a gaming surface;</claim-text><claim-text>automatically modifying, by the processor via the neural network model in response to the detecting the appearance of the one or more features, a presentation attribute associated with presentation of gaming content via a designated area of the gaming surface; and</claim-text><claim-text>projecting, by the processor via a projection system based on the modified presentation attribute, the gaming content onto the designated area of the gaming surface.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>capturing the image data from an image-sensor perspective of an image sensor oriented at the gaming surface within a gaming environment, and wherein the analysis of the image data comprises, analyzing the appearance of the one or more features in the image data against a known geometry of the one or more features.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the known geometry comprises an isomorphic equivalent to the appearance of the one or more features taken from a substantially equivalent image-sensor perspective oriented at the gaming surface during training of the neural network model in a training environment, and wherein the modifying is based on one or more transformations by the neural network model of the detected appearance of the one or more features to the isomorphic equivalent.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the one or more transformations are based on one or more layout elements of the gaming surface specified in a layout authorized for presentation of wagering games via the designated area of the gaming surface.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the gaming surface comprises a hard surface covered by a reflective material on which at least one of the one or more features is projected.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more features comprise features used for administration of a wagering game.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the automatically modifying comprises:<claim-text>detecting, by the processor based on the analysis of the image data by the neural network model, first relative positions between a first feature of the one or more features and a second feature of the one or more features;</claim-text><claim-text>searching, by the processor via the neural network model based on one or more transformations of the first relative positions, a library of layout templates;</claim-text><claim-text>selecting, by the processor via the neural network model based on the searching, a layout template from the library of layout templates, wherein the layout template has second relative positions between additional features on a gaming-surface layout, and wherein the second relative positions are isomorphic to the first relative positions; and</claim-text><claim-text>wherein modifying the presentation attribute is based, at least in part, on dimensions of the additional features obtained from the layout template.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, further comprising detecting, based on the analysis of the image data by the neural network model, a manufacturer of one or more of the gaming surface or the layout template, and wherein the searching comprises searching only a portion of the library of layout templates related to the detected manufacturer.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the image data is captured via an image-sensor perspective of an image sensor affixed relative to the designated area, and wherein prior to automatically modifying the presentation attribute, said method further comprising:<claim-text>obtaining additional image data taken of the gaming content projected onto the gaming surface using the presentation attribute for projection prior to being modified; and</claim-text><claim-text>determining, based on isomorphic evaluation of the additional image data by the neural network model against the image data, a change in position of the one or more features relative to the designated area, wherein the automatically modifying the presentation attribute comprises automatically calibrating the presentation attribute based on the change in position.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the automatically modifying the presentation attribute comprises one or more of:<claim-text>self-calibrating a projector setting of the projection system; or</claim-text><claim-text>modifying, based on analysis of the appearance of the one or more features by the neural network model, one or more of a position, a dimension, or an orientation of the gaming content within a virtual overlay of the gaming surface.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more features comprise at least one physical feature of the gaming surface and a grid of fiducial markers projected at the gaming surface via a projection perspective of the projection system, wherein each fiducial marker within the grid of fiducial markers has a unique appearance associated with specific coordinates of a grid structure, and wherein detecting the appearance of the one or more features comprises:<claim-text>detecting, by the neural network model via the analysis of the image data, at least a portion of the grid of fiducial markers that are visible on the gaming surface; and</claim-text><claim-text>determining, based on a detected orientation of the at least a portion of the grid of fiducial markers relative to known dimensions of the at least one physical feature, a homography matrix to automatically transform, based on the projection perspective and based on the specific coordinates of the grid structure, one or more dimensions of the gaming content to fit the designated area via the projecting.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A gaming system comprising:<claim-text>a projection system; and</claim-text><claim-text>a processor, wherein the processor is configured to execute instructions, which, when executed, cause the gaming system to perform operations to:<claim-text>detect, in response to analysis of image data by a neural network model, an appearance of one or more features of a gaming surface;</claim-text><claim-text>automatically modify, via the neural network model in response to the detecting the appearance of the one or more features, a presentation attribute associated with presentation of gaming content via a designated area of the gaming surface; and</claim-text><claim-text>project, via the projection system based on the modified presentation attribute, the gaming content onto the designated area of the gaming surface.</claim-text></claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The gaming system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the processor is further configured to execute instructions, which, when executed, cause the gaming system to perform operations to:<claim-text>capture the image data from an image-sensor perspective of an image sensor oriented at the gaming surface within a gaming environment, and wherein the operation of analysis of the image data comprises operations to evaluate the appearance of the one or more features in the image data against a known geometry of the one or more features.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The gaming system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the known geometry comprises an isomorphic equivalent to the appearance of the one or more features taken from a substantially equivalent image-sensor perspective oriented at the gaming surface during training of the neural network model in a training environment, and wherein the operation to automatically modify the presentation attribute is based on one or more transformations by the neural network model of the detected appearance of the one or more features to the isomorphic equivalent.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The gaming system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the gaming surface comprises a hard surface covered by a reflective material on which at least one of the one or more features is projected.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The gaming system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the processor is further configured to execute instructions, which, when executed, cause the gaming system to perform operations to:<claim-text>detect, based on the analysis of the image data by the neural network model, first relative positions between a first feature of the one or more features and a second feature of the one or more features;</claim-text><claim-text>search, via the neural network model based on one or more transformations of the first relative positions, a library of layout templates;</claim-text><claim-text>select, via the neural network model based on the searching, a layout template from the library of layout templates, wherein the layout template has second relative positions between additional features on a gaming-surface layout, and wherein the second relative positions are isomorphic to the first relative positions; and</claim-text><claim-text>wherein modification of the presentation attribute is based, at least in part, on dimensions of the additional features obtained from the layout template.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The gaming system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the image data is captured via an image-sensor perspective of an image sensor affixed relative to the designated area, and wherein prior to automatic modification of the presentation attribute, said processor is further configured to execute instructions, which, when executed, cause the gaming system to perform operations to:<claim-text>obtain additional image data taken of the gaming content projected onto the gaming surface using the presentation attribute for projection prior to being modified; and</claim-text><claim-text>determine, based on isomorphic evaluation of the additional image data by the neural network model against the image data, a change in position of the one or more features relative to the designated area, wherein automatic modification of the presentation attribute comprises automatic calibration of the presentation attribute based on the change in position.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. One or more machine-readable media including instructions executable by a processor, the instructions including:<claim-text>instructions for detecting, by a processor in response to analysis of image data by a neural network model, an appearance of one or more features of a gaming surface;</claim-text><claim-text>instructions for automatically modifying, via the neural network model in response to the detecting the appearance of the one or more features, a presentation attribute associated with presentation of gaming content via a designated area of the gaming surface; and</claim-text><claim-text>instructions for projecting, via a projection system based on the modified presentation attribute, the gaming content onto the designated area of the gaming surface.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The one or more machine-readable media of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the instructions for automatically modifying the presentation attribute comprise one or more of:<claim-text>instructions for self-calibrating a projector setting of the projection system; or</claim-text><claim-text>instructions for modifying, based on analysis of the appearance of the one or more features by the neural network model, one or more of a position, a dimension, or an orientation of the gaming content within a virtual overlay of the gaming surface.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The one or more machine-readable media of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the one or more features comprise at least one physical feature of the gaming surface and a grid of fiducial markers projected at the gaming surface via a projection perspective of the projection system, wherein each fiducial marker within the grid of fiducial markers has a unique appearance associated with specific coordinates of a grid structure, and wherein the instructions for detecting the appearance of the one or more features comprise:<claim-text>instructions for detecting, by the neural network model via the analysis of the image data, at least a portion of the grid of fiducial markers that are visible on the gaming surface; and</claim-text><claim-text>instructions for determining, based on a detected orientation of the at least a portion of the grid of fiducial markers relative to known dimensions of the at least one physical feature, a homography matrix to automatically transform, based on the projection perspective and based on the specific coordinates of the grid structure, one or more dimensions of the gaming content to fit the designated area via the projecting.</claim-text></claim-text></claim></claims></us-patent-application>
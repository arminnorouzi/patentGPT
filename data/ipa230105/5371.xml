<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005372A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005372</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17852533</doc-number><date>20220629</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>21183230.8</doc-number><date>20210701</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>16</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>0967</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>164</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>166</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>096725</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>096775</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>0129</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>0133</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>0112</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>7</main-group><subgroup>005</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">ESTIMATION OF ACCIDENT INTENSITY FOR VEHICLES</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only"><addressbook><orgname>ZENSEACT AB</orgname><address><city>Gothenburg</city><country>SE</country></address></addressbook><residence><country>SE</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>LINDBERG</last-name><first-name>Carl</first-name><address><city>V&#xe4;stra Fr&#xf6;lunda</city><country>SE</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present invention relates to a method for alerting drivers and/or autonomous vehicles of high risk scenarios. The method includes obtaining positional data of a vehicle, where the positional data is indicative of geographical position and heading of the vehicle. The method further includes obtaining environmental data of the vehicle, where the environmental data is indicative of state of the surrounding environment of the vehicle. The method includes determining, by means of trained model, accident intensity for upcoming road portion for the vehicle, the trained model being configured to determine accident intensity associated with the upcoming road portion based on the obtained environmental data and the obtained positional data. Then, if the determined accident intensity exceeds threshold, the method comprises transmitting signal indicating approaching high risk scenario to a Human-Machine-Interface, HMI, of the vehicle and/or to a control system of the vehicle.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="218.61mm" wi="140.38mm" file="US20230005372A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="200.49mm" wi="144.78mm" orientation="landscape" file="US20230005372A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="191.26mm" wi="156.04mm" orientation="landscape" file="US20230005372A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="243.59mm" wi="142.41mm" file="US20230005372A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="201.34mm" wi="145.97mm" orientation="landscape" file="US20230005372A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="215.56mm" wi="132.93mm" orientation="landscape" file="US20230005372A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application for patent claims priority to European Patent Office Application Ser. No. 21183230.8, entitled &#x201c;ESTIMATION OF ACCIDENT INTENSITY FOR VEHICLES&#x201d; filed on Jul. 1, 2021, assigned to the assignee hereof, and expressly incorporated herein by reference.</p><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present invention relates to estimation of accident intensities for vehicles, and in particular to estimation of accident intensities in a statistical sense (e.g. intensity of a Poisson point process).</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">During these last few years, the development of autonomous vehicles has exploded and many different solutions are being explored. An increasing number of modern vehicles have advanced driver-assistance systems (ADAS) to increase vehicle safety and more generally road safety. ADAS&#x2014;which for instance may be represented by adaptive cruise control, ACC, collision avoidance system, forward collision warning, etc.&#x2014;are electronic systems that may aid a vehicle driver while driving. To function as intended, ADAS may rely on inputs from multiple data sources, such as e.g. automotive imaging, LIDAR, radar, image processing, computer vision, and/or in-car networking.</p><p id="p-0005" num="0004">Today, development is ongoing in both ADAS as well as Autonomous Driving (AD), within a number of different technical areas within these fields. ADAS and AD will herein be referred to under the common term Automated Driving System (ADS) corresponding to all of the different levels of automation as for example defined by the SAE J3016 levels (0-5) of driving automation.</p><p id="p-0006" num="0005">Accordingly, in a not too distant future, ADS solutions will to a greater extent find their way into modern vehicles. An ADS may be construed as a complex combination of various components that can be defined as systems where perception, decision making, and operation of the vehicle are performed by electronics and machinery instead of a human driver, and as introduction of automation into road traffic. This includes handling of the vehicle, destination, as well as awareness of surroundings. While the automated system has control over the vehicle, it allows the human operator to leave all responsibilities to the system. An ADS commonly combines a variety of sensors to perceive the vehicle's surroundings, such as e.g. radar, LIDAR, sonar, camera, navigation system e.g. GPS, odometer and/or inertial measurement units (IMUs), upon which advanced control systems may interpret sensory information to identify appropriate navigation paths, as well as obstacles and/or relevant signage.</p><p id="p-0007" num="0006">It is important that an ADS functions with high reliability and integrity to reduce the risk for the vehicle occupant(s) as well as their surrounding environments to an acceptable level. Ensuring that the risk is sufficiently low requires huge amounts of data to evidence the performance of the ADS. A statistical proof that an ADS is capable of responding to all possible or statistically relevant experiences a vehicle could encounter whilst being driven could, in theory, be obtained by testing the vehicle in the field before the vehicle is sold and driven on public roads. In practice, however, capturing such test data to show how an ADS would respond to every conceivable situation a vehicle could experience would take centuries using currently available technologies. Sharing the experiences of a fleet of, for example, a hundred test vehicles, is currently estimated to require around 500 years for sufficient data to be acquired to provide such a statistical proof. As this length of time is not practical, currently ADS features installed before a vehicle is driven on public roads are made as safe as possible, and are supplemented by monitoring the ADS of the vehicle whilst it is being driven on public roads in order to ensure that the ADS is performing to the required safety levels.</p><p id="p-0008" num="0007">To this end, there have been a number of proposals for increasing the general road safety by utilizing databases with historical accident data to notify the vehicle's ADS or the driver of the vehicle of upcoming road portions associated with historical accidents. For example, EP 3 227 148 A2 discloses a solution where gathered accident data is analyzed for the purpose of sending notifications to educate the users and alert them about accident patterns and precautious measures when being in locations associated with historical accidents.</p><p id="p-0009" num="0008">However, such methods have an inherent flaw in that they are essentially based on the presumption that accident events have occurred at specific geographical locations and/or during specific environmental conditions and that, those locations and/or environmental conditions are therefore high risk scenarios. However, such methods cannot be used to infer the actual risk of driving at those specific locations and/or during those specific environmental conditions at other appropriately defined similar locations.</p><p id="p-0010" num="0009">There is accordingly a need for improvements in the art for estimating the risk that a vehicle is about to be exposed to in order to potentially warn the driver of the vehicle or the ADS of the vehicle, and thereby improve the overall road safety.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0011" num="0010">It is therefore an object of the present invention to provide a method for alerting drivers and/or autonomous vehicles of high risk scenarios, a computer-readable storage medium, an apparatus, and a vehicle comprising such an apparatus that alleviate all or at least some of the above-discussed drawbacks of presently known systems and methods.</p><p id="p-0012" num="0011">This object is achieved by means of a method for alerting drivers and/or autonomous vehicles of high risk scenarios, a computer-readable storage medium, an apparatus, and a vehicle comprising such an apparatus as defined in the appended independent claims. The term exemplary is in the present context to be understood as serving as an instance, example or illustration.</p><p id="p-0013" num="0012">According to a first aspect of the present invention, there is provided a method for alerting drivers and/or autonomous vehicles of high risk scenarios. The method comprises obtaining positional data of a vehicle, where the positional data is indicative of a geographical position and a heading of the vehicle. The method further comprises obtaining environmental data of the vehicle, where the environmental data is indicative of a state of the surrounding environment of the vehicle. Furthermore, the method comprises determining, by means of a trained model, an accident intensity for an upcoming road portion for the vehicle, the trained model being configured to determine an accident intensity associated with the upcoming road portion based on the obtained environmental data and the obtained positional data. Then, if the determined accident intensity exceeds a threshold, the method comprises transmitting a signal indicating an approaching high risk scenario to a Human-Machine-Interface, HMI, of the vehicle and/or to a control system of the vehicle.</p><p id="p-0014" num="0013">According to a second aspect of the present invention, there is provided computer-readable storage medium storing one or more programs configured to be executed by one or more processors of a processing system, the one or more programs comprising instructions for performing the method according to any one of the embodiments disclosed herein. With this aspect of the invention, similar advantages and preferred features are present as in the previously discussed first aspect of the invention.</p><p id="p-0015" num="0014">The term &#x201c;non-transitory,&#x201d; as used herein, is intended to describe a computer-readable storage medium (or &#x201c;memory&#x201d;) excluding propagating electromagnetic signals, but are not intended to otherwise limit the type of physical computer-readable storage device that is encompassed by the phrase computer-readable medium or memory. For instance, the terms &#x201c;non-transitory computer readable medium&#x201d; or &#x201c;tangible memory&#x201d; are intended to encompass types of storage devices that do not necessarily store information permanently, including for example, random access memory (RAM). Program instructions and data stored on a tangible computer-accessible storage medium in non-transitory form may further be transmitted by transmission media or signals such as electrical, electromagnetic, or digital signals, which may be conveyed via a communication medium such as a network and/or a wireless link. Thus, the term &#x201c;non-transitory&#x201d;, as used herein, is a limitation of the medium itself (i.e., tangible, not a signal) as opposed to a limitation on data storage persistency (e.g., RAM vs. ROM).</p><p id="p-0016" num="0015">According to a second aspect of the present invention, there is provided an apparatus for alerting drivers and/or autonomous vehicles of high risk scenarios. The apparatus comprises control circuitry configured to obtain positional data of a vehicle, where the positional data indicates a geographical position and a heading of the vehicle. The control circuitry is further configured to obtain environmental data of the vehicle, where the environmental data indicates a state of the surrounding environment of the vehicle. Furthermore, the control circuitry is configured to determine, by means of a trained model, an accident intensity for an upcoming road portion for the vehicle, the trained model being configured to determine an accident intensity associated with the upcoming road portion based on the obtained environmental data and the obtained positional data. Moreover, if the determined accident intensity exceeds a threshold, the control circuitry is configured to transmit a signal indicating an approaching high risk scenario to a Human-Machine-Interface, HMI, of the vehicle and/or to a control system of the vehicle. With this aspect of the invention, similar advantages and preferred features are present as in the previously discussed first aspect of the invention.</p><p id="p-0017" num="0016">According to a fourth aspect of the present invention, there is provided a vehicle comprising a localization system for generating positional data indicating a geographical location and a heading of the vehicle, and an apparatus according to any one of the embodiments disclosed herein. With this aspect of the invention, similar advantages and preferred features are present as in the previously discussed first aspect of the invention.</p><p id="p-0018" num="0017">An advantage of some embodiments is that a driver of a vehicle or an ADS of a vehicle can be warned in due time before entering a potential high-risk region. Thereby general road safety may be improved.</p><p id="p-0019" num="0018">An advantage of some embodiments is that the determined accident intensity may be taken into account in a path planning or routing solution so that potential high-risk regions can be avoided already in the planning stage. Thereby general road safety and passenger comfort may be improved.</p><p id="p-0020" num="0019">Further embodiments of the invention are defined in the dependent claims. It should be emphasized that the term &#x201c;comprises/comprising&#x201d; when used in this specification is taken to specify the presence of stated features, integers, steps, or components. It does not preclude the presence or addition of one or more other features, integers, steps, components, or groups thereof.</p><p id="p-0021" num="0020">These and other features and advantages of the present invention will in the following be further clarified with reference to the embodiments described hereinafter.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0022" num="0021">Further objects, features and advantages of embodiments of the invention will appear from the following detailed description, reference being made to the accompanying drawings, in which:</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic block diagram representation of an accident intensity model in accordance with some embodiments.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic block diagram representation of an accident intensity engine in accordance with some embodiments.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic flow diagram representation of a method for alerting drivers and/or autonomous vehicles of high risk scenarios in accordance with some embodiments.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic block diagram representation of an apparatus for alerting drivers and/or autonomous vehicles of high risk scenarios.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic side-view of a vehicle comprising an apparatus for alerting drivers and/or autonomous vehicles of high risk scenarios in accordance with some embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0028" num="0027">Those skilled in the art will appreciate that the steps, services and functions explained herein may be implemented using individual hardware circuitry, using software functioning in conjunction with a programmed microprocessor or general purpose computer, using one or more Application Specific Integrated Circuits (ASICs) and/or using one or more Digital Signal Processors (DSPs). It will also be appreciated that when the present invention is described in terms of a method, it may also be embodied in one or more processors and one or more memories coupled to the one or more processors, wherein the one or more memories store one or more programs that perform the steps, services and functions disclosed herein when executed by the one or more processors.</p><p id="p-0029" num="0028">In the following description of exemplary embodiments, the same reference numerals denote the same or similar components. A vehicle is in the present context to be understood as a road vehicle such as e.g. a car, a bus, a truck, or the like. The vehicle may be equipped with an Automated Driving System (ADS) and may therefore be capable of autonomous or semi-autonomous operation.</p><p id="p-0030" num="0029">As mentioned in the foregoing there is a plethora of suggested approaches for identifying approaching high-risk scenarios. However, the present inventor realized that by forming a measure of accident intensities associated with the scenarios that a vehicle may be exposed to, a new and improved solution may be realized for warning a driver or an automated driving system about approaching high-risk scenarios. Further, it was realized that merely relying on data from an &#x201c;accident database&#x201d; and comparing the reported geographical position at the time of the accident (critical scenario) with a current position and heading of a vehicle may give a blunt estimate of the &#x201c;risk&#x201d; that the vehicle is or will be exposed to. In more detail, given accident data, together with related data such as traffic flow at site and time of accident, speed limit at site of accident, etc., one is only able to answer questions such as&#x2014;&#x201c;How many accidents happen while driving 70 km/h on a specific stretch of road during rain at night?&#x201d;&#x2014;Such questions, while interesting in their own right, say nothing about the actual risk the individual driver faces while driving 70 km/h in rain at night on the specific stretch of road.</p><p id="p-0031" num="0030">In other words, the present inventor realized that one may utilize an &#x201c;accident intensity&#x201d; (in a Poisson sense), to obtain a better estimate the risk exposure of the vehicle for upcoming scenarios. However, to be able to obtained such estimates, one needs to estimate a &#x201c;number of attempts&#x201d;, i.e. how large proportion of all time and/or mileage spent on roads occur with specific environmental conditions that correspond to the environmental conditions of each accident and/or critical scenario (e.g. near-accident scenario).</p><p id="p-0032" num="0031">Therefore, it is herein suggested that one trains a model based on accident data from an accident database comprising information about a plurality of critical scenarios at a time of each critical scenario (e.g. weather conditions during the critical scenario, time of day at the critical scenario, type of critical scenario, road type at the critical scenario, road conditions at the critical scenario, etc.) and data indicative of frequencies of similar situations as the critical scenarios. The term &#x201c;road type&#x201d; as used herein may be understood a characterization of the road such as e.g. national highway, controlled-access highway, state highway, district road, country road, highroad, rural road and so forth.</p><p id="p-0033" num="0032">The data indicative of frequencies of similar situations (i.e. &#x201c;number of attempts&#x201d;) may for example be derived from a &#x201c;proxy&#x201d; such as e.g. traffic flow monitoring solutions (tracking actual traffic flow or mobile devices) or reported directly from a fleet of connected vehicles. In the latter case, and in accordance with some embodiments, the data indicative of frequencies of similar situations is in the form of environmental data (e.g. time of day, weather conditions, road surface conditions, speed limits, type of road, etc.) obtained over time from a plurality of vehicles in a fleet of vehicles. In more detail, a fleet management system may for example request &#x201c;status reports&#x201d; from all or a subset of vehicles in a fleet of &#x201c;connected&#x201d; vehicles, and over time build the above-mentioned model&#x2014;&#x201c;Accident intensity model&#x201d;&#x2014;capable of estimating accident intensities for a multitude of scenarios. An advantage of utilizing a fleet of vehicles is that more nuanced data may be available (due to the sensory capabilities of modern vehicles, and in particular ADS-equipped vehicles), which consequently provides a better estimate of the &#x201c;number of attempts&#x201d; and thereby a better estimate of the accident intensity for a given scenario, and in extension a better risk assessment for the scenario.</p><p id="p-0034" num="0033">Turning to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a schematic block diagram illustration of an accident intensity model <b>25</b> is provided. In more detail, <figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts an example embodiment of how the accident intensity model <b>25</b> may be formed and trained/updated over time. Here, each scenario <b>21</b> is depicted as a &#x201c;container&#x201d; that is formed based on the information associated with each critical scenario that is obtained from an accident database <b>2</b>. For example, a first scenario <b>21</b> (&#x201c;Scenario 1&#x201d;) may be &#x201c;driving/traveling at 100 km/h in rain at night on a controlled-access highway&#x201d;, while a second scenario <b>21</b> (&#x201c;Scenario 2&#x201d;) may be &#x201c;driving/traveling at 60 km/h with icy road conditions, during the day, on a multi-lane road in a densely populated area&#x201d;, and so forth. It should be noted that the type and number of parameters comprised in each scenario may be set independently and have more parameters than the examples provided above. For example, the scenario may further include a time of day, day of week, outside temperature, geographical area/position, speed limit of the associated road portion, presence of barriers, and so forth. In other words, the accident data, that is obtained from the accident database, is at least indicative of a time and location of each critical scenario (e.g. each accident or &#x201c;near-accident&#x201d;). However, the accident data may further be indicative of a road surface condition, a weather condition, presence of road barriers, presence of wildlife fence barriers, number of involved vehicles in the critical scenario, severity of the critical scenario, and so forth.</p><p id="p-0035" num="0034">Moving on, over time, the accident intensity model <b>25</b> is further provided with an input in the form of data indicative of frequencies of similar situations as the critical scenarios. This data may for example be retrieved via an external network <b>20</b>. In more detail, this data may be obtained via a suitable &#x201c;proxy&#x201d; output as exemplified above (i.e. indirectly) or directly via &#x201c;fleet data&#x201d; (i.e. environmental data retrieved/received from a fleet of vehicles). The latter case may also be construed as a &#x201c;proxy&#x201d; of the actual &#x201c;number of attempts&#x201d; as one can further apply some statistical modelling on the &#x201c;fleet data&#x201d; to obtain an estimate of the &#x201c;number of attempts&#x201d; on a bigger scale (e.g. for a whole country). For example, if one knows how many vehicles are in the fleet, the rate of exposure of a given scenario in the fleet, and the percentage of the total population (e.g. of a country) that this fleet represents, one can derive an estimate of the &#x201c;number of attempts&#x201d; on a larger scale.</p><p id="p-0036" num="0035">The term &#x201c;proxy&#x201d; is in the present context be interpreted broadly and can be understood as any measure indicative of similar situations as the critical scenarios. In other words, the proxy provides data, from which, a number of similar situations as the critical scenarios is derivable.</p><p id="p-0037" num="0036">Further, any time data is retrieved or received via the external network <b>20</b>, it is &#x201c;stored&#x201d; in an appropriate container <b>21</b> corresponding to the critical scenario. Then, as the containers <b>21</b> are populated, the accident intensity model <b>25</b> is capable of providing an output indicative of an accident intensity for each scenario. As the skilled reader readily understands, over time, the accident intensity model <b>25</b> will be capable of providing more reliable indications of the accident intensity for a multitude of scenarios that a vehicle may be exposed to.</p><p id="p-0038" num="0037">Further, <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a schematic block diagram representation of an accident intensity engine <b>45</b> comprising an accident intensity model <b>25</b> as described above. The accident intensity model <b>25</b> (i.e. trained model) receives historical accident data from a suitable accident database <b>2</b> and data indicative of frequencies of similar situations as the critical scenarios (here in the form of &#x201c;fleet data&#x201d;). The fleet data is obtained from a plurality of vehicles <b>3</b>, each being part of a fleet of connected vehicles, via an external network <b>20</b>. The accident intensity engine <b>45</b> may be configured to (periodically) transmit a data request to one or more (randomly selected) vehicles <b>3</b> of the fleet via the external network <b>20</b>. The data request may for example be sent (periodically) to a random subset of vehicles <b>3</b> of the fleet. Upon receiving the request, the one or more vehicles <b>3</b> are configured to transmit environmental data to the accident intensity engine <b>45</b> via the external network. The transmitted environmental data may for example be a geographical position (e.g. GNSS coordinates), heading, time, temperature, and current speed/velocity of the vehicle). Thus, the environmental data may be indicative of a state of the surrounding environment and furthermore indicative of a state of the (reporting) vehicle <b>3</b>. In some embodiments, the environmental data further comprises map data (e.g. type of road, presence of barriers, presence of wildlife barrier fences, etc.), number of external vehicles in the surrounding environment, road surface conditions, and weather conditions.</p><p id="p-0039" num="0038">Once the accident intensity model <b>25</b> is trained, a vehicle <b>1</b> may use the accident intensity engine to obtain a risk estimate for an upcoming road portion (e.g. as part of an automated procedure as the vehicle is autonomously or semi-autonomously operated). In more detail, the vehicle <b>1</b> is configured to transmit (time-stamped) positional data indicating a geographical position and a heading (i.e. to transmit a pose) and optionally environmental data indicating a state of the surrounding environment (e.g. road type, weather conditions, and/or road surface conditions). The environmental data may further indicate a state of the vehicle <b>1</b> (e.g. speed of the vehicle, windshield wiper status, etc.).</p><p id="p-0040" num="0039">In some embodiments, the weather and road conditions are not directly indicated in the environmental data, but instead derived (by the accident intensity engine <b>45</b> or locally in the vehicle <b>1</b>) from the output of vehicle-mounted sensors. For example, a status of the vehicle's windshield wipers (engaged/disengaged) may be used to derive a weather condition (e.g. rain, snow, etc.), alternatively the output from a vehicle-mounted camera may be used to derive the current weather conditions and road conditions by means of a suitable image-processing algorithm as conventionally known. Moreover, in accordance with a further example, road conditions may be determined by estimating the difference in the speeds of the drive shaft and freely rotating axles in various driving situations and from that difference a level of friction may be derived in order to e.g. determine a presence of ice on the road. However, in some embodiments, weather conditions and/or road conditions may be indirectly obtained by comparing the vehicle's <b>1</b> reported position with a weather forecast for that geographical region.</p><p id="p-0041" num="0040">Once the positional data and the environmental data is received by the accident intensity engine <b>45</b>, the accident intensity engine <b>45</b> is configured to determine, by means of the trained accident intensity model <b>25</b>, an accident intensity for an upcoming road portion for the vehicle <b>1</b>. As discussed in the foregoing, the accident intensity model is configured to use the reported pose of the vehicle and the associated environmental data to find a corresponding/matching scenario (see ref. <b>21</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>) for the upcoming road portion and to output the accident intensity for that scenario and thereby the accident intensity for the upcoming road portion.</p><p id="p-0042" num="0041">As mentioned, the accident intensity engine may, in accordance with some embodiments, be provided on a server or a plurality of servers e.g. as a so-called cloud solution. However, in some embodiments, the accident intensity engine <b>45</b> together with the accident intensity model <b>25</b> is provided locally in each vehicle. In the local setup, the accident intensity model <b>25</b> may be subdued to periodical updates from a central managing entity.</p><p id="p-0043" num="0042">Further, <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic flow chart representation of a method S<b>100</b> for alerting drivers and/or autonomous vehicles of high risk scenarios in accordance with some embodiments. The method S<b>100</b> comprises obtaining S<b>101</b> positional data of a vehicle, where the positional data is at least indicative of a geographical position (e.g. GPS position) and a heading of the vehicle. In other words, the method S<b>100</b> comprises obtaining S<b>101</b> of a vehicle.</p><p id="p-0044" num="0043">In some embodiments, the method S<b>100</b> further comprises obtaining S<b>102</b> an intended path of the vehicle. The intended path may for example be a set route in the vehicle's navigation system or generated by an autonomous path planning system.</p><p id="p-0045" num="0044">Further, the method S<b>100</b> comprises obtaining S<b>103</b> environmental data of the vehicle, where the environmental data is indicative of a state of the surrounding environment of the vehicle. The environmental data may be indicative of weather conditions (e.g. rain, snow, fog, etc.) and/or road conditions (e.g. dry, icy, snow covered, etc.). The environmental data may be derived from the positional data by comparing the obtained positional data with a weather forecast for that geographical region. However, in some embodiments, the environmental data is either directly or indirectly reported by the vehicle as described in the foregoing. Moreover, in accordance with some embodiments, the environmental data is further indicative of a state of the vehicle, such as e.g., a current speed of the vehicle.</p><p id="p-0046" num="0045">Still further, the method S<b>100</b> comprises determining S<b>104</b>, by means of a trained model, an accident intensity for an upcoming road portion for the vehicle. Here, the trained model (e.g. accident intensity model as described in the foregoing) is configured to determine an accident intensity associated with the upcoming road portion based on the obtained environmental data and the obtained positional data. The accident intensity may be construed as an intensity in a Poission sense. In other words, &#x201c;intensity&#x201d; as used herein may be understood as the intensity of a nonhomogeneous Poisson point process, where the intensity function depends on e.g., temperature, traffic flow, etc., as discussed above. Expected values, or similar concepts of interest, can then be calculated given this model.</p><p id="p-0047" num="0046">Then, if the determined S<b>104</b> accident intensity exceeds a threshold, the method S<b>100</b> comprises transmitting S<b>105</b> a signal indicating an approaching high risk scenario to a Human-Machine-Interface, HMI, of the vehicle and/or to a control system of the vehicle. &#x201c;High risk&#x201d; is herein to be understood as a risk above the threshold as indicated by the determined S<b>104</b> accident intensity.</p><p id="p-0048" num="0047">Accordingly, in some embodiments, the signal indicating the approaching high risk scenario is transmitted S<b>105</b> to the control system of the vehicle (e.g. to an ADS of the vehicle) in order to generate S<b>111</b> a hand-over request or initiate a hand-over procedure. The hand-over may either be from autonomous control to manual control (i.e. from the ADS to the driver) or vice versa, depending on the situation. Moreover, in some embodiments, the signal indicating the approaching high risk scenario is transmitted S<b>105</b> to the control system of the vehicle in order to activate S<b>112</b> one or more ADS features. In more detail, if it is concluded that the vehicle is approaching a high risk scenario, one may activate one or more suitable security measures (e.g. Emergency Brake Assist, Lane Keeping Assist, etc.).</p><p id="p-0049" num="0048">Further, in some embodiments, the signal indicating the approaching high risk scenario is transmitted S<b>105</b> to the control system of the vehicle in order to deactivate S<b>113</b> one or more ADS features. This may for example be done in connection with the completion of the hand-over procedure. In some embodiments, the signal indicating the approaching high risk scenario is transmitted S<b>105</b> to the control system of the vehicle in order to reduce S<b>114</b> a speed of the vehicle. Moreover, in some embodiments, the signal indicating the approaching high risk scenario is transmitted S<b>105</b> to the control system of the vehicle in order to obtain S<b>115</b> a new candidate path for execution by an Automated Driving System, ADS, of the vehicle, wherein the new candidate path is configured to avoid the upcoming road portion. Thereby, the vehicle may suggest a different route to the driver or to the ADS, given that the different route has the same goal position, as the previously intended route.</p><p id="p-0050" num="0049">Accordingly, by utilizing a trained model <b>25</b> to determine the accident intensity&#x2014;where the trained model is configured to determine an accident intensity associated with the upcoming road portion based on environmental data (e.g. time of day, weather conditions, states of surrounding vehicles, road conditions, current speed of ego-vehicle, etc.) and the vehicle's positional data&#x2014;the overall road safety and user-experience of a vehicle occupant can be improved.</p><p id="p-0051" num="0050">Executable instructions for performing these functions are, optionally, included in a non-transitory computer-readable storage medium or other computer program product configured for execution by one or more processors.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic block diagram representation of an apparatus, here represented by the accident intensity engine <b>45</b>, for alerting drivers and/or autonomous vehicles of high risk scenarios in accordance with an embodiment of the present invention. In general, <figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts the flow of information from the reporting of the position and heading and of the environmental data, to the accident intensity determination, and further to the potential high risk scenario notification that is transmitted to the ADS <b>46</b> or in-vehicle HMI <b>47</b>. It should be noted that even though the accident intensity engine <b>45</b> is exemplified as being comprised by the vehicle <b>1</b>, it should not be construed as limiting to the present invention. As mentioned in the foregoing, the accident intensity engine <b>45</b> may be arranged on one or more servers configured to transmit and receive data to/from the vehicle <b>1</b>.</p><p id="p-0053" num="0052">Moving on, the vehicle <b>1</b> has a localization system, such as e.g., a Global Navigation Satellite System (GNSS) configured to monitor a geographical position and heading/orientation of the vehicle <b>1</b>. In other words, the localization system is configured to monitor a pose of the vehicle. This positional data is sent to the accident intensity engine <b>45</b> together with environmental data indicating a state of the surrounding environment of the vehicle. The environmental data may for example be derived from sensor data <b>41</b> generated by suitable vehicle-mounted sensors or from an external source (e.g. a conventional weather forecast service). The sensor data <b>71</b> may for example output from one or more of a RADAR device, a LIDAR device, a camera, and ultrasonic sensor, and so forth. The sensor data may provided directly from the vehicle-mounted sensors or indirectly by a perception system of the vehicle. A &#x201c;perception system&#x201d; is in the present context to be understood as a system responsible for acquiring raw sensor data from on-board sensors such as cameras, LIDARs and RADARs, ultrasonic sensors, and converting this raw data into scene understanding including state estimates and predictions thereof.</p><p id="p-0054" num="0053">Furthermore in some embodiments, the vehicle <b>1</b> has access to map data (e.g. from a local data storage device) such as e.g., HD-map data. The map data may for example be indicative of a road geometry in the surrounding environment of the vehicle, and may be provided as an input to the accident intensity engine. Furthermore, in some embodiments, the accident intensity engine <b>45</b> is further configured to receive an intended path of the vehicle. The intended path may for example be provided by a path-planning module of an ADS or by the GNSS.</p><p id="p-0055" num="0054">The accident intensity engine <b>45</b> is further configured to determine, by means of a trained model, an accident intensity for an upcoming road portion for the vehicle <b>1</b>. The trained model is configured to determine an accident intensity associated with the upcoming road portion based on the obtained environmental data and the obtained positional data (and optionally further based on map data <b>42</b> and the intended path). Accordingly, if the determined accident intensity exceeds a threshold. Then, the accident intensity engine <b>45</b> is configured to transmit a signal indicating an approaching high risk scenario to a Human-Machine-Interface (HMI) <b>47</b> of the vehicle <b>1</b> and/or to a control system <b>46</b> of the vehicle <b>1</b>.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts a schematic side view of a vehicle <b>1</b> comprising an apparatus <b>10</b> for alerting drivers and/or autonomous vehicles of high risk scenarios. The vehicle <b>1</b> further comprises a perception system <b>6</b> and a localization system <b>5</b>. A perception system <b>6</b> is in the present context to be understood as a system responsible for acquiring raw sensor data from on-board sensors <b>6</b><i>a</i>, <b>6</b><i>b</i>, <b>6</b><i>c </i>such as cameras, LIDARs and RADARs, ultrasonic sensors, and converting this raw data into scene understanding. The localization system <b>5</b> is configured to monitor a geographical position and heading of the vehicle, and may in the form of a Global Navigation Satellite System (GNSS), such as a GPS. However, the localization system may alternatively be realized as a Real Time Kinematics (RTK) GPS in order to improve accuracy.</p><p id="p-0057" num="0056">In more detail, the perception system <b>6</b> may refer to any commonly known system and/or functionality, e.g. comprised in one or more electronic control modules and/or nodes of the vehicle <b>1</b>, adapted and/or configured to interpret sensory information&#x2014;relevant for driving of the vehicle <b>1</b>&#x2014;to identify e.g. obstacles, vehicle lanes, relevant signage, appropriate navigation paths etc. The exemplified perception system <b>6</b> may thus be adapted to rely on and obtain inputs from multiple data sources, such as automotive imaging, image processing, computer vision, and/or in-car networking, etc., in combination with sensory information. Such exemplifying sensory information may for instance be derived from one or more optional surrounding detecting sensors <b>6</b><i>a</i>-<i>c </i>comprised in and/or provided on-board the vehicle <b>1</b>. The surrounding detecting sensors <b>6</b><i>a</i>-<i>c </i>may be represented by any arbitrary sensors adapted to sense and/or perceive the vehicle's <b>1</b> surroundings and/or whereabouts, and may e.g. refer to one or a combination of one or more of radar, LIDAR, sonar, camera, navigation system e.g. GPS, odometer and/or inertial measurement units.</p><p id="p-0058" num="0057">The apparatus <b>10</b> comprises one or more processors <b>11</b>, a memory <b>12</b>, a sensor interface <b>13</b> and a communication interface <b>14</b>. The processor(s) <b>11</b> may also be referred to as a control circuit <b>11</b> or control circuitry <b>11</b>. The control circuitry <b>11</b> is configured to execute instructions stored in the memory <b>12</b> to perform a method for estimating a risk exposure of an ADS of the vehicle <b>1</b> according to any one of the embodiments disclosed herein. Stated differently, the memory <b>12</b> of the apparatus <b>10</b> can include one or more (non-transitory) computer-readable storage mediums, for storing computer-executable instructions, which, when executed by one or more computer processors <b>11</b>, for example, can cause the computer processors <b>11</b> to perform the techniques described herein. The memory <b>12</b> optionally includes high-speed random access memory, such as DRAM, SRAM, DDR RAM, or other random access solid-state memory devices; and optionally includes non-volatile memory, such as one or more magnetic disk storage devices, optical disk storage devices, flash memory devices, or other non-volatile solid-state storage devices. The apparatus <b>10</b> is further provided with a communication interface <b>14</b> and a sensor interface <b>13</b>.</p><p id="p-0059" num="0058">The control circuitry <b>11</b> is configured to obtain positional data of a vehicle, where the positional data indicates a geographical position and a heading of the vehicle. The control circuitry <b>11</b> is further configured to obtain environmental data of the vehicle, where the environmental data indicates a state of the surrounding environment of the vehicle. Moreover, the control circuitry <b>11</b> is configured to determine, by means of a trained model (such as e.g. the accident intensity model <b>25</b> illustrated in <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>), an accident intensity for an upcoming road portion for the vehicle. The trained model is accordingly configured to determine an accident intensity associated with the upcoming road portion based on the obtained environmental data and the obtained positional data. Then, if the determined accident intensity exceeds a threshold, the control circuitry <b>11</b> is configured to transmit a signal indicating an approaching high risk scenario to a Human-Machine-Interface (HMI) of the vehicle <b>1</b> and/or to a control system of the vehicle <b>1</b>.</p><p id="p-0060" num="0059">Furthermore, in some embodiments, the control circuitry <b>11</b> is configured to transmit the signal indicating an approaching high risk scenario to an HMI of the vehicle <b>1</b>, where the HMI is configured to at an electronic device with a display, displaying on the display a user interface comprising a graphical representation indicative of the exceeded threshold. This may for example be used to alert a driver of the vehicle of the upcoming high risk scenario and thereby provide the driver with the possibility to take the appropriate actions (e.g. slow down or take another route).</p><p id="p-0061" num="0060">Moreover, in some embodiments, the control circuitry is configured to transmit the signal indicating an approaching high risk scenario to a control system (e.g. an ADS) of the vehicle <b>1</b>. In more detail, the control circuitry <b>11</b> may thereby cause the ADS to generate a hand-over request, activate one or more ADS features, deactivate one or more ADS features, reduce a speed of the vehicle, and/or obtain a new candidate path for execution by the ADS. An &#x201c;ADS feature&#x201d; (also referred to as an ADS function) may for example be an &#x201c;auto pilot function&#x201d; or any other partly or fully automated feature for manoeuvring the vehicle <b>1</b> or supporting a driver of the vehicle <b>1</b>.</p><p id="p-0062" num="0061">Further, the vehicle <b>1</b> may be connected to external network(s) <b>20</b> via for instance a wireless link (e.g. for retrieving map data). The same or some other wireless link may be used to communicate with other vehicles <b>2</b> in the vicinity of the vehicle or with local infrastructure elements. Cellular communication technologies may be used for long range communication such as to external networks and if the cellular communication technology used have low latency it may also be used for communication between vehicles, vehicle to vehicle (V2V), and/or vehicle to infrastructure, V2X. Examples of cellular radio technologies are GSM, GPRS, EDGE, LTE, 5G, 5G NR, and so on, also including future cellular solutions. However, in some solutions mid to short range communication technologies are used such as Wireless Local Area (LAN), e.g. IEEE 802.11 based solutions. ETSI is working on cellular standards for vehicle communication and for instance 5G is considered as a suitable solution due to the low latency and efficient handling of high bandwidths and communication channels.</p><p id="p-0063" num="0062">The present invention has been presented above with reference to specific embodiments. However, other embodiments than the above described are possible and within the scope of the invention. Different method steps than those described above, performing the method by hardware or software, may be provided within the scope of the invention. Thus, according to an exemplary embodiment, there is provided a non-transitory computer-readable storage medium storing one or more programs configured to be executed by one or more processors of a vehicle control system, the one or more programs comprising instructions for performing the method according to any one of the above-discussed embodiments. Alternatively, according to another exemplary embodiment a cloud computing system can be configured to perform any of the methods presented herein. The cloud computing system may comprise distributed cloud computing resources that jointly perform the methods presented herein under control of one or more computer program products.</p><p id="p-0064" num="0063">Generally speaking, a computer-accessible medium may include any tangible or non-transitory storage media or memory media such as electronic, magnetic, or optical media&#x2014;e.g., disk or CD/DVD-ROM coupled to computer system via bus. The terms &#x201c;tangible&#x201d; and &#x201c;non-transitory,&#x201d; as used herein, are intended to describe a computer-readable storage medium (or &#x201c;memory&#x201d;) excluding propagating electromagnetic signals, but are not intended to otherwise limit the type of physical computer-readable storage device that is encompassed by the phrase computer-readable medium or memory. For instance, the terms &#x201c;non-transitory computer-readable medium&#x201d; or &#x201c;tangible memory&#x201d; are intended to encompass types of storage devices that do not necessarily store information permanently, including for example, random access memory (RAM). Program instructions and data stored on a tangible computer-accessible storage medium in non-transitory form may further be transmitted by transmission media or signals such as electrical, electromagnetic, or digital signals, which may be conveyed via a communication medium such as a network and/or a wireless link.</p><p id="p-0065" num="0064">The processor(s) <b>11</b> (associated with the apparatus <b>10</b>) may be or include any number of hardware components for conducting data or signal processing or for executing computer code stored in memory <b>12</b>. The apparatus <b>10</b> has an associated memory <b>12</b>, and the memory <b>12</b> may be one or more devices for storing data and/or computer code for completing or facilitating the various methods described in the present description. The memory may include volatile memory or non-volatile memory. The memory <b>12</b> may include database components, object code components, script components, or any other type of information structure for supporting the various activities of the present description. According to an exemplary embodiment, any distributed or local memory device may be utilized with the systems and methods of this description. According to an exemplary embodiment the memory <b>12</b> is communicably connected to the processor <b>11</b> (e.g., via a circuit or any other wired, wireless, or network connection) and includes computer code for executing one or more processes described herein.</p><p id="p-0066" num="0065">It should be appreciated that the sensor interface <b>14</b> may also provide the possibility to acquire sensor data directly or via dedicated sensor control circuitry <b>6</b> in the vehicle. The communication/antenna interface <b>14</b> may further provide the possibility to send output to a remote location (e.g. remote operator or control centre) by means of the antenna <b>8</b>. Moreover, some sensors in the vehicle may communicate with the apparatus <b>10</b> using a local network setup, such as CAN bus, I2C, Ethernet, optical fibres, and so on. The communication interface <b>14</b> may be arranged to communicate with other control functions of the vehicle and may thus be seen as control interface also; however, a separate control interface (not shown) may be provided. Local communication within the vehicle may also be of a wireless type with protocols such as WiFi, LoRa, Zigbee, Bluetooth, or similar mid/short range technologies.</p><p id="p-0067" num="0066">Accordingly, it should be understood that parts of the described solution may be implemented either in the vehicle, in a system located external the vehicle, or in a combination of internal and external the vehicle; for instance in a server in communication with the vehicle, a so called cloud solution. For instance, positional data may be sent to an external system and that system performs the steps to determine the accident intensity for an upcoming road portion of the vehicle <b>1</b>. The different features and steps of the embodiments may be combined in other combinations than those described.</p><p id="p-0068" num="0067">It should be noted that the word &#x201c;comprising&#x201d; does not exclude the presence of other elements or steps than those listed and the words &#x201c;a&#x201d; or &#x201c;an&#x201d; preceding an element do not exclude the presence of a plurality of such elements. It should further be noted that any reference signs do not limit the scope of the claims, that the invention may be at least in part implemented by means of both hardware and software, and that several &#x201c;means&#x201d; or &#x201c;units&#x201d; may be represented by the same item of hardware.</p><p id="p-0069" num="0068">Although the figures may show a specific order of method steps, the order of the steps may differ from what is depicted. In addition, two or more steps may be performed concurrently or with partial concurrence. For example, the steps of obtaining positional data and obtaining environmental data may be interchanged based on a specific realization. Such variation will depend on the software and hardware systems chosen and on designer choice. All such variations are within the scope of the invention. Likewise, software implementations could be accomplished with standard programming techniques with rule-based logic and other logic to accomplish the various connection steps, processing steps, comparison steps and decision steps. The above mentioned and described embodiments are only given as examples and should not be limiting to the present invention. Other solutions, uses, objectives, and functions within the scope of the invention as claimed in the below described patent embodiments should be apparent for the person skilled in the art.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for alerting drivers and/or autonomous vehicles of high risk scenarios, the method comprising:<claim-text>obtaining positional data of a vehicle, the positional data indicating a geographical position and a heading of the vehicle;</claim-text><claim-text>obtaining environmental data of the vehicle, the environmental data indicating a state of the surrounding environment of the vehicle;</claim-text><claim-text>determining, by means of a trained model, an accident intensity for an upcoming road portion for the vehicle, the trained model being configured to determine an accident intensity associated with the upcoming road portion based on the obtained environmental data and the obtained positional data; and</claim-text><claim-text>if the determined accident intensity exceeds a threshold, transmitting a signal indicating an approaching high risk scenario to a Human-Machine-Interface, HMI, of the vehicle and/or to a control system of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the trained model is formed based on accident data from an accident database comprising information about a plurality of critical scenarios at a time of each critical scenario and data indicative of frequencies of similar situations as the critical scenarios.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the data indicative of frequencies of measured similar situations as the critical scenarios is in the form of environmental data obtained over time from a plurality of vehicles in a fleet of vehicles.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the accident intensity is an intensity in a Poisson sense.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the positional data of the vehicle is further indicative of an intended path of the vehicle.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the environmental data is further indicative of a state of the vehicle.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of transmitting the signal indicating the approaching high risk scenario is transmitted to the HMI of the vehicle comprises:<claim-text>at an electronic device with a display:</claim-text><claim-text>displaying on the display a user interface comprising:</claim-text><claim-text>a graphical representation indicative of the exceeded threshold.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the signal indicating the approaching high risk scenario is transmitted to the control system of the vehicle in order to perform at least one of:<claim-text>generate a hand-over request;</claim-text><claim-text>activate one or more ADS features;</claim-text><claim-text>deactivate one or more ADS features;</claim-text><claim-text>reduce a speed of the vehicle;</claim-text><claim-text>obtain a new candidate path for execution by an Automated Driving System, ADS, of the vehicle, wherein the new candidate path is configured to avoid the upcoming road portion.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A non-transitory computer-readable storage medium storing one or more instructions configured to be executed by one or more processors of a processing system, the one or more instructions for performing the method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. An apparatus for alerting drivers and/or autonomous vehicles of high risk scenarios, the apparatus comprising control circuitry configured to:<claim-text>obtain positional data of a vehicle, the positional data indicating a geographical position and a heading of the vehicle;</claim-text><claim-text>obtain environmental data of the vehicle, the environmental data indicating a state of the surrounding environment of the vehicle;</claim-text><claim-text>determine, by means of a trained model, an accident intensity for an upcoming road portion for the vehicle, the trained model being configured to determine an accident intensity associated with the upcoming road portion based on the obtained environmental data and the obtained positional data; and</claim-text><claim-text>if the determined accident intensity exceeds a threshold, transmit a signal indicating an approaching high risk scenario to a Human-Machine-Interface, HMI, of the vehicle and/or to a control system of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A vehicle comprising:<claim-text>a localization system for generating positional data indicating a geographical location and a heading of the vehicle;</claim-text><claim-text>an apparatus for alerting drivers and/or autonomous vehicles of high risk scenarios, the apparatus comprising control circuitry configured to:</claim-text><claim-text>obtain positional data of a vehicle, the positional data indicating a geographical position and a heading of the vehicle;</claim-text><claim-text>obtain environmental data of the vehicle, the environmental data indicating a state of the surrounding environment of the vehicle;</claim-text><claim-text>determine, by means of a trained model, an accident intensity for an upcoming road portion for the vehicle, the trained model being configured to determine an accident intensity associated with the upcoming road portion based on the obtained environmental data and the obtained positional data; and</claim-text><claim-text>if the determined accident intensity exceeds a threshold, transmit a signal indicating an approaching high risk scenario to a Human-Machine-Interface, HMI, of the vehicle and/or to a control system of the vehicle.</claim-text></claim-text></claim></claims></us-patent-application>
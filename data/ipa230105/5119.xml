<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005120A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005120</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17843293</doc-number><date>20220617</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2021-110397</doc-number><date>20210701</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>001</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>20081</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">Computer and Visual Inspection Method</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Hitachi, Ltd.</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KONDO</last-name><first-name>Naoaki</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>ITO</last-name><first-name>Akira</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>MIYAMOTO</last-name><first-name>Atsushi</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present invention includes image acquiring for acquiring an inspection image of a target object, pass/fail determining for determining whether the inspection image acquired in the image acquiring is the inspection image of a non-defect candidate or the inspection image of a defect candidate, overdetection determining for determining whether the inspection image determined as a defect candidate in the pass/fail determining is the inspection image of overdetection or the inspection image of non-overdetection which is not overdetection, non-defect estimation parameter learning for learning a non-defect estimation parameter used in the pass/fail determining using a learning non-defect image acquired in the image acquiring, and overdetection determination parameter learning for learning an overdetection determination parameter used in the overdetection determining using the learning non-defect image.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="102.70mm" wi="158.75mm" file="US20230005120A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="233.43mm" wi="159.94mm" orientation="landscape" file="US20230005120A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="248.67mm" wi="142.58mm" orientation="landscape" file="US20230005120A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="137.08mm" wi="75.44mm" orientation="landscape" file="US20230005120A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="228.01mm" wi="145.20mm" orientation="landscape" file="US20230005120A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="246.21mm" wi="142.24mm" orientation="landscape" file="US20230005120A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="227.75mm" wi="159.85mm" orientation="landscape" file="US20230005120A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="254.34mm" wi="159.77mm" orientation="landscape" file="US20230005120A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="225.89mm" wi="159.94mm" orientation="landscape" file="US20230005120A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="254.17mm" wi="154.60mm" orientation="landscape" file="US20230005120A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="240.45mm" wi="159.77mm" orientation="landscape" file="US20230005120A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="220.22mm" wi="159.77mm" orientation="landscape" file="US20230005120A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="228.01mm" wi="139.36mm" orientation="landscape" file="US20230005120A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="253.49mm" wi="139.45mm" orientation="landscape" file="US20230005120A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="240.88mm" wi="159.68mm" orientation="landscape" file="US20230005120A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="151.21mm" wi="98.89mm" orientation="landscape" file="US20230005120A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="151.21mm" wi="99.74mm" orientation="landscape" file="US20230005120A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading><heading id="h-0002" level="1">1. Field of the Invention</heading><p id="p-0002" num="0001">The present invention relates to a computer and a visual inspection method.</p><heading id="h-0003" level="1">2. Description of Related Art</heading><p id="p-0003" num="0002">The present invention preferably relates to a computer and a visual inspection method which are based on machine learning. The present invention provides a device and method to inspect whether an actual inspection target object is a non-defective product or a defective product by using a non-defect estimation parameter and an overdetection determination parameter learned from learning non-defect images acquired by imaging a non-defective product for learning in advance.</p><p id="p-0004" num="0003">In many industrial products including machinery, metals, chemicals, foods, textiles, and the likes, based on inspection images, visual inspections are widely performed to inspect whether a product is a non-defective product or a defective product due to poor shape, poor assembly, adhesion of foreign matter, internal defects and fatality, scratches and spots on a surface, dirt, and the like. In general, most of these visual inspections have been performed by visual determination of an inspector.</p><p id="p-0005" num="0004">With the increasing demand for mass production and quality improvement, an inspection cost and a load on an inspector are increasing. In addition, sensory inspections based on human senses require particularly high experience and skills. Personality and reproducibility, such as different evaluation values depending on an inspector and different results for each inspection, are also issues. There is a strong demand for automation of inspections to address issues such as inspection costs, skills, and personality.</p><p id="p-0006" num="0005">In recent years, automatic visual inspections based on machine learning has been proposed. In the automatic visual inspections based on machine learning, correspondence between images of an inspection target object and determination results such as non-defect/defect taught by an inspector is learned.</p><p id="p-0007" num="0006">At the time of learning, it is desirable to prepare a large number of images of non-defective products and images of defective products, but in an industrial product manufacturing line, collecting images of defective products requires a great deal of cost. Therefore, a visual inspection method has been proposed in which machine learning is performed using only images of non-defective products to inspect whether the inspection target object is a non-defective product or a defective product.</p><p id="p-0008" num="0007">For example, in JP-A-2020-160616, a method of learning a neural network which outputs an image of a product without defects even when an image of a product with defects is input using an image of a product (non-defective product) without defects is disclosed.</p><p id="p-0009" num="0008">However, in the automatic visual inspection method based on machine learning represented by JP-A-2020-160616, since there are variations in brightness and shape among non-defective products, a non-defective portion whose appearance is significantly different from that of a typical non-defective product is often detected (over-detected) as a defect. Basically, in order to feed back countermeasures based on the content of defects to a manufacturing process, an inspector will check images detected by a visual inspection device as defects, but when the number of overdetections is large, the load on the inspector to check the images increases. Therefore, there is a need for a visual inspection method which reduces overdetection when learning using only images of non-defective products.</p><p id="p-0010" num="0009">In addition, there are variations in brightness and shape among defective products, so defective portions that are similar in appearance to those of the non-defective products are often determined (defect-overlooking) as non-defects. When a defect is overlooked, not only that it not be possible to provide feedback to the manufacturing process, but there is also the risk of shipping defective products. Therefore, when learning using only images of non-defective products, there is a need for a visual inspection method that reduces overlooking of defects.</p><heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0011" num="0010">The present invention is made in view of the problems described above, and an object of the present invention is to provide a computer and a visual inspection method capable of inspecting whether an inspection target object is a non-defective product or a defective product with high accuracy.</p><p id="p-0012" num="0011">To solve the problems described above, a computer which follows one aspect of the present invention is a computer which determines whether a target object is a non-defective product or a defective product. The computer has a processor and the processor executes image acquiring for acquiring an inspection image of the target object, pass/fail determining for determining whether the inspection image acquired in the image acquiring is the inspection image of a non-defect candidate or the inspection image of a defect candidate, overdetection determining for determining whether the inspection image determined as a defect candidate in the pass/fail determining is the inspection image of overdetection or the inspection image of non-overdetection which is not overdetection, non-defect estimation parameter learning for learning a non-defect estimation parameter used in the pass/fail determining using a learning non-defect image acquired in the image acquiring, and overdetection determination parameter learning for learning an overdetection determination parameter used in the overdetection determining using the learning non-defect image, and in the overdetection determination parameter learning, by using the learning non-defect image as the inspection image in the pass/fail determining, the overdetection determination parameter is learned such that, in the pass/fail determining, the inspection image of a non-defect candidate is determined as the inspection image of non-overdetection and the inspection image of a defect candidate is determined as the inspection image of overdetection.</p><p id="p-0013" num="0012">According to the present invention, it is possible to realize a computer and a visual inspection method capable of inspecting whether an inspection target object is a non-defective product or a defective product with high accuracy.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating a schematic configuration of a visual inspection device according to a first example;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example of an overall processing sequence of the visual inspection device according to the first example;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example of a neural network configuration of a non-defective product estimator used in the visual inspection device according to the first example;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating a pass/fail determination method for determining whether an inspection image by the visual inspection device according to the first example is a non-defect candidate or a defect candidate;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating an example of a general visual inspection method by learning using only non-defect images;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram illustrating an example of a learning method of an overdetection determination parameter by the visual inspection device according to the first example;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating an example of a learning method of an overdetection determination parameter by the visual inspection device according to the first example;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating an example of a learning method of an overdetection determination parameter by the visual inspection device according to the first example;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating an example of a learning method of an overdetection determination parameter by the visual inspection device according to the first example;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating an example of a learning method of an overdetection determination parameter by the visual inspection device according to the first example;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram illustrating a method of additionally learning a non-defect estimation parameter by the visual inspection device according to the first example;</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram illustrating a schematic configuration of a visual inspection device according to a second example;</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram illustrating an example of an overall processing sequence of the visual inspection device according to the second example;</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram illustrating a GUI which displays a screen for inputting a learning frequency and a pass/fail determination threshold value and selecting a first image from defect candidate images by the visual inspection device according to the first example or the second example;</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a schematic diagram of distribution of a normal portion, an overdetection portion, and an abnormal portion in a visual inspection method according to an embodiment; and</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a schematic diagram of distribution of a normal portion, an overdetection portion, and an overlooked portion in the visual inspection method according to the embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0030" num="0029">Hereinafter, an embodiment of the present invention will be described with reference to the drawings. The embodiment described below does not limit the invention according to the claims, and not all of elements and combinations thereof described in the embodiment are indispensable for means for solving the invention.</p><p id="p-0031" num="0030">In the drawing for illustrating the embodiment, the same reference numerals are given to the parts having the same function, and the repeated description thereof will be omitted.</p><p id="p-0032" num="0031">Further, in the following description, an expression such as &#x201c;xxx data&#x201d; may be used as an example of information, but the data structure of the information may be any. That is, the &#x201c;xxx data&#x201d; can be referred to as an &#x201c;xxx table&#x201d; to show that the information does not depend on the data structure. Further, the &#x201c;xxx data&#x201d; may be simply referred to as &#x201c;xxx&#x201d;. In the following description, the configuration of each information is an example, and the information may be divided and held, or may be combined and held.</p><p id="p-0033" num="0032">In the following description, the process may be described with &#x201c;program&#x201d; as the subject. The program is executed by a processor (for example, a central processing unit (CPU)) to perform a predetermined process while appropriately using a storage resource (for example, a memory) and/or a communication interface device (for example, a port). Thus, the subject of the process may be a program. The process described with the program as the subject may be a process performed by a processor or a computer having the processor.</p><p id="p-0034" num="0033">In the following description, when the action subject is described as &#x201c;oo portion is&#x201d;, this means that the processor reads a processing content of the oo portion, which is a program, from a memory, loads it into the memory, and then realizes the function (details will be described below) of the oo portion.</p><p id="p-0035" num="0034">As described above, there are some parts of non-defective products that are correctly determined as non-defects and some parts that are erroneously determined as defects. Among the non-defective products, a part that is correctly determined as a non-defect is referred to as a normal portion, and among the non-defective products, a part that is erroneously determined as a defect is determined as an overdetection portion. In addition, there are some parts of defective products that are erroneously determined as non-defects and some parts that are correctly determined as defects. Among the defective products, a part that is erroneously determined as a non-defect is referred to as an overlooked portion, and among the defective products, a part that is correctly determined as a defect is determined as an abnormal portion.</p><p id="p-0036" num="0035">A visual inspection device and a visual inspection method of the present embodiment have the following configurations as an example.</p><p id="p-0037" num="0036">(1) The present invention is characterized in that it is provided with an image acquisition portion for acquiring an inspection image of a target object, a pass/fail determination portion for inputting the inspection image acquired in the image acquisition portion and determining whether the inspection image is a non-defect candidate or a defect candidate, an overdetection determination portion for inputting the inspection image determined as a defect candidate in the pass/fail determination portion of the inspection images acquired in the image acquisition portion and determining whether the inspection image is overdetected or non-overdetected (not overdetected), a non-defect estimation parameter learning portion for learning a non-defect estimation parameter used in the pass/fail determination portion using a learning non-defect image acquired in the image acquisition portion, and an overdetection determination parameter learning portion for learning an overdetection determination parameter used in the overdetection determination portion using the learning non-defect image acquired in the image acquisition portion, where the overdetection determination parameter learning portion learns the overdetection determination parameter so as to input the learning non-defect images to the pass/fail determination portion, divide the learning non-defect images into the non-defect candidates and the defect candidates, and determine the non-defect candidate as non-overdetection and the defect candidate as overdetection.</p><p id="p-0038" num="0037">This characteristic is supplemented. What is detected as a defect by a general visual inspection method is an overdetection portion in a non-defective product or an abnormal portion in a defective product. Therefore, when it is possible to determine whether the part detected as a defect by the general visual inspection method is overdetected or non-overdetected (non-overdetection), by making a part determined to be non-overdetected a defect, only the defective portion can be detected, and thus reduction of overdetection can be expected.</p><p id="p-0039" num="0038">The subject of this process is how to learn the overdetection determination parameter used in the overdetection determination portion. When the overdetection determination parameter is learned using an image of the overdetection portion and an image of the abnormal portion, it is possible to determine an appropriate boundary for separating the distribution of the overdetection portion and the distribution of the abnormal portion in the feature amount space. However, it is not desirable because it is necessary to collect images of defective products for learning. Further, it is difficult to determine an appropriate boundary for separating the distribution of the overdetection portion and the distribution of a portion other than the overdetection portion only from the image of the overdetection portion.</p><p id="p-0040" num="0039">Therefore, in the present embodiment, by determining the boundary that separates the overdetection portion and the portion other than the overdetection portion using the image of the overdetection portion and the image of the normal portion, the boundary that is also applicable to the separation of the overdetection portion and the abnormal portion is determined.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates a schematic diagram of the distribution of the normal portion, the overdetection portion, and the abnormal portion. In <figref idref="DRAWINGS">FIG. <b>15</b></figref>, distribution <b>1301</b> of the normal portion, distribution <b>1302</b> of the overdetection portion, and distribution <b>1303</b> of the abnormal portion are illustrated as a two-dimensional distribution, that is, on the feature amount plane. In the present embodiment, boundary <b>1304</b> for separating the overdetection portion and the portion other than the overdetection portion is determined by using the image of the overdetection portion and the image of the normal portion. Specifically, in the present embodiment, images of non-defective products for learning are input to the pass/fail determination portion and the images of non-defective products for learning are divided into non-defect candidates and defect candidates, and then the overdetection determination parameter is learned so that the non-defect candidate is determined to be non-overdetected and the defect candidate is determined to be overdetected. <figref idref="DRAWINGS">FIG. <b>15</b></figref> (and <figref idref="DRAWINGS">FIG. <b>16</b></figref> described below) illustrates the distribution <b>1301</b> and the like of the normal portion on the feature amount plane, but this is merely a premise for facilitating understanding, and there is no problem in treating it as a multidimensional distribution of three or more dimensions.</p><p id="p-0042" num="0041">(2) The present invention is characterized in that, in the overdetection determination parameter learning portion, a defect candidate image cutting portion in which the learning non-defect image is input to the pass/fail determination portion and the part determined as a defect candidate is set as a defect candidate image, a first image acquisition portion which selects a first image from the defect candidate images, and a second image acquisition portion which sets an region other than the first image from the learning non-defect image as a second image are provided, and the overdetection determination parameter is learned so that the first image is determined as overdetection and the second image is determined as non-overdetection.</p><p id="p-0043" num="0042">This characteristic is supplemented. In general, the overdetection portion is often present in a local region of the image of a non-defective product, and most of the remaining regions are similar in appearance to that of a typical non-defective product. Therefore, when the overdetection determination parameter is learned using the entire image acquired in the image acquisition portion, the overdetection determination accuracy may decrease because the learning is performed including the characteristics of a region other than the overdetection portion.</p><p id="p-0044" num="0043">Therefore, in the present embodiment, by cutting out the part determined as a defect candidate by the pass/fail determination portion, the characteristics of the overdetection portion can be further learned, and thus the accuracy of the overdetection determination can be expected to be improved.</p><p id="p-0045" num="0044">In addition, since there are variations in the appearance of the parts that are determined as defect candidates by the pass/fail determination portion, even when all the images of the parts determined as defect candidates are used for learning the overdetection determination parameter, the characteristics of the overdetection portion cannot be learned, and thus the accuracy of overdetection determination may decrease. Therefore, in the present embodiment, by selecting the first image from the defect candidate images obtained by cutting out the parts determined as defect candidates by the pass/fail determination portion and learning the overdetection determination parameter so that the first image is determined to be overdetected, the characteristics of the overdetection portion can be learned more, and thus improvement in the accuracy of overdetection determination can be expected.</p><p id="p-0046" num="0045">(3) The present invention is characterized in that a normality determination portion which inputs the inspection image determined as a non-defect candidate in the pass/fail determination portion of the inspection images acquired in the image acquisition portion and determines whether the inspection image is normal or not (abnormal), and a normality determination parameter learning portion for learning a normality determination parameter used in the normality determination portion using the learning non-defect image acquired in the image acquisition portion are provided, and the normality determination parameter learning portion inputs the learning non-defect images to the pass/fail determination portion and divides the learning non-defect images into non-defect candidates and defect candidates, and then the normality determination parameter learning portion learns the normality determination parameter so that the non-defect candidates are determined to be normal and the defect candidates are determined to be abnormal.</p><p id="p-0047" num="0046">This characteristic is supplemented. What is determined as a non-defect by a general visual inspection method is the normal portion in the non-defective product or an overlooked portion in a defective product. Therefore, when it is possible to determine whether the part determined as a non-defect by a general visual inspection method is normal or abnormal, by making a part determined to be abnormal a defect, it is possible to detect a defective portion that has been overlooked in the related arts, and thus it is expected that the overlooked defect can be reduced.</p><p id="p-0048" num="0047">The subject of this process is how to learn the normality determination parameter used in the normality determination portion. When the normality determination parameter is learned using the image of the normal portion and the image of the overlooked portion, it is possible to determine an appropriate boundary for separating the distribution of the normal portion and the distribution of the overlooked portion in the feature amount space. However, it is not desirable because it is necessary to collect images of defective products for learning. In addition, it is difficult to determine an appropriate boundary for separating the distribution of the normal portion and the distribution of the portion other than the normal portion only from the image of the normal portion.</p><p id="p-0049" num="0048">Therefore, in the present embodiment, by using the image of the normal portion and the image of the overdetection portion to determine the boundary for separating the normal portion and the portion other than the normal portion, the boundary which is also applicable to the separation between the normal portion and the overlooked portion is determined.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>16</b></figref> illustrates a schematic diagram of the distribution of the normal portion, the overdetection portion, and the overlooked portion. <figref idref="DRAWINGS">FIG. <b>16</b></figref> illustrates distribution <b>1401</b> of the normal portion, distribution <b>1402</b> of the overdetection portion, and distribution <b>1403</b> of the overlooked portion as a two-dimensional distribution. In the present embodiment, a boundary <b>1404</b> for separating the normal portion and the portion other than the normal portion is determined by using the image of the normal portion and the image of the overdetection portion. Specifically, in the present embodiment, the images of non-defective products for learning are input to the pass/fail determination portion and divided into non-defect candidates and defect candidates, and then the normality determination parameter is learned so that the non-defect candidates are determined to be normal and the defect candidates are determined to be abnormal.</p><p id="p-0051" num="0050">According to the present embodiment, in automating visual inspection using machine learning, when learning using only images of non-defective products, it is possible to reduce overdetection of non-defective portions having a significantly different appearance from those of typical non-defective products, and to reduce overlooking of defective portions having similar appearances to those of non-defective products. This makes it possible to inspect whether the inspection target object is a non-defective product or a defective product with high accuracy.</p><heading id="h-0007" level="1">First Example</heading><heading id="h-0008" level="1">1. SCHEMATIC CONFIGURATION OF VISUAL INSPECTION DEVICE</heading><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating a schematic configuration of a visual inspection device according to a first example.</p><p id="p-0053" num="0052">A visual inspection device <b>10</b> is a device capable of various information processing, for example, an information processing device such as a computer. The visual inspection device <b>10</b> has a processor <b>11</b> and a memory <b>12</b>.</p><p id="p-0054" num="0053">The processor <b>11</b> is, for example, a central processing unit (CPU), a graphics processing unit (GPU), an field-programmable gate array (FPGA), or the like. The memory <b>12</b> includes, for example, a magnetic storage medium such as a hard disk drive (HDD), a semiconductor storage medium such as a random access memory (RAM), a read only memory (ROM), and a solid state drive (SSD), and the like. A combination of an optical disk such as a digital versatile disk (DVD) and an optical disk drive is also used as the memory. In addition, known storage media such as magnetic tape media are also used as the memory.</p><p id="p-0055" num="0054">A program such as firmware is stored in the memory <b>12</b>. When the action of the visual inspection device <b>10</b> starts (for example, when the power is turned on), a program such as firmware is read from the memory <b>12</b> and executed to perform overall control of the visual inspection device <b>10</b>. In addition to the program, the memory <b>12</b> stores data and the like required for each process of the visual inspection device <b>10</b>.</p><p id="p-0056" num="0055">Imaging means <b>13</b>, input means <b>14</b>, and display means <b>15</b> are connected to the visual inspection device <b>10</b>.</p><p id="p-0057" num="0056">The imaging means <b>13</b> is, for example, a CCD camera, an optical microscope, a charged particle microscope, an ultrasonic inspection device, an X-ray inspection device, or the like. The imaging means <b>13</b> outputs an inspection image to the visual inspection device <b>10</b> by capturing the surface or the inside of an inspection target object as a digital image. The input means <b>14</b> is, for example, a keyboard, a mouse, or the like, and outputs an operation input signal to the visual inspection device <b>10</b> based on an operation by an inspector of the visual inspection device <b>10</b>. The display means <b>15</b> is, for example, a display or the like, and displays a predetermined screen based on a display control signal transmitted from the visual inspection device <b>10</b>.</p><p id="p-0058" num="0057">The visual inspection device <b>10</b> of this example may be configured by a so-called cloud in which a plurality of information processing devices can communicate with each other via a communication network.</p><p id="p-0059" num="0058">The processor <b>11</b> of the visual inspection device <b>10</b> has an image acquisition portion <b>20</b>, a non-defect estimation parameter learning portion <b>21</b>, an overdetection determination parameter learning portion <b>22</b>, a pass/fail determination portion <b>23</b>, and an overdetection determination portion <b>24</b> as function realization portions. The overdetection determination parameter learning portion <b>22</b> has a defect candidate image cutting portion <b>22</b><i>a</i>, a first image acquisition portion <b>22</b><i>b</i>, and a second image acquisition portion <b>22</b><i>c. </i></p><p id="p-0060" num="0059">Further, a non-defect estimation parameter <b>30</b> and an overdetection determination parameter <b>31</b> are stored in the memory <b>12</b> of the visual inspection device <b>10</b>. The non-defect estimation parameter <b>30</b> has an initial non-defect estimation parameter <b>30</b><i>a </i>and a final non-defect estimation parameter <b>30</b><i>b. </i></p><p id="p-0061" num="0060">The details of each of the function realization portions provided in the processor <b>11</b> and the parameters stored in the memory <b>12</b> will be described below.</p><heading id="h-0009" level="1">2. ENTIRE PROCESSING SEQUENCE OF VISUAL INSPECTION DEVICE</heading><p id="p-0062" num="0061">The entire processing sequence of the visual inspection device <b>10</b> in this example is illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The processing sequence is roughly divided into a learning phase <b>101</b> and an inspection phase <b>102</b>.</p><p id="p-0063" num="0062">In the learning phase <b>101</b>, the image acquisition portion acquires a learning non-defect image <b>105</b> obtained by imaging a non-defective product <b>103</b> for learning (<b>104</b>). The learning non-defect image is acquired by capturing the surface or the inside of a non-defective product for learning as a digital image with the imaging means <b>13</b>.</p><p id="p-0064" num="0063">As another example of &#x201c;acquisition&#x201d;, an image captured by another system may be simply received and stored in the memory <b>12</b> of the visual inspection device <b>10</b>.</p><p id="p-0065" num="0064">Next, in the non-defect estimation parameter learning portion, the non-defect estimation parameter used in the pass/fail determination portion (details will be described below in <figref idref="DRAWINGS">FIG. <b>4</b></figref>) is learned using the learning non-defect image <b>105</b>, and the initial non-defect estimation parameter <b>107</b> is obtained (<b>106</b>).</p><p id="p-0066" num="0065">The non-defect estimation parameter is an internal parameter of a non-defective product estimator based on machine learning that outputs a pseudo non-defect image for difference calculation by inputting an image captured by the image acquisition portion. As the non-defective product estimator, various existing machine learning engines can be used, and examples thereof include a neural network as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> described below.</p><p id="p-0067" num="0066">In general, the image (inspection image) of the inspection target object acquired by the image acquisition portion is input to the non-defective product estimator, and the output pseudo non-defect image and the inspection image are compared and inspected, so that a part having a large difference is determined as a defect. However, as illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> described below, since non-defective products for learning also have variations in brightness and shape, a non-defective portion whose appearance is significantly different from that of a typical non-defective product is often detected (over-detected) as a defect.</p><p id="p-0068" num="0067">In this example, in the overdetection determination parameter learning portion, the learning non-defect images are input to the pass/fail determination portion and the input images are divided into non-defect candidate inspection images (hereinafter, simply referred to as &#x201c;non-defect candidates&#x201d;) and defect candidate inspection images (hereinafter, simply referred to as &#x201c;defect candidates&#x201d;) by using the initial non-defect estimation parameter <b>107</b>, and then an overdetection determination parameter <b>109</b> used in the overdetection determination portion is learned so that non-defect candidates are determined as non-overdetection (non-overdetected) inspection images (hereinafter, simply referred to as &#x201c;non-overdetection&#x201d;) and defect candidates are determined as overdetection inspection images (hereafter, simply referred to as &#x201c;overdetection&#x201d;) (<b>108</b>).</p><p id="p-0069" num="0068">The overdetection determination parameter is an internal parameter of the overdetection discriminator based on machine learning that determines whether it is overdetection or non-overdetection by inputting the image determined as a defect candidate by a pass/fail determination process from the images captured by the image acquisition portion. As the overdetection discriminator, various existing machine learning engines can be used, and for example, a deep neural network represented by a Convolutional Neural Network (CNN), a Support Vector Machine (SVM)/Support Vector Regress (SVR), a k-nearest neighbor (k-NN), and the like can be exemplified. These engines can handle classification problems.</p><p id="p-0070" num="0069">Further, in this example, in the non-defect estimation parameter learning portion, the learning non-defect images are divided into non-defect candidates and defect candidates by the pass/fail determination process, and the non-defect candidate which is determined to be overdetected as a result of inputting the non-defect candidates to the overdetection determination portion and the defect candidate which is determined to be non-overdetected as a result of inputting the defect candidate to the overdetection determination portion are used to additionally learn a non-defect estimation parameter, in such a manner that a final non-defect estimation parameter <b>111</b> is obtained (<b>110</b>). Details of the additional learning of the non-defect estimation parameter will be described with reference to <figref idref="DRAWINGS">FIG. <b>11</b></figref> described below. The initial non-defect estimation parameter <b>107</b> may be set to the final non-defect estimation parameter <b>111</b> without performing the additional learning.</p><p id="p-0071" num="0070">In the inspection phase <b>102</b>, an inspection image <b>122</b> obtained by imaging an inspection target object <b>120</b> is acquired in the image acquisition portion (<b>121</b>). The inspection image <b>122</b> is acquired by capturing the surface or the inside of the inspection target object <b>120</b> as a digital image by the imaging means <b>13</b>.</p><p id="p-0072" num="0071">Next, as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, which will be described below, the inspection image is input to the pass/fail determination portion, and the image is determined whether it is a non-defect candidate or a defect candidate by using the final non-defect estimation parameter <b>111</b> (<b>123</b>). Next, among the inspection images, an inspection image <b>124</b> determined as a defect candidate in <b>123</b> is input to the overdetection determination portion, and it is determined whether the inspection image is overdetection or non-overdetection, and then the inspection image determined to be non-overdetected is output as a defect image <b>126</b> (<b>125</b>). The defect image <b>126</b> is confirmed by an inspector (<b>127</b>), and when there is a defect or the like, the countermeasure is fed back to a manufacturing process.</p><heading id="h-0010" level="1">3. NON-DEFECTIVE PRODUCT ESTIMATOR</heading><p id="p-0073" num="0072">As a non-defective product estimator which estimates a pseudo non-defect image from an input image in this example, for example, a convolutional neural network described in Document (Dong, Chao, et al. &#x201c;Image super-resolution using deep convolutional networks.&#x201d; arXiv preprint arXiv: 1501.00092 (2014)) may be used.</p><p id="p-0074" num="0073">Specifically, a neural network having a three-layer structure as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may be used. Here, Y indicates an input image, F1(Y) and F2(Y) indicate intermediate data, and F(Y) is an estimation result of a pseudo non-defect image.</p><p id="p-0075" num="0074">The intermediate data and the estimation result are calculated by the following equations (1) to (3). However, &#x201c;*&#x201d; represents a convolution operation. Here, W1 is a filter having a size of c0&#xd7;f1&#xd7;f1 whose the number is n1, where c0 represents the number of channels of the input image and f1 represents the size of a spatial filter. By convolving the c0&#xd7;f1&#xd7;f1 size filter n1 times in the input image, an n1 dimensional feature map can be obtained. B1 is an n1 dimensional vector and is a bias component corresponding to the filter whose the number is n1. Similarly, W2 is a filter having a size of n1&#xd7;f2&#xd7;f2 whose the number is n2, and B2 is an n2 dimensional vector. Also, W3 is a filter having a size of n2&#xd7;f3&#xd7;f3 whose the number is c0, and B3 is a c0 dimensional vector.</p><p id="p-0076" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>F</i>1(<i>Y</i>)=max(0,<i>W</i>1*<i>Y+B</i>1)&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0077" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>F</i>2(<i>Y</i>)=max(0,<i>W</i>2*<i>F</i>1(<i>Y</i>)+<i>B</i>2)&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0078" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>F</i>(<i>Y</i>)=<i>W</i>3*<i>F</i>2(<i>Y</i>)+<i>B</i>3&#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0079" num="0075">The above-mentioned c0 is a value determined by the number of channels of the input image. Further, f1 and f2, n1 and n2 are hyperparameters determined by a user before the learning sequence, and for example, f1=9, f2=5, n1=128, and n2=64 may be set. The parameters to be adjusted in the non-defect estimation parameter learning portion are W1, W2, W3, B1, B2, and B3.</p><p id="p-0080" num="0076">In learning the non-defect estimation parameters, by inputting the learning non-defect image into the non-defective product estimator, the pseudo non-defect image is estimated and the estimation error between the learning non-defect image and the pseudo non-defect image is calculated, and then the non-defect estimation parameter is updated so as to reduce the estimation error. Learning is performed by repeating this process for a predetermined number of times N1 of learnings of non-defect estimation parameters.</p><p id="p-0081" num="0077">Even when the number of repetitions is less than N1, the learning may be finished when the estimation error is small or when an operation of finishing the learning is received from a user such as an inspector.</p><p id="p-0082" num="0078">In updating the non-defect estimation parameter, error backpropagation, which is common in neural network learning, may be used. Further, when calculating the estimation error, all of the learning non-defect images may be used, but a mini-batch method may be adopted. That is, several images may be randomly extracted from the learning non-defect image, and the non-defect estimation parameter may be updated repeatedly.</p><p id="p-0083" num="0079">Further, a patch image may be randomly cut out from the learning non-defect image and used as the input image Y of the neural network. As a result, learning can be performed efficiently.</p><p id="p-0084" num="0080">In addition, another configuration may be used as the configuration of the convolutional neural network described above. For example, the number of layers may be changed, a network having four or more layers may be used, or a configuration having a skip connection may be used.</p><heading id="h-0011" level="1">4. PASS/FAIL DETERMINATION</heading><p id="p-0085" num="0081"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a method of determining whether the inspection image is a non-defect candidate or a defect candidate by using the pass/fail determination portion in this example. First, a pseudo non-defect image <b>308</b> is estimated from an inspection image <b>301</b> using a non-defect estimation parameter <b>306</b> learned in the non-defect estimation parameter learning portion (<b>307</b>). In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, as an example, three inspection images <b>302</b>, <b>303</b>, and <b>304</b> and a defect <b>305</b> are illustrated. Further, pseudo non-defect images <b>309</b>, <b>310</b>, and <b>311</b> estimated from the inspection images <b>302</b>, <b>303</b>, and <b>304</b>, respectively, are illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0086" num="0082">Next, a difference image <b>313</b> between the inspection image <b>301</b> and the pseudo non-defect image <b>308</b> is calculated (<b>312</b>). <figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates difference images <b>314</b>, <b>315</b>, and <b>316</b> corresponding to the inspection images <b>302</b>, <b>303</b>, and <b>304</b>, respectively. Next, with the difference image <b>313</b> as an input, a part where a pixel value of the difference image is smaller than a predetermined pass/fail determination threshold value TH is regarded as a non-defect candidate, and a part where the pixel value of the difference image is larger than TH is regarded as a defect candidate, and then a pass/fail determination result <b>318</b> is output (<b>317</b>). <figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates pass/fail determination results <b>319</b>, <b>320</b>, and <b>321</b> corresponding to the inspection images <b>302</b>, <b>303</b>, and <b>304</b>, respectively, and a defect candidate <b>322</b>.</p><heading id="h-0012" level="1">5. OVERDETECTION DETERMINATION</heading><heading id="h-0013" level="1">5.1 General Problem</heading><p id="p-0087" num="0083">As described above, in this example, in the overdetection determination parameter learning portion, the learning non-defect images are input to the pass/fail determination portion to divide them into the non-defect candidates and the defect candidates, and then the overdetection determination parameter is learned so that the non-defect candidates are determined to be non-overdetected and the defect candidates are determined to be overdetected.</p><p id="p-0088" num="0084">A general problem is that, since there are variations in brightness and shape among non-defective products, it is often the case that a non-defective portion having a significantly different appearance from that of a typical non-defective product is determined (over-detected) as a defect. <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a general visual inspection method by learning using only non-defect images.</p><p id="p-0089" num="0085">In a learning phase <b>401</b>, first, a non-defect estimation parameter <b>408</b> is learned by using a learning non-defect image <b>402</b> (<b>407</b>). <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates three learning non-defect images <b>403</b>, <b>404</b>, and <b>405</b> and an overdetection portion <b>406</b> as examples.</p><p id="p-0090" num="0086">In an inspection phase <b>410</b>, as described with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the non-defect estimation parameter <b>408</b> is used to perform a pass/fail determination on an inspection image <b>411</b>, and a pass/fail determination result <b>418</b> is obtained (<b>417</b>). In <figref idref="DRAWINGS">FIG. <b>5</b></figref>, as an example, three inspection images <b>412</b>, <b>413</b>, and <b>414</b>, a defect <b>415</b>, and an overdetection portion <b>416</b> are illustrated. Further, <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates pass/fail determination results <b>419</b>, <b>420</b>, and <b>421</b> corresponding to the inspection images <b>412</b>, <b>413</b>, and <b>414</b>, respectively and a defective part <b>422</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the overdetection portion <b>416</b> is overdetected. This occurs because the characteristics of the overdetection portion cannot be sufficiently learned when the number of learning non-defect images having an overdetection portion is small.</p><p id="p-0091" num="0087">What is determined as a defect by the method described with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref> is an overdetection portion in a non-defective product or an abnormal portion in a defective product. Therefore, when it is possible to determine whether the part determined as a defect by the method described with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref> is overdetected or non-overdetected, only a defective portion can be detected by defining the part determined to be non-overdetected as a defect, and thus it is possible to reduce overdetection.</p><p id="p-0092" num="0088">In this example, in the learning phase, the learning non-defect images are input to the pass/fail determination portion to divide them into non-defect candidates and defect candidates, and then the overdetection determination parameter is learned so that the non-defect candidates are determined to be non-overdetected and the defect candidates are determined to be overdetected. In the inspection phase, the inspection images are input to the pass/fail determination portion to determine whether it is a non-defect candidate or a defect candidate, and the inspection images determined as the defect candidates are input to the overdetection determination portion to determine whether it is overdetected or non-overdetected, and then the inspection image determined to be non-overdetected is output as a defect image. There are several examples of the learning method of the overdetection determination parameter in the learning phase of this example. Hereinafter, a typical example will be specifically described.</p><heading id="h-0014" level="1">5.2 Learning Method of Overdetection Determination Parameter 1</heading><p id="p-0093" num="0089">An example of the learning method of the overdetection determination parameter in this example will be described with reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0094" num="0090">In the example illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, first, a pass/fail determination is performed on a learning non-defect image <b>501</b> using an initial non-defect estimation parameter <b>506</b>, and a pass/fail determination result <b>508</b> is obtained (<b>507</b>). In <figref idref="DRAWINGS">FIG. <b>6</b></figref>, as an example, three learning non-defect images <b>502</b>, <b>503</b>, and <b>504</b> and an overdetection portion <b>505</b> are illustrated. Further, <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates pass/fail determination results <b>509</b>, <b>510</b>, and <b>511</b> corresponding to the learning non-defect images <b>502</b>, <b>503</b>, and <b>504</b>, respectively, and a defect candidate <b>512</b>.</p><p id="p-0095" num="0091">Next, among the learning non-defect images <b>501</b>, an image having a part determined as a defect candidate by pass/fail determination is referred to as a defect candidate image <b>514</b> (<b>513</b>). Next, among the learning non-defect images <b>501</b>, an image (image in which the entire region of the image is determined as a non-defect candidate) in which no part is determined as a defect candidate by pass/fail determination is defined as a non-defect candidate image <b>516</b> (<b>515</b>). Next, an overdetection determination parameter <b>518</b> is learned so as to determine the defect candidate image <b>514</b> as overdetection and the non-defect candidate image <b>516</b> as non-overdetection (<b>517</b>).</p><p id="p-0096" num="0092">In learning the overdetection determination parameter, by inputting the defect candidate images and the non-defect candidate images into the overdetection discriminator, it is determined whether the image is overdetected or non-overdetected, and based on the determination result, the determination error is calculated, and then the overdetection determination parameter is updated so that the determination error becomes smaller. Learning is performed by repeating this process for a predetermined number of times N2 of learnings of overdetection determination parameter.</p><p id="p-0097" num="0093">The determination error is calculated by the equation (4). In the equation (4), t_i is the correct label of an image i (i=1, 2, . . . , N, N: number of learning non-defect images), and y_i is the label representing the determination result of the image i. For example, the over-detection label may be 1 and the non-overdetection label may be 0. Even when the number of repetitions is less than N2, the learning may be finished when the determination error is small or when the operation of finishing the learning is received from a user such as an inspector.</p><p id="p-0098" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>L</i>={&#x3a3;(<i>t</i>_<i>i&#x2212;y</i>_<i>i</i>){circumflex over (&#x2003;)}2}/<i>N</i>&#x2003;&#x2003;(4)<?in-line-formulae description="In-line Formulae" end="tail"?></p><heading id="h-0015" level="1">5.3 Learning Method of Overdetection Determination Parameter 2</heading><p id="p-0099" num="0094">An example of the learning method of the overdetection determination parameter different from the example described in 5.2 in this example will be described with reference to <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0100" num="0095">In the example illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, first, as in the method described in 5.2, an initial non-defect estimation parameter <b>602</b> is used to perform the pass/fail determination of the learning non-defect image <b>601</b>, and the pass/fail determination result <b>604</b> is obtained (<b>603</b>).</p><p id="p-0101" num="0096">Next, a part determined as a defect candidate by the pass/fail determination is cut out as a defect candidate image <b>606</b> by using a defect candidate image cutting portion (<b>605</b>), and the defect candidate image <b>606</b> is displayed on the GUI by using a first image acquisition portion as illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> described below, and the inspector selects a first image <b>608</b> from the defect candidate image <b>606</b> (<b>607</b>), and then a part other than the first image <b>608</b> is cut out from the learning non-defect image <b>601</b> as a second image <b>610</b> by using a second image acquisition portion (<b>609</b>), and an overdetection determination parameter <b>612</b> is learned so that the first image <b>608</b> is determined to be overdetected and the second image <b>610</b> is determined to be non-overdetected (<b>611</b>).</p><p id="p-0102" num="0097">Therefore, in the example illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, by cutting out the part determined as a defect candidate by the pass/fail determination portion, the characteristics of the overdetection portion can be further learned, and the accuracy of the overdetection determination can be expected to be improved.</p><heading id="h-0016" level="1">5.4 Learning Method of Overdetection Determination Parameter 3</heading><p id="p-0103" num="0098">An example of the learning method of the overdetection determination parameter different from the examples described in 5.2 to 5.3 in this example will be described with reference to <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0104" num="0099">In the example illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, first, as in the method described in 5.2, an initial non-defect estimation parameter <b>702</b> is used to perform the pass/fail determination of a learning non-defect image <b>701</b>, and a pass/fail determination result <b>704</b> is obtained (<b>703</b>).</p><p id="p-0105" num="0100">Next, among learning non-defect images <b>701</b>, the image having a part determined as a defect candidate by the pass/fail determination is designated as a defect candidate image <b>706</b> (<b>705</b>), and the defect candidate image <b>706</b> is displayed in the GUI and the inspector selects a first image <b>708</b> from the defect candidate image <b>706</b> (<b>707</b>) by using the first image acquisition portion, and then, from the learning non-defect images <b>701</b>, the images other than the first image <b>708</b> are designated as second images <b>710</b> (<b>709</b>) by using the second image acquisition portion, and the overdetection determination parameter <b>612</b> is learned so that the first image <b>708</b> is determined to be overdetected and the second image <b>710</b> is determined to be non-overdetected (<b>711</b>).</p><p id="p-0106" num="0101">Therefore, in the example illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, by acquiring the defect candidate images determined as the defect candidates by the pass/fail determination portion and selecting the first image from these defect candidate images, the characteristics of the overdetection portion can be further learned. As a result, it is expected that the accuracy of overdetection determination will be improved.</p><heading id="h-0017" level="1">5.5 Learning Method of Overdetection Determination Parameter 4</heading><p id="p-0107" num="0102">An example of the learning method of the overdetection determination parameter different from the examples described in 5.2 to 5.4 in this example will be described with reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0108" num="0103">In the example illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, first, as in the method described in 5.2, an initial non-defect estimation parameter <b>802</b> is used to perform the pass/fail determination of a learning non-defect image <b>801</b>, and a pass/fail determination result <b>804</b> is obtained (<b>803</b>).</p><p id="p-0109" num="0104">Next, a part determined as a defect candidate by the pass/fail determination is cut out as a first image <b>806</b> from the learning non-defect image <b>801</b> by using a first image acquisition portion (<b>805</b>), and a part (a part determined as the non-defect candidate by the pass/fail determination) other than the first image <b>806</b> is cut out as a second image <b>808</b> from the learning non-defect image <b>801</b> by using a second image acquisition portion (<b>807</b>), and then an overdetection determination parameter <b>810</b> is learned so that the first image <b>806</b> is determined to be overdetected and the second image <b>808</b> is determined to be non-overdetected (<b>809</b>).</p><p id="p-0110" num="0105">Therefore, in the example illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the characteristics of the overdetection portion can be further learned by cutting out the part determined as the defect candidate by the pass/fail determination portion as the first image. As a result, it is expected that the accuracy of over-detection determination will be improved.</p><heading id="h-0018" level="1">5.6 Learning Method of Overdetection Determination Parameter 5</heading><p id="p-0111" num="0106">An example of the learning method of the overdetection determination parameter different from the examples described in 5.2 to 5.5 in this example will be described with reference to <figref idref="DRAWINGS">FIG. <b>10</b></figref>.</p><p id="p-0112" num="0107">In the example illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, first, as in the method described in 5.2, an initial non-defect estimation parameter <b>902</b> is used to perform the pass/fail determination of a learning non-defect image <b>901</b>, and a pass/fail determination result <b>904</b> is obtained (<b>903</b>).</p><p id="p-0113" num="0108">Next, regarding the part determined as a defect candidate in the pass/fail determination of the learning non-defect image <b>901</b>, the learning non-defect image <b>901</b> and a difference image calculated at the time of pass/fail determination are cut out, and a pair of the two cut out images is referred to as a first image pair <b>906</b> (<b>905</b>). In <figref idref="DRAWINGS">FIG. <b>10</b></figref>, as an example, three images <b>907</b>, <b>908</b>, and <b>909</b> obtained by cutting out defect candidate parts from the learning non-defect images are illustrated. Further, <figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates difference images <b>910</b>, <b>911</b>, and <b>912</b> corresponding to the images <b>907</b>, <b>908</b>, and <b>909</b>, respectively, and first image pairs <b>913</b>, <b>914</b>, and <b>915</b>.</p><p id="p-0114" num="0109">Next, regarding the parts (the parts determined as non-defect candidates by the pass/fail determination) other than the first images <b>906</b> of the learning non-defect images <b>901</b>, the learning non-defect images <b>901</b> and the difference images calculated at the time of pass/fail determination are cut out, and a pair of the two cut out images is referred to as a second image pair <b>917</b> (<b>916</b>). In <figref idref="DRAWINGS">FIG. <b>10</b></figref>, as an example, three images <b>918</b>, <b>919</b>, and <b>920</b> obtained by cutting out the non-defect candidate parts from the learning non-defect images are illustrated. Further, <figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates difference images <b>921</b>, <b>922</b>, and <b>923</b> corresponding to the images <b>918</b>, <b>919</b>, and <b>920</b>, respectively, and second image pairs <b>924</b>, <b>925</b>, and <b>926</b>.</p><p id="p-0115" num="0110">Next, an overdetection determination parameter <b>928</b> is learned so that the first image pair <b>906</b> is determined to be overdetected and the second image pair <b>917</b> is determined to be non-overdetected (<b>927</b>).</p><p id="p-0116" num="0111">Therefore, in the example illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, by cutting out the learning non-defect images and the difference images calculated at the time of pass/fail determination for each of the parts determined as non-defect candidates and defect candidates in the pass/fail determination by using the pass/fail determination portion, it is determined that whether the inspection images are non-defect candidates or defect candidates. Therefore, it is possible to reliably determine whether the inspection images are non-defect candidates or defect candidates.</p><p id="p-0117" num="0112">In addition, in the example illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, since the overdetection determination parameter is learned using this difference images and the learning non-defect images, it is possible to learn more about the characteristics of the overdetection portion. As a result, it is expected that the accuracy of overdetection determination will be improved.</p><heading id="h-0019" level="1">5.7 Effect of Overdetection Determination</heading><p id="p-0118" num="0113">In the visual inspection device in this example, the overdetection determination parameter is learned by the method described in 5.2 to 5.7 in the learning phase. In the inspection phase, it is the overdetection portion or the defective portion in the non-defective product that is determined as a defect candidate by the pass/fail determination.</p><p id="p-0119" num="0114">Therefore, by using the overdetection determination parameter learned in the learning phase, it is determined whether the part determined as a defect candidate by the pass/fail determination is overdetected or non-overdetected, and the part determined to be non-overdetection is regarded as a defect, in such manner that only defective portions can be detected and overdetection can be reduced.</p><p id="p-0120" num="0115">Therefore, according to this example, it is possible to realize the visual inspection device and the visual inspection method capable of inspecting whether the inspection target object is a non-defective product or a defective product with high accuracy.</p><heading id="h-0020" level="1">6. ADDITIONAL LEARNING</heading><p id="p-0121" num="0116">A method of additionally learning the non-defect estimation parameter using the non-defect estimation parameter learning portion in this example will be described with reference to <figref idref="DRAWINGS">FIG. <b>11</b></figref>.</p><p id="p-0122" num="0117">First, pass/fail determination is performed on learning non-defect images <b>1001</b> by using an initial non-defect estimation parameter <b>1002</b>, and an image (image in which the entire region is determined as a non-defect candidate) in which there is no part determined as the defect candidate is acquired as a non-defect candidate image <b>1004</b>, and then an image having a part determined as a defect candidate is acquired as a defect candidate image <b>1005</b> (<b>1003</b>).</p><p id="p-0123" num="0118">Next, by using an overdetection determination parameter <b>1006</b> learned in the overdetection determination parameter learning portion, non-defect candidate images are input to the overdetection determination portion, and an image determined to be overdetected is acquired as an overdetection image <b>1008</b> (<b>1007</b>).</p><p id="p-0124" num="0119">Next, by using the overdetection determination parameter <b>1006</b> learned in the overdetection determination parameter learning portion, defect candidate images are input to the overdetection determination portion, and an image determined to be non-overdetected is acquired as a non-overdetection image <b>1010</b> (<b>1009</b>).</p><p id="p-0125" num="0120">Next, a final non-defect estimation parameter <b>1012</b> is obtained by performing additional learning using the overdetection image <b>1008</b> and the non-overdetection image <b>1010</b> with the initial non-defect estimation parameter as an initial value of the non-defect estimation parameter (<b>1011</b>).</p><p id="p-0126" num="0121">Therefore, in an example illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, by performing the additional learning using the overdetection image and the non-overdetection image, the characteristics of the overdetection portion can be further learned, and thus the accuracy of the overdetection determination can be expected to be improved.</p><heading id="h-0021" level="1">Second Example</heading><heading id="h-0022" level="1">7. SCHEMATIC CONFIGURATION OF VISUAL INSPECTION DEVICE</heading><p id="p-0127" num="0122"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram illustrating a schematic configuration of a visual inspection device according to a second example.</p><p id="p-0128" num="0123">The processor <b>11</b> of the visual inspection device <b>10</b> includes, as function realization portions, the image acquisition portion <b>20</b>, the non-defect estimation parameter learning portion <b>21</b>, the overdetection determination parameter learning portion <b>22</b>, and a normality determination parameter learning portion <b>25</b>.</p><p id="p-0129" num="0124">Further, the memory <b>12</b> of the visual inspection device <b>10</b> stores the non-defect estimation parameter <b>30</b>, the overdetection determination parameter <b>31</b>, and a normality determination parameter <b>32</b>.</p><heading id="h-0023" level="1">8. NORMALITY DETERMINATION</heading><p id="p-0130" num="0125">As the visual inspection device in this example, a processing sequence different from the processing sequence of <figref idref="DRAWINGS">FIG. <b>1</b></figref> will be described with reference to <figref idref="DRAWINGS">FIG. <b>13</b></figref>. The processing sequence is roughly divided into a learning phase <b>1101</b> and an inspection phase <b>1102</b>.</p><p id="p-0131" num="0126">In the learning phase <b>1101</b>, in the image acquisition portion, a learning non-defective product <b>1103</b> is imaged and a learning non-defect image <b>1105</b> is acquired (<b>1104</b>). Next, in the non-defect estimation parameter learning portion, the learning non-defect image <b>1105</b> is used to learn a non-defect estimation parameter <b>1107</b> used in the pass/fail determination portion (<b>1106</b>: the same as <b>106</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>).</p><p id="p-0132" num="0127">Next, in the overdetection determination parameter learning portion, the learning non-defect images <b>1106</b> are input to the pass/fail determination portion and are divided into non-defect candidates and defect candidates by using the non-defect estimation parameter <b>1107</b>, and then a overdetection determination parameter <b>1109</b> used in the overdetection determination portion is learned so that the non-defect candidate is determined to be non-overdetected and the defect candidate is determined to be overdetected (<b>1108</b>: the same as <b>108</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>).</p><p id="p-0133" num="0128">Next, in the normality determination parameter learning portion, the learning non-defect images <b>1106</b> are input to the pass/fail determination portion and are divided into non-defect candidates and defect candidates by using the non-defect estimation parameter <b>1107</b>, and then a normality determination parameter <b>1111</b> used in the normality determination portion is learned so that the non-defect candidate is determined to be normal and the defect candidate is determined to be abnormal (non-normal) (<b>1110</b>).</p><p id="p-0134" num="0129">The normality determination parameter is an internal parameter of a normality discriminator based on machine learning that determines whether it is normal or abnormal by inputting an image determined as a non-defect candidate by the pass/fail determination process from the images captured by the image acquisition portion. As the normality discriminator, as similar to the overdetection discriminator, various existing machine learning engines can be used, and for example, a deep neural network represented by a Convolutional Neural Network (CNN), a Support Vector Machine (SVM)/Support Vector Regress (SVR), a k-nearest neighbor (k-NN), and the like can be exemplified. These engines can handle classification problems.</p><p id="p-0135" num="0130">In the inspection phase <b>1102</b>, an inspection target object <b>1112</b> is imaged and an inspection image <b>1114</b> is acquired in the image acquisition portion (<b>1113</b>: the same as <b>121</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>). Next, the inspection images are input to the pass/fail determination portion, and the inspection images are divided into non-defect candidates <b>1118</b> and defect candidates <b>1116</b> by using the non-defect estimation parameter <b>1107</b> (<b>1115</b>).</p><p id="p-0136" num="0131">Next, among the inspection images, the inspection image <b>1116</b> determined as the defect candidate by <b>1115</b> is input to the overdetection determination portion, and it is determined whether the inspection image <b>1116</b> is overdetected or non-overdetected, and then the image determined to be non-overdetected is output as a defect image <b>1120</b> (<b>1117</b>: the same as <b>125</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>).</p><p id="p-0137" num="0132">Next, among the inspection images, the inspection image <b>1118</b> determined as the non-defect candidate by <b>1115</b> is input to the normality determination portion, and it is determined whether the inspection image <b>1118</b> is normal or abnormal, and then the image determined to be abnormal is output as a defect image <b>1120</b> (<b>1119</b>). The defect image <b>1120</b> is confirmed by the inspector (<b>1121</b>), and when there is a defect or the like, countermeasures are fed back to the manufacturing process.</p><p id="p-0138" num="0133">The general problem is that there are variations in brightness and shape among defective products, so defective portions that are similar in appearance to those of the non-defective products are often determined (defect-overlooking) as non-defects. In the pass/fail determination process, the normal portion in the non-defective product or the overlooked portion in the defective product is determined as a non-defect candidate. Therefore, when it is possible to determine whether the part determined as a non-defect candidate in the pass/fail determination process is normal or abnormal, a defective portion that has been overlooked in the past can be detected by setting the part determined to be abnormal as a defect.</p><p id="p-0139" num="0134">Thus, according to the example illustrated in <figref idref="DRAWINGS">FIGS. <b>12</b> and <b>13</b></figref>, in automating visual inspection using machine learning, when learning using only images of non-defective products, it is possible to reduce overdetection of non-defective portions having a significantly different appearance from those of typical non-defective products, and to reduce overlooking of defective portions having similar appearances to those of non-defective products. This makes it possible to inspect whether the inspection target object is a non-defective product or a defective product with high accuracy.</p><heading id="h-0024" level="1">9. GUI</heading><p id="p-0140" num="0135"><figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates an example of a graphical user interface (GUI) for a user such as an inspector to select a first image from defect candidate images when specifying the number of times of learnings of the non-defect estimation parameter and overdetection determination parameter and learning the overdetection determination parameter in the visual inspection device <b>10</b> of the first example and the second example described above.</p><p id="p-0141" num="0136">In this GUI <b>1201</b>, a pass/fail determination result <b>1202</b> of the learning non-defect image is displayed. As an example, <figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates pass/fail determination results <b>1203</b>, <b>1204</b>, and <b>1205</b> of three learning non-defect images.</p><p id="p-0142" num="0137">The GUI <b>1201</b> displays an input portion <b>1206</b> which specifies parameters used in the learning phase of the visual inspection device. The input portion <b>1206</b> is composed of an input portion <b>1207</b> that specifies the number of times N1 of learnings of the non-defect estimation parameter, an input portion <b>1208</b> that specifies the pass/fail determination threshold value TH, and an input portion <b>1209</b> that specifies the number of times N2 of learnings of the overdetection determination parameter.</p><p id="p-0143" num="0138">The GUI <b>1201</b> displays a selection portion <b>1210</b> for a user such as an inspector to select a first image from defect candidate images when learning the overdetection determination parameter. The selection portion <b>1210</b> includes a defect candidate image display portion <b>1211</b> for displaying a defect candidate image, an add button <b>1218</b>, a return button <b>1219</b>, and a first image display portion <b>1220</b> for displaying the first image.</p><p id="p-0144" num="0139">When a user such as an inspector selects a defect candidate image displayed on the defect candidate image display portion <b>1211</b> and presses the add button <b>1218</b>, the selected image is added to the first image. Further, when a user such as an inspector selects the first image displayed on the first image display portion <b>1220</b> and presses the return button <b>1219</b>, the selected image is excluded from the first image. <figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates defect candidate images <b>1212</b> to <b>1217</b> and first images <b>1221</b> to <b>1223</b> as examples.</p><heading id="h-0025" level="1">10. SUMMARY</heading><p id="p-0145" num="0140">As described above, in the present embodiment, in automating visual inspection using machine learning, a mechanism to determine whether an image determined as a defect candidate by the pass/fail determination is overdetected or non-overdetected, and output the image determined to be non-overdetected as a defect is provided. This makes it possible to reduce overdetection of non-defective portions whose appearance is significantly different from that of a typical non-defective product. In addition, a mechanism to determine whether an image determined as a non-defect candidate by the pass/fail determination is normal or abnormal, and output the image determined to be abnormal as a defect is provided. As a result, it is possible to reduce overlooking of defective portions having a similar appearance to that of a non-defective product. That is, it is possible to inspect whether the inspection target object is a non-defective product or a defective product with high accuracy.</p><heading id="h-0026" level="1">11. OTHERS</heading><p id="p-0146" num="0141">In the example described above, the configuration is described in detail in order to describe the present invention in an easy-to-understand manner, and the example is not necessarily limited to the one including all the described configurations. Further, it is possible to add, delete, or replace a part of the configuration of each example with other configurations.</p><p id="p-0147" num="0142">As an example, in the present embodiment, two-dimensional image data is treated as input information. However, the present invention can also be applied when a one-dimensional signal such as an ultrasonic received wave or a three-dimensional volume data acquired by a laser range finder or the like is used as input information.</p><p id="p-0148" num="0143">Further, each of the above-described configurations, functions, processing portions, processing means and the like may be realized by hardware by designing a part or all of them as, for example, an integrated circuit. The present invention can also be realized by a software program code that realizes the functions of the examples. In this case, a storage medium in which the program code is recorded is provided to the computer, and the processor included in the computer reads out the program code stored in the storage medium. In this case, the program code itself read from the storage medium realizes the function of the above-described example, and thus the program code itself and the storage medium storing the program code configure the present invention. Examples of the storage medium for supplying such a program code include a flexible disk, a CD-ROM, a DVD-ROM, a hard disk, a solid state drive (SSD), an optical disk, a magneto-optical disk, a CD-R, a magnetic tape, a non-volatile memory card, and a ROM.</p><p id="p-0149" num="0144">In addition, the program code that realizes the functions described in the example can be implemented in a wide range of programs or script languages such as assembler, C/C++, perl, Shell, PHP, Java (registered trademark), and Python.</p><p id="p-0150" num="0145">Further, all or part of the program code of the software that realizes the functions of each example may be stored in the memory <b>12</b> in advance. Further, if necessary, all or part of the program code may be stored in the memory <b>12</b> from a non-temporary storage device of another device connected to the network, or from a non-temporary storage medium via an external I/F (not illustrated) included in the inspection visual device <b>10</b>.</p><p id="p-0151" num="0146">Further, by distributing the program code of the software that realizes the functions of the example via the network, the program code may be stored in storage means such as a hard disk or memory of a computer or a storage medium such as a CD-RW or CD-R, and then the processor provided in the computer may read and execute the program code stored in the storage means or the storage medium.</p><p id="p-0152" num="0147">In the above-described examples, regarding the control lines and information lines, what is considered necessary for description is shown, and not all control lines and information lines are shown in terms of the product. All configurations may be interconnected.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer which determines whether a target object is a non-defective product or a defective product,<claim-text>wherein the computer has a processor, and the processor executes</claim-text><claim-text>image acquiring for acquiring an inspection image of the target object,</claim-text><claim-text>pass/fail determining for determining whether the inspection image acquired in the image acquiring is the inspection image of a non-defect candidate or the inspection image of a defect candidate,</claim-text><claim-text>overdetection determining for determining whether the inspection image determined as a defect candidate in the pass/fail determining is the inspection image of overdetection or the inspection image of non-overdetection which is not overdetection,</claim-text><claim-text>non-defect estimation parameter learning for learning a non-defect estimation parameter used in the pass/fail determining using a learning non-defect image acquired in the image acquiring, and</claim-text><claim-text>overdetection determination parameter learning for learning an overdetection determination parameter used in the overdetection determining using the learning non-defect image, and</claim-text><claim-text>wherein, in the overdetection determination parameter learning, by using the learning non-defect image as the inspection image in the pass/fail determining, the overdetection determination parameter is learned such that, in the pass/fail determining, the inspection image of a non-defect candidate is determined as the inspection image of non-overdetection and the inspection image of a defect candidate is determined as the inspection image of overdetection.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computer according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the overdetection determination parameter learning includes</claim-text><claim-text>defect candidate image cutting in which a part by which the learning non-defect image is determined as the inspection image of a defect candidate in the pass/fail determining is set as a defect candidate image,</claim-text><claim-text>first image acquiring for selecting a first image from the defect candidate images, and</claim-text><claim-text>second image acquiring in which, from the learning non-defect image, a region other than the first image is set as a second image, and</claim-text><claim-text>wherein, in the overdetection determination parameter learning, the overdetection determination parameter is learned so as to determine that the first image is the inspection image of overdetection and the second image is the inspection image of non-overdetection.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computer according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the overdetection determination parameter learning includes</claim-text><claim-text>first image acquiring for selecting a first image from the learning non-defect image determined that the learning non-defect image is the inspection image of a defect candidate in the pass/fail determining, and</claim-text><claim-text>second image acquiring for selecting the inspection image other than the first image of the learning non-defect images as a second image, and</claim-text><claim-text>wherein, in the overdetection determination parameter learning, the overdetection determination parameter is learned so as to determine that the first image is the inspection image of overdetection and the second image is the inspection image of non-overdetection.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computer according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the overdetection determination parameter learning includes</claim-text><claim-text>first image acquiring in which a part by which the learning non-defect image is determined as the inspection image of a defect candidate in the pass/fail determining is set as a first image, and</claim-text><claim-text>second image acquiring in which a part by which the learning non-defect image is determined as the inspection image of a non-defect candidate in the pass/fail determining is set as a second image, and</claim-text><claim-text>wherein, in the overdetection determination parameter learning, the overdetection determination parameter is learned so as to determine that the first image is the inspection image of overdetection and the second image is the inspection image of non-overdetection.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computer according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein, in the non-defect estimation parameter learning,</claim-text><claim-text>the non-defect estimation parameter is additional learned by using the inspection image determined as the inspection image of overdetection in the overdetection determining of the inspection images determined as non-defect candidates in the pass/fail determining, and the inspection image determined as the inspection image of non-overdetection in the overdetection determining of the inspection images determined as defect candidates in the pass/fail determining.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computer according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein, in the non-defect estimation parameter learning, the non-defect estimation parameter is learned so as to estimate the learning non-defect image based on the learning non-defect image, and</claim-text><claim-text>wherein, in the pass/fail determining, by estimating a pseudo non-defect image from the inspection image using the non-defect estimation parameter and calculating a difference image between the inspection image and the pseudo non-defect image, it is determined whether the inspection image is the inspection image of a non-defect candidate or the inspection image of a defect candidate.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computer according to <claim-ref idref="CLM-00006">claim 6</claim-ref>,<claim-text>wherein, in the overdetection determination parameter learning, the overdetection determination parameter is learned using the difference image obtained in the pass/fail determining and the learning non-defect image.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The computer according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising:<claim-text>normality determining for determining whether the inspection image is the inspection image having normality or the inspection image having abnormality opposite to normality based on the inspection image determined as the inspection image of a non-defect candidate in the pass/fail determining of the inspection images; and</claim-text><claim-text>normality determination parameter learning for learning a normality determination parameter used in the normality determining using the learning non-defect image,</claim-text><claim-text>wherein, in the normality determination parameter learning, by using the learning non-defect image as the inspection image in the pass/fail determining, the normality determination parameter is learned so that the inspection image of a non-defect candidate is determined as the inspection image with normality, and the inspection image of a defect candidate is determined as the inspection image with abnormality.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A visual inspection method which is executed by a computer for determining whether a target object is a non-defective product or a defective product, the method comprising:<claim-text>image acquiring for acquiring an inspection image of the target object;</claim-text><claim-text>pass/fail determining for determining whether the inspection image acquired in the image acquiring is the inspection image of a non-defect candidate or the inspection image of a defect candidate;</claim-text><claim-text>overdetection determining for determining whether the inspection image determined as a defect candidate in the pass/fail determining is the inspection image of overdetection or the inspection image of non-overdetection which is not overdetection;</claim-text><claim-text>non-defect estimation parameter learning for learning a non-defect estimation parameter used in the pass/fail determining using a learning non-defect image acquired in the image acquiring; and</claim-text><claim-text>overdetection determination parameter learning for learning an overdetection determination parameter used in the overdetection determining using the learning non-defect image,</claim-text><claim-text>wherein, in the overdetection determination parameter learning, by using the learning non-defect image as the inspection image in the pass/fail determining, the overdetection determination parameter is learned such that, in the pass/fail determining, the inspection image of a non-defect candidate is determined as the inspection image of non-overdetection and the inspection image of a defect candidate is determined as the inspection image of overdetection.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The visual inspection method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>.<claim-text>wherein the overdetection determination parameter learning includes,</claim-text><claim-text>defect candidate image cutting in which a part by which the learning non-defect image is determined as the inspection image of a defect candidate in the pass/fail determining is set as a defect candidate image,</claim-text><claim-text>first image acquiring for selecting a first image from the defect candidate images, and</claim-text><claim-text>second image acquiring in which, from the learning non-defect image, a region other than the first image is set as a second image, and</claim-text><claim-text>wherein, in the overdetection determination parameter learning, the overdetection determination parameter is learned so as to determine that the first image is the inspection image of overdetection and the second image is the inspection image of non-overdetection.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The visual inspection method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>.<claim-text>wherein the overdetection determination parameter learning includes</claim-text><claim-text>first image acquiring for selecting a first image from the learning non-defect image determined that the learning non-defect image is the inspection image of a defect candidate in the pass/fail determining, and</claim-text><claim-text>second image acquiring for selecting the inspection image other than the first image of the learning non-defect images as a second image, and</claim-text><claim-text>wherein, in the overdetection determination parameter learning, the overdetection determination parameter is learned so as to determine that the first image is the inspection image of overdetection and the second image is the inspection image of non-overdetection.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The visual inspection method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>.<claim-text>wherein the overdetection determination parameter learning includes</claim-text><claim-text>first image acquiring in which a part by which the learning non-defect image is determined as the inspection image of a defect candidate in the pass/fail determining is set as a first image, and</claim-text><claim-text>second image acquiring in which a part by which the learning non-defect image is determined as the inspection image of a non-defect candidate in the pass/fail determining is set as a second image, and</claim-text><claim-text>wherein, in the overdetection determination parameter learning, the overdetection determination parameter is learned so as to determine that the first image is the inspection image of overdetection and the second image is the inspection image of non-overdetection.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The visual inspection method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>.<claim-text>wherein, in the non-defect estimation parameter learning,</claim-text><claim-text>the non-defect estimation parameter is additional learned by using the inspection image determined as the inspection image of overdetection in the overdetection determining of the inspection images determined as non-defect candidates in the pass/fail determining, and the inspection image determined as the inspection image of non-overdetection in the overdetection determining of the inspection images determined as defect candidates in the pass/fail determining.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The visual inspection method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>,<claim-text>wherein, in the non-defect estimation parameter learning, the non-defect estimation parameter is learned so as to estimate the learning non-defect image based on the learning non-defect image, and</claim-text><claim-text>wherein, in the pass/fail determining, by estimating a pseudo non-defect image from the inspection image using the non-defect estimation parameter and calculating a difference image between the inspection image and the pseudo non-defect image, it is determined whether the inspection image is the inspection image of a non-defect candidate or the inspection image of a defect candidate.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A computer program for causing a computer to execute the visual inspection method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007146A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007146</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17757239</doc-number><date>20201204</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2019-229442</doc-number><date>20191219</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>213</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>13</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>213</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>13</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">IMAGE PROCESSING DEVICE, IMAGE PROCESSING METHOD, AND PROGRAM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>SONY SEMICONDUCTOR SOLUTIONS CORPORATION</orgname><address><city>KANAGAWA</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>NAGANO</last-name><first-name>HIROSUKE</first-name><address><city>TOKYO</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>YOSHIMURA</last-name><first-name>SHIN</first-name><address><city>KANAGAWA</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>KOBAYASHI</last-name><first-name>ATSURO</first-name><address><city>KANAGAWA</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/045174</doc-number><date>20201204</date></document-id><us-371c12-date><date>20220613</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present technology relates to an image processing device, an image processing method, and a program that are able to effectively reduce noise. The image processing device according to the present technology includes a feedback rate setting section, a blending section, and a calculation section. The feedback rate setting section sets a feedback rate for pixels in a current line on the basis of a count that is set for pixels in a previous line. The current line and the previous line are among a plurality of lines forming an image. The pixels in the current line are to be subjected to a blending process of blending inputted pixels in the current line and already outputted pixels in the previous line. The blending section blends the pixels in the current line and the pixels in the previous line in accordance with the feedback rate. The calculation section calculates a count that is indicative of the cumulative number of pixels blended with the pixels in the current line by the blending process and is to be set for the pixels in the current line. The present technology is applicable to in-vehicle cameras.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="78.06mm" wi="133.52mm" file="US20230007146A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="86.02mm" wi="135.55mm" file="US20230007146A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="87.12mm" wi="135.72mm" file="US20230007146A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="91.52mm" wi="91.52mm" file="US20230007146A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="143.26mm" wi="115.91mm" file="US20230007146A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="62.65mm" wi="111.25mm" file="US20230007146A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="63.16mm" wi="111.25mm" file="US20230007146A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="62.99mm" wi="135.72mm" file="US20230007146A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="62.65mm" wi="111.25mm" file="US20230007146A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="83.74mm" wi="171.03mm" file="US20230007146A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="83.48mm" wi="171.03mm" file="US20230007146A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="90.00mm" wi="135.64mm" file="US20230007146A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="37.68mm" wi="118.45mm" file="US20230007146A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="89.58mm" wi="127.85mm" file="US20230007146A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="150.03mm" wi="110.24mm" file="US20230007146A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present technology relates to an image processing device, an image processing method, and a program, and more particularly to an image processing device, an image processing method, and a program that are able to effectively reduce noise.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">Various technologies regarding image noise reduction have been proposed.</p><p id="p-0004" num="0003">For example, a technology described in PTL 1 reduces noise by performing a smoothing process on image data without losing sharp edges through the use of a &#x3b5; filter.</p><p id="p-0005" num="0004">Further, a technology described in PTL 2 relates to 3DNR (3-Dimensional Noise Reduction) for reducing noise by mixing two consecutive two-dimensional frames on the time axis through the use of a small number of frame buffers.</p><heading id="h-0003" level="1">CITATION LIST</heading><heading id="h-0004" level="1">Patent Literature</heading><heading id="h-0005" level="2">[PTL 1]</heading><p id="p-0006" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0005">Japanese Patent Laid-open No. 2004-172726</li></ul></p><heading id="h-0006" level="2">[PTL 2]</heading><p id="p-0007" num="0000"><ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0006">PCT Patent Publication No. WO 2014/188799</li></ul></p><heading id="h-0007" level="1">SUMMARY</heading><heading id="h-0008" level="1">Technical Problems</heading><p id="p-0008" num="0007">Incidentally, in a case of eliminating low-frequency noise, the technology described in PTL 1 references a large number of pixels. Therefore, this technology requires the use of a line buffer with large capacity.</p><p id="p-0009" num="0008">Similarly, the technology described in PTL 2 requires the use of a large-capacity buffer such as a frame buffer.</p><p id="p-0010" num="0009">The present technology has been made in view of the above circumstances, and is able to reduce noise more effectively with limited hardware resources.</p><heading id="h-0009" level="1">Solution to Problems</heading><p id="p-0011" num="0010">According to an aspect of the present technology, there is provided an image processing device including a feedback rate setting section, a blending section, and a calculation section. The feedback rate setting section sets a feedback rate for pixels in a current line on the basis of a count that is set for pixels in a previous line. The current line and the previous line are among a plurality of lines forming an image. The pixels in the current line are to be subjected to a blending process of blending inputted pixels in the current line and already outputted pixels in the previous line. The blending section blends the pixels in the current line and the pixels in the previous line in accordance with the feedback rate. The calculation section calculates a count that is indicative of the cumulative number of pixels blended with the pixels in the current line by the blending process and is to be set for the pixels in the current line.</p><p id="p-0012" num="0011">According to another aspect of the present technology, there is provided an image processing method for causing the image processing device to perform the steps of setting a feedback rate for pixels in a current line on the basis of a count that is set for pixels in a previous line, the current line and the previous line being among a plurality of lines forming an image, the pixels in the current line being to be subjected to a blending process of blending inputted pixels in the current line and already outputted pixels in the previous line, blending the pixels in the current line and the pixels in the previous line in accordance with the feedback rate, and calculating a count that is indicative of the cumulative number of pixels blended with the pixels in the current line by the blending process and is to be set for the pixels in the current line.</p><p id="p-0013" num="0012">According to still another aspect of the present technology, there is provided a program for causing a computer to perform the processes of setting a feedback rate for pixels in a current line on the basis of a count that is set for pixels in a previous line, the current line and the previous line being among a plurality of lines forming an image, the pixels in the current line being to be subjected to a blending process of blending inputted pixels in the current line and already outputted pixels in the previous line, blending the pixels in the current line and the pixels in the previous line in accordance with the feedback rate, and calculating a count that is indicative of the cumulative number of pixels blended with the pixels in the current line by the blending process and is to be set for the pixels in the current line.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0010" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating an example configuration of an in-vehicle camera system according to an embodiment of the present technology.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an example functional configuration of an image processing section.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart illustrating a noise reduction process of the image processing section.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating an output process that is performed in step S<b>3</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating an SNR improvement effect that is produced by a recursive 2DNR process without a fast convergence function.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram illustrating an SNR improvement effect that is produced by the recursive 2DNR process with the fast convergence function.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating an SNR improvement effect comparison between the recursive 2DNR process with the fast convergence function and the recursive 2DNR process without the fast convergence function.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating an example of the SNR improvement effect that is produced by the recursive 2DNR process with the fast convergence function as compared with the recursive 2DNR process without the fast convergence function.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating response characteristics in a situation where the strength of NR processing is low.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating the response characteristics in a situation where the strength of NR processing is high.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram illustrating an example functional configuration of the image processing section.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a block diagram illustrating an example hardware configuration of a computer.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a block diagram depicting an example of schematic configuration of a vehicle control system.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram of assistance in explaining an example of installation positions of an outside-vehicle information detecting section and an imaging section.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0011" level="1">DESCRIPTION OF EMBODIMENT</heading><p id="p-0028" num="0027">An embodiment of the present technology will now be described. The description will be given in the following order.</p><p id="p-0029" num="0028">1. Example Configuration of In-Vehicle Camera System</p><p id="p-0030" num="0029">2. Operations of Image Processing Section</p><p id="p-0031" num="0030">3. Effect of Recursive 2DNR Process with Fast Convergence Function</p><p id="p-0032" num="0031">4. Modification of Image Processing Section</p><p id="p-0033" num="0032">5. Other Modifications</p><heading id="h-0012" level="1">1. Example Configuration of In-Vehicle Camera System</heading><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating an example configuration of an in-vehicle camera system <b>1</b> according to an embodiment of the present technology.</p><p id="p-0035" num="0034">The in-vehicle camera system <b>1</b> depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is used by an in-vehicle camera that is utilized for an autonomous or advanced driving system. The in-vehicle camera system <b>1</b> is a system that captures a video image of the surroundings of an automobile and performs a noise reduction (NR) process on the captured video image.</p><p id="p-0036" num="0035">As depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the in-vehicle camera system <b>1</b> includes a lens L, a camera control section <b>11</b>, an imaging element <b>12</b>, an analog front-end <b>13</b>, an A/D conversion section <b>14</b>, an image processing section <b>15</b>, a recognizer <b>16</b>, an AD/ADAS control section <b>17</b>, a storage <b>18</b>, a D/A conversion section <b>19</b>, and a display section <b>20</b>.</p><p id="p-0037" num="0036">The lens L captures incident light from an object, guides the incident light to the imaging element <b>12</b>, and forms an image of the object on a light-receiving surface of the imaging element <b>12</b>.</p><p id="p-0038" num="0037">The camera control section <b>11</b> controls the operations of the imaging element <b>12</b>, the analog front-end <b>13</b>, the A/D conversion section <b>14</b>, and the image processing section <b>15</b>. For example, the camera control section <b>11</b> controls the operations of the individual components so as to perform a better imaging operation by using the result of NR processing performed by the image processing section <b>15</b>.</p><p id="p-0039" num="0038">The imaging element <b>12</b> includes, for example, a CCD (Charge Coupled Device) image sensor or a CMOS (Complementary Metal Oxide Semiconductor) image sensor. Electrons are accumulated in individual pixels of the imaging element <b>12</b> for a predetermined period according to the image of the object that is formed on the light-receiving surface through the lens L. Signals corresponding to the electrons accumulated in the individual pixels are supplied to the analog front-end <b>13</b>.</p><p id="p-0040" num="0039">The analog front-end <b>13</b> performs an analog process such as a process of amplifying the signals supplied from the imaging element <b>12</b>. The signals subjected to the analog process are supplied to the A/D conversion section <b>14</b>.</p><p id="p-0041" num="0040">The A/D conversion section <b>14</b> receives the signals supplied from the analog front-end <b>13</b>, and converts the received signals to digital image data. The digital image data is supplied to the image processing section <b>15</b>.</p><p id="p-0042" num="0041">The image processing section <b>15</b> performs a recursive 2DNR (2-Dimensional Noise Reduction) process with a later-described fast convergence function on the digital image data supplied from the A/D conversion section <b>14</b>. After being subjected to the recursive 2DNR process, the digital image data is supplied to the camera control section <b>11</b>, the recognizer <b>16</b>, the storage <b>18</b>, and the D/A conversion section <b>19</b>.</p><p id="p-0043" num="0042">For application to an autonomous or advanced driving system, the digital image data subjected to the recursive 2DNR process is supplied to the recognizer <b>16</b>. For application to a dashboard camera, the digital image data subjected to the recursive 2DNR process is supplied to the storage <b>18</b>. For application to a smart display or a rear-vision display, the digital image data subjected to the recursive 2DNR process is supplied to the D/A conversion section <b>19</b>.</p><p id="p-0044" num="0043">The recognizer <b>16</b> includes, for example, a DMS (Drive Monitoring System). On the basis of the digital image data supplied from the image processing section <b>15</b>, the recognizer <b>16</b> recognizes, for example, automobiles, persons, signs, traffic lights, and white lines around an automobile in which the in-vehicle camera system <b>1</b> is mounted. The recognizer <b>16</b> supplies the result of recognition to the AD/ADAS control section <b>17</b>.</p><p id="p-0045" num="0044">The AD/ADAS control section <b>17</b> is a component for implementing autonomous driving (AD) of an automobile in which the in-vehicle camera system <b>1</b> is mounted or implementing an advanced driver-assistance system (ADAS). On the basis of the result of recognition supplied from the recognizer <b>16</b>, the AD/ADAS control section <b>17</b> controls the driving of the automobile.</p><p id="p-0046" num="0045">The storage <b>18</b> includes an auxiliary storage device such as a semiconductor memory, a HDD (Hard Disk Drive), or other internal or external storage. The storage <b>18</b> stores the digital image data supplied from the image processing section <b>15</b>.</p><p id="p-0047" num="0046">The D/A conversion section <b>19</b> receives the digital image data from the image processing section <b>15</b>, and converts the received digital image data to an analog signal. The resulting analog signal is supplied to the display section <b>20</b>.</p><p id="p-0048" num="0047">The display section <b>20</b> includes, for example, a display or what is called a smart rear-view mirror. On the basis of the analog signal supplied from the D/A conversion section <b>19</b>, the display section <b>20</b> displays a video image.</p><p id="p-0049" num="0048">For example, the in-vehicle camera system <b>1</b> may be configured such that the camera control section <b>11</b>, the imaging element <b>12</b>, the analog front-end <b>13</b>, the A/D conversion section <b>14</b>, and the image processing section <b>15</b>, which are enclosed by a broken line in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, are built in a single sensor chip. Further, the recognizer <b>16</b> may also be built in the same sensor chip in addition to the components enclosed by the broken line.</p><p id="p-0050" num="0049">Alternatively, the in-vehicle camera system <b>1</b> may be configured such that the camera control section <b>11</b>, the imaging element <b>12</b>, the analog front-end <b>13</b>, and the A/D conversion section <b>14</b> are built in a single sensor chip while the image processing section <b>15</b> is built in an independent chip.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an example functional configuration of the image processing section <b>15</b>.</p><p id="p-0052" num="0051">As depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the image processing section <b>15</b> includes a noise amplitude calculation section <b>41</b>, a V direction plane detection section <b>42</b>, a count calculation section <b>43</b>, a line buffer section <b>44</b>, a SNR (Signal-to-Noise Ratio) optimal feedback rate setting section <b>45</b>, a multiplication section <b>46</b>, an alpha blending processing section <b>47</b>, and a line buffer section <b>48</b>.</p><p id="p-0053" num="0052">The image processing section <b>15</b> is a vertical direction recursive 2DNR circuit suitable for a RAW image in which same-color pixels exist at intervals of two lines like a Bayer pixel arrangement.</p><p id="p-0054" num="0053">The digital image data regarding individual lines forming an image acquired by the imaging element <b>12</b> is supplied from the A/D conversion section <b>14</b> to the image processing section <b>15</b>. The image processing section <b>15</b> sequentially performs the recursive 2DNR process with the fast convergence function on the line-specific digital image data in the order in which the line-specific digital image data is supplied from the A/D conversion section <b>14</b>. The description given with reference to <figref idref="DRAWINGS">FIGS. <b>2</b> to <b>4</b></figref> relates to the recursive 2DNR process that is performed on a pixel value X<sub>t=0 </sub>of one of a plurality of pixels included in a current line in a situation where a line supplied from the A/D conversion section <b>14</b> to the image processing section <b>15</b> is regarded as the current line to be processed. The recursive 2DNR process performed on one line of pixels by the image processing section <b>15</b> is similar to the recursive 2DNR process performed on the pixel value X<sub>t=0 </sub>of the above-mentioned one pixel.</p><p id="p-0055" num="0054">As depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the pixel value X<sub>t=0 </sub>of pixels in the current line is inputted to the noise amplitude calculation section <b>41</b> and the alpha blending processing section <b>47</b>. Further, the line buffer section <b>48</b>, which is capable of retaining three lines of pixel values, inputs an NR pixel value Y<sub>t=&#x2212;2 </sub>to the noise amplitude calculation section <b>41</b> and the alpha blending processing section <b>47</b>. Here, an NR pixel value Y<sub>t=0 </sub>is a pixel value that is obtained when NR processing is performed on the pixel value X<sub>t=0 </sub>of pixels in the current line, and the NR pixel value Y<sub>t=&#x2212;2 </sub>is the pixel value of pixels in a second preceding line, which corresponds to the NR pixel value Y<sub>t=0</sub>. That is, the NR pixel value Y<sub>t=&#x2212;2 </sub>is a pixel value obtained when NR processing is performed on a pixel that is included in the second line preceding the current line and positioned vertically with respect to a pixel having the pixel value X<sub>t=0</sub>. It should be noted that subscripts included in the pixel value X<sub>t=0 </sub>and the NR pixel value Y<sub>t=0 </sub>indicate the number of lines relative to the current line.</p><p id="p-0056" num="0055">On the basis of the pixel value X<sub>t=0 </sub>and the NR pixel value Y<sub>t=&#x2212;2</sub>, the noise amplitude calculation section <b>41</b> calculates the noise amplitude of shot noise in photoelectric conversion for each of a plurality of pixels included in the current line. The noise amplitude calculation section <b>41</b> supplies information indicating the noise amplitude of each of the plurality of pixels included in the current line to the V direction plane detection section <b>42</b> together with the pixel value X<sub>t=0 </sub>and the NR pixel value Y<sub>t=&#x2212;2</sub>.</p><p id="p-0057" num="0056">The V direction plane detection section <b>42</b> performs a detection operation on the basis of the pixel value X<sub>t=0 </sub>and the NR pixel value Y<sub>t=&#x2212;2</sub>, which are supplied from the noise amplitude calculation section <b>41</b>, and detects an edge appearing vertically with respect to the current line. More specifically, in a case where the difference between the pixel value X<sub>t=0 </sub>and the NR pixel value Y<sub>t=&#x2212;2 </sub>of a pixel is greater than the noise amplitude calculated by the noise amplitude calculation section <b>41</b>, the V direction plane detection section <b>42</b> detects an edge of the pixel. Meanwhile, in a case where the difference is smaller than the noise amplitude, the V direction plane detection section <b>42</b> does not detect an edge of the pixel, and in this case, the pixel is flat as viewed vertically with respect to the current line.</p><p id="p-0058" num="0057">The V direction plane detection section <b>42</b> sets an edge determination result Z<sub>t=0 </sub>of each of the plurality of pixels included in the current line for all the pixels included in the current line. For example, the V direction plane detection section <b>42</b> sets the edge determination result Z<sub>t=0 </sub>to 0 for a pixel whose edge is detected, and sets the edge determination result Z<sub>t=0 </sub>to 1 for a pixel whose edge is not detected. Then, the edge determination result Z<sub>t=0 </sub>set to 0 or 1 for each pixel in the current line is supplied to the count calculation section <b>43</b> and the multiplication section <b>46</b>.</p><p id="p-0059" num="0058">On the basis of the edge determination result Z<sub>t=0 </sub>of each of the plurality of pixels included in the current line, which is supplied from the V direction plane detection section <b>42</b>, and on the count N<sub>t=&#x2212;2 </sub>of each pixel in the second preceding line, which is acquired from the line buffer section <b>44</b>, the count calculation section <b>43</b> calculates the count N<sub>t=0 </sub>of each of the plurality of pixels included in the current line.</p><p id="p-0060" num="0059">More specifically, the count calculation section <b>43</b> calculates the count N<sub>t=0 </sub>of each of the plurality of pixels included in the current line by multiplying the edge determination result Z<sub>t=0 </sub>of each of the plurality of pixels included in the current line by the count N<sub>t=&#x2212;2 </sub>of each pixel in the second preceding line and adding 1 to the result of the multiplication. That is, the count N<sub>t=0 </sub>of a pixel is expressed by Equation (1) below.</p><p id="p-0061" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>[Math. 1]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0062" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>N</i><sub>t=0</sub><i>=Z</i><sub>t=0</sub><i>&#xd7;N</i><sub>t=&#x2212;2</sub>+1&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0063" num="0060">In the recursive 2DNR process, the pixel value X<sub>t=0 </sub>of pixels in the current line and the NR pixel value Y<sub>t=0 </sub>of pixels in the second preceding line are mixed (blended). As a result, noise is reduced comparably to a case where the pixel values of a wide range of pixels are mixed. That is, the use of a recursive filter makes it possible to consider that a wide range of noise reduction results derived from processing of up to the current line are degenerated to the pixel values of individual pixels included in the current line. Therefore, the count N<sub>t=0 </sub>is a value indicating the cumulative number of pixels (the range of processed pixels including up to the ones in the current line) mixed with the pixel values of individual pixels included in the current line.</p><p id="p-0064" num="0061">The count calculation section <b>43</b> supplies the count N<sub>t=0 </sub>of each of the plurality of pixels included in the current line to the line buffer section <b>44</b>.</p><p id="p-0065" num="0062">The line buffer section <b>44</b> includes line buffers for three lines. Each of the line buffers included in the line buffer section <b>44</b> stores the count of one line of pixels. That is, the line buffer section <b>44</b> stores the count N<sub>t=&#x2212;2 </sub>of each pixel in the second line preceding the current line, the count N<sub>t=&#x2212;1 </sub>of each pixel in the first line preceding the current line, and the count N<sub>t=0 </sub>of each pixel in the current line on an individual line basis.</p><p id="p-0066" num="0063">An SNR optimal feedback rate setting section <b>45</b> acquires, from the line buffer section <b>44</b>, the count N<sub>t=&#x2212;2 </sub>of each of the plurality of pixels included in the current line, which corresponds to the individual pixels in the second preceding line. Then, on the basis of the count N<sub>t=&#x2212;2 </sub>of pixels in the second preceding line, the SNR optimal feedback rate setting section <b>45</b> sets an iir (Infinite Impulse Response) feedback rate for each of the plurality of pixels included in the current line. More specifically, as indicated in Equation (2) below, the SNR optimal feedback rate setting section <b>45</b> adds 1 to the count N<sub>t=&#x2212;2 </sub>of pixels in the second preceding line, divides the count N<sub>t=&#x2212;2 </sub>of pixels in the second preceding line by the result of the addition, and sets the result of the division as the iir feedback rate.</p><p id="p-0067" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>[Math. 2]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0068" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>iir </i>feedback rate=<i>N</i><sub>t=&#x2212;2</sub><i>/N</i><sub>t=&#x2212;2</sub>+1&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0069" num="0064">The SNR optimal feedback rate setting section <b>45</b> supplies, to the multiplication section <b>46</b>, information indicative of the iir feedback rate set for each of the plurality of pixels included in the current line.</p><p id="p-0070" num="0065">The multiplication section <b>46</b> multiplies the edge determination result Z<sub>t=0 </sub>of each of the plurality of pixels included in the current line, which is supplied from the V direction plane detection section <b>42</b>, by the iir feedback rate for each pixel, which is supplied from the SNR optimal feedback rate setting section <b>45</b>. Accordingly, the multiplication section <b>46</b> calculates a mixing ratio &#x3b1; for each of the plurality of pixels included in the current line, and supplies the calculated mixing ratio &#x3b1; to the alpha blending processing section <b>47</b>.</p><p id="p-0071" num="0066">The alpha blending processing section <b>47</b> performs an alpha blending process on each of the plurality of pixels included in the current line in order to mix the pixel value X<sub>t=0 </sub>and the NR pixel value Y<sub>t=&#x2212;2 </sub>at the mixing ratio &#x3b1; for each pixel, which is supplied from the multiplication section <b>46</b>.</p><p id="p-0072" num="0067">More specifically, the alpha blending processing section <b>47</b> adds the result of multiplication of the pixel value X<sub>t=0 </sub>by (1&#x2212;&#x3b1;) to the result of multiplication of the NR pixel value Y<sub>t=&#x2212;2 </sub>by &#x3b1;, and outputs the result of the addition to a subsequent stage as the NR pixel value Y<sub>t=0</sub>. The alpha blending process performed by the alpha blending processing section <b>47</b> is expressed by Equation (3) below.</p><p id="p-0073" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>[Math. 3]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0074" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Y</i><sub>t=0</sub><i>=Y</i><sub>t=&#x2212;2</sub><i>&#xd7;&#x3b1;+X</i><sub>t=0</sub>&#xd7;(1&#x2212;&#x3b1;)&#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0075" num="0068">As mentioned earlier, for a pixel whose edge is detected, the V direction plane detection section <b>42</b> sets the edge determination result Z<sub>t=0 </sub>to 0. Therefore, the multiplication section <b>46</b> calculates that the mixing ratio &#x3b1; is 0 (=edge determination result Z<sub>t=0</sub>&#xd7;iir feedback rate). Consequently, for the pixel whose edge is detected, the alpha blending processing section <b>47</b> adds the result of multiplication of the pixel value X<sub>t=0 </sub>by 1 (=1&#x2212;&#x3b1;) to the result of multiplication of the NR pixel value Y<sub>t=&#x2212;2 </sub>by 0 (=&#x3b1;).</p><p id="p-0076" num="0069">Meanwhile, for a pixel whose edge is not detected, the V direction plane detection section <b>42</b> sets the edge determination result Z<sub>t=0 </sub>to 1. Therefore, the multiplication section <b>46</b> calculates that the mixing ratio &#x3b1; is the iir feedback rate (=edge determination result Z<sub>t=0</sub>&#xd7;iir feedback rate). Consequently, for the pixel whose edge is not detected, the alpha blending processing section <b>47</b> adds the result of multiplication of the pixel value X<sub>t=0 </sub>by 1/(N<sub>t=&#x2212;2</sub>+1) (=1&#x2212;&#x3b1;) to the result of multiplication of the NR pixel value Y<sub>t=&#x2212;2 </sub>by N<sub>t=&#x2212;2</sub>/(N<sub>t=&#x2212;2</sub>+1) (=&#x3b1;).</p><p id="p-0077" num="0070">The NR pixel value Y<sub>t=0 </sub>outputted from the alpha blending processing section <b>47</b> is not only supplied to the outside of the image processing section <b>15</b>, but also supplied to the line buffer section <b>48</b>. In this instance, the NR pixel value Y<sub>t=0 </sub>derived from a horizontal smoothing process performed on the current line can be supplied to the outside of the image processing section <b>15</b>.</p><p id="p-0078" num="0071">The line buffer section <b>48</b> includes line buffers for three lines. Each of the line buffers included in the line buffer section <b>48</b> stores the NR pixel value of one line of pixels. That is, the line buffer section <b>48</b> stores the NR pixel value Y<sub>t=&#x2212;2 </sub>of each pixel in the second line preceding the current line, the NR pixel value Y<sub>t=&#x2212;1 </sub>of each pixel in the first line preceding the current line, and the NR pixel value Y<sub>t=0 </sub>of each pixel in the current line on an individual line basis.</p><p id="p-0079" num="0072">As described above, according to the edge determination result, the image processing section <b>15</b> resets the count N<sub>t=0 </sub>to 1 for a pixel whose edge is detected, and increments the count N<sub>t=0 </sub>for a pixel whose edge is not detected. Further, the image processing section <b>15</b> determines the iir feedback rate on the basis of the count N<sub>t=&#x2212;2</sub>. Therefore, the iir feedback rate for a pixel whose edge is detected can be determined without being affected by a wide range of noise reduction results derived from processing of up to the current line. This enables the image processing section <b>15</b> to set the iir feedback rate for each pixel so as to be able to perform optimal NR processing with respect to SNR depending on whether or not an edge is detected.</p><p id="p-0080" num="0073">Accordingly, the image processing section <b>15</b> is able to provide convergence such that the influence of SNR upon a pixel whose edge is detected rapidly goes into a steady state. Therefore, the function of setting the iir feedback rate for making it possible to perform optimal NR processing with respect to SNR, which is implemented by the count calculation section <b>43</b> and the SNR optimal feedback rate setting section <b>45</b>, is referred to as the fast convergence function.</p><p id="p-0081" num="0074">Further, the image processing section <b>15</b> is able to perform NR processing by using the line buffer sections <b>44</b> and <b>48</b>, which have a smaller capacity than a large-capacity buffer such as a frame buffer, and reduce noise more effectively with limited hardware resources.</p><heading id="h-0013" level="1">2. Operations of Image Processing Section</heading><p id="p-0082" num="0075">A noise reduction process of the image processing section <b>15</b> having the above-described configuration will now be described with reference to the flowchart of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0083" num="0076">The noise reduction process depicted in <figref idref="DRAWINGS">FIG. <b>3</b></figref> starts when the current line is supplied from the A/D conversion section <b>14</b> to the image processing section <b>15</b>.</p><p id="p-0084" num="0077">In step S<b>1</b>, the noise amplitude calculation section <b>41</b> calculates the noise amplitude of each pixel in accordance with the pixel value X<sub>t=0 </sub>of the plurality of pixels included in the current line and with the NR pixel value Y<sub>t=&#x2212;2 </sub>corresponding to each of the pixels.</p><p id="p-0085" num="0078">In step S<b>2</b>, on the basis of the pixel value X<sub>t=0</sub>, the NR pixel value Y<sub>t=&#x2212;2 </sub>and the noise amplitude, the V direction plane detection section <b>42</b> detects an edge of each of the plurality of pixels included in the current line that appears vertically with respect to the current line. For example, in a case where the difference between the pixel value X<sub>t=0 </sub>and the NR pixel value Y<sub>t=&#x2212;2 </sub>of a pixel is equal to or greater than the noise amplitude calculated in step S<b>1</b>, the V direction plane detection section <b>42</b> detects an edge of the pixel.</p><p id="p-0086" num="0079">In step S<b>3</b>, the image processing section <b>15</b> performs an output process. The output process is performed to output the NR pixel value Y<sub>t=0 </sub>that is derived from NR processing performed on the pixel value X<sub>t=0 </sub>of the plurality of pixels included in the current line. The output process will be described later with reference to the flowchart of <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0087" num="0080">In step S<b>4</b>, the image processing section <b>15</b> determines whether or not the current line is the last line forming an acquired captured image. In a case where it is determined that the current line is not the last line, the image processing section <b>15</b> repeats processes of step S<b>1</b> and the subsequent steps.</p><p id="p-0088" num="0081">Meanwhile, in a case where it is determined that the current line is the last line, the process terminates.</p><p id="p-0089" num="0082">The output process performed in step S<b>3</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref> will now be described with reference to the flowchart of <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0090" num="0083">In step S<b>11</b>, on the basis of the count N<sub>t=&#x2212;2 </sub>of each pixel in the second preceding line, which is acquired from the line buffer section <b>44</b>, the SNR optimal feedback rate setting section <b>45</b> sets the iir feedback rate for each of the plurality of pixels included in the current line.</p><p id="p-0091" num="0084">In step S<b>12</b>, in a case where a determination is made on the basis of the result of detection in step S<b>2</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref> and an edge of a determination target pixel is detected, processing proceeds to step S<b>13</b>. In this case, for the determination target pixel, the V direction plane detection section <b>42</b> sets the edge determination result Z<sub>t=0 </sub>to 0.</p><p id="p-0092" num="0085">In step S<b>13</b>, the multiplication section <b>46</b> calculates the mixing ratio &#x3b1; by multiplying the edge determination result Z<sub>t=0 </sub>of each of the plurality of pixels included in the current line by the iir feedback rate for each pixel. For a pixel targeted for processing in step S<b>13</b>, the mixing ratio &#x3b1; is 0 because the edge determination result Z<sub>t=0 </sub>is set to 0 according to the result of determination in step S<b>12</b>. In this case, therefore, the ratio (1&#x2212;&#x3b1;) of mixing the pixel value X<sub>t=0 </sub>is 1. The multiplication section <b>46</b> supplies the mixing ratio &#x3b1; to the alpha blending processing section <b>47</b>, and the alpha blending processing section <b>47</b> sets 1 as the ratio (1&#x2212;&#x3b1;) of mixing the pixel value X<sub>t=0 </sub>of pixels in the current line.</p><p id="p-0093" num="0086">In step S<b>14</b>, the alpha blending processing section <b>47</b> generates the NR pixel value Y<sub>t=0 </sub>by mixing the pixel value X<sub>t=0 </sub>of pixels in the current line with the NR pixel value Y<sub>t=&#x2212;2 </sub>of pixels in the second preceding line at the mixing ratio &#x3b1; calculated in step S<b>13</b> by the multiplication section <b>46</b>.</p><p id="p-0094" num="0087">In step S<b>15</b>, the alpha blending processing section <b>47</b> not only outputs the NR pixel value Y<sub>t=0</sub>, which represents a noise reduction result generated in step S<b>14</b>, to a subsequent stage, but also causes the line buffer section <b>48</b> to store the NR pixel value Y<sub>t=0</sub>.</p><p id="p-0095" num="0088">In step S<b>16</b>, on the basis of the edge determination result Z<sub>t=0</sub>, the count calculation section <b>43</b> sets 1 as the count N<sub>t=0 </sub>of a currently processed pixel, and causes the line buffer section <b>44</b> for the count to store the count N<sub>t=0</sub>.</p><p id="p-0096" num="0089">Meanwhile, in a case where an edge of the determination target pixel is not detected in step S<b>12</b>, processing proceeds to step S<b>17</b>. In this case, for the determination target pixel, the V direction plane detection section <b>42</b> sets the edge determination result Z<sub>t=0 </sub>to 1.</p><p id="p-0097" num="0090">In step S<b>17</b>, the multiplication section <b>46</b> calculates the mixing ratio &#x3b1; by multiplying the edge determination result Z<sub>t=0 </sub>of each of the plurality of pixels included in the current line by the iir feedback rate for each pixel. For a pixel targeted for processing in step S<b>17</b>, the mixing ratio &#x3b1; is N<sub>t=&#x2212;2</sub>/(N<sub>t=&#x2212;2</sub>+1) because the edge determination result Z<sub>t=0 </sub>is set to 1 according to the result of determination in step S<b>12</b>. In this case, therefore, the ratio (1&#x2212;&#x3b1;) of mixing the pixel value X<sub>t=0 </sub>is 1/(N<sub>t=&#x2212;2</sub>+1). The multiplication section <b>46</b> supplies the mixing ratio &#x3b1; to the alpha blending processing section <b>47</b>, and the alpha blending processing section <b>47</b> sets 1/(N<sub>t=&#x2212;2</sub>+1) as the ratio (1&#x2212;&#x3b1;) of mixing the pixel value X<sub>t=0 </sub>of pixels in the current line.</p><p id="p-0098" num="0091">In step S<b>18</b>, the alpha blending processing section <b>47</b> generates the NR pixel value Y<sub>t=0 </sub>by mixing the pixel value X<sub>t=0 </sub>of pixels in the current line with the NR pixel value Y<sub>t=&#x2212;2 </sub>of pixels in the second preceding line at the mixing ratio &#x3b1; calculated in step S<b>17</b> by the multiplication section <b>46</b>.</p><p id="p-0099" num="0092">In step S<b>19</b>, the alpha blending processing section <b>47</b> not only outputs the NR pixel value Y<sub>t=0</sub>, which represents a noise reduction result generated in step S<b>18</b>, to a subsequent stage, but also causes the line buffer section <b>48</b> to store the NR pixel value Y<sub>t=0</sub>.</p><p id="p-0100" num="0093">In step S<b>20</b>, on the basis of the edge determination result Z<sub>t=0</sub>, the count calculation section <b>43</b> sets (N<sub>t=&#x2212;2</sub>+1) as the count N<sub>t=0 </sub>of a currently processed pixel, and causes the line buffer section <b>44</b> for the count to store the count N<sub>t=0</sub>. It should be noted that step S<b>12</b> and steps S<b>13</b> to S<b>16</b> or steps S<b>17</b> to S<b>20</b> are performed on each of one line of pixels, as is the case with the pixel value X<sub>t=0</sub>. After a series of processing steps is performed on each of one line of pixels, processing returns to step S<b>3</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, and processes of step S<b>3</b> and the subsequent steps are performed.</p><heading id="h-0014" level="1">3. Effect of Recursive 2DNR Process with Fast Convergence Function</heading><p id="p-0101" num="0094">An effect produced by the recursive 2DNR process with the fast convergence function will now be described with reference to <figref idref="DRAWINGS">FIGS. <b>5</b> to <b>10</b></figref>. Here, it is assumed that the recursive 2DNR process is performed on an image structured to have flatness below an edge in a case of being viewed vertically.</p><p id="p-0102" num="0095">The above-mentioned recursive 2DNR process of mixing the pixel value X<sub>t=0 </sub>(the pixel value of pixels in the current line) with the NR pixel value Y<sub>t=&#x2212;2 </sub>(the pixel value of pixels in a previous line) at the mixing ratio &#x3b1; calculated by multiplying the edge determination result of each pixel in the current line with the iir feedback rate set for each pixel in the current line on the basis of the count of each pixel in the second preceding line is called the recursive 2DNR process with the fast convergence function. In the recursive 2DNR process with the fast convergence function, an appropriate iir feedback rate is set for each pixel.</p><p id="p-0103" num="0096">Meanwhile, the recursive 2DNR process of mixing the pixel value X<sub>t=0 </sub>(the pixel value of pixels in the current line) with the NR pixel value Y<sub>t=&#x2212;2 </sub>(the pixel value of pixels in a previous line) in accordance with the iir feedback rate set by using the certainty of the edge determination result is called the recursive 2DNR process without the fast convergence function. In the recursive 2DNR process without the fast convergence function, an appropriate iir feedback rate might not be set for each pixel.</p><p id="p-0104" num="0097">First of all, a case where the recursive 2DNR process without the fast convergence function is performed on a processing target image will be described.</p><p id="p-0105" num="0098">An effect of improving the current line SNR of a processing target that is produced by the recursive 2DNR process without the fast convergence function is expressed, for example, by Equation (4) below.</p><p id="p-0106" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mtext>                </mtext>     <mrow>      <mo>[</mo>      <mrow>       <mi>Math</mi>       <mo>.</mo>       <mtext>   </mtext>       <mn>4</mn>      </mrow>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mi>&#xf3ba;</mi>   </mtd>  </mtr>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>Improvement</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mrow>       <mi>effect</mi>       <mo>&#x2062;</mo>       <mrow>        <mtext>  </mtext>        <mtext> </mtext>       </mrow>       <mo>[</mo>       <mi>dB</mi>       <mo>]</mo>      </mrow>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <mrow>        <mo>-</mo>        <mn>20</mn>       </mrow>       <mo>&#xd7;</mo>       <msub>        <mi>log</mi>        <mn>10</mn>       </msub>       <mo>&#x2062;</mo>       <mtext>  </mtext>       <mrow>        <mo>(</mo>        <mfrac>         <mn>1</mn>         <msub>          <mi>Std</mi>          <mrow>           <mi>c</mi>           <mo>&#x2061;</mo>           <mo>(</mo>           <mrow>            <mi>t</mi>            <mo>=</mo>            <mn>1</mn>           </mrow>           <mo>)</mo>          </mrow>         </msub>        </mfrac>        <mo>)</mo>       </mrow>      </mrow>      <mo>+</mo>      <mrow>       <mn>20</mn>       <mo>&#xd7;</mo>       <msub>        <mi>log</mi>        <mn>10</mn>       </msub>       <mo>&#x2062;</mo>       <mtext>  </mtext>       <mrow>        <mo>(</mo>        <mfrac>         <mn>1</mn>         <msqrt>          <mrow>           <mrow>            <msub>             <msubsup>              <mi>Std</mi>              <mrow>               <mi>c</mi>               <mo>&#x2061;</mo>               <mo>(</mo>               <mrow>                <mi>t</mi>                <mo>=</mo>                <mn>1</mn>               </mrow>               <mo>)</mo>              </mrow>              <mn>2</mn>             </msubsup>             <mtext> </mtext>            </msub>            <mo>&#xd7;</mo>            <msup>             <mrow>              <mo>(</mo>              <mfrac>               <mn>1</mn>               <mn>32</mn>              </mfrac>              <mo>)</mo>             </mrow>             <mn>2</mn>            </msup>           </mrow>           <mo>+</mo>           <mrow>            <msubsup>             <mi>Std</mi>             <mrow>              <mi>p</mi>              <mo>&#x2061;</mo>              <mo>(</mo>              <mrow>               <mi>t</mi>               <mo>=</mo>               <mn>1</mn>              </mrow>              <mo>)</mo>             </mrow>             <mn>2</mn>            </msubsup>            <mo>&#xd7;</mo>            <msup>             <mrow>              <mo>(</mo>              <mfrac>               <mn>31</mn>               <mn>32</mn>              </mfrac>              <mo>)</mo>             </mrow>             <mn>2</mn>            </msup>           </mrow>          </mrow>         </msqrt>        </mfrac>        <mtext> </mtext>        <mo>)</mo>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>4</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0107" num="0099">Std<sub>c </sub>in Equation (4) represents the standard deviation of difference between individual pixels in a processing target current line with noise and individual pixels in an ideal current line without noise. Further, Std<sub>p </sub>in Equation (4) represents the standard deviation of difference between individual pixels in a processed previous line and individual pixels in an ideal previous line without noise.</p><p id="p-0108" num="0100">In a case where the recursive 2DNR process without the fast convergence function is performed, a plurality of pixels included in the current line in a case of t=0 is directly buffered. Therefore, the standard deviation Std<sub>p(t=1) </sub>is equal to Std<sub>c(t=0) </sub>as indicated in Equation (5) below.</p><p id="p-0109" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>[Math. 5]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0110" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Std</i><sub>p(t=1)</sub><i>=Std</i><sub>c(t=0)</sub>&#x2003;&#x2003;(5)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0111" num="0101">Further, the standard deviation Std<sub>p(t=x) </sub>of each pixel in the current line in a case of t=x remains constant. Thus, it can be assumed that Equation (6) below is established.</p><p id="p-0112" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>[Math. 6]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0113" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Std</i><sub>c</sub><i>=Std</i><sub>c(t=0)</sub><i>Std</i><sub>c(t=1)</sub><i>=Std</i><sub>c(t=2)</sub><i>=Std</i><sub>c(t=3)</sub><i>=Std</i><sub>c(t=4) </sub><i>. . . Std</i><sub>c(t=x)</sub>&#x2003;&#x2003;(6)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0114" num="0102">When Equation (4) is transformed by using Equations (5) and (6), Equation (7) below is obtained.</p><p id="p-0115" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mtext>                </mtext>     <mrow>      <mo>[</mo>      <mrow>       <mi>Math</mi>       <mo>.</mo>       <mtext>   </mtext>       <mn>7</mn>      </mrow>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mi>&#xf3ba;</mi>   </mtd>  </mtr>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>Improvement</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mrow>       <mi>effect</mi>       <mo>&#x2062;</mo>       <mrow>        <mtext>  </mtext>        <mtext> </mtext>       </mrow>       <mo>[</mo>       <mi>dB</mi>       <mo>]</mo>      </mrow>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <mrow>        <mrow>         <mo>-</mo>         <mn>20</mn>        </mrow>        <mo>&#xd7;</mo>        <msub>         <mi>log</mi>         <mn>10</mn>        </msub>        <mo>&#x2062;</mo>        <mtext>  </mtext>        <mrow>         <mo>(</mo>         <mfrac>          <mn>1</mn>          <msub>           <mi>Std</mi>           <mi>c</mi>          </msub>         </mfrac>         <mo>)</mo>        </mrow>       </mrow>       <mo>+</mo>       <mrow>        <mn>20</mn>        <mo>&#xd7;</mo>        <msub>         <mi>log</mi>         <mn>10</mn>        </msub>        <mo>&#x2062;</mo>        <mtext>  </mtext>        <mrow>         <mo>(</mo>         <mfrac>          <mn>1</mn>          <msqrt>           <mrow>            <mrow>             <msub>              <msubsup>               <mi>Std</mi>               <mi>c</mi>               <mn>2</mn>              </msubsup>              <mtext> </mtext>             </msub>             <mo>&#xd7;</mo>             <msup>              <mrow>               <mo>(</mo>               <mfrac>                <mn>1</mn>                <mn>32</mn>               </mfrac>               <mo>)</mo>              </mrow>              <mn>2</mn>             </msup>            </mrow>            <mo>+</mo>            <mrow>             <msubsup>              <mi>Std</mi>              <mi>c</mi>              <mn>2</mn>             </msubsup>             <mo>&#xd7;</mo>             <msup>              <mrow>               <mo>(</mo>               <mfrac>                <mn>31</mn>                <mn>32</mn>               </mfrac>               <mo>)</mo>              </mrow>              <mn>2</mn>             </msup>            </mrow>           </mrow>          </msqrt>         </mfrac>         <mtext> </mtext>         <mo>)</mo>        </mrow>       </mrow>      </mrow>      <mo>&#x2248;</mo>      <mrow>       <mn>0.27</mn>       <mo>[</mo>       <mi>dB</mi>       <mo>]</mo>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>7</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0116" num="0103">As indicated in Equation (7), in a case of t=1, an expected value of an SNR improvement effect produced by the recursive 2DNR process without the fast convergence function is approximately 0.27 [dB].</p><p id="p-0117" num="0104">Meanwhile, the SNR improvement effect produced by the recursive 2DNR process with the fast convergence function is expressed by Equation (8) below.</p><p id="p-0118" num="0000"><maths id="MATH-US-00003" num="00003"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mtext>                </mtext>     <mrow>      <mo>[</mo>      <mrow>       <mi>Math</mi>       <mo>.</mo>       <mtext>   </mtext>       <mn>8</mn>      </mrow>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>8</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr>  <mtr>   <mtd>    <mrow>     <mrow>      <mrow>       <mi>I</mi>       <mo>&#x2062;</mo>       <mi>mprovement</mi>      </mrow>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mrow>       <mi>effect</mi>       <mo>&#x2062;</mo>       <mrow>        <mtext>  </mtext>        <mtext> </mtext>       </mrow>       <mo>[</mo>       <mi>dB</mi>       <mo>]</mo>      </mrow>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <mrow>        <mrow>         <mo>-</mo>         <mn>20</mn>        </mrow>        <mo>&#xd7;</mo>        <msub>         <mi>log</mi>         <mn>10</mn>        </msub>        <mo>&#x2062;</mo>        <mtext>  </mtext>        <mrow>         <mo>(</mo>         <mfrac>          <mn>1</mn>          <msub>           <mi>Std</mi>           <mi>c</mi>          </msub>         </mfrac>         <mo>)</mo>        </mrow>       </mrow>       <mo>+</mo>       <mrow>        <mn>20</mn>        <mo>&#xd7;</mo>        <msub>         <mi>log</mi>         <mn>10</mn>        </msub>        <mo>&#x2062;</mo>        <mtext>  </mtext>        <mrow>         <mo>(</mo>         <mfrac>          <mn>1</mn>          <msqrt>           <mrow>            <mrow>             <msub>              <msubsup>               <mi>Std</mi>               <mi>c</mi>               <mn>2</mn>              </msubsup>              <mtext> </mtext>             </msub>             <mo>&#xd7;</mo>             <msup>              <mrow>               <mo>(</mo>               <mfrac>                <mn>1</mn>                <mn>2</mn>               </mfrac>               <mo>)</mo>              </mrow>              <mn>2</mn>             </msup>            </mrow>            <mo>+</mo>            <mrow>             <msubsup>              <mi>Std</mi>              <mi>c</mi>              <mn>2</mn>             </msubsup>             <mo>&#xd7;</mo>             <msup>              <mrow>               <mo>(</mo>               <mfrac>                <mn>1</mn>                <mn>2</mn>               </mfrac>               <mo>)</mo>              </mrow>              <mn>2</mn>             </msup>            </mrow>           </mrow>          </msqrt>         </mfrac>         <mtext> </mtext>         <mo>)</mo>        </mrow>       </mrow>      </mrow>      <mo>&#x2248;</mo>      <mrow>       <mn>3.01</mn>       <mtext>  </mtext>       <mo>[</mo>       <mi>dB</mi>       <mo>]</mo>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mtext> </mtext>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0119" num="0105">As indicated in Equation (8), in a case of t=1, the SNR improvement effect produced by the recursive 2DNR process with the fast convergence function is approximately 3.01 [dB]. That is, in a case of t=1, the recursive 2DNR process with the fast convergence function produces an improvement effect of approximately 2.74 [dB] as compared with the recursive 2DNR process without the fast convergence function.</p><p id="p-0120" num="0106">The improvement effect of t=2 or later will now be described. In recursive 2DNR, a line sent to a line below after being subjected to 2DNR processing is the same as a line that is used in the next line as a previous line. Therefore, the standard deviation Std<sub>p(t=x+1) </sub>of each pixel in a previous line in the recursive 2DNR process without the fast convergence function in a case of t=x+1 is expressed by Equation (9) below.</p><p id="p-0121" num="0000"><maths id="MATH-US-00004" num="00004"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mo>[</mo>     <mrow>      <mi>Math</mi>      <mo>.</mo>      <mtext>   </mtext>      <mn>9</mn>     </mrow>     <mo>]</mo>    </mrow>   </mtd>   <mtd>    <mi>&#xf3ba;</mi>   </mtd>  </mtr>  <mtr>   <mtd>    <mrow>     <msub>      <mi>Std</mi>      <mrow>       <mi>p</mi>       <mo>&#x2061;</mo>       <mo>(</mo>       <mrow>        <mi>t</mi>        <mo>=</mo>        <mrow>         <mi>x</mi>         <mo>+</mo>         <mn>1</mn>        </mrow>       </mrow>       <mo>)</mo>      </mrow>     </msub>     <mo>=</mo>     <msqrt>      <mrow>       <mrow>        <msubsup>         <mi>Std</mi>         <mrow>          <mi>c</mi>          <mo>&#x2061;</mo>          <mo>(</mo>          <mrow>           <mi>t</mi>           <mo>=</mo>           <mi>x</mi>          </mrow>          <mo>)</mo>         </mrow>         <mn>2</mn>        </msubsup>        <mo>&#xd7;</mo>        <msup>         <mrow>          <mo>(</mo>          <mfrac>           <mn>1</mn>           <mn>32</mn>          </mfrac>          <mo>)</mo>         </mrow>         <mn>2</mn>        </msup>       </mrow>       <mo>+</mo>       <mrow>        <msubsup>         <mi>Std</mi>         <mrow>          <mi>p</mi>          <mo>&#x2061;</mo>          <mo>(</mo>          <mrow>           <mi>t</mi>           <mo>=</mo>           <mi>x</mi>          </mrow>          <mo>)</mo>         </mrow>         <mn>2</mn>        </msubsup>        <mo>&#xd7;</mo>        <msup>         <mrow>          <mo>(</mo>          <mfrac>           <mn>31</mn>           <mn>32</mn>          </mfrac>          <mo>)</mo>         </mrow>         <mn>2</mn>        </msup>       </mrow>      </mrow>     </msqrt>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>9</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0122" num="0107">The NR pixel value of each pixel in the current line that is stored in a line buffer in a case of t=2 is read as the NR pixel value of each pixel in a previous line in a case of t=3. Therefore, the standard deviation of the NR pixel value in a case of t=2 is equal to Std<sub>p(t=3)</sub>. Consequently, the standard deviation Std<sub>p(t=3) </sub>of each pixel in a previous line in a case of t=3 is expressed by Equation (10) below by using Equation (9).</p><p id="p-0123" num="0000"><maths id="MATH-US-00005" num="00005"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mtext>                </mtext>     <mrow>      <mo>[</mo>      <mrow>       <mi>Math</mi>       <mo>.</mo>       <mtext>   </mtext>       <mn>10</mn>      </mrow>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mi>&#xf3ba;</mi>   </mtd>  </mtr>  <mtr>   <mtd>    <mtable>     <mtr>      <mtd>       <mrow>        <msub>         <mi>Std</mi>         <mrow>          <mi>p</mi>          <mo>&#x2061;</mo>          <mo>(</mo>          <mrow>           <mi>t</mi>           <mo>=</mo>           <mn>3</mn>          </mrow>          <mo>)</mo>         </mrow>        </msub>        <mo>=</mo>        <malignmark/>        <msqrt>         <mrow>          <mrow>           <msubsup>            <mi>Std</mi>            <mrow>             <mi>c</mi>             <mo>&#x2061;</mo>             <mo>(</mo>             <mrow>              <mi>t</mi>              <mo>=</mo>              <mn>2</mn>             </mrow>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msubsup>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>1</mn>              <mn>32</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>          <mo>+</mo>          <mrow>           <msubsup>            <mi>Std</mi>            <mrow>             <mi>p</mi>             <mo>&#x2061;</mo>             <mo>(</mo>             <mrow>              <mi>t</mi>              <mo>=</mo>              <mn>2</mn>             </mrow>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msubsup>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>31</mn>              <mn>32</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>         </mrow>        </msqrt>       </mrow>      </mtd>     </mtr>     <mtr>      <mtd>       <mrow>        <mo>=</mo>        <malignmark/>        <msqrt>         <mrow>          <mrow>           <msubsup>            <mi>Std</mi>            <mrow>             <mi>c</mi>             <mo>&#x2061;</mo>             <mo>(</mo>             <mrow>              <mi>t</mi>              <mo>=</mo>              <mn>2</mn>             </mrow>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msubsup>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>1</mn>              <mn>32</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>          <mo>+</mo>          <mrow>           <mrow>            <mo>(</mo>            <mrow>             <mrow>              <msubsup>               <mi>Std</mi>               <mrow>                <mi>c</mi>                <mo>&#x2061;</mo>                <mo>(</mo>                <mrow>                 <mi>t</mi>                 <mo>=</mo>                 <mn>1</mn>                </mrow>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msubsup>              <mo>&#xd7;</mo>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>1</mn>                 <mn>32</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>             </mrow>             <mo>+</mo>             <mrow>              <msubsup>               <mi>Std</mi>               <mrow>                <mi>p</mi>                <mo>&#x2061;</mo>                <mo>(</mo>                <mrow>                 <mi>t</mi>                 <mo>=</mo>                 <mn>1</mn>                </mrow>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msubsup>              <mo>&#xd7;</mo>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>31</mn>                 <mn>32</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>             </mrow>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>31</mn>              <mn>32</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>         </mrow>        </msqrt>       </mrow>      </mtd>     </mtr>     <mtr>      <mtd>       <mrow>        <mo>=</mo>        <malignmark/>        <msqrt>         <mrow>          <mrow>           <msubsup>            <mi>Std</mi>            <mi>c</mi>            <mn>2</mn>           </msubsup>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>1</mn>              <mn>32</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>          <mo>+</mo>          <mrow>           <mrow>            <mo>(</mo>            <mrow>             <mrow>              <msubsup>               <mi>Std</mi>               <mi>c</mi>               <mn>2</mn>              </msubsup>              <mo>&#xd7;</mo>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>1</mn>                 <mn>32</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>             </mrow>             <mo>+</mo>             <mrow>              <msubsup>               <mi>Std</mi>               <mi>c</mi>               <mn>2</mn>              </msubsup>              <mo>&#xd7;</mo>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>31</mn>                 <mn>32</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>             </mrow>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>31</mn>              <mn>32</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>         </mrow>        </msqrt>       </mrow>      </mtd>     </mtr>     <mtr>      <mtd>       <mrow>        <mo>=</mo>        <malignmark/>        <msqrt>         <mrow>          <msup>           <mrow>            <mo>(</mo>            <mfrac>             <mn>1</mn>             <mn>32</mn>            </mfrac>            <mo>)</mo>           </mrow>           <mn>2</mn>          </msup>          <mo>+</mo>          <mrow>           <mrow>            <mo>(</mo>            <mrow>             <msup>              <mrow>               <mo>(</mo>               <mfrac>                <mn>1</mn>                <mn>32</mn>               </mfrac>               <mo>)</mo>              </mrow>              <mn>2</mn>             </msup>             <mo>+</mo>             <msup>              <mrow>               <mo>(</mo>               <mfrac>                <mn>31</mn>                <mn>32</mn>               </mfrac>               <mo>)</mo>              </mrow>              <mn>2</mn>             </msup>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>31</mn>              <mn>32</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>          <mo>+</mo>          <msub>           <mi>Std</mi>           <mi>c</mi>          </msub>         </mrow>        </msqrt>       </mrow>      </mtd>     </mtr>    </mtable>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>10</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0124" num="0108">In a case of t=2, the SNR improvement effect produced by the recursive 2DNR process without the fast convergence function is expressed by Equation (11) below by using Equation (10).</p><p id="p-0125" num="0000"><maths id="MATH-US-00006" num="00006"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mtext>                </mtext>     <mrow>      <mo>[</mo>      <mrow>       <mi>Math</mi>       <mo>.</mo>       <mtext>   </mtext>       <mn>11</mn>      </mrow>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mi>&#xf3ba;</mi>   </mtd>  </mtr>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>Improvement</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mrow>       <mi>effect</mi>       <mo>&#x2062;</mo>       <mrow>        <mtext>  </mtext>        <mtext> </mtext>       </mrow>       <mo>[</mo>       <mi>dB</mi>       <mo>]</mo>      </mrow>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <mn>20</mn>       <mo>&#xd7;</mo>       <msub>        <mi>log</mi>        <mn>10</mn>       </msub>       <mo>&#x2062;</mo>       <mtext>  </mtext>       <mrow>        <mo>(</mo>        <mfrac>         <mn>1</mn>         <msqrt>          <mrow>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>1</mn>              <mn>32</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>           <mo>+</mo>           <mrow>            <mrow>             <mo>(</mo>             <mrow>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>1</mn>                 <mn>32</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>              <mo>+</mo>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>31</mn>                 <mn>32</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>             </mrow>             <mo>)</mo>            </mrow>            <mo>&#xd7;</mo>            <msup>             <mrow>              <mo>(</mo>              <mfrac>               <mn>31</mn>               <mn>32</mn>              </mfrac>              <mo>)</mo>             </mrow>             <mn>2</mn>            </msup>           </mrow>          </mrow>         </msqrt>        </mfrac>        <mo>)</mo>       </mrow>      </mrow>      <mo>&#x2248;</mo>      <mrow>       <mn>0.54</mn>       <mo>[</mo>       <mi>dB</mi>       <mo>]</mo>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mpadded width="0em" lspace="0em" depth="2.1ex" height="-2.1ex">     <mrow>      <mo>(</mo>      <mn>11</mn>      <mo>)</mo>     </mrow>    </mpadded>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0126" num="0109">Similarly, in a case of t=3, the SNR improvement effect produced by the recursive 2DNR process without the fast convergence function is expressed by Equation (12) below.</p><p id="p-0127" num="0000"><maths id="MATH-US-00007" num="00007"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mtext>                </mtext>     <mrow>      <mo>[</mo>      <mrow>       <mi>Math</mi>       <mo>.</mo>       <mtext>   </mtext>       <mn>12</mn>      </mrow>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mi>&#xf3ba;</mi>   </mtd>  </mtr>  <mtr>   <mtd>    <mrow>     <mrow>      <mrow>       <mi>Improvement</mi>       <mo>&#x2062;</mo>       <mtext>   </mtext>       <mrow>        <mi>effect</mi>        <mo>&#x2062;</mo>        <mrow>         <mtext>  </mtext>         <mtext> </mtext>        </mrow>        <mo>[</mo>        <mi>dB</mi>        <mo>]</mo>       </mrow>      </mrow>      <mo>=</mo>      <mrow>       <mn>20</mn>       <mo>&#xd7;</mo>       <msub>        <mi>log</mi>        <mn>10</mn>       </msub>      </mrow>     </mrow>     <mo>&#x2062;</mo>     <mtext></mtext>     <mrow>      <mrow>       <mo>(</mo>       <mfrac>        <mn>1</mn>        <msqrt>         <mrow>          <msup>           <mrow>            <mo>(</mo>            <mfrac>             <mn>1</mn>             <mn>32</mn>            </mfrac>            <mo>)</mo>           </mrow>           <mn>2</mn>          </msup>          <mo>+</mo>          <mrow>           <mrow>            <mo>(</mo>            <mrow>             <msup>              <mrow>               <mo>(</mo>               <mfrac>                <mn>1</mn>                <mn>32</mn>               </mfrac>               <mo>)</mo>              </mrow>              <mn>2</mn>             </msup>             <mo>+</mo>             <mrow>              <mrow>               <mo>(</mo>               <mrow>                <msup>                 <mrow>                  <mo>(</mo>                  <mfrac>                   <mn>1</mn>                   <mn>32</mn>                  </mfrac>                  <mo>)</mo>                 </mrow>                 <mn>2</mn>                </msup>                <mo>+</mo>                <msup>                 <mrow>                  <mo>(</mo>                  <mfrac>                   <mn>31</mn>                   <mn>32</mn>                  </mfrac>                  <mo>)</mo>                 </mrow>                 <mn>2</mn>                </msup>               </mrow>               <mo>)</mo>              </mrow>              <mo>&#xd7;</mo>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>31</mn>                 <mn>32</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>             </mrow>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>31</mn>              <mn>32</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>         </mrow>        </msqrt>       </mfrac>       <mo>)</mo>      </mrow>      <mo>&#x2248;</mo>      <mrow>       <mn>0.81</mn>       <mo>[</mo>       <mi>dB</mi>       <mo>]</mo>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mpadded width="0em" lspace="0em" depth="2.2ex" height="-2.2ex">     <mrow>      <mo>(</mo>      <mn>12</mn>      <mo>)</mo>     </mrow>    </mpadded>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0128" num="0110">Accordingly, in a case of t=0 to 31, the SNR improvement effect produced by the recursive 2DNR process without the fast convergence function is determined as depicted in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. In <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the horizontal axis represents t, and the vertical axis represents the SNR improvement effect. The similar representation applies also to <figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b></figref>, which will be referenced later.</p><p id="p-0129" num="0111">Meanwhile, the standard deviation Std<sub>p(t=x+1) </sub>of each pixel in a previous line in the recursive 2DNR process with the fast convergence function in a case of t=x+1 is expressed by Equation (13) below.</p><p id="p-0130" num="0000"><maths id="MATH-US-00008" num="00008"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mtext>                </mtext>     <mrow>      <mo>[</mo>      <mrow>       <mi>Math</mi>       <mo>.</mo>       <mtext>   </mtext>       <mn>13</mn>      </mrow>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mi>&#xf3ba;</mi>   </mtd>  </mtr>  <mtr>   <mtd>    <mrow>     <msub>      <mi>Std</mi>      <mrow>       <mi>p</mi>       <mo>&#x2061;</mo>       <mo>(</mo>       <mrow>        <mi>t</mi>        <mo>=</mo>        <mrow>         <mi>x</mi>         <mo>+</mo>         <mn>1</mn>        </mrow>       </mrow>       <mo>)</mo>      </mrow>     </msub>     <mo>=</mo>     <msqrt>      <mrow>       <mrow>        <msubsup>         <mi>Std</mi>         <mrow>          <mi>c</mi>          <mo>&#x2061;</mo>          <mo>(</mo>          <mrow>           <mi>t</mi>           <mo>=</mo>           <mi>x</mi>          </mrow>          <mo>)</mo>         </mrow>         <mn>2</mn>        </msubsup>        <mo>&#xd7;</mo>        <msup>         <mrow>          <mo>(</mo>          <mfrac>           <mn>1</mn>           <mrow>            <mi>x</mi>            <mo>+</mo>            <mn>1</mn>            <mtext> </mtext>           </mrow>          </mfrac>          <mo>)</mo>         </mrow>         <mn>2</mn>        </msup>       </mrow>       <mo>+</mo>       <mrow>        <msubsup>         <mi>Std</mi>         <mrow>          <mi>p</mi>          <mo>&#x2061;</mo>          <mo>(</mo>          <mrow>           <mi>t</mi>           <mo>=</mo>           <mi>x</mi>          </mrow>          <mo>)</mo>         </mrow>         <mn>2</mn>        </msubsup>        <mo>&#xd7;</mo>        <msup>         <mrow>          <mo>(</mo>          <mfrac>           <mi>x</mi>           <mrow>            <mi>x</mi>            <mo>+</mo>            <mn>1</mn>           </mrow>          </mfrac>          <mo>)</mo>         </mrow>         <mn>2</mn>        </msup>       </mrow>      </mrow>     </msqrt>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>13</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0131" num="0112">The standard deviation Std<sub>p(t=3) </sub>of each pixel in a previous line in a case of t=3, which is equal to the standard deviation of the NR pixel value in a case of t=2, is expressed by Equation (14) below by using Equation (13).</p><p id="p-0132" num="0000"><maths id="MATH-US-00009" num="00009"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mtext>                </mtext>     <mrow>      <mo>[</mo>      <mrow>       <mi>Math</mi>       <mo>.</mo>       <mtext>   </mtext>       <mn>14</mn>      </mrow>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mi>&#xf3ba;</mi>   </mtd>  </mtr>  <mtr>   <mtd>    <mtable>     <mtr>      <mtd>       <mrow>        <msub>         <mi>Std</mi>         <mrow>          <mi>p</mi>          <mo>&#x2061;</mo>          <mo>(</mo>          <mrow>           <mi>t</mi>           <mo>=</mo>           <mn>3</mn>          </mrow>          <mo>)</mo>         </mrow>        </msub>        <mo>=</mo>        <malignmark/>        <msqrt>         <mrow>          <mrow>           <msubsup>            <mi>Std</mi>            <mrow>             <mi>c</mi>             <mo>&#x2061;</mo>             <mo>(</mo>             <mrow>              <mi>t</mi>              <mo>=</mo>              <mn>2</mn>             </mrow>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msubsup>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>1</mn>              <mn>3</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>          <mo>+</mo>          <mrow>           <msubsup>            <mi>Std</mi>            <mrow>             <mi>p</mi>             <mo>&#x2061;</mo>             <mo>(</mo>             <mrow>              <mi>t</mi>              <mo>=</mo>              <mn>2</mn>             </mrow>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msubsup>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>2</mn>              <mn>3</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>         </mrow>        </msqrt>       </mrow>      </mtd>     </mtr>     <mtr>      <mtd>       <mrow>        <mo>=</mo>        <malignmark/>        <msqrt>         <mrow>          <mrow>           <msubsup>            <mi>Std</mi>            <mrow>             <mi>c</mi>             <mo>&#x2061;</mo>             <mo>(</mo>             <mrow>              <mi>t</mi>              <mo>=</mo>              <mn>2</mn>             </mrow>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msubsup>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>1</mn>              <mn>3</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>          <mo>+</mo>          <mrow>           <mrow>            <mo>(</mo>            <mrow>             <mrow>              <msubsup>               <mi>Std</mi>               <mrow>                <mi>c</mi>                <mo>&#x2061;</mo>                <mo>(</mo>                <mrow>                 <mi>t</mi>                 <mo>=</mo>                 <mn>1</mn>                </mrow>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msubsup>              <mo>&#xd7;</mo>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>1</mn>                 <mn>2</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>             </mrow>             <mo>+</mo>             <mrow>              <msubsup>               <mi>Std</mi>               <mrow>                <mi>p</mi>                <mo>&#x2061;</mo>                <mo>(</mo>                <mrow>                 <mi>t</mi>                 <mo>=</mo>                 <mn>1</mn>                </mrow>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msubsup>              <mo>&#xd7;</mo>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>1</mn>                 <mn>2</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>             </mrow>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>2</mn>              <mn>3</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>         </mrow>        </msqrt>       </mrow>      </mtd>     </mtr>     <mtr>      <mtd>       <mrow>        <mo>=</mo>        <malignmark/>        <msqrt>         <mrow>          <mrow>           <msubsup>            <mi>Std</mi>            <mi>c</mi>            <mn>2</mn>           </msubsup>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>1</mn>              <mn>3</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>          <mo>+</mo>          <mrow>           <mrow>            <mo>(</mo>            <mrow>             <mrow>              <msubsup>               <mi>Std</mi>               <mi>c</mi>               <mn>2</mn>              </msubsup>              <mo>&#xd7;</mo>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>1</mn>                 <mn>2</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>             </mrow>             <mo>+</mo>             <mrow>              <msubsup>               <mi>Std</mi>               <mi>c</mi>               <mn>2</mn>              </msubsup>              <mo>&#xd7;</mo>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>1</mn>                 <mn>2</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>             </mrow>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>2</mn>              <mn>3</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>         </mrow>        </msqrt>       </mrow>      </mtd>     </mtr>     <mtr>      <mtd>       <mrow>        <mo>=</mo>        <malignmark/>        <msqrt>         <mrow>          <msup>           <mrow>            <mo>(</mo>            <mfrac>             <mn>1</mn>             <mn>3</mn>            </mfrac>            <mo>)</mo>           </mrow>           <mn>2</mn>          </msup>          <mo>+</mo>          <mrow>           <mrow>            <mo>(</mo>            <mrow>             <msup>              <mrow>               <mo>(</mo>               <mfrac>                <mn>1</mn>                <mn>2</mn>               </mfrac>               <mo>)</mo>              </mrow>              <mn>2</mn>             </msup>             <mo>+</mo>             <msup>              <mrow>               <mo>(</mo>               <mfrac>                <mn>1</mn>                <mn>2</mn>               </mfrac>               <mo>)</mo>              </mrow>              <mn>2</mn>             </msup>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#xd7;</mo>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>2</mn>              <mn>3</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>          </mrow>          <mo>+</mo>          <msub>           <mi>Std</mi>           <mi>c</mi>          </msub>         </mrow>        </msqrt>       </mrow>      </mtd>     </mtr>    </mtable>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>14</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0133" num="0113">In a case of t=2, the SNR improvement effect produced by the recursive 2DNR process with the fast convergence function is expressed by Equation (15) below by using Equation (14).</p><p id="p-0134" num="0000"><maths id="MATH-US-00010" num="00010"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mtext>                </mtext>     <mrow>      <mo>[</mo>      <mrow>       <mi>Math</mi>       <mo>.</mo>       <mtext>   </mtext>       <mn>15</mn>      </mrow>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mi>&#xf3ba;</mi>   </mtd>  </mtr>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>Improvement</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mrow>       <mi>effect</mi>       <mo>&#x2062;</mo>       <mrow>        <mtext>  </mtext>        <mtext> </mtext>       </mrow>       <mo>[</mo>       <mi>dB</mi>       <mo>]</mo>      </mrow>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <mn>20</mn>       <mo>&#xd7;</mo>       <msub>        <mi>log</mi>        <mn>10</mn>       </msub>       <mo>&#x2062;</mo>       <mtext>  </mtext>       <mrow>        <mo>(</mo>        <mfrac>         <mn>1</mn>         <msqrt>          <mrow>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>1</mn>              <mn>3</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>           <mo>+</mo>           <mrow>            <mrow>             <mo>(</mo>             <mrow>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>1</mn>                 <mn>2</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>              <mo>+</mo>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>1</mn>                 <mn>2</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>             </mrow>             <mo>)</mo>            </mrow>            <mo>&#xd7;</mo>            <msup>             <mrow>              <mo>(</mo>              <mfrac>               <mn>2</mn>               <mn>3</mn>              </mfrac>              <mo>)</mo>             </mrow>             <mn>2</mn>            </msup>           </mrow>          </mrow>         </msqrt>        </mfrac>        <mo>)</mo>       </mrow>      </mrow>      <mo>&#x2248;</mo>      <mrow>       <mn>4.77</mn>       <mo>[</mo>       <mi>dB</mi>       <mo>]</mo>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mpadded width="0em" lspace="0em" depth="1.9ex" height="-1.9ex">     <mrow>      <mo>(</mo>      <mn>15</mn>      <mo>)</mo>     </mrow>    </mpadded>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0135" num="0114">Similarly, in a case of t=3, the SNR improvement effect produced by the recursive 2DNR process with the fast convergence function is expressed by Equation (16) below.</p><p id="p-0136" num="0000"><maths id="MATH-US-00011" num="00011"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mtext>                </mtext>     <mrow>      <mo>[</mo>      <mrow>       <mi>Math</mi>       <mo>.</mo>       <mtext>   </mtext>       <mn>16</mn>      </mrow>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mi>&#xf3ba;</mi>   </mtd>  </mtr>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>Improvement</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mrow>       <mi>effect</mi>       <mo>&#x2062;</mo>       <mrow>        <mtext>  </mtext>        <mtext> </mtext>       </mrow>       <mo>[</mo>       <mi>dB</mi>       <mo>]</mo>      </mrow>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <mn>20</mn>       <mo>&#xd7;</mo>       <msub>        <mi>log</mi>        <mn>10</mn>       </msub>       <mo>&#x2062;</mo>       <mtext>  </mtext>       <mrow>        <mo>(</mo>        <mfrac>         <mn>1</mn>         <msqrt>          <mrow>           <msup>            <mrow>             <mo>(</mo>             <mfrac>              <mn>1</mn>              <mn>4</mn>             </mfrac>             <mo>)</mo>            </mrow>            <mn>2</mn>           </msup>           <mo>+</mo>           <mrow>            <mrow>             <mo>(</mo>             <mrow>              <msup>               <mrow>                <mo>(</mo>                <mfrac>                 <mn>1</mn>                 <mn>3</mn>                </mfrac>                <mo>)</mo>               </mrow>               <mn>2</mn>              </msup>              <mo>+</mo>              <mrow>               <mrow>                <mo>(</mo>                <mrow>                 <msup>                  <mrow>                   <mo>(</mo>                   <mfrac>                    <mn>1</mn>                    <mn>2</mn>                   </mfrac>                   <mo>)</mo>                  </mrow>                  <mn>2</mn>                 </msup>                 <mo>+</mo>                 <msup>                  <mrow>                   <mo>(</mo>                   <mfrac>                    <mn>1</mn>                    <mn>2</mn>                   </mfrac>                   <mo>)</mo>                  </mrow>                  <mn>2</mn>                 </msup>                </mrow>                <mo>)</mo>               </mrow>               <mo>&#xd7;</mo>               <msup>                <mrow>                 <mo>(</mo>                 <mfrac>                  <mn>2</mn>                  <mn>3</mn>                 </mfrac>                 <mo>)</mo>                </mrow>                <mn>2</mn>               </msup>              </mrow>             </mrow>             <mo>)</mo>            </mrow>            <mo>&#xd7;</mo>            <msup>             <mrow>              <mo>(</mo>              <mfrac>               <mn>3</mn>               <mn>4</mn>              </mfrac>              <mo>)</mo>             </mrow>             <mn>2</mn>            </msup>           </mrow>          </mrow>         </msqrt>        </mfrac>        <mo>)</mo>       </mrow>      </mrow>      <mo>&#x2248;</mo>      <mrow>       <mn>6.02</mn>       <mo>[</mo>       <mi>dB</mi>       <mo>]</mo>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mpadded width="0em" lspace="0em" depth="2ex" height="-2ex">     <mrow>      <mo>(</mo>      <mn>16</mn>      <mo>)</mo>     </mrow>    </mpadded>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0137" num="0115">Accordingly, in a case of t=0 to 31, the SNR improvement effect produced by the recursive 2DNR process with the fast convergence function is determined as depicted in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0138" num="0116"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating an SNR improvement effect comparison between the recursive 2DNR process with the fast convergence function and the recursive 2DNR process without the fast convergence function.</p><p id="p-0139" num="0117">The maximum SNR improvement effect produced in a pseudo manner by the recursive 2DNR process capable of combining up 32 lines is theoretically approximately 15.05 [dB]. As depicted in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, in the recursive 2DNR process with the fast convergence function, the SNR improvement effect converges at t=31. Meanwhile, in the recursive 2DNR process without the fast convergence function, the SNR improvement effect does not converge.</p><p id="p-0140" num="0118"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating an example of the SNR improvement effect that is produced by the recursive 2DNR process with the fast convergence function as compared with the recursive 2DNR process without the fast convergence function.</p><p id="p-0141" num="0119">In <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the horizontal axis represents t, and the vertical axis represents the SNR improvement effect.</p><p id="p-0142" num="0120">As depicted in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, in a case of t=15, the maximum SNR improvement effect produced by the fast convergence function is approximately 18 [dB]. Further, in a case of t=1, the SNR improvement effect produced by the fast convergence function is approximately 2.74 [dB]. Furthermore, in a case of t=4 or later, the SNR improvement effect produced steadily by the fast convergence function is 6 [dB] or more.</p><p id="p-0143" num="0121">As described above, the recursive 2DNR process with the fast convergence function is able to produce a greater SNR improvement effect than the recursive 2DNR process without the fast convergence function.</p><p id="p-0144" num="0122">Response characteristics of the recursive 2DNR process without the fast convergence function and recursive 2DNR process with the fast convergence function will now be described with reference to <figref idref="DRAWINGS">FIGS. <b>9</b> and <b>10</b></figref>. In <figref idref="DRAWINGS">FIGS. <b>9</b> and <b>10</b></figref>, the horizontal axis represents t, and the vertical axis represents the pixel value.</p><p id="p-0145" num="0123"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating the response characteristics in a situation where the strength of NR processing is low.</p><p id="p-0146" num="0124">A of <figref idref="DRAWINGS">FIG. <b>9</b></figref> indicates an input value representing the pixel value of an input image. The input image is an image that contains a vertically oriented edge near line <b>65</b>.</p><p id="p-0147" num="0125">B of <figref idref="DRAWINGS">FIG. <b>9</b></figref> indicates the response characteristics of the recursive 2DNR process without the fast convergence function. As pointed out by a white arrow in B of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, in the recursive 2DNR process without the fast convergence function, a trailing phenomenon occurs so as to drag upper line pixels.</p><p id="p-0148" num="0126">C of <figref idref="DRAWINGS">FIG. <b>9</b></figref> indicates the response characteristics of the recursive 2DNR process with the fast convergence function according to the present technology. As indicated by C of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, in the recursive 2DNR process with the fast convergence function, the trailing phenomenon hardly occurs as compared with the recursive 2DNR process without the fast convergence function (B of <figref idref="DRAWINGS">FIG. <b>9</b></figref>).</p><p id="p-0149" num="0127"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating the response characteristics in a situation where the strength of NR processing is high.</p><p id="p-0150" num="0128">A of <figref idref="DRAWINGS">FIG. <b>10</b></figref> indicates an input value representing the pixel value of an input image. The input image is an image that contains a vertically oriented edge near line <b>65</b>.</p><p id="p-0151" num="0129">B of <figref idref="DRAWINGS">FIG. <b>10</b></figref> indicates the response characteristics of the recursive 2DNR process without the fast convergence function. In the recursive 2DNR process without the fast convergence function, the trailing phenomenon becomes more intense with an increase in NR strength as pointed out by a white arrow in B of <figref idref="DRAWINGS">FIG. <b>10</b></figref>.</p><p id="p-0152" num="0130">C of <figref idref="DRAWINGS">FIG. <b>10</b></figref> indicates the response characteristics of the recursive 2DNR process with the fast convergence function according to the present technology. As indicated by C of FIG. <b>10</b>, in the recursive 2DNR process with the fast convergence function, the trailing phenomenon hardly occurs as compared with the recursive 2DNR process without the fast convergence function (B of <figref idref="DRAWINGS">FIG. <b>10</b></figref>) even in a case where NR strength is high.</p><p id="p-0153" num="0131">As described above, when compared with the recursive 2DNR process without the fast convergence function, the recursive 2DNR process with the fast convergence function is able to reduce the number of lines exhibiting a processing result representative of transient characteristics prevailing before the influence of SNR reaches a steady state no matter whether NR strength is low or high.</p><p id="p-0154" num="0132">More specifically, in a case where the recursive 2DNR process without the fast convergence function is performed on an image depicting a building, the image outputted as the noise reduction result may look as if a building window is on the point of disappearing (an edge of the window is stretched downward) due to the trailing phenomenon. Meanwhile, in a case where the recursive 2DNR process with the fast convergence function is performed on an image depicting a building, the image outputted as the noise reduction result indicates that the trailing phenomenon is suppressed (an edge of the window remains intact).</p><p id="p-0155" num="0133">Further, in a case where, for example, the recursive 2DNR process without the fast convergence function is performed on an image depicting an object in front of a sky, the image outputted as the noise reduction result may look as if the sky is overhanging the object (an edge of the object is stretched downward) due to the trailing phenomenon. Meanwhile, in a case where the recursive 2DNR process with the fast convergence function is performed on an image depicting an object in front of a sky, the image outputted as the noise reduction result indicates that the trailing phenomenon is suppressed (an edge of the object remains intact).</p><p id="p-0156" num="0134">As described above, by performing the recursive 2DNR process with the fast convergence function, the in-vehicle camera system <b>1</b> is able to successively suppress a vertical trailing phenomenon in an image obtained as the noise reduction result while keeping the noise reduction effect produced by NR processing.</p><p id="p-0157" num="0135">Accordingly, the in-vehicle camera system <b>1</b> is able to effectively reduce noise. Particularly, the in-vehicle camera system <b>1</b> is able to reduce white noise at an optimal SNR.</p><p id="p-0158" num="0136">By using limited hardware resources, the in-vehicle camera system <b>1</b> is able to achieve SNR improvement performance comparable to a case where 2DNR processing is performed by using a large-capacity line buffer. Therefore, the in-vehicle camera system <b>1</b> is able to capture a high-quality video image.</p><p id="p-0159" num="0137">Further, by using limited hardware resources, the in-vehicle camera system <b>1</b> is able to achieve SNR improvement performance comparable to a case where 3DNR processing is performed by using a large-capacity frame buffer. Therefore, the in-vehicle camera system <b>1</b> is able to capture a high-quality video image.</p><p id="p-0160" num="0138">In a case where the maximum feedback rate is equivalent to the feedback rate in 3DNR processing, the in-vehicle camera system <b>1</b> is able to achieve SNR improvement performance comparable to that of 3DNR processing by using a line buffer having a capacity smaller than 3DNR processing requiring the use of a large-capacity frame buffer.</p><p id="p-0161" num="0139">In a case where NR strength is raised excessively high, the trailing phenomenon and other artifacts may occur in the recursive 2DNR process without the fast convergence function. Therefore, NR processing cannot be performed with NR strength raised high. However, the recursive 2DNR process with the fast convergence function according to the present technology is able to perform NR processing with NR strength raised high.</p><p id="p-0162" num="0140">An in-vehicle camera moves when an automobile moves. Therefore, 3DNR processing, which is strong NR processing, is not suitable for NR processing of images captured by the in-vehicle camera. Consequently, 2DNR processing is performed as NR processing of images captured by the in-vehicle camera. However, since the convergence of 2DNR processing is slow, the trailing phenomenon and other artifacts may occur and cause the recognizer <b>16</b> to make an erroneous recognition.</p><p id="p-0163" num="0141">The recursive 2DNR process with the fast convergence function according to the present technology is able to suppress the occurrence of artifacts. Therefore, the in-vehicle camera system <b>1</b> can be applied to an in-vehicle camera in order to improve the SNR of images acquired by the in-vehicle camera.</p><p id="p-0164" num="0142">In a case where NR processing is performed in an autonomous or advanced driving system, real-time capability is important. Therefore, a circuit scale and simple processing suitable for incorporation into an image sensor are demanded. The in-vehicle camera system <b>1</b>, which does not require a large-capacity line buffer or frame buffer, is applicable to an autonomous or advanced driving system. Further, since the recursive 2DNR process with the fast convergence function achieves better SNR improvement than the recursive 2DNR process without the fast convergence function, the in-vehicle camera system <b>1</b> exerts a favorable influence on the results of detection by the recognizer <b>16</b> and DMS.</p><p id="p-0165" num="0143">It should be noted that the in-vehicle camera system <b>1</b> produces a strong NR effect by using limited hardware resources and is thus applicable to a surveillance camera. Moreover, the in-vehicle camera system <b>1</b> is suitable for applications where a camera significantly moves and is thus applicable to an action camera.</p><heading id="h-0015" level="1">4. Modification of Image Processing Section</heading><p id="p-0166" num="0144">In some cases, the same pattern appears repeatedly in certain images. In such cases, edges exist repeatedly in a periodic manner. Therefore, when one of a plurality of pixels forming an image is viewed vertically, the count to be stored in the line buffer section <b>44</b> is repeatedly constant to some extent.</p><p id="p-0167" num="0145">Accordingly, in a case where the same pattern is repeated in images, the maximum count may be limited in order to prevent strong NR processing from being inadvertently performed.</p><p id="p-0168" num="0146"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram illustrating an example functional configuration of an image processing section <b>15</b><i>a. </i></p><p id="p-0169" num="0147">The configuration of the image processing section <b>15</b><i>a </i>depicted in <figref idref="DRAWINGS">FIG. <b>11</b></figref> differs from the configuration of the image processing section <b>15</b> described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref> in that the former includes a count monitoring section <b>101</b> disposed at a stage subsequent to the count calculation section <b>43</b>. The count N<sub>t=0 </sub>of each of a plurality of pixels included in the current line is supplied from the count calculation section <b>43</b> to the count monitoring section <b>101</b>.</p><p id="p-0170" num="0148">The count monitoring section <b>101</b> monitors the count N<sub>t=0 </sub>of each of the plurality of pixels included in the current line that is supplied from the line buffer section <b>44</b>. In a case where the count N<sub>t=0 </sub>of each of the plurality of pixels included in the current line is repeatedly equal to or smaller than a predetermined threshold, the count monitoring section <b>101</b> controls an SNR optimal feedback rate setting section <b>45</b><i>a </i>by limiting the maximum count used that is used to set the iir feedback rate for each pixel in the current line.</p><p id="p-0171" num="0149">According to control provided by the count monitoring section <b>101</b>, the SNR optimal feedback rate setting section <b>45</b><i>a </i>sets the iir feedback rate for each of the plurality of pixels included in the current line on the basis of the count N<sub>t=&#x2212;2 </sub>of each pixel in the second preceding line, which is acquired from the line buffer section <b>44</b>, and supplies information indicative of the iir feedback rate to the multiplication section <b>46</b>.</p><p id="p-0172" num="0150">As described above, in a case where the count of a plurality of processed pixels positioned vertically with respect to a certain pixel in the current line is repeatedly equal to or smaller than a constant value to some extent, the image processing section <b>15</b><i>a </i>causes the count monitoring section <b>101</b> to limit the maximum count. For example, if the count is inadvertently equal to or greater than a period between edges regardless periodical existence of the edges in a case where the count is repeatedly equal to or smaller than a constant value to some extent, that is, in a case where NR processing is performed on an image whose edges exist repeatedly in a periodic manner, it is assumed that strong NR processing may be erroneously performed.</p><p id="p-0173" num="0151">Consequently, the image processing section <b>15</b><i>a </i>causes the count monitoring section <b>101</b> to limit the maximum count, and thus enables the SNR optimal feedback rate setting section <b>45</b><i>a </i>to set the iir feedback rate by using a count that is equal to or less than the limited maximum count. This prevents strong NR processing from being erroneously performed.</p><p id="p-0174" num="0152">It should be noted that the flow of processing executed by the image processing section <b>15</b><i>a </i>is basically similar to the flow of processing depicted in the flowcharts of <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref>.</p><p id="p-0175" num="0153">As described above, the image processing section <b>15</b><i>a </i>causes the count monitoring section <b>101</b> to limit the iir feedback rate. This can suppress the occurrence of artifacts and thus can reduce noise.</p><heading id="h-0016" level="1">5. Other Modifications</heading><heading id="h-0017" level="1">Example Applications</heading><p id="p-0176" num="0154">Some components of the in-vehicle camera system <b>1</b> including the image processing section <b>15</b> may be disposed, for example, in a television receiver, a broadcast wave transmitter, or a recorder.</p><heading id="h-0018" level="1">Example Computer Configuration</heading><p id="p-0177" num="0155"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a block diagram illustrating an example hardware configuration of a computer that performs the above-described series of processes by executing a program.</p><p id="p-0178" num="0156">In the computer, a CPU (Central Processing Unit) <b>201</b>, a ROM (Read Only Memory) <b>202</b>, a RAM (Random Access Memory) <b>203</b>, and an EEPROM (Electronically Erasable and Programmable Read Only Memory) <b>204</b> are interconnected with a bus <b>205</b>. The bus <b>205</b> is further connected to an input/output interface <b>206</b>. The input/output interface <b>206</b> is connected to the outside.</p><p id="p-0179" num="0157">The computer configured as described above performs the above-described series of processes by allowing the CPU <b>201</b> to load the program which is stored, for example, in the ROM <b>202</b> or the EEPROM <b>204</b>, into the RAM <b>203</b> through the bus <b>205</b> and execute the loaded program. Further, the program to be executed by the computer (CPU <b>201</b>) may be written in advance in the ROM <b>202</b> or may be installed in the EEPROM <b>204</b> from the outside through the input/output interface <b>206</b> or updated.</p><heading id="h-0019" level="1">Example Applications to Mobile Bodies</heading><p id="p-0180" num="0158">The technology according to the present disclosure (the present technology) is applicable to various products. The technology according to the present disclosure may be implemented as a device that is to be mounted in one of various types of mobile bodies such as automobiles, electric automobiles, hybrid electric automobiles, motorcycles, bicycles, personal mobility devices, airplanes, drones, ships, and robots, for example.</p><p id="p-0181" num="0159"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a block diagram depicting an example of schematic configuration of a vehicle control system as an example of a mobile body control system to which the technology according to an embodiment of the present disclosure can be applied.</p><p id="p-0182" num="0160">The vehicle control system <b>12000</b> includes a plurality of electronic control units connected to each other via a communication network <b>12001</b>. In the example depicted in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the vehicle control system <b>12000</b> includes a driving system control unit <b>12010</b>, a body system control unit <b>12020</b>, an outside-vehicle information detecting unit <b>12030</b>, an in-vehicle information detecting unit <b>12040</b>, and an integrated control unit <b>12050</b>. In addition, a microcomputer <b>12051</b>, a sound/image output section <b>12052</b>, and a vehicle-mounted network interface (I/F) <b>12053</b> are illustrated as a functional configuration of the integrated control unit <b>12050</b>.</p><p id="p-0183" num="0161">The driving system control unit <b>12010</b> controls the operation of devices related to the driving system of the vehicle in accordance with various kinds of programs. For example, the driving system control unit <b>12010</b> functions as a control device for a driving force generating device for generating the driving force of the vehicle, such as an internal combustion engine, a driving motor, or the like, a driving force transmitting mechanism for transmitting the driving force to wheels, a steering mechanism for adjusting the steering angle of the vehicle, a braking device for generating the braking force of the vehicle, and the like.</p><p id="p-0184" num="0162">The body system control unit <b>12020</b> controls the operation of various kinds of devices provided to a vehicle body in accordance with various kinds of programs. For example, the body system control unit <b>12020</b> functions as a control device for a keyless entry system, a smart key system, a power window device, or various kinds of lamps such as a headlamp, a backup lamp, a brake lamp, a turn signal, a fog lamp, or the like. In this case, radio waves transmitted from a mobile device as an alternative to a key or signals of various kinds of switches can be input to the body system control unit <b>12020</b>. The body system control unit <b>12020</b> receives these input radio waves or signals, and controls a door lock device, the power window device, the lamps, or the like of the vehicle.</p><p id="p-0185" num="0163">The outside-vehicle information detecting unit <b>12030</b> detects information about the outside of the vehicle including the vehicle control system <b>12000</b>. For example, the outside-vehicle information detecting unit <b>12030</b> is connected with an imaging section <b>12031</b>. The outside-vehicle information detecting unit <b>12030</b> makes the imaging section <b>12031</b> image an image of the outside of the vehicle, and receives the imaged image. On the basis of the received image, the outside-vehicle information detecting unit <b>12030</b> may perform processing of detecting an object such as a human, a vehicle, an obstacle, a sign, a character on a road surface, or the like, or processing of detecting a distance thereto.</p><p id="p-0186" num="0164">The imaging section <b>12031</b> is an optical sensor that receives light, and which outputs an electric signal corresponding to a received light amount of the light. The imaging section <b>12031</b> can output the electric signal as an image, or can output the electric signal as information about a measured distance. In addition, the light received by the imaging section <b>12031</b> may be visible light, or may be invisible light such as infrared rays or the like.</p><p id="p-0187" num="0165">The in-vehicle information detecting unit <b>12040</b> detects information about the inside of the vehicle. The in-vehicle information detecting unit <b>12040</b> is, for example, connected with a driver state detecting section <b>12041</b> that detects the state of a driver. The driver state detecting section <b>12041</b>, for example, includes a camera that images the driver. On the basis of detection information input from the driver state detecting section <b>12041</b>, the in-vehicle information detecting unit <b>12040</b> may calculate a degree of fatigue of the driver or a degree of concentration of the driver, or may determine whether the driver is dozing.</p><p id="p-0188" num="0166">The microcomputer <b>12051</b> can calculate a control target value for the driving force generating device, the steering mechanism, or the braking device on the basis of the information about the inside or outside of the vehicle which information is obtained by the outside-vehicle information detecting unit <b>12030</b> or the in-vehicle information detecting unit <b>12040</b>, and output a control command to the driving system control unit <b>12010</b>. For example, the microcomputer <b>12051</b> can perform cooperative control intended to implement functions of an advanced driver assistance system (ADAS) which functions include collision avoidance or shock mitigation for the vehicle, following driving based on a following distance, vehicle speed maintaining driving, a warning of collision of the vehicle, a warning of deviation of the vehicle from a lane, or the like.</p><p id="p-0189" num="0167">In addition, the microcomputer <b>12051</b> can perform cooperative control intended for automatic driving, which makes the vehicle to travel automatedly without depending on the operation of the driver, or the like, by controlling the driving force generating device, the steering mechanism, the braking device, or the like on the basis of the information about the outside or inside of the vehicle which information is obtained by the outside-vehicle information detecting unit <b>12030</b> or the in-vehicle information detecting unit <b>12040</b>.</p><p id="p-0190" num="0168">In addition, the microcomputer <b>12051</b> can output a control command to the body system control unit <b>12020</b> on the basis of the information about the outside of the vehicle which information is obtained by the outside-vehicle information detecting unit <b>12030</b>. For example, the microcomputer <b>12051</b> can perform cooperative control intended to prevent a glare by controlling the headlamp so as to change from a high beam to a low beam, for example, in accordance with the position of a preceding vehicle or an oncoming vehicle detected by the outside-vehicle information detecting unit <b>12030</b>.</p><p id="p-0191" num="0169">The sound/image output section <b>12052</b> transmits an output signal of at least one of a sound and an image to an output device capable of visually or auditorily notifying information to an occupant of the vehicle or the outside of the vehicle. In the example of <figref idref="DRAWINGS">FIG. <b>13</b></figref>, an audio speaker <b>12061</b>, a display section <b>12062</b>, and an instrument panel <b>12063</b> are illustrated as the output device. The display section <b>12062</b> may, for example, include at least one of an on-board display and a head-up display.</p><p id="p-0192" num="0170"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram depicting an example of the installation position of the imaging section <b>12031</b>.</p><p id="p-0193" num="0171">In <figref idref="DRAWINGS">FIG. <b>14</b></figref>, the imaging section <b>12031</b> includes imaging sections <b>12101</b>, <b>12102</b>, <b>12103</b>, <b>12104</b>, and <b>12105</b>.</p><p id="p-0194" num="0172">The imaging sections <b>12101</b>, <b>12102</b>, <b>12103</b>, <b>12104</b>, and <b>12105</b> are, for example, disposed at positions on a front nose, sideview mirrors, a rear bumper, and a back door of the vehicle <b>12100</b> as well as a position on an upper portion of a windshield within the interior of the vehicle. The imaging section <b>12101</b> provided to the front nose and the imaging section <b>12105</b> provided to the upper portion of the windshield within the interior of the vehicle obtain mainly an image of the front of the vehicle <b>12100</b>. The imaging sections <b>12102</b> and <b>12103</b> provided to the sideview mirrors obtain mainly an image of the sides of the vehicle <b>12100</b>. The imaging section <b>12104</b> provided to the rear bumper or the back door obtains mainly an image of the rear of the vehicle <b>12100</b>. The imaging section <b>12105</b> provided to the upper portion of the windshield within the interior of the vehicle is used mainly to detect a preceding vehicle, a pedestrian, an obstacle, a signal, a traffic sign, a lane, or the like.</p><p id="p-0195" num="0173">Incidentally, <figref idref="DRAWINGS">FIG. <b>14</b></figref> depicts an example of photographing ranges of the imaging sections <b>12101</b> to <b>12104</b>. An imaging range <b>12111</b> represents the imaging range of the imaging section <b>12101</b> provided to the front nose. Imaging ranges <b>12112</b> and <b>12113</b> respectively represent the imaging ranges of the imaging sections <b>12102</b> and <b>12103</b> provided to the sideview mirrors. An imaging range <b>12114</b> represents the imaging range of the imaging section <b>12104</b> provided to the rear bumper or the back door. A bird's-eye image of the vehicle <b>12100</b> as viewed from above is obtained by superimposing image data imaged by the imaging sections <b>12101</b> to <b>12104</b>, for example.</p><p id="p-0196" num="0174">At least one of the imaging sections <b>12101</b> to <b>12104</b> may have a function of obtaining distance information. For example, at least one of the imaging sections <b>12101</b> to <b>12104</b> may be a stereo camera constituted of a plurality of imaging elements, or may be an imaging element having pixels for phase difference detection.</p><p id="p-0197" num="0175">For example, the microcomputer <b>12051</b> can determine a distance to each three-dimensional object within the imaging ranges <b>12111</b> to <b>12114</b> and a temporal change in the distance (relative speed with respect to the vehicle <b>12100</b>) on the basis of the distance information obtained from the imaging sections <b>12101</b> to <b>12104</b>, and thereby extract, as a preceding vehicle, a nearest three-dimensional object in particular that is present on a traveling path of the vehicle <b>12100</b> and which travels in substantially the same direction as the vehicle <b>12100</b> at a predetermined speed (for example, equal to or more than 0 km/hour). Further, the microcomputer <b>12051</b> can set a following distance to be maintained in front of a preceding vehicle in advance, and perform automatic brake control (including following stop control), automatic acceleration control (including following start control), or the like. It is thus possible to perform cooperative control intended for automatic driving that makes the vehicle travel automatedly without depending on the operation of the driver or the like.</p><p id="p-0198" num="0176">For example, the microcomputer <b>12051</b> can classify three-dimensional object data on three-dimensional objects into three-dimensional object data of a two-wheeled vehicle, a standard-sized vehicle, a large-sized vehicle, a pedestrian, a utility pole, and other three-dimensional objects on the basis of the distance information obtained from the imaging sections <b>12101</b> to <b>12104</b>, extract the classified three-dimensional object data, and use the extracted three-dimensional object data for automatic avoidance of an obstacle. For example, the microcomputer <b>12051</b> identifies obstacles around the vehicle <b>12100</b> as obstacles that the driver of the vehicle <b>12100</b> can recognize visually and obstacles that are difficult for the driver of the vehicle <b>12100</b> to recognize visually. Then, the microcomputer <b>12051</b> determines a collision risk indicating a risk of collision with each obstacle. In a situation in which the collision risk is equal to or higher than a set value and there is thus a possibility of collision, the microcomputer <b>12051</b> outputs a warning to the driver via the audio speaker <b>12061</b> or the display section <b>12062</b>, and performs forced deceleration or avoidance steering via the driving system control unit <b>12010</b>. The microcomputer <b>12051</b> can thereby assist in driving to avoid collision.</p><p id="p-0199" num="0177">At least one of the imaging sections <b>12101</b> to <b>12104</b> may be an infrared camera that detects infrared rays. The microcomputer <b>12051</b> can, for example, recognize a pedestrian by determining whether or not there is a pedestrian in imaged images of the imaging sections <b>12101</b> to <b>12104</b>. Such recognition of a pedestrian is, for example, performed by a procedure of extracting characteristic points in the imaged images of the imaging sections <b>12101</b> to <b>12104</b> as infrared cameras and a procedure of determining whether or not it is the pedestrian by performing pattern matching processing on a series of characteristic points representing the contour of the object. When the microcomputer <b>12051</b> determines that there is a pedestrian in the imaged images of the imaging sections <b>12101</b> to <b>12104</b>, and thus recognizes the pedestrian, the sound/image output section <b>12052</b> controls the display section <b>12062</b> so that a square contour line for emphasis is displayed so as to be superimposed on the recognized pedestrian. The sound/image output section <b>12052</b> may also control the display section <b>12062</b> so that an icon or the like representing the pedestrian is displayed at a desired position.</p><p id="p-0200" num="0178">An example of the vehicle control system to which the technology according to the present disclosure is applicable has been described above. The technology according to the present disclosure can be applied to the imaging section <b>12031</b>, the outside-vehicle information detecting unit <b>12030</b>, the microcomputer <b>12051</b>, the sound/image output section <b>12052</b>, and the display section <b>12062</b>, which are included in the above-described configuration. More specifically, the camera control section <b>11</b>, the imaging element <b>12</b>, the analog front-end <b>13</b>, the A/D conversion section <b>14</b>, and the image processing section <b>15</b>, which are depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, can be applied to the imaging section <b>12031</b>. Further, the recognizer <b>16</b>, which is depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, can be applied to the outside-vehicle information detecting unit <b>12030</b>. The AD/ADAS control section <b>17</b>, which is depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, can be applied to the microcomputer <b>12051</b>. The sound/image output section <b>12052</b> is equivalent to the D/A conversion section <b>19</b>, which is depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The display section <b>12062</b> is equivalent to the display section <b>20</b>, which is depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. When applied to automobiles, the technology according to the present disclosure is able to suppress the occurrence of artifacts and thus obtain images whose noise is reduced. Consequently, the technology according to the present disclosure ensures that outside-vehicle information for use in the ADAS is detected more accurately.</p><heading id="h-0020" level="1">Miscellaneous</heading><p id="p-0201" num="0179">The term &#x201c;system&#x201d; used in this description denotes an aggregate of a plurality of components (e.g., devices and modules (parts)), and is applicable no matter whether all the components are within the same housing. Therefore, the term &#x201c;system&#x201d; denotes not only a plurality of devices accommodated in separate housings and connected through a network, but also a single device including a plurality of modules accommodated in a single housing.</p><p id="p-0202" num="0180">Advantages described in this description are merely illustrative and not restrictive. The present technology may additionally provide advantages other than those described in this description.</p><p id="p-0203" num="0181">The embodiment of the present technology is not limited to the above-described one, and may be variously modified without departing from the scope and spirit of the present technology.</p><p id="p-0204" num="0182">For example, the present technology may be configured for cloud computing in which one function is shared by a plurality of devices through a network in order to perform processing in a collaborative manner.</p><p id="p-0205" num="0183">Further, each step described with reference to the foregoing flowcharts may be not only performed by a single device but also performed in a shared manner by a plurality of devices.</p><p id="p-0206" num="0184">Moreover, in a case where a plurality of processes is included in a single step, the plurality of processes included in the single step may be not only performed by a single device but also performed in a shared manner by a plurality of devices.</p><heading id="h-0021" level="1">Example Combinations of Configurations</heading><p id="p-0207" num="0185">The present technology can adopt the following configurations.</p><p id="p-0208" num="0000">(1)</p><p id="p-0209" num="0186">An image processing device including:</p><p id="p-0210" num="0187">a feedback rate setting section that sets a feedback rate for pixels in a current line on the basis of a count that is set for pixels in a previous line, the current line and the previous line being among a plurality of lines forming an image, the pixels in the current line being to be subjected to a blending process of blending inputted pixels in the current line and already outputted pixels in the previous line;</p><p id="p-0211" num="0188">a blending section that blends the pixels in the current line and the pixels in the previous line in accordance with the feedback rate; and</p><p id="p-0212" num="0189">a calculation section that calculates a count that is indicative of a cumulative number of pixels blended with the pixels in the current line by the blending process and is to be set for the pixels in the current line.</p><p id="p-0213" num="0000">(2)</p><p id="p-0214" num="0190">The image processing device according to (1), further including:</p><p id="p-0215" num="0191">an edge detection section that detects an edge of pixels in the current line,</p><p id="p-0216" num="0192">in which, on the basis of a detection result indicating the result of detection of an edge of pixels in the current line, the calculation section calculates a count that is to be set for the pixels in the current line.</p><p id="p-0217" num="0000">(3)</p><p id="p-0218" num="0193">The image processing device according to (2),</p><p id="p-0219" num="0194">in which the edge detection section sets the detection result to 0 in a case where an edge of the pixels in the current line is detected, and sets the detection result to 1 in a case where no edge of the pixels in the current line is detected, and in which the calculation section calculates a count that is to be set for the pixels in the current line by multiplying the count set for the pixels in the previous line by the detection result and adding 1 to a result of the multiplication.</p><p id="p-0220" num="0000">(4)</p><p id="p-0221" num="0195">The image processing device according to (3), further including:</p><p id="p-0222" num="0196">a multiplication section that calculates a ratio of blending the pixels in the previous line by multiplying the feedback rate by the detection result,</p><p id="p-0223" num="0197">in which the blending section blends the pixels in the current line with the pixels in the previous line at the ratio.</p><p id="p-0224" num="0000">(5)</p><p id="p-0225" num="0198">The image processing device according to any one of (1) to (4),</p><p id="p-0226" num="0199">in which the feedback rate setting section adds 1 to the count set for the pixels in the previous line, divides the count set for the pixels in the previous line by a result of the addition, and sets a result of the division as the feedback rate.</p><p id="p-0227" num="0000">(6)</p><p id="p-0228" num="0200">The image processing device according to any one of (1) to (5), further including:</p><p id="p-0229" num="0201">a monitoring section that monitors a count set for each pixel, and limits the count set for the pixels in the previous line on the basis of a result of the monitoring,</p><p id="p-0230" num="0202">in which the feedback rate setting section sets the feedback rate on the basis of the count limited by the monitoring section.</p><p id="p-0231" num="0000">(7)</p><p id="p-0232" num="0203">The image processing device according to (6),</p><p id="p-0233" num="0204">in which, in a case where the count is repeatedly equal to or smaller than a threshold, the monitoring section limits a maximum count that is set for the pixels in the previous line and is to be used for setting the feedback rate.</p><p id="p-0234" num="0000">(8)</p><p id="p-0235" num="0205">The image processing device according to (1), including:</p><p id="p-0236" num="0206">a sensor chip,</p><p id="p-0237" num="0207">in which the sensor chip includes<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0208">an imaging element that acquires a signal representing the image,</li>        <li id="ul0004-0002" num="0209">an analog front-end that performs an analog process on the signal,</li>        <li id="ul0004-0003" num="0210">a conversion section that converts the analog-processed signal to digital image data,</li>        <li id="ul0004-0004" num="0211">an image processing section that includes the feedback rate setting section, the blending section, and the calculation section, and</li>        <li id="ul0004-0005" num="0212">a control section that controls the imaging element, the analog front-end, the conversion section, and the image processing section.<br/>(9)</li>    </ul>    </li></ul></p><p id="p-0238" num="0213">An image processing method for causing an image processing device to perform the steps of:</p><p id="p-0239" num="0214">setting a feedback rate for pixels in a current line on the basis of a count that is set for pixels in a previous line, the current line and the previous line being among a plurality of lines forming an image, the pixels in the current line being to be subjected to a blending process of blending inputted pixels in the current line and already outputted pixels in the previous line;</p><p id="p-0240" num="0215">blending the pixels in the current line and the pixels in the previous line in accordance with the feedback rate; and</p><p id="p-0241" num="0216">calculating a count that is indicative of a cumulative number of pixels blended with the pixels in the current line by the blending process and is to be set for the pixels in the current line.</p><p id="p-0242" num="0000">(10)</p><p id="p-0243" num="0217">A program for causing a computer to perform the processes of:</p><p id="p-0244" num="0218">setting a feedback rate for pixels in a current line on the basis of a count that is set for pixels in a previous line, the current line and the previous line being among a plurality of lines forming an image, the pixels in the current line being to be subjected to a blending process of blending inputted pixels in the current line and already outputted pixels in the previous line;</p><p id="p-0245" num="0219">blending the pixels in the current line and the pixels in the previous line in accordance with the feedback rate; and</p><p id="p-0246" num="0220">calculating a count that is indicative of a cumulative number of pixels blended with the pixels in the current line by the blending process and is to be set for the pixels in the current line.</p><heading id="h-0022" level="1">REFERENCE SIGNS LIST</heading><p id="p-0247" num="0000"><ul id="ul0005" list-style="none">    <li id="ul0005-0001" num="0000">    <ul id="ul0006" list-style="none">        <li id="ul0006-0001" num="0221"><b>1</b>: In-vehicle camera system</li>        <li id="ul0006-0002" num="0222"><b>11</b>: Camera control section</li>        <li id="ul0006-0003" num="0223"><b>12</b>: Imaging element</li>        <li id="ul0006-0004" num="0224"><b>13</b>: Analog front-end</li>        <li id="ul0006-0005" num="0225"><b>14</b>: A/D conversion section</li>        <li id="ul0006-0006" num="0226"><b>15</b>: Image processing section</li>        <li id="ul0006-0007" num="0227"><b>16</b>: Recognizer</li>        <li id="ul0006-0008" num="0228"><b>17</b>: AD/ADAS control section</li>        <li id="ul0006-0009" num="0229"><b>18</b>: Storage</li>        <li id="ul0006-0010" num="0230"><b>19</b>: D/A conversion section</li>        <li id="ul0006-0011" num="0231"><b>20</b>: Display section</li>        <li id="ul0006-0012" num="0232"><b>41</b>: Noise amplitude calculation section</li>        <li id="ul0006-0013" num="0233"><b>42</b>: V direction plane detection section</li>        <li id="ul0006-0014" num="0234"><b>43</b>: Count calculation section</li>        <li id="ul0006-0015" num="0235"><b>44</b>: Line buffer section</li>        <li id="ul0006-0016" num="0236"><b>45</b>: SNR optimal feedback rate setting section</li>        <li id="ul0006-0017" num="0237"><b>46</b>: Multiplication section</li>        <li id="ul0006-0018" num="0238"><b>47</b>: Alpha blending processing section</li>        <li id="ul0006-0019" num="0239"><b>48</b>: Line buffer section</li>        <li id="ul0006-0020" num="0240"><b>101</b>: Count monitoring section</li>    </ul>    </li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230007146A1-20230105-M00001.NB"><img id="EMI-M00001" he="21.17mm" wi="76.20mm" file="US20230007146A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230007146A1-20230105-M00002.NB"><img id="EMI-M00002" he="20.49mm" wi="76.20mm" file="US20230007146A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00003" nb-file="US20230007146A1-20230105-M00003.NB"><img id="EMI-M00003" he="20.49mm" wi="76.20mm" file="US20230007146A1-20230105-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00004" nb-file="US20230007146A1-20230105-M00004.NB"><img id="EMI-M00004" he="9.48mm" wi="76.20mm" file="US20230007146A1-20230105-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00005" nb-file="US20230007146A1-20230105-M00005.NB"><img id="EMI-M00005" he="33.19mm" wi="96.27mm" file="US20230007146A1-20230105-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00006" nb-file="US20230007146A1-20230105-M00006.NB"><img id="EMI-M00006" he="18.71mm" wi="76.20mm" file="US20230007146A1-20230105-M00006.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00007" nb-file="US20230007146A1-20230105-M00007.NB"><img id="EMI-M00007" he="21.84mm" wi="76.20mm" file="US20230007146A1-20230105-M00007.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00008" nb-file="US20230007146A1-20230105-M00008.NB"><img id="EMI-M00008" he="9.48mm" wi="76.20mm" file="US20230007146A1-20230105-M00008.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00009" nb-file="US20230007146A1-20230105-M00009.NB"><img id="EMI-M00009" he="32.43mm" wi="96.27mm" file="US20230007146A1-20230105-M00009.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00010" nb-file="US20230007146A1-20230105-M00010.NB"><img id="EMI-M00010" he="18.71mm" wi="76.20mm" file="US20230007146A1-20230105-M00010.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00011" nb-file="US20230007146A1-20230105-M00011.NB"><img id="EMI-M00011" he="18.71mm" wi="76.20mm" file="US20230007146A1-20230105-M00011.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image processing device comprising:<claim-text>a feedback rate setting section that sets a feedback rate for pixels in a current line on a basis of a count that is set for pixels in a previous line, the current line and the previous line being among a plurality of lines forming an image, the pixels in the current line being to be subjected to a blending process of blending inputted pixels in the current line and already outputted pixels in the previous line;</claim-text><claim-text>a blending section that blends the pixels in the current line and the pixels in the previous line in accordance with the feedback rate; and</claim-text><claim-text>a calculation section that calculates a count that is indicative of a cumulative number of pixels blended with the pixels in the current line by the blending process and is to be set for the pixels in the current line.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The image processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>an edge detection section that detects an edge of pixels in the current line,</claim-text><claim-text>wherein, on a basis of a detection result indicating the result of detection of an edge of pixels in the current line, the calculation section calculates a count that is to be set for the pixels in the current line.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The image processing device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>,<claim-text>wherein the edge detection section sets the detection result to 0 in a case where an edge of the pixels in the current line is detected, and sets the detection result to 1 in a case where no edge of the pixels in the current line is detected, and</claim-text><claim-text>wherein the calculation section calculates a count that is to be set for the pixels in the current line by multiplying the count set for the pixels in the previous line by the detection result and adding 1 to a result of the multiplication.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The image processing device according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, further comprising:<claim-text>a multiplication section that calculates a ratio of blending the pixels in the previous line by multiplying the feedback rate by the detection result,</claim-text><claim-text>wherein the blending section blends the pixels in the current line with the pixels in the previous line at the ratio.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The image processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the feedback rate setting section adds 1 to the count set for the pixels in the previous line, divides the count set for the pixels in the previous line by a result of the addition, and sets a result of the division as the feedback rate.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The image processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>a monitoring section that monitors a count set for each pixel, and limits the count set for the pixels in the previous line on a basis of a result of the monitoring,</claim-text><claim-text>wherein the feedback rate setting section sets the feedback rate on a basis of the count limited by the monitoring section.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The image processing device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>,<claim-text>wherein, in a case where the count is repeatedly equal to or smaller than a threshold, the monitoring section limits a maximum count that is set for the pixels in the previous line and is to be used for setting the feedback rate.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The image processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising:<claim-text>a sensor chip,</claim-text><claim-text>wherein the sensor chip includes<claim-text>an imaging element that acquires a signal representing the image,</claim-text><claim-text>an analog front-end that performs an analog process on the signal,</claim-text><claim-text>a conversion section that converts the analog-processed signal to digital image data,</claim-text><claim-text>an image processing section that includes the feedback rate setting section, the blending section, and the calculation section, and</claim-text><claim-text>a control section that controls the imaging element, the analog front-end, the conversion section, and the image processing section.</claim-text></claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. An image processing method for causing an image processing device to perform the steps of:<claim-text>setting a feedback rate for pixels in a current line on a basis of a count that is set for pixels in a previous line, the current line and the previous line being among a plurality of lines forming an image, the pixels in the current line being to be subjected to a blending process of blending inputted pixels in the current line and already outputted pixels in the previous line;</claim-text><claim-text>blending the pixels in the current line and the pixels in the previous line in accordance with the feedback rate; and</claim-text><claim-text>calculating a count that is indicative of a cumulative number of pixels blended with the pixels in the current line by the blending process and is to be set for the pixels in the current line.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A program for causing a computer to perform the processes of:<claim-text>setting a feedback rate for pixels in a current line on a basis of a count that is set for pixels in a previous line, the current line and the previous line being among a plurality of lines forming an image, the pixels in the current line being to be subjected to a blending process of blending inputted pixels in the current line and already outputted pixels in the previous line;</claim-text><claim-text>blending the pixels in the current line and the pixels in the previous line in accordance with the feedback rate; and</claim-text><claim-text>calculating a count that is indicative of a cumulative number of pixels blended with the pixels in the current line by the blending process and is to be set for the pixels in the current line.</claim-text></claim-text></claim></claims></us-patent-application>
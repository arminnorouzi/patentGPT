<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004915A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004915</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17866721</doc-number><date>20220718</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>33</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>242</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>06393</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>06315</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>3344</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>243</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">CONVERSATIONAL BUSINESS TOOL</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16120146</doc-number><date>20180831</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11423347</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17866721</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>Kinaxis Inc.</orgname><address><city>Ottawa</city><country>CA</country></address></addressbook><residence><country>CA</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>PERRYMAN</last-name><first-name>Olivia Margot</first-name><address><city>Kanata</city><country>CA</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>BLACKMORE</last-name><first-name>Drew</first-name><address><city>Nepean</city><country>CA</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>OLIVEIRA ALMEIDA</last-name><first-name>Marcio</first-name><address><city>Stittsville</city><country>CA</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A business analytics conversational tool comprising: a device comprising a communication channel, a natural language processor (NLP), a fulfillment application program interface (F-API), a database application program interface (D-API), and a business management database; wherein: the NLP receives a user-input from a user through the communication channel; the NLP deduces an intent of the user-input; the NLP communicates the intent to the F-API; the F-API communicates a request for data associated with the intent to the database via the D-API; the D-API communicates the data associated with the intent to the F-API; the F-API converts the data associated with the intent to conversational form and sends the conversational form for voice output through the communication channel.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="48.09mm" wi="158.75mm" file="US20230004915A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="129.37mm" wi="171.45mm" file="US20230004915A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="196.51mm" wi="98.13mm" file="US20230004915A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="193.12mm" wi="181.44mm" file="US20230004915A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="235.97mm" wi="164.08mm" file="US20230004915A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="238.34mm" wi="168.66mm" file="US20230004915A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="242.99mm" wi="168.49mm" file="US20230004915A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="240.37mm" wi="118.53mm" file="US20230004915A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="232.58mm" wi="129.96mm" file="US20230004915A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="239.35mm" wi="110.57mm" file="US20230004915A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="238.25mm" wi="152.91mm" file="US20230004915A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="238.25mm" wi="115.23mm" file="US20230004915A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="226.40mm" wi="173.74mm" file="US20230004915A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="240.71mm" wi="135.21mm" file="US20230004915A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="230.55mm" wi="176.19mm" file="US20230004915A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="151.38mm" wi="171.87mm" file="US20230004915A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">PRIORITY CLAIM</heading><p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 16/120,146, filed Aug. 31, 2018, the entirety of which is hereby incorporated by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present disclosure relates to the field of business management. In particular, it relates to use of a conversational user interface for obtaining information related to the business.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Business data related to supply chain management is often very detailed and complicated to understand or visualize. The total amount of data available is often far too large for one person to read all of it. Since there is so much data, choosing the relevant features from the data can be time-consuming and difficult.</p><p id="p-0005" num="0004">Presenting the data poses a challenge since typical presentation methods (e.g. spreadsheets, charts) show raw numbers, whereas insights are left up to the reader to find. Furthermore, visualizations and graphs require trained skills to interpret meaningful results.</p><p id="p-0006" num="0005">Therefore, reporting up-to-date, aggregated business data in an easily-digestible format would greatly improve efficiency in making business decisions to correct and/or improve the supply chain.</p><p id="p-0007" num="0006">Currently, there are three main approaches to communicating aggregate business data: paper reports, phone or email communication, and interactive dashboards.</p><p id="p-0008" num="0007">Paper reports have the problem that they are inflexible. Data cannot be filtered, modified or explored further. If more details are required or requested, a new report must be created. This uses up valuable time and financial resources. Often too much data is provided in these reports such that irrelevant details obscure important aspects and insights. However, if too little data is provided, the executive may miss out on critical information. Also, the data provided in a paper report is not live, i.e., it is not being updated in real-time. As such, the most up-to-date business metrics will not be available, thereby hindering decision-making processes. Furthermore, the data is often represented in the form of spreadsheets, graphs and other visualizations that require trained skills to gain insight. Learning to interpret these results to gain meaningful knowledge of the business state is a time-consuming and challenging process.</p><p id="p-0009" num="0008">Phone or email communication can address the problem of up-to-date metrics. However, it comes at the cost of using human resources. For example, data scientists that report such information may not always be available for conversations and the results may be delayed.</p><p id="p-0010" num="0009">Interactive dashboards are a popular approach since they are up-to-date and can be filtered or modified. However, these do not solve the issue of complicated visualizations and may require even more training to comprehend. Dashboards also introduce a new challenge of fitting all the relevant information on the screen of a device. This approach also does not allow the user to multitask while they consume their business metrics.</p><p id="p-0011" num="0010">U.S. Pat. No. 9,977,808 B2 discloses intent based real-time analytical visualizations. Natural language processing is used to generate an analytical requirement statement from a received requirement statement (that is used to generate visualization analysis). The generated visualization analysis is displayed on a computer generated graphical user interface (GUI).</p><p id="p-0012" num="0011">US2014351232 Al discloses a method for accessing enterprise data using a natural language user interface. A mobile application converts voice data to text data, which is then used to generate a command for use by a business analytics engine or by an enterprise search engine. In either case, results are presented to the user on a user interface.</p><p id="p-0013" num="0012">U.S. Pat. No. 9,996,531 B1 discloses methods, mediums, and systems for managing a conversation. The system includes a computer-implemented input interface for receipt of an input comprising information in natural language; a dialog manager configured to determine an intent of the input, determine information to fulfill the intent; a conversational understanding document that documents the intent and the identified information; and an output interface that forwards the conversational understanding document towards a task completion handler separate and distinct from the dialog manager.</p><p id="p-0014" num="0013">US20180012163 discloses a method and system for providing sales information and insights through a conversational interface. The method and system processes data from data sources and analyzes the data to provide suggestions on how to improve the performance of the business.</p><p id="p-0015" num="0014">U.S. Ser. No. 10/042,882 B2 discloses an analytics program interface for retrieving analytics data from a data sources. The method includes receiving a request to retrieve analytics data, issuing a first query for analytics data from a first data source; and issuing a second query for data from a second data source different from the first data source. The method can include providing the analytics data and the data.</p><p id="p-0016" num="0015">It is thus advantageous to provide a conversational tool that is flexible, always available, up-to-date, easy to understand and provides only relevant information such as KPIs, business insights, anticipate future inquiries (i.e. requests for future data/metrics), and initiate collaboration to address problems in the supply chain.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0017" num="0016">In accordance with one embodiment, a business analytics conversational tool comprising: a device comprising a communication channel, a natural language processor (NLP), a fulfillment application program interface (F-API), a database application program interface (D-API), and a business management database; wherein: the NLP receives a user-input from a user through the communication channel; the NLP deduces an intent of the user-input; the NLP communicates the intent to the F-API; the F-API communicates a request for data associated with the intent to the database via the D-API; the D-API communicates the data associated with the intent to the F-API; the F-API converts the data associated with the intent to conversational form and sends the conversational form for voice output through the communication channel.</p><p id="p-0018" num="0017">In accordance with another embodiment, one or more computer-readable storage medium for executing a method for accessing business data and reporting an analysis thereof, the method comprising: receiving an oral query via a communication channel located in a device; converting the oral query to a command for communicating with a business database, performing a search and/or analysis of data in the database based on the command; retrieving the search and/or analysis results; and transmitting the search and/or analysis result in conversational form for voice output to the communication channel.</p><p id="p-0019" num="0018">Disclosed herein is a conversational business tool that comprises a Natural Language Processing Model that is trained on business conversations; intelligent analytics to prioritize business insights; and data-driven speech that delivers insights in a conversational manner.</p><p id="p-0020" num="0019">The conversational business tool may be integrated with a supply chain planning platform. A platform that provides rapid processing of business metrics and scenario simulations can be used to provide up-to-date analysis in a natural conversational flow when integrated with the conversational business tool. An example of a supply chain planning platform that provides rapid processing of business metrics and scenario simulations is disclosed in U.S. Pat. Nos. 7,610,212 B2; 8,015,044 B2; 9,292,573 B2; and U.S. Pub. No. 20130080200A1&#x2014; all of which are incorporated herein by reference. Such a &#x201c;rapid&#x201d; platform is heretofore referred to as a &#x201c;rapid response&#x201d; supply chain planning platform. Such a conversation business tool can compare forecasts of customizable KPIs to planned targets using the scenario simulation functionality disclosed in U.S. Pat. Nos. 7,610,212 B2; 8,015,044 B2; 9,292,573 B2; and U.S. Pub. No. 20130080200A1 (all of which are incorporated herein by reference).</p><p id="p-0021" num="0020">The foregoing and additional aspects and embodiments of the present disclosure will be apparent to those of ordinary skill in the art in view of the detailed description of various embodiments and/or aspects, which is made with reference to the drawings, a brief description of which is provided next.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF FIGURES</heading><p id="p-0022" num="0021">The foregoing and other advantages of the disclosure will become apparent upon reading the following detailed description and upon reference to the drawings.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an overview of a system architecture of an embodiment of the conversational business tool.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a more detailed view of the system architecture shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> summarizes the function of an NLP and illustrates a pseudocode of an embodiment of the conversational business tool.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a system architecture of another embodiment of the conversational business tool.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a master flowchart of an embodiment of the conversational business tool.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a detailed flowchart of an embodiment of a conversational business tool comprising five submodules.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a dialogue comprising a series of conversational turns in an embodiment of the conversational business tool, in which the modules shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> are used.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a flowchart of a subroutine comprising the business summary module shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates further details of the subroutine portion highlighted by the dotted square in <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a flowchart of a subroutine comprising the metric detail module shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates further details of the subroutine portion highlighted by the dotted square in <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates a flowchart of a subroutine comprising the metric contributing factors module shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates further details of the subroutine portion highlighted by the dotted square in <figref idref="DRAWINGS">FIG. <b>11</b></figref>.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates a flowchart of a subroutine comprising the &#x2018;responsibility with message&#x2019; and &#x2018;collaboration&#x2019; modules shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates further details of the subroutine portion highlighted by the upper dotted square in <figref idref="DRAWINGS">FIG. <b>13</b></figref>.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates further details of the subroutine portion highlighted by the lower dotted square in <figref idref="DRAWINGS">FIG. <b>13</b></figref>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0039" num="0038">While the present disclosure is susceptible to various modifications and alternative forms, specific embodiments or implementations have been shown by way of example in the drawings and will be described in detail herein. It should be understood, however, that the disclosure is not intended to be limited to the particular forms disclosed. Rather, the disclosure is to cover all modifications, equivalents, and alternatives falling within the spirit and scope of an invention as defined by the appended claims.</p><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0040" num="0039">Disclosed herein is a conversational business tool that comprises a Natural Language Processing Model that is trained on business conversations; intelligent analytics to prioritize business insights; and data driven speech that delivers insights in a conversational manner.</p><p id="p-0041" num="0040">Furthermore, by using a cloud service, the metric conversation business is &#x201c;always-on,&#x201d; and calculating the latest metrics for each inquiry the user has. It can be used at any time of day and provides immediate answers. The tool can recalculate metrics, filter results and drill down to further details at the request of the user. Once the relevant data is obtained, it is processed into an easy-to-understand sentence maintaining the flow of a natural conversation.</p><p id="p-0042" num="0041">The conversation business tool can check many possible filter combinations of the data to find trends and patterns in the data to communicate the interpretation of the results, not just the numbers. By checking forecasts in many different scenarios and time horizons, the conversation business tool may also able provide the user with early detection of potential issues and give indications of root causes to problems. The conversation business tool tracks what has been discussed to structure its responses and anticipate what will be asked next which can save the user time.</p><p id="p-0043" num="0042">Due to the nature of the conversation, the amount of information the user can obtain is almost unlimited but also not overwhelming since the user is in control of what is being presented. Language is an interface that everyone can understand intuitively with no special training or courses needed. Within the same interface, the user may able to send messages to others in the company by starting collaborations. With integration into a mobile device, the user can multitask while checking KPIs and can access business data from anywhere.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an overview of a system architecture of an embodiment of the conversational business tool (<b>10</b>). <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a more detailed view of the system architecture shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0045" num="0044">With reference to both <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>, a user (<b>15</b>) initiates a conversation by providing an utterance via a communication channel (<b>20</b>) in a device. The communication channel may be any type of channel that conveys utterances to a Natural Language Processor (NLP) (<b>25</b>). For example, the communication channel (<b>20</b>) may be a conversational virtual assistant (e.g. Siri&#xae;, Alexa&#xae;, Cortana&#xae;, etc.), Skype&#xae;, etc. The device may be a smart phone, a tablet, a laptop, a smart speaker, etc. The NLP (<b>25</b>) determines aspects of the utterance, such as intent and entities, which are then communicated to a Fulfillment Application Programming Interface (F-API) (<b>30</b>). The F-API (<b>30</b>) converts the intent to specific data requests, which are then communicated to a Database API (<b>40</b>) which is in communication with a business database (<b>35</b>). An example of the Database API (<b>40</b>) includes a RESTful API. The data associated with a specific intent is then retrieved from the database (<b>35</b>), and sent via the Database API (<b>40</b>) to the F-API, which in turn, draws insights, checks multiple cases and finds data that stands out; it then converts this information to conversational form which is then communicated to the user (<b>15</b>) via the communication channel (<b>20</b>). The business database may be part of a larger business software platform-for example, a supply chain management software platform, such as a rapid response platform as defined above.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> summarizes the function of an NLP and illustrates a pseudocode of an embodiment of the conversational business tool. The NLP undergoes training in order to classify utterances into the correct intent. Training includes positive reinforcement when the system correctly identifies intents and negative reinforcement when it is wrong. Such training enables the conversational business tool to handle user utterances in in the future.</p><p id="p-0047" num="0046">The pseudo code of the Fulfillment API basically takes a user query (utterance), matches intent to a function, obtains the appropriate data, forms the response and sends the response to the user.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a system architecture (<b>50</b>) of another embodiment of the conversational business tool, in which multiple different customers (<b>55</b>, <b>60</b>, <b>65</b>) use the tool simultaneously. Specifically, <figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates scalable, multitenant architecture to support customized business metrics and multiple customers. Each customer (<b>55</b>, <b>60</b>, <b>65</b>) accesses a respective individual NLP (<b>75</b>,<b>80</b>, <b>85</b>) that is customized for that particular customer. Each NLP (<b>75</b>,<b>80</b>, <b>85</b>) communicates with a common Fulfillment API (<b>90</b>), marking the conversation with identification for the particular customer (<b>76</b>), which the F-API uses to correctly (<b>95</b>) channel data requests to the respective correct customer database (<b>87</b>, <b>88</b>, <b>89</b>). In addition, a customer's database updates names of entities (<b>91</b>) to the customer's NLP (<b>75</b>). Where a rapid response system is used, the command (<b>92</b>) is given to generate data resources that can be calculated sufficiently quickly.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a master flowchart of an embodiment of the conversational business tool. A conversation (<b>100</b>) starts with a first utterance (<b>105</b>), which is converted (<b>110</b>) to a request for data from the database, followed by a response (<b>115</b>) to the first utterance. If the conversation is incomplete, the process is repeated until the conversation ends.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a detailed flowchart of an embodiment of the conversational business tool comprising five submodules (<b>200</b>, <b>205</b>, <b>210</b>, <b>215</b>, <b>220</b>). The user (<b>225</b>) is greeted, and is provided with an introduction (<b>230</b>) is s/he is new; or welcomed back (<b>235</b>) if s/he is returning. At this juncture, there are three conversational modules available&#x2014;one that provides a business summary (<b>200</b>); one that provides reporting on a specific metric (<b>205</b>); and a third that provides contributing factors (<b>210</b>) to the reported metric. The modules are configured to interact, depending on the request of the user (<b>225</b>).</p><p id="p-0051" num="0050">For example, the user may initially request a business summary (<b>200</b>), followed by a request for a specific metric (<b>205</b>) (e.g. revenue, inventory, etc), followed by a request for contributing factors (<b>210</b>) for that metric. Or the user may request a business summary (<b>200</b>) followed by a request for contributing factors (<b>210</b>) of a specific metric (i.e. bypass the request for a specific metric). Or, a user may simply request a summary of a specific metric (<b>205</b>), followed by a request for details of that metric (<b>210</b>).</p><p id="p-0052" num="0051">The business summary (<b>200</b>) can provide a list of metrics (<b>240</b>), and may classify the metrics in different ranges (<b>245</b>), as discussed in greater detail in <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0053" num="0052">The user may then want to contact (<b>235</b>) an individual responsible for a particular metric, so that a collaboration (<b>220</b>) may begin to address the particular metric. A responsibility-with-message module (<b>215</b>) can be used to compose a message that is verified by the user, and then sent to the responsible individual. A further collaboration module (<b>220</b>) can be used to initiate collaboration between authorized personnel to address issues provided by the business analysis. The collaboration module (<b>220</b>) is used, provided the supply chain planning platform supports collaboration.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a dialogue comprising a series of conversational turns in an embodiment of the conversational business tool, in which the modules shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> are used. In addition, the tool is integrated with a supply chain planning platform that provides for rapid processing of business metrics and scenario simulations; i.e. the &#x201c;rapid response&#x201d; platform defined above.</p><p id="p-0055" num="0054">The user has requested a report for the day. A summary is provided orally, while a summary graphic can be provided on the device used by the user to access the tool. The user then asks for a future forecast of a specific metric (utilization), which the tool is able to provide instantaneously due to its integration with the rapid reply supply chain planning platform described above. The user then requests a summary report of another specific metric (revenue), followed by a request for contributing factors. This is reported orally, and also includes a graphic (i.e. pie chart) for easy visualization. More information regarding contributing factors is requested by the user. The tool responds with two more factors. These responses are up-to-date and instantaneous due to the integration of the tool with the aforementioned platform.</p><p id="p-0056" num="0055">The user then requests action in the form of a request to contact the appropriate personnel. The tool provides the appropriate contact information and composes a draft message for review by the user. Once confirmed, the message is sent. The tool checks to see if the user requests anything further.</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a flowchart of a subroutine comprising the business summary module (<b>200</b>) shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. In this subroutine, a basic intent (<b>305</b>) is deduced from the utterance (<b>300</b>). The intent may be selected from a class of intents-for example, a question, a command to get data, a response, etc. Once the intent (<b>305</b>) is deduced, this triggers a step to establish which data to retrieve from the database (<b>310</b>). The Fulfillment API stores the most up to date status data locally. After identifying the intent (<b>305</b>), the F-API updates the status of its data via a command to the database, as denoted by the step &#x201c;Update Status&#x201d; (<b>315</b>).</p><p id="p-0058" num="0057">Data is retrieved in two forms: an overview of the data (<b>320</b>) and insights (<b>325</b>) into the relevant data (e.g. business metrics such as revenue, inventory, utilization, margins, KPIs, etc). This is then designed into a conversational response (<b>330</b>) which is conveyed to the communication channel (<b>335</b>). There is an option of providing graphics (<b>340</b>) to accompany the response. The user then determines whether to end the conversation or continue to ask further questions.</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates further details of the subroutine portion (<b>350</b>) highlighted in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. The business summary routine is initiated by a general verbal query (<b>400</b>), examples of which are shown in the upper box. The subroutine then obtains a list of metrics (<b>405</b>) and groups the metrics by range (<b>410</b>). As an example, there can be three ranges: whether a metric is on track (i.e. compared to targets), warrants a risk warning, or is in a critical state (i.e. &#x2018;on-track&#x2019;, &#x2018;warning&#x2019;, &#x2018;critical&#x2019;). A breakdown (<b>415</b>) of metrics in each range can be reported. For example, if there are no metrics in a given range, this range is skipped (<b>420</b>). If there is 1 metric in the range (<b>425</b>), the user interface replies to that effect. If there is more than one metric in the range (<b>430</b>), the response is to that effect. For example, for the range &#x201c;on-track&#x201d;, if only revenue is on track, then the conversational user interface replies &#x201c;revenue on track&#x201d;. If, say revenue and inventory are on track, the conversational user interface replies &#x201c;revenue and inventory are on track&#x201d;. Subsequently, subroutine obtains (<b>435</b>) details on the metric that has the poorest performance in relation to its target. The user is informed whether the worst-performing metric is above target (440) or below target (<b>445</b>).</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a flowchart of a subroutine comprising the metric detail module (<b>205</b>) shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0061" num="0060">In this module, both a basic intent (<b>505</b>) and an entity (<b>510</b>) are identified from the utterance (<b>500</b>). For example, an entity (<b>510</b>) may be revenue, while the intent (<b>505</b>) may be &#x201c;get data&#x201d; related to the entity (<b>510</b>). This directs the tool to perform the intent (<b>505</b>) function related to the entity (<b>510</b>). In an example, this may mean to get data about revenue. Since most entities are reported in different time horizons (e.g. monthly, quarterly, yearly; current, previous year, etc), the time horizon (<b>515</b>) is set, after which the status is updated (<b>520</b>).</p><p id="p-0062" num="0061">Data is then gathered (<b>525</b>) for the current time horizon, and data calculated for future time horizons is also retrieved (<b>530</b>). This step (of obtaining calculated data) relies on a command being sent to the supply chain planning platform to calculate the appropriate metrics for the future. As such, a meaningful result is obtained if the tool is integrated into a rapid reply platform, as described above. The results are then compared (<b>535</b>), and relayed in conversational form (<b>540</b>) to the user.</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates further details of the subroutine portion (<b>550</b>) highlighted by the dotted square in <figref idref="DRAWINGS">FIG. <b>9</b></figref>. The metric-details subroutine is triggered by a query (<b>600</b>) about a particular metric, and the entities are a metric name. Examples of metrics include revenue, utilization, margin, inventory, etc. The subroutine can have three steps: get time horizon (<b>605</b>), get metric calculations (<b>610</b>), and get end of year calculations (<b>615</b>), which are executed sequentially. First a time horizon is chosen (<b>605</b>); the time horizon may be monthly, quarterly, yearly or the previous year's data. For example the bucket could be quarterly data, yearly data or last year's data. The &#x2018;get metric calculation&#x2019; (<b>610</b>) will check the calculated values for a metric and compare with the actual value. For example &#x201c;Revenue is $6.2 million but the target is $5 million&#x201d;. Finally the future predictions (<b>615</b>) are given by retrieving results of scenario simulations, found for example, in a supply chain planning platform such as &#x201c;rapid response&#x201d;, and compared with the target (<b>620</b>).</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates a flowchart of a subroutine comprising the metric contributing factors module (<b>210</b>) shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0065" num="0064">This module is accessed following either the business summary module (<b>200</b>) and/or the metric detail module (<b>205</b>), in which a metric (i.e. entity) has been identified (<b>700</b>). The preceding dialogue has been stored as &#x201c;context&#x201d; (705)&#x2014; thus the entity (<b>700</b>) is already identified. The intent is deduced (<b>710</b>). For example, the intent (<b>710</b>) may be a question (e.g. &#x201c;why&#x201d;?). Once deduced, detailed information is retrieved (<b>715</b>) from the database, in which regional data (<b>720</b>) and product family data (<b>725</b>) are each grouped and summarized. While the full summary and grouping can be reported in conversational form, in order to avoid repetition, only that data which has not been previously conveyed (<b>730</b>), is provided to the user in a conversational form (<b>735</b>), and optionally with a graphic (<b>740</b>).</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates further details of the subroutine portion highlighted (<b>750</b>) by the dotted square in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. The intent and entities (<b>800</b>) have been previously identified, and as such, further details/analysis of the metrics is provided in this contributing-factors subroutine. Different filters may be applied to the data (e.g. filter by region, by part, etc.) to find the areas in which a metric diverges from its target the most, since these will be of highest interest to the user. In <figref idref="DRAWINGS">FIG. <b>12</b></figref>, for example, a region filter (<b>805</b>) and a parts filter (<b>810</b>) have been selected. The region and the part for the selected metric that are the furthest (<b>815</b>) from their respective target are highlighted to the user through the speech examples (820, 825) shown.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates a flowchart of a subroutine comprising the responsibility-with-message (<b>215</b>) and collaboration modules (<b>220</b>) shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. The utterance (<b>900</b>) in this conversation turn includes entities (<b>905</b>) for a metric name, a region name and a part name. Once the necessary parameters (<b>910</b>) are given, the module requests (<b>915</b>) a name of the requested responsible individual from the database (<b>920</b>). If no such person (<b>925</b>) is found in the database (<b>920</b>), a message is not sent (<b>935</b>). If such a person is found (<b>940</b>) in the database (<b>920</b>), a draft message is composed (<b>945</b>) for verification (<b>950</b>) by the user. Once approved (<b>955</b>), a further module can initiate collaboration (<b>960</b>) between authorized personnel to address any metrics issue, provided the supply chain planning platform supports (<b>965</b>) collaboration in the form of concurrent planning.</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates further details of the subroutine portion highlighted by the upper dotted square (<b>970</b>) in <figref idref="DRAWINGS">FIG. <b>13</b></figref>. The responsibility-with-message module is triggered by a combination of intents and specific entities of a metric name, and filters of the metric (<b>980</b>) (in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the example of region and parts filters are used). Examples of utterances (<b>982</b>) for this module are provided at the top. After successfully obtaining the responsible individual (<b>984</b>) from the database, the tool audibly conveys the information in a conversation format (<b>986</b>) to the user. This is followed by either a draft message (<b>988</b>) (to send to the responsible individual) or a query (<b>990</b>) to the user to compose a message to be sent.</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates further details of the collaboration subroutine portion highlighted by the lower dotted square (<b>975</b>) in in <figref idref="DRAWINGS">FIG. <b>13</b></figref>. The collaboration module is triggered by a combination of intent and specific entities of a metric name, a region name, part name and message. Examples of utterances for this module are provided at the top. After successfully sending the message composed in the previous module, the tool conveys to the user that confirmation that collaboration has been initiated.</p><p id="p-0070" num="0069">Although the operations of some of the disclosed methods are described in a particular, sequential order for convenient presentation, it should be understood that this manner of description encompasses rearrangement, unless a particular ordering is required by specific language set forth below. For example, operations described sequentially may in some cases be rearranged or performed concurrently. Moreover, for the sake of simplicity, the attached figures may not show the various ways in which the disclosed methods can be used in conjunction with other methods.</p><p id="p-0071" num="0070">Although the algorithms described above including those with reference to the foregoing flow charts have been described separately, it should be understood that any two or more of the algorithms disclosed herein can be combined in any combination. Any of the methods, algorithms, implementations, or procedures described herein can include machine-readable instructions for execution by: (a) a processor, (b) a controller, and/or (c) any other suitable processing device. Any algorithm, software, or method disclosed herein can be embodied in software stored on a non-transitory tangible medium such as, for example, a flash memory, a CD-ROM, a floppy disk, a hard drive, a digital versatile disk (DVD), or other memory devices, but persons of ordinary skill in the art will readily appreciate that the entire algorithm and/or parts thereof could alternatively be executed by a device other than a controller and/or embodied in firmware or dedicated hardware in a well known manner (e.g., it may be implemented by an application specific integrated circuit (ASIC), a programmable logic device (PLD), a field programmable logic device (FPLD), discrete logic, etc.). Also, some or all of the machine-readable instructions represented in any flowchart depicted herein can be implemented manually as opposed to automatically by a controller, processor, or similar computing device or machine. Further, although specific algorithms are described with reference to flowcharts depicted herein, persons of ordinary skill in the art will readily appreciate that many other methods of implementing the example machine readable instructions may alternatively be used. For example, the order of execution of the blocks may be changed, and/or some of the blocks described may be changed, eliminated, or combined.</p><p id="p-0072" num="0071">It should be noted that the algorithms illustrated and discussed herein as having various modules which perform particular functions and interact with one another. It should be understood that these modules are merely segregated based on their function for the sake of description and represent computer hardware and/or executable software code which is stored on a computer-readable medium for execution on appropriate computing hardware. The various functions of the different modules and units can be combined or segregated as hardware and/or software stored on a non-transitory computer-readable medium as above as modules in any manner, and can be used separately or in combination.</p><p id="p-0073" num="0072">While particular implementations and applications of the present disclosure have been illustrated and described, it is to be understood that the present disclosure is not limited to the precise construction and compositions disclosed herein and that various modifications, changes, and variations can be apparent from the foregoing descriptions without departing from the spirit and scope of an invention as defined in the appended claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer-implemented method comprising:<claim-text>deducing, by an NLP, an intent and one or more entities from an oral query;</claim-text><claim-text>obtaining, by a fulfillment application program interface (F-API), data associated with the intent and the one or more entities from a database, the F-API comprising a business summary module, a business metrics detail module and a business metrics contributing factor module;</claim-text><claim-text>configuring access to the business metrics contributing factor module after at least one of the business summary module and the business metric detail module;</claim-text><claim-text>in response to a first type of intent:<claim-text>grouping and summarizing, by the business summary module, the data associated with the intent and the one or more entities;</claim-text><claim-text>providing, by the business summary module, one or more insights into the data; and</claim-text><claim-text>forming, by the business summary module, a first conversational response to the user;</claim-text></claim-text><claim-text>in response to a second type of intent:<claim-text>setting, by the business metric detail module, a time horizon for the one or more entities;</claim-text><claim-text>gathering, by the business metric detail module, data related to the one or more entities for the time horizon;</claim-text><claim-text>gathering, by the business metric detail module, data related to the one or more entities for a future time horizon;</claim-text><claim-text>providing, by the business metric detail module, a comparison of the data for the time horizon with the data for the future time horizon; and</claim-text><claim-text>forming, by the business metric detail module, a second conversational response to the user comprising the comparison;</claim-text><claim-text>in response to a third type of intent:</claim-text><claim-text>identifying, by the business metrics contributing factor module, a subset of the one or more entities based on a previous dialogue involving at least one of the business summary module and the business metrics detail module;</claim-text><claim-text>obtaining, by the business metrics contributing factor module, further information about the subset;</claim-text><claim-text>grouping and summarizing, by the business metrics contributing factor module, data related to subset; and</claim-text><claim-text>forming, by the business metrics contributing factor module, a third conversational response to the user comprising information about data that has not been previously conveyed by either the business summary module or the business metrics detail module;</claim-text></claim-text><claim-text>and</claim-text><claim-text>sending, by the F-API, each of the first, second and third conversational responses for voice output through a communication channel.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>obtaining, by the business summary module, an up-to-date list of business metrics related to the one or more entities;</claim-text><claim-text>listing, by the business summary module, how many business metrics are found in a respective performance range; and</claim-text><claim-text>providing, by the business summary module, information of a worst-performing business metric in relation to a target thereof.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>providing, by the business metric detail module, current performance of a business metric in the time horizon;</claim-text><claim-text>comparing, by the business metric detail module, the current performance of the business metric to a performance target thereof; and</claim-text><claim-text>providing, by the business metric detail module, a future projection of the business metric.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>obtaining, by the business metric contributing factor module, a breakdown of the subset according to one or more filters; and</claim-text><claim-text>determining which business metric is furthest from a projected target thereof within each of the one or more filters.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the F-API further comprises a user responsible module and a collaboration initiation module; and<claim-text>wherein the method further comprises:<claim-text>in response to a fourth type of intent:<claim-text>providing, by the user responsible module, a name of an individual to address a subset of the business metric that is performing below a projected target thereof;</claim-text><claim-text>sending, by the user responsible module, a communication to the individual; and</claim-text><claim-text>initiating, by the collaboration initiation module, collaboration between individuals to address the subset of the business metric that is performing below the projected target.</claim-text></claim-text></claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the database forms part of a supply chain planning platform that provides rapid processing of business metrics, rapid processing of scenario simulations, and up-to-date analytics in response to the oral query.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the communication channel is housed in a device selected from a laptop, a tablet, a smartphone and a smart speaker.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The computer-implemented method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the device further comprises a screen; and<claim-text>wherein the method further comprises:<claim-text>converting, by the F-API, the data associated with the intent and the one or more entities to a visualized form for presentation on the screen.</claim-text></claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The computer-implemented method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the visualized form is a text, a graph, a chart or a table.</claim-text></claim></claims></us-patent-application>
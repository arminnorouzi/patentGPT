<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230006977A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230006977</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17939224</doc-number><date>20220907</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>9</main-group><subgroup>40</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>62</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>30</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>9</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>9</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>20</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>17</main-group><subgroup>16</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>63</main-group><subgroup>0428</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>6267</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>623</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>082</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>30</main-group><subgroup>0623</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>9</main-group><subgroup>008</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>9</main-group><subgroup>0625</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>20</main-group><subgroup>401</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>17</main-group><subgroup>16</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>2209</main-group><subgroup>46</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>2220</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEMS AND METHODS FOR SECURE AVERAGING OF MODELS FOR FEDERATED LEARNING AND BLIND LEARNING USING SECURE MULTI-PARTY COMPUTATION</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17180475</doc-number><date>20210219</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17939224</doc-number></document-id></child-doc></relation></continuation><continuation-in-part><relation><parent-doc><document-id><country>US</country><doc-number>16828085</doc-number><date>20200324</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17180475</doc-number></document-id></child-doc></relation></continuation-in-part><continuation-in-part><relation><parent-doc><document-id><country>US</country><doc-number>16828216</doc-number><date>20200324</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17180475</doc-number></document-id></child-doc></relation></continuation-in-part><continuation-in-part><relation><parent-doc><document-id><country>US</country><doc-number>17176530</doc-number><date>20210216</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17180475</doc-number></document-id></child-doc></relation></continuation-in-part><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16828354</doc-number><date>20200324</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10924460</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17176530</doc-number></document-id></child-doc></relation></continuation><continuation-in-part><relation><parent-doc><document-id><country>US</country><doc-number>16828420</doc-number><date>20200324</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11363002</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17180475</doc-number></document-id></child-doc></relation></continuation-in-part><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17743887</doc-number><date>20220513</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>16828420</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17742808</doc-number><date>20220512</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17743887</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>63241255</doc-number><date>20210907</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>63020930</doc-number><date>20200506</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>62948105</doc-number><date>20191213</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>62948105</doc-number><date>20191213</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>62948105</doc-number><date>20191213</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>62948105</doc-number><date>20191213</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>TripleBlind, Inc.</orgname><address><city>Kansas City</city><state>MO</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Poorebrahim Gilkalaye</last-name><first-name>Babak</first-name><address><city>Kansas City</city><state>MO</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>GHARIBI</last-name><first-name>Gharib</first-name><address><city>Overland Park</city><state>KS</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>PATEL</last-name><first-name>Ravi</first-name><address><city>Kansas City</city><state>MO</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>STORM</last-name><first-name>Greg</first-name><address><city>Kansas City</city><state>MO</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>DAS</last-name><first-name>Riddhiman</first-name><address><city>Parkville</city><state>MO</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A system and method are disclosed for providing an averaging of models for federated learning and blind learning systems. The method includes selecting, at a server, a generator g and a number p, transmitting, to at least two n client devices, the generator g and the number p, receiving, from each client device i of the at least two client devices, a respective value k<sub>i</sub>=g<sup>ri </sup>mod p and transmitting the set of respective values k<sub>i </sub>to each client device i of the at least two client devices where respective added group of shares are generated on each client device i. The method includes receiving each respective added group of shares from each client device i of the at least two client devices and adding all the respective added group of shares to make a global sum of shares and dividing the global sum of shares by n.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="169.08mm" wi="135.72mm" file="US20230006977A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="204.55mm" wi="147.24mm" file="US20230006977A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="199.14mm" wi="137.75mm" file="US20230006977A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="198.88mm" wi="137.75mm" file="US20230006977A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="198.63mm" wi="137.92mm" file="US20230006977A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="213.78mm" wi="139.70mm" file="US20230006977A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="229.02mm" wi="155.87mm" orientation="landscape" file="US20230006977A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="203.79mm" wi="123.78mm" file="US20230006977A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="213.53mm" wi="139.78mm" file="US20230006977A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="213.70mm" wi="139.70mm" file="US20230006977A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="214.63mm" wi="139.70mm" file="US20230006977A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="221.32mm" wi="142.83mm" file="US20230006977A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="207.69mm" wi="142.92mm" file="US20230006977A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="167.05mm" wi="151.55mm" orientation="landscape" file="US20230006977A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="220.64mm" wi="148.51mm" file="US20230006977A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="216.92mm" wi="150.45mm" file="US20230006977A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="220.39mm" wi="148.51mm" file="US20230006977A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="216.92mm" wi="148.34mm" file="US20230006977A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="212.34mm" wi="148.34mm" file="US20230006977A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="216.92mm" wi="148.34mm" file="US20230006977A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="212.34mm" wi="148.34mm" file="US20230006977A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="193.97mm" wi="144.19mm" orientation="landscape" file="US20230006977A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">PRIORITY CLAIM</heading><p id="p-0002" num="0001">The present application claims priority to U.S. Provisional Application No. 63/241,255, (Docket No. 213-0110P), filed Sep. 7, 2021, the content of which is incorporated herein by reference.</p><p id="p-0003" num="0002">The present application is a continuation of U.S. patent application Ser. No. 17/180,475 (Docket No. 213-0108), filed Feb. 19, 2021, which claims priority to U.S. Provisional Application No. 63/020,930 (Docket No. 213-0104P), filed on May 6, 2020; and is a continuation-in-part of U.S. application Ser. No. 16/828,085 (Docket No. 213-0100), filed Mar. 24, 2020, which claims priority to U.S. Provisional App. No. 62/948,105, filed on Dec. 13, 2019; and is a continuation-in-part of U.S. application Ser. No. 16/828,216 (Docket No. 213-0101), filed Mar. 24, 2020, which claims priority to U.S. Provisional App. No. 62/948,105, filed on Dec. 13, 2019; and is a continuation-in-part of U.S. application Ser. No. 17/176,530 (213-0102-CON), filed Feb. 16, 2021, which is a continuation of U.S. application Ser. No. 16/828,354 (213-0102), filed Mar. 24, 2020, now U.S. Pat. No. 10,924,460, issued Feb. 16, 2021, which claims priority to U.S. Provisional App. No. 62/948,105, filed on Dec. 13, 2019; and is a continuation-in-part of U.S. application Ser. No. 16/828,420 (Docket No. 213-0103), filed on Mar. 24, 2020, which claims priority to U.S. Provisional App. No. 62/948,105, filed on Dec. 13, 2019, the contents of which are incorporated herein by reference.</p><p id="p-0004" num="0003">The present application is a continuation of U.S. patent application Ser. No. 17/743,887 (Docket No. 213-0116), filed May 13, 2022, the contents of which are incorporated herein by reference.</p><p id="p-0005" num="0004">The present application is a continuation of U.S. patent application Ser. No. 17/742,808 (Docket No. 213-0117), filed May 12, 2022, the contents of which are incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0006" num="0005">The present disclosure generally relates to a process of secure multi-party averaging of models for federal learning and blind learning systems. Each of a plurality of clients can obtain an average of a group of client models without seeing each others' models.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0007" num="0006">The following details are not considered prior art but an introduction and background to the concepts disclosed herein. Federated Learning (FL) and Blind Learning (BL) are two deep learning paradigms to learn from decentralized datasets without transferring the data to a centralized location. In both methods, a centralized server manages the training process. At the end of each training epoch (iteration), the server receives and averages the local models trained at each client to generate a global model. While FL and BL can preserve some data privacy by not transferring it to the server, a malicious server can exploit clients' models during the averaging process to extract some sensitive information from the models' weights.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0008" num="0007">In order to describe the manner in which the above-recited and other advantages and features of the disclosure can be obtained, a more particular description of the principles briefly described above will be rendered by reference to specific embodiments thereof which are illustrated in the appended drawings. Understanding that these drawings depict only exemplary embodiments of the disclosure and are not therefore to be considered to be limiting of its scope, the principles herein are described and explained with additional specificity and detail through the use of the accompanying drawings in which:</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a federated learning model training approach;</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a split learning centralized model training approach;</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a split learning peer-to-peer approach;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a federated split leaning approach;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an embodiment related to blind learning;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates how blind decorrelation works across multiple clients;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a method embodiment;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a method embodiment;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates a method embodiment;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates a group of parties each with private data;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates a method embodiment</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates another method embodiment;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>14</b>A</figref> illustrates another method related to averaging of models from the standpoint of a server;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>14</b>B</figref> illustrates another method related to averaging of models from the standpoint of a respective client device; and</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates a system embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">INTRODUCTION</heading><p id="p-0024" num="0023">Certain aspects and embodiments of this disclosure are provided below. Some of these aspects and embodiments may be applied independently and some of them may be applied in combination as would be apparent to those of skill in the art. In the following description, for the purposes of explanation, specific details are set forth in order to provide a thorough understanding of embodiments of the application. However, it will be apparent that various embodiments may be practiced without these specific details. The figures and description are not intended to be restrictive.</p><p id="p-0025" num="0024">The ensuing description provides example embodiments only, and is not intended to limit the scope, applicability, or configuration of the disclosure. Rather, the following description of the exemplary embodiments will provide those skilled in the art with an enabling description for implementing an exemplary embodiment. It should be understood that various changes may be made in the function and arrangement of elements without departing from the spirit and scope of the application as set forth in the appended claims.</p><heading id="h-0006" level="1">BRIEF DESCRIPTION</heading><p id="p-0026" num="0025">What is needed in the art is a method to prevent the ability of a hacker to extract sensitive information from model weights as outlined above. This disclosure provides an innovative, secure averaging function that prevents the server from &#x201c;seeing&#x201d; the clients' models in plain text. Specifically, the secure averaging encrypts the model of each client before sending it to the server, which then (the server) averages the encrypted models to generate the global model. In this way, the server cannot exploit sensitive data from any specific client's model. Each client can therefore receive an average of all of the client models without seeing or having any data about any other client model weights.</p><p id="p-0027" num="0026">This disclosure will first discuss some background approaches and then introduce the new approaches. In one aspect, a particular platform is used to enable a federated development or training of neural network models. The use of the disclosed platform for training models in this manner is disclosed as another embodiment herein. In yet another embodiment, data is encrypted as it is passed between a server and one or more client devices. Various types of federated learning (Shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>), split learning (shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>), and split-learning peer-to-peer (Shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>) are disclosed herein. This disclosure describes as background two primary improvements over federated learning and split learning. The first is a blind learning approach (shown in <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>5</b></figref>) in which client side processing occurs in parallel and independent of other clients. The second disclosed approach (shown in <figref idref="DRAWINGS">FIGS. <b>6</b>-<b>10</b></figref>) relates to a multi-modal artificial intelligence (MMAI) training approach to handle different types of data from different clients. <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>13</b></figref> show background data such as concepts related to blind decorrelation in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, related methods and information regarding how to perform processes in a &#x201c;shared space&#x201d; in which parties generate &#x201c;shares&#x201d; of their data and rather than sharing data with another party, they provide just a &#x201c;share&#x201d; of their data that does not reveal anything regarding their data.</p><p id="p-0028" num="0027">Typical federated learning involves passing a whole model from a server to a client device for training using the client data. The process can include using a number of different clients, each with their respective data, for training purposes. The approach typically is performed in a linear and iterative fashion in which the whole model is sent to the first client with data, then after training at the first client, the whole model is received back to the server for &#x201c;averaging&#x201d;. Then whole updated model is sent to second client with data for additional processing. Then that updated model is sent back to the server for additional &#x201c;averaging&#x201d;, and so on. In a split learning approach, the model is split and part is sent to each client but there still is a linear and interactive training process that is inefficient. The split-learning peer-to-peer approach also is performed linearly as peer clients share data in the linear process. Improvements in maintaining the privacy of data and efficiency in the training process are needed.</p><p id="p-0029" num="0028">As noted above, a blind learning approach is disclosed as a variation on the typical federated learning approach. A method in this regard includes splitting up, at a server, a neural network into a first portion and a second portion, and sending the second portion separately to a first client and a second client. The clients can have the data (MRIs, patient data, banking data for customers, etc.) and each receive a portion of the neutral network (a certain number of layers of the network up to a cut layer). The method includes performing the following operations until a threshold is met: (1) performing, at the first client and the second client, a forward step on the second portion simultaneously to generate data SA<b>1</b> and SA<b>2</b> (See <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>4</b></figref>); (2) transmitting, from the first client and the second client, SA<b>1</b> and SA<b>2</b> to the server; (3) calculating, at the server, a loss value for the first client and the second client; (4) calculating, at the server, an average loss across the first client and the second client; (5) performing, at the server, backpropagation using the average loss and calculating gradients; and (6) sending, from the server, the gradients to the first client and the second client. This approach provides an improvement over the federated learning approach and the split learning approach by causing the processing on the client side (or the &#x201c;data server&#x201d; side) to operate in parallel and independent of each other. This approach also differs from the split learning peer-to-peer approach as well. The independent data servers send their activations up to the server side which aggregates, averages or otherwise processes the data depending on the network requirement to obtain the final trained model.</p><p id="p-0030" num="0029">Another aspect of this disclosure relates to an improvement in developing an artificial intelligence model in which multiple different modes of data or types of data are available to be used for training. For example, different clients might have different types of data. One client might have images of X-rays or MRIs and another client may have text describing a patient's health condition. In this regard, a method can include splitting a neural network into a first client-side network, a second client-side network and a server-side network, sending the first client-side network to a first client. The first client-side network is configured to process first data from the first client, the first data having a first type. The first client-side network can include at least one first client-side layer. The method includes sending the second client-side network to a second client. The second client-side network is configured to process second data from the second client, the second data having a second type. The second client-side network can include at least one second client-side layer, wherein the first type and the second type have a common association.</p><p id="p-0031" num="0030">The method can further include receiving, at the server-side network, first activations from a training of the first client-side network on first data from the first client, receiving, at the server-side network, second activations from a training of the second client-side network on second data from the second client, training at least one server-side layer of the server-side network based on the first activations and the second activations to generate gradients and transmitting the gradients from the server-side network to the first client-side network and the second client-side network. In this manner, multiple different types of data, having a common relationship such as being related to single patient or a single type or category of patient, are used to train the model.</p><p id="p-0032" num="0031">With respect to this present disclosure, the concept of providing a secure multi-party averaging of model for federated learning and blind learning systems. The disclosure enables n parties (clients) to securely average their models with the server without peer-to-peer socket communication. Specifically, the approach encrypts each model using the Diffie-Hellman key or some other type of key. The server then acts as the communication channel for the key exchange using Diffie Hellman or some other protocol. It is proven that the Diffie Hellman, when it is sued, is secure in case of the corrupted communication channel. The server in this case does not learn the actual key.</p><p id="p-0033" num="0032">An example method includes selecting, at a server, a generator g and a number p, transmitting, to n client devices comprising at least two client devices, the generator g and the number p, receiving, at the server and from each client device i of the at least two client devices, a respective value k<sub>i</sub>=g<sup>ri </sup>mod p to generate a set of respective values k<sub>i </sub>and transmitting the set of respective values k<sub>i </sub>to each client device i of the at least two client devices. Each client device i of the at least two client devices computes a key k<sub>ij </sub>in which the client device i computes the key k<sub>ij </sub>with a client device j: k<sub>ij</sub>=k<sub>j</sub><sup>r</sup><sup><sub2>i </sub2></sup>in which r<sub>i </sub>is a random number r<sub>i </sub>generated by the client device i. The client device i creates n shares of a respective model (d) associated with the client device i: [d]<sub>i1</sub>, . . . , [d]<sub>in</sub>=ShareGeneration(d). The client device i encrypts a client device j share using the key k<sub>ij</sub>: ([d&#x2032;]<sub>ij</sub>=[d]<sub>ij</sub>+k<sub>ij</sub>) for all 1&#x2264;j&#x2264;n and j&#x2260;i.</p><p id="p-0034" num="0033">The method further includes receiving, at the server, the client device j share ([d&#x2032;]<sub>ij</sub>) from the client device i, transmitting the client device j share ([d&#x2032;]<sub>ij</sub>) to each corresponding client device, wherein each respective client device decrypts the client device j share ([d&#x2032;]<sub>ij</sub>) with the k<sub>ij</sub>: [d]<sub>ij</sub>=[d&#x2032;]<sub>ij</sub>&#x2212;k<sub>ij </sub>and adds all the shares to generate a respective added group of shares, receiving, at the server, each respective added group of shares from each client device i of the at least two client devices and adding all the respective added group of shares to yield a global sum of shares and dividing the global sum of shares by n to compute an average of models.</p><p id="p-0035" num="0034">Systems and computer readable media can also be claims as well as other methods from the standpoint of a client device or group of client devices, a server device, or can cover processing that occurs on both devices.</p><p id="p-0036" num="0035">This summary is not intended to identify key or essential features of the claimed subject matter, nor is it intended to be used in isolation to determine the scope of the claimed subject matter. The subject matter should be understood by reference to appropriate portions of the entire specification of this patent, any or all drawings, and each claim.</p><p id="p-0037" num="0036">The foregoing, together with other features and embodiments, will become more apparent upon referring to the following specification, claims, and accompanying drawings.</p><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0038" num="0037">Disclosed herein is a new system, a platform, compute environment, cloud environment, marketplace, or any other characterization of the system that will enable an improved approach averaging of models such that an individual client can obtain an average of a group of client models without getting access to data of the other models. In one aspect, the approach is called a federated-split leaning approach that combines features from known approaches but that provides a training process that maintains privacy for data used to train the model from various client devices. This disclosure first discusses in more detail the federated learning approach, follow by the split learning approach and a split learning peer-to-peer approach and then discusses a federated split-learning approach. Additionally, the multi-modal artificial intelligent (MMAI) learning approach for different types of data is introduced as well. The federated split-learning approach and the MMAI approach build on several models including those mentioned above. The application will review these first approaches in more detail and then introduce the novel learning techniques.</p><heading id="h-0008" level="1">Federated Learning</heading><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates the federated learning approach <b>100</b>. This is an approach used by major companies now. A downside of this approach is that it proceeds &#x201c;linearly&#x201d; to one data provider at a time&#x2014;rather than in parallel. The example neural network shown is a fully connected feed forward neural network that is being trained using a federated learning approach. The training process in this case includes a server <b>102</b> creating a model <b>104</b> and sharing the model <b>106</b>A, <b>108</b>A and <b>110</b>A with respective clients <b>106</b>, <b>108</b>, <b>110</b> in a linear fashion. The clients train the respective model <b>106</b>A, <b>108</b>A, <b>110</b>A separately when they receive the model on their turn and respectively send their trained model data back to the server <b>102</b> as shown. The server <b>102</b> averages the models and produces a new model <b>104</b> with updated weights (a.k.a a trained model). The server <b>102</b> sends the new model or weights to the respective clients <b>106</b>, <b>108</b>, <b>110</b> in a linear fashion. The process is repeated a number of iterations or until a specific accuracy is achieved.</p><p id="p-0040" num="0039">In each iteration, the server <b>102</b> averages all participating models to create a trained model B. Thus, the server has a fully-trained model <b>104</b> at any point of time. The term &#x201c;global model&#x201d; refers to the model that results from the training process. The global model is a trained object that will be used for an inference task. An inference task might be to evaluate a medical image to classify whether the patient has cancer or a broken bone or some other medical condition.</p><p id="p-0041" num="0040">An example of this approach being used, devices such as an electronic watch, or a mobile device, a device charging at night for example, and connected to a Wi-Fi network, could have its processor used to train neural network models. Thus, client <b>1</b> (<b>106</b>) could be an Apple watch, client <b>2</b> (<b>108</b>) could be another person's iPhone, and so forth. An example of a model is the Siri speech processing service offered by Apple. Every device is training the same model and the only difference is that the respective client is training on the data local to them. The model or data is transmitted back to the server <b>102</b> and the server averages the model together. The downside is that respective clients, such as client <b>1</b> (<b>106</b>), could be tricked into sharing something about the data being used to train the model. This would be a leakage of privacy data and raise the issued outlined above. The challenge of the federated learning approach is that there is no model privacy as the entire model is passed from client to client. There are high computational costs as each client processes the entire model, and a heavy communication overhead as the entire model is transmitted numerous times. A reconstruction attack can make training data venerable as well.</p><heading id="h-0009" level="1">Split Learning</heading><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a split learning centralized approach. A model (neural network) <b>204</b> is split into two parts: one part (<b>206</b>A, <b>208</b>A, <b>210</b>A) resides on the respective client side <b>206</b>, <b>208</b>, <b>210</b> and includes the input layer to the model and optionally other layers up to a cut layer, and the other part (B) resides on the server side <b>202</b> and often includes the output layer. Split layer (S) refers to the layer (the cut layer) where A and B are split. In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, SA represents a split layer or data sent from A to B and SB represents a split layer sent from B to A.</p><p id="p-0043" num="0042">In one example, the neural network between B <b>204</b> and client <b>1</b> (<b>206</b>) is the B portion <b>204</b> plus the A<b>1</b> portion (<b>206</b>A) with the communication of data SB<b>1</b> (<b>206</b>C) and SA<b>1</b> (<b>206</b>B) to complete the entire neural network. The training process is as follows in this model. The server <b>202</b> creates A and B and sends a respective model A (<b>206</b>A, <b>208</b>A, <b>210</b>A) to the respective client <b>206</b>, <b>208</b>, <b>210</b>. For every client, the operations include repeating the following in a linear or iterative fashion across the group of clients until some conditions occurs. The respective client <b>206</b>, <b>208</b>, <b>210</b> on their turn downloads the most recent model A from the server <b>202</b> (Note that this step is different between the approach shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and <figref idref="DRAWINGS">FIG. <b>3</b></figref>). The clients <b>206</b>, <b>208</b>, <b>210</b> in their respective turn do a forward step on the model A and sends the output of A (i.e., activations at S only or SA<b>1</b> (<b>206</b>B), SA<b>2</b>(<b>208</b>B), SAN <b>210</b>B)) to the server <b>202</b> in addition to the required labels. The server <b>202</b> does a forward step on B using the SAs received from the respective client <b>206</b>, <b>208</b>, <b>210</b>. The server <b>202</b> calculates the loss function and the server <b>202</b> does backpropagation and calculates gradients at the S layer. The server <b>202</b> sends the gradients of S only (i.e., SB<b>1</b> (<b>206</b>C), SB<b>2</b> (<b>208</b>C), SBN (<b>210</b>C)) to the respective client <b>206</b>, <b>208</b>, <b>210</b>. This is process is performed linearly across the different clients such that the operations occur first for client <b>206</b>, followed by client <b>208</b>, and then client <b>210</b>. The client <b>206</b>, <b>208</b>, <b>210</b> does backpropagation using the SB gradients received from the server <b>202</b> and the client <b>206</b>, <b>208</b>, <b>210</b> shares their updated A (SA<b>1</b> (<b>206</b>B), SA<b>2</b> (<b>208</b>B), SAN (<b>210</b>B)) with the server <b>202</b>.</p><p id="p-0044" num="0043">The horizontal axis in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is time such that the processing occurs in like a round-robin fashion from client to client.</p><p id="p-0045" num="0044">In one example, network A<b>1</b> <b>206</b>A on client <b>1</b> can include a convolution layer and an activation layer. Having processed data, the client <b>1</b> (<b>206</b>) sends the result of that layer forward (SA<b>1</b> (<b>206</b>B)) to the next layer in the network, which is at the server <b>202</b>, which calculates the backpropagation and so forth as outlined above. The B network repeatedly (in round robin fashion) processes the different data from the different clients <b>206</b>, <b>208</b>, <b>210</b>. It will ultimately arrive at an averaged reflection of the network. It never trains the network on all the data from all the clients <b>206</b>, <b>208</b>, <b>210</b> at the same time. It can process data faster and have a benefit of B being averaged across the data as it is built. The final algorithm has not seen all the data. The model B cannot be tricked into revealing its data as it has never been trained on all of the data.</p><heading id="h-0010" level="1">Split Learning in a Peer-to-Peer Environment</heading><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a split learning peer-to-peer approach. A model (neural network) is split into two parts: one part (A) resides on the client side and includes the input layer, and the other part (B) resides on the server side and often includes the output layer. In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the client side part (A) is shown respectively as A<b>1</b> (<b>306</b>A) at client <b>306</b>, A<b>2</b> (<b>308</b>A) at client <b>308</b>, AN (<b>310</b>A) at client <b>310</b>. A split layer (S) refers to the layer where A and B are split. In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, SA represents a split layer sent from A to B and SB represents a split layer sent from B to A.</p><p id="p-0047" num="0046">In one example, the neural network between B and client <b>1</b> <b>306</b> is the B portion plus the A<b>1</b> portion <b>306</b>A with the communication of data SB<b>1</b> <b>306</b>C and SA<b>1</b> <b>306</b>B to complete the entire neural network. The training process is as follows in this model. The server <b>302</b> creates A and B and sends A to the clients <b>306</b>, <b>308</b>, <b>310</b>. For every client, the process includes repeating the following until some conditions occurs. First, the process includes downloading the most recent A from a previous client.</p><p id="p-0048" num="0047">Note that this step is different between the approach shown in other figures. The process then includes performing a forward step on A and sending the output of A (i.e., activations at S only) to the server <b>302</b> in addition to the required labels. The server <b>302</b> performs a forward step on B using the SA received from the respective client <b>306</b>, <b>308</b>, <b>310</b>. The server <b>302</b> calculates a loss function and performs a backpropagation and calculates gradients at S. The server <b>302</b> sends the gradients of S only (i.e., SB) to the respective clients <b>306</b>, <b>308</b>, <b>310</b>. The client does backpropagation using the SB gradients received from the server <b>302</b>. The client shares their updated A with the server <b>302</b>.</p><p id="p-0049" num="0048">The peer-to-peer approach generally involves the respective client updating its A model by directly downloading it from a last trained client, or more broadly, by a previously trained client. In this regard, the process of training clients can occur in a round-robin fashion where the clients are trained sequentially. For example, if client <b>1</b> <b>306</b> gets trained first, then in a peer-to-peer model, rather than client <b>2</b> <b>308</b> updating its client-side model A<b>2</b> from the server <b>302</b> or another trusted server, client <b>2</b> <b>308</b> updates its client model A<b>2</b> by downloaded the client side model A<b>1</b> from client <b>1</b> <b>306</b>. The previously trained model can be the last trained client model or it could be a model from some other previously trained client based on some criteria. For example, client <b>1</b> <b>306</b> and client <b>2</b> <b>308</b> may have their respective models trained. Client <b>3</b> <b>310</b> needs a client-side model update and might implement an algorithm or process to determine which client-side model to download between client <b>1</b> <b>306</b> and client <b>2</b> <b>308</b>. Note that the disclosure below implements a multi-model artificial intelligence training process that could apply here. If client <b>1</b> <b>306</b> processes images and its model A<b>1</b> focuses on image processing, and client <b>2</b> <b>308</b> processes text and its model A<b>2</b> focuses on text processing, and client <b>3</b> <b>310</b> processes images, then the algorithm or process could cause, in a peer-to-peer environment, the downloading of the client side model A<b>1</b> to the client <b>3</b> <b>310</b> as its update.</p><p id="p-0050" num="0049">In one scenario, there is not enough information from split learning to achieve proper training of the neural network. It is assumed in this model that a good training approach could be that A and B are aggregated at the server <b>302</b> in plain text by simply stacking them (A and B).</p><heading id="h-0011" level="1">Blind Learning</heading><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates the improvement to training neural networks disclosed herein. This improvement can be characterized as a blind learning approach and addresses some of the deficiencies of the approaches disclosed above. <figref idref="DRAWINGS">FIG. <b>4</b></figref> introduces a parallel processing approach. The parallel and independent processing causes the model training to occur at a faster pace than the other models described above.</p><p id="p-0052" num="0051">The blind learning approach does not perform the round robin processing described above. The server <b>402</b> splits the network at the &#x201c;split layer&#x201d; which is a user parameter inserted into the network definition codes. The &#x201c;top portion&#x201d; of the network is kept at the server <b>402</b> the &#x201c;bottom portion&#x201d; is sent to the respective data providers or clients <b>406</b>, <b>408</b>, <b>410</b> (the terms clients and data providers are used interchangeably here). The training starts at the very lowest network layer which is the layer closest to the data. Each layer reads either the data (from the first layer) or the output of the previous layer (all other layers).</p><p id="p-0053" num="0052">The layers can calculate their output (these are termed &#x201c;activations&#x201d; because they come from an activation function) based on any valid network architecture command (convolutions, dropouts, batch normalization, flatten layers, etc.) and activation function (relu, tanh, etc.). When the last layer on the data side <b>406</b>, <b>408</b>, <b>410</b> has calculated its appropriate activations (i.e., output) those outputs are sent to the first layer on &#x201c;the other side of the split&#x201d;&#x2014;the first layer on the server side <b>402</b>.</p><p id="p-0054" num="0053">The following approach involves splitting the model up as before. A model is split into two parts: (A) on the client side and includes the input layer, and (B) on the server side and often includes the output layer. (S) is the split layer. The clients or data providers <b>406</b>, <b>408</b>, <b>410</b> run independently and send back the answer if they have it. The code on the server <b>402</b> processes the data and sends back its output equally to all the clients as SB (<b>406</b>C, <b>408</b>C, <b>410</b>C).</p><p id="p-0055" num="0054">An example training process is as follows. The server <b>402</b> creates A and B and sends the portion A (<b>406</b>A, <b>408</b>A, <b>410</b>A) to the clients <b>406</b>, <b>408</b>, <b>410</b>. The following steps are repeated until a condition is met (e.g., accuracy). All the clients <b>406</b>, <b>408</b>, <b>410</b> do the forward step on A simultaneously. Up to this point, all the calculations on the clients <b>406</b>, <b>408</b>, <b>410</b>, are being done on independent servers and there is no dependency from one data server to the other. This approach highlights a one of the innovations disclosed herein. All these calculations by the clients/data providers <b>406</b>, <b>408</b>, <b>410</b> can all operate in parallel, at the same time. This is in contrast to the linear or &#x201c;round robin&#x201d; fashion discussed above.</p><p id="p-0056" num="0055">The clients <b>406</b>, <b>408</b>, <b>410</b> each run their portion A (<b>406</b>A, <b>408</b>A, <b>410</b>A) of the neural network and generate a respective output of A (i.e., SA (<b>406</b>B, <b>408</b>B, <b>410</b>B) and send the output to the server <b>402</b>. The server <b>402</b> receives 3 different &#x2018;versions&#x2019; of the activations (one from each of SA<b>1</b>, SA<b>2</b>, SA<b>3</b>). At this point, the server <b>402</b> processes those activations &#x201c;appropriately&#x201d;, which can mean that the server <b>402</b> does different operations depending on the case. For example, the server <b>402</b> calculates the loss value for each client <b>406</b>, <b>408</b>, <b>410</b> and the server <b>402</b> calculates the average loss across all clients. Another example includes the server <b>402</b> stacking all received sets of activations from each client <b>406</b>, <b>408</b>, <b>410</b>, generating a global single batch of activations, which is then used by the server <b>402</b> to calculate the average loss. The server <b>402</b> performs backpropagation using the average loss and calculates gradients at S. The server <b>402</b> performs backpropagation using the average loss and calculates gradients at S. The server <b>402</b> sends gradients at S (i.e., SB (<b>406</b>C, <b>408</b>C, <b>410</b>C)) to all the clients <b>406</b>, <b>408</b>, <b>410</b>.</p><p id="p-0057" num="0056">In other words, training on the server side <b>402</b> proceeds much like is described above. Once the first layer on the server side <b>402</b> is &#x201c;complete&#x201d; (either through averaging or aggregating what is received from the data providers <b>406</b>, <b>408</b>, <b>410</b>) forward propagation occurs until the &#x201c;top&#x201d; of the network is reached. An additional innovation described in this disclosure is in the management of the activations coming from the data providers <b>406</b>, <b>408</b>, <b>410</b> and how they get averaged, aggregated or some other treatment. Once the system arrives at the top of the model, the server <b>402</b> calculates the gradients necessary for back propagation, and sends them back down and across the split networks as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0058" num="0057">As noted above, the processing and the management of the activations by the server <b>402</b> can vary depending on different factors. For example, assume a case where all three data providers <b>406</b>, <b>408</b>, <b>410</b> are supplying the same data (X-rays). In that case, the data will be combined horizontally which can conceptually mean that the data is &#x201c;stacked&#x201d; one file on top of the other. In this case, the activations that come up will most likely be averaged. The &#x201c;average of each activation&#x201d; will then be sent forward into the &#x201c;top half&#x201d; of the network.</p><p id="p-0059" num="0058">In a different case, the data can be &#x201c;vertically&#x201d; stacked, so Client <b>1</b> <b>406</b> has the first 40 columns of data (say a blood test), Client <b>2</b> <b>408</b> has the next 60 columns of data (say an Electronic Health record that includes data such as age, weight, etc.) and Client <b>3</b> <b>410</b> has the last 100 columns of data (say insurance information&#x2014;previous claims, etc.). In this instance, the three clients can be considered as establishing a combined &#x201c;record&#x201d; of 200 columns (aggregated vertically across the page). In this case, the activations will be &#x201c;combined vertically&#x201d; and sent forward into the server network. This and other approaches to combining data can be implemented. Note that the multi-model artificial intelligence model described more fully below builds upon the concept just described with respect to combining vertically the activations. More details will be provided below on this concept.</p><p id="p-0060" num="0059">As noted above, the clients <b>406</b>, <b>408</b>,<b>410</b> run in parallel in this embodiment. This reduces the time it takes to train the model&#x2014;as all the processing is done in parallel. Further, this data is delivered over a particular platform. The applications incorporated above provide examples of the particular platform that can be used to deliver the data as disclosed herein. This will be discussed more below.</p><p id="p-0061" num="0060">A global model in federated-split learning can be aggregated as follows. After the training is done, the system uses on the following approach to aggregate a global model, which will be used for the inference task. In a first approach, the server selects one of the models, Ai, to be aggregated with its model, B, to form the global model. The selection of Ai could be achieved using one of the following ways. For example, random selection could be used where the server selects a model (Ai) of any client <b>406</b>, <b>408</b>, <b>410</b> randomly. This random selection might be influenced by other factors, such as the currently available clients online, the types of data each client processes (text data, image data, temporal data) or based on the transmission speed or network delay between the two entities. The server then stacks both parts Ai and B to generate the global model.</p><p id="p-0062" num="0061">In another example, a weighted client selection could be used. For this selection criteria, the server <b>402</b> assigns each client a weight (i.e., a numerical value) that reflects their importance based on their data, computational powers, and other valuable assets they possess and contribute during the training process. For example, a particular model set (say data for a certain language, data associated with a type of image, data associated with a patient set, or data from a particular country or region) could get weighted heavily in the model development. Thus, if a country is selected, then the client devices from that country can be weighted more heavily than clients from other countries. Japanese-based client devices can be used for 80% of the model data, for example. Australia could be 10% and Canada could be the other 10%. In another example, data from a certain clinic associated with an outbreak of the flu or COVID could be weighted more heavily. In yet another example, the type of data might be weighted more heavily as well. Image data may be used for 70% of a model, while textual data for 20% and temporal data for 10%.</p><p id="p-0063" num="0062">Yet another model could be an accuracy-based selection. In this case, the server <b>402</b> can test the accuracy generated from each client model Ai and then select the model that generates the &#x201c;best&#x201d; accuracy. The &#x201c;best&#x201d; can be identified by stakeholders, through a machine learning approach, or otherwise. These are all models of the first approach.</p><p id="p-0064" num="0063">A second approach can be where the global model is aggregated by averaging all clients' models Ai {1, N}. Each client first encrypts their model using homomorphic encryption and then sends the encrypted Ai&#x2032; data to the server <b>402</b>. The server <b>402</b> adds all the encrypted models, decrypts the addition results, and then calculates their average. The averaged A is then stacked with B to generate a global model. One approach could be a default approach, and optional approaches could be provided as well. The decryption processes and averaging process could also be spread between different servers, for example, with one process occurring on the client side and another process being performed by the server <b>402</b> to achieve the global model.</p><p id="p-0065" num="0064">The approaches may vary through the development of the model. For example, the model may begin to be trained using a default approach and then the training could be adjusted such that a weighted approach is used to complete the model training.</p><p id="p-0066" num="0065">A method example is shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and can include splitting up, at a server, a neural network into a first portion and a second portion (<b>502</b>), sending the second portion separately to a first client and a second client (<b>504</b>) and performing the following operations until a threshold is met:</p><p id="p-0067" num="0066">(1) performing, at the first client and the second client, a forward step on the second portion simultaneously to generate data SA<b>1</b> and SA<b>2</b>;</p><p id="p-0068" num="0067">(2) transmitting, from the first client and the second client, SA<b>1</b> and SA<b>2</b> to the server;</p><p id="p-0069" num="0068">(3) calculating, at the server, a loss value for the first client and the second client;</p><p id="p-0070" num="0069">(4) calculating, at the server, an average loss across the first client and the second client;</p><p id="p-0071" num="0070">(5) performing, at the server, backpropagation using the average loss and calculating gradients; and</p><p id="p-0072" num="0071">(6) sending, from the server, the gradients to the first client and the second client (<b>506</b>).</p><p id="p-0073" num="0072">A computing device or devices performing the above operations can also be covered as well as a computer-readable storage device storing instructions which, when executed, cause the processor to perform these operations. The operations can be performed in any order and the method can include one or more of the operations.</p><p id="p-0074" num="0073">In another aspect of this disclosure, the platforms described in the patent applications incorporated above can provide the basis for communicating data back and forth in any of the federated models. For example, each of the clients and/or the server as well may be required to be logged onto a platform or one of the versions of the platform referenced in the applications incorporated herein. Therefore, delivering this functionality over a platform or an exchange configured as disclosed in these applications is also covered as an aspect of this disclosure.</p><p id="p-0075" num="0074">In another aspect, a customer could choose SA, SB lines (vectors and numbers) which represent weights that need to be propagated. If a client wanted their data to be locked down without the server knowing anything about the data, that data can be homomorphically encrypted. The encryption process (which can include any encryption process) could be used in any approach disclosed above.</p><p id="p-0076" num="0075">The incorporated patent applications above provide example platforms that client devices and/or servers can log into or may be required to be logged into in order to perform the federated-split learning approach disclosed herein.</p><p id="p-0077" num="0076">It is noted that in one aspect, the steps disclosed herein can be practiced by a &#x201c;system.&#x201d; The system can include the server and one or more clients together, or might just be functionality performed by the server. The system could also be a client or a group of clients, such as clients in a particular geographic area or client groups in some manner that are performing the client-based functions disclosed herein. In one aspect, the &#x201c;server&#x201d; can also be a computing device (physical or virtual) on the server side as well as a computing device (physical or virtual) on the client side. In one example, a server can be on the client side and can receive back-propagation output of the respective client-side models Ai and can synchronize a client-side global model in a round of training.</p><p id="p-0078" num="0077">Thus, each of the server-side system and the client-side system can perform any one or more of the operations disclosed herein. Claims can be included which outline the steps that occur from the standpoint of any device disclosed herein. For example, the steps of transmission, calculation, and receiving of data can be claimed from the standpoint of a server device, a client device, or group of client devices depending on which embodiment is being covered. All such communication from the standpoint of an individual component or device can be included as within the scope of a particular embodiment focusing on that device.</p><p id="p-0079" num="0078">In another aspect, the system can include a platform as disclosed in the patent applications incorporated by reference also performing steps in coordination with the concept disclosed above. Therefore, the platform as used to provide the federated-split learning process described herein is also an embodiment of this disclosure and steps can be recited in connection with the use of that platform for training models in a manner that maintains privacy of the data as described herein.</p><p id="p-0080" num="0079">Typically, the training of a neural network is performed on similar data types. For example, a neural network trained to identify cancer by receiving a patient image or a kidney is trained on images of kidneys that are and are not cancerous. Next is discussed a new approach to training which uses different types of training data together to train a neural network, using the blind learning approaches disclosed herein.</p><heading id="h-0012" level="1">Multi-Model Artificial Intelligence Approach</heading><p id="p-0081" num="0080">As mentioned above, the MMAI innovation builds on the &#x201c;vertical aggregation&#x201d; idea described in an example of blind learning. The example related to all three clients <b>406</b>, <b>408</b>, <b>410</b> providing the same type of data&#x2014;either images (for stacking) or tabular data to be combined vertically. When the inventors were considering the vertical aggregation concept, they realized that this could be done with different types of data. For example, Client <b>1</b> could provide images, Client <b>2</b> could provide a blood test, and Client <b>3</b> could provide doctors textual notes. The significant difference is all of those data types require different network architectures. In this case, the developers of the system can't define one network and then let the server &#x201c;split&#x201d; it. Thus, part of the solution is to let the users define the network &#x201c;before the split&#x201d; for each data provider, and then define the network and aggregation technique on the server. This approach is illustrated in <figref idref="DRAWINGS">FIGS. <b>6</b>-<b>10</b></figref>.</p><p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates the multi-modal artificial intelligence (MMAI) platform or a machine leaning (ML) platform <b>600</b>. The MMAI approach reduces the computational requirements and communication overhead of other approaches. Additionally, the training speed is much faster and the process maintains a much higher privacy in the data, including the fact that the model stays private as well.</p><p id="p-0083" num="0082">The MMAI platform <b>600</b> applies AI/ML techniques to multiple data types in one large AI model. Typically, different data types require different AI network architectures to yield accurate results. Images, for example, typically require special filters (convolutions), whereas text or speech require different &#x201c;time series-like&#x201d; treatment, and tabular data frequently works best with ML or feed forward architectures. The issue is that images are best understood by looking at all of the pixels together and &#x201c;convoluting&#x201d; them in various ways, whereas speech is best understood in the context of what came before and/or after a certain sound (i.e. in a manner similar to time-series data), etc. Because of these differences in processing, &#x201c;state of the art&#x201d; systems today typically process one data type (i.e. images, text, speech, tabular, etc.).</p><p id="p-0084" num="0083">Most AI researchers recognize that breakthroughs in &#x201c;next generation&#x201d; accuracy can be achieved by adding more unique data to their models. This is essentially the equivalent to providing more data to the model to give it more context with which to discover interesting differences in cases. An example of this concept is a model that diagnoses Atrial Fibrillation (A-fib) by examining ECG (electro-cardiogram) data. The model can reach a certain level of accuracy based on the ECG data alone, but when the researchers add age, sex, height and weight to the ECG data, the model becomes far more accurate. The increase in accuracy is due to the four additional data types being able to help the model better understand what would otherwise look to the model like &#x201c;equivalent&#x201d; ECGs. Adding the four items or characterizations of the data can make the data more granular.</p><p id="p-0085" num="0084">The MMAI platform <b>600</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> introduces a new generation crypography toolset to improve the training and protection of private data. The MMAI platform <b>600</b> provides the model with more data than is typically used to train AI/ML models and expands on the data. The approach adds a significant amount of data by combining different data types&#x2014;i.e. images and tabular data, for instance.</p><p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a first outside source of data <b>602</b>, which is shown as Wells Fargo bank. The Wells Fargo data <b>602</b><i>a </i>is encrypted <b>602</b><i>b </i>and the package of encrypted data <b>602</b><i>c </i>is transmitted to a private AI infrastructure <b>603</b>. A second outside source of data <b>604</b> is shown as Citibank. The Citibank data <b>604</b><i>a </i>is encrypted <b>604</b><i>b </i>and the package of encrypted data <b>604</b><i>c </i>is transmitted to the private AI infrastructure <b>603</b>. A third outside source of data <b>606</b> is shown as from Bank of America. The Bank of America data <b>606</b><i>a </i>is encrypted <b>606</b><i>b </i>and the package of encrypted data <b>606</b><i>c </i>is transmitted to the private AI infrastructure <b>603</b>. The AI infrastructure <b>603</b> includes a first module <b>608</b> that will privately explore, select and preprocess all of the data <b>610</b> from the disparate sources <b>602</b>, <b>604</b>, <b>606</b>. In this example, all of the sources are identified as banks but they will have different structures for their data, and the respective data can be disparate as well. Of course, it is not a requirement that all of the outside sources <b>602</b>, <b>604</b>, <b>606</b> of data be of the same type, i.e., banks. The use of banks is just an example. The outside sources <b>602</b>, <b>604</b>, <b>606</b> could be, for example, a hospital, a clinic, a university, and so forth. The basic concept is that the data types can be different from the various different outside sources <b>602</b>, <b>604</b>, <b>606</b>.</p><p id="p-0087" num="0086">The private AI infrastructure <b>603</b> can include a component that privately explores, selects and preprocesses the relevant features from all of the data <b>602</b><i>c</i>, <b>604</b><i>c</i>, <b>606</b><i>c </i>it receives for training. Feature <b>612</b> represents the subset of the data <b>610</b> which can result from the processing of the component in the private AI infrastructure <b>603</b>. In operations <b>614</b>, <b>616</b>, the AI infrastructure <b>603</b> privately trains new deep and statistical models on the selected data <b>612</b> and in operation <b>618</b> will predict on any private and sensitive data, which can include images, video, text and/or other data types. The AI infrastructure <b>603</b> can then sell or grant access to the new models which is presented in operation <b>620</b>.</p><p id="p-0088" num="0087"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates another variation on the split learning technique <b>700</b>. This approach provides low compute requirements and low communication overhead to improve the training of models by using a blind decorrelation process for training based on disparate types of data. Building on the A-fib model example above, another source of even more data for the model would be to include a chest X-ray for each case the model considers. Unfortunately, the typical processing of the X-ray image is not consistent with the typical processing of the tabular ECG data. With a few minor engineering additions, the above-disclosed split-federated learning tool can be used to address this incompatibility problem. Namely, new instructions can be provided to the tool to allow different data types to process in the existing pipeline.</p><p id="p-0089" num="0088">In this case rather than an &#x201c;automatic&#x201d; split of the network architecture this variation on the idea allows the network architect (i.e. the data scientist developing the algorithm) to specify the specific network components desired for each data type. Each data type will need network architecture layers relevant to its data type (i.e. convolutional layers for images, Recurrent layers/Long Short Term Memory layers for speech, feed forward layers for tabular data, etc.). These disparate layers, each specific to the data type in question, will be specified such that they run on the &#x201c;data server&#x201d; side (almost like independent networks in and of themselves). The last layer of each &#x201c;independent network&#x201d; (per data type) will send it's activations &#x201c;across the split&#x201d; to the &#x201c;server side&#x201d;. The algorithm server side will have one consistent &#x201c;network&#x201d; that processes the incoming activations (from the data server side) appropriately. In some respects this approach is similar to an &#x201c;ensemble of networks&#x201d; (on the data server side) being aggregated into one final network on the algorithm server side (which ultimately produces the final &#x201c;answer&#x201d; from the &#x201c;ensemble&#x201d; of networks).</p><p id="p-0090" num="0089">Split learning is a collaborative deep learning technique, where a deep learning network or neural network (NN) can be split into two portions, a client-side network A and a server-side network B, as discussed above. The NN includes weights, bias, and hyperparameters. In <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the clients <b>702</b>, <b>704</b>, <b>706</b>, where the data reside, commit only to the client-side portion of the network, and the server <b>710</b> commits only to the server-side portion of the network. The client-side and server-side portions collectively form the full network NN.</p><p id="p-0091" num="0090">The training of the network is done by a sequence of distributed training processes. The forward propagation and the back-propagation can take place as follows. With the raw data, a client (say client <b>702</b>) trains the client-side network <b>702</b>A up to a certain layer of the network, which can be called the cut layer or the split layer, and sends the activations of the cut layer to the server <b>710</b>. The server <b>710</b> trains the remaining layers of the NN with the activations that it received from the client <b>702</b>. This completes a single forward propagation step. A similar process occurs in parallel for the second client <b>704</b> and its client-side network <b>704</b>A and its data and generated activations which are transmitted to the server <b>710</b>. A further similar process occurs in parallel for the third client <b>706</b> and its client side network <b>706</b>A and its data and generated activations which are transmitted to the server <b>710</b>.</p><p id="p-0092" num="0091">Next, the server <b>710</b> carries out the back-propagation up to the cut layer and sends the gradients of the activations to the respective clients <b>702</b>, <b>704</b>, <b>706</b>. With the gradients, each respective client <b>702</b>, <b>704</b>, <b>706</b> performs back-propagation on the remaining network <b>702</b>A, <b>704</b>A, <b>706</b>A. This completes a single pass of the back-propagation between a client <b>702</b>, <b>704</b>, <b>706</b> and the server <b>710</b>.</p><p id="p-0093" num="0092">This process of forward propagation and back-propagation continues until the network gets trained with all the available clients <b>702</b>, <b>704</b>, <b>706</b> and reaches its convergence. In split learning, the architectural configurations are assumed to be conducted by a trusted party that has direct access to the main server <b>710</b>. This authorized party selects the ML model (based on the application) and network splitting (finding the cut layer) at the beginning of the learning.</p><p id="p-0094" num="0093">As noted above, a concept introduced in this disclosure relates to the clients <b>702</b>, <b>704</b>, <b>706</b> each providing a different type of data but also where the different types of data have a common association. Thus, the selection of the machine learning model can be based on the types of data that are being processed on the client side, and the process of finding the cut layer can also depend on what types of data or the disparity in the different types of data. For example, for widely disparate data types across the clients <b>702</b>, <b>704</b>, <b>706</b>, the cut layer may be chosen to have more or less layers on the client-side networks <b>702</b>A, <b>704</b>A, <b>706</b>A. In another aspect, the number of layers before the cut layer or split layer may vary across clients. Client <b>702</b> may be processing images and require 8 layers before the cut layer, while client <b>704</b> may process text and only need 4 layers before the cut layer. In this regard, as long as the vectors, activations or activation layer at the cut layer is consistent across the different clients <b>702</b>, <b>704</b>, <b>706</b> having different types of data, there is no requirement that the number of layers at the client-side networks <b>702</b>A, <b>704</b>A, <b>706</b>A be the same.</p><p id="p-0095" num="0094">The synchronization of the learning process with multiple clients <b>702</b>, <b>704</b>, <b>706</b> can be done either in centralized mode or peer-to-peer mode. In the centralized mode, before starting training with the server <b>710</b>, a client <b>702</b>, <b>704</b>, <b>706</b> updates its client-side model <b>702</b>A, <b>704</b>A, <b>706</b>A by downloading the model parameters from a trusted third-party server <b>710</b>, which retains the updated client-side model uploaded by the last trained client. On the other hand, in peer-to-peer mode, the client <b>702</b>, <b>704</b>, <b>706</b> updates its client-side model by directly downloading it from the last trained client. As noted above, previously-trained models may have a data type similarity to a current client that needs to update its model. For example, the similarity may be based on the data be images, textual data, speech data, video data, temporal data, and so forth. Thus, there may be an intelligent selection of which previously-trained client model to use to download from a peer. The processing by the server <b>710</b> can also be split in some cases between some processing on the server side and other processing at a federated server on the client side.</p><p id="p-0096" num="0095">As introduced above, client one <b>702</b>, client two <b>704</b> and client three <b>706</b> could have different data types. The server <b>710</b> will create two parts of the network and sends one part <b>702</b>A, <b>704</b>A, <b>706</b>A to all the clients <b>702</b>, <b>704</b>, <b>706</b>. The system repeats certain steps until an accuracy condition or other condition is met, such as all the clients sending data to the part of the network that they have, and sends the output to the server <b>710</b>. The server <b>710</b> calculates the loss value for each client and the average loss across all the clients. The server <b>710</b> can update its model using a weighted average of the gradients that it computes during back-propagation and sends the gradients back to all the clients <b>702</b>, <b>704</b>, <b>706</b>. The clients <b>702</b>, <b>704</b>, <b>706</b> receives the gradients from the server <b>710</b> and each client <b>702</b>, <b>704</b>, <b>706</b> performs the back-propagation on their client-side network <b>702</b>A, <b>704</b>A, <b>706</b>A and computes the respective gradients for each client-side-network <b>702</b>A, <b>704</b>A, <b>706</b>A. The respective gradients from the client-side networks <b>702</b>A, <b>704</b>A, <b>706</b>A can then be transmitted back to the server <b>710</b> which conducts an averaging of the client-side updates and sends the global result back to all the clients <b>702</b>, <b>704</b>, <b>706</b>.</p><p id="p-0097" num="0096">It is noted that the server <b>710</b> functionality can be also broken into several servers that each perform the different operations (such as updating its model by one server and averaging the local client updates by another server, each located in different areas). In the case of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the clients <b>702</b>, <b>704</b>, <b>706</b> all process disparate types of data which normally would or could not be processed to develop an AI model.</p><p id="p-0098" num="0097">For example purposes, the A-fib model from above can be used to illustrate the process. Client one <b>702</b> could have ECG data, client two <b>704</b> could have X-ray data, and client three <b>706</b> could have genetic data. Client one <b>702</b>, for example, could be a hospital, client two <b>704</b> could be a medical diagnostics imaging company and client three <b>706</b> could be a bank or financial institution, in a manner depicted in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. One of the clients could also have time-based data such as progressive information about the patient relative to weekly visits to the hospital for checkups.</p><p id="p-0099" num="0098">The approach shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates how the system can implement new user instructions that allow a user to bring different data types together with the &#x201c;correct&#x201d; processing before the split or cut layer or as shown in the blind decorrelation block <b>708</b>. Each of those parts of the model can be independent, and will operate independently. In one aspect, the processing performed by the blind decorrelation block <b>708</b> will result in an activation layer or activations that are transferred to the server <b>710</b>. This approach is similar to the approach described above with the addition of the differences in data type amongst the clients <b>702</b>, <b>704</b>, <b>706</b>.</p><p id="p-0100" num="0099">The server <b>710</b> will combine those activation layers in one of a multitude of ways. The server <b>710</b> can average them (which is also described above), but it could also concatenate them into one long activation layer. In another aspect, the server <b>710</b> could apply any mathematical function to achieve the desired combination of the activation layers. The server <b>710</b> can then process the combined activation layers further using any appropriate network architecture. In one aspect, a server on the client side can receive gradients and average the gradients to generate a global model of the various clients <b>702</b>, <b>704</b>, <b>706</b> and send the global model to the server <b>710</b> for concatenation or for further processing.</p><p id="p-0101" num="0100">The ideas shown in <figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b></figref> represent an expansion and application of the split-federated learning tool set and provides a platform of off-the-shelf tools to bring disparate data types together into a superset AI model. The processing can be done all privately and the offering can also be included in a marketplace as described in the incorporated patent applications referenced above.</p><p id="p-0102" num="0101">Not only can the system combine different data types, but the system can also combine different AI/ML techniques. For example, client one <b>702</b> can be a CNN (convolutional neural network), client two <b>704</b> can be an ML routine (i.e. XGBoost), and client <b>3</b> <b>706</b> can apply a different technique as well. In this regard, although the different AI/ML techniques are different, as long as the resulting data at the cut layer is consistent and properly configured, the forward propagation and back propagation can occur and the models can be trained.</p><p id="p-0103" num="0102">In order to assist one of skill in the art to understand how the MMAI approach might work, the following is an example of actual commands per data type coming from the three data providers <b>702</b>, <b>704</b>, <b>706</b>. This code uses the python numbering convention so it starts with builder0 (tabular data from data provider <b>1</b> <b>702</b>). Builder1 in this example is for a CT Scan or image data. The commands would be similar for Xray, MRI, and/or any other picture. Builder2 (from data provider <b>704</b>) is text data. Note the &#x201c;lstm&#x201d; command, which is short for &#x201c;long/short term memory&#x201d;. The &#x201c;server&#x201d; builder commands define the network that aggregates the other three at the &#x201c;top&#x201d; on the other side of the split.</p><p id="p-0104" num="0000">builder0=tb.NetworkBuilder( )<br/>builder0.add_dense_layer(100, 120)<br/>builder0.add_relu( )<br/>builder0.add_dense_layer(120, 160)<br/>builder0.add_relu( )<br/>builder0.add_dropout(0.25)<br/>builder0.add_dense_layer(160, 200)<br/>builder0.add_relu( )<br/>builder0.add_split( )<br/>builder1=tb.NetworkBuilder( )<br/>builder1.add_conv2d_layer(1, 32, 3, 1)<br/>builder1. add_batchnorm2d(32)<br/>builder1.add_relu( )<br/>builder1.add_max_pool2d_layer(2, 2)<br/>builder1.add_conv2d_layer(32, 64, 3, 1)<br/>builder1. add_batchnorm2d(64)<br/>builder1.add_relu( )<br/>builder1.add_max_pool2d_layer(2, 2)<br/>builder1.add_flatten_layer( )<br/>builder1.add_split( )<br/>builder2=tb.NetworkBuilder( )<br/>builder2.add_lstm_layer(39, 100, batch_first=True)<br/>builder2.add_dense_layer(100, 39)<br/>builder2.add_split( )<br/>server_builder=tb.NetworkBuilder( )<br/>server_builder.add_dense_layer(60000, 8000),<br/>server_builder.add_relu( )<br/>server_builder.add_dense_layer(8000, 1000),<br/>server_builder.add_relu( )<br/>server_builder.add_dense_layer(1000, 128),<br/>server_builder.add_relu( )<br/>server_builder.add_dense_layer(128, 1)</p><p id="p-0105" num="0103"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrate an example method <b>800</b> for providing a MMAI concept from the standpoint of the clients. The method includes receiving a first set of data from a first data source, the first set of data having a first data type (<b>802</b>), training a first client-side network on the first set of data and generating first activations (<b>804</b>), receiving a second set of data from a second data source, the second set of data having a second data type (<b>806</b>) and training a second client-side network on the second set of data and generating second activations (<b>808</b>).</p><p id="p-0106" num="0104">The method can further include transmitting the first activations and the second activations to a server-side network, wherein the server-side network is trained based on the first activations and the second activations to generate gradients (<b>810</b>), and receiving the gradients at the first client-side network and the second client-side network (<b>812</b>). The first data type and the second data type can be different data types, such as one being image-based and the other being textual or temporally based as in speech.</p><p id="p-0107" num="0105"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an example method <b>900</b> from the standpoint of both a server <b>710</b> and one or more clients <b>702</b>, <b>704</b>, <b>706</b>. The method can include splitting a neural network into a first client-side network, a second client-side network and a server-side network (<b>902</b>), sending the first client-side network to a first client, wherein the first client-side network is configured to process first data from the first client, the first data having a first type and wherein the first client-side network can include at least one first client-side layer (<b>904</b>), and sending the second client-side network to a second client, wherein the second client-side network is configured to process second data from the second client, the second data having a second type and wherein the second client-side network can include at least one second client-side layer, wherein the first type and the second type have a common association (<b>906</b>).</p><p id="p-0108" num="0106">The method can further include training the first client-side network on first data from the first client and generating first activations (<b>908</b>), transmitting the first activations from the first client-side network to the server-side network (<b>910</b>), training the second client-side network on second data from the second client and generating second activations (<b>912</b>), transmitting the second activations from the second client-side network to the server-side network (<b>914</b>), training at least one server-side layer of the server-side network based on the first activations and the second activations to generate gradients (<b>916</b>) and transmitting the gradients from the server-side network to the first client-side network and the second client-side network (<b>918</b>).</p><p id="p-0109" num="0107">The common association between the disparate types of data can include at least one of a device, a person, a consumer, a patient, a business, a concept, a medical condition, a group of people, a process, a product and/or a service. Any concept, device or person can be the common association or theme of the various disparate types of data that come from different clients and that are processed by different and independent client-side networks up to a cut or split layer. The server-side network can include a global machine learning model. The neural network can include weights, bias and hyperparameters. Hyperparameters typically relate to a parameter whose value is used to control the learning process, such as a topology parameter or a size of a neural network. For example, a learning rate, a mini-batch size, a number of layers on client side, or any parameter related to controlling the process that might impact or relate to different data types can represent a hyperparameter.</p><p id="p-0110" num="0108">The at least one first client-side layer and the at least one second client-side layer each can include a same number of layers or a different number of layers. Because they operate independently, the client-side networks can have a different number of layers as long as they process their data to generate vectors or activations that are in a proper format for passing on to the server-side network for further training. A cut layer can exist between the server-side network and the first client-side network and the second client-side network.</p><p id="p-0111" num="0109"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates an example method <b>1000</b> from the standpoint of the server <b>710</b>. A method can include splitting a neural network into a first client-side network, a second client-side network and a server-side network (<b>1002</b>), sending the first client-side network to a first client, wherein the first client-side network is configured to process first data from the first client, the first data having a first type and wherein the first client-side network can include at least one first client-side layer (<b>1004</b>) and sending the second client-side network to a second client, wherein the second client-side network is configured to process second data from the second client, the second data having a second type and wherein the second client-side network can include at least one second client-side layer, wherein the first type and the second type have a common association (<b>1006</b>).</p><p id="p-0112" num="0110">The method can further include receiving, at the server-side network, first activations from a training of the first client-side network on first data from the first client (<b>1008</b>), receiving, at the server-side network, second activations from a training of the second client-side network on second data from the second client (<b>1010</b>), training at least one server-side layer of the server-side network based on the first activations and the second activations to generate gradients (<b>1012</b>) and transmitting the gradients from the server-side network to the first client-side network and the second client-side network (<b>1014</b>).</p><p id="p-0113" num="0111">Note that in each case, part of the process of the server <b>710</b> in terms of training could be perform by the server <b>710</b> and other parts such as an averaging of values over the various clients could be performed by a different server (not shown) that could be at a client site, a separate location, or across different clients.</p><p id="p-0114" num="0112">This approach enables the use of the federated split-learning tool set in a new way that when the system splits up the neural network, at the blind decorrelation <b>708</b>, the system can make it harder to take the resulting trained model, break it and apply a training inference attack. Because the system can break the neural network in half (or in two portions), and the way it is described above, all that is exchanged from the neural network parts <b>702</b>A, <b>704</b>A, <b>706</b>A is a string or array of numbers, also described as activation layer numbers. Since these are only numbers or an array of characters, what happens at a first neural network portion <b>702</b>A could be different from what happens at a second neural network portion <b>704</b>A. For example, the first neural network portion <b>702</b>A could be 2 layers deep and the second neural network portion <b>704</b>A could be 90 layers deep. As long as each output resolves to a string of numbers that is structured appropriately for transmission to the top part of the neural network <b>710</b>, then the forward propagation and the back propagation can work and the training can be achieved. This understanding paves the way for a new concept disclosed herein that different types of data handled across the different portions <b>702</b>A, <b>704</b>A, <b>706</b>A of the neural network can be received and processed properly to train the models( ). If the system can create a different bottom half <b>702</b>A, <b>704</b>A, <b>706</b>A for each of different clients, then the clients <b>702</b>, <b>704</b>, <b>706</b> don't have to produce or process the same type of data (between text and images, for example), but the properly formatted neural network portions <b>702</b>A, <b>704</b>A, <b>706</b>A can process that disparate data, and produce the structured output that can be sent to the server <b>710</b>.</p><p id="p-0115" num="0113">In one example, client one <b>702</b> might provide a person's ECG, client two <b>704</b> can provide a chest X-ray of a heart can client three <b>706</b> can provide the genetic profile of the most four interesting proteins in the patient's blood. If the neural network portions <b>702</b>A, <b>704</b>A, <b>706</b>A can process the different respective types of data down to the right vector structure for output, and provide the disparate types of data to the server <b>710</b>, the server <b>710</b> can be configured with the proper neural network to combine all of that information to train a model to be used to make a diagnosis which can utilize the different and disparate types of data.</p><p id="p-0116" num="0114">In one aspect, while the neural network portions <b>702</b>A, <b>704</b>A, <b>706</b>A each process a different type of data, there is some correlating factor associated with the data. In the above example, all of the data may relate generally to the same person, although some data is ECG related and other data is associated with a genetic profile, yet they all are for the same person. Thus, one aspect of this disclosure is that the data does have a common association. In another aspect, the data may not be related to the same person but the common association could be related to an age, gender, race, project, concept, the weather, the stock market, or other factors. All of the data might relate to women between the ages of 30-35, for example. Thus, the common association has some flexibility to how it would be applied.</p><p id="p-0117" num="0115">In another example, the data could be images from a camera of a jet engine stream, another stream of data could be sensor data, and other data could be flight characteristics from an airplane, and the common association could be the airplane. In another aspect, the common association could be a consumer with one type of data being purchasing habits, another type of data being web-surfing patterns, another type of data being emails that the user sends, another type of data being audio from Siri or other speech processing tools, and another type of data being what physical stores the consumer frequents or what is the user's current location. The output of the server could be an advertisement to provide to the user based on the analysis of the disparate types of input. Thus, the common association can relate to any concept that could be used in which disparate types of data can relate to the concept.</p><p id="p-0118" num="0116">A detailed example of how the process of obtaining &#x201c;shares&#x201d; of individual private data and then sharing that data between parties is explained with respect to <figref idref="DRAWINGS">FIGS. <b>11</b>-<b>13</b></figref>. The use of shares is part of the approach disclosed herein with respect to averaging the models and thus is important to understand. <figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates a framework <b>1100</b> in which a first party <b>1102</b> has example data L<sub>1</sub>=[1, 5, 6, 10], a second party <b>1104</b> has a respective list of data L<sub>2</sub>=[7, 0, 100] and a third party <b>106</b> has its private data L<sub>3</sub>=[3, 4, 550]. In one example, the various respective lists of data are stored on computer-readable media on various computer systems. Each of the components <b>1102</b>, <b>1104</b>, <b>1106</b> can represent the respective computer system of the respective party. The component <b>1108</b> can represent the shared list which includes each combined list of data from the respective parties <b>1102</b>, <b>1104</b>, <b>1106</b>. Again, the respective lists can be shared over any type of network such as the Internet or a wireless network, cellular network and so forth.</p><p id="p-0119" num="0117">Each party contributed their private lists of data to a combined list of data Si. Si=[0, 1, 3, 4, 5, 6, 7, 20, 100, 550]. Again, in one aspect, this is only in theory and the parties never actually share their data at a location that combined the various lists together. This figure therefore is used to show conceptually how the combined list might exist logically but not physically. The combined list in other words is the combination of the various lists that physically remain private on the computer systems of the various parties. The output of the solution disclosed herein is the Nth smallest value.</p><p id="p-0120" num="0118">The number of participants can be termed &#x201c;m&#x201d; and 1&#x2264;i&#x2264;m. The total numbers in the combined list Si is S=s1+ . . . +sn. The algorithm disclosed herein enables the various parties to securely compute the Nth value of the combined list Si. Note that the approach could be used a number of different times to find various Nth values. Also note that in this example, the data is numerical although in other aspects the data might not be numerical or might be a combination of numerical data and non-numerical data.</p><p id="p-0121" num="0119">Next, several examples shall be provided of the algorithm in practice. Assume in one example that there are the three parties shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref> with data: L1=[1, 5, 6, 10], L2=[7, 0, 100] and L3=[3, 4, 550]. The sorted combined list is S<sub>i</sub>=[0, 1, 3, 4, 5, 6, 7, 20, 100, 550]. An unsorted list can be W=[1, 5, 6, 20, 7, 01, 100, 3, 4, 550]. The goal is to determine or compute the Nth value in the combined list. Note that the list, if it were sorted as in S<sub>i </sub>above, that the third position, for example, would have a value of 3. In the example, we'll assume that the goal is to find the value in the third position. The value of N can be set by the participants or in some other fashion.</p><p id="p-0122" num="0120">The value of m is the number of participants which is 3 in this case. The value sj is the number of data in the list belonging to a user j. For example, user 1 has a sj value of 4 and the other two users have a sj value of 3. The value S is the total number of the data s1+s2+ . . . +2m, which in this case is 10.</p><p id="p-0123" num="0121">The SMPC (secure multi-party computation) protocol disclosed herein is equipped with SecureMult and SecureCompare on Ring R. An example of such protocols is found in U.S. patent application Ser. No. 16/828,216, filed on Mar. 24, 2020. The contents of this application are incorporated herein by reference. These are multi-party primitives enabling parties to perform multiplication and comparison securely as would be known by one of skill in the art. A ring is a set equipped with two binary operations and which prevents values from becoming too large. A ring is a set R equipped as noted above with two binary operations which can be + (addition) and * (multiplication) satisfying three sets of axioms called ring axioms. First, R is an abelian group under addition that has a number of requirements. Next, R is a monoid under multiplication with several requirements and third, the multiplication is distributive with respect to addition with several distributivity requirements. One of skill in the art will understand more of the ring structure in math.</p><p id="p-0124" num="0122">In this example Ring R=[Z]264. This means that all the integers from 0 to 264 in the ring. The modulus of the ring is 264. In this example, the maximum value of the ring is 264 and if a number goes above 264, it gets wrapped around and starts over at 1. For example, if the modulus is 7, and a number being processed by the ring results in 11 (such as 5+6), the value would not be 11 because the maximum value of the ring is 7, but the number of would be 4. The reasons for the use of the Ring is to prevent the use of unlimited or infinite numbers when performing the operations disclosed herein.</p><p id="p-0125" num="0123">The protocol or algorithm includes performing a loop of steps until the loop ends on step (5). The first (1) step involves one of the parties creating m additive shares (m&#x2212;1 shares for other users and 1 for themselves) from their list and distributing them among the other users and themselves. The goal of step (1) is to generate three sets of shares W1, W2, W3 of the set W used for the rest of the process to enable the parties to compute the Nth smallest value of the combined list securely.</p><p id="p-0126" num="0124">To do so, user number i, for each element A in their respective list, generates m&#x2212;1 random numbers r1, . . . , ri&#x2212;1, ri+1, . . . , rm&#x2212;1 (from the Ring) and distributes them between the other parties and sets their own share: ri=A&#x2212;r1&#x2212;r2&#x2212; . . . &#x2212;ri&#x2212;1&#x2212;ri+1 . . . &#x2212;rm&#x2212;1.</p><p id="p-0127" num="0125">Note that in step (1), each party computes their additive shares for each value A in their respective lists and shares the (m&#x2212;1) additive shares (one share of the group of additive shares) to the other parties and computes their own additive share for their own value in the propose position.</p><p id="p-0128" num="0126">This setup is needed to use the SMPC PROTOCOL which uses both the SecureMult and SecureCompare algorithms. See the patent application incorporated above by reference for data on the SecureCompare algorithm and how it works in practice.</p><p id="p-0129" num="0127">In the above example, party 2 has [7, 0, 100]. For each number in the list (say 7 for party 2), the respective party generates 2 random numbers (say 5, &#x2212;2) and sends r1=5 to party 1 and sends r3=&#x2212;2 to party 3 and sets his own share r2=7&#x2212;5&#x2212;(&#x2212;2)=4. If the system adds 5, &#x2212;2 and 4, the result is 7 and that's why this is called additive sharing. This process will be repeated for all numbers in the list. Each party gets only one share of the original value (7). The end of this process, for the one value 7 for the first party, each party's share will be as follows: Part 1 share: 5; Party 2 share: 4; Party 3 share: &#x2212;2. For each number in each list, each party gets one number as a &#x201c;share&#x201d; of that number. If the system repeats the process for all numbers in all lists, each party will end up with S=s1+s2+ . . . +sm shares. S=10 in this example.</p><p id="p-0130" num="0128">In one example, here could be an example of the sets of shares each party would have. If these lists are added, the W=[1, 5, 6, 20, 7, 0, 100, 3, 4, 550] would be obtained:</p><heading id="h-0013" level="2">W<sub>1</sub>=[3, 0, 2, &#x2212;3, 4, 5, 50, 12, 8, 214]</heading><heading id="h-0014" level="2">W<sub>2</sub>=[&#x2212;4, 7, 3, 14, 6, 4, 35, &#x2212;9, 2, 150]</heading><heading id="h-0015" level="2">W<sub>3</sub>=[2, &#x2212;2, 1, 9, &#x2212;10, &#x2212;2, 15, 0, &#x2212;6, 186]</heading><p id="p-0131" num="0129">Note how for each position, if all the numbers are added, the appropriate value of W is obtained. Such as position 3, in which 2+3+1=6. Each party only has access to the respective list of shares which hides the values of the data from the other parties.</p><p id="p-0132" num="0130">Next in step (2), each party gets a share of a one-hot-code vector V of size S created by a trusted party. The goal of step (2) is to generate three sets of shares V1, V2, V3 associated with a hot-code vector V. Another goal is to select one of the numbers in the list randomly without letting the parties know which number that was selected. In other words, the goal is to select one number from the list of 10 numbers randomly but not tell the party which number they are evaluating. Each party has 10 numbers in their share of the combined list.</p><p id="p-0133" num="0131">The trusted party can have a computer system that performs the operations disclosed herein with the proper security and structure and management to consider being a trusted party. A hot-code vector is a vector consisting of only 0's and a 1 in which there is only a single &#x201c;1&#x201d; in the vector with all the other values being zero. In one example, V=[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]. In this example, it is the 6th position in the set of 10 values that is selected. However, how the system selects this number without telling the partis which value is being evaluated. Note that each of these 0's and the 1 is an additive share as defined above. For example, the system can generate randomly three sets of numbers:</p><heading id="h-0016" level="2">V<sub>1</sub>=[3, 4, 5, . . . ]</heading><heading id="h-0017" level="2">V<sub>2</sub>=[&#x2212;4, &#x2212;4, 3, . . . ]</heading><heading id="h-0018" level="2">V<sub>3</sub>=[1, 0, &#x2212;8, . . . ].</heading><p id="p-0134" num="0132">The three parties will each get one of the randomly-generated set of numbers V1, V2, V3. The use of these three sets of numbers hides the selected number (the 6th position of V). Note that in the first position, the three shares (3, &#x2212;4, 1) add up to zero. The second position of the various V1, V2, V3 sets of numbers includes (4, &#x2212;4, 0) which adds up to zero, the third position adds up to zero as well (5+3&#x2212;8) and so forth. The sixth position of V has the &#x201c;1&#x201d; and the three shares in that case would add up to 1. Each of these sets of numbers is a respective V set. In step (3), each party, with their respective Vi set of numbers computes Ri=Sum(SecureMult(Wi,Vi)). For example, if W1=[3, 0, 2, &#x2212;3, 4, 5, 50, 12, 8, 214] and V1=[3, 4, 5, 3, &#x2212;2, 9, 3, 8, 3, &#x2212;4], then the sum of the secure multiplication of W1 and V1 (W1*V1) is 3*3+0*4+2*5+(&#x2212;3)*3+ . . . 214*(4)=R1. Assume in this example that R1=9, R2=17 and R3=&#x2212;6. These represent a share of a randomly selected number from the sets. There may be more details about how this secure multi-party multiplication operates to obtain these values but at a high level this is how it works. If you add these three numbers (9, 17 and &#x2212;6), the result is 20.</p><p id="p-0135" num="0133">Note that from the original W=[1, 5, 6, 20, 7, 0, 100, 3, 4, 550], the value of 20 is the in the 8th position of this list or the 8th smallest value. Each party then has a &#x201c;share&#x201d; at the end of step (3) of the 8th smallest value in the list or the number 20. None of the parties knows the number 20 but have shares of the number 20.</p><p id="p-0136" num="0134">Note as well that if V=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0] then the actual sum of the secure multiplication of V with W would be [0, 0, 0, 20, 0, 0, 0, 0, 0, 0], or 0+0+0+20+0 . . . +0=20. Neither the system nor the parties do this computation as they only have shares of W and V.</p><p id="p-0137" num="0135">Next, step (4) involves running the SecureCompare protocol on Ri and Wi to find the position of Ri in Wi. The parties get a set of V1, V2, V3 or shares of V as part of the SecureCompare protocol.</p><p id="p-0138" num="0136">Each party runs the SecureCompare (Ri, Wi) protocol and gets one share of the final result. The protocol returns the comparison result in &#x201c;real space&#x201d;.</p><p id="p-0139" num="0137">In step (5), if N=Pi+1 the protocol stops and returns Ri. In this case, N, the position the parties are trying to determine, is 3 and thus N does not equal 8 and the protocol is not ready to end but moves on to step (6).</p><p id="p-0140" num="0138">Step (6) involves determining if N&#x3e;Pi+1, which it is not. If it was, the system would remove all numbers smaller than Ri from their shares of W (or their Wi set) and set N=N&#x2212;(Pi+1). The process would then loop back to step (2) with the smaller number of shares in the respective Wi list.</p><p id="p-0141" num="0139">In step (7), if N&#x3c;Pi+1, then the system removes all number bigger than or equal to Ri (8) from their shares of W and then returns to step (2). In this case, since 3 is less than 8, for party 1, the new W1 becomes [3, 0, 2, &#x2212;3, 4, 5, 8] with 50, 12, 214 being removed.</p><p id="p-0142" num="0140">Then, with the new W1, the system now has 7 values in this set and once the steps are performed by each of the three parties, the process starts returns to step (2) with a new set of W1, W2, W3.</p><p id="p-0143" num="0141"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates an example method <b>1200</b> embodiment related to the use of shares to determine an Nth smallest value. The method <b>1200</b> enables separate parties to compute securely an Nth smallest value in a combined list of values from m number of parties W. In one example, the method is performed across multiple computing devices (an example of which is in <figref idref="DRAWINGS">FIG. <b>15</b></figref>) in that each party has their own secure computing systems and share data with each other but then perform the computations and comparisons securely on their own systems with the data they receive.</p><p id="p-0144" num="0142">The method <b>1200</b> can include (1) creating, by each party of the m parties, m additive shares for each value in a respective list of values for each party of the m parties to yield m lists of additive shares for each party of the m parties (<b>1202</b>), (2) distributing, from each party of the m parties, m&#x2212;1 lists of additive shares from the m lists of additive shares for each party by distributing one of the m&#x2212;1 lists of additive shares to each other party of the m parties to yield a respective combined list of shares Wi having S values for each of the m parties, wherein S equals the total number of values in the combined list of values from the m parties (<b>1204</b>), (3) receiving, from a trusted party and by each of the m parties, a respective list of additive shares Vi associated with a hot-code vector V comprising a value of 1 randomly assigned a position in V and the rest of the values being 0 (<b>1206</b>), (4) computing, by each party of the m parties and via a SecureMult protocol, Ri=Sum(SecureMult(Wi,Vi,) (<b>1208</b>), (5) applying a comparison protocol to compare, by each party of the m parties, R against all elements in W, such that each party learns a total number of values in W that are smaller than R as a value Pi, where Pi is one share of the total number of values in W that are smaller than R and after combining all Pi values, all parties learn P, wherein a position or R in W is equal to P+1 (<b>1210</b>), (6) when N=P+1, returning, from each party, a value Ri and concluding the method (<b>212</b>), (7) when N&#x3e;P+1, removing, by each party, all numbers smaller than Ri (and Ri as well) from each party's Wi and setting N=N&#x2212;(P+1) to yield a new Wi and new N (<b>1214</b>), (8) when N&#x3c;P+1, removing, by each party, all numbers bigger than Ri (and Ri as well) from Wi to yield anew Wi (<b>1216</b>) and (9) returning to an earlier step such as step (3) (<b>1218</b>). Other secure multiplication and comparison protocols can be used as well other than those listed above for the parties to be able to compute the data they need in a secure way.</p><p id="p-0145" num="0143">The hot-code vector V has a number of values equal to S. This number of values S can change as the method iterates because the respective values of Wi are reduced in iterations which don't end in step (6). In step (7) the respective Wi is reduced where all numbers smaller or equal to Ri are removed and in step (8) it's all numbers bigger than or equal to Ri are removed from Wi. As these operations are performed in the shared space, it is each party operating on their &#x201c;additive shares&#x201d; that they received from the other parties and not on the actual raw data. This can be in contrast to &#x201c;real space&#x201d; in which the parties are operating on the real data and not additional shares of the data.</p><p id="p-0146" num="0144">The comparison protocol can be the SecureCompare protocol as discussed above. The method can loop or iterate from step (9) to step (3) until N=Pi+1. At that point, the method is done and the value of Ri is returned to the other parties or each respective party knows the value of Ri. Because each party operates in the &#x201c;shared space&#x201d; where they are operating on lists of numbers that are &#x201c;shares&#x201d; of the actual raw data, each party does not know what numbers are being compared. An owner of a value in the combined list only learns in the end that the value in the combined list W is smaller or bigger than a number the owner of the value does not know from the combined list W. The SecureMult protocol and the SecureCompare protocol operate on a Ring R set equipped with two binary operations. In one example, the Ring R=[Z]264 but other values of the modulus <b>264</b> can also be used as needed depending on the application of the method. The SecureMult protocol and the SecureCompare protocol include multi-party computation primitives enabling each party to perform multiplication and comparison securely.</p><p id="p-0147" num="0145">In another example, each party will have a secure and separate computer server or system. The operations disclosed herein can also be considered from the standpoint of each party's computer and what operations are just performed at that location. A system in this regard can be used for enabling separate parties to compute securely an Nth smallest value in a combined list of values from m number of parties W, the system being operated by one of the parties of the m parties. The system can include a processor and a computer-readable storage device storing instructions which, when executed by the processor, cause the processor to perform operations including (1) creating m additive shares for each value in a respective list of values for each party of the m parties to yield m lists of additive shares for each party of the m parties, (2) distributing m&#x2212;1 lists of additive shares from the m lists of additive shares for each party by distributing one of the m&#x2212;1 lists of additive shares to each other party of the m parties to yield a respective combined list of shares Wi having S values for each of the m parties, wherein S equals the total number of values in the combined list of values from the m parties, (3) receiving, from a trusted party, a respective list of additive shares Vi associated with a hot-code vector V comprising a value of 1 randomly assigned a position in V and the rest of the values being 0, (4) computing, via a SecureMult protocol, Ri=Sum(SecureMult(Wi,Vi), (5) applying a comparison protocol to compare R against all elements in W, to learn a total number of values in Wi that are smaller than Ri as a value Pi, wherein Pi values add to equal P and wherein a position or Ri in Wi is equal to Pi+1, (6) when N=P+1, returning a value Ri and concluding the operations, (7) when N&#x3e;P+1, removing all numbers smaller than Ri (and Ri as well) from each party's Wi and setting N=N&#x2212;(P+1) to yield a new Wi and new N, (8) when N&#x3c;P+1, removing all numbers bigger than or equal to Ri from Wi to yield a new Wi and (9) returning to an earlier step such as step (3).</p><p id="p-0148" num="0146">Another method <b>1300</b> embodiment is shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>. This is a broader version of the method of <figref idref="DRAWINGS">FIG. <b>12</b></figref>. In this aspect, a method <b>1300</b> is used for determining an Nth smallest value in a list of combined values. The method <b>1300</b> includes creating, by each party of a group of m parties, m lists of additive shares associated with each party's respective list of data (<b>1302</b>), distributing, from each party to each other party in the group of m parties, m&#x2212;1 of the lists of additive shares to yield a respective combined list of additive shares W<sub>i </sub>obtained by each party of the m parties (<b>1304</b>), receiving from a trusted party a list of additive shares V<sub>i </sub>associated with a hot-code vector V (<b>1306</b>), computing, in a shared space by each party, a respective R<sub>i </sub>value using a secure multiplication protocol (<b>1308</b>), comparing, in the shared space, by each party and using secure multi-party comparison protocol, the respective R<sub>i </sub>to all elements in the respective combined list of additive shares W<sub>i </sub>to yield a total number P<sub>1 </sub>of values in W<sub>i </sub>that are smaller than R<sub>i</sub>, wherein adding P<sub>i </sub>values or shares equals P (<b>1310</b>) and using P to either (1) return R<sub>i </sub>when N=P+1 and end the method; (2) remove all numbers smaller than R<sub>i </sub>(and R<sub>i </sub>as well) from W<sub>i </sub>and set a new value of N and return to an earlier step in the method until N=P+1; or (3) remove all numbers bigger than R<sub>i </sub>(and R<sub>i </sub>as well) from W<sub>i </sub>and return to an earlier step in the method until N=P+1 (<b>1312</b>).</p><p id="p-0149" num="0147">The method <b>1300</b> can be performed be each party's computer system or as a group where various parties perform their portions of the operations of receiving data, distributing data (shares) and performing the multi-party operations to learn about the results of the comparison.</p><heading id="h-0019" level="1">Averaging Models Using Secure Multi-Party Computations</heading><p id="p-0150" num="0148">This disclosure now turns to the subject matter of the present claims. <figref idref="DRAWINGS">FIG. <b>14</b>A</figref> illustrates the approach. The goal is to enable a client to average their model with other client models without learning any data from the other client models. The approach involves how n clients and one server can securely average their models d. The method <b>1400</b> is performed in one aspect from the standpoint of the server <b>102</b> and can include selecting a generator g and a number p (<b>1402</b>). This step can include generating random numbers for the generator g and the number p. The number p can also be a prime number and in one aspect can be large. The server <b>102</b> can select these numbers. These numbers will be used for processing using a protocol such as the Diffie Hellman protocol as an example. The Diffie Hellman protocol is a method of securely exchanging cryptographic keys over a public channel. The protocol is one of the earliest practical works that proposed the idea of a private key and a corresponding public key. Any approach can be used.</p><p id="p-0151" num="0149">The method <b>1400</b> can include transmitting, to n client devices comprising at least two client devices, the generator g and the number p (<b>1404</b>) and receiving, at the server and from each client device i of the at least two client devices, a respective value k<sub>i</sub>=g<sup>ri </sup>mod p to generate a set of respective values k<sub>i </sub>(<b>1406</b>). The value k<sub>i </sub>can be generated according to other equations as well.</p><p id="p-0152" num="0150">Each client device can generate the &#x201c;k&#x201d; or &#x201c;r<sub>i</sub>&#x201d; value and the modulus &#x201c;mod p&#x201d; is the remainder after dividing one number by another. For example, 100 mod 9 equals 1 because 100/9=11 with a remainder of 1. Another example is 14 mod 12 equals 2 because 14/12=1 with a remainder of 2. The &#x201c;k&#x201d; may be random or some other number. The &#x201c;k&#x201d; or &#x201c;r<sub>i</sub>&#x201d; in one example in the equation is generated by each client i based on a randomly generated number and will assign a share of that number to each of the other clients in the network. The process of determining k<sub>ij </sub>below is how each client obtains the &#x201c;r<sub>i</sub>&#x201d; value.</p><p id="p-0153" num="0151">The method <b>1400</b> includes transmitting the set of respective values k<sub>i </sub>to each client device i of the at least two client devices wherein: each client device i of the at least two client devices computes a key k<sub>ij </sub>in which the client device i computes the key k<sub>ij </sub>with a client device j: k<sub>ij</sub>=k<sub>j</sub><sup>r</sup><sup><sub2>i </sub2></sup>in which r<sub>i </sub>is a random number generated by the client device i. The client device i creates n shares of a respective model (d) associated with the client device i: [d]<sub>i1</sub>, . . . , [d]<sub>in</sub>=ShareGeneration(d). The client device i encrypts a client device j share using the key k<sub>ij</sub>: ([d&#x2032;]<sub>ij</sub>=[d]<sub>ij</sub>+k<sub>ij</sub>) for all 1&#x2264;j&#x2264;n and j&#x2260;i (<b>1408</b>). The respective model (d) is the respective model on each respective client device that is desired to be used as part of a process of averaging all of the models across all client devices. The value k<sub>ij </sub>is a different share that a client i is going to generate between them and client j. If there are three clients, client <b>1</b> will send its shares to clients <b>2</b> and <b>3</b> and then generate between client <b>2</b> a value k<sub>12 </sub>and then between client <b>3</b> a value k<sub>13</sub>. Client <b>2</b> sends two random numbers to client <b>1</b> and client <b>3</b>, and client <b>3</b> sends two random numbers to client <b>1</b> and client <b>2</b>. The value k<sub>ij </sub>is generated locally at each respective client.</p><p id="p-0154" num="0152">The method further can include receiving, at the server <b>102</b>, the client device j share ([d&#x2032;]<sub>ij</sub>) from the client device i (<b>1410</b>) and transmitting the client device j share ([d&#x2032;]<sub>ij</sub>) to each corresponding client device, wherein each respective client device decrypts the client device j share ([d&#x2032;]<sub>ij</sub>) with the k<sub>ij</sub>: [d]<sub>ij</sub>=[d&#x2032;]<sub>ij</sub>&#x2212;k<sub>ij </sub>and adds all the shares to generate a respective added group of shares (<b>1412</b>). The method includes receiving each respective added group of shares from each client device i of the at least two client devices (<b>1414</b>) and adding all the respective added group of shares to yield a global sum of shares and dividing the global sum of shares by n to compute an average of models (<b>1416</b>). The number p can include a prime number. The generator g can include a random number that is generated. The server acts as a communication channel for a key exchange using a Diffie-Hellman key. The key k<sub>ij </sub>can include a Diffie-Hellman key. The ShareGeneration(d) performs an operation comprising generating shares of a model (d) operating on a respective client device i.</p><p id="p-0155" num="0153">In one aspect, the step of selecting, at the server <b>102</b>, of the generator g is performed according to a Diffie-Hellman protocol.</p><p id="p-0156" num="0154">An embodiment of this disclosure can also include a system <b>102</b>. The system can include a processor and a computer-readable storage device storing instructions which, when executed by the processor, cause the processor to perform operations including selecting, at a server, a generator g and a number p, transmitting, to n client devices comprising at least two client devices, the generator g and the number p and receiving, from each client device i of the at least two client devices, a respective value k<sub>i</sub>=g<sup>r</sup><sup><sub2>i </sub2></sup>mod p to generate a set of respective values k<sub>i</sub>. Each client i, generates a random number r<sub>i </sub>and computes or generates the key k<sub>i</sub>, using the formula. The client device send the key k<sub>i </sub>to the server. The operations can further include transmitting the set of respective values k<sub>i </sub>to each client device i of the at least two client devices. Each client device i of the at least two client devices can compute a key k<sub>ij </sub>in which the client device i computes the key k<sub>i </sub>with a client device j: k<sub>ij</sub>=k<sub>j</sub><sup>r</sup><sup><sub2>i </sub2></sup>in which r<sub>i </sub>is a random number generated by the client device i. The client device i can create n shares of a respective model (d) associated with the client device i: [d]<sub>i1</sub>, . . . , [d]<sub>in</sub>=ShareGeneration(d) and the client device i can encrypt a client device j share using the key k<sub>ij</sub>: ([d&#x2032;]<sub>ij</sub>=[d]<sub>ij</sub>+k<sub>ij</sub>) for all 1&#x2264;j&#x2264;n and j&#x2260;i.</p><p id="p-0157" num="0155">The operations can further include receiving the client device j share ([d&#x2032;]<sub>ij</sub>) from the client device i, transmitting the client device j share ([d&#x2032;]<sub>ij</sub>) to each corresponding client device, wherein each respective client device decrypts the client device j share ([d&#x2032;]<sub>ij</sub>) with the k<sub>ij</sub>: [d]<sub>ij</sub>=[d&#x2032;]<sub>ij</sub>&#x2212;k<sub>ij </sub>and adds all the shares to generate a respective added group of shares, receiving each respective added group of shares from each client device i of the at least two client devices and adding all the respective added group of shares to yield a global sum of shares and dividing the global sum of shares by n to compute an average of models.</p><p id="p-0158" num="0156"><figref idref="DRAWINGS">FIG. <b>14</b>B</figref> illustrates a method <b>1440</b> from the standpoint of a respective client device i. The method <b>1440</b> can include receiving, from a server and at a client device i of a group of client devices, a generator g and a number p (<b>1442</b>), transmitting, to the server, a respective value k<sub>i</sub>=g<sup>ri </sup>mod p to generate a set of respective values k<sub>i </sub>(<b>1444</b>), receiving, from the server, the set of respective values k<sub>i </sub>(<b>1446</b>), computing a key k<sub>ij </sub>in which the client device i computes the key k<sub>ij </sub>with a client device j of the group of client device: k<sub>ij</sub>=k<sub>j</sub><sup>r</sup><sup><sub2>i </sub2></sup>in which r<sub>i </sub>is a random number generated by the client device i (<b>1448</b>), creating n shares of a respective model (d) associated with the client device i: [d]<sub>i1</sub>, . . . , [d]<sub>in</sub>=ShareGeneration(d) (<b>1450</b>) and encrypting a client device j share using the key k<sub>ij</sub>: ([d&#x2032;]<sub>ij</sub>=[d]<sub>ij</sub>+k<sub>ij</sub>) for all 1&#x2264;j&#x2264;n and j&#x2260;i (<b>1452</b>). The method can further include transmitting, to the server, the client device j share ([d&#x2032;]<sub>ij</sub>) from the client device i (<b>1454</b>), receiving, at the client device i, the client device j share ([d&#x2032;]<sub>ij</sub>) corresponding to the client device i, wherein each respective client device of the group of client devices decrypts the client device j share ([d&#x2032;]<sub>ij</sub>) with the k<sub>ij</sub>: [d]<sub>ij</sub>=[d&#x2032;]<sub>ij</sub>&#x2212;k<sub>ij </sub>and adds all the shares to generate a respective added group of shares (<b>1456</b>) and transmitting the respective added group of shares from the client device i to the server, wherein the server adds all the respective added group of shares to yield a global sum of shares and divides the global sum of shares by n to compute an average of models (<b>1458</b>).</p><p id="p-0159" num="0157"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates example computer device that can be used in connection with any of the systems disclosed herein. In this example, <figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates a computing system <b>1100</b> including components in electrical communication with each other using a connection <b>1105</b>, such as a bus. System <b>1100</b> includes a processing unit (CPU or processor) <b>1110</b> and a system connection <b>1105</b> that couples various system components including the system memory <b>1115</b>, such as read only memory (ROM) <b>1120</b> and random access memory (RAM) <b>1125</b>, to the processor <b>1110</b>. The system <b>1100</b> can include a cache of high-speed memory connected directly with, in close proximity to, or integrated as part of the processor <b>1110</b>. The system <b>1100</b> can copy data from the memory <b>1115</b> and/or the storage device <b>1130</b> to the cache <b>1112</b> for quick access by the processor <b>1110</b>. In this way, the cache can provide a performance boost that avoids processor <b>1110</b> delays while waiting for data. These and other modules can control or be configured to control the processor <b>1110</b> to perform various actions. Other system memory <b>1115</b> may be available for use as well. The memory <b>1115</b> can include multiple different types of memory with different performance characteristics. The processor <b>1110</b> can include any general purpose processor and a hardware or software service or module, such as service (module) <b>1</b> <b>1132</b>, service (module) <b>2</b> <b>1134</b>, and service (module) <b>3</b> <b>1136</b> stored in storage device <b>1130</b>, configured to control the processor <b>1110</b> as well as a special-purpose processor where software instructions are incorporated into the actual processor design. The processor <b>1110</b> may be a completely self-contained computing system, containing multiple cores or processors, a bus, memory controller, cache, etc. A multi-core processor may be symmetric or asymmetric.</p><p id="p-0160" num="0158">To enable user interaction with the device <b>1100</b>, an input device <b>1145</b> can represent any number of input mechanisms, such as a microphone for speech, a touch-sensitive screen for gesture or graphical input, keyboard, mouse, motion input, speech and so forth. An output device <b>1135</b> can also be one or more of a number of output mechanisms known to those of skill in the art. In some instances, multimodal systems can enable a user to provide multiple types of input to communicate with the device <b>1100</b>. The communications interface <b>1140</b> can generally govern and manage the user input and system output. There is no restriction on operating on any particular hardware arrangement and therefore the basic features here may easily be substituted for improved hardware or firmware arrangements as they are developed.</p><p id="p-0161" num="0159">Storage device <b>1130</b> is a non-volatile memory and can be a hard disk or other types of computer readable media which can store data that are accessible by a computer, such as magnetic cassettes, flash memory cards, solid state memory devices, digital versatile disks, cartridges, random access memories (RAMs) <b>1125</b>, read only memory (ROM) <b>1120</b>, and hybrids thereof.</p><p id="p-0162" num="0160">The storage device <b>1130</b> can include services or modules <b>1132</b>, <b>1134</b>, <b>1136</b> for controlling the processor <b>1110</b>. Other hardware or software modules are contemplated. The storage device <b>1130</b> can be connected to the system connection <b>1105</b>. In one aspect, a hardware module that performs a particular function can include the software component stored in a computer-readable medium in connection with the necessary hardware components, such as the processor <b>1110</b>, connection <b>1105</b>, output device <b>1135</b>, and so forth, to carry out the function.</p><p id="p-0163" num="0161">In some cases, such a computing device or apparatus may include a processor, microprocessor, microcomputer, or other component of a device that is configured to carry out the steps of the methods disclosed above. In some examples, such computing device or apparatus may include one or more antennas for sending and receiving RF signals. In some examples, such computing device or apparatus may include an antenna and a modem for sending, receiving, modulating, and demodulating RF signals, as previously described.</p><p id="p-0164" num="0162">The components of the computing device can be implemented in circuitry. For example, the components can include and/or can be implemented using electronic circuits or other electronic hardware, which can include one or more programmable electronic circuits (e.g., microprocessors, graphics processing units (GPUs), digital signal processors (DSPs), central processing units (CPUs), and/or other suitable electronic circuits), and/or can include and/or be implemented using computer software, firmware, or any combination thereof, to perform the various operations described herein. The computing device may further include a display (as an example of the output device or in addition to the output device), a network interface configured to communicate and/or receive the data, any combination thereof, and/or other component(s). The network interface may be configured to communicate and/or receive Internet Protocol (IP) based data or other type of data.</p><p id="p-0165" num="0163">The methods discussed above are illustrated as a logical flow diagram, the operations of which represent a sequence of operations that can be implemented in hardware, computer instructions, or a combination thereof. In the context of computer instructions, the operations represent computer-executable instructions stored on one or more computer-readable storage media that, when executed by one or more processors, perform the recited operations. Generally, computer-executable instructions include routines, programs, objects, components, data structures, and the like that perform particular functions or implement particular data types. The order in which the operations are described is not intended to be construed as a limitation, and any number of the described operations can be combined in any order and/or in parallel to implement the processes.</p><p id="p-0166" num="0164">Additionally, the methods disclosed herein may be performed under the control of one or more computer systems configured with executable instructions and may be implemented as code (e.g., executable instructions, one or more computer programs, or one or more applications) executing collectively on one or more processors, by hardware, or combinations thereof. As noted above, the code may be stored on a computer-readable or machine-readable storage medium, for example, in the form of a computer program including a plurality of instructions executable by one or more processors. The computer-readable or machine-readable storage medium may be non-transitory.</p><p id="p-0167" num="0165">The term &#x201c;computer-readable medium&#x201d; includes, but is not limited to, portable or non-portable storage devices, optical storage devices, and various other mediums capable of storing, containing, or carrying instruction(s) and/or data. A computer-readable medium may include a non-transitory medium in which data can be stored and that does not include carrier waves and/or transitory electronic signals propagating wirelessly or over wired connections. Examples of a non-transitory medium may include, but are not limited to, a magnetic disk or tape, optical storage media such as compact disk (CD) or digital versatile disk (DVD), flash memory, memory or memory devices. A computer-readable medium may have stored thereon code and/or machine-executable instructions that may represent a procedure, a function, a subprogram, a program, a routine, a subroutine, a module, a software package, a class, or any combination of instructions, data structures, or program statements. A code segment may be coupled to another code segment or a hardware circuit by passing and/or receiving information, data, arguments, parameters, or memory contents. Information, arguments, parameters, data, etc. may be passed, forwarded, or transmitted via any suitable means including memory sharing, message passing, token passing, network transmission, or the like.</p><p id="p-0168" num="0166">In some embodiments the computer-readable storage devices, mediums, and memories can include a cable or wireless signal containing a bit stream and the like. However, when mentioned, non-transitory computer-readable storage media expressly exclude media such as energy, carrier signals, electromagnetic waves, and signals per se.</p><p id="p-0169" num="0167">Specific details are provided in the description above to provide a thorough understanding of the embodiments and examples provided herein. However, it will be understood by one of ordinary skill in the art that the embodiments may be practiced without these specific details. For clarity of explanation, in some instances the present technology may be presented as including individual functional blocks including devices, device components, steps or routines in a method embodied in software, or combinations of hardware and software. Additional components may be used other than those shown in the figures and/or described herein. For example, circuits, systems, networks, processes, and other components may be shown as components in block diagram form in order not to obscure the embodiments in unnecessary detail. In other instances, well-known circuits, processes, algorithms, structures, and techniques may be shown without unnecessary detail in order to avoid obscuring the embodiments.</p><p id="p-0170" num="0168">Individual embodiments may be described above as a process or method which is depicted as a flowchart, a flow diagram, a data flow diagram, a structure diagram, or a block diagram. Although a flowchart may describe the operations as a sequential process, many of the operations can be performed in parallel or concurrently. In addition, the order of the operations may be re-arranged. A process is terminated when its operations are completed, but can have additional steps not included in a figure. A process may correspond to a method, a function, a procedure, a subroutine, a subprogram, etc. When a process corresponds to a function, its termination can correspond to a return of the function to the calling function or the main function.</p><p id="p-0171" num="0169">Processes and methods according to the above-described examples can be implemented using computer-executable instructions that are stored or otherwise available from computer-readable media. Such instructions can include, for example, instructions and data which cause or otherwise configure a general purpose computer, special purpose computer, or a processing device to perform a certain function or group of functions. Portions of computer resources used can be accessible over a network. The computer executable instructions may be, for example, binaries, intermediate format instructions such as assembly language, firmware, source code. Examples of computer-readable media that may be used to store instructions, information used, and/or information created during methods according to described examples include magnetic or optical disks, flash memory, USB devices provided with non-volatile memory, networked storage devices, and so on.</p><p id="p-0172" num="0170">Devices implementing processes and methods according to these disclosures can include hardware, software, firmware, middleware, microcode, hardware description languages, or any combination thereof, and can take any of a variety of form factors. When implemented in software, firmware, middleware, or microcode, the program code or code segments to perform the necessary tasks (e.g., a computer-program product) may be stored in a computer-readable or machine-readable medium. A processor(s) may perform the necessary tasks. Typical examples of form factors include laptops, smart phones, mobile phones, tablet devices or other small form factor personal computers, personal digital assistants, rackmount devices, standalone devices, and so on. Functionality described herein also can be embodied in peripherals or add-in cards. Such functionality can also be implemented on a circuit board among different chips or different processes executing in a single device, by way of further example.</p><p id="p-0173" num="0171">The instructions, media for conveying such instructions, computing resources for executing them, and other structures for supporting such computing resources are example means for providing the functions described in the disclosure.</p><p id="p-0174" num="0172">In the foregoing description, aspects of the application are described with reference to specific embodiments thereof, but those skilled in the art will recognize that the application is not limited thereto. Thus, while illustrative embodiments of the application have been described in detail herein, it is to be understood that the inventive concepts may be otherwise variously embodied and employed, and that the appended claims are intended to be construed to include such variations, except as limited by the prior art. Various features and aspects of the above-described application may be used individually or jointly. Further, embodiments can be utilized in any number of environments and applications beyond those described herein without departing from the broader spirit and scope of the specification. The specification and drawings are, accordingly, to be regarded as illustrative rather than restrictive. For the purposes of illustration, methods were described in a particular order. It should be appreciated that in alternate embodiments, the methods may be performed in a different order than that described.</p><p id="p-0175" num="0173">One of ordinary skill will appreciate that the less than (&#x201c;&#x3c;&#x201d;) and greater than (&#x201c;&#x3e;&#x201d;) symbols or terminology used herein can be replaced with less than or equal to (&#x201c;&#x2264;&#x201d;) and greater than or equal to (&#x201c;&#x2265;&#x201d;) symbols, respectively, without departing from the scope of this description.</p><p id="p-0176" num="0174">Where components are described as being &#x201c;configured to&#x201d; perform certain operations, such configuration can be accomplished, for example, by designing electronic circuits or other hardware to perform the operation, by programming programmable electronic circuits (e.g., microprocessors, or other suitable electronic circuits) to perform the operation, or any combination thereof.</p><p id="p-0177" num="0175">The phrase &#x201c;coupled to&#x201d; refers to any component that is physically connected to another component either directly or indirectly, and/or any component that is in communication with another component (e.g., connected to the other component over a wired or wireless connection, and/or other suitable communication interface) either directly or indirectly.</p><p id="p-0178" num="0176">Claim language or other language reciting &#x201c;at least one of&#x201d; a set and/or &#x201c;one or more&#x201d; of a set indicates that one member of the set or multiple members of the set (in any combination) satisfy the claim. For example, claim language reciting &#x201c;at least one of A and B&#x201d; or &#x201c;at least one of A or B&#x201d; means A, B, or A and B. In another example, claim language reciting &#x201c;at least one of A, B, and C&#x201d; or &#x201c;at least one of A, B, or C&#x201d; means A, B, C, or A and B, or A and C, or B and C, or A and B and C. The language &#x201c;at least one of&#x201d; a set and/or &#x201c;one or more&#x201d; of a set does not limit the set to the items listed in the set. For example, claim language reciting &#x201c;at least one of A and B&#x201d; or &#x201c;at least one of A or B&#x201d; can mean A, B, or A and B, and can additionally include items not listed in the set of A and B.</p><p id="p-0179" num="0177">Although a variety of examples and other information was used to explain aspects within the scope of the appended claims, no limitation of the claims should be implied based on particular features or arrangements in such examples, as one of ordinary skill would be able to use these examples to derive a wide variety of implementations. Further and although some subject matter may have been described in language specific to examples of structural features and/or method steps, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to these described features or acts. For example, such functionality can be distributed differently or performed in components other than those identified herein. Rather, the described features and steps are disclosed as examples of components of systems and methods within the scope of the appended claims.</p><p id="p-0180" num="0178">Claim language reciting &#x201c;at least one of&#x201d; a set indicates that one member of the set or multiple members of the set satisfy the claim. For example, claim language reciting &#x201c;at least one of A and B&#x201d; means A, B, or A and B.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method comprising:<claim-text>selecting, at a server, a generator g and a number p;</claim-text><claim-text>transmitting, to n client devices comprising at least two client devices, the generator g and the number p;</claim-text><claim-text>receiving, at the server and from each client device i of the at least two client devices, a respective value k<sub>i</sub>=g<sup>ri </sup>mod p to generate a set of respective values k<sub>i</sub>;</claim-text><claim-text>transmitting the set of respective values k<sub>i </sub>to each client device i of the at least two client devices, wherein:<claim-text>each client device i of the at least two client devices computes a key k<sub>ij </sub>in which the client device i computes the key k<sub>ij </sub>with a client device j: k<sub>ij</sub>=k<sub>j</sub><sup>r</sup><sup><sub2>i </sub2></sup>in which r<sub>i </sub>is a random number generated by the client device i;</claim-text><claim-text>the client device i creates n shares of a respective model (d) associated with the client device i: [d]<sub>i1</sub>, . . . , [d]<sub>in</sub>=ShareGeneration(d); and</claim-text><claim-text>the client device i encrypts a client device j share using the key k<sub>ij</sub>: ([d&#x2032;]<sub>ij</sub>=[d]<sub>ij</sub>+k<sub>ij</sub>) for all 1&#x2264;j&#x2264;n and j&#x2260;i;</claim-text></claim-text><claim-text>receiving, at the server, the client device j share ([d&#x2032;]<sub>ij</sub>) from the client device i;</claim-text><claim-text>transmitting the client device j share ([d&#x2032;]<sub>ij</sub>) to each corresponding client device, wherein each respective client device decrypts the client device j share ([d&#x2032;]<sub>ij</sub>) with the k<sub>ij</sub>: [d]<sub>ij</sub>=[d&#x2032;]<sub>ij</sub>&#x2212;k<sub>ij </sub>and adds all the shares to generate a respective added group of shares;</claim-text><claim-text>receiving each respective added group of shares from each client device i of the at least two client devices; and</claim-text><claim-text>adding all the respective added group of shares to yield a global sum of shares and dividing the global sum of shares by n to compute an average of models.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the number comprises a prime number.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the generator g comprises a random number.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the server acts as a communication channel for a key exchange using a Diffie-Hellman key.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the key k<sub>ij </sub>comprises a Diffie-Hellman key.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the ShareGeneration(d) performs an operation comprising generating shares of a model (d) operating on a respective client device i.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein selecting, at the server, the generator g is performed according to a Diffie-Hellman protocol.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A system comprising:<claim-text>a processor; and</claim-text><claim-text>a computer-readable storage device storing instructions which, when executed by the processor, cause the processor to perform operations comprising:<claim-text>selecting, at a server, a generator g and a number p;</claim-text><claim-text>transmitting, to n client devices comprising at least two client devices, the generator g and the number p;</claim-text><claim-text>receiving, from each client device i of the at least two client devices, a respective value k<sub>i</sub>=g<sup>ri </sup>mod p to generate a set of respective values k<sub>i</sub>;</claim-text><claim-text>transmitting the set of respective values k<sub>i </sub>to each client device i of the at least two client devices, wherein:<claim-text>each client device i of the at least two client devices computes a key k<sub>ij </sub>in which the client device i computes the key k<sub>ij </sub>with a client device j: k<sub>ij</sub>=k<sub>j</sub><sup>r</sup><sup><sub2>i </sub2></sup>in which r<sub>i </sub>is a random number generated by the client device i;</claim-text><claim-text>the client device i creates n shares of a respective model (d) associated with the client device i: [d]<sub>i1</sub>, . . . , [d]<sub>in</sub>=ShareGeneration(d); and</claim-text><claim-text>the client device i encrypts a client device j share using the key k<sub>ij</sub>: ([d&#x2032;]<sub>ij</sub>=[d]<sub>ij</sub>+k<sub>ij</sub>) for all 1&#x2264;j&#x2264;n and j&#x2260;i;</claim-text></claim-text><claim-text>receiving the client device j share ([d&#x2032;]<sub>ij</sub>) from the client device i;</claim-text><claim-text>transmitting the client device j share ([d&#x2032;]<sub>ij</sub>) to each corresponding client device, wherein each respective client device decrypts the client device j share ([d&#x2032;]<sub>ij</sub>) with the k<sub>ij</sub>: [d]<sub>ij</sub>=[d&#x2032;]<sub>ij</sub>&#x2212;k<sub>ij </sub>and adds all the shares to generate a respective added group of shares;</claim-text><claim-text>receiving each respective added group of shares from each client device i of the at least two client devices; and</claim-text><claim-text>adding all the respective added group of shares to yield a global sum of shares and dividing the global sum of shares by n to compute an average of models.</claim-text></claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the number comprises a prime number.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the generator g comprises a random number.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the server acts as a communication channel for a key exchange using a Diffie-Hellman key.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the key k<sub>ij </sub>comprises a Diffie-Hellman key.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the ShareGeneration(d) performs an operation comprising generating shares of a model (d) operating on a respective client device i.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein selecting, at the server, the generator g is performed according to a Diffie-Hellman protocol.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A method comprising:<claim-text>receiving, from a server and at a client device i of a group of client devices, a generator g and a number p;</claim-text><claim-text>transmitting, to the server, a respective value k<sub>i</sub>=g<sup>ri </sup>mod p to generate a set of respective values k<sub>i</sub>;</claim-text><claim-text>receiving, from the server, the set of respective values k<sub>i</sub>;</claim-text><claim-text>computing a key k<sub>ij </sub>in which the client device i computes the key k<sub>ij </sub>with a client device j of the group of client device: k<sub>ij</sub>=k<sub>j</sub><sup>r</sup><sup><sub2>i </sub2></sup>in which r<sub>i </sub>is a random number generated by the client device i;</claim-text><claim-text>creating n shares of a respective model (d) associated with the client device i: [d]<sub>i1</sub>, . . . , [d]<sub>in</sub>=ShareGeneration(d); and</claim-text><claim-text>encrypting a client device j share using the key k<sub>ij</sub>: ([d&#x2032;]<sub>ij</sub>=[d]<sub>ij</sub>+k<sub>ij</sub>) for all 1&#x2264;j&#x2264;n and j&#x2260;i;</claim-text><claim-text>transmitting, to the server, the client device j share ([d&#x2032;]<sub>ij</sub>) from the client device i;</claim-text><claim-text>receiving, at the client device i, the client device j share ([d&#x2032;]<sub>ij</sub>) corresponding to the client device i, wherein each respective client device of the group of client devices decrypts the client device j share ([d&#x2032;]<sub>ij</sub>) with the k<sub>ij</sub>: [d]<sub>ij</sub>=[d&#x2032;]<sub>ij</sub>&#x2212;k<sub>ij </sub>and adds all the shares to generate a respective added group of shares; and</claim-text><claim-text>transmitting the respective added group of shares from the client device i to the server, wherein the server adds all the respective added group of shares to yield a global sum of shares and divides the global sum of shares by n to compute an average of models.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising receiving the average of models at the client device i.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the number comprises a prime number and wherein the generator g comprises a random number.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the key k<sub>ij </sub>comprises a Diffie-Hellman key.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the ShareGeneration(d) performs an operation comprising generating shares of a model (d) operating on a respective client device i.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the server selects the generator g according to a Diffie-Hellman protocol.</claim-text></claim></claims></us-patent-application>
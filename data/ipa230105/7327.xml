<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007328A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007328</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17941045</doc-number><date>20220909</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>2662</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>47</main-group><subgroup>193</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>24</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>61</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>442</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>44</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>4363</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>643</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>2662</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>47</main-group><subgroup>193</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>2402</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>6125</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>44209</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>44004</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>4363</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>64322</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>43</main-group><subgroup>12</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">METHOD AND APPARATUS FOR MANAGING OVER-THE-TOP VIDEO RATE</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17463586</doc-number><date>20210901</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11477505</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17941045</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17037250</doc-number><date>20200929</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11140430</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17463586</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15289408</doc-number><date>20161010</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10827211</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17037250</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>AT&#x26;T Intellectual Property I, L.P.</orgname><address><city>Atlanta</city><state>GA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Liu</last-name><first-name>Zhengye</first-name><address><city>Pleasanton</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Wang</last-name><first-name>Jin</first-name><address><city>Fremont</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Liu</last-name><first-name>Yali</first-name><address><city>Dublin</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Zhao</last-name><first-name>Yongdong</first-name><address><city>Pleasanton</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>AT&#x26;T Intellectual Property I, L.P.</orgname><role>02</role><address><city>Atlanta</city><state>GA</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Aspects of the subject disclosure may include, for example, a device including a processing system including a processor and a memory that stores executable instructions that, when executed by the processing system, facilitate performance of operations, including monitoring network traffic to determine a transmission control protocol traffic pattern, determining a target video rate from the transmission control protocol traffic pattern, and modifying an over-the-top video delivery service network according to the target video rate. Other embodiments are disclosed.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="93.39mm" wi="158.75mm" file="US20230007328A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="222.67mm" wi="140.04mm" orientation="landscape" file="US20230007328A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="226.57mm" wi="105.07mm" orientation="landscape" file="US20230007328A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="279.40mm" wi="156.72mm" orientation="landscape" file="US20230007328A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="222.67mm" wi="153.84mm" orientation="landscape" file="US20230007328A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="164.85mm" wi="166.45mm" orientation="landscape" file="US20230007328A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="148.00mm" wi="186.44mm" orientation="landscape" file="US20230007328A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="127.25mm" wi="128.95mm" orientation="landscape" file="US20230007328A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="115.82mm" wi="178.14mm" orientation="landscape" file="US20230007328A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 17/463,586, filed Sep. 1, 2021, which is a continuation of U.S. patent application Ser. No. 17/037,250, filed Sep. 29, 2020 (now U.S. Pat. No. 11,140,430), which is a continuation of U.S. patent application Ser. No. 15/289,408, filed Oct. 10, 2016 (now U.S. Pat. No. 10,827,211). All sections of the aforementioned application(s) and patent(s) are incorporated herein by reference in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD OF THE DISCLOSURE</heading><p id="p-0003" num="0002">The subject disclosure relates to a method and apparatus for managing Over-The-Top Video Rate.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Over-The-Top (OTT) services dominate Internet traffic. OTT video services and Internet service providers often seek to estimate video rates. Video rates can be the rates that videos are encoded into, from network traffics, including how video bits are transmitted over the networks.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0005" num="0004">Reference will now be made to the accompanying drawings, which are not necessarily drawn to scale, and wherein:</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts an illustrative embodiment of system <b>100</b>;</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts an illustrative embodiment of method <b>200</b> used in portions of the system described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>;</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts an illustrative embodiment of a method used in portions of the system described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>;</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts an illustrative example of estimating video rates;</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIGS. <b>5</b>A, <b>5</b>B, <b>5</b>C, and <b>5</b>D</figref> depicts illustrative examples of estimating video rates for various OTT service providers.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts an illustrative embodiment of a method used in portions of the system described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts an illustrative embodiment of a communication system that provide media services used in portions of the system described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>8</b></figref> depicts an illustrative embodiment of a communication device; and</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagrammatic representation of a machine in the form of a computer system within which a set of instructions, when executed, may cause the machine to perform any one or more of the methods described herein.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0015" num="0014">The subject disclosure describes, among other things, illustrative embodiments for estimating video rates. Other embodiments are described in the subject disclosure.</p><p id="p-0016" num="0015">One or more aspects of the subject disclosure include a device including a processing system including a processor and a memory that stores executable instructions that, when executed by the processing system, facilitate performance of operations, including monitoring network traffic to determine transmission control protocol traffic pattern, determining a target video rate from the transmission control protocol traffic pattern, and modifying an over-the-top video delivery service network according to the target video rate.</p><p id="p-0017" num="0016">One or more aspects of the subject disclosure include a method including monitoring, by a processing system comprising a processor, network traffic to determine transmission control protocol traffic pattern, determining, by the processing system, an optimized video rate from the transmission control protocol traffic pattern, determining, by the processing system, a quality of video service of an over-the-top video delivery service network using the network traffic, and improving the quality of video service of the over-the-top video delivery service network according to the optimized video rate.</p><p id="p-0018" num="0017">One or more aspects of the subject disclosure include a machine-readable storage medium, including executable instructions that, when executed by a processing system including a processor, facilitate performance of operations that include monitoring network traffic to determine transmission control protocol traffic pattern, determining a target video rate from the transmission control protocol traffic pattern, and modifying an over-the-top video delivery service network according to the target video rate.</p><p id="p-0019" num="0018">The evolution of IP networks and access-agnostic access paved the way for Over-The-Top (OTT) services to flourish. OTT video services now dominate Internet traffic. To improve subscriber quality of experience and generating new revenue streams, it is preferable to efficiently measure and monitor video quality from network traffic. Video rate is one of the most important parameters to indicate video quality and user experience. OTT video services need to accurately estimate video rates. Video rates are the rates that videos are encoded into, from network traffics, including how video bits are transmitted over the networks. This can be done without knowing the OTT's service's video coding configurations.</p><p id="p-0020" num="0019">Embodiments of the present invention provide a system that can evaluate the performance of OTT video applications and provide an assessment of the end user experience impact. Exemplarily, embodiments of the present invention provide a simple and cost-effective solution to estimate slow-varying video playback bit rate from highly dynamic, fast varying TCP traffic counters for general OTT video applications.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an exemplary OTT video service system <b>100</b>. Different OTT video applications <b>102</b> may adopt different video transmission schemes and protocols with very different configurations. OTT video applications <b>102</b> can include different OTT video service providers that provide video services over the Internet <b>104</b>. In some instances, an OTT application can use single server design vs. multiple server design, single TCP flows vs. multiple TCP flows, different video chunk sizes, different video coding schemes, HTTPS or HTTP, and many more affecting parameters.</p><p id="p-0022" num="0021">As exemplarily illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the OTT video service can be provided to a user <b>110</b> through a mobile communications device <b>108</b> that receives the video stream via a mobile communications service provider <b>106</b> that is connected to the Internet <b>104</b>. In other embodiments, users can receive the OTT video service directly through computers or communication devices directly from the Internet <b>104</b>. Various OTT video designs present various network traffic patterns. Exemplarily, embodiments of the present invention can provide a generic approach that is able to estimate video rates that are streamed from all/most OTT video transmission designs. Exemplarily, embodiments of the present invention can provide a model that is able to capture fundamental behaviors of OTT video systems across the many available various designs.</p><p id="p-0023" num="0022">Conventional schemes mainly rely on the side information which may contains the video rate information, i.e., the full domain URLs or a manifest file. However, the conventional approach is not applied for the encrypted video which are becoming more and more popular in OTT video applications. Other conventional approaches are based on complex mathematical models with an input from video encoding and application implementation parameters.</p><p id="p-0024" num="0023">The exemplary OTT video service system <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> also exemplarily includes a network monitor <b>112</b> according to various embodiments of the present invention. Exemplarily, in the network monitor <b>112</b>, a mathematic model, which is able to capture buffer management behavior is applied to the exemplary OTT video service system <b>100</b> to determine the fundamental behaviors of OTT video systems.</p><p id="p-0025" num="0024">For internet service providers (ISP's), network probes/monitors are conventionally used to monitor network performance Such probes typically capture network packets, and perform an analysis on the traffic. After the analysis is performed, a TCP throughput is available. In some embodiments, headers are analyzed without a payload analysis. In other embodiments, customers may be given the option to &#x201c;opt-in&#x201d; or &#x201c;opt-out&#x201d; of this analysis. Exemplarily, various types of analysis of packets can be used to determine patterns and traffic. Exemplarily, this TCP throughput can be the input of the algorithm used in <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>. Exemplarily, the analysis process can identify which Internet traffic is from a particular OTT video service.</p><p id="p-0026" num="0025">In one example, buffer behavior is a fundamental behavior of an OTT video system design. Exemplarily, provided a traffic pattern, containing the transmitted bytes from network in time series, an optimization problem that allocates these bytes optimally to video bytes, to maximize received video quality, is solved. The video bytes obtained based on exemplary embodiments can construct the video rate. Exemplarily, a water-filling algorithm solves the optimization problem. Exemplarily, computation efficiency is taken into account in the water-filling algorithm to handle a huge amount of data.</p><p id="p-0027" num="0026">As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, an end result is an optimization of a customer user experience <b>114</b>. The customer user experience <b>114</b> can include minimizing of video discontinuities and a maximization of video resolution. By estimating the video rate, the at the network monitor <b>112</b>, the customer experience <b>114</b> can exemplarily be remotely monitored and improved.</p><p id="p-0028" num="0027">Exemplary, the processes mimic the buffer behavior of a typical OTT video system application. In general, no matter how conventional OTT video transmission schemes are designed, (and accordingly traffic patterns are presented), transmitted bytes in network will be sent through a buffer to smooth out network dynamics and reconstruct the original video encoding rate.</p><p id="p-0029" num="0028">Exemplary embodiments of the mathematical model can convert the problem of estimating video rate from network traffic pattern to an optimization problem, provided a network traffic pattern, to exemplarily determine what the best available video rate. The estimated video rate can be considered as a performance upper bound, given a network traffic pattern. Exemplarily, for existing OTT video systems, the transmitted bytes are largely used in an optimized way.</p><p id="p-0030" num="0029">Exemplarily, the optimization problem of estimating video rate from the network traffic pattern is described as follows (see, also, <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref> and the associated text below):</p><p id="p-0031" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <mrow>   <mi>max</mi>   <mo>&#x2062;</mo>   <mrow>    <munderover>     <mo>&#x2211;</mo>     <mrow>      <mi>i</mi>      <mo>=</mo>      <mn>1</mn>     </mrow>     <mrow>      <mi>N</mi>      <mo>+</mo>      <mi>B</mi>     </mrow>    </munderover>    <mtext> </mtext>    <mrow>     <mi>log</mi>     <mo>&#x2061;</mo>     <mo>(</mo>     <msub>      <mi>v</mi>      <mi>i</mi>     </msub>     <mo>)</mo>    </mrow>   </mrow>  </mrow>  <mo>&#x2062;</mo>  <mtext></mtext>  <mtable>   <mtr>    <mtd>     <mrow>      <mrow>       <msub>        <mi>b</mi>        <mi>i</mi>       </msub>       <mo>=</mo>       <mrow>        <msub>         <mi>b</mi>         <mrow>          <mi>i</mi>          <mo>,</mo>          <mi>i</mi>         </mrow>        </msub>        <mo>+</mo>        <msub>         <mi>b</mi>         <mrow>          <mi>i</mi>          <mo>,</mo>          <mrow>           <mi>i</mi>           <mo>+</mo>           <mn>1</mn>          </mrow>         </mrow>        </msub>        <mo>+</mo>        <mtext> </mtext>        <mo>&#x2026;</mo>        <mo>+</mo>        <msub>         <mi>b</mi>         <mrow>          <mi>i</mi>          <mo>,</mo>          <mrow>           <mi>i</mi>           <mo>+</mo>           <mi>B</mi>           <mo>-</mo>           <mn>1</mn>          </mrow>         </mrow>        </msub>       </mrow>      </mrow>      <mo>,</mo>      <mrow>       <mi fontstyle="normal">where</mi>       <mo>&#x2062;</mo>       <mtext>   </mtext>       <mi>i</mi>       <mo>&#x2062;</mo>       <mtext>   </mtext>       <mi fontstyle="normal">is</mi>       <mo>&#x2062;</mo>       <mtext>   </mtext>       <mi fontstyle="normal">from</mi>       <mo>&#x2062;</mo>       <mtext>   </mtext>       <mn>1</mn>       <mo>&#x2062;</mo>       <mtext>   </mtext>       <mi fontstyle="normal">to</mi>       <mo>&#x2062;</mo>       <mtext>   </mtext>       <mi>N</mi>      </mrow>     </mrow>    </mtd>   </mtr>   <mtr>    <mtd>     <mrow>      <mtext>       </mtext>      <mrow>       <mrow>        <msub>         <mi>v</mi>         <mi>i</mi>        </msub>        <mo>=</mo>        <mrow>         <msub>          <mi>b</mi>          <mrow>           <mrow>            <mi>i</mi>            <mo>-</mo>            <mi>B</mi>            <mo>+</mo>            <mn>1</mn>           </mrow>           <mo>,</mo>           <mi>i</mi>          </mrow>         </msub>         <mo>+</mo>         <msub>          <mi>b</mi>          <mrow>           <mrow>            <mi>i</mi>            <mo>-</mo>            <mi>B</mi>            <mo>+</mo>            <mn>2</mn>           </mrow>           <mo>,</mo>           <mi>i</mi>          </mrow>         </msub>         <mo>+</mo>         <mtext> </mtext>         <mo>&#x2026;</mo>         <mtext> </mtext>         <mo>+</mo>         <msub>          <mi>b</mi>          <mrow>           <mi>i</mi>           <mo>,</mo>           <mi>i</mi>          </mrow>         </msub>        </mrow>       </mrow>       <mo>,</mo>       <mrow>        <mi fontstyle="normal">where</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mi>i</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mi fontstyle="normal">is</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mi fontstyle="normal">from</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mn>1</mn>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mi fontstyle="normal">to</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mi>N</mi>       </mrow>      </mrow>     </mrow>    </mtd>   </mtr>  </mtable> </mrow></math></maths></p><p id="p-0032" num="0000">where bi represents bytes of the network traffic pattern, and vi represents the estimated video rate.</p><p id="p-0033" num="0030"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an exemplary formulation of the optimization problem. In this example, b<b>1</b>, b<b>2</b>, b<b>3</b>, and b<b>4</b> represents numbers of received bytes in times T<b>1</b>, T<b>2</b>, T<b>3</b>, and T<b>4</b>. In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the buffer size is assumed to be approximately 2 seconds. The optimization problem is to allocate b<b>1</b>, b<b>2</b>, b<b>3</b>, b<b>4</b> to v<b>1</b>, v<b>2</b>, v<b>3</b>, v<b>4</b>, v<b>5</b>. <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a process that may occur in monitor <b>112</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0034" num="0031"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates another exemplary formulation of the optimization problem. In particular, <figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates the optimal solution and the estimated video rates for a given setup. Thus, for example, if 10 bytes, 2 bytes, 20 bytes, 10 bytes are transmitted in time slot <b>1</b>, <b>2</b>, <b>3</b>, <b>4</b>, the estimated video rate will be 6 bytes, 6 byte, 10 bytes, 10 bytes, and 10 bytes, accordingly. <figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a process that may occur in monitor <b>112</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. As discussed above, when the TCP throughput of video traffic is available, exemplary applications of the algorithm, as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, for example, can take the TCP throughput as an input, and output the estimated video rate.</p><p id="p-0035" num="0032"><figref idref="DRAWINGS">FIG. <b>4</b></figref> provides an illustration of an example in which a video rate is estimated from real network traffic. In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the &#x201c;+&#x201d; points represent the network traffic pattern, i.e., bitrate of received traffic in each individual second, which is very dynamic. In particular, the network traffic pattern can be referred to as a &#x201c;TCP throughput&#x201d; curve. The &#x201c;TCP throughput&#x201d; curve is exemplarily what is observed by a network monitor <b>112</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The &#x201c;TCP throughput&#x201d; curve tends to be very dynamic. The &#x201c;actual video rate&#x201d; curve is the video coding rate by content provider, such as the OTT video service <b>102</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Generally, these two curves can be quite different. The &#x201c;estimated video rate&#x201d; is the output of the exemplary algorithm, where the input is &#x201c;TCP throughput&#x201d;.</p><p id="p-0036" num="0033">Exemplarily, through testing, the &#x201c;estimated video rate&#x201d; and &#x201c;actual video rate&#x201d; are largely identical, illustrating that exemplary embodiments of the estimation algorithm tend works in estimating the video rate. In addition, in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the dashed line exemplarily represents the actual video rate, and the solid exemplarily represents the estimated video rate. The solid and dashed lines match with each other very well, which illustrates the accuracy of exemplary embodiments of the estimator.</p><p id="p-0037" num="0034"><figref idref="DRAWINGS">FIGS. <b>5</b>A, <b>5</b>B, <b>5</b>C, and <b>5</b>D</figref> illustrates examples in which OTT video application's video rates <b>510</b>, <b>520</b>, <b>530</b>, and <b>540</b> are estimated from network traffic for various OTT services. <figref idref="DRAWINGS">FIGS. <b>5</b>A, <b>5</b>B, <b>5</b>C, and <b>5</b>D</figref> clearly show that exemplary embodiments of the present invention can efficiently and accurately measure video quality in terms of video bitrate. Exemplarily, each of <figref idref="DRAWINGS">FIGS. <b>5</b>A, <b>5</b>B, <b>5</b>C, and <b>5</b>D</figref> represent a different OTT video delivery service.</p><p id="p-0038" num="0035">Exemplary embodiments of the invention can be used to accurately estimate OTT video playback rate from highly-dynamic HTTP streaming throughput. The embodiments allow the characterization of the performance of OTT video in a network and provides opportunities to monitor, track and optimize OTT video quality, as well as quickly troubleshoot any degradation of the OTT video quality.</p><p id="p-0039" num="0036">Exemplary embodiments can provide various services including performance monitoring to determine how different OTT video applications provide different user experience (for individual users, network planning to determine if a service provider is to launch an OTT video service and/or change OTT video configurations and how to plan network accordingly. Exemplarily, this analysis can provide critical guidance for Internet service providers to answer questions that, between OTT video service providers, who provides a better user experience. In other embodiments, the Internet service providers network planning team can answer the question that if one OTT video service providers double its customer base, how to prepare and plan the network accordingly.</p><p id="p-0040" num="0037"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts an illustrative embodiment of a method used by system <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In Step <b>602</b>, network traffic for an OTT video delivery service is exemplarily monitored or probed. Exemplarily, information such as raw TCP throughout information is obtained. Next, in Step <b>604</b>, the video rate is estimated with exemplary embodiments of a water-filling algorithm. For example, water-filling algorithms <b>200</b> and <b>300</b> of <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>, respectively, can be employed. Exemplarily, the video rates for the OTT video service can be determined as similarly illustrated in any one of <figref idref="DRAWINGS">FIGS. <b>5</b>A, <b>5</b>B, <b>5</b>C, and <b>5</b>D</figref> OTT video application's video rates <b>510</b>, <b>520</b>, <b>530</b>, and <b>540</b> are determined.</p><p id="p-0041" num="0038">Exemplarily, once the video rates are estimated, the estimated video rates can be utilized adjust the network traffic pattern to provide an optimized or target video rate. In some instances, the estimated video rate may show a poor video viewing experience. In some embodiments, additional bandwidth may be required to ensure that the video rates provide adequate, target, or optimal video rates.</p><p id="p-0042" num="0039">For example, in one instance, video performance monitoring in Step <b>610</b>. In another embodiment, the estimated video rate can be used in planning the growth of the network in Step <b>608</b>. As video traffic has and continues to be a large portion of Internet traffic. ISP can plan its network better with a better understanding on video performance. In yet another embodiment, the estimated video rate can be the basis through which the video optimization of the OTT video stream is performed in Step <b>606</b>. In general, as a video rate is the most important parameter that indicates the quality of video service. With video performance monitoring, an ISP can have a better understanding how its network can serve video applications. Exemplarily, provided that video quality can be monitored, an ISP can design and optimize its network to better support OTT video services.</p><p id="p-0043" num="0040">In additional embodiments, the determination may be subject to a determination to override (or otherwise adjust) the need or desire to meet the target video rate or the optimal video rate. In some instance, the end user device may not be capable of providing an optimal video display if the optimal video rate were achieved. In other embodiments, the target user device or devices may not have a sufficient subscription level to justify enhancing traffic to optimize their respective video rates. In other embodiments, the network may not be capable of increasing bandwidth without undue cost or other technical barriers. Accordingly, in some instances, any one of steps <b>606</b>, <b>608</b>, and <b>610</b> can be overridden if network conditions or the user devices dictate away from efforts to increase the video rate. In other embodiments, an optimal video rate can be determined but a different video rate (e.g., increased but less than optimal) may be utilized, such as where other factors are considered (e.g., end user device capabilities, subscriber agreements, predicted network traffic, and so forth).</p><p id="p-0044" num="0041">While for purposes of simplicity of explanation, the respective processes are shown and described as a series of blocks in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, it is to be understood and appreciated that the claimed subject matter is not limited by the order of the blocks, as some blocks may occur in different orders and/or concurrently with other blocks from what is depicted and described herein. Moreover, not all illustrated blocks may be required to implement the methods described herein.</p><p id="p-0045" num="0042"><figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts an illustrative embodiment of a communication system <b>700</b> for providing various communication services, such as delivering media content. The communication system <b>700</b> can represent an interactive media network, such as an interactive television system (e.g., an Internet Protocol Television (IPTV) media system). Communication system <b>700</b> can be overlaid or operably coupled with OTT video service <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> as another representative embodiment of communication system <b>700</b>. For instance, one or more devices illustrated in the communication system <b>700</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref> can perform a method including monitoring, by a processing system comprising a processor, network traffic to determine transmission control protocol traffic pattern, determining, by the processing system, an optimized video rate from the transmission control protocol traffic pattern, determining, by the processing system, a quality of video service of an over-the-top video delivery service network using the network traffic, and improving the quality of video service of the over-the-top video delivery service network according to the optimized video rate.</p><p id="p-0046" num="0043">In one or more embodiments, the communication system <b>700</b> can include a super head-end office (SHO) <b>710</b> with at least one super headend office server (SHS) 711 which receives media content from satellite and/or terrestrial communication systems. In the present context, media content can represent, for example, audio content, moving image content such as 2D or 3D videos, video games, virtual reality content, still image content, and combinations thereof. The SHS server <b>711</b> can forward packets associated with the media content to one or more video head-end servers (VHS) <b>714</b> via a network of video head-end offices (VHO) <b>712</b> according to a multicast communication protocol. The VHS <b>714</b> can distribute multimedia broadcast content via an access network <b>718</b> to commercial and/or residential buildings <b>702</b> housing a gateway <b>704</b> (such as a residential or commercial gateway).</p><p id="p-0047" num="0044">The access network <b>718</b> can represent a group of digital subscriber line access multiplexers (DSLAMs) located in a central office or a service area interface that provide broadband services over fiber optical links or copper twisted pairs <b>719</b> to buildings <b>702</b>. The gateway <b>704</b> can use communication technology to distribute broadcast signals to media processors <b>706</b> such as Set-Top Boxes (STBs) which in turn present broadcast channels to media devices <b>708</b> such as computers or television sets managed in some instances by a media controller <b>707</b> (such as an infrared or RF remote controller).</p><p id="p-0048" num="0045">The gateway <b>704</b>, the media processors <b>706</b>, and media devices <b>708</b> can utilize tethered communication technologies (such as coaxial, powerline or phone line wiring) or can operate over a wireless access protocol such as Wireless Fidelity (WiFi), Bluetooth&#xae;, Zigbee&#xae;, or other present or next generation local or personal area wireless network technologies. By way of these interfaces, unicast communications can also be invoked between the media processors <b>706</b> and subsystems of the IPTV media system for services such as video-on-demand (VoD), browsing an electronic programming guide (EPG), or other infrastructure services.</p><p id="p-0049" num="0046">A satellite broadcast television system <b>729</b> can be used in the media system of <figref idref="DRAWINGS">FIG. <b>7</b></figref>. The satellite broadcast television system can be overlaid, operably coupled with, or replace the IPTV system as another representative embodiment of communication system <b>700</b>. In this embodiment, signals transmitted by a satellite <b>715</b> that include media content can be received by a satellite dish receiver <b>731</b> coupled to the building <b>702</b>. Modulated signals received by the satellite dish receiver <b>731</b> can be transferred to the media processors <b>706</b> for demodulating, decoding, encoding, and/or distributing broadcast channels to the media devices <b>708</b>. The media processors <b>706</b> can be equipped with a broadband port to an Internet Service Provider (ISP) network <b>732</b> to enable interactive services such as VoD and EPG as described above.</p><p id="p-0050" num="0047">In yet another embodiment, an analog or digital cable broadcast distribution system such as cable TV system <b>733</b> can be overlaid, operably coupled with, or replace the IPTV system and/or the satellite TV system as another representative embodiment of communication system <b>700</b>. In this embodiment, the cable TV system <b>733</b> can also provide Internet, telephony, and interactive media services. System <b>700</b> enables various types of interactive television and/or services including IPTV, cable and/or satellite.</p><p id="p-0051" num="0048">The subject disclosure can apply to other present or next generation over-the-air and/or landline media content services system.</p><p id="p-0052" num="0049">Some of the network elements of the IPTV media system can be coupled to one or more computing devices <b>730</b>, a portion of which can operate as a web server for providing web portal services over the ISP network <b>732</b> to wireline media devices <b>708</b> or wireless communication devices <b>716</b>.</p><p id="p-0053" num="0050">Communication system <b>700</b> can also provide for all or a portion of the computing devices <b>730</b> to function as an OTT video service video rate estimator (herein referred to as estimator <b>730</b>). The estimator <b>730</b> can use computing and communication technology to perform an estimation of an OTT video service video rate <b>762</b>, which can include among other things, video optimization of Step <b>606</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref> and the network monitor <b>112</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. For instance, the estimation of an OTT video service video rate <b>762</b> of estimator <b>730</b> can be similar to the functions described in accordance with method <b>600</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. The media processors <b>706</b> and wireless communication devices <b>716</b> can be provisioned with software functions <b>764</b> and <b>766</b>, respectively, to utilize the services of estimator <b>730</b>. For instance, functions <b>764</b> and <b>766</b> of media processors <b>706</b> and wireless communication devices <b>716</b> can be similar to the functions described for the OTT video service system <b>100</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref> in accordance with method <b>600</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0054" num="0051">Multiple forms of media services can be offered to media devices over landline technologies such as those described above. Additionally, media services can be offered to media devices by way of a wireless access base station <b>717</b> operating according to common wireless access protocols such as Global System for Mobile or GSM, Code Division Multiple Access or CDMA, Time Division Multiple Access or TDMA, Universal Mobile Telecommunications or UMTS, World interoperability for Microwave or WiMAX, Software Defined Radio or SDR, Long Term Evolution or LTE, and so on. Other present and next generation wide area wireless access network technologies can be used in one or more embodiments of the subject disclosure.</p><p id="p-0055" num="0052"><figref idref="DRAWINGS">FIG. <b>8</b></figref> depicts an illustrative embodiment of a communication device <b>800</b>. Communication device <b>800</b> can serve in whole or in part as an illustrative embodiment of the devices depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref> and <figref idref="DRAWINGS">FIG. <b>7</b></figref> and can also be configured to perform portions of method <b>600</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0056" num="0053">Communication device <b>800</b> can comprise a wireline and/or wireless transceiver <b>802</b> (herein transceiver <b>802</b>), a user interface (UI) <b>804</b>, a power supply <b>814</b>, a location receiver <b>816</b>, a motion sensor <b>818</b>, an orientation sensor <b>820</b>, and a controller <b>806</b> for managing operations thereof. The transceiver <b>802</b> can support short-range or long-range wireless access technologies such as Bluetooth&#xae;, ZigBee&#xae;, WiFi, DECT, or cellular communication technologies, just to mention a few (Bluetooth&#xae; and ZigBee&#xae; are trademarks registered by the Bluetooth&#xae; Special Interest Group and the ZigBee&#xae; Alliance, respectively). Cellular technologies can include, for example, CDMA-1&#xd7;, UMTS/HSDPA, GSM/GPRS, TDMA/EDGE, EV/DO, WiMAX, SDR, LTE, as well as other next generation wireless communication technologies as they arise. The transceiver <b>802</b> can also be adapted to support circuit-switched wireline access technologies (such as PSTN), packet-switched wireline access technologies (such as TCP/IP, VoIP, etc.), and combinations thereof.</p><p id="p-0057" num="0054">The UI <b>804</b> can include a depressible or touch-sensitive keypad <b>808</b> with a navigation mechanism such as a roller ball, a joystick, a mouse, or a navigation disk for manipulating operations of the communication device <b>800</b>. The keypad <b>808</b> can be an integral part of a housing assembly of the communication device <b>800</b> or an independent device operably coupled thereto by a tethered wireline interface (such as a USB cable) or a wireless interface supporting for example Bluetooth&#xae;. The keypad <b>808</b> can represent a numeric keypad commonly used by phones, and/or a QWERTY keypad with alphanumeric keys. The UI <b>804</b> can further include a display <b>810</b> such as monochrome or color LCD (Liquid Crystal Display), OLED (Organic Light Emitting Diode) or other suitable display technology for conveying images to an end user of the communication device <b>800</b>. In an embodiment where the display <b>810</b> is touch-sensitive, a portion or all of the keypad <b>808</b> can be presented by way of the display <b>810</b> with navigation features.</p><p id="p-0058" num="0055">The display <b>810</b> can use touch screen technology to also serve as a user interface for detecting user input. As a touch screen display, the communication device <b>800</b> can be adapted to present a user interface with graphical user interface (GUI) elements that can be selected by a user with a touch of a finger. The touch screen display <b>810</b> can be equipped with capacitive, resistive or other forms of sensing technology to detect how much surface area of a user's finger has been placed on a portion of the touch screen display. This sensing information can be used to control the manipulation of the GUI elements or other functions of the user interface. The display <b>810</b> can be an integral part of the housing assembly of the communication device <b>800</b> or an independent device communicatively coupled thereto by a tethered wireline interface (such as a cable) or a wireless interface.</p><p id="p-0059" num="0056">The UI <b>804</b> can also include an audio system <b>812</b> that utilizes audio technology for conveying low volume audio (such as audio heard in proximity of a human ear) and high volume audio (such as speakerphone for hands free operation). The audio system <b>812</b> can further include a microphone for receiving audible signals of an end user. The audio system <b>812</b> can also be used for voice recognition applications. The UI <b>804</b> can further include an image sensor <b>813</b> such as a charged coupled device (CCD) camera for capturing still or moving images.</p><p id="p-0060" num="0057">The power supply <b>814</b> can utilize common power management technologies such as replaceable and rechargeable batteries, supply regulation technologies, and/or charging system technologies for supplying energy to the components of the communication device <b>800</b> to facilitate long-range or short-range portable applications. Alternatively, or in combination, the charging system can utilize external power sources such as DC power supplied over a physical interface such as a USB port or other suitable tethering technologies.</p><p id="p-0061" num="0058">The location receiver <b>816</b> can utilize location technology such as a global positioning system (GPS) receiver capable of assisted GPS for identifying a location of the communication device <b>800</b> based on signals generated by a constellation of GPS satellites, which can be used for facilitating location services such as navigation. The motion sensor <b>818</b> can utilize motion sensing technology such as an accelerometer, a gyroscope, or other suitable motion sensing technology to detect motion of the communication device <b>800</b> in three-dimensional space. The orientation sensor <b>820</b> can utilize orientation sensing technology such as a magnetometer to detect the orientation of the communication device <b>800</b> (north, south, west, and east, as well as combined orientations in degrees, minutes, or other suitable orientation metrics).</p><p id="p-0062" num="0059">The communication device <b>800</b> can use the transceiver <b>802</b> to also determine a proximity to a cellular, WiFi, Bluetooth&#xae;, or other wireless access points by sensing techniques such as utilizing a received signal strength indicator (RSSI) and/or signal time of arrival (TOA) or time of flight (TOF) measurements. The controller <b>806</b> can utilize computing technologies such as a microprocessor, a digital signal processor (DSP), programmable gate arrays, application specific integrated circuits, and/or a video processor with associated storage memory such as Flash, ROM, RAM, SRAM, DRAM or other storage technologies for executing computer instructions, controlling, and processing data supplied by the aforementioned components of the communication device <b>800</b>.</p><p id="p-0063" num="0060">Other components not shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref> can be used in one or more embodiments of the subject disclosure. For instance, the communication device <b>800</b> can include a reset button (not shown). The reset button can be used to reset the controller <b>806</b> of the communication device <b>800</b>. In yet another embodiment, the communication device <b>800</b> can also include a factory default setting button positioned, for example, below a small hole in a housing assembly of the communication device <b>800</b> to force the communication device <b>800</b> to re-establish factory settings. In this embodiment, a user can use a protruding object such as a pen or paper clip tip to reach into the hole and depress the default setting button. The communication device <b>800</b> can also include a slot for adding or removing an identity module such as a Subscriber Identity Module (SIM) card. SIM cards can be used for identifying subscriber services, executing programs, storing subscriber data, and so forth.</p><p id="p-0064" num="0061">The communication device <b>800</b> as described herein can operate with more or less of the circuit components shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. These variant embodiments can be used in one or more embodiments of the subject disclosure.</p><p id="p-0065" num="0062">The communication device <b>800</b> can be adapted to perform the functions of communications device <b>108</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the media processor <b>706</b>, the media devices <b>708</b>, or the portable communication devices <b>716</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>. It will be appreciated that the communication device <b>700</b> can also represent other devices that can operate in OTT video system <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> and communication system <b>700</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref> such as a gaming console and a media player. In addition, the controller <b>706</b> can be adapted in various embodiments to perform the functions <b>762</b>, <b>764</b>, <b>766</b>.</p><p id="p-0066" num="0063">Upon reviewing the aforementioned embodiments, it would be evident to an artisan with ordinary skill in the art that said embodiments can be modified, reduced, or enhanced without departing from the scope of the claims described below. For example, other sources of Internet traffic can be measured. In additional embodiments, other forms of Internet service quality or data rates can be estimated and then optimized. Other embodiments can be used in the subject disclosure.</p><p id="p-0067" num="0064">It should be understood that devices described in the exemplary embodiments can be in communication with each other via various wireless and/or wired methodologies. The methodologies can be links that are described as coupled, connected and so forth, which can include unidirectional and/or bidirectional communication over wireless paths and/or wired paths that utilize one or more of various protocols or methodologies, where the coupling and/or connection can be direct (e.g., no intervening processing device) and/or indirect (e.g., an intermediary processing device such as a router).</p><p id="p-0068" num="0065"><figref idref="DRAWINGS">FIG. <b>9</b></figref> depicts an exemplary diagrammatic representation of a machine in the form of a computer system <b>900</b> within which a set of instructions, when executed, may cause the machine to perform any one or more of the methods described above. For example, one or more instances of the machine can operate, for example, as the estimator <b>730</b>, the media processor <b>706</b>, communications device <b>108</b>, as well as the delivery systems for providing and optimizing the OTT video services and other devices of <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>5</b></figref>. In some embodiments, the machine may be connected (e.g., using a network <b>926</b>) to other machines. In a networked deployment, the machine may operate in the capacity of a server or a client user machine in a server-client user network environment, or as a peer machine in a peer-to-peer (or distributed) network environment.</p><p id="p-0069" num="0066">The machine may comprise a server computer, a client user computer, a personal computer (PC), a tablet, a smart phone, a laptop computer, a desktop computer, a control system, a network router, switch or bridge, or any machine capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that machine. It will be understood that a communication device of the subject disclosure includes broadly any electronic device that provides voice, video or data communication. Further, while a single machine is illustrated, the term &#x201c;machine&#x201d; shall also be taken to include any collection of machines that individually or jointly execute a set (or multiple sets) of instructions to perform any one or more of the methods discussed herein.</p><p id="p-0070" num="0067">The computer system <b>900</b> may include a processor (or controller) <b>902</b> (e.g., a central processing unit (CPU)), a graphics processing unit (GPU, or both), a main memory <b>904</b> and a static memory <b>906</b>, which communicate with each other via a bus <b>908</b>. The computer system <b>900</b> may further include a display unit <b>910</b> (e.g., a liquid crystal display (LCD), a flat panel, or a solid state display). The computer system <b>900</b> may include an input device <b>912</b> (e.g., a keyboard), a cursor control device <b>914</b> (e.g., a mouse), a disk drive unit <b>916</b>, a signal generation device <b>918</b> (e.g., a speaker or remote control) and a network interface device <b>920</b>. In distributed environments, the embodiments described in the subject disclosure can be adapted to utilize multiple display units <b>910</b> controlled by two or more computer systems <b>900</b>. In this configuration, presentations described by the subject disclosure may in part be shown in a first of the display units <b>910</b>, while the remaining portion is presented in a second of the display units <b>910</b>.</p><p id="p-0071" num="0068">The disk drive unit <b>916</b> may include a tangible computer-readable storage medium <b>922</b> on which is stored one or more sets of instructions (e.g., software <b>924</b>) embodying any one or more of the methods or functions described herein, including those methods illustrated above. The instructions <b>924</b> may also reside, completely or at least partially, within the main memory <b>904</b>, the static memory <b>906</b>, and/or within the processor <b>902</b> during execution thereof by the computer system <b>900</b>. The main memory <b>904</b> and the processor <b>902</b> also may constitute tangible computer-readable storage media.</p><p id="p-0072" num="0069">Dedicated hardware implementations including, but not limited to, application specific integrated circuits, programmable logic arrays and other hardware devices can likewise be constructed to implement the methods described herein. Application specific integrated circuits and programmable logic array can use downloadable instructions for executing state machines and/or circuit configurations to implement embodiments of the subject disclosure. Applications that may include the apparatus and systems of various embodiments broadly include a variety of electronic and computer systems. Some embodiments implement functions in two or more specific interconnected hardware modules or devices with related control and data signals communicated between and through the modules, or as portions of an application-specific integrated circuit. Thus, the example system is applicable to software, firmware, and hardware implementations.</p><p id="p-0073" num="0070">In accordance with various embodiments of the subject disclosure, the operations or methods described herein are intended for operation as software programs or instructions running on or executed by a computer processor or other computing device, and which may include other forms of instructions manifested as a state machine implemented with logic components in an application specific integrated circuit or field programmable gate array. Furthermore, software implementations (e.g., software programs, instructions, etc.) including, but not limited to, distributed processing or component/object distributed processing, parallel processing, or virtual machine processing can also be constructed to implement the methods described herein. Distributed processing environments can include multiple processors in a single machine, single processors in multiple machines, and/or multiple processors in multiple machines. It is further noted that a computing device such as a processor, a controller, a state machine or other suitable device for executing instructions to perform operations or methods may perform such operations directly or indirectly by way of one or more intermediate devices directed by the computing device.</p><p id="p-0074" num="0071">While the tangible computer-readable storage medium <b>922</b> is shown in an example embodiment to be a single medium, the term &#x201c;tangible computer-readable storage medium&#x201d; should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and/or associated caches and servers) that store the one or more sets of instructions. The term &#x201c;tangible computer-readable storage medium&#x201d; shall also be taken to include any non-transitory medium that is capable of storing or encoding a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methods of the subject disclosure. The term &#x201c;non-transitory&#x201d; as in a non-transitory computer-readable storage includes without limitation memories, drives, devices and anything tangible but not a signal per se.</p><p id="p-0075" num="0072">The term &#x201c;tangible computer-readable storage medium&#x201d; shall accordingly be taken to include, but not be limited to: solid-state memories such as a memory card or other package that houses one or more read-only (non-volatile) memories, random access memories, or other re-writable (volatile) memories, a magneto-optical or optical medium such as a disk or tape, or other tangible media which can be used to store information. Accordingly, the disclosure is considered to include any one or more of a tangible computer-readable storage medium, as listed herein and including art-recognized equivalents and successor media, in which the software implementations herein are stored.</p><p id="p-0076" num="0073">Although the present specification describes components and functions implemented in the embodiments with reference to particular standards and protocols, the disclosure is not limited to such standards and protocols. Each of the standards for Internet and other packet switched network transmission (e.g., TCP/IP, UDP/IP, HTML, HTTP) represent examples of the state of the art. Such standards are from time-to-time superseded by faster or more efficient equivalents having essentially the same functions. Wireless standards for device detection (e.g., RFID), short-range communications (e.g., Bluetooth&#xae;, WiFi, Zigbee&#xae;), and long-range communications (e.g., WiMAX, GSM, CDMA, LTE) can be used by computer system <b>900</b>. In one or more embodiments, information regarding use of services can be generated including services being accessed, media consumption history, user preferences, and so forth. This information can be obtained by various methods including user input, detecting types of communications (e.g., video content vs. audio content), analysis of content streams, and so forth. The generating, obtaining and/or monitoring of this information can be responsive to an authorization provided by the user. In one or more embodiments, an analysis of data (e.g., packet traffic) can be subject to authorization from user(s) associated with the data, such as an opt-in, an opt-out, acknowledgement requirements, notifications, selective authorization based on types of data, and so forth. In one or more embodiments, analysis of traffic can be performed in limited ways, such as based on analysis of particular headers (e.g., without analyzing payloads). Other analysis can be performed via sampling, which may or may not be limited to headers.</p><p id="p-0077" num="0074">The illustrations of embodiments described herein are intended to provide a general understanding of the structure of various embodiments, and they are not intended to serve as a complete description of all the elements and features of apparatus and systems that might make use of the structures described herein. Many other embodiments will be apparent to those of skill in the art upon reviewing the above description. The exemplary embodiments can include combinations of features and/or steps from multiple embodiments. Other embodiments may be utilized and derived therefrom, such that structural and logical substitutions and changes may be made without departing from the scope of this disclosure. Figures are also merely representational and may not be drawn to scale. Certain proportions thereof may be exaggerated, while others may be minimized. Accordingly, the specification and drawings are to be regarded in an illustrative rather than a restrictive sense.</p><p id="p-0078" num="0075">Although specific embodiments have been illustrated and described herein, it should be appreciated that any arrangement which achieves the same or similar purpose may be substituted for the embodiments described or shown by the subject disclosure. The subject disclosure is intended to cover any and all adaptations or variations of various embodiments. Combinations of the above embodiments, and other embodiments not specifically described herein, can be used in the subject disclosure. For instance, one or more features from one or more embodiments can be combined with one or more features of one or more other embodiments. In one or more embodiments, features that are positively recited can also be negatively recited and excluded from the embodiment with or without replacement by another structural and/or functional feature. The steps or functions described with respect to the embodiments of the subject disclosure can be performed in any order. The steps or functions described with respect to the embodiments of the subject disclosure can be performed alone or in combination with other steps or functions of the subject disclosure, as well as from other embodiments or from other steps that have not been described in the subject disclosure. Further, more than or less than all of the features described with respect to an embodiment can also be utilized.</p><p id="p-0079" num="0076">Less than all of the steps or functions described with respect to the exemplary processes or methods can also be performed in one or more of the exemplary embodiments. Further, the use of numerical terms to describe a device, component, step or function, such as first, second, third, and so forth, is not intended to describe an order or function unless expressly stated so. The use of the terms first, second, third and so forth, is generally to distinguish between devices, components, steps or functions unless expressly stated otherwise. Additionally, one or more devices or components described with respect to the exemplary embodiments can facilitate one or more functions, where the facilitating (e.g., facilitating access or facilitating establishing a connection) can include less than every step needed to perform the function or can include all of the steps needed to perform the function.</p><p id="p-0080" num="0077">In one or more embodiments, a processor (which can include a controller or circuit) has been described that performs various functions. It should be understood that the processor can be multiple processors, which can include distributed processors or parallel processors in a single machine or multiple machines. The processor can be used in supporting a virtual processing environment. The virtual processing environment may support one or more virtual machines representing computers, servers, or other computing devices. In such virtual machines, components such as microprocessors and storage devices may be virtualized or logically represented. The processor can include a state machine, application specific integrated circuit, and/or programmable gate array including a Field PGA. In one or more embodiments, when a processor executes instructions to perform &#x201c;operations&#x201d;, this can include the processor performing the operations directly and/or facilitating, directing, or cooperating with another device or component to perform the operations.</p><p id="p-0081" num="0078">The Abstract of the Disclosure is provided with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition, in the foregoing Detailed Description, it can be seen that various features are grouped together in a single embodiment for the purpose of streamlining the disclosure. This method of disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather, as the following claims reflect, inventive subject matter lies in less than all features of a single disclosed embodiment. Thus the following claims are hereby incorporated into the Detailed Description, with each claim standing on its own as a separately claimed subject matter.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230007328A1-20230105-M00001.NB"><img id="EMI-M00001" he="15.49mm" wi="76.20mm" file="US20230007328A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A device comprising:<claim-text>a processing system including a processor; and</claim-text><claim-text>a memory that stores executable instructions that, when executed by the processing system, facilitate performance of operations, the operations comprising:</claim-text><claim-text>determining a first target video rate from a traffic pattern, wherein the traffic pattern is determined based upon monitoring network traffic, wherein the network traffic includes a first video stream utilizing a first video transmission scheme, wherein the network traffic includes a second video stream utilizing a second, different, video transmission scheme, wherein the first video transmission scheme includes a first video chunk size, a first video coding, and a first number of flows, and wherein the second video transmission scheme includes a second video chunk size, a second video coding, and a second number of flows;</claim-text><claim-text>adjusting the first target video rate based upon predicted network traffic, wherein the adjusting results in a second target video rate;</claim-text><claim-text>transmitting a third video stream to meet the second target video rate when an end user device is capable of displaying video with the second target video rate; and</claim-text><claim-text>transmitting a fourth video stream to meet the first target video rate when the end user device is incapable of displaying video with the second target video rate.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second video chunk size is different from the first video chunk size.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second video coding is different from the first video coding.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second number of flows is different from the first number of flows.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining the first target video rate comprises applying a water-filling algorithm to a plurality of values corresponding to a respective number of bytes monitored according to the traffic pattern.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the adjusting the first target video rate is based in part on a subscriber agreement.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the operations further comprise:<claim-text>adjusting a network resource allocation based on the adjusting of the first target video rate.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The device of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the network resource allocation is adjusted to facilitate a group of individual video streams to meet the second target video rate at each of a plurality of time slots.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the monitoring of the network traffic includes monitoring bytes in a time series.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The device of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the monitoring of the bytes is performed over a recurring period.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining the first target video rate comprises determining an optimized video rate to provide a particular video playback quality for an over-the-top video delivery service network to individual subscribers.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the monitoring of the network traffic comprises applying a network probe to capture network packets.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the monitoring of the network traffic comprises performing an analysis on the network packets to determine a network throughput.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the monitoring of the network traffic comprises analyzing packet headers of network packets, and wherein the packet headers are analyzed without performing a payload analysis.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A method comprising:<claim-text>determining, by a processing system including a processor, a first target video rate based on network traffic, wherein the network traffic includes a first video stream utilizing a first video transmission scheme, wherein the network traffic includes a second video stream utilizing a second, different, video transmission scheme, wherein the first video transmission scheme includes a first video chunk size, a first video coding, and a first number of flows, wherein the second video transmission scheme includes a second, different, video chunk size, a second, different, video coding, and a second, different, number of flows;</claim-text><claim-text>adjusting, by the processing system, the first target video rate based upon predicted network traffic, wherein the adjusting results in a second target video rate;</claim-text><claim-text>transmitting, by the processing system, a third video stream to meet the second target video rate when an end user device is capable of displaying video with the second target video rate; and</claim-text><claim-text>transmitting, by the processing system, a fourth video stream to meet the first target video rate when the end user device is incapable of displaying video with the second target video rate.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the determining of the first target video rate is based on applying a water-filling algorithm to a plurality of values corresponding to a respective number of monitored bytes.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the adjusting the first target video rate is based in part on a subscriber agreement.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising:<claim-text>monitoring, by the processing system, the network traffic by applying a network probe to capture network packets; and</claim-text><claim-text>performing, by the processing system, an analysis on the network packets to determine a network throughput.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising:<claim-text>monitoring, by the processing system, the network traffic;</claim-text><claim-text>obtaining, by the processing system and based on the monitoring of the network traffic, packet headers; and</claim-text><claim-text>analyzing, by the processing system, the packet headers without performing a payload analysis.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A non-transitory machine-readable medium comprising executable instructions that, when executed by a processing system including a processor, facilitate performance of operations, the operations comprising:<claim-text>determining a first target video rate from a traffic pattern, wherein the traffic pattern is determined based upon network traffic, wherein the network traffic includes a first video stream utilizing a first video transmission scheme, wherein the network traffic includes a second video stream utilizing a second, different, video transmission scheme, wherein the first video transmission scheme includes a first video chunk size, a first video coding, and a first number of flows, and wherein the second video transmission scheme includes a second video chunk size, a second video coding, and a second number of flows;</claim-text><claim-text>adjusting the first target video rate based upon predicted network traffic, wherein the adjusting results in a second target video rate;</claim-text><claim-text>transmitting a third video stream to meet the second target video rate when an end user device is capable of displaying video with the second target video rate; and</claim-text><claim-text>transmitting a fourth video stream to meet the first target video rate when the end user device is incapable of displaying video with the second target video rate.</claim-text></claim-text></claim></claims></us-patent-application>
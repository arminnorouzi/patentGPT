<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005508A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005508</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17856905</doc-number><date>20220701</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>11</class><subclass>B</subclass><main-group>27</main-group><subgroup>031</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>44</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>783</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>11</class><subclass>B</subclass><main-group>27</main-group><subgroup>031</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>44</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>783</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">METHOD OF MERGING DIGITAL MEDIA</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63218297</doc-number><date>20210703</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Logitech Europe S.A.</orgname><address><city>Lausanne</city><country>CH</country></address></addressbook><residence><country>CH</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MANERI</last-name><first-name>Thomas</first-name><address><city>San Diego</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>KAISER</last-name><first-name>Sean Elliot</first-name><address><city>Vancouver</city><country>CA</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>SOKOLOV</last-name><first-name>Lev</first-name><address><city>Vancouver</city><country>CA</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>URS</last-name><first-name>Ashray Sameer</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Embodiments herein provide for methods of dividing selected areas of a first video clip having a first composition, e.g., by generating individual video data corresponding to the selected areas, arranging the selected areas to provide a second composition, e.g., by combining the individual video data to generate composite video data corresponding to the second composition, and compiling the composite video data to provide a second video clip having the second composition.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="102.19mm" wi="158.75mm" file="US20230005508A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="176.19mm" wi="104.06mm" file="US20230005508A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="247.99mm" wi="160.44mm" orientation="landscape" file="US20230005508A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="152.48mm" wi="151.64mm" file="US20230005508A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims benefit of U.S. provisional patent application Ser. No. 63/218,297, filed Jul. 3, 2021, which is herein incorporated by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Field</heading><p id="p-0003" num="0002">Embodiments of the present invention generally relate to methods of generating media content and, more particularly, to video editing methods for generating a composite video clip suitable for a first display configuration from a video clip generated from a livestream application formatted for a second display configuration.</p><heading id="h-0004" level="1">Description of the Related Art</heading><p id="p-0004" num="0003">The online video industry has grown rapidly since YouTube made it simple to share online videos in 2005. Netflix introduced its streaming video service in 2007, followed by Hulu in 2008. All three services focused on pre-recorded video, also known as Video-On-Demand (&#x201c;VOD&#x201d;) until YouTube introduced YouTube Live in 2008. It marked the first easily accessible implementation of a live streaming video service.</p><p id="p-0005" num="0004">Similarly, video games have evolved from single or multiplayer experiences shared around a single TV to complicated, internet-based multiplayer games that allow hundreds of thousands of players to participate in shared gaming experiences. Fans of video games historically used magazines such as GamePro Magazine to stay abreast of new game releases, uncover otherwise difficult-to-find game secrets, and learn how to optimize their gameplay. Eventually, the medium was replaced by YouTube channels dedicated to video game content.</p><p id="p-0006" num="0005">The popularity of online video game content led to the founding of a new class of Streaming Services: Twitch, founded in 2011, and YouTube Gaming, which came online in 2015. These services allowed players to broadcast their gaming experiences directly to the world. Streaming Services differ from the aforementioned Netflix, Hulu, and YouTube products because they focus on streaming live video instead of pre-recorded VOD content. Today Twitch serves over 170 million visitors every month, and unlike YouTube's VOD product, which primarily serves short-form video, the average Twitch visitor views over an hour of streaming content. In the present disclosure, the term Streaming Services refers to one or more services designed to stream live video content via a digital channel including, but not limited to, Twitch, YouTube Gaming, Mixer, and Facebook Live.</p><p id="p-0007" num="0006">These extended viewing times are enabled by video game fans' voracious appetite for video game content and by Streaming Services such as Twitch or YouTube Gaming providing tools to enable users, the streamers, broadcasting their games to monetize the time they spend streaming their game sessions. These tools include allowing viewers to sign up for a monthly subscription to the channel of specific streamers whose personality or gameplay they enjoy, a chat panel for viewers to chat with each other and the streamer, and extensive application programming interfaces (APIs) for developers to build applications that interface with the Streaming Services. Many streamers can make a substantial living through Streaming Services and the ecosystems they have created. A primary source of income for streamers is donations from viewers, who are more likely to donate during an interactive live stream where the streamer can encourage the donations, the viewers can see the streamer's reaction to the donations, and the streamer can publically thank the individual viewers for the donation.</p><p id="p-0008" num="0007">Key visual elements of the broadcast, such as chat panes, the streamer's local camera feed, and stock or custom overlays, can help streamers engage with their viewers and monetize their channel. Overlays can provide static images, such as decorative video borders or animated graphics that respond in real time to the actions of the viewers or the game. Due to the instantaneous and live nature of video streamed to a Streaming Service, it is not possible to edit a video before it goes live using traditional video editing software. Thus, the desired key visual elements are arranged within the video to provide a desired composition before or concurrently with the video being encoded and sent to Streaming Services for viewer consumption. The composition of the video, e.g., the position and sizing of the individual visual elements over the live video game, can be based on the most likely and desirable display format used by viewers of the interactive live feed. For example, the composition may be configured for viewing on a desktop or laptop display having an HD widescreen aspect ratio of 16:9 (1080p) for viewers who desire to watch and engage with the broadcast for extended periods, e.g., up to an hour or more.</p><p id="p-0009" num="0008">In addition, to live broadcasts, streamers can record their previously streamed video (Past Broadcasts) and publish the recordings to an online video streaming platform as a Video on Demand (VOD) so that fans can watch broadcast events that they were unable to view live. The Past Broadcast recordings may be archived on the Streaming Service account, and the individual visual elements can be arranged to provide a desired composition before the recording is compiled into a format suitable for uploading to the video streaming platform, such as an mp4, mov, avi, or gif format. Streamers can create highlights of their Past Broadcasts by extracting and publishing one or more segments of the recorded Past Broadcast video. Like the recorded Past Broadcasts, the individual visual elements of highlights can be arranged to provide a desired composition before the highlights are published for viewer consumption or compiled into a format suitable for uploading to a video streaming platform. The streamer can use highlights to showcase their best content to new viewers and engage existing viewers when they are not live. However, conventional software that is used to edit and merge the highlights is often complicated, requires multiple repetitive steps, and thus requires a significant amount of time for the streamer to generate and upload the compiled highlight in a desired format that is compatible with the video streaming platform running on a separate user's electronic device.</p><p id="p-0010" num="0009">Viewers and streamers can record and share clips of the streamer's live broadcasts, published Past Broadcasts (VOD), and highlights. Clips are short-form videos that allow viewers and streamers to capture unique or memorable moments from the broadcast event. Clips can be shared through links and uploaded to various media platforms to aid streamers in growing their audience through social sharing. A clip can be a single video segment that incorporates the visual elements of the broadcast in an encoding format suitable for uploading to the social media platform. Unfortunately, the aspect ratio and orientation of the clip, such as the 16:9 widescreen format, is undesirable for viewing on mobile social media applications, such as TikTok&#xae; or Instagram&#xae; where users prefer to view content in portrait mode (e.g., so they don't have to turn their phone sideways). Further, while suitable for a larger display such as a desktop or laptop monitor, the composition of the clip may be less than desirable for a mobile display.</p><p id="p-0011" num="0010">Accordingly, there is a need in the art for a system and methods that solve the problems described above.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0012" num="0011">One embodiment provides a method for generating an output video clip, the method comprising: displaying on a first electronic device an input video clip in an editing screen of an editing preview application; defining a plurality of layers for display in the editing preview application, the plurality of layers including a first layer comprising a first portion of the input video clip and a second layer comprising a second portion of the input video clip; adjusting one or more characteristics of at least one of the first layer and the second layer; forming an output video clip having a plurality of regions; causing the output video clip to be generated from the preview; and causing the output video clip to be transmitted for display on an application running on a second electronic device, wherein the plurality of regions of the output video clip is configured to be displayed in an output video format of the application running on the second electronic device. The plurality of regions of the output video clip each comprise a different layer of the plurality of layers, and the characteristics of the layers in the regions of the plurality of regions, which include the adjusted at least one of the first layer and the second layer, are more similar to each than the characteristics of the initially defined plurality of layers are to each other.</p><p id="p-0013" num="0012">Embodiments of the disclosure may also provide a method for generating an output video clip, the method comprising: displaying on a first electronic device an input video clip in an editing screen of an editing preview application; defining a plurality of layers for display in the editing preview application, the plurality of layers including a first layer comprising a first portion of the input video clip and a second layer comprising a second portion of the input video clip; adjusting one or more characteristics of at least one of the first layer and the second layer; forming an output video clip having a plurality of regions; causing the output video clip to be generated from the preview; and causing the output video clip to be transmitted to a second electronic device. In some embodiments, the plurality of regions each comprise a different layer of the plurality of layers, and the characteristics of the layers in the regions of the plurality of regions, which include the adjusted at least one of the first layer and the second layer, are more similar to each than the characteristics of the initially defined plurality of layers are to each other. In some embodiments, the first layer comprises game content and the second layer comprises a view of a user's camera. In some embodiments, the output video clip has an output format selected for a social media application operated by the second electronic device.</p><p id="p-0014" num="0013">Embodiments of the disclosure may also provide a system for generating an output video clip, the system comprising a processor, and a memory having loaded therein for execution by the processor an edit preview application. The edit preview application is configured to display on a first electronic device an input video clip in an editing screen of an editing preview application, define a plurality of layers for display in the editing preview application, the plurality of layers including a first layer comprising a first portion of the input video clip and a second layer comprising a second portion of the input video clip, adjust characteristics of at least one of the first layer and the second layer; form an output video clip in which the first layer and the second layer are each disposed in separate regions of a plurality of regions formed within the output video clip, wherein the adjusted characteristics of the at least one of the first layer and the second layer makes characteristics of the first layer and the second layer more similar to each other; cause the output video clip to be generated from the preview; and cause the output video clip to be transmitted for display on an application running on a second electronic device, wherein the plurality of regions of the output video clip is configured to be displayed in an output video format of the application running on the second electronic device.</p><p id="p-0015" num="0014">Embodiments of the disclosure may also provide a non-transitory computer-readable medium comprising instructions that are executable in a processor of a computer system to carry out a method of scheduling a plurality of workloads for execution in a cluster of nodes. The method comprising: displaying on a first electronic device an input video clip in an editing screen of an editing preview application; defining a plurality of layers for display in the editing preview application, the plurality of layers including a first layer comprising a first portion of the input video clip and a second layer comprising a second portion of the input video clip; adjusting characteristics of at least one of the first layer and the second layer to provide an output video clip having a plurality of regions, each corresponding to one of the layers in the plurality of layers; causing the output video clip to be generated from the preview; and causing the output video clip to be transmitted for display on an application running on a second electronic device, wherein the plurality of regions of the output video clip is configured to be displayed in an output video format of the application running on the second electronic device. The output video clip is a composition of the plurality of regions corresponding to the plurality of layers, and adjusting the characteristics of the regions makes characteristics of the regions more similar to each than the characteristics of the corresponding plurality of layers are to each other.</p><p id="p-0016" num="0015">Embodiments of the disclosure may also provide a method of generating an output video clip. The method includes displaying on a first electronic device an input video clip in an editing screen of an editing preview application, where the input video clip may be but is not limited to a short form content video obtained from a live stream. The method further includes defining a plurality of layers for display in the editing preview application, where the plurality of layers includes a first layer comprising a first portion of the input video clip and a second layer comprising a second portion of the input video clip. The method further includes adjusting the characteristics of at least one of the first and second layers to provide an output video clip with a plurality of regions, where each region corresponds to one of the layers in the plurality of layers. The output video clip is a composition of the plurality of regions corresponding to the plurality of layers with characteristics of the regions adjusted to make them more similar to each other than the corresponding layers are to each other. The method further includes causing the output video clip to be generated from the preview and causing the output video clip to be transmitted for display on an application running on a second electronic device, where the plurality of regions of the output video clip is configured to be displayed in an output video format of the application running on the second electronic device.</p><p id="p-0017" num="0016">Embodiments of the disclosure may also provide a method for generating an output video clip, comprising: displaying on a first electronic device an input video clip in an editing screen of an editing preview application; defining a plurality of layers for display in the editing preview application, the plurality of layers including a first layer comprising a first portion of the input video clip, and a second layer comprising a second portion of the input video clip; adjusting, by use of the editing preview application, characteristics of at least one of the first layer and the second layer; forming, by use of the editing preview application, an output video clip having a plurality of regions; causing the output video clip to be generated from the preview; and causing the output video clip to be transmitted to a second electronic device. In some embodiments, the plurality of regions each comprise a different layer of the plurality of layers, and the characteristics of each layer of the plurality of layers corresponding to a region of the plurality of regions, which include the adjusted at least one of the first layer and the second layer, are more similar to each than the characteristics of the defined plurality of layers are to each other.</p><p id="p-0018" num="0017">In the embodiment, the characteristics of the layers of the input video clip include size, position, aspect ratio, frame rate, audio, and background color. The start point in time and ending point in time of portions of the input video clip may be selected.</p><p id="p-0019" num="0018">In other embodiments, the generation of the output video clip includes the removal of backgrounds from a portion of the input video clip, smart text generation from chats received during the playing of the input video clip, addition of audio streams to the output video clip, and volume stabilization throughout the output video clip.</p><p id="p-0020" num="0019">In other embodiments, parameters are sent to a third electronic device along with the input video clip, and the third electronic device generates the output video clip based on the received parameters.</p><p id="p-0021" num="0020">In other embodiments, the output video clip is automatically generated for and sent to several second electronic devices, each with a different format.</p><p id="p-0022" num="0021">Further embodiments include a computer-readable medium containing instructions for carrying out one more aspects of the above method and a system configured to carry out one or more aspects of the above method.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0023" num="0022">So that the manner in which the above-recited features of the present disclosure can be understood in detail, a more particular description of the disclosure, briefly summarized above, may be had by reference to embodiments, some of which are illustrated in the appended drawings. It is to be noted, however, that the appended drawings illustrate only exemplary embodiments and are therefore not to be considered limiting of its scope, may admit to other equally effective embodiments.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a media content generation scheme that may be used to perform the methods herein.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts a user interface display generated by a video editing application executed on a user device, according to one embodiment.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts a diagram of a method of generating media content, according to one embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0027" num="0026">To facilitate understanding, identical reference numerals have been used, where possible, to designate identical elements that are common to the figures. It is contemplated that elements and features of one embodiment may be beneficially incorporated in other embodiments without further recitation.</p><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0028" num="0027">In embodiments described herein, editing software includes displaying an input video clip on an editing screen of a first electronic device, where the input video clip may be, but is not limited to, a short form video obtained from a live stream. In the editing screen, a number of layers are defined, each with different content and each having characteristics that include an aspect ratio, a position in the editing screen, a frame rate, and possibly an audio stream. The editing software allows the user to preview the video layers and format an output video clip according to selections made in a dropdown box or according to pre-set arrangements in the editing software. The editing software allows the user to adjust the preview by adjusting the characteristics of regions in the output video clip corresponding to the layers in the input video clip. The user may also adjust the previewed input video clip's start and end. The adjusted preview can then be compiled to generate the output video clip, and while the parameters defining the compilation are retained. The editing software creates the output video clip or sends the parameters and the input video clip to another device which generates the output video clip using the received parameters. An automated process may generate and send output video clips to multiple viewing devices, where each output video clip is targeted to the format needed by the different viewing devices.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a media generation scheme <b>100</b> that may be used to divide selected areas of a first video clip having a first composition, arrange the selected areas to provide a second composition, and compile the composite video data to provide a second video clip having the second composition. The second video clip can then be transmitted to an electronic device, wherein the second video clip is formatted so that it can be displayed on an application that is running on the electronic device.</p><p id="p-0030" num="0029">The media generation scheme <b>100</b> includes a user device <b>102</b>, a server <b>104</b>, a source for input videos, such as a live-streaming platform <b>106</b>, configured to generate short-form videos (e.g., clips of live streaming events hosted thereon), and (optionally) a mobile device <b>108</b>. The media generation scheme <b>100</b> further includes a network <b>116</b> that facilitates communication between the user device <b>102</b> and the server <b>104</b> and between the server <b>104</b> and the live streaming platform <b>106</b>. The network <b>116</b> generally represents any data communication network suitable for transmitting media content, which can include video and/or audio data (e.g., the Internet), between different locations.</p><p id="p-0031" num="0030">Examples of the user device <b>102</b> can include, without limitation, a laptop, a personal computer, a tablet, a smartphone, a virtual or augmented reality computing device, or any related personal computing device. The user device <b>102</b> includes an edit preview application <b>118</b> stored in a non-volatile memory of the user device <b>102</b>. The edit preview application <b>118</b>, when executed by a processor of the user device <b>102</b>, is configured to receive an input video clip <b>202</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) from an input video source, provide a preview <b>222</b> of a desired output video composition based on user input, determine compositional parameters for the desired output video composition, save the compositional parameters and upload the input video clip <b>202</b> and the compositional parameters to the server <b>104</b>. The server <b>104</b> can be a &#x201c;headless server&#x201d; and includes a video editing application <b>120</b> stored in a non-volatile memory of the server <b>104</b>. The video editing application <b>120</b>, when executed by a processor of the server <b>104</b>, is configured to crop video data from the input video clip <b>202</b> according to the compositional parameters, generate composite video data corresponding to the desired output video composition, and compile the composite video data to provide an output video clip in a predetermined format, such as a format suitable for uploading to a mobile social media application stored in a memory of the mobile device <b>108</b>.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts a schematic representation of a user interface, e.g., an editing screen <b>200</b>, generated by the edit preview application <b>118</b> when executed by the user device <b>102</b>.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts a method <b>300</b> of transforming media content for display on the mobile device <b>108</b> using the media generation scheme <b>100</b> described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to one embodiment. Aspects of the method <b>300</b> are described with reference to the user interface (editing screen <b>200</b>) depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0034" num="0033">In activity <b>302</b>, the method <b>300</b> includes displaying an input video clip <b>202</b> in an editing screen <b>200</b> of the edit preview application <b>118</b> (editing preview application). Here, the input video clip <b>202</b> has a first aspect ratio, a first orientation, and one or more first dimensions that define an input video area <b>204</b> in the editing screen <b>200</b>. As shown, the input video clip comprises a short-form video generated from a Livestream video gaming session, e.g., a driving simulation game. In this example, the Livestream included a display of the driving simulation game <b>208</b>, a video game content window <b>211</b>, and a camera feed <b>210</b> of the streamer to facilitate engagement with the streamer's fans. In some embodiments, the input video clip is formatted for displaying its content in a horizontal landscape orientation.</p><p id="p-0035" num="0034">In activity <b>304</b>, the method <b>300</b> includes defining a plurality of video layers <b>220</b> from the input video clip <b>202</b>, the plurality of video layers <b>220</b> comprising a first video layer <b>220</b>A corresponding to a first region (the game content region) of the input video area <b>204</b>, a second video layer <b>220</b>B corresponding to a second region of the input video area <b>204</b> (the streamer's camera region), and (optionally) a third video layer <b>220</b>C corresponding to a third region of the input video area <b>204</b> (a speedometer portion of the video game content window <b>211</b>). In some embodiments, the layers are used to define and separate different portions of the individual frames of the input video clip. The individual frames used to form the layers may each include different characteristics, such as aspect ratio, position within the video area <b>204</b>, resolution, frame rate, and audio characteristics, for example, that are derived from the source of the video content.</p><p id="p-0036" num="0035">During activity <b>304</b> the edit preview application <b>118</b> utilizes pre-set user-defined settings that are used to define the desired content of each of the layers. Based on the user's (e.g., streamer's) knowledge of the structure or characteristics of the input video area <b>204</b> the user utilizes aspects of the edit preview application <b>118</b> to define the desired portions of the input video area <b>204</b>, which are used to form each of the layers that are eventually transmitted and displayed on one or more external electronic devices, such as the mobile device <b>108</b>. Typically, the layout of the input video area <b>204</b> of the input video includes a pre-set fixed configuration, and thus the content of the layers for all input videos received and processed by the edit preview application <b>118</b> does not require significant adjustment of the pre-set user-defined settings. Characteristics of the layers, such as aspect ratio, position, and/or background color depending on the particular layer, may be locked by a user using a layer menu <b>226</b> in the editing preview application <b>118</b>. For example, a camera region may require a minimum number of pixels to prevent the region from becoming blurry, while a text region may require a white background to make the text readable. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the layer menu <b>226</b> may include a plurality of categories that include one or more selections that each include embedded commands that are used by the edit preview application <b>118</b> to adjust one or more characteristics of the layers.</p><p id="p-0037" num="0036">In activity <b>306</b>, the method <b>300</b> includes displaying the plurality of video layers <b>220</b> in an output preview area <b>212</b> in the editing screen <b>200</b> to generate a preview of an output video clip that is to be sent to a second electronic device and displayed thereon. The output preview area <b>212</b> may be determined through user input or by determining, using the edit preview application <b>118</b>, a desired media format for an output video clip. The desired media format may have a second resolution, a second aspect ratio, and one or more second dimensions that define the output preview area <b>212</b> when displayed on the editing screen. Generally, the desired media format is based on a selection by a user of a predetermined media format from a plurality of predetermined media formats (dropdown box <b>214</b>), the plurality of predetermined media formats corresponding to desired formats of corresponding social media applications. In some embodiments, the output preview area <b>212</b> is determined by a second resolution, a second aspect ratio, and one or more second dimensions of a video stream formatted for displaying the content of the output video clip in a desired orientation (e.g., vertical portrait orientation) on the mobile device, such as on a mobile application of TikTok, Facebook or Instagram.</p><p id="p-0038" num="0037">In some embodiments, the method <b>300</b> includes defining a plurality of regions <b>216</b> in the output preview area <b>212</b> according to one or more pre-sets. In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the plurality of regions <b>216</b> includes a first region <b>216</b>A, a second region <b>216</b>B, and a third region <b>216</b>C, where each of the plurality of regions are different from the other ones in one or more of size, location of the region within the preview, and aspect ratio. In some embodiments, the plurality of regions <b>216</b> in the output preview area <b>212</b> is defined using one of a plurality of pre-set arrangements <b>218</b> selected by a user of the editing preview application <b>118</b>.</p><p id="p-0039" num="0038">In activity <b>308</b>, the method <b>300</b> includes, based on user input, adjusting a characteristic of one or more of the regions <b>216</b> that is to be used to form the output video clip. In some embodiments, the characteristic comprises a size, position, aspect ratio, and/or background color, of one or more of the plurality of regions <b>216</b> in the output preview area <b>212</b>, one or more of the plurality of video layers <b>220</b>, or a combination thereof, to provide a desired composition of a to-be-generated output video clip. Here, the desired composition corresponds to the preview <b>222</b> of the output preview area <b>212</b> at the time a user requests compiling the output video clip through the edit preview application <b>118</b>. In some embodiments, the method <b>300</b> further includes adjusting a beginning and end of the output video clip, e.g., by using the slider <b>224</b> on the editing screen.</p><p id="p-0040" num="0039">In some embodiments of activity <b>308</b>, the process includes forming an output video clip having a plurality of regions, wherein the plurality of regions each comprise a layer. Due to the adjustments performed to one or more of the layers during activity <b>308</b>, the characteristics of the layers disposed within each of the regions, whether they required an adjustment or not, will be more similar to each other than the same layers that were originally defined during activity <b>304</b>. In this way, the plurality of layers displayed in the output video clip will appear more uniform and/or have less visual or audio related defects than the original portions of the input video clip or audio that were defined during activity <b>304</b>.</p><p id="p-0041" num="0040">In some embodiments of activity <b>308</b>, the process includes upscaling or downscaling the video or audio data in one or more of the layers so that the images captured within each layer are configured to fit in their respective region of the output video clip and/or to normalize the appearance of the layers disposed within each of the regions. In one example, each of the layers in the output video clip has a similar resolution and scale.</p><p id="p-0042" num="0041">In activity <b>310</b>, the method includes generating the output video clip. In some embodiments, the method <b>300</b> includes generating, based on the preview <b>222</b> of the output video clip area <b>112</b>, output compilation parameters that can be used to generate the output video clip. In some embodiments, the server <b>204</b> generates the output video clip, and the method includes transmitting the output compilation parameters and the input video clip to the server <b>204</b>. In some embodiments, the method <b>300</b> includes transmitting the input video clip <b>202</b> and the output compilation parameters to a headless worker software found on the server <b>204</b> to generate the output video clip. In some embodiments, the method <b>300</b> includes receiving the compilation parameters for generating the output video clip and generating the output video clip using the headless worker software.</p><p id="p-0043" num="0042">In some embodiments, generating the output video clip includes setting the characteristics of the regions to be more similar to each other than the layers of the input video clip are to each other. Thus, the aspect ratio, position, and frame rate of each layer are adjusted to make each region more like the other regions than the corresponding layers were in the input video clip. This adjustment improves the quality of the output video clip because the resolution of the output video clip does not degrade (e.g., pixelate) some regions over other regions.</p><p id="p-0044" num="0043">In some embodiments, generating the output video clip during activity <b>310</b> includes transcribing audio data, chat text or other related text information formed during and/or associated with the input video clip and generate a text representation of the audio data, chat text or other related text information in the output video clip. In some embodiments, the transcribed audio data or a chat information provided in the output video clip is provided as a banner within a region of the output video clip. In one example, the transcribed audio data or chat text provided in a banner may replace or supplement the second region <b>216</b>B in the output preview area <b>212</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0045" num="0044">In some embodiments, generating the output video clip includes removing or altering the background from portions of the input video clip because some native backgrounds may make audio data, chat text or other text unreadable. In some embodiments, the edit preview application <b>118</b> is configured to automatically alter or remove portions of a chat text, such as filler words or other undesirable text.</p><p id="p-0046" num="0045">In some embodiments, generating the output video clip includes adding an audio stream to the output video clip. The audio stream may be generated during or associated with the generation of the input video clip. As noted above, the audio stream may be transcribed and presented in the output video clip in a banner.</p><p id="p-0047" num="0046">In some embodiments, generating the output video clip includes providing pre-set or automatic adjustments to the layers of the input video clip by the edit preview application <b>118</b> to stabilize and or damp undesirable characteristics of the input video clip, such as adjust the amount of noise, adjust audio volumes or remove silence from one or more portions of the input video clip.</p><p id="p-0048" num="0047">In some embodiments, generating the output video clip includes cropping portions of the input video clip <b>202</b> to generate individual video data corresponding to the plurality of layers <b>220</b>, combining the video data according to the compilation parameters to generate composite video data, and compiling the composite video data, e.g., by selecting the compile feature to provide a single output video clip having a composition corresponding to the desired preview of the preview <b>222</b> of the output preview area <b>212</b>. For example, in the output video clip depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, only a portion of the second input layer <b>220</b>B and only a portion of the third video layer are present in the corresponding regions.</p><p id="p-0049" num="0048">In some embodiments, as part of activity <b>310</b>, regions in the output video clip are stitched together, wherein a region displaying content that is the same as in another region allows the regions to be connected seamlessly by their common content regions. In some embodiments, two or more input video clips, which were formed at different times, are stitched together automatically by the edit preview application <b>118</b> or by use of user input, wherein a transition between the different video clips is substantially seamless due to the smoothing of characteristics of the input video clip in adjacent portions of each of the layers formed in the serially positioned input video clips. The process of stitching together two or more input video clips may also include inserting pre-set video data that is configured to smooth the transition between adjacently positioned input video clips.</p><p id="p-0050" num="0049">In activity <b>312</b>, the method includes transmitting the output video clip to a second electronic device, e.g., a mobile phone <b>108</b>, for display thereon. In some embodiments, the second electronic device is configured to display the output video clip in a second aspect ratio, a second orientation, and one or more second dimensions that are based on the desired output format, where at least one of the second aspect ratio, the second orientation, and one or more second dimensions are different from at least one of the first aspect ratio, the first orientation, and the one or more first dimensions.</p><p id="p-0051" num="0050">In some embodiments, by use of the edit preview application <b>118</b>, the output video clip is automatically formatted for a number of second electronic devices configured to display the output video clip and sent by use of one or more communication links to each device. In activity <b>312</b>, the method may include transmitting the output video clip to a plurality of electronic devices that are each configured to display the output video clip in one or more aspect ratios, orientations, and/or one or more dimensions that are based on the desired output format for the receiving electronic device of the plurality of electronic devices.</p><p id="p-0052" num="0051">While the foregoing is directed to embodiments of the present disclosure, other and further embodiments of the disclosure may be devised without departing from the basic scope thereof, and the scope thereof is determined by the claims that follow.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for generating an output video clip, the method comprising:<claim-text>displaying on a first electronic device an input video clip in an editing screen of an editing preview application;</claim-text><claim-text>defining a plurality of layers for display in the editing preview application, the plurality of layers including a first layer comprising a first portion of the input video clip and a second layer comprising a second portion of the input video clip;</claim-text><claim-text>adjusting one or more characteristics of at least one of the first layer and the second layer;</claim-text><claim-text>forming an output video clip having a plurality of regions, wherein<claim-text>the plurality of regions each comprise a different layer of the plurality of layers, and</claim-text><claim-text>the characteristics of the layers in the regions of the plurality of regions, which include the adjusted at least one of the first layer and the second layer, are more similar to each than the characteristics of the initially defined plurality of layers are to each other;</claim-text></claim-text><claim-text>causing the output video clip to be generated from the preview; and</claim-text><claim-text>causing the output video clip to be transmitted to a second electronic device.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising sending parameters and the input video clip to a third electronic device, wherein the output video clip is generated by the third electronic device using the input video clip and the parameters.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising:<claim-text>generating, using the first electronic device, the parameters based on a preview of the output video clip;</claim-text><claim-text>saving the parameters using the first electronic device; and</claim-text><claim-text>transmitting the parameters to the third electronic device,</claim-text><claim-text>wherein the third electronic device uses the parameters to generate the output video clip.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the characteristics include at least one of an aspect ratio, position within a video area, resolution, frame rate, and audio characteristics.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the input video clip comprises short-form video content generated from a live-streaming event.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the input video clip has a resolution and an aspect ratio for displaying its content in a horizontal landscape orientation.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the preview of the output video clip has a resolution and an aspect ratio for displaying content of the output video clip in a vertical portrait orientation on the second electronic device.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first layer comprises game content and the second layer comprises a view of a user's camera.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A system for generating an output video clip, the system comprising:<claim-text>a processor; and</claim-text><claim-text>a memory having loaded therein for execution by the processor an edit preview application, wherein the edit preview application is configured to:<claim-text>display on a first electronic device an input video clip in an editing screen of an editing preview application;</claim-text><claim-text>define a plurality of layers for display in the editing preview application, the plurality of layers including a first layer comprising a first portion of the input video clip and a second layer comprising a second portion of the input video clip;</claim-text><claim-text>adjust characteristics of at least one of the first layer and the second layer;</claim-text><claim-text>form an output video clip in which the first layer and the second layer are each disposed in separate regions of a plurality of regions formed within the output video clip, wherein the adjusted characteristics of the at least one of the first layer and the second layer makes characteristics of the first layer and the second layer more similar to each other;</claim-text><claim-text>cause the output video clip to be generated from the preview; and</claim-text><claim-text>cause the output video clip to be transmitted for display on an application running on a second electronic device, wherein the plurality of regions of the output video clip is configured to be displayed in an output video format of the application running on the second electronic device.</claim-text></claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>,<claim-text>wherein the edit preview application is further configured to send parameters and the input video clip to a third electronic device,</claim-text><claim-text>wherein the output video clip is generated by the third electronic device using the input video clip and the parameters.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the editing preview application is further configured to:<claim-text>generate, using the first electronic device, the parameters based on the preview of the output video clip;</claim-text><claim-text>save the parameters using the first electronic device for re-use in generating the output video; and</claim-text><claim-text>transmit the parameters to the third electronic device, wherein the third electronic device uses the parameters to generate the output video clip.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the characteristics include an aspect ratio, position within a video area, resolution, frame rate, and audio characteristics.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the input video clip comprises short-form video content generated from a live-streaming event on a live-streaming service.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the input video clip has an aspect ratio for displaying its content in a horizontal landscape orientation.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the preview of the output video clip has a resolution and an aspect ratio for displaying content of the output video clip in a vertical portrait orientation on the second electronic device.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A non-transitory computer-readable medium comprising instructions that are executable in a processor of a computer system to carry out a method of scheduling a plurality of workloads for execution in a cluster of nodes, the method comprising:<claim-text>displaying on a first electronic device an input video clip in an editing screen of an editing preview application;</claim-text><claim-text>defining a plurality of layers for display in the editing preview application, the plurality of layers including a first layer comprising a first portion of the input video clip and a second layer comprising a second portion of the input video clip; and</claim-text><claim-text>adjusting characteristics of at least one of the first layer and the second layer to provide an output video clip having a plurality of regions, each corresponding to one of the layers in the plurality of layers, wherein<claim-text>the output video clip is a composition of the plurality of regions corresponding to the plurality of layers, and</claim-text><claim-text>adjusting the characteristics of the regions makes characteristics of the regions more similar to each than the characteristics of the corresponding plurality of layers are to each other;</claim-text></claim-text><claim-text>causing the output video clip to be generated from the preview; and</claim-text><claim-text>causing the output video clip to be transmitted to a second electronic device, wherein the plurality of regions of the output video clip is configured to be displayed in an output video format of an application running on a third electronic device.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, the method further comprising:<claim-text>generating, using the first electronic device, the parameters based on the preview of the output video clip;</claim-text><claim-text>saving the parameters using the first electronic device; and</claim-text><claim-text>transmitting the parameters to the second electronic device,</claim-text></claim-text><claim-text>wherein the second electronic device uses the parameters to generate the output video clip.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the output video clip has an output format selected for a social media application operated by the second electronic device.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the preview of the output video clip has a resolution and an aspect ratio for displaying content of the output video clip in a vertical portrait orientation on the second electronic device.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A method for generating an output video clip, comprising:<claim-text>displaying on a first electronic device an input video clip in an editing screen of an editing preview application;</claim-text><claim-text>defining a plurality of layers for display in the editing preview application, the plurality of layers including<claim-text>a first layer comprising a first portion of the input video clip, and</claim-text><claim-text>a second layer comprising a second portion of the input video clip;</claim-text></claim-text><claim-text>adjusting, by use of the editing preview application, characteristics of at least one of the first layer and the second layer;</claim-text><claim-text>forming, by use of the editing preview application, an output video clip having a plurality of regions, wherein<claim-text>the plurality of regions each comprise a different layer of the plurality of layers, and</claim-text><claim-text>the characteristics of each layer of the plurality of layers corresponding to a region of the plurality of regions, which include the adjusted at least one of the first layer and the second layer, are more similar to each than the characteristics of the defined plurality of layers are to each other;</claim-text></claim-text><claim-text>causing the output video clip to be generated from the preview; and</claim-text><claim-text>causing the output video clip to be transmitted to a second electronic device.</claim-text></claim-text></claim></claims></us-patent-application>
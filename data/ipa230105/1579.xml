<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230001580A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230001580</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17784916</doc-number><date>20201222</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>DE</country><doc-number>10 2019 135 810.8</doc-number><date>20191227</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>25</class><subclass>J</subclass><main-group>9</main-group><subgroup>16</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>25</class><subclass>J</subclass><main-group>13</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>25</class><subclass>J</subclass><main-group>9</main-group><subgroup>1664</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>25</class><subclass>J</subclass><main-group>13</main-group><subgroup>085</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>25</class><subclass>J</subclass><main-group>13</main-group><subgroup>088</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>25</class><subclass>J</subclass><main-group>9</main-group><subgroup>161</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>B</subclass><main-group>2219</main-group><subgroup>40599</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>B</subclass><main-group>2219</main-group><subgroup>40607</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">GENERATING A CONTROL PROGRAM FOR A ROBOT MANIPULATOR</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Franka Emika GmbH</orgname><address><city>M&#xfc;nchen</city><country>DE</country></address></addressbook><residence><country>DE</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Spenninger</last-name><first-name>Andreas</first-name><address><city>Karlsfeld</city><country>DE</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Medina Hernandez</last-name><first-name>Jose Ramon</first-name><address><city>M&#xfc;nchen</city><country>DE</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/EP2020/087557</doc-number><date>20201222</date></document-id><us-371c12-date><date>20220613</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method of generating a control program, wherein the method includes: executing an application by the first robot manipulator, at the same time, determining trajectory data and/or wrench data, determining robot commands from a stored time series, the robot commands being principal elements of the control program for the robot manipulator without relation to design conditions of a first robot manipulator, and generating the control program for a second robot manipulator based on the stored robot commands and based on the design conditions of the second robot manipulator.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="138.18mm" wi="132.25mm" file="US20230001580A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="223.86mm" wi="134.28mm" file="US20230001580A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application is the U.S. National Phase of PCT/EP2020/087557, filed on 22 Dec. 2020, which claims priority to German Patent Application No. 10 2019 135 810.8, filed on 27 Dec. 2019, the entire contents of which are incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Field</heading><p id="p-0003" num="0002">The invention relates to a method for generating a control program for a second robot manipulator based on empirical data from executing a predetermined application by a first robot manipulator, and to a robot system having a first control unit and a second control unit for performing the method.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0004" num="0003">It is the object of the invention to simplify the generation of a control program for executing a task by a robot manipulator.</p><p id="p-0005" num="0004">The invention results from the features of the independent claims. Advantageous developments and embodiments are the subject of the dependent claims.</p><p id="p-0006" num="0005">A first aspect of the invention relates to a method of generating a control program for a second robot manipulator based on empirical data from executing a predetermined application by a first robot manipulator, the method including:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0006">executing the predetermined application by the first robot manipulator;</li>        <li id="ul0002-0002" num="0007">during execution of the predetermined application: obtaining time series of trajectory data by joint angle sensors of the first robot manipulator and/or time series of wrench data by a sensor unit of the first robot manipulator for detecting forces and/or torques, and storing the obtained time series in a storage unit, wherein the trajectory data include kinematic data relating to a reference point of the first robot manipulator or with respect to the joint angles of the first robot manipulator, and wherein the wrench data include forces and/or torques acting between the first robot manipulator and an object in the surroundings;</li>        <li id="ul0002-0003" num="0008">determining robot commands from the stored time series and storing the determined robot commands in the storage unit, the robot commands being principal elements of a control program for a respective robot manipulator without reference to the design conditions of the first robot manipulator; and</li>        <li id="ul0002-0004" num="0009">generating the control program for the second robot manipulator based on the stored robot commands and based on design conditions of the second robot manipulator.</li>    </ul>    </li></ul></p><p id="p-0007" num="0010">Furthermore, the next step preferably takes place:<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0011">executing the control program for the second robot manipulator by the second robot manipulator, in particular, by the second control unit of the second robot manipulator.</li>    </ul>    </li></ul></p><p id="p-0008" num="0012">The first robot manipulator and the second robot manipulator are not necessarily similar or of the same design, but may also have different technical solutions and designs. The first robot manipulator is, in particular, connected to such a (first) control unit, which is designed for executing a first control program in order to execute the predetermined application. This first control program is, in particular, optimized for the first robot manipulator, that is it takes into account the technical conditions and design solutions at the first robot manipulator, so that the application can be executed by the first robot manipulator altogether, whereby the first control program is, in particular, also optimized for the design conditions of the first robot manipulator. All steps of the method according to the first aspect of the invention are preferably carried out by the first control unit. Alternatively, the control program for the second robot manipulator is preferably generated by a second control unit different from the first control unit.</p><p id="p-0009" num="0013">In the first step of the method according to the first aspect of the invention, the predetermined application is executed by the first robot manipulator. Possible applications include, in particular, moving an object from one location to another, merely grasping the object, selecting an object from a plurality of objects, grasping the selected object, processing a surface of a work piece, or other tasks typical of a robot manipulator.</p><p id="p-0010" num="0014">During this execution of the predetermined application by the first robot manipulator, a time series of trajectory data is determined, in particular, by the first control unit. This is performed based on sensor values from joint angle sensors of the first robot manipulator. These joint angle sensors are designed, in particular, to detect and output a respective angle between two links of the first robot manipulator connected to each other by a common joint. In particular, this is performed repeatedly in discrete time steps and at high frequencies so that a time series of discrete joint angle data of the first robot manipulator is available. A pose of the first robot manipulator is thus known throughout all joint angles at each point in time, from which a path curve of a reference point of the first robot manipulator can be determined in Cartesian coordinate systems, in particular, with respect to a first fixed coordinate system.</p><p id="p-0011" num="0015">The reference point of the first robot manipulator is preferably notionally located at a distal end, and more preferably notionally located at an end effector, of the first robot manipulator. The concept of trajectory further includes a path curve, that is, the purely geometric information of a motion, either purely with respect to joint angles or (also) with respect to a Cartesian trajectory of the reference point of the first robot manipulator. Optionally, the concept of trajectory additionally includes time information, so that each location of the geometric path curve is also associated with a time, and a velocity and/or an acceleration of the reference point during the traversal of this geometric path curve are also known via the information of the geometric path curve.</p><p id="p-0012" num="0016">In addition or alternatively to the joint angle information, during this embodiment of the predetermined application, Cartesian information of a path curve or a trajectory based on the joint angle information is detected by the first robot manipulator, as well as, in particular, one or more forces and/or torques acting between the first robot manipulator and an object in the surroundings of the robot manipulator. The latter is performed, in particular, by the sensor unit for detecting forces and/or torques, preferably, torque sensors in the joints or also strain gauges on the robot structure, so that a time series of force-related interactions between the first robot manipulator and the surroundings are recorded.</p><p id="p-0013" num="0017">As a result, kinematic information and/or information regarding a force/torque during the execution of the predetermined application by the first robot manipulator are available. These data are each stored in time series, so that a history of the course of execution of the application is known.</p><p id="p-0014" num="0018">Robot commands are subsequently formed from this information of the time series. Such robot commands provide functional information about how the predetermined application is executed in general, based on how it was executed specifically by the first robot manipulator, regardless of the design conditions of the first robot manipulator. These robot commands thus do not include the conversion via the Jacobian matrix valid for the first robot manipulator or its (pseudo-)inverse, that is, it does not take into account how a movement of an object from a first location to a second location is to be executed specifically by controlling the actuators in relation to each other. The robot commands are therefore abstracted function blocks of a control program, which are to be executed in principle and independently of the architecture of the currently used robot manipulator. They basically therefore correspond to the commands of an outermost loop of a closed-loop control of the respective robot manipulator during the execution of the control program.</p><p id="p-0015" num="0019">Based on this abstracted information, a concrete control program for the second robot manipulator is then generated, wherein the complete control program for the second robot manipulator takes into account the design conditions of the second robot manipulator, in particular, how many joints the second robot manipulator has, whether it is a redundant or a unique second robot manipulator, what type of gripper or generally type of end effector is currently arranged on the second robot manipulator, etc.</p><p id="p-0016" num="0020">It is therefore an advantageous effect of the invention that a control program is provided for the second robot manipulator based on the empirically acquired data during the execution of the application by the first robot manipulator, which control program already contains the functionally essential information in the form of robot commands, and so that further sensors are not required for the second robot manipulator and for the application to be executed by it and its control program, in particular, in order to detect objects in the surroundings of the second robot manipulator, and, generally speaking, to adapt the control program for the second robot manipulator to the current situation. Rather, the execution of the application is based on the provided robot commands, which contain the empirically determined information of the execution of the application by the first robot manipulator. Advantageously, therefore, the generation of the control program for the second robot manipulator is significantly accelerated and simplified, since the latter can draw on information from executions of the applications that have already taken place, irrespective of whether the first robot manipulator is identical in construction to the second robot manipulator, or whether these two differ in terms of construction or configuration or software.</p><p id="p-0017" num="0021">According to an advantageous embodiment, the robot commands include at least one of the following categories:<ul id="ul0005" list-style="none">    <li id="ul0005-0001" num="0000">    <ul id="ul0006" list-style="none">        <li id="ul0006-0001" num="0022">a predetermined path curve of a reference point of the respective robot manipulator from a predetermined start point to a predetermined end point of the path curve;</li>        <li id="ul0006-0002" num="0023">a velocity of the reference point on the path curve;</li>        <li id="ul0006-0003" num="0024">an acceleration of the reference point on the path curve;</li>        <li id="ul0006-0004" num="0025">a force and/or a torque that the reference point of the respective robot manipulator exerts on an object in the surroundings of the respective robot manipulator; and</li>        <li id="ul0006-0005" num="0026">target torques for rotational actuators of the respective robot manipulator.</li>    </ul>    </li></ul></p><p id="p-0018" num="0027">According to a further advantageous embodiment, at least two successive robot commands from different categories are determined, wherein a blending transition between the two successive, categorically different robot commands is determined. The blending transition, in particular, causes the selected robot commands to transition to each other in a smooth transition. This corresponds to intuitive human behavior in which, for example, the sense of sight and the sense of touch are combined for haptically and visually coordinated action. For example, a transition from impedance closed-loop control and so-called &#x201c;visual servoing&#x201d; (optically guided path) is generated by a smooth function course without jumps as a weighting function.</p><p id="p-0019" num="0028">According to a further advantageous embodiment, the blending transition is performed by a continuous and over the time of the transition time-dependent predetermined function course. Such a continuous function course is, in particular, without jumps and kinks, and in particular, exhibits a strictly monotonically falling or rising progression over the time duration of the transition. Such a function course advantageously provides a particularly smooth transition between the applications of the robot commands.</p><p id="p-0020" num="0029">According to a further advantageous embodiment, the robot commands are determined from the stored time series by nonlinear optimization. Nonlinear optimization, in particular, uses a cost function that reflects the difference between the time series hypothetically performed by the selected commands and the time series actually performed. Such a cost function is then minimized by methods of nonlinear optimization, in particular, gradient-based methods, evolution methods, genetic algorithms, quadratic optimization methods, etc., so that, in particular, those robot commands are selected which, calculated backwards, lead to time series that also correspond to the actual time series. Thus, the best fitting robot commands are selected.</p><p id="p-0021" num="0030">According to a further advantageous embodiment, the robot commands are determined from the stored time series by applying a predetermined artificial neural network, wherein an input variable of the artificial neural network are the stored time series, and an output variable of the artificial neural network is a respective selected one of a plurality of at least structurally predetermined robot commands, wherein parameters of the respective selected one of the predetermined robot commands are adapted based on the stored time series. The advantage of an artificial neural network is the great flexibility and the broad class of functions that can be represented by the artificial neural network.</p><p id="p-0022" num="0031">According to a further advantageous embodiment, the determination of time series of trajectory data is additionally performed by a camera unit. The camera unit is preferably arranged on the robot manipulator itself. Moreover, the camera unit is preferably a stereo camera unit, so that advantageously spatial information about the path curve and/or the trajectory of the reference point of the robot manipulator is acquired by the camera unit. The information from the camera unit is preferably fused with or supplemented to the information from the joint angle sensors.</p><p id="p-0023" num="0032">According to a further advantageous embodiment, the camera unit is an external camera unit. The external camera unit is preferably arranged physically separate from the first robot manipulator on a frame or on another support in the surroundings of the first robot manipulator. Advantageously, information from non-robot sensors is thus also available, which can be optimally supplemented with the robot sensors to form altogether more reliable data sources.</p><p id="p-0024" num="0033">According to a further advantageous embodiment, the design conditions of the first robot manipulator and/or the second robot manipulator include at least one of the following:<ul id="ul0007" list-style="none">    <li id="ul0007-0001" num="0000">    <ul id="ul0008" list-style="none">        <li id="ul0008-0001" num="0034">distances between joints of the respective robot manipulator;</li>        <li id="ul0008-0002" num="0035">number of joints of the respective robot manipulator;</li>        <li id="ul0008-0003" num="0036">maximum torque that can be applied by rotational actuators of the respective robot manipulator;</li>        <li id="ul0008-0004" num="0037">type and configuration of an end effector of the respective robot manipulator;</li>        <li id="ul0008-0005" num="0038">virtual stiffness of a closed-loop control of the respective robot manipulator, in particular, the stiffness of a virtual spring in the closed-loop control, in particular, impedance closed-loop control;</li>        <li id="ul0008-0006" num="0039">material stiffness of links and/or joints of the respective robot manipulator;</li>        <li id="ul0008-0007" num="0040">a geometrically maximum possible working space of the respective robot manipulator;</li>        <li id="ul0008-0008" num="0041">time constants and/or bandwidths of actuators of the respective robot manipulator;</li>        <li id="ul0008-0009" num="0042">safety level and/or current safety configuration and/or residual risk of the respective robot manipulator;</li>        <li id="ul0008-0010" num="0043">physical existence and/or configuration of communication interfaces of the respective robot manipulator;</li>        <li id="ul0008-0011" num="0044">number of robot arms of the respective robot manipulator; and</li>        <li id="ul0008-0012" num="0045">mass and/or inertia of components, in particular links, of the respective robot manipulator.</li>    </ul>    </li></ul></p><p id="p-0025" num="0046">Another aspect of the invention relates to a robot system including a first control unit and a second control unit which together are used for generating a control program for a second robot manipulator of the robot system based on empirical data from executing a predetermined application by a first robot manipulator of the robot system, wherein the first control unit is designed to control the first robot manipulator to execute the predetermined application, and further is designed to determine time series of trajectory data by joint angle sensors of the first robot manipulator and/or time series of wrench data by a sensor unit of the first robot manipulator during the execution of the predetermined application, and to store the determined time series in a storage unit, wherein the trajectory data include kinematic data relating to a reference point of the first robot manipulator and/or relating to the joint angles of the first robot manipulator, and the wrench data include forces and/or torques acting between the first robot manipulator and an object in the surroundings, and wherein the first control unit is designed to determine robot commands from the stored time series and to store the determined robot commands in the storage unit, wherein the robot commands are principal elements of a control program for a respective robot manipulator without reference to the design conditions of the first robot manipulator, and wherein the second control unit is designed for generating the control program for the second robot manipulator based on the stored robot commands and based on design conditions of the second robot manipulator.</p><p id="p-0026" num="0047">Advantages and preferred further embodiments of the proposed robot system result from an analogous and mutatis mutandis transfer of the explanations made above in connection with the proposed method.</p><p id="p-0027" num="0048">Further advantages, features, and details result from the following description, in which<ul id="ul0009" list-style="none">    <li id="ul0009-0001" num="0000">    <ul id="ul0010" list-style="none">        <li id="ul0010-0001" num="0049">possibly with reference to the drawings&#x2014;at least one embodiment example is described in detail. Identical, similar, and/or functionally identical parts are referred to using the same reference numerals.</li>    </ul>    </li></ul></p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0028" num="0050">In the drawings:</p><p id="p-0029" num="0051"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a method of generating a control program for a second robot manipulator based on empirical data from executing a predetermined application by a first robot manipulator according to an example embodiment of the invention; and</p><p id="p-0030" num="0052"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a robot system for carrying out the method according to <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0031" num="0053">The representations in the figures are schematic and not to scale.</p><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0032" num="0054"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a method for generating a control program for a second robot manipulator <b>2</b> based on empirical data from executing a predetermined application by a first robot manipulator <b>1</b>. The following description of the method also refers to the robot system <b>10</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Therefore, both figures can be referred to for understanding, in particular, also the following mentioned reference signs refer to steps of <figref idref="DRAWINGS">FIG. <b>1</b></figref> as well as optionally to respective operations of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. In step S<b>1</b>, the execution of the predetermined application by the first robot manipulator <b>1</b> takes place. The application concerns the lifting out of a pointed object from a cylindrical box. For this purpose, a control program for the first robot manipulator <b>1</b> is predetermined, which is adapted to the design conditions of the first robot manipulator <b>1</b>, in particular, to the number of joints, the geometry of the links and the configuration with its gripper.</p><p id="p-0033" num="0055">During the execution of the application, in further step S<b>2</b>, the determination of time series of trajectory data by joint angle sensors <b>3</b> of the first robot manipulator <b>1</b> and of time series of wrench data by a sensor unit <b>5</b> of the first robot manipulator <b>1</b> takes place, wherein the joint angle sensors <b>3</b> together with the torque sensors of the sensor unit <b>5</b> for detecting forces and torques are accommodated in a respective joint of the first robot manipulator <b>1</b>. These determined time series are stored in a storage unit <b>7</b>. The trajectory data include data on a path curve with respect to a reference point of the first robot manipulator <b>1</b> of the first robot manipulator <b>1</b> by transforming the joint angles into a Cartesian position course of the reference point at the end effector of the first robot manipulator <b>1</b>. On the other hand, the wrench data include the forces and torques acting between the first robot manipulator <b>1</b> and the pointed object.</p><p id="p-0034" num="0056">Furthermore, in step S<b>3</b> the determination of robot commands from the stored time series and the storage of the determined robot commands in the storage unit <b>7</b> follows, wherein the robot commands are principal elements of a control program for a respective robot manipulator without reference to the design conditions of the first robot manipulator <b>1</b>. The composite robot commands include the predetermined path curve of the reference point of the first robot manipulator <b>1</b> from the box to a predetermined end point, thereby an acceleration of the reference point on the path curve, and a force and a torque exerted by the end effector at the reference point on the pointed object. These robot commands, when composed, result in a functional sequence of the application that is independent of the aforementioned design conditions of the first robot manipulator <b>1</b>. The robot commands are determined by applying an artificial neural network in that all the time series are fed to the artificial neural network as input variables and the combination of the robot commands follow as output by execution of the artificial neural network.</p><p id="p-0035" num="0057">This is followed in step S<b>4</b> by the generation of the control program for the second robot manipulator <b>2</b> based on the stored robot commands and based on design conditions of the second robot manipulator <b>2</b>. Further explanations of these can be found in the description of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0036" num="0058"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a robot system <b>10</b> having a first control unit <b>11</b> and a second control unit <b>12</b>, for generating a control program for a second robot manipulator <b>2</b> of the robot system <b>10</b> based on empirical data from executing a predetermined application by a first robot manipulator <b>1</b> of the robot system <b>10</b>. In this case, the robot manipulator <b>1</b> is a conventional one-arm robot manipulator without redundant degrees of freedom. In contrast, the second robot manipulator <b>2</b> is a two-arm robot manipulator. The design conditions of the two robot manipulators <b>1</b>, <b>2</b> therefore differ from each other. The first control unit <b>11</b> is arranged on the first robot manipulator <b>1</b> and is used to control the first robot manipulator <b>1</b> for the execution of the predetermined application, and to determine time series of trajectory data by joint angle sensors <b>3</b> of the first robot manipulator <b>1</b> and time series of wrench data by a sensor unit <b>5</b> of the first robot manipulator <b>1</b> during execution of the predetermined application, and to store the determined time series in a storage unit <b>7</b>. Furthermore, the first control unit <b>11</b> determines the robot commands from the stored time series and stores these determined robot commands in the storage unit <b>7</b>, which is part of the first control unit <b>11</b>. The second control unit <b>12</b> is arranged on the second robot manipulator <b>2</b> and is used to generate the control program for the second robot manipulator <b>2</b> based on the stored robot commands and based on design conditions of the second robot manipulator <b>2</b>.</p><p id="p-0037" num="0059">Although the invention has been further illustrated and explained in detail by preferred embodiments, the invention is not limited by the disclosed examples and other variations may be derived therefrom by those skilled in the art without departing from the scope of protection sought for the invention. It is therefore clear that a wide variety of possible variations exist. It is also clear that example embodiments mentioned are really only examples, which are not to be understood in any way as limiting, for example, the scope of protection, the possible applications or the configuration of the invention. Rather, the foregoing description and the figure description enable the person skilled in the art to implement the example embodiments in a concrete manner, whereby the person skilled in the art, being aware of the disclosed idea of the invention, can make a variety of changes, for example with respect to the function or the arrangement of individual elements mentioned in an example embodiment, without leaving the scope of protection defined by the claims and their legal equivalents, such as further explanations in the description.</p><heading id="h-0007" level="1">LIST OF REFERENCE NUMERALS</heading><p id="p-0038" num="0060"><b>1</b> first robot manipulator</p><p id="p-0039" num="0061"><b>2</b> second robot manipulator</p><p id="p-0040" num="0062"><b>3</b> joint angle sensors</p><p id="p-0041" num="0063"><b>5</b> sensor unit</p><p id="p-0042" num="0064"><b>7</b> storage unit</p><p id="p-0043" num="0065"><b>10</b> robot system</p><p id="p-0044" num="0066"><b>11</b> first control unit</p><p id="p-0045" num="0067"><b>12</b> second control unit</p><p id="p-0046" num="0068">S<b>1</b> executing</p><p id="p-0047" num="0069">S<b>2</b> determining</p><p id="p-0048" num="0070">S<b>3</b> determining</p><p id="p-0049" num="0071">S<b>4</b> generating</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of generating a control program for a second robot manipulator based on empirical data from executing a predetermined application by a first robot manipulator, the method comprising:<claim-text>executing the predetermined application by the first robot manipulator;</claim-text><claim-text>during execution of the predetermined application: determining time series of trajectory data by joint angle sensors of the first robot manipulator and/or time series of wrench data by a sensor unit of the first robot manipulator for detecting forces and/or torques, and storing the determined time series in a storage unit, the trajectory data comprising kinematic data relating to a reference point of the first robot manipulator or relating to the joint angles of the first robot manipulator, and the wrench data comprising forces and/or torques acting between the first robot manipulator and an object in the surroundings;</claim-text><claim-text>determining robot commands from the stored time series, and storing the determined robot commands in the storage unit, the robot commands being principal elements of a control program for a respective robot manipulator without reference to design conditions of the first robot manipulator; and</claim-text><claim-text>generating the control program for the second robot manipulator based on the stored robot commands and based on design conditions of the second robot manipulator.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the robot commands comprise at least one category of different categories comprising:<claim-text>a predetermined path curve of a reference point of the respective robot manipulator from a predetermined start point to a predetermined end point of the predetermined path curve;</claim-text><claim-text>a velocity of the reference point on the predetermined path curve;</claim-text><claim-text>an acceleration of the reference point on the predetermined path curve;</claim-text><claim-text>a force and/or a torque that the reference point of the respective robot manipulator exerts on an object in the surroundings of the respective robot manipulator; and</claim-text><claim-text>target torques for rotational actuators of the respective robot manipulator.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the method comprises:<claim-text>determining at least two successive robot commands from the different categories; and</claim-text><claim-text>determining a blending transition between the at least two successive robot commands from the different categories.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the method further comprises performing the blending transition by a continuous, and over time of the blending transition, a time-dependent predetermined function course.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the method further comprises performing nonlinear optimization in determination of the robot commands from the stored time series.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein in determination of the robot commands from the stored time series, the method further comprises:<claim-text>applying a predetermined artificial neural network, an input variable of the artificial neural network being the stored time series and an output variable of the artificial neural network being a respectively selected one of a plurality of structurally predetermined robot commands; and</claim-text><claim-text>adapting parameters of the respectively selected one of the predetermined robot commands based on the stored time series.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determination of the time series of trajectory data is additionally performed by a camera unit.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the camera unit is an external camera unit.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the design conditions of the first robot manipulator and/or the design conditions of the second robot manipulator comprise at least one of the following:<claim-text>distances between joints of the respective robot manipulator;</claim-text><claim-text>number of joints of the respective robot manipulator;</claim-text><claim-text>maximum torque that is capable of being applied by rotational actuators of the respective robot manipulator;</claim-text><claim-text>type and configuration of an end effector of the respective robot manipulator;</claim-text><claim-text>virtual stiffness of a closed-loop control of the respective robot manipulator;</claim-text><claim-text>material stiffness of links and/or joints of the respective robot manipulator;</claim-text><claim-text>a geometrically maximum possible working space of the respective robot manipulator;</claim-text><claim-text>time constants and/or bandwidths of actuators of the respective robot manipulator;</claim-text><claim-text>safety level, and/or current safety configuration, and/or residual risk of the respective robot manipulator;</claim-text><claim-text>physical existence and/or configuration of communication interfaces of the respective robot manipulator;</claim-text><claim-text>number of robot arms of the respective robot manipulator; and</claim-text><claim-text>mass and/or inertia of components, in particular links, of the respective robot manipulator.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A robot system to generate a control program for a second robot manipulator of the robot system based on empirical data from executing a predetermined application by a first robot manipulator of the robot system, the robot system comprising:<claim-text>a first control unit configured to:<claim-text>control the first robot manipulator to execute the predetermined application, and further designed to determine time series of trajectory data by joint angle sensors of the first robot manipulator and/or time series of wrench data by a sensor unit of the first robot manipulator during execution of the predetermined application and to store the determined time series in a storage unit, the trajectory data comprising kinematic data relating to a reference point of the first robot manipulator or relating to the joint angles of the first robot manipulator, the wrench data comprising forces and/or torques acting between the first robot manipulator and an object in the surroundings; and</claim-text><claim-text>determine robot commands from the stored time series and to store the determined robot commands in the storage unit, the robot commands being principal elements of a control program for a respective robot manipulator without reference to design conditions of the first robot manipulator; and</claim-text></claim-text><claim-text>a second control unit configured to generate the control program for the second robot manipulator based on stored robot commands and based on design conditions of the second robot manipulator.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The robot system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the robot commands comprise at least one category of different categories comprising:<claim-text>a predetermined path curve of a reference point of the respective robot manipulator from a predetermined start point to a predetermined end point of the predetermined path curve;</claim-text><claim-text>a velocity of the reference point on the predetermined path curve;</claim-text><claim-text>an acceleration of the reference point on the predetermined path curve;</claim-text><claim-text>a force and/or a torque that the reference point of the respective robot manipulator exerts on an object in the surroundings of the respective robot manipulator; and</claim-text><claim-text>target torques for rotational actuators of the respective robot manipulator.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The robot system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the first control unit is further configured to:<claim-text>determine at least two successive robot commands from the different categories; and</claim-text><claim-text>determine a blending transition between the at least two successive robot commands from the different categories.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The robot system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the first control unit is further configured to perform the blending transition by a continuous, and over time of the blending transition, a time-dependent predetermined function course.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The robot system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the first control unit is further configured to perform nonlinear optimization in determination of the robot commands from the stored time series.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The robot system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein in determination of the robot commands from the stored time series, the first control unit is further configured to:<claim-text>apply a predetermined artificial neural network, an input variable of the artificial neural network being the stored time series and an output variable of the artificial neural network being a respectively selected one of a plurality of structurally predetermined robot commands; and</claim-text><claim-text>adapt parameters of the respectively selected one of the predetermined robot commands based on the stored time series.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The robot system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein determination of the time series of trajectory data is additionally performed by a camera unit.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The robot system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the camera unit is an external camera unit.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The robot system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the design conditions of the first robot manipulator and/or the design conditions of the second robot manipulator comprise at least one of the following:<claim-text>distances between joints of the respective robot manipulator;</claim-text><claim-text>number of joints of the respective robot manipulator;</claim-text><claim-text>maximum torque that is capable of being applied by rotational actuators of the respective robot manipulator;</claim-text><claim-text>type and configuration of an end effector of the respective robot manipulator;</claim-text><claim-text>virtual stiffness of a closed-loop control of the respective robot manipulator;</claim-text><claim-text>material stiffness of links and/or joints of the respective robot manipulator;</claim-text><claim-text>a geometrically maximum possible working space of the respective robot manipulator;</claim-text><claim-text>time constants and/or bandwidths of actuators of the respective robot manipulator;</claim-text><claim-text>safety level, and/or current safety configuration, and/or residual risk of the respective robot manipulator;</claim-text><claim-text>physical existence and/or configuration of communication interfaces of the respective robot manipulator;</claim-text><claim-text>number of robot arms of the respective robot manipulator; and</claim-text><claim-text>mass and/or inertia of components, in particular links, of the respective robot manipulator.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000446A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000446</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17490714</doc-number><date>20210930</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2021-0085999</doc-number><date>20210630</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>145</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>1455</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>7267</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>14546</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>7275</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>1455</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">APPARATUS AND METHOD FOR ESTIMATING LIPID CONCENTRATION</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>SAMSUNG ELECTRONICS CO., LTD.</orgname><address><city>Suwon-si</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant><us-applicant sequence="01" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Korea University Research and Business Foundation</orgname><address><city>Seoul</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>PARK</last-name><first-name>Yun S</first-name><address><city>Suwon-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Seoung Bum</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>KWON</last-name><first-name>Yong Joo</first-name><address><city>Yongin-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>KWAK</last-name><first-name>Mingu</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>CHO</last-name><first-name>Yoon Sang</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>MOK</last-name><first-name>Chunghyup</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="06" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Yeol Ho</first-name><address><city>Uiwang-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="07" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Joon Hyung</first-name><address><city>Seongnam-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="08" designation="us-only"><addressbook><last-name>JEONG</last-name><first-name>Kee Won</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="09" designation="us-only"><addressbook><last-name>BAE</last-name><first-name>Jinsoo</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>SAMSUNG ELECTRONICS CO., LTD.</orgname><role>03</role><address><city>Suwon-si</city><country>KR</country></address></addressbook></assignee><assignee><addressbook><orgname>Korea University Research and Business Foundation</orgname><role>03</role><address><city>Seoul</city><country>KR</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An apparatus for estimating lipid concentration is provided. According to an example embodiment, the apparatus may include a training data collector configured to collect, as training data, a reference lipid concentration measured through blood samples of a plurality of users for a predetermined time period and sensor data obtained through light signals detected from the plurality of users for the predetermined time period and a processor configured to perform preprocessing including a moving average and data augmentation on the obtained sensor data, select a valid variable relevant to a change in lipid concentration based on the preprocessed sensor data and the reference lipid concentration, and generate a lipid concentration prediction model based on the selected valid variable.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="31.75mm" wi="72.31mm" file="US20230000446A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="73.15mm" wi="74.34mm" file="US20230000446A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="167.30mm" wi="133.60mm" orientation="landscape" file="US20230000446A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="136.40mm" wi="75.44mm" file="US20230000446A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="208.53mm" wi="103.21mm" orientation="landscape" file="US20230000446A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="135.81mm" wi="70.53mm" file="US20230000446A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="117.77mm" wi="108.97mm" file="US20230000446A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="146.30mm" wi="119.04mm" file="US20230000446A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="137.84mm" wi="119.04mm" file="US20230000446A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="121.41mm" wi="82.47mm" file="US20230000446A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="121.67mm" wi="58.76mm" file="US20230000446A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION(S)</heading><p id="p-0002" num="0001">This application is based on and claims priority to Korean Patent Application No. 10-2021-0085999, filed on Jun. 30, 2021, in the Korean Intellectual Property Office, the entire disclosure of which is herein incorporated by reference for all purposes.</p><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">1. Field</heading><p id="p-0003" num="0002">The disclosure relates to lipid concentration estimation.</p><heading id="h-0004" level="1">2. Description of Related Art</heading><p id="p-0004" num="0003">With the aging population, increased medical costs, and a lack of medical personnel for specialized medical services, research is being actively conducted on information technology (IT)-medical convergence technologies, in which IT technology and medical technology are combined. Particularly, monitoring of a health condition of a human body may not be limited to places such as hospitals, but is expanded by mobile healthcare fields that may monitor a user's health condition anywhere (e.g., at home or office or in transit from one place to another place) and anytime in daily life. Some examples of bio-signals, which indicate the health condition of individuals, may include an electrocardiography (ECG) signal, a photoplethysmogram (PPG) signal, an electromyography (EMG) signal, and the like, and various bio-signal sensors are being developed to measure the bio-signals in daily life.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0005" num="0004">This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter.</p><p id="p-0006" num="0005">According to an aspect of an example embodiment, there is provided an apparatus for estimating lipid concentration, including: a training data collector configured to collect, as training data, a reference lipid concentration measured through blood samples of a plurality of users for a predetermined time period and sensor data obtained through light signals detected from the plurality of users for the predetermined time period; and a processor configured to perform preprocessing, including a moving average and data augmentation, on the obtained sensor data, configured to select a valid variable relevant to a change in lipid concentration based on the preprocessed sensor data and the reference lipid concentration, and configured to generate a lipid concentration prediction model based on the selected valid variable.</p><p id="p-0007" num="0006">The training data collector may further collect, as the training data, metadata including at least one of gender, age, height, weight, body mass index (BMI), skin temperature, or skin humidity of the plurality of users and the processor may select the valid variable based further on the collected metadata.</p><p id="p-0008" num="0007">The processor may perform preprocessing on a sensor data variable obtained over time for each user of the plurality of users using a cumulative weighted moving average, wherein a lower weight may be assigned to data farther from a central point of a predetermined moving average period unit.</p><p id="p-0009" num="0008">The processor may obtain additional sensor data by augmenting data based on the sensor data using a data augmentation technique including Gaussian blur.</p><p id="p-0010" num="0009">The processor may scale a senor data variable using an L-2 norm.</p><p id="p-0011" num="0010">The processor may classify the collected training data into at least two groups based on the reference lipid concentration and select the valid variable by comparing the training data between the classified at least two groups.</p><p id="p-0012" num="0011">The processor may select the valid variable by applying a nonparametric statistical test including a Wilcoxon rank-sum test to the training data in the classified groups.</p><p id="p-0013" num="0012">The processor may select the valid variable using an auto-encoder based on the training data.</p><p id="p-0014" num="0013">The processor may generate the lipid concentration prediction model based further on a machine learning model including at least one of partial least square (PLS), elastic net, random forest, gradient boosting machine (GBM), or XGBoost.</p><p id="p-0015" num="0014">The training data collector may include a light sensor provided in a pixel array, the pixel array including light sources configured to emit light toward an object and detectors configured to detect a light signal through light scattered or reflected from the object.</p><p id="p-0016" num="0015">The processor may drive a light source of a specific pixel and detectors of all pixels in the light sensor.</p><p id="p-0017" num="0016">The processor may sequentially drive light sources of pixels in a specific row of the pixel array and drive detectors in remaining rows of the pixel array while the light sources of the pixel in the specific row are being sequentially driven.</p><p id="p-0018" num="0017">The processor may sequentially drive light sources of all pixels of the pixel array and drive a detector of the same pixel as that of a driven light source while the light sources of all pixels are being sequentially driven.</p><p id="p-0019" num="0018">The processor may generate a personalized lipid concentration prediction model by performing a calibration based on the generated lipid concentration prediction model, a bio-signal obtained through a light signal detected from a specific user, and metadata of the specific user.</p><p id="p-0020" num="0019">According to an aspect of another example embodiment, there is provided a method of estimating lipid concentration, including: collecting, as training data, a reference lipid concentration measured through blood samples of a plurality of users for a predetermined time period and sensor data obtained through light signals detected from the plurality of users for the predetermined time period; performing preprocessing including a moving average and data augmentation on the obtained sensor data; selecting a valid variable relevant to a change in lipid concentration based on the preprocessed sensor data and the reference lipid concentration; and generating a lipid concentration prediction model based on the selected valid variable.</p><p id="p-0021" num="0020">The collecting may include further collecting, as the training data, metadata including at least one of gender, age, height, weight, body mass index (BMI), skin temperature, or skin humidity of the plurality of users and the selecting of the valid variable may include selecting the valid variable based further on the collected metadata.</p><p id="p-0022" num="0021">The performing the preprocessing may include obtaining additional sensor data by augmenting data based on the sensor data using a data augmentation technique including Gaussian blur.</p><p id="p-0023" num="0022">The selecting of the valid variable may include classifying the collected training data into at least two groups based on the reference lipid concentration and selecting the valid variable by comparing the training data between the classified at least two groups.</p><p id="p-0024" num="0023">The selecting of the valid variable by comparing the training data between the classified at least two groups may include selecting the valid variable by applying a nonparametric statistical test including a Wilcoxon rank-sum test to the training data in the classified at least two groups.</p><p id="p-0025" num="0024">The selecting of the valid variable may include selecting the valid variable using an auto-encoder based on the training data.</p><p id="p-0026" num="0025">Other features and aspects will be apparent from the following detailed description, the drawings, and the claims.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0027" num="0026">The above and other aspects, features, and advantages of certain example embodiments of the disclosure will be more apparent from the following description taken in conjunction with the accompanying drawings.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating an apparatus for estimating lipid concentration according to an example embodiment.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an apparatus for estimating lipid concentration according to an example embodiment.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIGS. <b>3</b>A, <b>3</b>B, and <b>3</b>C</figref> are diagrams for explaining a process in which a light source and a detector are driven in a light sensor formed of a pixel array.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram illustrating an apparatus for estimating lipid concentration according to an example embodiment.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart illustrating a method of estimating lipid concentration according to an example embodiment.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating a method of estimating lipid concentration according to an example embodiment.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating a wearable device according to an example embodiment.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating a smart device according to an example embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0036" num="0035">Details of example embodiments are provided in the following detailed description with reference to the accompanying drawings. Throughout the drawings and the detailed description, unless otherwise described, the same drawing reference numerals will be understood to refer to the same elements, features, and structures. The relative size and depiction of these elements may be exaggerated for clarity, illustration, and convenience. The disclosure may be understood more readily by reference to the following detailed description of example embodiments and the accompanying drawings. The disclosure may, however, be embodied in many different forms and should not be construed as being limited to the embodiments set forth herein. Rather, these embodiments are provided so that the disclosure will be thorough and complete and will fully convey the concept of the invention to those skilled in the art, and the disclosure will only be defined by the appended claims. Like reference numerals refer to like elements throughout the specification.</p><p id="p-0037" num="0036">It will be understood that, although the terms first, second, etc. may be used herein to describe various elements, these elements should not be limited by these terms. These terms are only used to distinguish one element from another. Also, the singular forms are intended to include the plural forms as well, unless the context clearly indicates otherwise. In the specification, unless explicitly described to the contrary, the word &#x201c;comprise&#x201d; and variations such as &#x201c;comprises&#x201d; or &#x201c;comprising,&#x201d; will be understood to imply the inclusion of stated elements but not the exclusion of any other elements. Terms such as &#x201c;unit&#x201d; and &#x201c;module&#x201d; denote units that process at least one function or operation, and they may be implemented by using hardware, software, or a combination of hardware and software.</p><p id="p-0038" num="0037">Hereinafter, example embodiments of the apparatus and method for estimating lipid concentration will be described in detail with reference to the drawings.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating an apparatus for estimating lipid concentration according to an example embodiment.</p><p id="p-0040" num="0039">Various example embodiments of the apparatus <b>100</b> for estimating lipid concentration may be mounted in various terminals, such as a smartphone, a tablet personal computer (PC), a desktop PC, a notebook PC, a wearable device, and the like. Here, the wearable device may include a watch type, a wristlet type, a wrist band type, a ring type, a glasses type, and a hair band type. However, the disclosure is not limited thereto and the apparatus <b>100</b> may be mounted in any hardware manufactured in various forms, e.g., mounted in hardware used in specialized medical institutions.</p><p id="p-0041" num="0040">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, an apparatus <b>100</b> for estimating lipid concentration includes a training data collector <b>110</b> and a processor <b>120</b>.</p><p id="p-0042" num="0041">The training data collector <b>110</b> may collect reference lipid concentration, metadata of a plurality of users, and sensor data of the plurality of users as training data. In this case, the training data collector <b>110</b> may collect, as training data, reference lipid concentration, metadata of a plurality of users, and sensor data of the plurality of users for the same predetermined time period. For example, for a total of 5 days, 7 times a day at a predetermined time interval, a total of 35 reference lipid concentrations, metadata, and sensor data may be collected as training data, but the training data is not limited thereto, and the total predetermined period, number of days of measurement, the predetermined time interval, and the total number of collections may be varied without limitation.</p><p id="p-0043" num="0042">The reference lipid concentration may mean a lipid concentration measured through blood samples of a plurality of users, and in this case, the reference lipid concentration is a result of collecting blood samples from a plurality of users a predetermined number of times for a predetermined time period and may be obtained by measuring the lipid concentration from the collected samples through an external device (not shown).</p><p id="p-0044" num="0043">The metadata may include any one of gender, age, height, weight, BMI, body fat mass, muscle mass, body water content, skin temperature, and skin humidity of a plurality of users. In this case, the metadata may be directly input to the apparatus <b>100</b> for estimating lipid concentration by the plurality of users, measured by another configuration included in the apparatus <b>100</b>, or received from an external device (not shown).</p><p id="p-0045" num="0044">The training data collector <b>110</b> may collect, as training data, sensor data obtained through light signals detected from the plurality of users for a predetermined time period. The sensor data may refer to a plurality of light signals detected by each of a plurality of detectors (e.g., <b>111</b><i>b </i>in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) of a light sensor (e.g., <b>111</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) that may be included in the training data collector <b>110</b>.</p><p id="p-0046" num="0045">An electrical, mechanical, wired, and/or wireless connection between the processor <b>120</b> and the training data collector <b>110</b> may be established. Upon request for generating a lipid concentration model, the processor <b>120</b> may control the training data collector <b>110</b> and receive sensor data, reference lipid concentration, and metadata from the training data collector <b>110</b>.</p><p id="p-0047" num="0046">The processor <b>120</b> may select a valid variable significant to the change in lipid concentration based on the training data received from the training data collector <b>110</b>, and generate a lipid concentration prediction model based on the selected valid variable. In this case, lipids may include triglycerides.</p><p id="p-0048" num="0047">Variables may refer to all factors that affect the change in lipid concentration, including metadata variables and sensor data variables.</p><p id="p-0049" num="0048">For example, the metadata variable may mean any one of gender, age, height, weight, BMI, body fat mass, muscle mass, body water content, skin temperature, and skin humidity of a user, but is not limited thereto.</p><p id="p-0050" num="0049">In another example, the sensor data variable may be a feature value of each of the plurality of light signals detected by the light sensor <b>111</b>, and the feature value may be predetermined. In this case, the feature value may be determined based on an alternating current (AC) component signal and a direct current (DC) component signal of the detected light signal. For example, the feature value may be an average of AC component amplitudes, an average of DC component amplitudes, or an average value obtained by dividing an AC component by a DC component. Alternatively, the feature value may be an area value of the detected light signal, a maximum value, a minimum value, and a statistical value of a maximum value and a minimum value in a differential signal of the light signal, or the like, but is not limited thereto.</p><p id="p-0051" num="0050">The sensor data acquisition process of the training data collector <b>110</b> and the preprocessing process, valid variable selection process, and lipid concentration prediction model generation process of the processor <b>120</b> will be described in detail with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an apparatus <b>200</b> for estimating lipid concentration according to an example embodiment. Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the apparatus <b>200</b> for estimating lipid concentration may include a training data collector <b>110</b>, a processor <b>120</b>, a storage <b>130</b>, an output interface <b>140</b>, and a communication interface <b>150</b>.</p><p id="p-0053" num="0052">The training data collector <b>110</b> may include a light sensor <b>111</b>. The light sensor <b>111</b> may be formed of a pixel array and may obtain sensor data from a plurality of users for a predetermined time period. Each pixel of the pixel array may include a light source <b>111</b><i>a </i>configured to emit light to an object and a detector <b>111</b><i>b </i>configured to detect a light signal through light scattered or reflected from the object.</p><p id="p-0054" num="0053">Each pixel of the light sensor <b>111</b> may detect a plurality of light signals from an object of a user using the light source <b>111</b><i>a </i>and the detector <b>111</b><i>b. </i>In this case, the light signal may include a photoplethysmography (PPG) signal or an electrocardiography (ECG) signal, but is not limited thereto. As described above in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the sensor data may mean a plurality of light signals detected by a plurality of detectors <b>111</b><i>b </i>of the light sensor <b>111</b>.</p><p id="p-0055" num="0054">In this case, the object may be a region of a wrist surface adjacent to the radial artery, which is an upper area of the wrist where the capillary blood or venous blood passes through, or a body part with a high blood vessel density, e.g., a finger, a toe, an earlobe, etc.</p><p id="p-0056" num="0055">The light source <b>111</b><i>a </i>of each pixel may include at least one of a light emitting diode (LED), a laser diode, or a phosphor, but is not limited thereto. In this case, the light source <b>111</b><i>a </i>of each pixel may be formed of, for example, an LED array, and each LED may emit light at a different wavelength, such as a green, red, and/or infrared.</p><p id="p-0057" num="0056">The detector <b>111</b><i>b </i>of each pixel may include a photodiode, a photo transistor, a photodiode array, a phototransistor array, an image sensor (e.g., a complementary metal oxide semiconductor (CMOS) image sensor), etc.</p><p id="p-0058" num="0057">The light sensor <b>111</b> may further include an additional configuration to be used for sensor data acquisition. For example, additional configurations, such as an amplifier configured to amplify an electrical signal output by the detector <b>111</b><i>b </i>that has detected by the light signal, or an analog-to-digital converter configured to convert an electrical signal output by the amplifier into a digital signal, may be further included in the light sensor <b>111</b>. In addition, in a case where the light sensor <b>111</b> measures an ECG signal, the light sensor <b>111</b> may include a plurality of electrodes.</p><p id="p-0059" num="0058">The processor <b>120</b> may include a light sensor controller <b>121</b>, a preprocessor <b>122</b>, a valid variable selector <b>123</b>, and a lipid concentration prediction model generator <b>124</b>.</p><p id="p-0060" num="0059">The light sensor controller <b>121</b> may drive the light sensor <b>111</b> in various ways. In this case, for example, the driving method of the light sensor <b>111</b>, including information on a light source of a pixel to be driven, a duration, light source intensity, a detector of a pixel to be driven, and the like, may be predefined.</p><p id="p-0061" num="0060">Various driving methods of the light sensor <b>111</b> will be described with reference to <figref idref="DRAWINGS">FIGS. <b>3</b>A to <b>3</b>C</figref>. <figref idref="DRAWINGS">FIGS. <b>3</b>A to <b>3</b>C</figref> are diagrams for explaining a process in which a light source and a detector are driven in a light sensor formed of a pixel array.</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> illustrates a 9&#xd7;9 pixel array of the light sensor <b>111</b>. Referring to <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, the light sensor controller <b>121</b> may drive the light sensor <b>111</b> according to a first driving method. For example, a light source <b>310</b><i>a </i>of a specific pixel <b>310</b> in a pixel array <b>300</b><i>a </i>may be driven to emit light to an object, and at this time, the detectors of all pixels including a detector <b>310</b><i>b </i>of the specific pixel <b>310</b> may be driven and a light signal scattered or reflected from the object may be detected by the detector of each pixel. Accordingly, light signals on different light paths may be detected.</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> illustrates that the light source <b>310</b><i>a </i>of the pixel <b>310</b> is placed in the first row and the fifth column is driven, but the disclosure is not limited thereto and a light source of any pixel in the pixel array <b>300</b><i>a </i>may be driven.</p><p id="p-0064" num="0063">Referring to <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, the light sensor controller <b>121</b> may drive the light sensor <b>111</b> according to a second driving method. For example, the light sensor controller <b>121</b> may determine a plurality of light source driving pixels in which light sources are to be driven in the pixel array <b>300</b><i>b, </i>drive the light sources of the determined pixels, and drive detectors of pixels other than the determined light source driving pixels.</p><p id="p-0065" num="0064">For example, referring to <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, the light sensor controller <b>121</b> may determine pixels <b>320</b>, <b>321</b>, <b>322</b>, <b>323</b>, and <b>324</b> on a first row to be light source driving pixels. The pixels <b>320</b>, <b>321</b>, <b>322</b>, <b>323</b>, and <b>324</b> determined to be the light source driving pixels may each include light sources <b>320</b><i>a, </i><b>321</b><i>a, </i><b>323</b><i>a, </i><b>322</b><i>a, </i>and <b>324</b><i>a </i>and detectors <b>320</b><i>b, </i><b>321</b><i>b, </i><b>322</b><i>b, </i><b>323</b><i>b, </i>and <b>324</b><i>b, </i>respectively, as illustrated.</p><p id="p-0066" num="0065">In this case, the light sensor controller <b>121</b> may drive the light source <b>320</b><i>a </i>of the pixel <b>320</b> in the first row and a first column, and drive detectors of pixels other than the pixels <b>320</b>, <b>321</b>, <b>322</b>, <b>323</b>, and <b>324</b> in the first row, which are light source driving pixels. Then, the light sensor controller <b>121</b> may drive the light source <b>321</b><i>a </i>of the pixel <b>321</b> in the first row and a second column, and drive detectors of pixels other than the pixels <b>320</b>, <b>321</b>, <b>322</b>, <b>323</b>, and <b>324</b> in the first row, which are light source driving pixels. In a similar way, the light sensor controller <b>121</b> may drive the remaining pixels <b>322</b>, <b>323</b>, and <b>324</b>, which are determined to be the light source driving pixels, and detectors of pixels other than the pixels <b>320</b>, <b>321</b>, <b>322</b>, <b>323</b>, and <b>324</b> in the first row.</p><p id="p-0067" num="0066">In <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, the light sources <b>320</b><i>a, </i><b>321</b><i>a, </i><b>322</b><i>a, </i><b>323</b><i>a, </i>and <b>324</b><i>a </i>of the pixels <b>320</b>, <b>321</b>, <b>322</b>, <b>323</b>, and <b>324</b> in the first row, which are light source driving pixels, are illustrated as being driven in order from left to right, but is not limited thereto, and the driving order of the light sources of the light source driving pixels may be changed without limitation.</p><p id="p-0068" num="0067">In the case of <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, the light sensor controller <b>121</b> is illustrated as determining the pixels in the first row to be the light source driving pixels, but is not limited thereto and the light sensor controller <b>121</b> may determine pixels in another row other than the first row in the pixel array <b>300</b><i>b </i>to be light source driving pixels, or determine pixels in a plurality of rows of the pixel array <b>300</b><i>b </i>to be the light source driving pixels. Alternatively, unlike <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, the light sensor controller <b>121</b> may not determine pixels in a specific row of the pixel array <b>300</b><i>b </i>to be light source driving pixels, but may determine pixels in a specific column of the pixel array <b>300</b><i>b </i>to be light source driving pixels, or may determine arbitrary pixels in the pixel array <b>300</b><i>b </i>to be light source driving pixels, rather than pixels arranged side by side, such as pixels in the same row or pixels in the same column of the pixel array <b>300</b><i>b. </i></p><p id="p-0069" num="0068">Under the control of the light sensor controller <b>121</b>, a light source of the pixel determined to be the light source driving pixel may emit light to the object, and at this time, the detectors of the pixels other than the light source driving pixel may detect light signals scattered or reflected by the object. Accordingly, light signals on different light paths may be detected.</p><p id="p-0070" num="0069">Referring to <figref idref="DRAWINGS">FIG. <b>3</b>C</figref>, the light sensor controller <b>121</b> may drive the light sensor <b>111</b> according to a third driving method. For example, the light sensor controller <b>121</b> may determine one or more light source driving pixels in which light sources are to be driven in a pixel array <b>300</b><i>c, </i>drive the light sources of the determined pixels, and drive detectors of pixels in which the light sources are driven.</p><p id="p-0071" num="0070">For example, the light sensor controller <b>121</b> may first drive the light source of the pixel in a first row and a first column, and in the meantime drive the detector of the same pixel as that of the driven light source, that is, the detector of the pixel in the first row and the first column. Then, the light sensor controller <b>121</b> may drive the light source of the pixel in the first row and a second column, and in the meantime drive the detector of the same pixel as that of the driven light source, that is, the detector of the pixel in the first row and the second column.</p><p id="p-0072" num="0071">At this time, among the pixels of the pixel array <b>300</b><i>c, </i>the light sensor controller <b>121</b> may drive the light source and the detector of each pixel in the order of the light source and detector of the pixel in the first row and the first column, the light source and detector of the pixel in the first row and the second column, and then the light source and detector of the pixel in the first row and the third column. However, the disclosure is not limited thereto, and a pixel of which the light source and detector are to be first driven may be determined without limitation.</p><p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. <b>3</b>C</figref> illustrates that the light sensor controller <b>121</b> determines all pixels of the pixel array <b>300</b><i>c </i>to be light source driving pixels and drives a detector of the same pixel as that of the light source driven, but the disclosure is not limited thereto, and the light sensor controller <b>121</b> may determine that only some pixels in the pixel array are light source driving pixels.</p><p id="p-0074" num="0073">The light sensor controller <b>121</b> may determine a wavelength band of light emitted by the light source of each pixel. In this case, the light sensor controller <b>121</b> may control the light sources of each pixel or the plurality of light sources of one pixel to all emit light of the same wavelength or light of different wavelengths. For example, the light sources of each pixel or the plurality of light sources of one pixel may emit light of green, blue, red, infrared wavelength, etc., but is not limited thereto. The light signal detected by the detector may differ according to the wavelength band of the light emitted by each light source.</p><p id="p-0075" num="0074">Referring back to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, for example, the preprocessor <b>122</b> may perform preprocessing, such as filtering for removing noise, such as motion noise or the like, from sensor data obtained from the light sensor, amplification of the sensor data, or the like. For example, the preprocessor <b>122</b> may use a bandpass filter to perform bandpass filtering of 0.4 Hz to 10 Hz, thereby removing noise from the sensor data received from the training data collector <b>110</b>. The bandpass filter may be a digital filter implemented in software code executable by the preprocessor <b>122</b>. In another example, the bandpass filter may be an analog filter, and in this case, the sensor data obtained by the training data collector <b>110</b> may be transmitted to the preprocessor <b>122</b> after passing through the bandpass filter (not shown). In addition, the processor <b>122</b> may correct bio-signals through reconstruction of the bio-signals based on fast Fourier transform. However, the disclosure is not limited thereto, and various other preprocessing operations may be performed according to various measurement environments, such as the computing performance or measurement accuracy of the apparatus, the position of the object, the temperature and humidity of the object, the temperature of the sensor part, etc.</p><p id="p-0076" num="0075">In another example, the preprocessor <b>122</b> may calculate a moving average of a sensor data variable over time for each user, which is obtained by the training data collector <b>110</b>. A moving average may be a cumulative weighted moving average obtained by accumulating and weighting data in units of a predetermined moving average period.</p><p id="p-0077" num="0076">In this case, the moving average period unit and/or a weight for each period unit may be preset. For example, the preprocessor <b>122</b> may set a moving average period unit to be 3 and may assign decreasing weights to data farther from the central point of the moving average period unit. For example, when time T is a central point of a moving average period unit, a weight of 1 may be assigned at time T&#x2212;1, a weight of 2 may be assigned at time T, and a weight of 1 may be assigned at time T+1, but the disclosure is not limited thereto, and the moving average period unit and the method of setting a weight may be modified without limitation. By using such preprocessing through the cumulative weighted moving average, the influence that the noise generated in the sensor data acquisition process of the training data collector <b>110</b> has on the lipid concentration prediction model may be reduced.</p><p id="p-0078" num="0077">In another example, the preprocessor <b>122</b> may obtain additional sensor data by augmenting the sensor data obtained by the training data collector <b>110</b>. In this case, the preprocessor <b>122</b> may augment the data using various data augmentation techniques, and, for example, may augment the sensor data based on Gaussian blur using an image filter based on a normal distribution. However, the disclosure is not limited thereto, and various data augmentation techniques that can be used for augmenting sensor data, which is image data, may be used.</p><p id="p-0079" num="0078">In this case, the additional sensor data may have a pattern similar to that of the sensor data obtained by the training data collector <b>110</b>. In general, a large amount of data is required to sufficiently train a lipid concentration prediction model and improve its performance, but it takes a significant amount of time and cost to acquire the reference lipid concentration and sensor data multiple times from a plurality of users. In this way, by acquiring the additional sensor data through data augmentation, the cost and time required may be reduced and at the same time an enormous amount of training data may be acquired.</p><p id="p-0080" num="0079">The preprocessor <b>122</b> may scale the sensor data variable obtained by the training data collector <b>110</b>. The preprocessor <b>122</b> may scale the sensor data variable using, for example, an L-2 norm. For example, the preprocessor <b>122</b> may scale a sensor data variable associated with each acquisition time point based on a plurality of sensor data variables acquired at the same time point. In this case, an equation such as Equation 1 for the L-2 norm below may be used, but the disclosure is not limited thereto.</p><p id="p-0081" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msub>      <mi>x</mi>      <mi>norm</mi>     </msub>     <mo>=</mo>     <mfrac>      <mi>x</mi>      <mrow>       <mo>&#xf605;</mo>       <mrow>        <mi>x</mi>        <msub>         <mo>&#xf605;</mo>         <mn>2</mn>        </msub>       </mrow>      </mrow>     </mfrac>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>1</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0082" num="0080">Here, x denotes a sensor data variable before scaling, and x<sub>norm </sub>denotes a sensor data variable after scaling by the L-2 norm. In this case, the sensor data variable may be, for example, a feature value in each of a plurality of light signals obtained at each time point, such as, as described above, an average of AC component amplitudes, an average of DC component amplitudes, an average value obtained by dividing an AC component by a DC component, an area value, or a maximum value, a minimum value, or a statistical value of a maximum value and a minimum value in a differential signal.</p><p id="p-0083" num="0081">The valid variable selector <b>123</b> may select a valid variable significant (or substantially relevant) to the change in lipid concentration based on the training data collected by the training data collector <b>110</b> or the data preprocessed by the preprocessor <b>122</b>. In this case, the valid variable selector <b>123</b> may select a valid variable from among metadata variables and/or sensor data variables.</p><p id="p-0084" num="0082">For example, the valid variable selector <b>123</b> may select a valid variable using a nonparametric statistical test including a Wilcoxon rank-sum test based on the training data.</p><p id="p-0085" num="0083">The valid variable selector <b>123</b> may classify the collected training data into a first group having a reference lipid concentration greater than or equal to a first threshold and a second group having a reference lipid concentration less than or equal to a second threshold. In this case, the first group may be a group having a reference lipid concentration greater than or equal to the third quartile in the distribution of the obtained reference lipid concentration, and the second group may be a group having a reference lipid concentration less than or equal to the first quartile in the distribution of the obtained reference lipid concentration. However, the disclosure is not limited thereto.</p><p id="p-0086" num="0084">In this case, the valid variable selector <b>123</b> may compare the sensor data and/or metadata of the first group and the second group, and select, as a valid variable, a variable determined to be significant to the change in lipid concentration from among the sensor data variables and the metadata variables.</p><p id="p-0087" num="0085">In another example, the valid variable selector <b>123</b> may select a valid variable using an auto-encoder based on the training data collected by the training data collector <b>110</b>.</p><p id="p-0088" num="0086">In general, an auto-encoder may include an unsupervised learning-based artificial neural network model that is trained so that a desired output approximates to an input, and may include an encoding process and a decoding process. The valid variable selector <b>123</b> may encode a sensor data variable input to an input layer to a hidden layer using only an encoding process of the auto-encoder, thereby selecting a valid variable significant to the change in lipid concentration. That is, the valid variable selector <b>123</b> may encode the variable having high dimensional data by using an auto-encoder, thereby compressing the input variable and selecting a predetermined valid variable having smaller dimensional data.</p><p id="p-0089" num="0087">The lipid concentration prediction model generator <b>124</b> may generate a lipid concentration prediction model based on the training data collected by the training data collector <b>110</b> and the valid variable selected. In this case, the lipid concentration prediction model generator <b>124</b> may use various types of machine learning models. The machine learning models may include linear models and nonlinear models, and the machine learning models may include, for example, at least one of partial least square (PLS), elastic net, random forest, gradient boosting machine (GBM), or XGBoost, but are not limited thereto.</p><p id="p-0090" num="0088">The lipid concentration prediction model generator <b>124</b> may generate a lipid concentration prediction model, such as Equation 2 below, but is not limited thereto. The lipid concentration prediction model may be defined as various linear or non-linear combination functions, such as addition, subtraction, division, multiplication, logarithmic value, regression equation, and the like, with no particular limitation. Equation <b>2</b> below represents a simple linear function.</p><p id="p-0091" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>y=ax</i><sub>1</sub><i>+bx</i><sub>2</sub><i>+cx</i><sub>3</sub><i>+d</i>&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0092" num="0089">In Equation 2, y denotes a lipid concentration to be estimated, and x<sub>1</sub>, x<sub>2</sub>, and x<sub>3 </sub>values may each denote a selected valid variable or a value obtained by combining two or more of the selected valid variables. d denotes a fixed constant, and a, b, and c may be coefficients for weighting the selected valid variables and be fixed values that are universally applicable to a plurality of users predefined.</p><p id="p-0093" num="0090">The storage <b>130</b> may store therein various items of reference information required for generating a lipid concentration prediction model, the obtained sensor data, the preprocessing result of the sensor data, the selection result of valid variable, and the like. In this case, the reference information may include user information, such as a user's age, gender, occupation, health condition, and the like, and information regarding a relationship between the valid variable and the lipid concentration prediction model, etc., but is not limited thereto. In this case, the storage <b>130</b> may include at least one storage medium of a flash memory type memory, a hard disk type memory, a multimedia card micro type memory, a card type memory (e.g., an SD memory, an XD memory, etc.), a random access memory (RAM), a static random access memory (SRAM), a read only memory (ROM), an electrically erasable programmable read only memory (EEPROM), a programmable read only memory (PROM), a magnetic memory, a magnetic disk, and an optical disk, and the like, but is not limited thereto.</p><p id="p-0094" num="0091">The output interface <b>140</b> may provide the user with the sensor data, metadata, and reference lipid concentration collected by the training data collector <b>110</b> and the processing result of the processor <b>120</b>. The output interface <b>140</b> may provide the information to the user in various visual/non-visual manners using a display module, a speaker, and a haptic device mounted in the apparatus.</p><p id="p-0095" num="0092">For example, the output interface <b>140</b> may visually display the generated lipid concentration prediction model along with the selected valid variable. The output interface <b>140</b> may provide the user with the moving average, data augmentation, and scaling result for the sensor data.</p><p id="p-0096" num="0093">The communication interface <b>150</b> may be connected to an external device through communication techniques under the control of the processor <b>120</b> and may receive a bio-signal and a reference lipid concentration from the external device. In this case, the external device may include, without limitation, various devices, such as smartphones, tablet PCs, wearable devices, and the like, which measure a bio-signal and a reference lipid concentration directly from the user or manage the measured bio-signal and reference lipid concentration. Also, the communication interface <b>150</b> may transmit the processing results of the processor <b>120</b> to the external device.</p><p id="p-0097" num="0094">In this case, the communication techniques may include Bluetooth communication, Bluetooth Low Energy (BLE) communication, near field communication unit, WLAN communication, ZigBee communication, infrared data association (IrDA) communication, Wi-Fi direct (WFD) communication, ultra wideband (UWB) communication, Ant+communication, WI-FI communication, and mobile communication techniques, but are not limited thereto.</p><p id="p-0098" num="0095">When both the light sensor <b>111</b> and the communication interface <b>150</b> are included in the apparatus <b>200</b> for estimating lipid concentration, the processor <b>120</b> may selectively control the light sensor <b>111</b> and the communication interface <b>150</b> to obtain a bio-signal. The light sensor <b>111</b> may be omitted according to the characteristics of the apparatus <b>200</b>.</p><p id="p-0099" num="0096"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram illustrating an apparatus <b>400</b> for estimating lipid concentration according to an example embodiment.</p><p id="p-0100" num="0097">Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, an apparatus <b>400</b> for estimating lipid concentration may include a sensor part <b>410</b>, a processor <b>420</b>, a storage <b>430</b>, an output interface <b>440</b>, and a communication interface <b>450</b>.</p><p id="p-0101" num="0098">The sensor part <b>410</b> may include a light sensor and may use the light sensor to obtain a plurality of bio-signals of a specific user for a predetermined time period. In this case, the light sensor may be formed of a pixel array, and each pixel of a pixel array may include one or more light sources and detectors, but is not limited thereto. The bio-signal obtained by the sensor part <b>410</b> may include a bio-signal for calibration and a bio-signal for lipid concentration estimation.</p><p id="p-0102" num="0099">When a specific user estimates a lipid concentration using the apparatus for estimating lipid concentration, calibration for generating a personalized lipid concentration prediction model may be carried out. The processor <b>420</b> may perform a calibration at preset intervals, or according to an analysis of lipid concentration estimation result or a user's request.</p><p id="p-0103" num="0100">For example, the processor <b>420</b> may perform a calibration at a time of initial use of the apparatus by the user and at preset intervals from the time of initial use. For example, when the user requests estimation of an initial lipid concentration using the apparatus <b>400</b>, the processor <b>420</b> may refer to the storage <b>430</b> to check whether reference information for estimation of lipid concentration exist, and, if there is no reference information, may perform a calibration.</p><p id="p-0104" num="0101">In another example, the processor <b>420</b> may analyze the lipid concentration estimation result and determine whether to perform a calibration based on the analysis result. For example, once the lipid concentration estimation is complete, the processor <b>420</b> may determine the accuracy of the estimated lipid concentration and determine whether to perform a calibration. For example, a normal range of an estimated lipid concentration value may be predefined, and a determination may be made based on the normal range of the estimated lipid concentration value. For example, it may be determined that a calibration is needed when an estimated lipid concentration value falls outside the normal range, when the number of times that an estimated lipid concentration value is outside the normal range is outside a threshold, when the number of consecutive occurrences in which an estimated lipid concentration value does not fall in the normal range is greater than or equal to a predetermined threshold, or when the number of occurrences in which the estimated lipid concentration value does not fall within the normal range in a predetermined time period is greater than or equal to a predetermined threshold.</p><p id="p-0105" num="0102">When the processor <b>420</b> determines to perform a calibration, the processor <b>420</b> may control the sensor part <b>410</b> to obtain a bio-signal for calibration. For example, the processor <b>420</b> may guide the user to bring an object into contact with the sensor part <b>410</b>. In this case, the processor <b>420</b> may guide the user to make the object in contact with the sensor part <b>410</b> in units of a predetermined time, for a predetermined period of time.</p><p id="p-0106" num="0103">The processor <b>420</b> may generate a personalized lipid concentration prediction model based on the lipid concentration prediction model stored in the storage <b>430</b> or the lipid concentration prediction model received from an external source through the communication interface <b>450</b> by performing a calibration based on the bio-signal for calibration obtained by the sensor part <b>410</b> and the metadata of a specific user.</p><p id="p-0107" num="0104">For example, the processor <b>420</b> may obtain a valid variable of the lipid concentration prediction model, for example, an average of AC component amplitudes of a first light signal, based on a bio-signal at a time of initial calibration performed in the stable state, and obtain a measured lipid concentration of the specific user at the time of calibration. In this case, the measured lipid concentration may be measured directly from the apparatus <b>400</b> for estimating lipid concentration, or received from an external device (not shown), and the stable state may refer to a state in which there is no influence of external noise and the user's physical state maintains a value within a certain error range, and may mean, for example, a fasting period. The processor <b>420</b> may apply the obtained valid variable value to the lipid concentration prediction model, perform a calibration by comparing the lipid concentration prediction model with the measured lipid concentration of the specific user, and generate a personalized lipid concentration prediction model. The generated personalized lipid concentration prediction model may be stored in the storage <b>430</b>.</p><p id="p-0108" num="0105">When a request for estimation of lipid concentration is received at the time of lipid concentration estimation, the processor <b>420</b> may estimate a lipid concentration of the user using the bio-signal for lipid concentration estimation obtained through the sensor part <b>410</b>, the user's metadata, and the personalized lipid concentration prediction model.</p><p id="p-0109" num="0106">For example, the processor <b>420</b> may extract a value corresponding to the valid variable from the bio-signal for lipid concentration estimation and/or metadata obtained through the sensor part <b>410</b>, and apply the extracted valid variable value to the personalized lipid concentration model to estimate lipid concentration.</p><p id="p-0110" num="0107">In this case, the output interface <b>440</b> may provide the estimated lipid concentration to the user in various visual/non-visual manners. Also, the output interface <b>440</b> may provide the estimated lipid concentration value to the user by using one or more of various methods, such as by changing a color, a line thickness, font, and the like based on whether the estimated lipid concentration value falls within or outside a normal range. Additionally, the output interface <b>440</b> may also use vibrations and/or tactile sensations according to an abnormal lipid concentration value being estimated so that the user can easily recognize the abnormality of the lipid concentration. Alternatively, upon comparing the estimated lipid estimation value with a previous measurement history, if it is determined that the estimated lipid concentration is abnormal, the output interface <b>440</b> may display information on a user's action to be taken, such as food information that the user should be careful about, information on a related hospital, and the like, together with a warning message, an alert signal, or the like.</p><p id="p-0111" num="0108"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart illustrating a method of estimating lipid concentration according to an example embodiment. The method of <figref idref="DRAWINGS">FIG. <b>5</b></figref> is one example embodiment of a method performed by the apparatus for estimating lipid concentration according to the example embodiment of <figref idref="DRAWINGS">FIG. <b>1</b> or <b>2</b></figref>, which is described above in detail such that a description thereof will be briefly given below.</p><p id="p-0112" num="0109">First, sensor data obtained through a reference lipid concentration measured through blood samples of a plurality of users for a predetermined time period and light signals detected from the plurality of users for the predetermined time period may be collected as training data in <b>510</b>.</p><p id="p-0113" num="0110">In this case, metadata including at least one of the user's gender, age, height, weight, BMI, body fat mass, muscle mass, body water content, skin temperature, and skin humidity may be further collected as training data.</p><p id="p-0114" num="0111">Next, preprocessing including a moving average and data augmentation may be performed on the obtained sensor data in <b>520</b>.</p><p id="p-0115" num="0112">For example, sensor data variables acquired over time for each user may be preprocessed by using the cumulative weighted moving average, wherein a lower weight may be assigned to data farther from the central point of a predetermined moving average period unit. In another example, additional sensor data may be acquired by augmenting data using a data augmentation technique including Gaussian blur. Alternatively, the sensor data variable may be scaled using the L-2 norm.</p><p id="p-0116" num="0113">Next, a valid variable significant (or substantially relevant) to the change in lipid concentration may be selected based on the preprocessed sensor data and the reference lipid concentration in <b>530</b>.</p><p id="p-0117" num="0114">For example, the collected training data may be classified into two or more groups based on the reference lipid concentration, and a valid variable may be selected by comparing the training data between the classified groups. In this case, the valid variable may be selected by applying a nonparametric statistical test including a Wilcoxon rank-sum test to the training data in the classified groups.</p><p id="p-0118" num="0115">In another example, the valid variable may be selected using an auto-encoder based on the training data.</p><p id="p-0119" num="0116">Next, a lipid concentration prediction model may be generated based on the selected valid variable in <b>540</b>. In this case, the lipid concentration prediction model may be generated based further on a machine learning model including at least one of PLS, elastic net, random forest, GBM, or XGBoost.</p><p id="p-0120" num="0117"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating a method of estimating lipid concentration according to an example embodiment. The method of <figref idref="DRAWINGS">FIG. <b>6</b></figref> is one example embodiment of a method performed by the apparatus for estimating lipid concentration according to the example embodiment of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, which is described above in detail such that a description thereof will be briefly given below.</p><p id="p-0121" num="0118">First, a bio-signal and metadata of a specific user may be obtained at a time of calibration in <b>610</b>. In this case, the bio-signal of the specific user may be obtained by detecting a light signal using a light sensor.</p><p id="p-0122" num="0119">Next, in <b>620</b>, a personalized lipid concentration prediction model may be generated by performing a calibration based on a previously generated lipid concentration prediction model, an obtained bio-signal for calibration of the specific user, and the obtained metadata.</p><p id="p-0123" num="0120">Then, a user's lipid concentration may be estimated based on the generated personalized lipid concentration prediction model and the bio-signal obtained at the time of lipid concentration estimation in <b>630</b>. In this case, the user's lipid concentration may be estimated based further on the user's metadata obtained at the time of lipid concentration estimation.</p><p id="p-0124" num="0121"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating a wearable device according to an example embodiment. Various example embodiments of the apparatus <b>400</b> for estimating lipid concentration may be mounted in a smartwatch that is worn on a wrist of a user. However, the shape of the wearable device is not limited to the illustrated example.</p><p id="p-0125" num="0122">Referring to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, a wearable device <b>700</b> includes a main body <b>710</b> and a strap <b>720</b>.</p><p id="p-0126" num="0123">The strap <b>720</b> may be made of a flexible material. The strap <b>720</b> may be connected to opposite ends of the main body <b>710</b> and may wrap around the user's wrist such that the main body <b>810</b> is in close contact with an upper portion of the wrist. In this case, air may be injected into the strap <b>720</b> or an airbag may be included in the strap <b>720</b>, so that the strap <b>720</b> may have elasticity according to a change in pressure applied to the wrist, and the change in pressure of the wrist may be transmitted to the main body <b>710</b>.</p><p id="p-0127" num="0124">A battery, which supplies power to the wearable device <b>700</b>, may be embedded in the main body <b>710</b> or the strap <b>720</b>. Further, a sensor part <b>730</b> may be mounted in a rear surface of the main body <b>710</b>. The sensor part <b>730</b> may include a light sensor, the light sensor may be formed of a pixel array, and each pixel of the pixel array may include one or more light sources and detectors. However, the disclosure is not limited thereto.</p><p id="p-0128" num="0125">The processor is mounted inside the main body <b>710</b> and may generate a personalized lipid concentration prediction model based on a bio-signal for calibration obtained by the sensor part <b>730</b>, or estimate the user's lipid concentration based on a bio-signal for lipid concentration estimation.</p><p id="p-0129" num="0126">In addition, a display may be mounted on the front surface of the main body <b>710</b> and may display a lipid concentration estimation result and the like. In this case, the display may include a touch screen which allows touch input.</p><p id="p-0130" num="0127">In addition, a storage may be mounted inside the main body <b>710</b>, and a lipid concentration prediction model generated in advance, a personalized lipid concentration prediction model generated as a result of calibration, and/or a processing result of the processor may be stored in the storage.</p><p id="p-0131" num="0128">In addition, a manipulator <b>740</b> configured to receive a control command from a user and transmit the control command to the processor may be mounted on the side of the main body <b>710</b>. The manipulator <b>740</b> may have a function for inputting a command to turn on/off the wearable device <b>700</b>. Also, the manipulator <b>740</b> may include a PPG sensor to obtain a bio-signal from a finger when the finger is in contact with the manipulator <b>740</b>.</p><p id="p-0132" num="0129">Further, a communication interface configured to transmit and receive data with an external device may be mounted in the main body <b>710</b>. The communication interface may communicate with the external device, such as the user's smartphone, a lipid concentration measuring device, or the like, to transmit and receive various types of data related to estimation of lipid concentration. The communication interface may transmit a personalized lipid concentration prediction model of a specific user generated as a result of calibration to an external database, and may periodically receive a modified lipid concentration prediction model from the external database. The processor may update the personalized lipid concentration prediction model of a specific user by performing a re-calibration based on the modified lipid concentration prediction model.</p><p id="p-0133" num="0130"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating a smart device according to an example embodiment. Here, a smart device <b>800</b> may include a smartphone, a tablet PC, etc. The smart device <b>800</b> may include the above-described various example embodiments of the apparatus <b>400</b> for estimating lipid concentration.</p><p id="p-0134" num="0131">Referring to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the smart device <b>800</b> may have a sensor part <b>830</b> mounted on a rear surface of a main body <b>810</b>. The sensor part <b>830</b> may include a light source <b>831</b> and a detector <b>832</b>. The number and arrangement of the light sources <b>831</b> and detectors <b>832</b> included in the sensor part <b>830</b> may be varied without limitation to the example shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. The sensor part <b>830</b> may be mounted on the rear surface of the main body <b>810</b> as illustrated, but is not limited thereto. For example, the sensor part <b>830</b> may be formed on a fingerprint sensor on a front surface, a part of a touch panel, or a power button or volume button mounted on the side or an upper portion of the smart device.</p><p id="p-0135" num="0132">In addition, a display for displaying various types of information, such as a lipid concentration estimation result, contact state guide information, and the like, may be mounted on the front surface of the main body <b>810</b>.</p><p id="p-0136" num="0133">An image sensor <b>820</b> may be mounted in the main body <b>810</b> as illustrated, and the image sensor <b>820</b> may capture an image of a finger when the user approaches the sensor part <b>830</b> to measure a bio-signal and may transmit the image to the processor. In this case, the processor may identify a relative position of the finger relative to the actual position of the sensor part <b>830</b> and perform operation to guide the user for information on the relative position of the finger through the display.</p><p id="p-0137" num="0134">The processor may generate a personalized lipid concentration prediction model by performing a calibration based on a previously generated lipid concentration prediction model, a specific user's bio-signal obtained at the time of calibration, and metadata, as described above, or may estimate the user's lipid concentration based on the generated personalized concentration prediction model, the bio-signal obtained at the time of lipid concentration estimation, and the metadata. A detailed description thereof will be omitted.</p><p id="p-0138" num="0135">The current embodiments may be implemented as computer readable codes in a computer readable record medium. Codes and code segments constituting the computer program may be easily inferred by a skilled computer programmer in the art. The computer readable record medium includes all types of record media in which computer readable data are stored. Examples of the computer readable record medium include a ROM, a RAM, a CD-ROM, a magnetic tape, a floppy disk, and an optical data storage. Further, the record medium may be implemented in the form of a carrier wave such as Internet transmission. In addition, the computer readable record medium may be distributed to computer systems over a network, in which computer readable codes may be stored and executed in a distributed manner.</p><p id="p-0139" num="0136">At least one of the components, elements, modules or units (collectively &#x201c;components&#x201d; in this paragraph) represented by a block in the drawings may be embodied as various numbers of hardware, software and/or firmware structures that execute respective functions described above, according to an example embodiment. According to example embodiments, at least one of these components may use a direct circuit structure, such as a memory, a processor, a logic circuit, a look-up table, etc. that may execute the respective functions through controls of one or more microprocessors or other control apparatuses. Also, at least one of these components may be specifically embodied by a module, a program, or a part of code, which contains one or more executable instructions for performing specified logic functions, and executed by one or more microprocessors or other control apparatuses. Further, at least one of these components may include or may be implemented by a processor such as a central processing unit (CPU) that performs the respective functions, a microprocessor, or the like. Two or more of these components may be combined into one single component which performs all operations or functions of the combined two or more components. Also, at least part of functions of at least one of these components may be performed by another of these components. Functional aspects of the above exemplary embodiments may be implemented in algorithms that execute on one or more processors. Furthermore, the components represented by a block or processing steps may employ any number of related art techniques for electronics configuration, signal processing and/or control, data processing and the like.</p><p id="p-0140" num="0137">A number of examples have been described above. Nevertheless, it will be understood that various modifications may be made. For example, suitable results may be achieved if the described techniques are performed in a different order and/or if components in a described system, architecture, device, or circuit are combined in a different manner and/or replaced or supplemented by other components or their equivalents. Accordingly, other implementations are within the scope of the following claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230000446A1-20230105-M00001.NB"><img id="EMI-M00001" he="5.25mm" wi="76.20mm" file="US20230000446A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An apparatus for estimating lipid concentration, comprising:<claim-text>a training data collector configured to collect, as training data, a reference lipid concentration measured through blood samples of a plurality of users for a predetermined time period and sensor data obtained through light signals detected from the plurality of users for the predetermined time period; and</claim-text><claim-text>a processor configured to perform preprocessing, including a moving average and data augmentation, on the obtained sensor data, configured to select a valid variable relevant to a change in lipid concentration based on the preprocessed sensor data and the reference lipid concentration, and configured to generate a lipid concentration prediction model based on the selected valid variable.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the training data collector is further configured to collect, as the training data, metadata including at least one of gender, age, height, weight, body mass index (BMI), skin temperature, or skin humidity of the plurality of users, and the processor is further configured to select the valid variable based further on the collected metadata.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is further configured to perform the preprocessing on a sensor data variable obtained over time for each user of the plurality of users using a cumulative weighted moving average, wherein a lower weight is assigned to data farther from a central point of a predetermined moving average period unit.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is further configured to obtain additional sensor data by augmenting data based on the sensor data using a data augmentation technique including Gaussian blur.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is further configured to scale a senor data variable using an L-2 norm.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to classify the collected training data into at least two groups based on the reference lipid concentration and select the valid variable by comparing the training data between the classified at least two groups.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The apparatus of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the processor is further configured to select the valid variable by applying a nonparametric statistical test including a Wilcoxon rank-sum test to the training data in the classified at least two groups.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is further configured to select the valid variable using an auto-encoder based on the training data.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is further configured to generate the lipid concentration prediction model based further on a machine learning model including at least one of partial least square (PLS), elastic net, random forest, gradient boosting machine (GBM), or XGBoost.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the training data collector comprises a light sensor provided in a pixel array, the pixel array comprising light sources configured to emit light toward an object and detectors configured to detect a light signal through light scattered or reflected from the object.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the processor is further configured to drive a light source of a specific pixel and detectors of all pixels in the light sensor.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the processor is further configured to sequentially drive light sources of pixels in a specific row of the pixel array and drive detectors in remaining rows of the pixel array while the light sources of the pixels in the specific row are being sequentially driven.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the processor is further configured to sequentially drive light sources of all pixels of the pixel array and drive a detector of the same pixel as that of a driven light source while the light sources of all pixels are being sequentially driven.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is further configured to generate a personalized lipid concentration prediction model by performing a calibration based on the generated lipid concentration prediction model, a bio-signal obtained through a light signal detected from a specific user, and metadata of the specific user.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A method of estimating lipid concentration, comprising:<claim-text>collecting, as training data, a reference lipid concentration measured through blood samples of a plurality of users for a predetermined time period and sensor data obtained through light signals detected from the plurality of users for the predetermined time period;</claim-text><claim-text>performing preprocessing including a moving average and data augmentation on the obtained sensor data;</claim-text><claim-text>selecting a valid variable relevant to a change in lipid concentration based on the preprocessed sensor data and the reference lipid concentration; and</claim-text><claim-text>generating a lipid concentration prediction model based on the selected valid variable.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the collecting comprises further collecting, as the training data, metadata including at least one of gender, age, height, weight, body mass index (BMI), skin temperature, or skin humidity of the plurality of users and the selecting of the valid variable comprises selecting the valid variable based further on the collected metadata.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the performing the preprocessing comprises obtaining additional sensor data by augmenting data based on the sensor data using a data augmentation technique including Gaussian blur.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the selecting the valid variable comprises classifying the collected training data into at least two groups based on the reference lipid concentration and selecting the valid variable by comparing the training data between the classified at least two groups.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the selecting the valid variable by comparing the training data between the classified at least two groups comprises selecting the valid variable by applying a nonparametric statistical test including a Wilcoxon rank-sum test to the training data in the classified at least two groups.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the selecting of the valid variable comprises selecting the valid variable using an auto-encoder based on the training data.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000600A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000600</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17781060</doc-number><date>20201203</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>C</subclass><main-group>9</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>C</subclass><main-group>9</main-group><subgroup>0053</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>C</subclass><main-group>9</main-group><subgroup>0086</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">INTRAORAL 3D SCANNING WITH AUTOMATIC CHARTING</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>62943557</doc-number><date>20191204</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>CARESTREAM DENTAL LLC</orgname><address><city>Atlanta</city><state>GA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>WONG</last-name><first-name>Victor C.</first-name><address><city>Pittsford</city><state>NY</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>INGLESE</last-name><first-name>Jean-Marc</first-name><address><city>Bussy-Saint-Georges</city><country>FR</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>SHELLARD</last-name><first-name>Edward R.</first-name><address><city>Atlanta</city><state>GA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/US2020/063093</doc-number><date>20201203</date></document-id><us-371c12-date><date>20220531</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method for intraoral imaging generates one or more output imaging signals from an intraoral probe and acquires multimodal image content from intraoral surface locations according to tissue response from the one or more imaging signals and associates spatial coordinates to the acquired multimodal image content. A surface contour of the patient dentition is generated by stitching the acquired multimodal image content and preserving the association of spatial coordinates with the stitched multimodal image content. Tooth outlines for one or more teeth are generated from the generated surface contour and the generated outlines arranged as a dental chart representing a spatial ordering of the one or more teeth and of supporting gum tissue adjacent to the teeth. The dental chart is populated by analyzing the acquired multimodal image content and associating the analysis to positions on the dental chart according to the preserved association of spatial coordinates and is displayed.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="56.47mm" wi="158.75mm" file="US20230000600A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="182.29mm" wi="100.75mm" orientation="landscape" file="US20230000600A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="165.02mm" wi="123.61mm" orientation="landscape" file="US20230000600A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="174.33mm" wi="112.86mm" orientation="landscape" file="US20230000600A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="174.33mm" wi="112.86mm" orientation="landscape" file="US20230000600A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="177.72mm" wi="167.98mm" orientation="landscape" file="US20230000600A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="172.55mm" wi="138.51mm" orientation="landscape" file="US20230000600A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="157.82mm" wi="106.17mm" orientation="landscape" file="US20230000600A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="153.50mm" wi="95.84mm" orientation="landscape" file="US20230000600A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="128.35mm" wi="104.06mm" orientation="landscape" file="US20230000600A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="135.04mm" wi="123.27mm" orientation="landscape" file="US20230000600A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="104.90mm" wi="95.50mm" orientation="landscape" file="US20230000600A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="131.83mm" wi="101.35mm" orientation="landscape" file="US20230000600A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="138.60mm" wi="95.08mm" orientation="landscape" file="US20230000600A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="127.93mm" wi="96.69mm" orientation="landscape" file="US20230000600A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="181.27mm" wi="127.76mm" orientation="landscape" file="US20230000600A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="149.01mm" wi="132.33mm" orientation="landscape" file="US20230000600A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="93.90mm" wi="94.57mm" orientation="landscape" file="US20230000600A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="161.04mm" wi="113.62mm" orientation="landscape" file="US20230000600A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="195.50mm" wi="92.63mm" orientation="landscape" file="US20230000600A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="151.30mm" wi="115.74mm" orientation="landscape" file="US20230000600A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="188.55mm" wi="153.08mm" orientation="landscape" file="US20230000600A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="149.10mm" wi="141.05mm" orientation="landscape" file="US20230000600A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00023" num="00023"><img id="EMI-D00023" he="170.10mm" wi="130.13mm" orientation="landscape" file="US20230000600A1-20230105-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00024" num="00024"><img id="EMI-D00024" he="185.93mm" wi="151.55mm" orientation="landscape" file="US20230000600A1-20230105-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00025" num="00025"><img id="EMI-D00025" he="185.93mm" wi="151.55mm" orientation="landscape" file="US20230000600A1-20230105-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00026" num="00026"><img id="EMI-D00026" he="150.96mm" wi="130.13mm" orientation="landscape" file="US20230000600A1-20230105-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00027" num="00027"><img id="EMI-D00027" he="164.51mm" wi="130.13mm" orientation="landscape" file="US20230000600A1-20230105-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00028" num="00028"><img id="EMI-D00028" he="97.79mm" wi="143.09mm" orientation="landscape" file="US20230000600A1-20230105-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00029" num="00029"><img id="EMI-D00029" he="164.51mm" wi="130.13mm" orientation="landscape" file="US20230000600A1-20230105-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00030" num="00030"><img id="EMI-D00030" he="136.48mm" wi="138.68mm" orientation="landscape" file="US20230000600A1-20230105-D00030.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The disclosure relates generally to intraoral imaging and, more particularly, relates to methods and apparatuses for automatic generation of a tooth chart and related content from intraoral scanning.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">A dental chart is a widely used tool that supports a dental practitioner in planning and tracking patient treatment. Conventionally, the dental chart is manually annotated by the practitioner and treatment staff and is stored in the patient folder in order to maintain an updated record of patient status, treatment progress, and diagnostic concerns.</p><p id="p-0004" num="0003">With the recent adaptation of various electronic tools for imaging and diagnostic support, there is interest in storing and maintaining dental chart information online to allow ready access for reference and update. Among solutions developed to meet this need is, for example, the SOFTDENT&#x2122; software from Carestream Dental LCC. Electronic solutions of this type have helped to improve the efficiency of record-keeping functions and provide mechanisms for better integration of patient information systems and images. Using automated dental charting with segmentation and automatic tooth identification utilities, the dental practitioner can generate, reference, and maintain a dental chart that relates more closely to a particular patient's set of teeth, rather than to standard models. The displayed dental chart can serve as a convenient index and link to information individually obtained from a number of different types of imaging and measurement systems.</p><p id="p-0005" num="0004">For some practitioners, the requirement to manually enter notes and measurement information relevant to each tooth using a computer keyboard makes such a system unattractive in practice, in spite of the perceived benefits of digital data storage. Thus, there is a need for automatic tooth charting methods and apparatus that can both generate an appropriate dental chart for a particular patient from dental images and populate the generated chart with information obtained from applying automated diagnostics to the tooth image data.</p><p id="p-0006" num="0005">Although some automated tools for generating a dental chart for display and integrating the dental chart with image content have been developed, there appears to be appreciable room for improvement. For example, although electronic dental charting allows indexing to image content from various radiographic, optical, and ultrasound sources, in practice, the integration of this image content is typically not straightforward. The task of spatial registration of data from various sources can be challenging with results that can be unsatisfactory and fall short of the accuracy needed for diagnosis and tracking. As a related complication, data from different sources must be temporally synchronized with other image data in order to provide updated information on patient condition. Because existing solutions mimic the &#x201c;snapshot&#x201d; data recording function of manually maintained charts, advantages of stored data and automatic update have not been explored and it can be difficult to follow treatment progress. Still other shortcomings relate to limitations in data representation.</p><p id="p-0007" num="0006">Thus, it can be appreciated that there is a need for improvement in systems, apparatuses, and methods that automate the dental charting process and, in particular, provide solutions that integrate the dental chart with multifunctional and/or multimodal intraoral imaging systems.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0008" num="0007">Broadly described, the present invention comprises apparatuses, methods and systems for automating the dental charting process by integrating the dental chart with multifunctional and/or multimodal intraoral imaging systems. According to one example embodiment, there is provided a method for intraoral imaging comprising: (a) generating one or more output imaging signals from an intraoral probe; (b) acquiring multimodal image content from each of a plurality of intraoral surface locations for a patient's dentition according to tissue response from the one or more imaging signals and associating spatial coordinates to the acquired multimodal image content; (c) generating a surface contour of the patient dentition by reconstructing and stitching from a data subset of the acquired multimodal image content, and preserving the association of spatial coordinates of the multimodal image content to the stitched surface contour; (d) generating tooth outlines for one or more teeth from the generated surface contour and arranging the generated outlines as a dental chart representing a spatial ordering of the one or more teeth and of supporting gum tissue adjacent to the teeth; (e) populating the dental chart by analyzing the acquired multimodal image content and indicating analysis results at one or more positions on the dental chart according to the preserved association of spatial coordinates; and (f) displaying, communicating, or storing the populated dental chart.</p><p id="p-0009" num="0008">Advantageously, the present invention acquires multimodal image content, automatically associates and preserves spatial coordinates associated with the image content, and automatically analyzes the multimodal image content to populate or update a patient dental chart with minimal input by a dental technician. By automating the dental charting process, the present invention substantially lessens the time required for a dental technician to create and/or update a patient dental chart. As an additional benefit, the accuracy of a patient dental chart may be improved over manual generation or updating of a patient dental chart. As yet another benefit, substantially more information is integrated into a patient dental chart, thereby providing a dental practitioner with more information on a patient's dentition.</p><p id="p-0010" num="0009">Other desirable advantages and benefits inherently achieved by the disclosed systems, apparatuses, and methods may occur or become apparent to those skilled in the art. The invention is defined by the appended claims.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0011" num="0010">The foregoing and other objects, features, and advantages of the invention will be apparent from the following more particular description of the example embodiments of the invention, as illustrated in the accompanying drawings. The elements of the drawings are not necessarily to scale relative to each other.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram that shows components of an imaging apparatus for multimode image acquisition and automated dental chart generation.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram showing an alternate example embodiment for an imaging apparatus for combined OCT (&#x201c;Optical Coherence Tomography&#x201d;) scanning and color image acquisition.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram showing another alternate example embodiment for an imaging apparatus for multimodal image acquisition.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic diagram showing yet another alternate example embodiment for an imaging apparatus for multimodal image acquisition.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref> show functional and geometric aspects of OCT imaging.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a combined OCT and color scanning sequence in schematic form.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIGS. <b>7</b>A through <b>7</b>G</figref> show various embodiments of a color light emitter/detector.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>7</b>H</figref> shows an example embodiment in which RGB (&#x201c;Red Green Blue&#x201d;) light detection is performed at the OCT spectrometer.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart that shows an example method for combined color calibration.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a graph that shows spectral ranges for OCT and reflectance imaging.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>10</b>A</figref> is a schematic diagram that shows an association of acquired image content to each scanned x, y, z location in the scanner field of view.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>10</b>B</figref> is a schematic diagram that shows re-mapping of the acquired image content for a set of locations following the stitching transform.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart that shows a method for OCT processing to obtain OCT imaging content along with a surface point cloud extracted from the OCT content according to an example embodiment of the present disclosure.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIGS. <b>12</b>A-<b>12</b>E</figref> show different types of imaging content acquired and generated as part of the OCT processing method, using the example of a tooth image having a severe cavity.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flowchart that shows a method for generating a dental chart using multimodal scan image data according to an embodiment of the present invention.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIGS. <b>14</b>A, <b>14</b>B, and <b>14</b>C</figref> show various aspects of a dental chart generated and displayed according to an example embodiment of the present invention.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>14</b>D</figref> shows an example of a generated dental chart with a top view of the patient's dentition.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>14</b>E</figref> shows an example of a generated dental chart with a perspective view of the patient's dentition.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart that shows a method of steps for automating the process of dental chart preparation according to an example embodiment of the present disclosure.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a schematic diagram that shows an example of highlighting positioned on a perspective view of a dental chart and showing the current position of a scanner or probe relative to the overall patient dentition for acquiring image content.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a schematic diagram that shows example entries of touchscreen instructions for identifying particular teeth or other features.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION OF EXAMPLE EMBODIMENTS</heading><p id="p-0033" num="0032">The following is a detailed description of example embodiments with reference being made to the drawings in which the same reference numerals identify the same apparatus elements or method steps in each of the several figures.</p><p id="p-0034" num="0033">Where used in the context of the present disclosure, the terms &#x201c;first&#x201d;, &#x201c;second&#x201d;, and so on, do not necessarily denote any ordinal, sequential, or priority relation, but are simply used to more clearly distinguish one step, element, or set of steps or elements from another, unless specified otherwise.</p><p id="p-0035" num="0034">As used herein, the term &#x201c;energizable&#x201d; relates to a device or set of components that perform an indicated function upon receiving power and, optionally, upon receiving an enabling signal.</p><p id="p-0036" num="0035">In the context of the present disclosure, the terms &#x201c;viewer&#x201d;, &#x201c;operator&#x201d;, and &#x201c;user&#x201d; are considered to be equivalent and refer to the viewing practitioner, technician, or other person who views and manipulates an image, such as a dental image, on a display monitor. An &#x201c;operator instruction&#x201d; or &#x201c;viewer instruction&#x201d; is obtained from explicit commands entered by the viewer, such as by clicking a button on a camera or by using a computer mouse or by touch screen or keyboard entry.</p><p id="p-0037" num="0036">In the context of the present disclosure, the phrase &#x201c;in signal communication&#x201d; indicates that two or more devices and/or components are capable of communicating with each other via signals that travel over some type of signal path. Signal communication may be wired or wireless. The signals may be communication, power, data, or energy signals. The signal paths may include physical, electrical, magnetic, electromagnetic, optical, wired, and/or wireless connections between the first device and/or component and second device and/or component. The signal paths may also include additional devices and/or components between the first device and/or component and second device and/or component.</p><p id="p-0038" num="0037">In the context of the present disclosure, the term &#x201c;optics&#x201d; is used, generally, to refer to lenses and other refractive, diffractive, and reflective components or apertures used for shaping and orienting a light beam. An individual component of this type is termed an optic.</p><p id="p-0039" num="0038">In the context of the present disclosure, the term &#x201c;scattered light&#x201d; is used, generally, to include light that is reflected and backscattered from an object.</p><p id="p-0040" num="0039">The general term &#x201c;scanner&#x201d; relates to an optical system that is used for obtaining various types of intraoral images of patient dentition, including support structures. For OCT (optical coherence tomography) imaging, scanner optics project a scanned light beam of broadband near-IR (BNIR) light that is directed to the tooth surface through a sample arm and is acquired, as scattered light returned in the sample arm, for detecting interference with light from a reference arm used in OCT imaging of a surface. The general term &#x201c;raster scanner&#x201d; relates to the combination of hardware components that scan light toward a sample, as described in more detail subsequently.</p><p id="p-0041" num="0040">In the context of the present disclosure, the general term &#x201c;camera&#x201d; refers more particularly to a device that is enabled to acquire a reflectance, 2D (&#x201c;two dimensional&#x201d;) digital image from reflected visible or NIR light, such as structured light that is reflected from the surface of teeth and supporting structures. According to an example embodiment of the present disclosure, a camera that operates at video or near-video rates is used for acquiring images used to generate a 3D (&#x201c;three dimensional&#x201d;) contour image of the teeth and supporting intraoral surfaces.</p><p id="p-0042" num="0041">The term &#x201c;subject&#x201d; refers to the tooth or other portion of a patient that is being imaged and, in optical terms, can be considered equivalent to the &#x201c;object&#x201d; of the corresponding imaging system.</p><p id="p-0043" num="0042">In the context of the present disclosure, the phrase &#x201c;broadband light emitter&#x201d; refers to a light source that emits a continuous spectrum output over a range of wavelengths at any given point of time. Short-coherence or low-coherence, broadband light sources can include, for example, super luminescent diodes, short-pulse lasers, many types of white-light sources, and supercontinuum light sources. Most short coherence length sources of these types have a coherence length on the order of tens of microns or less.</p><p id="p-0044" num="0043">In the context of the present disclosure, two wavelengths can be considered to be &#x201c;near&#x201d; each other when within no more than +/&#x2212;10 nm apart.</p><p id="p-0045" num="0044">In the context of the present disclosure, the terms &#x201c;color light&#x201d;, &#x201c;polychromatic light&#x201d;, and &#x201c;RGB light&#x201d; describe visible light illumination that is provided for reflectance imaging. The color image of an intraoral surface location can be considered a reflectance image or color texture image. As is well known in the color imaging arts, a color combiner, such as a dichroic surface that transmits one spectral band and reflects another spectral band, can be used to combine colors for light traveling in one direction along an optical axis and to separate colors for light traveling along an axis in the opposite direction. Thus, the general term &#x201c;combiner&#x201d; is typically used for a &#x201c;combiner/separator&#x201d; device that both combines and separates light according to wavelength and direction along an optical path.</p><p id="p-0046" num="0045">The term &#x201c;highlighting&#x201d; for a displayed feature has its conventional meaning as is understood to those skilled in the information and image display arts. In general, highlighting uses some form of localized display enhancement to attract the visual attention of the viewer. Highlighting a portion of an image, such as an individual organ, bone, or structure, or a path from one chamber to the next, for example, can be achieved in any of a number of ways, including, but not limited to, annotating, displaying a nearby or overlaying symbol, outlining or tracing, display in a different color or at a markedly different intensity or gray scale value than other image or information content, blinking or animation of a portion of a display, or display at higher sharpness or contrast.</p><p id="p-0047" num="0046">The term &#x201c;set&#x201d;, as used herein, refers to a non-empty set, as the concept of a collection of elements or members of a set is widely understood in elementary mathematics. The term &#x201c;subset&#x201d;, unless otherwise explicitly stated, is used herein to refer to a non-empty proper subset, that is, to a subset of the larger set, having one or more members. For a set &#x201c;S&#x201d;, a subset may comprise the complete set &#x201c;S&#x201d;. A &#x201c;proper subset&#x201d; of set &#x201c;S&#x201d;, however, is strictly contained in set &#x201c;S&#x201d; and excludes at least one member of set &#x201c;S&#x201d;.</p><p id="p-0048" num="0047">An example embodiment of the present disclosure obtains multimodal image content from a single intraoral scan. According to an example embodiment of the present disclosure, the multimodal image content that can be obtained from each scanned location on the intraoral surface can include image content of two or more imaging modes, wherein the imaging modes can obtain color/polychromatic or monochrome reflectance image content, fluorescence image content, and depth-resolved image content, for example. Still other image modes can use signal content from different types of sources, including x-ray or ultrasound image content. Image modes can be distinguished from each other in terms of the signal that is provided and the signal that is acquired for obtaining the image.</p><p id="p-0049" num="0048">Image stitching algorithms that form a more complete, composite image by properly aligning and joining together content from a number of 2D images captured from adjacent views provide a data subset of the full set of acquired image content and wherein members of this data subset share adjacent features, are well known to those skilled in the image processing arts.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram that shows components of an intraoral imaging apparatus <b>300</b> for multimode image acquisition and automated dental chart generation. An intraoral scanner <b>314</b> can be energized to acquire multimode image content, generating the different types of light signals and other signals needed to obtain image content from intraoral surfaces. Light signals may, for example, include polychromatic visible illumination, excitation illumination for fluorescence, or a scan sequence of coherent light beams. Other example signal types can include ultrasound and opto-acoustic signals. Operating under multiple imaging modes, a single scanner <b>314</b> in the <figref idref="DRAWINGS">FIG. <b>1</b></figref> apparatus can provide multiple functions such as 3D surface contour imaging and depth-resolved imaging. The scanner <b>314</b> is in signal communication with a processor <b>320</b>, such as a computer. Signal communication can be wired, wireless, or may use some combination of wired and wireless transfer. Processor <b>320</b> is in signal communication with a memory <b>324</b> or with data storage that provides longer term data retention and archival. A display <b>326</b>, also in signal communication with processor <b>320</b>, provides the display of the generated dental chart and associated operator interface.</p><p id="p-0051" num="0050">Images obtained from surface contour imaging form a data subset of the acquired multimodal image content obtained from scanner <b>314</b>. Processing of this data subset through surface contour reconstruction and stitching provides the spatial reference for mapping the data content that is acquired in any imaging mode.</p><heading id="h-0006" level="1">Depth-Resolved Imaging Modes</heading><p id="p-0052" num="0051">OCT, ultrasound, and opto-acoustic imaging technologies can each provide depth-resolved imaging from a suitably configured intraoral scanner. Each of these depth-resolved imaging modes direct a series of depth-probing output imaging signals to the scanned surface location, using generated signal energy that is capable of penetrating beneath the surface of tissue to provide depth-resolved image content in addition to surface contour information. Depth-resolved imaging modes such as OCT, ultrasound, and opto-acoustic imaging can obtain imaging data for surface contour reconstruction as well as provide useful information related to features that lie beneath the surface of the imaged tissue, accurate to some depth, depending on the limitations of the signal energy that is used. In addition to depth-related information, various depth-resolved imaging apparatus and methods can also provide useful data on feature density, distribution, and dimension.</p><p id="p-0053" num="0052">Example embodiments of the present disclosure can use depth-resolved imaging to address the need for enhanced characterization of the teeth and other intraoral features. Using the added information obtained from depth-resolved images, the methods of such example embodiments add dimension and further utility to the dental chart that is maintained for the patient, supplementing the standard tooth-by-tooth assessment that is conventionally obtained by visual examination with data that was previously hidden below the surface.</p><p id="p-0054" num="0053">The description that follows focuses on OCT image acquisition, using OCT as an exemplary type of depth-resolved imaging system that can be used for enhanced characterization and generation of a dental chart in an automated manner. It should be appreciated and understood, however, that similar processing and methods can be used for assembling surface content with alternative depth-resolved imaging types such as, for example, when using ultrasound and optoacoustic imaging.</p><p id="p-0055" num="0054">Advantageously, the depth-resolved image content is acquired using the same scanner that obtains reflectance and fluorescence images. By combining the image acquisition functions in a single intraoral scanner, methods of the present disclosure address problems of spatial and temporal synchronization that limited the utility, accuracy, and practicality of previous imaging solutions.</p><p id="p-0056" num="0055">Example embodiments of the present disclosure can utilize results acquired from an apparatus that performs depth-resolved imaging such as optical coherence tomography (OCT) in order to generate a dental chart and to populate the generated dental chart with results from image analysis that support recognition of likely conditions for teeth and gums. OCT results can be combined with 3-D surface contour imaging results and analysis acquired using the same imaging apparatus, obtained concurrently and in register with the OCT data.</p><p id="p-0057" num="0056">Subsequent description gives more detailed information on OCT and multimodal imaging subsystems that can be used to provide dental chart content according to an example embodiment of the present disclosure. It should be appreciated and understood that the multimodal imaging apparatus, scanner <b>314</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, can acquire any of a number of types of image data, all registered to a shared set of spatial coordinates.</p><heading id="h-0007" level="1">OCT Imaging Subsystem</heading><p id="p-0058" num="0057">OCT has been described as a type of &#x201c;optical ultrasound&#x201d;, imaging reflected energy from within living tissue to obtain cross-sectional data. In an OCT imaging system, light from a wide-bandwidth source, such as a super luminescent diode (SLD) or other light source, is directed as a depth-probing output signal along two different optical paths: a reference arm of known length and a sample arm that illuminates the tissue or other subject under study. Reflected and back-scattered light from the reference and sample arms is then recombined in the OCT apparatus and interference effects are used to determine characteristics of the surface and near-surface underlying structure of the sample. Interference data can be acquired by rapidly scanning the sample illumination across the sample. At each of several thousand points, the OCT apparatus obtains an interference profile which can be used to reconstruct an A-scan with an axial depth into the material that is a factor of light source coherence. For most tissue imaging applications, OCT uses broadband illumination sources and can provide image content at depths of up to a few millimeters (mm).</p><p id="p-0059" num="0058">Initial OCT apparatuses employed a time-domain (TD-OCT) architecture in which depth scanning was achieved by rapidly changing the length of the reference arm using, for example, some type of mechanical mechanism, such as a piezoelectric actuator. TD-OCT methods use point-by-point scanning, requiring that the illumination probe be moved or scanned from one position to the next during the imaging session. More recent OCT apparatuses can use a Fourier-domain architecture (FD-OCT) that discriminates reflections from different depths according to the optical frequencies of the signals they generate. FD-OCT methods simplify or eliminate axial scan requirements by collecting information from multiple depths simultaneously and offer improved acquisition rate and signal-to-noise ratio (SNR).</p><p id="p-0060" num="0059">Because of their potential to achieve higher performance at lower cost, FD-OCT systems based on swept-frequency laser sources have attracted significant attention for medical applications that require subsurface imaging in highly scattering tissues. There are two implementations of Fourier-domain OCT: spectral domain OCT (SD-OCT) and swept-source OCT (SS-OCT).</p><p id="p-0061" num="0060">SD-OCT imaging can be accomplished by illuminating the sample with a broadband illumination source and dispersing the reflected and scattered light with a spectrometer onto an array detector such as, for example, a CCD (charge-coupled device) detector. SS-OCT imaging illuminates the sample with a rapid wavelength-tuned laser and collects light reflected during a wavelength sweep using only a single photodetector or balanced photodetector. With both SD-OCT and SS-OCT, a profile of scattered light reflected from different depths is obtained by operating on the recorded interference signals using Fourier transforms, such as Fast-Fourier transforms (FFT), well known to those skilled in the signal analysis arts.</p><p id="p-0062" num="0061">A recent advance for swept-source OCT imaging is the use of a Fourier Domain Mode Locking (FDML) laser source. FDML-OCT scanning offers significant increases in acquisition speed for OCT sampling, as well as increased depth resolution over other OCT types.</p><p id="p-0063" num="0062">Example embodiments of the present disclosure can utilize any of the various types of OCT scanning methods, including time-domain, spectral, or frequency-domain OCT. Because the speed advantage is of particular interest, the description that follows is primarily directed to example embodiments that employ swept-source OCT, a type of frequency-domain OCT that is generally advantageous for faster speed and overall scanning throughput. However, it should be noted that the compressive sampling methods or other available OCT methods can be used to improve the response of time-domain OCT and other types of OCT as well as with SS-OCT. Methods of the present disclosure can also be used where a spectrometer is used for sensing in the OCT system.</p><p id="p-0064" num="0063">According to an example embodiment of the present disclosure, there is provided a hybrid imaging apparatus that obtains OCT scanned data with accompanying color texture content for intraoral features, along with fluorescence image content. The image content that is generated is provided using the same optical probe.</p><p id="p-0065" num="0064">Referring to the schematic diagram of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, an imaging apparatus <b>100</b> is shown for multimodal image acquisition that combines OCT scanning, reflectance imaging, and fluorescence image acquisition modes, and wherein the image data for each mode shares the same spatial registration. Having identical spatial registration relates to acquiring image content, from each mode, with reference to the same sensor position and orientation and obviates the need for mapping of one type of image to another.</p><p id="p-0066" num="0065">Imaging apparatus <b>100</b> has an intraoral probe <b>30</b> that combines the light paths for directed and acquired light of different/multiple imaging modes along a common or shared optical path, shown as an optical axis OA in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and extending outside probe <b>30</b>. The distinct directed output and acquired input signals can then be separated and channeled to/from the corresponding optical subsystems within probe <b>30</b>.</p><p id="p-0067" num="0066">For example, in an OCT light path <b>40</b>, an OCT light source <b>10</b> provides illumination for OCT image scanning. Light source <b>10</b> can employ a super luminescent diode (SLD) or other source that emits continuous wavelength broadband light. Alternately, light source <b>10</b> can be some other type of suitable light source, such as a swept source that emits light with continuously varying spectral content. One advantaged type of swept source is a Fourier Domain Mode Locking (FDML) laser having a high sweep rate and suitable wavelength range for depth-resolved imaging.</p><p id="p-0068" num="0067">In the <figref idref="DRAWINGS">FIG. <b>2</b></figref> configuration, the coherent laser light is directed through a first fiber coupler FC<b>1</b> or wavelength division multiplexer WDM to a second fiber coupler FC<b>2</b>. Fiber coupler FC<b>2</b> splits the light path into a reference arm <b>42</b> and a sample arm <b>44</b>. Light in reference arm <b>42</b> reflects back from a reference mirror <b>48</b> This light is coupled back through fiber coupler FC<b>2</b> and goes to OCT signal detector <b>46</b>. Light directed to sample arm <b>44</b> is directed to the subject or sample S by a scanner <b>24</b>. For intraoral imaging, sample &#x201c;S&#x201d; is a surface location of the patient's mouth, which can include one or more teeth along with gums and other supporting features. For OCT depth-resolved image acquisition, reflected and scattered light from sample &#x201c;S&#x201d; is coupled back through sample arm <b>44</b> to fiber coupler FC<b>2</b> and is conveyed to OCT signal detector <b>46</b>. The light from reference arm <b>42</b> interferes with light from reference arm <b>44</b> to provide the OCT scan data for processing and reconstruction.</p><p id="p-0069" num="0068">In a color reflectance imaging path <b>50</b>, polychromatic or color light is emitted from a color light emitter/detector (CLED) <b>52</b> and directed through fiber coupler FC<b>1</b> or WDM to the second fiber coupler FC<b>2</b>. Coupler FC<b>2</b> acts as a combiner/separator. The polychromatic visible light is combined with the OCT sample light and is simultaneously directed to sample &#x201c;S&#x201d; through an output scanner <b>24</b>, part of intraoral probe <b>30</b>. Returned reflected color light from the surface location, such as the surface of the tooth or other intraoral feature, is conveyed through fiber coupler FC<b>2</b> back to CLED <b>52</b>. CLED <b>52</b> senses the color content from the reflected light to form a reflectance image of sample &#x201c;S&#x201d;. A control logic processor <b>60</b> is in signal communication with OCT signal detector <b>46</b>, CLED <b>52</b>, and light source <b>10</b> to record and process the OCT output data from interference and combine this data with the color data from the intraoral surface. The resulting combined image content can then be presented on a display <b>72</b> and can alternately be communicated, transmitted, and/or stored.</p><p id="p-0070" num="0069">The reflectance image can be used for a variety of purposes, such as to provide a high resolution 2D intraoral image for documentation and patient communication. Its color content (e.g. R, G, and B image values) can also be used for determining the shade of a tooth.</p><p id="p-0071" num="0070">Fluorescence imaging employs components of reflectance imaging path <b>50</b>, optionally using a separate light source for directing excitation illumination of a suitable wavelength range for stimulating the surface location to generate fluorescent light image content. In this case, a long-pass spectral filter can be used in the detector of CLED <b>52</b> to sense the fluorescent light signal, forming a fluorescence image of sample &#x201c;S&#x201d;.</p><p id="p-0072" num="0071">The schematic diagrams of <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref> show similar imaging apparatuses <b>120</b> and <b>140</b>, respectively, having slightly different light path arrangements for combining the OCT and reflectance imaging functions. In the <figref idref="DRAWINGS">FIG. <b>3</b></figref> arrangement of imaging apparatus <b>120</b>, the OCT path can be the same as that described previously with respect to imaging apparatus <b>100</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The light from color light emitter/detector (CLED) <b>52</b> is directed through a fiber coupler FC<b>3</b> and shares the sample arm with OCT light. This combined light is directed to the subject or sample &#x201c;S&#x201d; through scanner <b>24</b>. Backscattered color light from the intraoral surface is conveyed through fiber coupler FC<b>3</b> to color light emitter/detector (CLED) <b>52</b> to measure the color content, recorded and processed by processor <b>60</b>. The resulting combined image content can then be presented on a display <b>72</b> and can alternately be communicated, transmitted, and/or stored.</p><p id="p-0073" num="0072">In the <figref idref="DRAWINGS">FIG. <b>4</b></figref> configuration of imaging apparatus <b>140</b>, the OCT path is the same as that described previously with respect to imaging apparatus <b>100</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The light from color light emitter/detector (CLED) <b>52</b> is directed into the sample path through a dichroic combiner <b>54</b>, that has a reflective surface and a dichroic surface in the configuration shown. Backscattered color light from the intraoral surface is conveyed back to CLED <b>52</b> through combiner <b>54</b> for detection and measurement, recorded and processed by processor <b>60</b>. The resulting combined image content can similarly be presented on a display <b>72</b> and can alternately be communicated, transmitted, and/or stored.</p><p id="p-0074" num="0073">According to an example embodiment of the present disclosure, the different signals that are directed from the scanner to an intraoral surface location share a common axis.</p><heading id="h-0008" level="1">Scanning Method for OCT Imaging</heading><p id="p-0075" num="0074">The schematic diagrams of <figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref> show a scan sequence that can be used for forming tomographic images using the OCT apparatus of the present disclosure in a Fourier domain acquisition. The sequence shown in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> shows how a single B-scan image is generated. Raster scanner <b>24</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) scans the selected light sequence over the subject, sample &#x201c;S&#x201d;, point by point. A periodic drive signal <b>92</b>, as shown in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, is used to drive the raster scanner <b>24</b> galvo mirrors to control a lateral scan or B-scan that extends across each row of the sample, shown as discrete points <b>82</b> extending in the horizontal direction in <figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref>. At each of a plurality of points <b>82</b> along a line or row of the B-scan, an A-scan or depth scan, acquiring data in the z-axis direction, is generated using successive portions of the selected wavelength band. <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> shows drive signal <b>92</b> for generating a straightforward ascending sequence using raster scanner <b>24</b>, with corresponding micro-mirror actuations, or other spatial light modulator pixel-by-pixel pixel actuation, through the wavelength band. The retro-scan signal <b>93</b>, part of drive signal <b>92</b>, simply restores the scan mirror back to its starting position for the next line. No OCT data is obtained during retro-scan signal <b>93</b>.</p><p id="p-0076" num="0075">It should be noted that the B-scan drive signal <b>92</b> drives the galvo mirror of scanner <b>24</b> for raster scanner <b>90</b> as shown in <figref idref="DRAWINGS">FIGS. <b>2</b>-<b>4</b></figref>. At each incremental position, point <b>82</b> along the row of the B-scan, an A-scan is obtained. To acquire the A-scan data, the tuned laser or other OCT light source sweeps through a spectral sequence controlled by a programmable filter in the OCT source <b>10</b>. Thus, in an example embodiment in which the light source sweeps through a 30 nm range of wavelengths, this sequence is carried out at each point <b>82</b> along the B-scan path. As <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> shows, the set of A-scan acquisitions executes at each point <b>82</b>, that is, at each position of the scanner <b>24</b>. By way of example, there can be 2,048 measurements for generating the A-scan at each position <b>82</b>.</p><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>5</b>A</figref> schematically shows the information acquired during each A-scan. An interference signal <b>88</b>, shown with DC signal content removed, is acquired over the time interval for each point <b>82</b>, wherein the signal is a function of the time interval required for the spectral sweep, with the signal that is acquired indicative of the spectral interference fringes generated by combining the light from reference and feedback arms of the OCT interferometer components. The Fourier transform generates a transform T for each A-scan. One transform signal corresponding to an A-scan is shown by way of example in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>.</p><p id="p-0078" num="0077">From the above description, it can be appreciated that a significant amount of data is acquired over a single B-scan sequence. In order to process this data efficiently, a Fast-Fourier Transform (FFT) is used, transforming the time-based signal data to corresponding frequency-based data from which image content can more readily be generated.</p><p id="p-0079" num="0078">In Fourier domain OCT, the A-scan corresponds to one line of spectrum acquisition which generates a line of depth (z-axis) resolved OCT signal. The B-scan data generates a 2D OCT image along the corresponding scanned line.</p><p id="p-0080" num="0079">Raster scanning is used to obtain multiple B-scan data by incrementing the raster scanner <b>24</b> acquisition in the C-scan direction. This is represented schematically in <figref idref="DRAWINGS">FIG. <b>5</b>B</figref>, which shows how 3D volume information is generated using the A-scan, B-scan, and C-scan data.</p><p id="p-0081" num="0080">As noted previously, the wavelength or frequency sweep sequence that is used at each A-scan point <b>82</b> can be modified from the ascending or descending wavelength sequence that is typically used. Arbitrary wavelength sequencing can alternately be used. In the case of arbitrary wavelength selection, which may be useful for some particular implementations of OCT, only a portion of the available wavelengths are provided as a result of each sweep. In arbitrary wavelength sequencing, each wavelength can be randomly selected, in arbitrary sequential order, to be used in the OCT system during a single sweep.</p><heading id="h-0009" level="1">Multimodal Imaging Sequence</heading><p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the combined OCT and color scanning scheme in schematic form. Scanner <b>24</b> steers both the color light beam and OCT light beam to sample &#x201c;S&#x201d; in a two-dimensional (x, y) raster scan at each point <b>82</b>, with x&#x2208;[0,L&#x2212;1] indexed along the x scanning axis. The orthogonal component, y&#x2208;[0, M&#x2212;1] is indexed along the y scanning axis. The color signal with three reflectance values (R(x, y), G(x, y), B(x, y)) and the OCT signal I<sub>OCT</sub>(x,y) with dimension &#x201c;N&#x201d; (for &#x201c;N&#x201d; data points) in the depth direction are acquired corresponding to each scanned position (x, y).</p><p id="p-0083" num="0082">When the 2D scanner <b>24</b> scans continuously, a 2D color image is populated with a number L&#xd7;M of color pixels; correspondingly a 3D OCT volume is reconstructed with values L&#xd7;M&#xd7;N. The (R(x, y), G(x, y), B(x, y)) values are inherently registered with I<sub>OCT</sub>(x,y) along lateral directions. <figref idref="DRAWINGS">FIG. <b>6</b></figref> part (b) shows the inherent mapping provided for the color content at each point <b>82</b> corresponding to the OCT scan, with values (R(x, y), G(x, y), B(x, y)) mapped to corresponding I<sub>OCT</sub>(x,y) measurements. <figref idref="DRAWINGS">FIG. <b>6</b></figref> part (c) shows I<sub>OCT</sub>(x,y,z<sub>i</sub>) with the surface point intensity at (x,y,z<sub>i</sub>), wherein z<sub>i </sub>is depth of surface from a zero-delay line along the A-line OCT signal. The color texture (R(x, y), G(x, y), B(x, y)) is thus mapped directly to the OCT signal at (x,y,z<sub>0</sub>).</p><p id="p-0084" num="0083">An example embodiment of the present disclosure preserves the spatial mapping of data from different imaging modes, including OCT and reflectance imaging, in the surface reconstruction that is formed. The dental chart that is generated from the surface reconstruction can then incorporate data on multiple characteristics of teeth, gums, and other features without the need for separate alignment processing from different types of scanning. This arrangement not only allows the dental chart to be generated without a separate alignment step, but also allows straightforward updating of dental chart contents using subsequent scans. Thus, for example, a complete scan can be used for initial generation of the dental chart, incorporating reflectance image content, color shade, 3D surface profiles, OCT depth-resolved data, and fluorescence data, and preserving the spatial association of each data type. Subsequent to this initial scan, a partial scan can be performed, such as scanning an implant site, an individual tooth requiring treatment, or other partial portion of the dentition. Reconstructed surfaces of the new scan can be stitched to the 3D surfaces of the dental arch initially generated. Updated information for the scanned portion, including updated data from multiple modes, can then be readily aligned with the previously scanned content and used to modify the existing dental chart.</p><heading id="h-0010" level="1">CLED Structure and Functional Components</heading><p id="p-0085" num="0084"><figref idref="DRAWINGS">FIGS. <b>7</b>A, <b>7</b>B, and <b>7</b>C</figref> show different example embodiments of color light emitter/detector CLED <b>52</b>. Laser diodes LD<b>1</b>, LD<b>2</b>, and LD<b>3</b> are red, green and blue laser diodes, respectively. Lenses L<b>1</b>, L<b>2</b> and L<b>3</b> are the corresponding collimation lenses used with each of LD<b>1</b>, LD<b>2</b>, and LD<b>3</b> to generate collimated light beams.</p><p id="p-0086" num="0085">In the <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> arrangement, collimated beams are combined onto the same light path by dichroic mirrors DM<b>1</b> and DM<b>2</b>. Mirrors DM<b>1</b> and DM<b>2</b> have appropriate cutoff wavelengths for corresponding routing of light to and from the light path, such as center wavelengths of red and green laser diodes LD<b>1</b> and LD<b>2</b>. Lens L<b>4</b> couples the light from the shared path into a single mode optical fiber <b>74</b> to provide full color or polychromatic light. Full color light that has been backscattered from the sample &#x201c;S&#x201d; is coupled back to CLED <b>52</b>. Each color light is coupled back to its original channel through beam splitters BS<b>1</b>, BS<b>3</b>, and BS<b>3</b> and a portion of the light power is directed to corresponding photodiodes PD<b>1</b>, PD<b>2</b>, and PD<b>3</b> for measurement.</p><p id="p-0087" num="0086">In the <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> configuration, a trichroic beam splitter TB S with dichroic filters F<b>1</b> and F<b>2</b>, similar to a Philips prism, combines the light from Red, Green, and Blue laser diodes LD<b>1</b>, LD<b>2</b>, and LD<b>3</b> onto optical fiber <b>74</b>, coupled through lens L<b>4</b>. Full color light that has been backscattered from the subject, sample &#x201c;S&#x201d;, is coupled back to CLED <b>52</b>. Each color light is coupled back to its original channel through trichroic beam splitter TBS.</p><p id="p-0088" num="0087">In the <figref idref="DRAWINGS">FIG. <b>7</b>C</figref> configuration, a wave division multiplexer WDM is used for combining and separating the Red, Green, and Blue light from their respective color channels.</p><p id="p-0089" num="0088">In the <figref idref="DRAWINGS">FIG. <b>7</b>D</figref> configuration, a fiber combiner <b>76</b> is used for combining and separating the Red, Green, and Blue light from their respective color channels.</p><p id="p-0090" num="0089">In the <figref idref="DRAWINGS">FIG. <b>7</b>E</figref> configuration, two fiber combiners <b>76</b> are used, one for combining the outgoing Red, Green, and Blue light onto a single channel, the other for separating the returned Red, Green, and Blue light to their respective color channels.</p><p id="p-0091" num="0090">In the <figref idref="DRAWINGS">FIG. <b>7</b>F</figref> configuration, a wide-bandwidth visible light source, such as a supercontinuum laser SCL, serves as the light source for color imaging. The SCL has a continuous visible spectrum output. Wavelength division multiplexer WDM in the path of returned light separates the backscattered light and redirects the light to each respective photodiode PD<b>1</b>, PD<b>2</b>, PD<b>3</b>. A fiber coupler FC is used to couple the light to and from fiber <b>74</b>.</p><p id="p-0092" num="0091">In the <figref idref="DRAWINGS">FIG. <b>7</b>G</figref> configuration, a pair of wave division multiplexers WDM and variable attenuators VA are used to modulate the SCL light in the emission path. A WDM in the path of returned light separates the backscattered light and redirects the light to each respective photodiode PD<b>1</b>, PD<b>2</b>, PD<b>3</b>. A fiber coupler FC is used to couple the light to and from fiber <b>74</b>.</p><p id="p-0093" num="0092">The <figref idref="DRAWINGS">FIG. <b>7</b>H</figref> configuration shows an example embodiment in which RGB light detection is performed at the OCT spectrometer. Input polychromatic light is coupled to the OCT scanning system, as shown in previous <figref idref="DRAWINGS">FIGS. <b>7</b>A-<b>7</b>G</figref>. Detection of the polychromatic light utilizes a spectral separator <b>124</b>, such as a grating or prism to provide spectral separation of the light, directing red, green, and blue light to corresponding detectors <b>126</b><i>r, </i><b>126</b><i>g, </i><b>126</b><i>b </i>at appropriate angles, as determined by grating, prism, or other separator characteristics.</p><heading id="h-0011" level="1">Light Source Options</heading><p id="p-0094" num="0093">Visible light Vis used in the scanner optics can be of multiple wavelengths in the visible light range. The Vis source can be used, for example, for color-coding of the projected structured light pattern. The Vis source can alternately be used for white light image preview or for tooth shade measurement or color or texture characterization.</p><p id="p-0095" num="0094">Vis light can be provided from a conventional bulb source or may originate in a solid-state emissive device, such as a laser or one or more light-emitting diodes (LEDs). Individual Red, Green, and Blue LEDs are used to provide the primary color wavelengths for reflectance imaging.</p><p id="p-0096" num="0095">In addition to providing a structured light pattern, the Vis source can alternately provide light of particular wavelengths or broadband light that is scanned over the subject for conventional reflectance imaging such as, for example, for detecting tooth shade or for obtaining surface contour data by a method that does not employ a light pattern such as, for example, structure-from-motion imaging.</p><p id="p-0097" num="0096">A violet light, in the near-UV region can be used as the excitation light for tooth fluorescence imaging. Backscattered fluorescence can be collected by the OCT light path. The fluorescence image can be detected by the same detector path of the Fourier domain OCT, but at a different lateral spectrum location.</p><heading id="h-0012" level="1">Color Image Processing and Calibration</heading><p id="p-0098" num="0097">For system calibration and imaging, the reflectance imaging apparatus should be calibrated to a reference standard. R, G, B laser emission is adjusted to provide balanced light intensities. Background signals are captured with sample &#x201c;S&#x201d; removed from the sample arm. The R, G, B photodiodes, PD<b>1</b>, PD<b>2</b>, and PD<b>3</b>, respectively, detect background signals that are reflected from the components in the light path. Background signals are subtracted from the R, G, and B signals, respectively. The color image calibration method is similar to that used in color photography which is also adapted in the calculation flowchart of <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0099" num="0098"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows a color calibration sequence that can be used for the color scanner that performs both OCT and RGB imaging. RGB signals are obtained from a calibration target, such as a gray or white light reference patch, in a reference imaging step <b>700</b>. Values from a standard color model such as sRGB of the reference white patch or other calibration target are acquired in a standard color model step <b>710</b>. A least squares calculation or other suitable method for obtaining the calibration transform between the RGB signals and sRGB is performed at a calibration step <b>720</b>, generating a calibration matrix at a transform step <b>730</b>. The calibration matrix is applied to the RGB signals obtained from a reflectance imaging step <b>732</b> to generate a calibrated RGB signal <b>734</b>. This is combined with OCT surface detection obtained in an OCT surface imaging step <b>740</b>. An attachment step <b>750</b> then combines the OCT surface detection data in register with calibrated RGB data to provide a combined output.</p><p id="p-0100" num="0099">The difference in spectral ranges for the two imaging modes makes the combination of OCT light and RGB color light possible, either using spectral division or amplitude division.</p><p id="p-0101" num="0100"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows the spectrum distribution of visible R, G, B light and infrared OCT light waves. As can be readily seen from this mapping, the spectral wavelength ranges are non-overlapping. Visible light ranges from wavelengths of about 380 nm to about 740 nm. The infrared light ranges from wavelengths above 740 nm to about 1600 nm. <figref idref="DRAWINGS">FIG. <b>9</b></figref> also shows related dichroic mirror cut off and bandpass wavelengths for WDM operation. Additional color content can be added to provide more accurate shade matching, such as a violet V wavelength (less than about 450 nm), as shown in the spectral diagram of <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0102" num="0101">Illumination for fluorescence imaging can be at wavelengths near the visible blue region, or in the violet or ultraviolet range.</p><p id="p-0103" num="0102">An alternate approach to meeting the need for combined OCT and color texture image data uses an OCT scanner that is coupled with a color preview camera for obtaining the needed image content. When using this alternate approach, processing is needed in order to register the color texture data with the OCT scan content.</p><heading id="h-0013" level="1">Preserving the Association of Image Data with Corresponding Surface Location</heading><p id="p-0104" num="0103">In each of the <figref idref="DRAWINGS">FIGS. <b>2</b>-<b>4</b></figref> configurations, CLED signal detection and OCT signal detection can be synchronized and share the same optical path in the sample arm to and from the sample probe <b>30</b> and its scanner <b>24</b>.</p><p id="p-0105" num="0104">With high-rate image acquisition for different modes, a substantial amount of image content can be obtained in a single scan using imaging apparatus <b>100</b>. Instead of requiring some type of manual &#x201c;mode-switching&#x201d; or requiring a change in scanning practices, imaging apparatus <b>100</b> can be configured for multimode operation so that each scan of the patient's mouth can acquire image content in multiple modes. With this arrangement, the different types of image content obtained in each scan can be integrated in surface reconstruction, stitching, and display of the complete dental arch. Data that identifies each imaged surface location, typically identified using Cartesian x, y, z coordinates, can be spatially associated with each type of image data that is acquired at that surface location.</p><p id="p-0106" num="0105">Referring to the schematic diagram of <figref idref="DRAWINGS">FIG. <b>10</b>A</figref>, an association of acquired image content to each scanned x, y, z spatial location in the scanner <b>314</b> field of view is shown. Repeated execution of the imaging acquisition sequence during the scan, 3D surface reconstruction, and stitching generates an association between the acquired image content and the calculated x, y, z location coordinates. This spatial association can be formed, stored, and represented in various ways. The <figref idref="DRAWINGS">FIG. <b>10</b>A</figref> example shows generating a set of association vectors <b>510</b> corresponding to each scanned location of the patient dentition. The vector <b>510</b> data structure is merely one example mechanism for representing the association obtained between the spatial location (x, y, z) and the data acquired at that location.</p><p id="p-0107" num="0106">According to an example embodiment of the present disclosure, preserving the association of spatial coordinates with the results of tissue response to a signal follows a similar sequence for each imaging mode. Working backward from the reconstruction and stitching, control logic can relate one image frame to each surface point such as by using the image frame orthogonal to a vector that is orthogonal to the surface point. The data value corresponding to a particular point in the frame can be the most accurate measure of tissue response at a corresponding point on the surface. Data related to a point in the stitched surface can alternately be averaged such as taking a weighted average of all points used for stitching at the location.</p><p id="p-0108" num="0107">Preserving the association of spatial coordinates with the results of tissue response to light or other stimulus at each intraoral location simplifies the problem of matching and mapping the different types of data obtained to an automatically generated dental chart. Instead of requiring computationally intensive methods for feature detection and alignment of separate data content, the preserved association allows the 3D surface reconstruction and stitching operation to serve as a reference for organizing and displaying the information obtained from multiple imaging modes.</p><p id="p-0109" num="0108">In order to preserve the association of the multimodal image content with its spatial coordinates, the stitching algorithm that is used can transform image coordinates and link the corresponding content to the new coordinates in the transformation. The schematic diagram of <figref idref="DRAWINGS">FIG. <b>10</b>B</figref> shows re-mapping of the acquired image content for a set of locations following the stitching transform. Acquired association vectors <b>510</b> provide structure to the measured data for tissue response for locations shown with corresponding spatial coordinates (x<sub>1</sub>, y<sub>1</sub>, z<sub>1</sub>), (x<sub>2</sub>, y<sub>2</sub>, z<sub>2</sub>), and (x<sub>3</sub>, y<sub>3</sub>, z<sub>3</sub>). Following the stitching process, these initial coordinates are transformed to coordinates of the stitched reconstructed 3D surface, represented in this example as spatial coordinates (x<sub>1b</sub>, y<sub>1b</sub>, z<sub>1b</sub>), (x<sub>2b</sub>, y<sub>2b</sub>, z<sub>2b</sub>), and (x<sub>3b</sub>, y<sub>3b</sub>, z<sub>3b</sub>). The stitching transformation thus brings along with it the corresponding data, maintaining the original correspondence between the multimodal measurements acquired at each particular intraoral location and coordinates assigned to a reconstruction from the acquired images. In this way, the 3D surface reconstruction and stitching maintain the registration of different elements of multimodal data to each other, simplifying analysis and presentation of the multimodal image content.</p><heading id="h-0014" level="1">Processing for OCT Imaging</heading><p id="p-0110" num="0109">The flowchart of <figref idref="DRAWINGS">FIG. <b>11</b></figref> shows a method for OCT processing to obtain OCT imaging content along with a surface point cloud extracted from the OCT content according to an example embodiment of the present disclosure. The raw 2D spectral data <b>150</b> with numerous A-scans per each B-scan is provided over the range of wavelength &#x3bb; of the light signal, provided as &#x201c;N&#x201d; lines with &#x201c;M&#x201d; pixels per line. A mapping <b>152</b> then provides a wave-number value &#x201c;k&#x201d; for each corresponding wavelength &#x3bb;. A background subtraction <b>154</b> executes, calculated along the B direction for each k value, and a line of background signal is obtained. Background subtraction <b>154</b>, performed on each A-line, helps to remove fixed pattern noise. In a zero-padding operation <b>156</b> and a phase correction process <b>160</b>, spectrum sampling is corrected and dispersion-induced OCT signal broadening obtained. An FFT processing step <b>162</b> provides processing and scaling of the phase-corrected data to provide input for a 3D volume rendering and 2D cross-section frame display rendering <b>166</b>, useful for visualization and diagnostic support. At the conclusion of step <b>162</b>, the OCT image content is available.</p><p id="p-0111" num="0110">Subsequent processing in the <figref idref="DRAWINGS">FIG. <b>11</b></figref> method then extracts the point cloud for surface characterization and subsequent matching/stitching. A segmentation step <b>170</b> is executed to extract the surface contour data from the OCT volume data. Object surface point cloud generation step <b>172</b> provides the surface point clouds of the measured object. Point clouds can then be used for mesh rendering step <b>174</b> along with further processing. Geometric distortion calibration of OCT images can be executed in order to help correct shape distortion. Unless properly corrected, distortion can result from the scanning pattern or from the optical arrangement that is used. Distortion processing can use spatial calibration data obtained by using a calibration target of a given geometry. Scanning of the target and obtaining the scanned data establishes a basis for adjusting the registration of scanned data to 3D space, compensating for errors in the scanning system. The calibration target can be a 2D target imaged at one or more positions or a 3D target.</p><p id="p-0112" num="0111">Segmentation step <b>170</b>, object surface point cloud generation step <b>172</b> and mesh generation and rendering step <b>174</b> of the <figref idref="DRAWINGS">FIG. <b>11</b></figref> method obtain surface contour data from OCT volume measurements. Importantly, results of these steps are the reconstructed surfaces of the object measured by OCT. When reflectance image data and fluorescence image data are also captured during scanning, the OCT volume, reconstructed 3D surface, 2D reflectance images, and 2D/3D fluorescence images are all linked together, registered to each other, being identified to the same view of sample &#x201c;S&#x201d;.</p><p id="p-0113" num="0112">The generated 3D surface is stitched together to new 3D surfaces reconstructed from scanned data obtained in new views, using matching methods commonly known in the art, such as iterative closest point (ICP) merging. The stitching process also makes use of the spatial calibration data described above. Successful stitching determines the spatial coordinates of each point on the imaged surfaces and thus obtains the correct spatial relationship between different 3D surfaces. In this way, association of spatial locations of the various types of obtained data are preserved. OCT and the multimodal image data content obtained by the scanner can thus be automatically registered, without requiring additional steps.</p><p id="p-0114" num="0113">The 3D surface data, OCT depth-resolved volume, 2D reflectance images, and 2D/3D fluorescence images can be displayed, stored, or transmitted to another computer or storage device. According to an example embodiment of the present disclosure, these multimodal image data can be used to form and to populate a dental chart, as described in more detail subsequently. Processed results of the <figref idref="DRAWINGS">FIG. <b>11</b></figref> method can be directed to subsequent control logic processing for image and diagnostic analysis for generation of information needed for arranging the dental chart.</p><p id="p-0115" num="0114">Depending on applications and imaging conditions, various image segmentation algorithms can be used in segmentation step <b>170</b> of the <figref idref="DRAWINGS">FIG. <b>11</b></figref> method to extract object surfaces. Image segmentation algorithms such as simple direct threshold, active contour level set, watershed, supervised and unsupervised image segmentation, neural network-based image segmentation, spectral embedding and max-flow/min-cut graph-based image segmentation are well known in the image processing fields and can be utilized. They can be applied to the entire reconstructed 3D volume or separately to each 2D frame of the OCT data.</p><p id="p-0116" num="0115"><figref idref="DRAWINGS">FIGS. <b>12</b>A-<b>12</b>E</figref> show different types of imaging content acquired and generated as part of the OCT processing method, using the example of a tooth image having a severe cavity. <figref idref="DRAWINGS">FIG. <b>12</b>A</figref> shows a 2D slice that corresponds to a B-scan for OCT imaging. <figref idref="DRAWINGS">FIG. <b>12</b>B</figref> shows a depth-encoded color projection of the tooth with an optional color bar <b>180</b> as a reference. <figref idref="DRAWINGS">FIG. <b>12</b>C</figref> shows a corresponding slice of the volume rendering obtained from the OCT imaging content. <figref idref="DRAWINGS">FIG. <b>12</b>D</figref> shows the results of segmentation processing of <figref idref="DRAWINGS">FIG. <b>12</b>A</figref> in which points along the tooth surface are extracted. <figref idref="DRAWINGS">FIG. <b>12</b>E</figref> shows a surface point cloud <b>64</b> of the tooth generated from the OCT volume data. The surface point cloud <b>64</b> can be obtained from the OCT volume data following segmentation, as shown previously with respect to the method of <figref idref="DRAWINGS">FIG. <b>11</b></figref>.</p><heading id="h-0015" level="1">Mapping and Analysis of the OCT Data</heading><p id="p-0117" num="0116">As shown in the example images of <figref idref="DRAWINGS">FIGS. <b>12</b>A-<b>12</b>E</figref>, the depth-resolved OCT data that is acquired also supports reconstruction of the surface contour of teeth, gums, and other features of patient dentition and supporting structures. In addition, the depth-resolved data itself is associated or mapped to the reconstructed surface contour. Association of the depth-resolved data with spatial locations on the surface also allows the resulting dental charts that are generated to be spatially associated with analysis or assessment of cavities and other lesions, assessment of the integrity of temporary and permanent fillings, assessment of various prosthetic devices, hardware, and implants. This association can also help to provide indicators of the health of specific areas of the gums and other supporting and nearby tissue.</p><heading id="h-0016" level="1">Surface Contour Imaging using Reflected Light</heading><p id="p-0118" num="0117">Unlike OCT imaging described previously, conventional surface contour imaging uses reflectance imaging and provides data for characterizing a surface, such as surface structure, curvature, and contour characteristics, but does not provide information on material that lies below the surface. Contour imaging data or surface contour image data can be obtained from a structured light imaging apparatus or from an imaging apparatus that obtains structure information related to a surface from a sequence of 2D reflectance images obtained using visible light illumination, generally in the wavelength range above about 380 nm and less than a 740 nm threshold, near-infrared light near and extending higher than 740 nm, or ultraviolet light wavelengths below 380 nm. Alternate techniques for contour imaging include structured light imaging as well as other known techniques for characterizing surface structure such as, for example, feature tracking by triangulation, structure-from-motion photogrammetry, time-of-flight imaging, interferometric-based imaging, and depth-from-focus imaging. Contour image content can alternately be extracted from volume image content such as, for example, from the OCT volume content (as described previously with respect to <figref idref="DRAWINGS">FIG. <b>11</b></figref>) by identifying and collecting only those voxels that represent surface tissue.</p><p id="p-0119" num="0118">The phrase &#x201c;patterned light&#x201d; is used to indicate light that has a predetermined spatial pattern, such that the light has one or more features such as one or more discernable parallel lines, curves, a grid or checkerboard pattern, or other features having areas of light separated by areas without illumination. In the context of the present disclosure, the phrases &#x201c;patterned light&#x201d; and &#x201c;structured light&#x201d; are considered to be equivalent, both used to identify the light that is projected onto the subject in order to derive contour image data.</p><p id="p-0120" num="0119">In structured light imaging, a pattern of lines or other structured pattern is projected from the imaging apparatus toward the surface of an object from a given angle. The projected pattern from the surface is then viewed from another angle as a contour image, taking advantage of triangulation in order to analyze surface information based on the appearance of contour lines. Phase shifting, in which the projected pattern is incrementally shifted spatially for obtaining additional measurements at the new locations, is typically applied as part of structured light imaging, used in order to complete the contour mapping of the surface and to increase overall resolution in the contour image.</p><p id="p-0121" num="0120">Multimodal imaging devices of the present invention may include depth-resolved imaging or conventional surface contour imaging. For example, the TRIOS&#xae; dental intraoral scanner from 3Shape, Copenhagen, Denmark performs surface contour imaging using depth-from-focus technique and captures color reflectance images and tooth shades during scanning. The CEREC&#x2122; Omnicam&#x2122; system from Dentsply Sirona, Salzburg, Austria performs surface contour imaging using structured light triangulation technique and captures color reflectance images and tooth shades during scanning. International Patent Application No. US 2014/070719 entitled &#x201c;Intra-Oral 3-D Fluorescence Imaging&#x201d; by Inglese et al. captures 3D surface contours using structured light triangulation, color reflectance images, and 2D/3D fluorescence images.</p><heading id="h-0017" level="1">3D Arch Surface Reconstruction</heading><p id="p-0122" num="0121">Reconstruction of the 3D mesh corresponding to a full arch is typically done by acquiring a series of slightly overlapping intraoral 3D surface views and stitching them together. The process of identifying over which portion of the mesh under construction the newly acquired view overlaps is referred to as &#x201c;matching&#x201d; or &#x201c;stitching&#x201d;. Employing matching methods familiar to those in the surface contour imaging arts, an intraoral 3D scanner can generate a 3D mesh of an entire arch of a patient as the separate views are acquired.</p><p id="p-0123" num="0122">As was described previously with reference to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, multiple OCT measurements can alternately be used for 3D surface reconstruction, following the same stitching process described above. The OCT data from successive scans is processed to identify surface content. With respect to the description related to <figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref>, the surface features are readily provided by identifying the outermost A-scan data for each B- and C-scan position.</p><heading id="h-0018" level="1">Generating and Populating the Dental Chart</heading><p id="p-0124" num="0123">According to an example embodiment of the present disclosure, the image content from any of the available imaging modes can be spatially associated with the surface reconstruction that is generated following a scan. For any of the image data obtained in a scan, spatial locations are automatically determined as a result of successful stitching. The surface reconstruction that is generated preserves the association of spatial coordinates with the image data that shows the response of tissue in the various modes. Thus, for example, a given coordinate of the surface reconstruction can be associated with a particular reflectance imaging value such as an R, G, B value, with a shade, with a fluorescence value, and with OCT depth imaging content. Combined information for multiple imaging modes can thus be associated with coordinate space without the need for separate calibration, alignment, or matching logic.</p><p id="p-0125" num="0124">For example, the reflectance image content and OCT scan content for a particular intraoral surface location can be associated with a location on the 3D arch surface reconstruction. This reconstruction can then be used for forming and populating a dental chart, preserving the spatial coordinate information related to each corresponding area of the dental chart.</p><p id="p-0126" num="0125">The flowchart of <figref idref="DRAWINGS">FIG. <b>13</b></figref> shows a method for generating a dental chart according to scanned data from a scanner device capable of capturing multimodal image content, such as reflectance imaging, OCT scanning, and fluorescence imaging. A scanning step S<b>1920</b> acquires 3D contour data and other multimodal image data content. A reconstruction and stitching step S<b>1930</b> then reconstructs a 3D surface contour using a subset of the scanned data. As part of step S<b>1930</b>, the reconstruction and stitching operation obtains the spatial coordinate information related to image content from multimodal imaging.</p><p id="p-0127" num="0126">Continuing with the <figref idref="DRAWINGS">FIG. <b>13</b></figref> method, a segmentation step S<b>1940</b> then performs tooth segmentation and labeling, based on spatial relationships of the surface points obtained in step S<b>1930</b> and using utilities and approaches familiar to those skilled in the image reconstruction arts. An outline generation step S<b>1950</b> generates outline data suitable for dental chart construction such as, for example, providing line art for side and top views. An analysis step S<b>1960</b> then analyzes the scan data for the teeth and associated gum structures and associates the analysis with elements of the dental chart. A display step S<b>1970</b> presents the generated dental chart for viewing on a display and, alternately, stores the chart for future reference or for transmitting or communicating to another computing device or data storage unit.</p><p id="p-0128" num="0127">The generated chart can be updated using subsequent scan data from the same multimodal scanner device. Because the internal spatial reference of the scanner is unchanged, the reconstructed 3D surface from the newly scanned data can be stitched to the existing dentition, thereby establishing spatial locations of the new multimodal image data. The existing and updated analysis results at any part of the tooth can be easily compared to bring attention to changing conditions such as, for example, presence of fillings (e.g., amalgam, composite) or prosthesis (e.g., crown, bridge, veneer, denture), absence of tooth, onset of caries, development of cracks, recession of gum line, and erosion of enamel.</p><p id="p-0129" num="0128">Because it acquires some amount of depth data, depth-resolved imaging data (such as, for example, OCT scan data or alternately ultrasound or photoacoustic data) includes information that can be used for analysis of the condition of teeth and gums. Ultrasound images are useful for detecting periodontal pocket depths. The reflectance image content can provide accurate information on tooth contour and overall geometry, as well as detailed surface features for teeth, gums, and other structures. Fluorescence image content is useful for detecting caries, mineralization state, plaque, and prosthetic materials on the tooth. Each type of information can be used to populate the dental chart that is generated, allowing ready reference to detailed data about specific features of patient dentition.</p><p id="p-0130" num="0129">Presentation of detailed information can take various forms. According to an example embodiment of the present disclosure, various types of information can be selectively enabled or hidden from view as desired by the practitioner. This can help to reduce confusion, while still allowing association and storage of significant information accessible from the dental chart. A layered model can be adapted so that more specialized information of a particular type is presented as an &#x201c;overlay&#x201d;. Thus, for example, information on gum condition can be separately enabled from information on teeth such as cavities, fillings, implants, or other features.</p><p id="p-0131" num="0130">In addition to generating dental charts in standard view formats, an example embodiment of the present disclosure can provide some degree of manipulation of standard views, for example, allowing perspective views. Cross-sectional views (for example, corresponding to OCT B-scans as described previously) can be viewed at locations of interest. A progressive sequence of views can alternately be presented so that the view angle is adjusted based on cursor position. Coordinate locations can also be displayed for various features, allowing the conventional &#x201c;flattened&#x201d;, 2-D dental chart to include annotation that is descriptive of the actual position of a tooth or other feature.</p><p id="p-0132" num="0131"><figref idref="DRAWINGS">FIGS. <b>14</b>A, <b>14</b>B, and <b>14</b>C</figref> show various aspects of a dental chart generated and displayed according to an example embodiment of the present invention. In <figref idref="DRAWINGS">FIG. <b>14</b>A</figref>, a displayed dental chart <b>270</b> is shown. Individual entries in dental chart <b>270</b> can be linked to surface contour images <b>276</b>, shown in low-resolution or thumbnail form in <figref idref="DRAWINGS">FIG. <b>14</b>A</figref>. Coordinate references <b>272</b> obtained as part of the scan can be provided on the display. Features such as hovering using a mouse or other pointer can provide both coordinate reference data and any associated image content that relates to an indicated location.</p><p id="p-0133" num="0132">By way of example, <figref idref="DRAWINGS">FIG. <b>14</b>B</figref> shows an enlarged area E<b>1</b> of the dental chart <b>270</b>, schematically showing a few teeth <b>120</b>. Related information for one of the teeth <b>120</b> includes an area of suspected caries <b>122</b>. <figref idref="DRAWINGS">FIG. <b>14</b>C</figref> includes additional information, highlighting a nearby portion of the gum tissue <b>124</b> that may be bleeding or show other conditions. Display for various detected conditions of teeth and gums can be separately enabled or disabled, as described previously, allowing the practitioner to focus on particular conditions of interest or concern.</p><p id="p-0134" num="0133"><figref idref="DRAWINGS">FIG. <b>14</b>D</figref> shows an example of a generated dental chart <b>270</b> with a top view of the patient's dentition.</p><p id="p-0135" num="0134"><figref idref="DRAWINGS">FIG. <b>14</b>E</figref> shows an example of a generated dental chart <b>270</b> with a perspective view of the patient's dentition. As shown in <figref idref="DRAWINGS">FIGS. <b>14</b>D and <b>14</b>E</figref>, a reference origin &#x201c;R&#x201d; can be displayed, providing a reference datum for the spatial coordinate associations that are preserved in the reconstruction. A number of thumbnail images <b>280</b> can be provided to show the various types of information available for a selected tooth or gum area.</p><p id="p-0136" num="0135">According to an example embodiment of the present disclosure, the graphical arrangement of dental chart data that has been automatically generated can be displayed in a standard dental chart format familiar to the practitioner or in a 3D format or other format using tooth outline generated according to the procedures described above. A toggle or other command can be provided in order to select the display format preferred by the practitioner according to an entered operator instruction. Display format options can include the flat, 2D alignment of the traditional dental chart as shown in the example of <figref idref="DRAWINGS">FIG. <b>14</b>A</figref>, the flat 2D plan view or top view from a standard chart or from the patient image as shown in the <figref idref="DRAWINGS">FIG. <b>14</b>D</figref> example, or the perspective 3D view of the upper or lower jaw as shown in <figref idref="DRAWINGS">FIG. <b>14</b>E</figref>. Pan, zoom and 3D rotation for individual teeth, for sets of teeth, or for the jaw structure can be displayed using various dental chart representations shown in the examples of <figref idref="DRAWINGS">FIGS. <b>14</b>A-<b>14</b>E</figref>. The position of origin &#x201c;R&#x201d; can be adjusted, with corresponding changes made to other coordinates of the populated dental chart.</p><p id="p-0137" num="0136">Various dental chart arrangements can be displayed. For example, the conventional dental chart arrangement shown in <figref idref="DRAWINGS">FIGS. <b>14</b>A-<b>14</b>C</figref> can be most preferred by experienced practitioners, who may find this configuration most readily usable and can take advantage of added features that allow viewing different types of information available from the populated dental chart. The alternative views of <figref idref="DRAWINGS">FIGS. <b>14</b>D and <b>14</b>E</figref> can be valuable for viewing specific information about the spatial arrangement of the teeth and may be more useful in assessing how the teeth are disposed with respect to each other within the jaw. Annotation can be provided for different dental chart embodiments, allowing the practitioner and staff, for example, to record various data during examination or cleaning. <figref idref="DRAWINGS">FIG. <b>14</b>D</figref> shows an arrangement of annotations <b>282</b> that can be displayed showing, for example, practitioner observations or showing details detected in an automated analysis of tooth condition. Labeling, such as with a tooth number, can be provided and can track tooth position, following the displayed content such as when a 3D view of the dentition is rotated or during zoom or pan operations.</p><p id="p-0138" num="0137">The flowchart of <figref idref="DRAWINGS">FIG. <b>15</b></figref> shows a method including steps that can be executed for automating the process of dental chart preparation using acquired multimodal image data according to an example embodiment of the present disclosure. Multimodal image content is obtained in an acquisition step S<b>1510</b>. The multimodal image content can be acquired by using a single imaging signal, such as a visible light source that has the spectral bandwidth to provide both reflectance imaging content and fluorescence. Spatial coordinates are retained with the image acquisition and provide a mechanism for automatic association of image content originating from multiple imaging modes. Alternately, acquisition step S<b>1510</b> can use multiple output imaging signals such as employing light signals of different bandwidths acquired simultaneously or in close sequence, directed along a common axis. In a surface contour generation step S<b>1520</b>, control logic in the intraoral probe generates a surface contour using the acquired multimodal image content. Stitching logic is used to join adjacent images, again preserving the association of spatial coordinates for the multimodal image content. A tooth outline generation step S<b>1530</b> then executes and in which probe logic can generate tooth outlines for use in the dental chart. Dental chart setup step S<b>1540</b> can then assemble the dental chart using the sequence of tooth outlines obtained in step S<b>1530</b> to show a spatial ordering of teeth as well as supporting gum tissue adjacent to the teeth. Each assembled element of the dental chart can then be associated with corresponding multimodal image content in a dental chart population step S<b>1550</b>. Step S<b>1550</b> analyzes the multimodal image content and associates results of this analysis with positions and features of the assembled dental chart. A display step S<b>1560</b> then renders the dental chart to a display, as well as generating any necessary data file for storage, transmission, or communication of the populated dental chart to other systems.</p><p id="p-0139" num="0138">In addition to image content acquired using an intraoral imaging device, example embodiments of the present disclosure can also use, as multimodal image content, image data obtained from extraoral imaging apparatus such as bite-wing and periapical dental x-ray or cone beam computed tomography (CBCT) systems. Imaging modes using radiation can be associated with spatial coordinates for the intraoral image content using various utilities for feature recognition. For example, the volume image obtained using CBCT processing can be registered to the surface contour or surface mesh obtained by the intraoral imaging apparatus using volume image registration methods commonly known in the art. X-ray and CBCT image content can thus be correlated to the dental chart for ready reference and display.</p><p id="p-0140" num="0139">Advantageously, spatial correlation of image content from multiple imaging modes can be readily achieved using an example embodiment of the present disclosure. No processing delay is needed for separate registration processing for image content that is obtained from the scanner <b>314</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>). Coordinates of the surface reconstruction can be associated with a particular reflectance imaging value such as with an R, G, B value, with a shade, with a fluorescence value, and with OCT depth imaging content, as well as with x-ray and CBCT image content. Combined information for multiple imaging modes can thus inventively be associated with intraoral coordinate space without the need for separate calibration, alignment, or matching logic and the processing overhead required to achieve registration for image data of different types related to patient dentition.</p><heading id="h-0019" level="1">Update Utilities and Workflow</heading><p id="p-0141" num="0140">The capability for straightforward spatial association of image data of different modes provides a number of options and features useful for improving the update process. As noted previously, it can be helpful to image a single tooth or a small portion of the jaw during treatment such as periodically during various stages of implant preparation or in order to track ongoing progress of a suspected caries condition, using the same or another calibrated multimodal intraoral scanner. Example embodiments of the present disclosure support update in a number of ways, including the following:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0141">(i) Dental chart generation and update options. As one option, the practitioner can choose to generate a new dental chart, such as with a full scan of intraoral surfaces and a repetition of the chart generation processing described hereinabove. By default, the previously acquired dental chart and associated image content can be stored or archived to maintain historical data for the patient when the new chart is generated. Alternately, the practitioner can opt to update the existing chart with new information specific to one or more teeth or intervening tissue areas or with new image content relative to specific imaging modes. This type of partial update requires that the new surface reconstruction be stitched to the surfaces of the existing dentition, thereby allowing the new content that is associated with the new surface reconstruction be mapped to coordinates of the existing dental chart. Techniques to support stitching of the newly reconstructed surface to the existing reconstructed surface are familiar to those skilled in the imaging arts. The dental chart update option can be fully automated or may benefit from some measure of operator input, such as a touch screen, mouse, or keyboard entry that coarsely identifies the tooth location being probed and scanned by the operator.</li>        <li id="ul0002-0002" num="0142">(ii) Localized highlighting relative to the update position and/or content. As noted previously, the practitioner can have the capability to select a display format for the dental chart, such as showing the conventional 2D array view (<figref idref="DRAWINGS">FIGS. <b>14</b>A-C</figref>), a plan view or top schematic view (<figref idref="DRAWINGS">FIG. <b>14</b>D</figref>), or a perspective 3D view (<figref idref="DRAWINGS">FIG. <b>14</b>E</figref>). To support update scanning operation with the intraoral probe or scanner <b>314</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>), any of a number of highlighting schemes can be selected. <figref idref="DRAWINGS">FIG. <b>16</b></figref> shows highlighting <b>330</b> positioned on a perspective view of the dental chart and showing the current position of scanner <b>314</b>, relative to the overall patient dentition, for the newly acquired image content. This type of visual operator feedback can be helpful to the practitioner or technician for assurance that the proper area for update is being imaged. Other types of highlighting can help to indicate various imaging modes for which data is acquired. Color-coding can be used to indicate which type of image content is available or is currently being updated such as, for example, orange for OCT image content and green for fluorescent content. Color or other highlighting method can also be used to indicate processing status. Boundary coordinates for relating the scanned area to the overall dental chart and origin &#x201c;R&#x201d; can also be displayed if useful to the technician or practitioner.</li>        <li id="ul0002-0003" num="0143">(iii) Chart-guided update. According to an example embodiment, markup utilities are provided for identifying areas needing image content update by entries made on the dental chart. Using this scheme, the electronically generated, populated dental chart can be a useful tool for improved communication and for advancing workflow for the dental treatment team. For example, a practitioner may want updated image content for teeth numbers 8-11 and for gum tissue between teeth numbers 2 and 5. The practitioner can electronically mark the dental chart by entering operator instructions such as by using a mouse or touchscreen entry. The schematic diagram of <figref idref="DRAWINGS">FIG. <b>17</b></figref> shows example entries of touchscreen instructions that identify particular teeth or other features such as by using simple outlining as shown. A popup menu <b>290</b> can provide selections that allow the practitioner to specify imaging modes for scan information to be acquired. Using the same or another calibrated multimodal intraoral scanner, the update process can be carried out without other detailed positioning sequence. The technician can operate the probe or scanner <b>314</b>, scanning over the teeth of interest and can receive on-screen or audible operator feedback indicating that some or all requested information from the practitioner entries has been obtained and updated. This sequence simplifies the acquisition and processing of information without requiring written or verbal instructions and consequent risk of confusion.</li>        <li id="ul0002-0004" num="0144">(iv) Time-lapse display using stored &#x201c;historical&#x201d; content for one or more modes. As part of the update process, previously stored image content of one or more imaging modes can be retained for future analysis and presentation. Thus, for example, progression of a caries condition at one or more teeth over time can be readily observed and displayed in fluorescence 2D images or OCT cross-sectional (B-scan) images, with the successively stored image content in registration and rendered to the display in time sequence, following the familiar model of a time-lapse video. Time information related to each stored image can also be displayed as an aid to tracking progress and rate for a condition. A selection button or other instruction entry tool on the populated dental chart enables selection and &#x201c;playback&#x201d; of previously stored views and includes the capability for specifying the particular modes of image content that display.</li>    </ul>    </li></ul></p><p id="p-0142" num="0145">The invention has been described in detail with particular reference to presently understood example embodiments, but it should be appreciated and understood that variations and modifications can be affected within the spirit and scope of the invention.</p><p id="p-0143" num="0146">For example, control logic processor <b>340</b> can be any of a number of types of logic processing device including, without limitation, a computer or computer workstation, a dedicated host processor, a microprocessor, a digital signal processor, logic array, or other device that executes stored program logic instructions.</p><p id="p-0144" num="0147">The presently disclosed example embodiments are, therefore, considered in all respects to be illustrative and not restrictive. The scope of the invention is indicated by the appended claims, and all changes that come within the meaning and range of equivalents thereof are intended to be embraced therein.</p><p id="p-0145" num="0148">Consistent with at least one example embodiment, example methods/apparatus can use a computer program with stored instructions that operate on image data that is accessed from an electronic memory. As can be appreciated by those skilled in the image processing arts, a computer program of an example embodiment herein can be utilized by a suitable, general-purpose computer system such as a personal computer or workstation. However, many other types of computer systems can be used to execute the computer program of described example embodiments including, for example, an arrangement of one or networked processors.</p><p id="p-0146" num="0149">A computer program for performing methods of certain example embodiments described herein may be stored in a computer readable storage medium. This medium may comprise, for example and not limitation: magnetic storage media such as a magnetic disk, a hard drive, or removable device or magnetic tape; optical storage media such as an optical disc, optical tape, or machine readable optical encoding; solid state electronic storage devices such as random access memory (RAM) or read only memory (ROM); or, any other physical device or medium employed to store a computer program. Computer programs for performing example methods of described embodiments may also be stored on computer readable storage medium that is connected to the image processor by way of the Internet or other network or communication medium. Those skilled in the art will further readily recognize that the equivalent of such a computer program product may also be constructed in hardware.</p><p id="p-0147" num="0150">It should be noted that the term &#x201c;memory&#x201d; is equivalent to &#x201c;computer-accessible memory&#x201d; in the context of the present disclosure, and can refer to any type of temporary or more enduring data storage workspace used for storing and operating upon image data and accessible to a computer system including, for example, a database. The memory could be non-volatile using, for example, a long-term storage medium such as magnetic or optical storage. Alternately, the memory could be of a more volatile nature using an electronic circuit such as random-access memory (RAM) that is used as a temporary buffer or workspace by a microprocessor or other control logic processor device. Display data, for example, is typically stored in a temporary storage buffer that can be directly associated with a display device and is periodically refreshed as needed in order to provide displayed data. This temporary storage buffer can also be considered to be a memory, as the term is used in the present disclosure. Memory is also used as the data workspace for executing and storing intermediate and final results of calculations and other processing. Computer-accessible memory can be volatile, non-volatile, or a hybrid combination of volatile and non-volatile types.</p><p id="p-0148" num="0151">It should be appreciated and understood that computer program products for example embodiments herein may make use of various image manipulation algorithms and/or processes that are well known. It should be further appreciated and understood that example computer program product embodiments herein may embody algorithms and/or processes not specifically shown or described herein that are useful for implementation. Such algorithms and processes may include conventional utilities that are within the ordinary skill of the image processing arts. Additional aspects of such algorithms and systems, and hardware and/or software for producing and otherwise processing the images or co-operating with the computer program product of the application, are not specifically shown or described herein and may be selected from such algorithms, systems, hardware, components and elements known in the art.</p><p id="p-0149" num="0152">Example embodiments according to the present disclosure can include various features described herein individually or in combination.</p><p id="p-0150" num="0153">While the invention has been illustrated with respect to one or more implementations, alterations and/or modifications can be made to the illustrated examples without departing from the spirit and scope of the appended claims. In addition, while a particular feature of the invention may have been disclosed with respect to only one of several implementations/example embodiments, such feature can be combined with one or more other features of the other implementations/example embodiments as can be desired and advantageous for any given or particular function. The term &#x201c;a&#x201d; or &#x201c;at least one of&#x201d; is used to mean one or more of the listed items can be selected. The term &#x201c;about&#x201d; indicates that the value listed can be somewhat altered, as long as the alteration does not result in nonconformance of the process or structure to the illustrated example embodiment. Other embodiments of the invention may become apparent to those skilled in the art from consideration of the specification and practice of the invention disclosed herein. It is intended that the specification and examples be considered as examples only, with a true scope and spirit of the invention being indicated by the following claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for intraoral imaging, the method comprising the steps of:<claim-text>(a) generating one or more output imaging signals from an intraoral probe;</claim-text><claim-text>(b) acquiring multimodal image content from each of a plurality of intraoral surface locations for a patient's dentition according to tissue response from the one or more imaging signals and associating spatial coordinates to the acquired multimodal image content;</claim-text><claim-text>(c) generating a surface contour of the patient dentition by reconstructing and stitching from a data subset of the acquired multimodal image content, and preserving the association of spatial coordinates of the multimodal image content to the stitched surface contour;</claim-text><claim-text>(d) generating tooth outlines for one or more teeth from the generated surface contour and arranging the generated outlines as a dental chart representing a spatial ordering of the one or more teeth and of supporting gum tissue adjacent to the teeth;</claim-text><claim-text>(e) populating the dental chart by analyzing the acquired multimodal image content and indicating analysis results at one or more positions on the dental chart according to the preserved association of spatial coordinates; and</claim-text><claim-text>(f) displaying the populated dental chart.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of acquiring multimodal image content comprises directing the first and second output imaging signals along a common imaging path.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the method further comprises a step of updating a populated dental chart by:<claim-text>(i) acquiring updated multimodal image content from one or more intraoral surface locations;</claim-text><claim-text>(ii) reconstructing updated surface views from a data subset of the updated multimodal image content;</claim-text><claim-text>(iii) stitching the reconstructed updated surface views to the surface contour of the patient dentition; and</claim-text><claim-text>(iv) mapping the updated multimodal image content to spatial coordinates according to the populated dental chart.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the method further comprises a step of highlighting the relative location of the updated multimodal image content on the populated dental chart.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the highlighting is color-coded according to the mode of the updated multimodal image content.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the method further comprises a step of indicating a relative position of an intraoral scanner with respect to patient dentition on the populated dental chart.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein displaying indicates a status for acquisition or processing of one or more modes of image content.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of displaying the populated dental chart further comprises presenting either a flat 2D view or a perspective 3D view in response to an operator instruction.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the step of displaying the populated dental chart further comprises displaying partial analysis results for one or more imaging modes in response to an operator instruction.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the method further comprises the steps of storing multimodal image content from successive imaging sessions, and rendering successive versions of the stored image content to the display.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the method further comprises a step of updating a populated dental chart by:<claim-text>(i) accepting operator instruction entries that specify one or more intraoral surface locations requiring updated multimodal image content;</claim-text><claim-text>(ii) acquiring the updated multimodal image content from the one or more intraoral surface locations;</claim-text><claim-text>(iii) mapping the acquired updated image content to spatial coordinates according to the populated dental chart; and</claim-text><claim-text>(iv) highlighting the relative location of the updated image content on the populated dental chart.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the method further comprises a step of providing visual or audible operator feedback on acquisition status.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more output imaging signals differ from each other in at least one of wavelength range, wavelength sequence, bandwidth, or coherence.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a first output imaging signal comprises color light, from three or more primary colors.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a first output imaging signal comprises a swept source laser.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the tissue response to the first output imaging signal includes fluorescence.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. A method for intraoral imaging, the method comprising the steps of:<claim-text>(a) generating a plurality of output imaging signals from an intraoral probe, wherein the output imaging signals are directed along a common axis and wherein the generated signals differ from each other in at least one of wavelength range, wavelength sequence, bandwidth, or coherence length;</claim-text><claim-text>(b) acquiring multimodal image content from each of a plurality of intraoral surface locations for a patient's dentition according to tissue response to the plurality of output imaging signals and associating spatial coordinates to the acquired multimodal image content;</claim-text><claim-text>(c) generating a surface contour of the patient dentition by reconstructing and stitching from a data subset of the acquired multimodal image content, and preserving the association of spatial coordinates of the multimodal image content to the stitched surface contour;</claim-text><claim-text>(d) generating tooth outlines for one or more teeth from the generated surface contour and arranging the generated outlines as a dental chart representing a spatial ordering of the one or more teeth according to the preserved association of spatial coordinates;</claim-text><claim-text>(e) populating the dental chart by analyzing the acquired multimodal image content and associating the analysis to positions on the dental chart according to the preserved association of spatial coordinates; and</claim-text><claim-text>(f) displaying the populated dental chart.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the step of displaying the populated dental chart comprises displaying a spatial coordinate for an intraoral feature.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the plurality of output imaging signals comprises a coherent laser beam.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the coherent laser beam repeatedly changes in wavelength.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the plurality of output imaging signals comprises an ultrasound signal.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the step of populating the dental chart comprises associating image content of two or more different imaging modes to a tooth on the dental chart.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. A method for intraoral imaging, the method comprising the steps of:<claim-text>(a) obtaining multimodal image content at each of a plurality of intraoral surface locations from an intraoral probe that is configured to sequentially:<claim-text>(i) direct polychromatic visible illumination to the surface location and acquire surface image content associated with the surface location from reflected polychromatic light; and</claim-text><claim-text>(ii) direct a surface contour imaging signal to the surface location;</claim-text></claim-text><claim-text>(b) reconstructing a surface contour of the patient dentition from the obtained multimodal image content, wherein the reconstruction preserves the spatial association of the acquired surface image content and the reconstructed surface contour;</claim-text><claim-text>(c) generating tooth outlines for one or more teeth from the reconstruction and arranging the generated outlines as a dental chart representing a spatial ordering of the one or more teeth and of supporting gum tissue adjacent to the teeth;</claim-text><claim-text>(d) analyzing the acquired image content;</claim-text><claim-text>(e) populating the dental chart by associating analysis results to positions on the dental chart; and</claim-text><claim-text>(f) displaying the populated dental chart.</claim-text></claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the step of populating the dental chart comprises highlighting one or more portions of the analysis results.</claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The method of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the acquired surface image content includes a color image.</claim-text></claim><claim id="CLM-00026" num="00026"><claim-text><b>26</b>. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the step of populating the dental chart comprises highlighting the tooth outline using color or shading according to the analysis results.</claim-text></claim><claim id="CLM-00027" num="00027"><claim-text><b>27</b>. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the method further comprises a step of storing, transmitting, or communicating the populated dental chart.</claim-text></claim><claim id="CLM-00028" num="00028"><claim-text><b>28</b>. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the method further comprises the steps of directing an excitation illumination of an excitation wavelength range to the surface location, and acquiring fluorescent light image content associated with the surface location, wherein fluorescent wavelengths of the acquired fluorescent light image content lie outside the excitation wavelength range, and wherein the step of reconstructing further preserves the spatial association of the acquired surface image content with the fluorescent light image content and the reconstructed surface contour.</claim-text></claim><claim id="CLM-00029" num="00029"><claim-text><b>29</b>. The method of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the excitation illumination is provided from a light source that is also used for the polychromatic illumination.</claim-text></claim><claim id="CLM-00030" num="00030"><claim-text><b>30</b>. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the surface contour imaging signal acquires depth-resolved image content.</claim-text></claim><claim id="CLM-00031" num="00031"><claim-text><b>31</b>. A method for intraoral imaging, the method comprising the steps of:<claim-text>(a) obtaining multimodal image content at each of a plurality of surface locations within a patient's mouth from an intraoral probe that is configured to sequentially:<claim-text>(i) direct polychromatic visible illumination to the surface location and acquire 2D image content associated with the surface location from reflected polychromatic light; and</claim-text><claim-text>(ii) direct a point-by-point scan sequence of coherent light beams that penetrate points along the surface location, modulating the wavelength of the scanned coherent light beams at each penetrated point over a wavelength range, to acquire an interference signal having depth-resolved image content;</claim-text><claim-text>wherein the polychromatic visible illumination and sequence of coherent light beams are directed along a common optical axis of the intraoral probe;</claim-text></claim-text><claim-text>(b) reconstructing a surface contour of the patient dentition from the obtained multimodal image content, wherein the reconstruction preserves the association of the acquired 2D image content and depth-resolved image content with each surface location;</claim-text><claim-text>(c) generating tooth outlines for one or more teeth from the reconstruction and arranging the generated outlines as a dental chart representing a spatial ordering of the one or more teeth and of supporting gum tissue adjacent to the teeth;</claim-text><claim-text>(d) analyzing the acquired image content and populating the dental chart by associating analysis results to positions on the dental chart; and</claim-text><claim-text>(e) displaying the populated dental chart.</claim-text></claim-text></claim><claim id="CLM-00032" num="00032"><claim-text><b>32</b>. An intraoral probe, comprising:<claim-text>(a) signal generation circuitry energizable to generate one or more output imaging signals;</claim-text><claim-text>(b) one or more imaging sensors capable of generating multimodal image content from each of a plurality of intraoral surface locations for a patient's dentition according to detected tissue response to the one or more generated imaging signals;</claim-text><claim-text>(c) a control logic processor in signal communication with the signal generation circuitry and with the one or more sensors and configured with programmed instructions to:<claim-text>(i) associate spatial coordinates corresponding to the intraoral surface locations with the acquired multimodal image content;</claim-text><claim-text>(ii) generate a surface contour of the patient dentition by reconstructing and stitching from a data subset of the acquired multimodal image content while preserving the association of spatial coordinates of the multimodal image content to the stitched surface contour;</claim-text><claim-text>(iii) generate tooth outlines for one or more teeth from the generated surface contour;</claim-text><claim-text>(iv) arrange the generated outlines as a dental chart representing a spatial ordering of the one or more teeth and of supporting gum tissue adjacent to the teeth;</claim-text><claim-text>(v) populate the dental chart by analyzing the acquired multimodal image content and by associating the analysis to positions on the dental chart according to the preserved association of spatial coordinates; and</claim-text><claim-text>(d) a display in signal communication with the control logic processor for displaying the populated dental chart.</claim-text></claim-text></claim-text></claim></claims></us-patent-application>
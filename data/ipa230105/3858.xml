<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003859A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003859</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17929767</doc-number><date>20220906</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>7</main-group><subgroup>4912</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>7</main-group><subgroup>481</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>931</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>7</main-group><subgroup>4912</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>7</main-group><subgroup>4816</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>931</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>27</main-group><subgroup>1446</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">REAL TIME NOISE DETECTION METHOD AND SYSTEM FOR PHOTON COUNTING PIXEL ARRAY COMPRISING A MASK MATERIAL TO YIELD BLOCKED PIXELS FROM DETECTING REFLECTED PULSES OF ENERGY</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17062856</doc-number><date>20201005</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11486987</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17929767</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Argo AI, LLC</orgname><address><city>Pittsburgh</city><state>PA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Hostetler</last-name><first-name>John</first-name><address><city>Hightstown</city><state>NJ</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Tachwali</last-name><first-name>Yahia</first-name><address><city>Princeton</city><state>NJ</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A single photon counting sensor array includes one or more emitters configured to emit a plurality of pulses of energy, and a detector array comprising a plurality of pixels. Each pixel includes one or more detectors, a plurality of which are configured to receive reflected pulses of energy that were emitted by the one or more emitters. A mask material is positioned to cover some but not all of the detectors of the plurality of pixels to yield blocked pixels and unblocked pixels so that each blocked pixel is prevented from detecting the reflected pulses of energy and therefore only detects intrinsic noise.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="99.06mm" wi="152.74mm" file="US20230003859A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="151.47mm" wi="94.40mm" file="US20230003859A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="225.04mm" wi="90.00mm" file="US20230003859A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="117.35mm" wi="154.77mm" file="US20230003859A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="197.78mm" wi="112.69mm" file="US20230003859A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="124.04mm" wi="165.02mm" file="US20230003859A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="151.98mm" wi="150.71mm" file="US20230003859A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="164.25mm" wi="166.54mm" file="US20230003859A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="239.69mm" wi="132.08mm" orientation="landscape" file="US20230003859A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">RELATED APPLICATIONS AND CLAIM OF PRIORITY</heading><p id="p-0002" num="0001">This patent document claims priority to, and is a continuation of, U.S. patent application Ser. No. 17/062,856, filed Oct. 5, 2020, the disclosure of which is fully incorporated into this document by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Recently, increased development of autonomy in transportation including both fully autonomous vehicles (AVs) and advanced driver assistance systems (ADAS) has led to an increased demand for high speed three-dimensional (3D) imaging technologies that can detect the location and details of objects in a highly dynamic environment. Light detection and ranging (LiDAR) systems have become an extremely important imaging technology for autonomous vehicle applications as it offers the highest range and resolution for 3D imaging compared to other methods, e.g. radar and ultrasonics. A LiDAR system is a sensor that emits light directed at the surrounding environment, and detects the reflected light off of objects such as landscape, pedestrians, structures and vehicles (i.e., moving actors or stationary objects).</p><p id="p-0004" num="0003">One method of determining the location of such objects is by time-of-flight (TOF) where light pulses are emitted from the sensor and the distance to the target is determined by the round trip time of the reflected pulse, since the speed of light is constant. This time based data is collected and used to generate a LiDAR spatial point cloud, which is a three-dimensional (3D) representation of the surrounding environment in space, depicted as discrete points along the vertical, horizontal and longitudinal axes. For each point generated in the point cloud, a histogram of data is collected where the detector samples all responses occurring during the time after which the pulse is emitted until the time that corresponds to the maximum measurable distance set by the system parameters. The histogram is formed by sampling the return pulse intensity and recording the time the reflected pulses arrived back at the detector.</p><p id="p-0005" num="0004">The job of the LiDAR system analyzer is to survey the time based histogram and discern which intensity peaks are from real targets, i.e. the signal, and which are from noise sources. Not all light received by LiDAR systems is reflected light that the LiDAR system originally generated. A wide variety of noise sources can interfere with the LiDAR system which includes external noise sources, such as solar background and other light sources, as well as intrinsic noise generated within the LiDAR system itself. Intrinsic noise generally includes any signal (avalanche counts) not caused by the direct photon reception. Example types of intrinsic noise include dark count noise and cross talk.</p><p id="p-0006" num="0005">More recently, improvements in LiDAR systems that utilize avalanche photodiodes in Geiger-mode (GmAPD) allow for single photon counting and can provide increased sensitivity for light detection compared to traditional LiDAR systems utilizing linear mode avalanche photodiodes (APDs) which require multi-photons for a measurable response. Accurate noise characterization is even more critical in LiDAR systems that use Geiger-mode photodiode detectors, as the higher sensitivity inherently comes with higher noise components from the surrounding environment and from the system itself. Accurate determination of the noise components in the time-based intensity histogram is critical to achieving a high signal-to-noise ratio, or alternatively tolerating a lower signal-to-noise ratio, and accurately creating a 3D point cloud in the space that surrounds the lidar system. For the case of autonomous vehicles, this noise characterization must be analyzed in a high speed manner as the LiDAR system is moving in a highly dynamic and ever-changing environment.</p><p id="p-0007" num="0006">The intrinsic noise of Geiger-mode detectors include noise sources such as dark count rate, afterpulses and early fires, which can occur from within individual detectors. Furthermore, as Geiger-mode LiDAR systems are deployed with a high density array of tightly pitched pixels for better spatial resolution, the characterization of intrinsic noise interference between neighboring pixels, i.e. crosstalk, is even more critical for correctly analyzing and realizing a higher signal-to-noise ratio for longer range detection with higher spatial resolution.</p><p id="p-0008" num="0007">This document describes methods and systems that are directed to addressing the realtime in situ characterization of intrinsic noise sources of Geiger-mode avalanche photodiode pixels arranged in a high density pixel array, and/or other issues related thereto.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0009" num="0008">A single photon counting sensor array includes one or more emitters configured to emit a plurality of pulses of energy, and a detector array comprising a plurality of pixels. Each pixel includes one or more detectors, a plurality of which are configured to receive reflected pulses of energy that were emitted by the one or more emitters. A mask material is positioned to cover some but not all of the detectors of the plurality of pixels to yield blocked pixels and unblocked pixels so that each blocked pixel is prevented from detecting the reflected pulses of energy.</p><p id="p-0010" num="0009">A system that is operable with the sensor array includes a processor and programming instructions to receive characteristic data of signals received by the blocked pixels and the unblocked pixels, and to compare the characteristic data of the signals received by the blocked pixels with the characteristic data of the signals received by the unblocked pixels to determine a measurement of intrinsic noise in the detector array.</p><p id="p-0011" num="0010">In various embodiments, the single photon counting sensor array may be an element of a light detection and ranging (LiDAR) system in systems in which the distance between centerpoints of adjacent pixels in the detector array is less than the crosstalk length.</p><p id="p-0012" num="0011">In various embodiments, each detector may include a photosensor that has a surface region of p-type semiconductor material that is positioned to receive light, a drift region of n-type semiconductor material, and a conductive trace that is connected to the surface region and positioned to serve as an anode for the photosensor. The detector array may include a substrate on which the photosensors are positioned. The substrate may be configured to function as a cathode for each of the photosensors. Each blocked pixel may have the mask material positioned over its surface region to block light from entering the blocked pixel.</p><p id="p-0013" num="0012">In various embodiments, the detector array may include a substrate that is configured to function as a cathode for each of the photosensors. Each of the photosensors may include a metal window that extends through the substrate and that is configured to receive light into the photosensor. A region of n-type semiconductor material may be connected to the metal window of each photosensor. A region of p-type semiconductor material may be connected to the region of n-type semiconductor material of each photosensor. A conductive trace may be connected to the region of p-type semiconductor material of each photosensor and positioned to serve as an anode for the photosensor. The mask material may be positioned to cover the metal window of each blocked pixel.</p><p id="p-0014" num="0013">In various embodiments, when comparing the characteristic data of the signals received by the blocked pixels with the characteristic data of the signals received by the unblocked pixels to determine a measurement of intrinsic noise in the detector array, the system may: (i) identify a superpixel comprising a group of the pixels in the detector array; (ii) determine a total photon count rate received by the superpixel; (iii) determine an avalanche count rate received by the unblocked pixels of the superpixel; and (iv) determine the measurement of noise as a function of the total photon count rate and the avalanche count rate received by the unblocked pixels of the superpixel. Optionally, the function may be:</p><p id="p-0015" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x3bb;=&#x3a3;<sub>i=1</sub><sup>N</sup>&#x3bb;<sub>i</sub>:&#x3bb;<sub>i</sub>=&#x3b2;&#x3bb;<sub>S</sub><sup>(i)</sup>+&#x3b2;&#x3bb;<sub>bk</sub><sup>(i)</sup>+&#x3bb;<sub>n</sub><sup>(i) </sup><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0016" num="0014">in which:</p><p id="p-0017" num="0015">&#x3bb;=avalanche count rate as received by of the superpixel;</p><p id="p-0018" num="0016">&#x3bb;<sub>S</sub><sup>(i)</sup>=a photon count rate resulting from reflected signal photons at photosensor i;</p><p id="p-0019" num="0017">&#x3bb;<sub>bk</sub><sup>(i)</sup>=a photon count rate resulting from background signal photons (i.e., at detector i;</p><p id="p-0020" num="0018">&#x3bb;<sub>n</sub><sup>(i)</sup>=avalanche count rate of intrinsic noise of detector i; and</p><p id="p-0021" num="0019">&#x3b2;=photon detection efficiency.</p><p id="p-0022" num="0020">In various embodiments, the system may include a data recorder that is configured to receive the signals from the pixels and store the characteristic data corresponding to the received signals.</p><p id="p-0023" num="0021">Optionally, the mask material may be formed of metal.</p><p id="p-0024" num="0022">In various embodiments, the system may be configured to measure health of the detector array by monitoring spatial variation, temporal variation, or both spatial variation and temporal variation of measured noise from blocked detectors. In addition or alternatively, the system may be configured to apply a characterization function to estimate, in an intensity estimation, an amount of measurement bias caused by crosstalk.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0025" num="0023"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates example components of a LiDAR system.</p><p id="p-0026" num="0024"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is an example detector array for a LiDAR system in which light is received via a front (anode) side of the detector array.</p><p id="p-0027" num="0025"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example masked pixel and an example unmasked pixel that may be employed in a detector array such as that of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0028" num="0026"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is an example detector array for a LiDAR system in which light is received via a back (cathode) side of the detector array.</p><p id="p-0029" num="0027"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example masked pixel and an example unmasked pixel that may be employed in a detector array such as that of <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0030" num="0028"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow diagram illustrating a process of determining intrinsic noise in a detector array.</p><p id="p-0031" num="0029"><figref idref="DRAWINGS">FIG. <b>7</b></figref> further illustrates certain signal processing steps performed in the noise estimation and signal processing stages of <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0032" num="0030"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram that illustrates various elements of a possible electronic subsystem of an AV and/or external electronic device.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0033" num="0031">As used in this document, the singular forms &#x201c;a,&#x201d; &#x201c;an,&#x201d; and &#x201c;the&#x201d; include plural references unless the context clearly dictates otherwise. Unless defined otherwise, all technical and scientific terms used in this document have the same meanings as commonly understood by one of ordinary skill in the art. As used in this document, the term &#x201c;comprising&#x201d; means &#x201c;including, but not limited to.&#x201d; Definitions for additional terms that are relevant to this document are included at the end of this Detailed Description.</p><p id="p-0034" num="0032"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an example LiDAR system <b>101</b> as may be used in various embodiments. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the LiDAR system <b>101</b> includes a housing <b>105</b> which may be rotatable 360&#xb0; about a central axis such as hub or axle <b>118</b>. The housing may include an emitter/receiver aperture <b>111</b> made of a material transparent to light. Although the example shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> has a single aperture, in various embodiments, multiple apertures for emitting and/or receiving light may be provided. Either way, the system can emit light through one or more of the aperture(s) <b>111</b> and receive reflected light back toward one or more of the aperture(s) <b>111</b> as the housing <b>105</b> rotates. In an alternative embodiment, the outer shell of housing <b>105</b> may be a stationary dome, at least partially made of a material that is transparent to light, with rotatable components inside of the housing <b>105</b>.</p><p id="p-0035" num="0033">Inside the rotating shell or stationary dome is a light emitter system <b>104</b> that is configured and positioned to generate and emit pulses of light through the aperture <b>111</b> or through the transparent dome of the housing <b>105</b> via one or more laser emitter chips, an array of emitters on one chip, or other light emitting devices. The emitter system <b>104</b> may include any number of individual emitters, including for example but not limited to 8 emitters, 64 emitters or 128 emitters. The emitters may emit light of substantially the same intensity, or of varying intensities. The LiDAR system will also include a light detector <b>108</b> containing a photodetector or array of photodetectors positioned and configured to receive light reflected back into the system. The emitter system <b>104</b> and detector <b>108</b> would rotate with the rotating shell, or they would rotate inside the stationary dome of the housing <b>105</b>. One or more optical element structures <b>109</b> may be positioned in front of the light emitting unit <b>104</b> and/or the detector <b>108</b> to serve as one or more lenses or waveplates that focus and direct light that is passed through the optical element structure <b>109</b>.</p><p id="p-0036" num="0034">The LiDAR system will include a power unit <b>121</b> to power the laser emitter unit <b>104</b>, a motor, and electronic components. The LiDAR system will also include an analyzer <b>115</b> with elements such as a processor <b>122</b> and non-transitory computer-readable memory <b>123</b> containing programming instructions that are configured to enable the system to receive data collected by the light detector unit, analyze it to measure characteristics of the light received, and generate information that a connected system can use to make decisions about operating in an environment from which the data was collected. Optionally, the analyzer <b>115</b> may be integral with the LiDAR system <b>101</b> as shown, or some or all of it may be external to the LiDAR system and communicatively connected to the LiDAR system via a wired or wireless communication network or link.</p><p id="p-0037" num="0035">This document describes a noise compensation method and system that may be used with single photon counting pixel arrays. Single photon counting pixel arrays may be used in LiDAR systems such as those described above, and especially in LiDAR systems that use GmAPDs as sensors. However, the methods and systems described below are not limited to LiDAR systems and also may be used in X-ray detectors and other sensing systems that use single photon counting pixel arrays and other types of pixel arrays as detectors.</p><p id="p-0038" num="0036">As noted in the Background section above, intrinsic noise generated within a LiDAR system can cause counts that do not originate from a reflected light pulse off of an intended target. Intrinsic noise can be caused by a variety of factors, including material quality and cross talk between pixels. Intrinsic noise can also vary with temperature, humidity, or other environmental conditions of the area in which the system is being used. Accurate, real-time characterization of noise can help separate true signal count rates from noise count rates, and thus improve performance of the system.</p><p id="p-0039" num="0037">For example, the dark count rate (DCR) of a Geiger-mode detection system is the average rate of registered counts, i.e., avalanche events, without any incident light on the pixels, and thus represents an intrinsic noise component. The DCR of a detection system is a function of the applied bias on the device where at higher applied bias over a breakdown voltage, (Vbr), the higher the DCR. In addition, for an array of isolated pixels that extend over an appreciable spatial region, variations in Vbr and DCR can exist and thus create a variation in noise across the pixel array. The sensitivity of a single photon detector is a function of its pixels' DCR, as this dictates how much &#x201c;overbias&#x201d; can be applied to a detector and still maintain a usable signal-to-noise ratio.</p><p id="p-0040" num="0038">The methods below provide a method to detect, and optionally to compensate, for the intrinsic noise in an isolated pixel in real time. In this way, the sensitivity of the system can be improved without further increasing the bias, or by increasing the signal-to-noise ratio at higher bias, thereby improving performance.</p><p id="p-0041" num="0039"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a front side view of an example front side detector array <b>200</b> that includes N&#xd7;2 pixels for a LiDAR system. (In this context, the &#x201c;front&#x201d; side is the side of the detector array <b>200</b> that includes the anode. In this embodiment, the anode is positioned to face outward from the LiDAR system so that it receives the reflected light.) Each pixel <b>201</b> includes an active area that serves as a photodetector, and each pixel is connected to an anode contact via a conductive (typically metal) trace <b>203</b>. Most of the pixels will be unmasked, meaning that their photodetectors are exposed and receive reflected energy as would be expected in such an array. However, a subset of the pixels and their conductive traces will be covered by a mask that blocks the photodetectors from receiving reflected energy. (<figref idref="DRAWINGS">FIG. <b>2</b></figref> designates a few example unmasked pixels as <b>201</b><i>a </i>and masked pixels (which also be referred to as blocked pixels) as <b>201</b><i>b</i>. It also designates example unmasked traces as <b>203</b><i>a </i>and masked traces as <b>203</b><i>b</i>.) The masks may be formed of metal such as typical metal stacks such as Ti/Pt/Au, Ni, Cr, W, or any material that effectively blocks light having a wavelength of interest from passing through it. In a LiDAR system, the wavelengths of interest may be those in the ultraviolet (UV) region (i.e., 180-480 nm), and optionally those in the visible region (i.e., 400-700 nm) and optionally those in the near infrared (IR) region (i.e. 700-2000 nm). The spatial distribution of blocked detectors shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is only an example; other arrangements are possible.</p><p id="p-0042" num="0040">Each mask will cover the entire active (photosensitive) area of the pixel, and each mask may be formed during the wafer manufacturing process. The mask may also be formed at the same times as the metal traces. The masks may be applied at various locations in the array in any arrangement, such as every nth pixel in a row or column, or even in a random arrangement.</p><p id="p-0043" num="0041">In the arrangement shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, masked pixels will be biased equally to their neighboring pixels, but will be unable to receive direct optical input from outside light. Accordingly, any counts generated by any masked pixel must only come from intrinsic noise such as material defects and crosstalk from neighboring pixels. This noise measurement for any active pixel can be used to adjust the values of signals received by neighboring pixels, or values of all signals received, to provide real time noise suppression.</p><p id="p-0044" num="0042"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates elements of an unmasked pixel <b>201</b><i>a </i>and a masked pixel <b>201</b><i>b </i>on a substrate <b>311</b> of a detector array. A surface region of p-type semiconductor material <b>312</b><i>a </i>is positioned at the top of the photodetector forming a p-n junction that is held in reverse bias. In a Geiger-mode avalanche photodiode, the reverse bias is held at a value above the breakdown voltage, Vbr. The drift layer <b>313</b><i>a </i>located just below the p-type region <b>312</b><i>a </i>extends a few microns and acts as a multiplication region which amplifies excited carriers from the absorber region. The substrate <b>311</b> may be formed of an n-type semiconductor material and serve an n+ cathode for each pixel. The Geiger-mode device can also be formed with opposite polarity using a p-type substrate and drift region with an n+ region formed at the top.</p><p id="p-0045" num="0043">Referring to unmasked pixel <b>201</b><i>a</i>, an incident photon <b>351</b><i>a </i>passes through the top of the pixel, p-region and drift layer until it reaches the absorber <b>314</b><i>a</i>, which is a semiconductor material with lower bandgap energy than the incident photon energy (e.g. InGaAs for near IR photons). In the absorber, the photon generates an exciton, <b>316</b><i>a </i>(i.e. electron-hole pair). The generated carriers are accelerated in opposite directions by the applied electric field, where one carrier <b>316</b><i>a </i>(in this case a hole) drifts to the multiplication region <b>313</b><i>a</i>. Once the carrier reaches the multiplication region, the carrier induces an electron avalanche through impact ionization and amplification occurs to create a measurable current as measured through metal trace <b>317</b><i>a </i>that leads from the surface region of p-type semiconductor material <b>312</b><i>a </i>to a readout integrated circuit (ROIC) (not shown).</p><p id="p-0046" num="0044">For the polarity case in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the contact trace <b>317</b><i>a </i>serves as an anode for the detector and may be made of a metal or any suitable conductive material typical for semiconductor wafer processes. The entire surface of the pixel array and substrate <b>311</b> are coated with an anti-reflective dielectric coating <b>319</b><i>a </i>that also serves as an electrically insulating passivation layer to prevent current from leaving the detector at any point other than the point where the contact trace <b>317</b><i>a </i>meets the semiconductor material in the p-region <b>312</b><i>a</i>. The anti-reflective coating may be formed using a process such as depositing a thin oxide or nitride layer on the surface of the photodiode suitable to passivate the pixel surfaces at the applied reverse bias and prevent any significant current leakage from the anode to the cathode.</p><p id="p-0047" num="0045">Referring to unmasked pixel <b>201</b><i>a</i>, a fundamental source of intrinsic noise arises due to impact ionization and avalanching process. The process also induces luminescence <b>315</b> at the higher band gap energy of the drift layer material (e.g. Eg=1.33 eV for InP for near IR regime). These higher energy photons scatter in all directions, and can propagate to the neighboring pixel's absorber layer <b>314</b><i>b </i>and create unwanted excitons <b>316</b><i>b</i>, and unwanted counts in those pixels, i.e. noise. This phenomena is a form of crosstalk and is a fundamental component of the intrinsic noise generated in Geiger-mode photodetectors, and limits how tightly the pixels can be pitched, by reducing the signal-to-noise ratio of any particular pixel as the pixels get closer and closer. Furthermore, the drift layer luminescence created by avalanche events can induce a cascading effect as the unwanted excitons <b>316</b><i>b </i>also create avalanches in neighboring pixels and thus more luminescence events. This cascading intrinsic noise source, if strong enough, can propagate across a whole array of tightly pitched pixels.</p><p id="p-0048" num="0046">Similar to unmasked pixel <b>201</b><i>a</i>, masked pixel <b>201</b><i>b </i>includes a surface region of p-type semiconductor material <b>312</b><i>b</i>, a drift region of n-type semiconductor material <b>313</b><i>b</i>, an anti-reflective coating <b>319</b><i>b </i>and a conductive contact trace <b>317</b><i>b </i>that leads to a ROIC (not shown). However, the exposed surfaces of pixel <b>201</b><i>b</i>, including surface region <b>312</b><i>b </i>and a conductive contact trace <b>317</b><i>b </i>are coated with a mask <b>320</b> that blocks light <b>351</b><i>b </i>from reaching the absorber region <b>314</b><i>b </i>of the photodetector. The incident photons are absorbed in the mask material and reflected away. Because no light reaches the active region, the only signal that will be emitted via the conductive trace <b>317</b><i>b </i>of the masked pixel <b>201</b><i>b </i>will be that resulting from intrinsic noise including material defects and crosstalk.</p><p id="p-0049" num="0047"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example back side detector array <b>400</b> that includes N&#xd7;N pixels for a LiDAR system. (In this context, the &#x201c;back&#x201d; side is the side of the detector array <b>400</b> that includes the substrate <b>411</b> on which the photodetectors are fabricated and that serves as a cathode. In this embodiment, the cathode is positioned to face outward from the LiDAR system so that it receives the reflected light.) Each pixel <b>401</b> includes an active area that serves as a photodetector, and each pixel is connected to the cathode via a metal layer with a &#x201c;window&#x201d; <b>403</b> that extends to the outward facing side of the cathode to receive and detect light. As with the embodiment of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in the embodiment of <figref idref="DRAWINGS">FIG. <b>4</b></figref> a subset of the pixels' light-receiving regions will be covered by a light-blocking mask <b>420</b> made of materials such as those described above.</p><p id="p-0050" num="0048"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates elements of several unmasked pixels <b>501</b><i>a </i>and a masked pixel <b>501</b><i>b </i>on a substrate <b>511</b> of a back side detector array such as that shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. The materials used in this embodiment may include any of those described above in the context of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. In this variation, all pixels may have the same construction, a photodetector having a surface region of p-type semiconductor material <b>512</b> is positioned at the bottom of the photodetector to serve as an anode, and a region of n-type semiconductor material <b>513</b> is positioned between the p-type semiconductor <b>512</b> and the N+ substrate <b>511</b> to provide a p-n junction that is held under reverse bias. The current is sourced by the surface region of p-type semiconductor material <b>452</b> of the photodetector via a conductive contact trace <b>517</b> that leads from the region of p-type semiconductor material <b>512</b> to the ROIC <b>533</b>. The entire photodetector and device side of the substrate <b>511</b> surface are coated with an anti-reflective dielectric coating <b>519</b> that covers all areas except where trace <b>517</b> meets makes contact to p-region <b>512</b> as described above for <figref idref="DRAWINGS">FIG. <b>3</b></figref> for passivation purposes. Mask material <b>520</b> may be coated on the substrate <b>511</b> to block the light-receiving region of masked pixel <b>501</b><i>b</i>. Mask <b>520</b> can be the backside metal and also be the cathode. Because no light reaches the active region, the only signal that will be emitted via the conductive trace of the masked pixel <b>501</b><i>b </i>will be that resulting from intrinsic noise such as DCR and crosstalk as described above. As described in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the avalanche event induces luminescence <b>515</b> at the higher band gap energy of the drift layer material (for example, Eg=1.33 eV for indium phosphide (InP) for the near IR regime). These higher energy photons scatter in all directions, and can propagate to the neighboring pixel's absorber layer <b>414</b> and create unwanted excitons <b>516</b>, and unwanted counts in those pixels, i.e. noise.</p><p id="p-0051" num="0049">A partially masked photon counting pixel array such as those described above may be used to determine intrinsic noise in the array at any given point in time. The signal generated by unblocked (unmasked) detectors is a composite signal that is associated with multiple sources, including the reflected pulse signal, solar noise and intrinsic detector noise. The signal generated by blocked (masked) detectors should be substantially&#x2014;if not entirely&#x2014;the result of intrinsic noise. The spatial characteristics of this signal (i.e., where in the array the noise is located) can be used to better filter the local signal, increase the local signal-to-noise ratio and increase the detector sensitivity. The temporal characteristics of this signal (i.e., when was it detected) can be used to decouple material driven DCR and from crosstalk, since DCR typically has non-temporal statistical characteristics while crosstalk may have non-stationary temporal characteristics. The in-situ noise monitor allows for tight pitching of pixels for enhanced spatial resolution of the LiDAR system, and for addressing effects like blooming, or cascading crosstalk from intense reflections from highly reflective objects like retroreflectors used in road signs.</p><p id="p-0052" num="0050">To do this, the system may measure noise of individual pixels as shown above. Or it may identify clusters of any number of adjacent pixels (referred to in this document as &#x201c;superpixels&#x201d;, which is an N&#xd7;N array of pixels that is a subset of the overall detector array). Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, each superpixel <b>601</b><i>a </i>. . . <b>601</b><i>k </i>includes a cluster of adjacent pixels that include at least one unblocked (unmasked) pixel <b>612</b> and at least one blocked (masked) pixel <b>613</b>. The system may include a signal processing chain <b>608</b> that receives the output of each pixel and/or superpixel and generates the LiDAR histogram or other sensor data from the pixels' readings. This signal processing chain <b>608</b> may include hardware and programming instructions typical of that used in autonomous vehicles or other now or hereafter known LiDAR and other single photon counting detection systems. However, this system also includes a noise estimation module <b>607</b> that includes a processor, memory and programming instructions for estimating the intrinsic noise in each superpixel. The processor and memory of the noise estimation module <b>607</b> may be the same as those used in the signal processing chain <b>608</b> and/or the LiDAR system of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, or it may contain separate hardware and/or software elements.</p><p id="p-0053" num="0051">To determine intrinsic noise rates of a single pixel or superpixel, the system may employ a function that describes the composite signal generated by unblocked (unmasked)</p><p id="p-0054" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <mi>&#x3bb;</mi>  <mo>=</mo>  <mrow>   <mrow>    <munderover>     <mo>&#x2211;</mo>     <mrow>      <mi>i</mi>      <mo>=</mo>      <mn>1</mn>     </mrow>     <mi>N</mi>    </munderover>    <mtext> </mtext>    <mrow>     <msub>      <mi>&#x3bb;</mi>      <mi>i</mi>     </msub>     <mo>:</mo>     <mtext>   </mtext>     <msub>      <mi>&#x3bb;</mi>      <mi>i</mi>     </msub>    </mrow>   </mrow>   <mo>=</mo>   <mrow>    <msubsup>     <mi>&#x3b2;&#x3bb;</mi>     <mi>S</mi>     <mrow>      <mo>(</mo>      <mi>i</mi>      <mo>)</mo>     </mrow>    </msubsup>    <mo>+</mo>    <msubsup>     <mi>&#x3b2;&#x3bb;</mi>     <mi>bk</mi>     <mrow>      <mo>(</mo>      <mi>i</mi>      <mo>)</mo>     </mrow>    </msubsup>    <mo>+</mo>    <msubsup>     <mi>&#x3bb;</mi>     <mi>n</mi>     <mrow>      <mo>(</mo>      <mi>i</mi>      <mo>)</mo>     </mrow>    </msubsup>   </mrow>  </mrow> </mrow></math></maths></p><p id="p-0055" num="0052">detectors:</p><p id="p-0056" num="0053">in which:</p><p id="p-0057" num="0054">&#x3bb;=the avalanche count rate as received by the superpixel;</p><p id="p-0058" num="0055">&#x3bb;<sub>S</sub><sup>(i)</sup>=the photon count rate resulting from reflected signal photons at detector i;</p><p id="p-0059" num="0056">&#x3bb;<sub>bk</sub><sup>(i)</sup>=the photon count rate resulting from background signal photons (i.e., ambient light and scattered light) at detector i;</p><p id="p-0060" num="0057">&#x3bb;<sub>n</sub><sup>(i)</sup>=the avalanche count rate of intrinsic noise of detector (i) (e.g., dark count rate (DCR) and o, crosstalk from other detectors; and</p><p id="p-0061" num="0058">&#x3b2;=photon detection efficiency, the probability that an incident photon will create a photocarrier and sustained avalanche.</p><p id="p-0062" num="0059">The photon detection efficiency &#x3b2; is the combined efficiency due to the quantum efficiency, breakdown probability, the fill factor, and the reflective and absorptive properties of the layers above the absorber layer. The typical quantum efficiency for InGaAs devices is around 80% to 90%, whereas &#x3b2; is only on the order of 20-30%. The quantum efficiency is the probability that a photon incident on the active area is converted to anexciton pair, i.e. an electron and hole pair. These photo-generated carriers, in addition to the dark current carriers, are known as primary carriers, which have potential to pass through the amplification stage and be recorded as a count. In Geiger mode, the reverse bias is a voltage above the breakdown voltage to yield a very high gain (&#x3e;&#x3e;1) region in the semiconductor device. A fraction of those primary carriers results in an avalanche event and a digital counter stores the arrival time of this event. This fraction is determined by the breakdown probability.</p><p id="p-0063" num="0060">The avalanche count rate &#x3bb;<sub>n</sub><sup>(i) </sup>resembles first-order intrinsic noise of Geiger-mode APD and does not include effects like after pulsing and early fires, which are assumed to be blocked by sufficiently long hold-off time, i.e. the time before rearming a pixel after a count has been registered.</p><p id="p-0064" num="0061">If the equation above were applied to individual pixels, the noise estimation module <b>601</b> may identify &#x3bb;<sub>n S</sub><sup>(i) (i) </sup>and determine its effect on the total composite avalanche count rate &#x3bb;.</p><p id="p-0065" num="0062">The determination of intrinsic noise rates is not limited to the specific model above. Other models, including nonlinear models, may be employed.</p><p id="p-0066" num="0063"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flow diagram that expands on the disclosure of <figref idref="DRAWINGS">FIG. <b>6</b></figref> and describes in block diagram function various process steps of an example of how the blocked pixel signal can be used for noise estimation in conjunction with the remaining pixels in a superpixel. It also depicts how this information is used in a typical LiDAR signal processing chain.</p><p id="p-0067" num="0064">At the noise estimation stage <b>607</b>, one capability that is enabled by the presence of blocked pixel is the ability to characterize crosstalk in a superpixel. Crosstalk estimation is done by applying a pattern matching routine or by using cross-correlation techniques between the active pixel signal and the blocked pixel signal to obtain a score (i.e. a probability value), that a particular sample (i.e. a photon count at a particular timestamp) from any unblocked pixel is a result of a crosstalk event instead of a stationary noise (i.e. DCR). This operation is conducted by the crosstalk analysis stage <b>701</b>, using active pixel data <b>702</b> and blocked pixel signal data <b>703</b> which may be retrieved from memory as shown. Then, the aggregated samples (from blocked and active pixels) are passed along with their corresponding scores to a classifier <b>704</b> which aims to divide those samples into two streams: one stream <b>705</b> is composed of the samples that are caused by crosstalk and the other one is the stream <b>706</b> of samples that are caused by uniform noise e.g., background light and dark count noise.</p><p id="p-0068" num="0065">The samples caused by uniform noise are expected to have stationary statistical characteristics i.e., they are time invariant and can be used effectively in estimating dark count rate in this particular superpixel (by using those samples only that are obtained from blocked pixels). Aggregating this dark count rate estimate from this superpixel and other superpixels will result in a spatial profile of the dark count rate across the whole detector array which can be used by a health monitoring function <b>707</b> to gauge the health of the detector array. If the spatial variation, temporal variation, or both of that dark count rate exceeds a particular tolerance margin then the detector array is considered defective.</p><p id="p-0069" num="0066">At signal processing level <b>608</b>, <figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an application of a blocked pixel signal in a typical LiDAR signal processing chain. This chain takes a histogram <b>711</b> of the pixel samples as an input. Then, it passes the histogram into the detection stage <b>722</b>, which aims to identify a particular region of the histogram <b>711</b> that is expected to have a potential object. This region is marked with grey color bars of the histogram <b>711</b>. Once this part of the histogram is isolated (see <b>714</b>), it is passed into a waveform analysis stage <b>723</b> which performs accurate range estimation and reflected pulse intensity estimation on that region of the histogram.</p><p id="p-0070" num="0067">Blocked pixels enable the crosstalk and stationary noise classification, which can be leveraged in the signal processing chain as follows: The accurate noise estimation obtained by the stationary noise estimation stage <b>607</b> is fed into the detection <b>722</b> as it is used directly as a detection threshold. The crosstalk samples have temporal statistical features that can be characterized by a characterization function <b>708</b> to estimate the amount of measurement bias (amplification) in intensity estimation caused by crosstalk and compensate for this in waveform analysis stage <b>723</b>.</p><p id="p-0071" num="0068">Also, when receiving a reflected signal, the system may compare the determined intrinsic noise to the signal algorithm output to determine whether a received signal is noise only, or whether it includes a reflected signal plus noise.</p><p id="p-0072" num="0069">When analyzing waveforms, LiDAR systems may measure the received photon counts (pulse intensity). Noise can amplify intensity measurements. By measuring the contribution of noise to signal content, the system may correct for the bias of pulse intensity estimation.</p><p id="p-0073" num="0070">Finally, as explained above in the discussion of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the system may measure the health of the LiDAR detector array by monitoring the spatial variation of measured noise from blocked detectors.</p><p id="p-0074" num="0071">The system and methods described above may be useful in various types of LiDAR systems, and can be especially useful in systems in which the density of the pixels is less than the crosstalk length. For example, referring to the example detector array <b>200</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, if the pixel pitch (that is, the distance between center points of adjacent pixels) of the array is 5 mm or less, the use of masks as described above can be of significant value of the crosstalk length is 5 mm or more.</p><p id="p-0075" num="0072">For example, in some embodiments the system above may be used with a LiDAR system of an autonomous vehicle. For example, <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example system architecture <b>800</b> for a vehicle, such as an autonomous vehicle. The vehicle includes an engine or motor <b>802</b> and various sensors for measuring various parameters of the vehicle and/or its environment. Operational parameter sensors that are common to both types of vehicles include, for example: a position sensor <b>836</b> such as an accelerometer, gyroscope and/or inertial measurement unit; a speed sensor <b>838</b>; and an odometer sensor <b>840</b>. The vehicle also may have a clock <b>842</b> that the system uses to determine vehicle time during operation. The clock <b>842</b> may be encoded into the vehicle on-board computing device, it may be a separate device, or multiple clocks may be available.</p><p id="p-0076" num="0073">The vehicle also will include various sensors that operate to gather information about the environment in which the vehicle is traveling. These sensors may include, for example: a location sensor <b>860</b> such as a global positioning system (GPS) device; object detection sensors such as one or more cameras <b>862</b>; a LiDAR sensor system <b>864</b>; and/or a radar and or and/or a sonar system <b>866</b>. The sensors also may include environmental sensors <b>868</b> such as a precipitation sensor and/or ambient temperature sensor. The object detection sensors may enable the vehicle to detect objects that are within a given distance range of the vehicle <b>899</b> in any direction, while the environmental sensors collect data about environmental conditions within the vehicle's area of travel. The system will also include one or more cameras <b>862</b> for capturing images of the environment.</p><p id="p-0077" num="0074">During operations, information is communicated from the sensors to an on-board computing device <b>820</b>. The on-board computing device <b>820</b> may include a processor <b>851</b> and a memory device <b>852</b> with programming instructions that, when executed, cause the processor <b>851</b> to analyze the data captured by the sensors and optionally control operations of the vehicle based on results of the analysis. For example, the on-board computing device <b>820</b> may control braking via a brake controller <b>822</b>; direction via a steering controller <b>824</b>; speed and acceleration via a throttle controller <b>826</b> (in a gas-powered vehicle) or a motor speed controller <b>828</b> (such as a current level controller in an electric vehicle); a differential gear controller <b>830</b> (in vehicles with transmissions); and/or other controllers. The on-board computing device <b>820</b> also may perform the signal processing functions and/or noise estimation functions described above in <figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b></figref>. The memory device <b>852</b> of the on-board computing device <b>820</b>, or another memory device in the system (such as a memory device of the LiDAR system) may provide the function of a data recorder that is configured to receive the signals from the pixels and store the characteristic data corresponding to the received signals.</p><p id="p-0078" num="0075">Geographic location information may be communicated from the location sensor <b>860</b> to the on-board computing device <b>820</b>, which may then access a map of the environment that corresponds to the location information to determine known fixed features of the environment such as streets, buildings, stop signs and/or stop/go signals. Captured images from the cameras <b>862</b> and/or object detection information captured from sensors such as a LiDAR system <b>864</b> is communicated from those sensors) to the on-board computing device <b>820</b>. The object detection information and/or captured images may be processed by the on-board computing device <b>820</b> to detect objects in proximity to the vehicle <b>800</b>. In addition or alternatively, the AV may transmit any of the data to an external server for processing. Any known or to be known technique for making an object detection based on sensor data and/or captured images can be used in the embodiments disclosed in this document.</p><p id="p-0079" num="0076">In the various embodiments discussed in this document, the description may state that the vehicle or on-board computing device of the vehicle may implement programming instructions that cause the on-board computing device of the vehicle to make decisions and use the decisions to control operations of one or more vehicle systems. However, the embodiments are not limited to this arrangement, as in various embodiments the analysis, decision making and or operational control may be handled in full or in part by other computing devices that are in electronic communication with the vehicle's on-board computing device. Examples of such other computing devices include an electronic device (such as a smartphone) associated with a person who is riding in the vehicle, as well as a remote server that is in electronic communication with the vehicle via a wireless communication network. The processor of any such device may perform the operations that will be discussed below.</p><p id="p-0080" num="0077">Terminology that is relevant to the disclosure provided above includes:</p><p id="p-0081" num="0078">The term &#x201c;vehicle&#x201d; refers to any moving form of conveyance that is capable of carrying either one or more human occupants and/or cargo and is powered by any form of energy. The term &#x201c;vehicle&#x201d; includes, but is not limited to, cars, trucks, vans, trains, autonomous vehicles, aircraft, aerial drones and the like. An &#x201c;autonomous vehicle&#x201d; is a vehicle having a processor, programming instructions and drivetrain components that are controllable by the processor without requiring a human operator. An autonomous vehicle may be fully autonomous in that it does not require a human operator for most or all driving conditions and functions, or it may be semi-autonomous in that a human operator may be required in certain conditions or for certain operations, or that a human operator may override the vehicle's autonomous system and may take control of the vehicle. Autonomous vehicles also include vehicles in which autonomous systems augment human operation of the vehicle, such as vehicles with driver-assisted steering, speed control, braking, parking and other systems.</p><p id="p-0082" num="0079">As used in this document, the term &#x201c;light&#x201d; means electromagnetic radiation associated with optical frequencies, e.g., ultraviolet, visible, infrared and terahertz radiation. Example emitters of light include laser emitters and other emitters that emit converged light. In this document, the term &#x201c;emitter&#x201d; will be used to refer to an emitter of light, such as a laser emitter that emits infrared light.</p><p id="p-0083" num="0080">An &#x201c;electronic device&#x201d; or a &#x201c;computing device&#x201d; refers to a device that includes a processor and memory. Each device may have its own processor and/or memory, or the processor and/or memory may be shared with other devices as in a virtual machine or container arrangement. The memory will contain or receive programming instructions that, when executed by the processor, cause the electronic device to perform one or more operations according to the programming instructions.</p><p id="p-0084" num="0081">The terms &#x201c;memory,&#x201d; &#x201c;memory device,&#x201d; &#x201c;data store,&#x201d; &#x201c;data storage facility&#x201d; and the like each refer to a non-transitory device on which computer-readable data, programming instructions or both are stored. Except where specifically stated otherwise, the terms &#x201c;memory,&#x201d; &#x201c;memory device,&#x201d; &#x201c;data store,&#x201d; &#x201c;data storage facility&#x201d; and the like are intended to include single device embodiments, embodiments in which multiple memory devices together or collectively store a set of data or instructions, as well as individual sectors within such devices.</p><p id="p-0085" num="0082">The terms &#x201c;processor&#x201d; and &#x201c;processing device&#x201d; refer to a hardware component of an electronic device that is configured to execute programming instructions, such as a microprocessor or other logical circuit, A processor and memory may be elements of a microcontroller, custom configurable integrated circuit, programmable system-on-a-chip, or other electronic device that can be programmed to perform various functions. Except where specifically stated otherwise, the singular term &#x201c;processor&#x201d; or &#x201c;processing device&#x201d; is intended to include both single-processing device embodiments and embodiments in which multiple processing devices together or collectively perform a process.</p><p id="p-0086" num="0083">This document may use the terms &#x201c;photodetector&#x201d; and &#x201c;photosensor&#x201d; interchangeably. No difference in meaning is intended between the two terms.</p><p id="p-0087" num="0084">The above-disclosed features and functions, as well as alternatives, may be combined into many other different systems or applications. Various components may be implemented in hardware or software or embedded software. Various presently unforeseen or unanticipated alternatives, modifications, variations or improvements may be made by those skilled in the art, each of which is also intended to be encompassed by the disclosed embodiments.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230003859A1-20230105-M00001.NB"><img id="EMI-M00001" he="8.13mm" wi="76.20mm" file="US20230003859A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230003859A1-20230105-M00002.NB"><img id="EMI-M00002" he="8.13mm" wi="76.20mm" file="US20230003859A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system including a single photon counting sensor array comprising:<claim-text>a detector array comprising a plurality of pixels, wherein each pixel comprises one or more detectors, a plurality of which are configured to receive pulses of energy; and</claim-text><claim-text>a mask material that is positioned to cover some but not all of the detectors of the plurality of pixels to yield blocked pixels and unblocked pixels so that each blocked pixel is prevented from detecting the pulses of energy.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising;<claim-text>a processor; and</claim-text><claim-text>a memory containing programming instructions that are configured to instruct the processor to:<claim-text>receive characteristic data of signals received by the blocked pixels and the unblocked pixels, and</claim-text><claim-text>compare the characteristic data of the signals received by the blocked pixels with the characteristic data of the signals received by the unblocked pixels to determine a measurement of intrinsic noise in the detector array.</claim-text></claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the single photon counting sensor array is an element of a light detection and ranging (LiDAR) system in systems in which a distance between center points of adjacent pixels in the detector array is less than a crosstalk length.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>each detector comprises a photosensor that comprises:<claim-text>a surface region of p-type semiconductor material that is positioned to receive light,</claim-text><claim-text>a drift region of n-type semiconductor material, and</claim-text><claim-text>a conductive trace that is connected to the surface region and positioned to serve as an anode for the photosensor;</claim-text></claim-text><claim-text>the detector array comprises a substrate on which the photosensors are positioned, wherein the substrate is configured to function as a cathode for each of the photosensors; and</claim-text><claim-text>each blocked pixel has the mask material positioned over its surface region to block light from entering the blocked pixel.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein:<claim-text>the detector array comprises a substrate that is configured to function as a cathode for each of the photosensors;</claim-text><claim-text>each of the photosensors comprises:<claim-text>a metal window that extends through the substrate and is configured to receives light into the photosensor,</claim-text><claim-text>a region of n-type semiconductor material that is connected to the metal window,</claim-text><claim-text>a region of p-type semiconductor material that is connected to the region of n-type semiconductor material, and</claim-text><claim-text>a conductive trace that is connected to the region of p-type semiconductor material and positioned to serve as an anode for the photosensor; and</claim-text></claim-text><claim-text>the mask material is positioned to cover the metal window of each blocked pixel.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the programming instructions that are configured to instruct the processor to compare the characteristic data of the signals received by the blocked pixels with the characteristic data of the signals received by the unblocked pixels to determine a measurement of intrinsic noise in the detector array comprise instructions to:<claim-text>identify a superpixel comprising a group of the pixels in the detector array;</claim-text><claim-text>determine a total photon count rate received by the superpixel;</claim-text><claim-text>determine an avalanche count rate received by the unblocked pixels of the superpixel; and</claim-text><claim-text>determine the measurement of noise as a function of the total photon count rate and the avalanche count rate received by the unblocked pixels of the superpixel.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the detector array is a back side detector array of a light detection and ranging (LiDAR) system.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a data recorder that is configured to receive the signals from the pixels and store the characteristic data corresponding to the received signals.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the mask material comprises metal.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising additional programming instructions that are configured to instruct the processor to measure health of the detector array by monitoring spatial variation, temporal variation, or both spatial and temporal variation of measured noise from blocked detectors.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising additional programming instructions that are configured to instruct the processor to apply a characterization function to estimate, in an intensity estimation, an amount of measurement bias caused by crosstalk.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A method of operating a single photon counting sensor array, the method comprising:<claim-text>operating a LiDAR system that comprises:<claim-text>a detector array comprising a plurality of pixels, wherein each pixel comprises one or more detectors, a plurality of which are configured to receive pulses of energy, and</claim-text><claim-text>a mask material that is positioned to cover some but not all of the detectors of the plurality of pixels to yield blocked pixels and unblocked pixels so that each blocked pixel is prevented from detecting the pulses of energy; and</claim-text></claim-text><claim-text>by a processor:<claim-text>receiving characteristic data of signals received by the blocked pixels and the unblocked pixels, and</claim-text><claim-text>comparing the characteristic data of the signals received by the blocked pixels with the characteristic data of the signals received by the unblocked pixels to determine a measurement of intrinsic noise in the detector array.</claim-text></claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein:<claim-text>each detector comprises a photosensor that comprises:<claim-text>a surface region of p-type semiconductor material that is positioned to receive light,</claim-text><claim-text>a drift region of n-type semiconductor material, and</claim-text><claim-text>a conductive trace that is connected to the surface region and positioned to serve as an anode for the photosensor;</claim-text></claim-text><claim-text>the detector array comprises a substrate on which the photosensors are positioned, wherein the substrate is configured to function as a cathode for each of the photosensors; and</claim-text><claim-text>each blocked pixel has the mask material positioned over its surface region to block light from entering the blocked pixel.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein:<claim-text>the detector array comprises a substrate that is configured to function as a cathode for each of the photosensors;</claim-text><claim-text>each of the photosensors comprises:<claim-text>a metal window that extends through the substrate and is configured to receives light into the photosensor;</claim-text><claim-text>a region of n-type semiconductor material that is connected to the metal window;</claim-text><claim-text>a region of p-type semiconductor material that is connected to the region of n-type semiconductor material; and</claim-text><claim-text>a conductive trace that is connected to the region of p-type semiconductor material and positioned to serve as an anode for the photosensor; and</claim-text></claim-text><claim-text>the mask material is positioned to cover the metal window of each blocked pixel.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein comparing the characteristic data of the signals received by the blocked pixels with the characteristic data of the signals received by the unblocked pixels to determine a measurement of intrinsic noise in the detector array comprises:<claim-text>identifying a superpixel comprising a group of the pixels in the detector array;</claim-text><claim-text>determining a total photon count rate received by the superpixel;</claim-text><claim-text>determining an avalanche count rate received by the unblocked pixels of the superpixel; and</claim-text><claim-text>determining the measurement of noise as a function of the total photon count rate and the avalanche count rate received by the unblocked pixels of the superpixel.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the function is:</claim-text><claim-text><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mrow>  <mi>&#x3bb;</mi>  <mo>=</mo>  <mrow>   <mrow>    <munderover>     <mo>&#x2211;</mo>     <mrow>      <mi>i</mi>      <mo>=</mo>      <mn>1</mn>     </mrow>     <mi>N</mi>    </munderover>    <mtext> </mtext>    <mrow>     <msub>      <mi>&#x3bb;</mi>      <mi>i</mi>     </msub>     <mo>:</mo>     <mtext>   </mtext>     <msub>      <mi>&#x3bb;</mi>      <mi>i</mi>     </msub>    </mrow>   </mrow>   <mo>=</mo>   <mrow>    <msubsup>     <mi>&#x3b2;&#x3bb;</mi>     <mi>S</mi>     <mrow>      <mo>(</mo>      <mi>i</mi>      <mo>)</mo>     </mrow>    </msubsup>    <mo>+</mo>    <msubsup>     <mi>&#x3b2;&#x3bb;</mi>     <mi>bk</mi>     <mrow>      <mo>(</mo>      <mi>i</mi>      <mo>)</mo>     </mrow>    </msubsup>    <mo>+</mo>    <msubsup>     <mi>&#x3bb;</mi>     <mi>n</mi>     <mrow>      <mo>(</mo>      <mi>i</mi>      <mo>)</mo>     </mrow>    </msubsup>   </mrow>  </mrow> </mrow></math></maths><claim-text>in which:<claim-text>&#x3bb;=avalanche count rate as received by of the superpixel;</claim-text><claim-text>&#x3bb;<sub>S</sub><sup>(i)</sup>=a photon count rate resulting from reflected signal photons at photosensor i;</claim-text><claim-text>&#x3bb;<sub>bk</sub><sup>(i)</sup>=a photon count rate resulting from background signal photons (i.e., at detector i;</claim-text><claim-text>&#x3bb;<sub>n</sub><sup>(i)</sup>=avalanche count rate of intrinsic noise of detector i; and</claim-text><claim-text>&#x3b2;=photon detection efficiency.</claim-text></claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref> further comprising, by a data recorder:<claim-text>receiving the signals from the pixels; and</claim-text><claim-text>storing the characteristic data corresponding to the received signals.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref> further comprising, by the processor, measuring health of the detector array by monitoring spatial variation, temporal variation, or both spatial and temporal variation of measured noise from blocked detectors.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref> further comprising, by the processor, applying a characterization function to estimate, in an intensity estimation, an amount of measurement bias caused by crosstalk.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A computer program product comprising a memory storing programming instructions that, when executed, will cause one or more processors to:<claim-text>in a LiDAR system that comprises:<claim-text>a detector array comprising a plurality of pixels, wherein each pixel comprises one or more detectors, a plurality of which are configured to receive pulses of energy, and</claim-text><claim-text>a mask material that is positioned to cover some but not all of the detectors of the plurality of pixels to yield blocked pixels and unblocked pixels so that each blocked pixel is prevented from detecting the pulses of energy;</claim-text></claim-text><claim-text>receive characteristic data of signals received by the blocked pixels and the unblocked pixels; and</claim-text><claim-text>compare the characteristic data of the signals received by the blocked pixels with the characteristic data of the signals received by the unblocked pixels to determine a measurement of intrinsic noise in the detector array.</claim-text></claim-text></claim></claims></us-patent-application>
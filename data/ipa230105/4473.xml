<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004474A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004474</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17364051</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>34</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>62</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>3438</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>628</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">MACHINE LEARNING TO INFER POOR USER EXPERIENCE WITH ELECTRONIC SYSTEM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Lenovo (Singapore) Pte. Ltd.</orgname><address><city>Singapore</city><country>SG</country></address></addressbook><residence><country>SG</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Hansen</last-name><first-name>Jordan</first-name><address><city>Boise</city><state>ID</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Legg</last-name><first-name>Stefan</first-name><address><city>Perrysburg</city><state>OH</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">In one aspect, a device may include a processor and storage accessible to the processor. The storage may include instructions executable by the processor to determine an insufficiency related to a system in a first instance based on input from an end user. The instructions may also be executable to analyze first data related to the first instance and, based on the analysis, determine that the insufficiency has or will occur again based on second data also related to the system but that corresponds to a second instance occurring after the first instance. The instructions may then be executable to proactively address the insufficiency based on determination that the insufficiency has or will occur again. In some examples, the determination that the insufficiency has/will occur again may be performed using an artificial neural network trained using the first data to infer whether the insufficiency has or will occur again.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="113.71mm" wi="74.93mm" file="US20230004474A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="243.59mm" wi="161.88mm" file="US20230004474A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="170.69mm" wi="98.72mm" orientation="landscape" file="US20230004474A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="236.56mm" wi="158.24mm" orientation="landscape" file="US20230004474A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="247.82mm" wi="148.59mm" file="US20230004474A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="192.11mm" wi="148.67mm" file="US20230004474A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="206.25mm" wi="148.93mm" file="US20230004474A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD</heading><p id="p-0002" num="0001">The disclosure below relates to technically inventive, non-routine solutions that are necessarily rooted in computer technology and that produce concrete technical improvements. In particular, the disclosure below relates to machine learning to infer poor user experiences with electronic systems.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">As recognized herein, advanced device networking as presently used in many systems involves numerous interconnected nodes and pieces of software operating in concert. However, as further recognized herein, the network components and nodes do not always operate in concert as desired, which can lead to bad user experiences. But given that the numerous interconnected network components and nodes might be using different standards and operating software, the present disclosure further recognizes that current network and device diagnostic systems are insufficient for adequately identifying and addressing problems that might arise anywhere across these numerous components. Therefore, there are currently no adequate solutions to the foregoing computer-related, technological problem.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">Accordingly, in one aspect a first device includes at least one processor and storage accessible to the at least one processor. The storage includes instructions executable by the at least one processor to identify a first poor user experience with a system based on user input indicating the first poor user experience. The instructions are also executable to use data related to operation of the system to determine one or more causes of the first poor user experience. The instructions are then executable to predict that a second poor user experience will occur based on subsequent identification of one or more of the causes. Based on the prediction, the instructions are executable to proactively prevent the second poor user experience from occurring and/or present a notification in advance of the second poor user experience.</p><p id="p-0005" num="0004">In some examples, the determination may be performed using at least one artificial neural network (ANN) to process the data and infer from the data one or more system insufficiencies indicating the one or more causes. Further, in some examples the instructions may be executable to train the ANN using the data as input, where the data may be labeled with the one or more causes for training the ANN. The data may also be labeled as being a poor user experience for training the ANN, with the data labeled by the first device as being a poor user experience based on the user input. The ANN may then be trained using the labeled data and one or more machine learning algorithms such as a multi-label classification learning algorithm. Additionally, if desired the prediction itself may be made using the ANN as trained or not.</p><p id="p-0006" num="0005">In various example implementations, the system may include the first device, a second device different from the first device and associated with an end user, and/or a server providing an online service to an end user.</p><p id="p-0007" num="0006">In another aspect, a method includes determining an insufficiency of a system based on input from an end user indicating the insufficiency exists in a first instance. The method also includes using first data related to the system to identify one or more reasons for the insufficiency and then determining that the insufficiency has or will occur again based on subsequent identification of one or more of the reasons from second data different from the first data. The second data is also related to the system and corresponds to a second instance occurring after the first instance. The method then includes, based on determining that the insufficiency has or will occur again, proactively addressing the insufficiency.</p><p id="p-0008" num="0007">In various examples, the insufficiency may be proactively addressed by attempting to prevent or mitigate the insufficiency, and/or by presenting a notification at an end-user device regarding the insufficiency.</p><p id="p-0009" num="0008">Also in various examples, the method may include using at least one artificial neural network (ANN) to infer, from the second data, that the insufficiency has or will occur again. The ANN may be trained using the first data and at least one machine learning algorithm.</p><p id="p-0010" num="0009">In still another aspect, at least one computer readable storage medium (CRSM) that is not a transitory signal includes instructions executable by at least one processor to determine an insufficiency related to a system in a first instance and analyze first data related to the first instance. Based on the analysis, the instructions are executable to determine that the insufficiency has or will occur again based on second data different from the first data. The second data is also related to the system and corresponds to a second instance occurring after the first instance. The instructions are then executable to proactively address the insufficiency based on determination that the insufficiency has or will occur again.</p><p id="p-0011" num="0010">Thus, in some examples the instructions may be executable to determine the insufficiency related to the system in the first instance based on user input indicating the insufficiency exists in the first instance.</p><p id="p-0012" num="0011">Also in some examples, the analysis may be used to recognize a pattern in the second data that is similar to a pattern indicated in the first data, where recognition of the pattern from the second data may contribute to the determination that the insufficiency has or will occur again. If desired, in various examples the system in the first and second instances may be facilitating a video conference.</p><p id="p-0013" num="0012">The details of present principles, both as to their structure and operation, can best be understood in reference to the accompanying drawings, in which like reference numerals refer to like parts, and in which:</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of an example system consistent with present principles;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram of an example network of devices consistent with present principles;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows an example graphical user interface (GUI) at which an end user may indicate a poor user experience consistent with present principles;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows example artificial intelligence architecture that may be used consistent with present principles;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates example logic in example flow chart format that may be executed by a device consistent with present principles;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIGS. <b>6</b>-<b>9</b></figref> show various example GUIs that may be presented on a display regarding proactively addressing one or more potential poor user experiences consistent with present principles; and</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>10</b></figref> shows an example GUI that may be presented on a display for configuring one or more settings of the system to operate consistent with present principles.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0021" num="0020">Among other things, the detailed description below describes use of methods and devices that can predict poor user experiences and one or both of notify the user and/or prevent the poor user experience. So, for example, when a user has a poor user experience, the user can flag it as so with a thumbs up or thumbs down or other user input. After a thumbs down, the system can analyze all diagnostic information related to the associated session and apply machine learning to predict and possibly prevent future poor user experiences, notify end users, and/or notify back-end system administrators. The poor experiences may be based on one or a combination of things that have been identified as together leading to the prior poor user experience.</p><p id="p-0022" num="0021">Machine learning inputs that may be used include the user input of the bad experience, collected diagnostic information around existing times when the poor experience occurred (such as error logs as well as long loading times and other insufficient system resources, server errors, etc.), and/or diagnostics/metric data from the poor experiences (such as time of day when the problem occurred, how many people were in on the same session or using the same system generally, the system load, database load, memory load, etc.). As indicated above, the data may be limited to a particular window of time such as a particular discrete segment of a video conference during which an error occurred, or for the particular video conference as a whole. Then as the system learns through machine learning, the system can better identify, report, and attempt to fix bad experiences for the detected problem in the future.</p><p id="p-0023" num="0022">Thus, the outputs from the machine learning model may include possible causes of a past or current bad experience, notification of a potential bad experience along with possibly offering solutions, and/or correcting predicted bad experiences before they even happen. The notification(s) may be presented to the end user and/or may even be presented to back-end system administrators along with recommendations on how the same or a similar problem was solved in the past.</p><p id="p-0024" num="0023">As a use case, suppose a teacher is monitoring student screens during online distance learning using a video conferencing service. Some of the student screens may unexpectedly go offline. The teacher may flag this as a poor experience. The system may then analyze hardware data from the students' computers that went offline, data on the network status at the time, database load data, server load data, etc. to identify patterns in this data with machine learning and predict similar poor experiences in the future to help mitigate them in the future.</p><p id="p-0025" num="0024">Again, in terms of machine learning, note that present principles may employ machine learning models, including deep learning models. Machine learning models use various algorithms trained in ways that include supervised learning, unsupervised learning, semi-supervised learning, reinforcement learning, feature learning, self-learning, and other forms of learning. Examples of such algorithms, which can be implemented by computer circuitry, include one or more neural networks, such as a convolutional neural network (CNN), recurrent neural network (RNN) which may be appropriate to learn information from a series of network diagnostic inputs, and a type of RNN known as a long short-term memory (LSTM) network/unit. Support vector machines (SVM) and Bayesian networks also may be considered to be examples of machine learning models for use consistent with present principles.</p><p id="p-0026" num="0025">As understood herein, performing machine learning involves accessing and then training a model on training data to enable the model to process further data to make predictions. A neural network may include an input layer, an output layer, and multiple hidden layers in between that that are configured and weighted to make inferences about an appropriate output.</p><p id="p-0027" num="0026">Prior to delving further into the details of the instant techniques, note with respect to any computer systems discussed herein that a system may include server and client components, connected over a network such that data may be exchanged between the client and server components. The client components may include one or more computing devices including televisions (e.g., smart TVs, Internet-enabled TVs), computers such as desktops, laptops and tablet computers, so-called convertible devices (e.g., having a tablet configuration and laptop configuration), and other mobile devices including smart phones. These client devices may employ, as non-limiting examples, operating systems from Apple Inc. of Cupertino Calif., Google Inc. of Mountain View, Calif., or Microsoft Corp. of Redmond, Wash. A Unix&#xae; or similar such as Linux&#xae; operating system may be used. These operating systems can execute one or more browsers such as a browser made by Microsoft or Google or Mozilla or another browser program that can access web pages and applications hosted by Internet servers over a network such as the Internet, a local intranet, or a virtual private network.</p><p id="p-0028" num="0027">As used herein, instructions refer to computer-implemented steps for processing information in the system. Instructions can be implemented in software, firmware or hardware, or combinations thereof and include any type of programmed step undertaken by components of the system; hence, illustrative components, blocks, modules, circuits, and steps are sometimes set forth in terms of their functionality.</p><p id="p-0029" num="0028">A processor may be any general-purpose single- or multi-chip processor that can execute logic by means of various lines such as address lines, data lines, and control lines and registers and shift registers. Moreover, any logical blocks, modules, and circuits described herein can be implemented or performed with a general-purpose processor, a digital signal processor (DSP), a field programmable gate array (FPGA) or other programmable logic device such as an application specific integrated circuit (ASIC), discrete gate or transistor logic, discrete hardware components, or any combination thereof designed to perform the functions described herein. A processor can also be implemented by a controller or state machine or a combination of computing devices. Thus, the methods herein may be implemented as software instructions executed by a processor, suitably configured application specific integrated circuits (ASIC) or field programmable gate array (FPGA) modules, or any other convenient manner as would be appreciated by those skilled in those art. Where employed, the software instructions may also be embodied in a non-transitory device that is being vended and/or provided that is not a transitory, propagating signal and/or a signal per se (such as a hard disk drive, CD ROM or Flash drive). The software code instructions may also be downloaded over the Internet. Accordingly, it is to be understood that although a software application for undertaking present principles may be vended with a device such as the system <b>100</b> described below, such an application may also be downloaded from a server to a device over a network such as the Internet.</p><p id="p-0030" num="0029">Software modules and/or applications described by way of flow charts and/or user interfaces herein can include various sub-routines, procedures, etc. Without limiting the disclosure, logic stated to be executed by a particular module can be redistributed to other software modules and/or combined together in a single module and/or made available in a shareable library.</p><p id="p-0031" num="0030">Logic when implemented in software, can be written in an appropriate language such as but not limited to hypertext markup language (HTML)-5, Java/JavaScript, C# or C++, and can be stored on or transmitted from a computer-readable storage medium such as a random access memory (RAM), read-only memory (ROM), electrically erasable programmable read-only memory (EEPROM), a hard disk drive or solid state drive, compact disk read-only memory (CD-ROM) or other optical disk storage such as digital versatile disc (DVD), magnetic disk storage or other magnetic storage devices including removable thumb drives, etc.</p><p id="p-0032" num="0031">In an example, a processor can access information over its input lines from data storage, such as the computer readable storage medium, and/or the processor can access information wirelessly from an Internet server by activating a wireless transceiver to send and receive data. Data typically is converted from analog signals to digital by circuitry between the antenna and the registers of the processor when being received and from digital to analog when being transmitted. The processor then processes the data through its shift registers to output calculated data on output lines, for presentation of the calculated data on the device.</p><p id="p-0033" num="0032">Components included in one embodiment can be used in other embodiments in any appropriate combination. For example, any of the various components described herein and/or depicted in the Figures may be combined, interchanged or excluded from other embodiments.</p><p id="p-0034" num="0033">&#x201c;A system having at least one of A, B, and C&#x201d; (likewise &#x201c;a system having at least one of A, B, or C&#x201d; and &#x201c;a system having at least one of A, B, C&#x201d;) includes systems that have A alone, B alone, C alone, A and B together, A and C together, B and C together, and/or A, B, and C together, etc.</p><p id="p-0035" num="0034">The term &#x201c;circuit&#x201d; or &#x201c;circuitry&#x201d; may be used in the summary, description, and/or claims. As is well known in the art, the term &#x201c;circuitry&#x201d; includes all levels of available integration, e.g., from discrete logic circuits to the highest level of circuit integration such as VLSI and includes programmable logic components programmed to perform the functions of an embodiment as well as general-purpose or special-purpose processors programmed with instructions to perform those functions.</p><p id="p-0036" num="0035">Now specifically in reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, an example block diagram of an information handling system and/or computer system <b>100</b> is shown that is understood to have a housing for the components described below. Note that in some embodiments the system <b>100</b> may be a desktop computer system, such as one of the ThinkCentre&#xae; or ThinkPad&#xae; series of personal computers sold by Lenovo (US) Inc. of Morrisville, N.C., or a workstation computer, such as the ThinkStation&#xae;, which are sold by Lenovo (US) Inc. of Morrisville, N.C.; however, as apparent from the description herein, a client device, a server or other machine in accordance with present principles may include other features or only some of the features of the system <b>100</b>. Also, the system <b>100</b> may be, e.g., a game console such as XBOX&#xae;, and/or the system <b>100</b> may include a mobile communication device such as a mobile telephone, notebook computer, and/or other portable computerized device.</p><p id="p-0037" num="0036">As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the system <b>100</b> may include a so-called chipset <b>110</b>. A chipset refers to a group of integrated circuits, or chips, that are designed to work together. Chipsets are usually marketed as a single product (e.g., consider chipsets marketed under the brands INTEL&#xae;, AMD&#xae;, etc.).</p><p id="p-0038" num="0037">In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the chipset <b>110</b> has a particular architecture, which may vary to some extent depending on brand or manufacturer. The architecture of the chipset <b>110</b> includes a core and memory control group <b>120</b> and an I/O controller hub <b>150</b> that exchange information (e.g., data, signals, commands, etc.) via, for example, a direct management interface or direct media interface (DMI) <b>142</b> or a link controller <b>144</b>. In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the DMI <b>142</b> is a chip-to-chip interface (sometimes referred to as being a link between a &#x201c;northbridge&#x201d; and a &#x201c;southbridge&#x201d;).</p><p id="p-0039" num="0038">The core and memory control group <b>120</b> include one or more processors <b>122</b> (e.g., single core or multi-core, etc.) and a memory controller hub <b>126</b> that exchange information via a front side bus (FSB) <b>124</b>. As described herein, various components of the core and memory control group <b>120</b> may be integrated onto a single processor die, for example, to make a chip that supplants the &#x201c;northbridge&#x201d; style architecture.</p><p id="p-0040" num="0039">The memory controller hub <b>126</b> interfaces with memory <b>140</b>. For example, the memory controller hub <b>126</b> may provide support for DDR SDRAM memory (e.g., DDR, DDR2, DDR3, etc.). In general, the memory <b>140</b> is a type of random-access memory (RAM). It is often referred to as &#x201c;system memory.&#x201d;</p><p id="p-0041" num="0040">The memory controller hub <b>126</b> can further include a low-voltage differential signaling interface (LVDS) <b>132</b>. The LVDS <b>132</b> may be a so-called LVDS Display Interface (LDI) for support of a display device <b>192</b> (e.g., a CRT, a flat panel, a projector, a touch-enabled light emitting diode display or other video display, etc.). A block <b>138</b> includes some examples of technologies that may be supported via the LVDS interface <b>132</b> (e.g., serial digital video, HDMI/DVI, display port). The memory controller hub <b>126</b> also includes one or more PCI-express interfaces (PCI-E) <b>134</b>, for example, for support of discrete graphics <b>136</b>. Discrete graphics using a PCI-E interface has become an alternative approach to an accelerated graphics port (AGP). For example, the memory controller hub <b>126</b> may include a 16-lane (x16) PCI-E port for an external PCI-E-based graphics card (including, e.g., one of more GPUs). An example system may include AGP or PCI-E for support of graphics.</p><p id="p-0042" num="0041">In examples in which it is used, the I/O hub controller <b>150</b> can include a variety of interfaces. The example of <figref idref="DRAWINGS">FIG. <b>1</b></figref> includes a SATA interface <b>151</b>, one or more PCI-E interfaces <b>152</b> (optionally one or more legacy PCI interfaces), one or more USB interfaces <b>153</b>, a LAN interface <b>154</b> (more generally a network interface for communication over at least one network such as the Internet, a WAN, a LAN, a Bluetooth network using Bluetooth 5.0 communication, etc. under direction of the processor(s) <b>122</b>), a general purpose I/O interface (GPIO) <b>155</b>, a low-pin count (LPC) interface <b>170</b>, a power management interface <b>161</b>, a clock generator interface <b>162</b>, an audio interface <b>163</b> (e.g., for speakers <b>194</b> to output audio), a total cost of operation (TCO) interface <b>164</b>, a system management bus interface (e.g., a multi-master serial computer bus interface) <b>165</b>, and a serial peripheral flash memory/controller interface (SPI Flash) <b>166</b>, which, in the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, includes basic input/output system (BIOS) <b>168</b> and boot code <b>190</b>. With respect to network connections, the I/O hub controller <b>150</b> may include integrated gigabit Ethernet controller lines multiplexed with a PCI-E interface port. Other network features may operate independent of a PCI-E interface.</p><p id="p-0043" num="0042">The interfaces of the I/O hub controller <b>150</b> may provide for communication with various devices, networks, etc. For example, where used, the SATA interface <b>151</b> provides for reading, writing, or reading and writing information on one or more drives <b>180</b> such as HDDs, SDDs or a combination thereof, but in any case, the drives <b>180</b> are understood to be, e.g., tangible computer readable storage mediums that are not transitory, propagating signals. The I/O hub controller <b>150</b> may also include an advanced host controller interface (AHCI) to support one or more drives <b>180</b>. The PCI-E interface <b>152</b> allows for wireless connections <b>182</b> to devices, networks, etc. The USB interface <b>153</b> provides for input devices <b>184</b> such as keyboards (KB), mice and various other devices (e.g., cameras, phones, storage, media players, etc.).</p><p id="p-0044" num="0043">In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the LPC interface <b>170</b> provides for use of one or more ASICs <b>171</b>, a trusted platform module (TPM) <b>172</b>, a super I/O <b>173</b>, a firmware hub <b>174</b>, BIOS support <b>175</b> as well as various types of memory <b>176</b> such as ROM <b>177</b>, Flash <b>178</b>, and non-volatile RAM (NVRAM) <b>179</b>. With respect to the TPM <b>172</b>, this module may be in the form of a chip that can be used to authenticate software and hardware devices. For example, a TPM may be capable of performing platform authentication and may be used to verify that a system seeking access is the expected system.</p><p id="p-0045" num="0044">The system <b>100</b>, upon power on, may be configured to execute boot code <b>190</b> for the BIOS <b>168</b>, as stored within the SPI Flash <b>166</b>, and thereafter processes data under the control of one or more operating systems and application software (e.g., stored in system memory <b>140</b>). An operating system may be stored in any of a variety of locations and accessed, for example, according to instructions of the BIOS <b>168</b>.</p><p id="p-0046" num="0045">Additionally, though not shown for simplicity, in some embodiments the system <b>100</b> may include a gyroscope that senses and/or measures the orientation of the system <b>100</b> and provides related input to the processor <b>122</b>, as well as an accelerometer that senses acceleration and/or movement of the system <b>100</b> and provides related input to the processor <b>122</b>. Still further, the system <b>100</b> may include an audio receiver/microphone that provides input from the microphone to the processor <b>122</b> based on audio that is detected, such as via a user providing audible input to the microphone. The system <b>100</b> may also include a camera that gathers one or more images and provides the images and related input to the processor <b>122</b>. The camera may be a thermal imaging camera, an infrared (IR) camera, a digital camera such as a webcam, a three-dimensional (3D) camera, and/or a camera otherwise integrated into the system <b>100</b> and controllable by the processor <b>122</b> to gather still images and/or video. Also, the system <b>100</b> may include a global positioning system (GPS) transceiver that is configured to communicate with at least one satellite to receive/identify geographic position information and provide the geographic position information to the processor <b>122</b>. However, it is to be understood that another suitable position receiver other than a GPS receiver may be used in accordance with present principles to determine the location of the system <b>100</b>.</p><p id="p-0047" num="0046">It is to be understood that an example client device or other machine/computer may include fewer or more features than shown on the system <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In any case, it is to be understood at least based on the foregoing that the system <b>100</b> is configured to undertake present principles.</p><p id="p-0048" num="0047">Turning now to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, example devices are shown communicating over a network <b>200</b> such as the Internet in accordance with present principles. It is to be understood that each of the devices described in reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref> may include at least some of the features, components, and/or elements of the system <b>100</b> described above. Indeed, any of the devices disclosed herein may include at least some of the features, components, and/or elements of the system <b>100</b> described above.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a notebook computer and/or convertible computer <b>202</b>, a desktop computer <b>204</b>, a wearable device <b>206</b> such as a smart watch, a smart television (TV) <b>208</b>, a smart phone <b>210</b>, a tablet computer <b>212</b>, and a server <b>214</b> such as an Internet server that may provide cloud storage accessible to the devices <b>202</b>-<b>212</b>. It is to be understood that the devices <b>202</b>-<b>214</b> may be configured to communicate with each other over the network <b>200</b> to undertake present principles.</p><p id="p-0050" num="0049">Now in reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, it shows an example graphical user interface (GUI) <b>300</b> that may be presented on the display of an end user's device responsive to conclusion of a video conference call conducted using the device. The device might be a smartphone, tablet computer, laptop, or wearable device for example.</p><p id="p-0051" num="0050">As shown, the GUI <b>300</b> may include a prompt <b>302</b> asking the end user if the end user's experience during the video conference was good or if the user experience problems like client software not loading, being dropped from the call, having interruptions in the data streams from other conference participants, etc. The user may select the selector <b>304</b> to provide user input that the user had a good experience, whereas selector <b>306</b> may be selected to provide user input that the user had a poor user experience.</p><p id="p-0052" num="0051">Responsive to selection of one of the selectors <b>304</b>, <b>306</b>, the user's device may then transmit the user's selection to one or more remotely-located servers to save the user's selection and the session's data in storage. Session data may include many different types of data related to the system (including its network components) as used to conduct the video conference. Thus, session data may include network status, database load (e.g., number of read and/or write actions within a threshold amount of time), server load, server errors, etc.</p><p id="p-0053" num="0052">In addition to being stored, the user's selection and the session data may also be provided to an artificial intelligence (AI) model <b>400</b> as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> for training the model <b>400</b> to identify similar problems in the future and act proactively to fix or mitigate a potential bad user experience for a future conference call. Training may be performed using one or more machine learning algorithms, including one or more deep learning algorithms if desired. The model <b>400</b> itself may be stored and deployed at a server or even an end user device.</p><p id="p-0054" num="0053">With respect to the AI architecture of the model <b>400</b> as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the model <b>400</b> may include a pattern extraction module <b>402</b> that may be established by one or more artificial neural networks (ANNs), such as one or more recurrent neural networks (RNNs) and other suitable ANNs, and even one or more long short-term memory (LTSM) units in particular. Thus, each of the module's ANN(s) may have an input layer <b>404</b>, output layer <b>406</b>, and multiple hidden layers <b>408</b> in between such as Softmax layers, ReLU layers, and batch normalization layers. During execution/deployment, the module <b>402</b> may receive as input session/system data <b>410</b> for a given system session (for video conferencing or other purposes) that is currently ongoing or that is scheduled to occur within a threshold time in the future (e.g., within five minutes). The session/system data may include data related to different network operating parameters, system node metrics and error reports, for example.</p><p id="p-0055" num="0054">The module <b>402</b> may then process the data through its layers and provide as output <b>412</b> pattern data and/or system issue data that it has inferred from the input. The output <b>412</b> may in turn be provided to a classifier module <b>414</b> that may itself include one or more ANNs, like RNNs and other suitable ANNs and LTSM units in particular, that each also have an input layer <b>416</b>, output layer <b>418</b>, and multiple hidden layers <b>420</b> in between such as Softmax layers, ReLU layers, and batch normalization layers. The module <b>414</b> may thus process the output <b>412</b> from the module <b>402</b> as input to its own input layer and use one or more classification algorithms to then provide as output <b>422</b> classification of one or more causes or reasons for a system insufficiency and/or poor user experience as inferred from the data <b>412</b>.</p><p id="p-0056" num="0055">Then based on the output <b>422</b>, the server or other device may access a local or remote relational database <b>424</b> that correlates particular insufficiencies/poor experiences with respective actions the server can proactively take upon inferring such things during a given system session that is currently ongoing or is expected to take place in the future, such as within a threshold number of minutes of the current time. The actions may include notifying an end user actively participating in the session or a user that is to participate in the session shortly. The actions may also include the server/other device autonomously taking steps to cure or mitigate the issue. The database may be preconfigured by a developer or system administrator, for example. However, further note that in addition to or in lieu of using the database <b>424</b>, the classifier module <b>414</b> itself may be trained to infer appropriate action to proactively take, e.g., using labeled training data indicating various actions to take based on various sets of data indicating various network/component patterns and metrics.</p><p id="p-0057" num="0056">During training but more generally, note the modules <b>402</b>, <b>414</b> may be variously trained using one or more machine learning algorithms in supervised fashion, unsupervised fashion (e.g., using deep learning), semi-supervised fashion, using reinforcement learning, using dimensionality reduction, etc. Thus, session data from a prior session for which user input has been received indicating a poor experience may be labeled with the poor user experience, and/or labeled with one or more causes of the poor experience as labeled by an administrator or as previously output by the model <b>400</b> during execution/deployment of the model <b>400</b> (e.g., prior to training or after any given training session). If a given block of session data to be used for training is assigned both labels (poor experience and the particular cause), a multi-label classification learning algorithm may be used. Also note that in some examples, session data for good user experiences or sessions where no negative user input was provided may also be used for training to further optimize the model <b>400</b>.</p><p id="p-0058" num="0057">As for the ANNs themselves that are to be trained, they may initially include random weightings/functions for the respective nodes of the respective layers and undergo extensive training to render desired outputs. Additionally, or alternatively, one or more nodes of the layers for each ANN may be preconfigured by a developer to recognize certain issues or bugs for a given set of patterns, trends and metrics and infer a given output, which may then be further refined through machine learning over time. In either case, the machine learning may be triggered manually and/or responsive to each reported bad user experience.</p><p id="p-0059" num="0058">Continuing the detailed description in reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, it shows example logic that may be executed in any appropriate combination by a device such as the system <b>100</b>, end user device, and/or server providing on online service consistent with present principles in order to employ the above-described architecture/model <b>400</b>. Beginning at block <b>500</b>, the device may identify a first poor user experience in a first instance (e.g., for a first video conferencing session) based on user input indicating the poor experience. From block <b>500</b> the logic may then proceed to block <b>502</b>.</p><p id="p-0060" num="0059">At block <b>502</b> the device may use system/session data and an AI model such as the model <b>400</b> to determine the causes or system insufficiencies leading to the poor user experience. The logic may then proceed to block <b>504</b> where the model may be trained as described above to, in the future, infer similar system insufficiencies to proactively take action for other instances. Thus, at block <b>506</b> the device may use the AI model to predict a second poor user experience or system insufficiency for a second instance (e.g., for a different video conferencing session between the same or different participants).</p><p id="p-0061" num="0060">Responsive to the predicting performed at block <b>506</b>, the logic may then proceed to block <b>508</b> where the device may proactively attempt to prevent or mitigate the issue(s) itself and/or proactively present one or more notifications to an end user via the end user's device regarding the prediction. One such example notification is shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0062" num="0061">Accordingly, in reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, note that a GUI <b>600</b> may be presented on the display of the end user's device and include a notification or prompt <b>602</b> that a network bandwidth problem is expected to occur during a given session the user has started or will start shortly. Again, note that the session may be for a video conference but may also be for playing a video game online, remote access to another computer, streaming audio video content, etc. In certain examples, the session may even relate to single-device use in isolation, like graphics design, acoustic modeling, etc. on a laptop where issues might still arise among various components.</p><p id="p-0063" num="0062">The GUI <b>600</b> may also include various selectors that the end user may then select to help address the bandwidth problem. For example, a selector <b>604</b> may be presented to command the user's own device or another system component (like a server hosting a video conference) to restart the session. Restarting the session may include closing and re-launching an application being used for the video conference or refreshing a local network connection, for example.</p><p id="p-0064" num="0063">The GUI <b>600</b> may also include a selector <b>606</b> that may be selectable to command the end user's device to switch to a different LAN/Wi-Fi network than one to which the end user's device is currently connected in order to help address the bandwidth problem. The name of the different network being suggested by the device may also be presented on the selector <b>606</b> as shown.</p><p id="p-0065" num="0064">Additionally, a selector <b>608</b> may be presented on the GUI <b>600</b> and may be selectable to command the end user's device to attempt to login to the video conference using a different conferencing service than the one the user is currently attempting to use for the video conference. For example, if the user were trying to use Zoom but sufficient bandwidth does not exist through Zoom's servers, the user may selector the selector <b>608</b> to use another service provider such as Teams that might have more bandwidth availability and/or less server load at the moment than Zoom's servers (as may also be indicated on the face of the selector <b>608</b> as shown). Thus, note that this example assumes that the different conferencing software apps can be used together for video conferencing through a unified communications platform being used by the system. Other reasons for selecting the selector <b>608</b> that are not shown but that might still be presented on the face of the selector <b>608</b> or elsewhere on the GUI <b>600</b> include the other provider's server having less memory load or less server errors or less load time, the other provider's client-side software and/or back-end server software having less bugs and failures, etc.</p><p id="p-0066" num="0065">Still further, in some examples the GUI <b>600</b> may also include one or more recommendations <b>610</b> for other actions the end user might take to help address the bandwidth problem. In the present example, the recommendation <b>610</b> is to move with the device to a different location so that the device automatically connects to a different cellular base station (e.g., where a cellular data network is being used by the end user's device for the video conference call). Thus, it is to be understood that the recommendation <b>610</b> and remedies associated with the other selectors on the GUI <b>600</b> may dynamically change and be tailored to whatever is determined to be the cause of the bandwidth problem. So here, the recommendation <b>610</b> has been tailored responsive to a determination that the bandwidth problem lies with the local cellular base station to which the end user's device is connected.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIGS. <b>7</b>-<b>9</b></figref> show additional example GUIs that may also be presented on the display of an end user's device, but where a system/server has already proactively taken action on its own to at least attempt to prevent or mitigate a system insufficiency itself. Beginning with <figref idref="DRAWINGS">FIG. <b>7</b></figref>, a GUI <b>700</b> may be presented that provides a prompt <b>702</b> that a server error has been detected or is expected to occur. The GUI <b>700</b> may also include an indication <b>704</b> of what action(s) the system is proactively taking to help fix or mitigate the server error, which in this case is switching to a different conferencing service provider than one the end user's device is currently attempting to use to conduct the video conference. However, if the user for any reason desires to continue using the current provider, selector <b>706</b> may be selected to provide a command to the device/system to continue using the current provider/app instead.</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows another example where a GUI <b>800</b> may include a prompt <b>802</b> indicating that there exists an undue amount of network latency to effectively conduct the video conference call. Accordingly, an indication <b>804</b> is also presented that indicates that the system/end user's device is proactively restarting the video conference session and/or switching to a different Wi-Fi/LAN that might not be currently experiencing as much latency. But should the user still wish to have their device remain connected to the current network and/or maintain the current session, selector <b>806</b> may be selected to command the system/device to do so.</p><p id="p-0069" num="0068">With reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, it shows another example GUI <b>900</b> that may be presented on the end user's device. The GUI <b>900</b> may include a prompt <b>902</b> indicating that there has been a network connection error. Thus, an indication <b>904</b> may be presented that indicates that the server being used for the video conference is proactively refreshing its network connection to the end user's device (or that the end user's device is itself refreshing the connection on its end). The indication <b>904</b> might also indicate that a port on the server through which the end user's device is connecting is being restarted. However, to further assist, the end user might select the selector <b>906</b> to command their device to disconnect from a certain Wi-Fi network the end user's device is currently using for the video conference and to instead use a wired LAN connection to which the device also has access to attempt a better connection. Another selector (not shown) might also be presented that may be selectable to command the end user's device to refresh or restart an Internet browser being executed at the device if the browser is being used to facilitate the session to further help resolve the issue.</p><p id="p-0070" num="0069">Continuing the detailed description in reference to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, it shows an example settings GUI <b>1000</b> that may be presented on the display of an end user's device or server that operates consistent with present principles to configure one or more settings of the device/system to operate as described herein. In the present example, each option or sub-option discussed below may be selected by directing touch or cursor input to the respectively adjacent check box.</p><p id="p-0071" num="0070">As shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the GUI <b>1000</b> may include a first option <b>1002</b> that is selectable to enable proactive system/network management to prevent poor user experiences. For example, the user may select the option <b>1002</b> to set or configure the device/system to in the future undertake the functions described above with respect to <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref>, to execute the logic of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, and/or to present the GUIs of <figref idref="DRAWINGS">FIGS. <b>6</b>-<b>9</b></figref>.</p><p id="p-0072" num="0071">In some examples, the option <b>1002</b> may be accompanied by sub-options <b>1004</b> and <b>1006</b>. Sub-option <b>1004</b> may be selected to set or configure the device/system notify the end user about system insufficiencies, while sub-option <b>1006</b> may be selected to set or configure the device/system to attempt to proactively remedy the insufficiencies itself. Both sub-options may be concurrently selected in certain examples so that both functions are executed for a given set of system data.</p><p id="p-0073" num="0072">As also shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the GUI <b>1000</b> may include an option <b>1008</b> to set or enable the device/system to use machine learning to improve the AI model/ANNs that are being used over time to make better inferences in the future as described above.</p><p id="p-0074" num="0073">It may now be appreciated that present principles provide for improved computer-based user interfaces that increase the functionality and ease of use of the devices disclosed herein. The disclosed concepts are rooted in computer technology for computers to carry out their functions.</p><p id="p-0075" num="0074">It is to be understood that whilst present principals have been described with reference to some example embodiments, these are not intended to be limiting, and that various alternative arrangements may be used to implement the subject matter claimed herein. Components included in one embodiment can be used in other embodiments in any appropriate combination. For example, any of the various components described herein and/or depicted in the Figures may be combined, interchanged or excluded from other embodiments.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A first device, comprising:<claim-text>at least one processor; and</claim-text><claim-text>storage accessible to the at least one processor and comprising instructions executable by the at least one processor to:</claim-text><claim-text>identify a first poor user experience with a system based on user input indicating the first poor user experience;</claim-text><claim-text>use data related to operation of the system to determine one or more causes of the first poor user experience;</claim-text><claim-text>predict that a second poor user experience will occur based on subsequent identification of one or more of the causes; and</claim-text><claim-text>based on the prediction, proactively prevent the second poor user experience from occurring and/or present a notification in advance of the second poor user experience.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The first device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions are executable to:<claim-text>based on the prediction, proactively prevent the second poor user experience from occurring.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The first device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions are executable to:<claim-text>based on the prediction, present a notification in advance of the second poor user experience.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The first device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determination is performed using at least one artificial neural network (ANN) to process the data and infer from the data one or more system insufficiencies indicating the one or more causes.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The first device of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the instructions are executable to:<claim-text>train the ANN using the data as input.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The first device of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the data is labeled with the one or more causes for training the ANN.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The first device of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the data is labeled as being a poor user experience for training the ANN, the data labeled by the first device as being a poor user experience based on the user input.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The first device of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the ANN is trained using one or more machine learning algorithms and the labeled data.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The first device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the ANN is trained using a multi-label classification learning algorithm.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The first device of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the prediction is made using the trained ANN.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The first device of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the prediction is made using the ANN.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The first device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the system comprises the first device, a second device different from the first device and associated with an end user, and/or a server providing an online service to an end user.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A method, comprising:<claim-text>determining an insufficiency of a system based on input from an end user indicating the insufficiency exists in a first instance;</claim-text><claim-text>using first data related to the system to identify one or more reasons for the insufficiency;</claim-text><claim-text>determining that the insufficiency has or will occur again based on subsequent identification of one or more of the reasons from second data different from the first data, the second data also related to the system, the second data corresponding to a second instance occurring after the first instance; and</claim-text><claim-text>based on determining that the insufficiency has or will occur again, proactively addressing the insufficiency.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the insufficiency is proactively addressed by attempting to prevent or mitigate the insufficiency.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the insufficiency is proactively addressed by presenting a notification at an end-user device regarding the insufficiency.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, comprising:<claim-text>using at least one artificial neural network (ANN) to infer, from the second data, that the insufficiency has or will occur again.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the ANN is trained using the first data and at least one machine learning algorithm.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. At least one computer readable storage medium (CRSM) that is not a transitory signal, the computer readable storage medium comprising instructions executable by at least one processor to:<claim-text>determine an insufficiency related to a system in a first instance;</claim-text><claim-text>analyze first data related to the first instance;</claim-text><claim-text>based on the analysis, determine that the insufficiency has or will occur again based on second data different from the first data, the second data also related to the system, the second data corresponding to a second instance occurring after the first instance; and</claim-text><claim-text>based on determination that the insufficiency has or will occur again, proactively address the insufficiency.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The CRSM of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the instructions are executable to:<claim-text>determine the insufficiency related to the system in the first instance based on user input indicating the insufficiency exists in the first instance.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The CRSM of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the analysis is used to recognize a pattern in the second data that is similar to a pattern indicated in the first data, wherein recognition of the pattern from the second data contributes to the determination that the insufficiency has or will occur again, and wherein the system in the first and second instances is facilitating a video conference.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003640A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003640</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17930341</doc-number><date>20220907</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>N</subclass><main-group>21</main-group><subgroup>3504</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>M</subclass><main-group>3</main-group><subgroup>26</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>M</subclass><main-group>3</main-group><subgroup>38</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>J</subclass><main-group>3</main-group><subgroup>42</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>J</subclass><main-group>3</main-group><subgroup>28</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>N</subclass><main-group>21</main-group><subgroup>3504</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>M</subclass><main-group>3</main-group><subgroup>26</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>M</subclass><main-group>3</main-group><subgroup>38</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>J</subclass><main-group>3</main-group><subgroup>42</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>J</subclass><main-group>3</main-group><subgroup>2823</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>N</subclass><main-group>2021</main-group><subgroup>1793</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">GAS LEAK EMISSION QUANTIFICATION WITH A GAS CLOUD IMAGER</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16661407</doc-number><date>20191023</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17930341</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>14792477</doc-number><date>20150706</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10458905</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16661407</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>62021636</doc-number><date>20140707</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>62021907</doc-number><date>20140708</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>62083131</doc-number><date>20141121</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>REBELLION PHOTONICS, INC.</orgname><address><city>Houston</city><state>TX</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Kester</last-name><first-name>Robert Timothy</first-name><address><city>Pearland</city><state>TX</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Hagen</last-name><first-name>Nathan Adrian</first-name><address><city>Houston</city><state>TX</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Mallery</last-name><first-name>Ryan</first-name><address><city>Houston</city><state>TX</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An instrument and method for analyzing a gas leak. The instrument can obtain a time series of spectra from a scene. The instrument can compare spectra from different times to determine a property of a gas cloud within the scene. The instrument can estimate the column density of the gas cloud at one or more locations within the scene. The instrument can estimate the total quantity of gas in the cloud. The instrument can estimate the amount of gas which has left the field of view of the instrument. The instrument can also estimate the amount of gas in the cloud which has dropped below the sensitivity limit of the instrument.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="101.18mm" wi="158.75mm" file="US20230003640A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="198.54mm" wi="146.47mm" orientation="landscape" file="US20230003640A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="180.93mm" wi="150.11mm" file="US20230003640A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="219.20mm" wi="152.32mm" file="US20230003640A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="221.91mm" wi="148.84mm" file="US20230003640A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="103.72mm" wi="152.06mm" file="US20230003640A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="194.73mm" wi="151.81mm" file="US20230003640A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="223.94mm" wi="148.67mm" file="US20230003640A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="168.57mm" wi="155.96mm" file="US20230003640A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="98.13mm" wi="140.29mm" file="US20230003640A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="233.34mm" wi="140.21mm" orientation="landscape" file="US20230003640A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="233.34mm" wi="140.21mm" orientation="landscape" file="US20230003640A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="233.34mm" wi="140.21mm" orientation="landscape" file="US20230003640A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="233.34mm" wi="140.21mm" orientation="landscape" file="US20230003640A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="207.35mm" wi="141.05mm" file="US20230003640A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="97.87mm" wi="152.06mm" file="US20230003640A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">INCORPORATION BY REFERENCE TO ANY PRIORITY APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 14/792,477, filed Jul. 6, 2015, and entitled &#x201c;GAS LEAK EMISSION QUANTIFICATION WITH A GAS CLOUD IMAGER.&#x201d; which claims priority to U.S. Provisional Patent Applications 62/021,636, filed Jul. 7, 2014, 62/021,907, filed Jul. 8, 2014, and 62/083,131, filed Nov. 21, 2014, all of which are entitled &#x201c;GAS LEAK EMISSION QUANTIFICATION WITH A GAS CLOUD IMAGER.&#x201d; All of the foregoing applications, and any other for which a foreign or domestic priority claim is identified in the Application Data Sheet as filed with the present application, are hereby incorporated by reference under 37 CFR 1.57.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Field</heading><p id="p-0003" num="0002">This disclosure generally relates to systems and methods for gas cloud detection and gas leak emission quantification.</p><heading id="h-0004" level="1">Description of the Related Art</heading><p id="p-0004" num="0003">There are a wide variety of systems that create, store, transfer, process, or otherwise involve gases. These include, but are not limited to, industrial systems, such as oil and gas drilling rigs and refineries. In such systems, there may be a risk of gas leaks. Such gases may include hydrocarbons (e.g., methane), ammonia, hydrogen sulfide, volatile organic compounds, and many, many others. Gas leaks can pose safety and/or environmental risks. They can also result in financial loss. It would therefore be advantageous to develop systems and methods for detecting gas leaks and quantifying gas leak emission.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0005" num="0004">In some embodiments, an infrared (IR) imaging system for quantifying one or more parameters of a gas leak having a gaseous emission rate is disclosed, the imaging system comprising: an optical system including an optical focal plane array (EPA) unit, the optical system having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA unit; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire multispectral optical data from the IR radiation received at the optical IPA unit and output gaseous emission rate data for a gaseous leak.</p><p id="p-0006" num="0005">In some embodiments, an infrared (IR) imaging system for quantifying one or more parameters of a gas cloud is disclosed, the imaging system comprising: an optical system including an optical focal plane array (FPA) unit, the optical system having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer <b>1</b>R radiation incident on the optical system towards the optical FPA unit; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire spectral optical data from the IR radiation received at the optical FPA unit, wherein said data-processing unit is configured to determine absorption spectra data at a given pixel of a given frame by comparing spectral data for said pixel of said frame with spectral data from prior frames.</p><p id="p-0007" num="0006">In some embodiments, a system for quantifying one or more parameters of a gas leak is disclosed, the system comprising: a communication subsystem for receiving multi-spectral optical data produced by a camera including an optical focal plane array (FPA) unit, the camera having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer JR radiation incident on the optical system towards the optical FPA, said multi-spectral optical data derived from the IR radiation received at the optical FPA; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire said multispectral spectral optical data from said communication subsystem, wherein said data-processing unit is configured to process said multispectral optical data and output gaseous emission rate data from a gaseous leak.</p><p id="p-0008" num="0007">In some embodiments, a system for quantifying one or more parameters of a gas leak is disclosed, the system comprising: a communication subsystem for receiving processed data derived from multi-spectral optical data produced by a camera including an optical focal plane array (FPA) unit, the camera having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA, said multi-spectral optical data derived from the IR radiation received at the optical FPA; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire said processed data from said communication subsystem, wherein said data-processing unit is configured to further process said processed data and output gaseous emission rate data for a gaseous leak.</p><p id="p-0009" num="0008">In some embodiments, a system for quantifying one or more parameters of a gas cloud is disclosed, the system comprising: a communication subsystem for receiving multi-spectral optical data produced by a camera including an optical focal plane array (FPA) unit, the camera having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA, said multi-spectral optical data derived from the IR radiation received at the optical FPA; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire said multi-spectral optical data from said communication subsystem, wherein said data-processing unit is configured to determine absorption spectra data at a given pixel of a given frame from a comparison of spectral data for said pixel of said frame with spectral data from prior frames.</p><p id="p-0010" num="0009">In some embodiments, a system for quantifying one or more parameters of a gas cloud is disclosed, the system comprising: a communication subsystem for receiving multi-spectral optical data produced by a camera including an optical focal plane array (FPA) unit, the camera having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA, said multi-spectral optical data derived from the IR radiation received at the optical FPA; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire said multi-spectral optical data from said communication subsystem, wherein said data-processing unit is configured to compare spectral data for said pixel of said frame with spectral data from prior frames for the determination of absorption spectra data at a given pixel of a given frame.</p><p id="p-0011" num="0010">In some embodiments, a system for quantifying one or more parameters of a gas cloud is disclosed, the system comprising: a communication subsystem for receiving optical data produced by a camera including an optical focal plane array (FPA) unit, the camera having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA, said multi-spectral optical data derived from the IR radiation received at the optical FPA; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire said optical data from said communication subsystem, wherein said data-processing unit is configured to consider noise as a criteria for determining whether to include data for the given pixel for a particular prior frame with data from other prior frames for comparing spectral data for a pixel of a later frame with spectral data from prior frames for the determination of absorption spectra data for the given pixel of the later frame.</p><p id="p-0012" num="0011">In some embodiments, an infrared (IR) imaging system for quantifying one or more parameters of a gas cloud is disclosed, the imaging system comprising: an optical system including an optical focal plane array (FPA) unit, the optical system having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer <b>1</b>R radiation incident on the optical system towards the optical FPA unit; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire spectral optical data from the IR radiation received at the optical FPA unit, wherein said data-processing unit is configured to determine gas emission by comparing data from a given frame with data from one or more prior frames.</p><p id="p-0013" num="0012">In some embodiments, an infrared (IR) imaging system for quantifying one or mom parameters of a gas cloud is disclosed, the imaging system comprising: an optical system including an optical focal plane array (FPA) unit, the optical system having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA unit; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire spectral optical data from the IR radiation received at the optical FPA unit, wherein said data-processing unit is configured to include an estimate of loss caused by a portion of said cloud being blown out of the field of view of the optical system.</p><p id="p-0014" num="0013">In some embodiments, an infrared (IR) imaging system for quantifying one or more parameters of a gas cloud is disclosed, the imaging system comprising: an optical system including an optical focal plane array (FPA) unit, the optical system having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA unit; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire spectral optical data from the IR radiation received at the optical FPA unit, wherein said optical system and FPA unit together with said data-processing unit has a detection sensitivity for detecting absorption, and wherein said data-processing unit is configured to include an estimate of loss caused by a portion of said cloud having absorption less than the detection sensitivity.</p><p id="p-0015" num="0014">In some embodiments, an infrared (IR) imaging system for quantifying one or more parameters of a gas cloud is disclosed, the imaging system comprising: an optical system including an optical focal plane array (FPA) unit, the optical system having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA unit; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire spectral optical data from the IR radiation received at the optical FPA unit, wherein said data-processing unit is configured to use noise as a criteria for determining whether to de-emphasize or exclude data for a particular frame.</p><p id="p-0016" num="0015">In some embodiments, an infrared (IR) imaging system for quantifying one or more parameters of a gas cloud is disclosed, the imaging system comprising: an optical system including an optical focal plane array (FPA) unit, the optical system having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA unit; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire spectral optical data from the IR radiation received at the optical FPA unit, wherein said data-processing unit is configured to determine a quantity of gas using one or more specifications of the FPA unit, one or more specification of the optical system, distance of camera to the gas cloud, or combinations thereof.</p><p id="p-0017" num="0016">In some embodiments, a system for quantifying one or more parameters of a gas cloud is disclosed, the system comprising: a communication subsystem for receiving optical data produced by a camera including an optical focal plane array (FPA) unit, the camera having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA, said multi-spectral optical data derived from the JR radiation received at the optical FPA; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire said optical data from said communication subsystem, wherein said data-processing unit is configured to determine gas emission by comparing data from a given frame with data from one or more prior frames.</p><p id="p-0018" num="0017">In some embodiments, a system for quantifying one or more parameters of a gas cloud is disclosed, the system comprising: a communication subsystem for receiving optical data produced by a camera including an optical focal plane array (FPA) unit, the camera having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA, said multi-spectral optical data derived from the IR radiation received at the optical FPA; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire said optical data from said communication subsystem, wherein said data-processing unit is configured to include an estimate of loss caused by a portion of said cloud being blown out of the field of view of the optical system.</p><p id="p-0019" num="0018">In some embodiments, a system for quantifying one or more parameters of a gas cloud is disclosed, the system comprising: a communication subsystem for receiving optical data produced by a camera including an optical focal plane array (FPA) unit, the camera having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA, said multi-spectral optical data derived from the IR radiation received at the optical FPA; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire said optical data from said communication subsystem, wherein said optical system and FPA unit together with said data-processing unit has a detection sensitivity for detecting absorption, and wherein said data-processing unit is configured to include an estimate of loss caused by a portion of said cloud having absorption less than the detection sensitivity.</p><p id="p-0020" num="0019">In some embodiments, a system for quantifying one or more parameters of a gas cloud is disclosed, the system comprising: a communication subsystem for receiving optical data produced by a camera including an optical focal plane array (FPA) unit, the camera having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA, said multi-spectral optical data derived from the IR radiation received at the optical FPA; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire said optical data from said communication subsystem, wherein said data-processing unit is configured to use noise as a criteria for determining whether to de-emphasize or exclude data for a particular frame.</p><p id="p-0021" num="0020">In some embodiments, a system for quantifying one or more parameters of a gas cloud is disclosed, the system comprising: a communication subsystem for receiving optical data produced by a camera including an optical focal plane array (FPA) unit, the camera having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA, said multi-spectral optical data derived from the JR radiation received at the optical FPA; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire said optical data from said communication subsystem, wherein said data-processing unit is configured to determine a quantity of gas using one or more specifications of the FPA unit, one or more specification of the optical system, distance of camera to the gas cloud, or combinations thereof.</p><p id="p-0022" num="0021">In some embodiments, an infrared (IR) imaging system for quantifying one or more parameters of a gas cloud is disclosed, the imaging system comprising: an optical system including an optical focal plane array (FPA) unit, the optical system having components defining at least two optical channels thereof, said at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA unit; and a data-processing unit comprising one or more processors, said data-processing unit configured to acquire spectral optical data from the IR radiation received at the optical FPA unit, wherein said data-processing unit is configured to include an estimate of atmospheric absorption between the gas cloud and the optical system.</p><p id="p-0023" num="0022">In some embodiments, a method of analyzing a gas leak using a processor is disclosed, the method comprising: receiving a time series of data from a sensor, the data being capable of quantifying an absorption spectrum of a gas cloud located within a field of view of the sensor, the data comprising a frame for each time in the time series, each frame comprising optical signal values corresponding to different locations within the field of view for each of a plurality of spectral wavelengths of electromagnetic radiation; comparing a subsequent frame of data with at least one prior frame of data in the time series; analyzing at least one property of a gas cloud located within the field of view of the sensor based on the comparison between the subsequent frame of data and the at least one prior frame of data; and outputting an indicator of the at least one property of the gas cloud to a user interface.</p><p id="p-0024" num="0023">In some embodiments, a method of analyzing the emission rate of a gas leak using a processor is disclosed, the method comprising: receiving a time series of data from a sensor, the data being capable of quantifying an absorption spectrum of a gas cloud located within a field of view of the sensor, the data comprising a frame for each time in the time series, each frame comprising optical signal values corresponding to different locations within the field of view for each of a plurality of spectral wavelengths of electromagnetic radiation; estimating the total amount of gas within the field of view of the sensor, temporally smoothing the estimate of the total amount of gas within the field of view; combining the temporally-smoothed estimate of the total amount of gas within the field of view with an estimate of the amount of gas that has exited the field of view; combining the temporally-smoothed estimate of the total amount of detected gas within the field of view of the sensor with an estimate of the amount of gas that has dropped below the sensitivity limit of the sensor, and outputting an indicator of the emission rate of the gas cloud to a user interface.</p><p id="p-0025" num="0024">In some embodiments, a system for analyzing a gas leak is disclosed, the system comprising: at least one processor; and a non-transitory memory with instructions configured to cause the at least one processor to perform a method comprising: receiving a time series of data from a sensor, the data being capable of quantifying an absorption spectrum of a gas cloud located within a field of view of the sensor, the data comprising a frame for each time in the time series, each frame comprising optical signal values corresponding to different locations within the field of view for each of a plurality of spectral wavelengths of electromagnetic radiation; comparing a subsequent frame of data with at least one prior frame of data in the time series; analyzing at least one property of a gas cloud located within the field of view of the sensor based on the comparison between the subsequent frame of data and the at least one prior frame of data; and outputting an indicator of the at least one property of the gas cloud to a user interface.</p><p id="p-0026" num="0025">In some embodiments, a system for analyzing the emission rate of a gas leak is disclosed, the system comprising: at least one processor; and a non-transitory memory with instructions configured to cause the at least one processor to perform a method comprising: receiving a time series of data from a sensor, the data being capable of quantifying an absorption spectrum of a gas cloud located within a field of view of the sensor, the data comprising a frame for each time in the time series, each frame comprising optical signal values corresponding to different locations within the field of view for each of a plurality of spectral wavelengths of electromagnetic radiation; estimating the total amount of gas within the field of view of the sensor; temporally smoothing the estimate of the total amount of gas within the field of view; combining the temporally-smoothed estimate of the total amount of gas within the field of view with an estimate of the amount of gas that has exited the field of view; combining the temporally-smoothed estimate of the total amount of detected gas within the field of view of the sensor with an estimate of the amount of gas that has dropped below the sensitivity limit of the sensor; and outputting an indicator of the emission rate of the gas cloud to a user interface.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>1</b></figref> provides a diagram schematically illustrating spatial and spectral division of incoming light by an embodiment of a divided aperture infrared spectral imager (DAISI) system that can image an object possessing IR spectral signature(s).</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates another embodiment of a spectral imager system.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example of the measurement geometry for a gas cloud imager (GCI).</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of an example method for calculating a running average of a scene spectral distribution.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart of an example method for detecting a gas cloud.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a gas cloud imager detector pixel projected to the location of the gas cloud.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart of an example method for calculating the absolute quantity of gas present in a gas cloud.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart of an example method for quantizing the emission rate of a gas leak.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart of an example method <b>700</b> for compensating an estimate of emission rate based on gas exiting the field of view of the camera and absorption dropping below sensitivity limits of the camera.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates a top view of an example scene measured by a gas cloud imager camera, with the gas cloud at a distance z (left). <figref idref="DRAWINGS">FIG. <b>8</b></figref> also illustrates the example scene as viewed from the gas cloud imager camera itself (right).</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows an example of the gas cloud imager (GCI) live viewer graphical user interface.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>12</b></figref> shows an example of the mosaic viewer interface which shows an overview of the entire area being monitored.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows an example of the graphical user interface with an alarm condition.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>14</b></figref> shows an example of an alarm thresholds settings window.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>15</b></figref> shows the measurement geometry for a single pixel in a gas cloud imager.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>16</b></figref> shows an example absorption spectrum measurement for propylene gas, showing the measured spectrum M(&#x3bb;).</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>17</b></figref> shows a detector pixel projected to the location of the gas cloud.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0044" num="0043">A. Gas Cloud Imagers</p><p id="p-0045" num="0044">Various embodiments of gas cloud imager (GCI) instruments are disclosed in U.S. patent application Ser. No. 14/538,827, filed Nov. 12, 2014, and entitled &#x201c;DIVIDED-APERTURE INFRA-RED SPECTRAL IMAGING SYSTEM,&#x201d; U.S. patent application Ser. No. 14/700,791, filed Apr. 30, 2015, and entitled &#x201c;MOBIL GAS AND CHEMICAL IMAGING CAMERA.&#x201d; and in U.S. patent application Ser. No. 14/700,567, filed Apr. 30, 2015, and entitled &#x201c;DUAL-BAND DIVIDED-APERTURE INFRA-RED SPECTRAL IMAGING SYSTEM.&#x201d; Each of the foregoing applications is hereby incorporated by reference herein in its entirety. The instruments disclosed in the foregoing applications are non-limiting examples of gas cloud imagers which may be used in conjunction with the algorithms disclosed herein.</p><p id="p-0046" num="0045">By way of background, one type of gas cloud imager is a divided-aperture infrared spectral imaging (DAISI) system that is structured and adapted to provide identification of target chemical contents of the imaged scene. The system is based on spectrally-resolved imaging and can provide such identification with a single-shot (also referred to as a snapshot) comprising a plurality of images having different wavelength compositions that are obtained generally simultaneously.</p><p id="p-0047" num="0046">Without any loss of generality, snapshot refers to a system in which most of the data elements that are collected are continuously viewing the light emitted from the scene. In contrast in scanning systems, at any given time only a minority of data elements are continuously viewing a scene, followed by a different set of data elements, and so on, until the full dataset is collected. Relatively fast operation can be achieved in a snapshot system because it does not need to use spectral or spatial scanning for the acquisition of infrared (IR) spectral signatures of the target chemical contents. Instead, IR detectors (such as, for example, infrared focal plane arrays or FPAs) associated with a plurality of different optical channels having different wavelength profiles can be used to form a spectral cube of imaging data. Although spectral data can be obtained from a single snapshot comprising multiple simultaneously-acquired images corresponding to different wavelength ranges, in various embodiments, multiple snap shots may be obtained. In various embodiments, these multiple snapshots can be averaged. Similarly, in certain embodiments multiple snap shots may be obtained and a portion of these can be selected and possibly averaged.</p><p id="p-0048" num="0047">Also, in contrast to commonly used IR spectral imaging systems, the DAISI system does not require cooling (for example cryogenic cooling). Accordingly, it can advantageously use uncooled infrared detectors. For example, in various implementations, the imaging systems disclosed herein do not include detectors configured to be cooled to a temperature below 300 Kelvin. As another example, in various implementations, the imaging systems disclosed herein do not include detectors configured to be cooled to a temperature below 273 Kelvin. As yet another example, in various implementations, the imaging systems disclosed herein do not include detectors configured to be cooled to a temperature below 250 Kelvin. As another example, in various implementations, the imaging systems disclosed herein do not include detectors configured to be cooled to a temperature below 200 Kelvin.</p><p id="p-0049" num="0048">Implementations disclosed herein provide several advantages over existing <b>1</b>R spectral imaging systems, most if not all of which may require FPAs that are highly sensitive and cooled in order to compensate, during the optical detection, for the reduction of the photon flux caused by spectrum-scanning operation. The highly sensitive and cooled FPA systems are expensive and require a great deal of maintenance. Since various embodiments disclosed herein are configured to operate in single-shot acquisition mode without spatial and/or spectral scanning, the instrument can receive photons from a plurality of points (e.g., every point) of the object substantially simultaneously, during the single reading. Accordingly, the embodiments of imaging system described herein can collect a substantially greater amount of optical power from the imaged scene (for example, an order of magnitude more photons) at any given moment in time especially in comparison with spatial and/or spectral scanning systems. Consequently, various embodiments of the imaging systems disclosed herein can be operated using uncooled detectors (for example, FPA unit including an array of microbolometers) that are less sensitive to photons in the IR but are well fit for continuous monitoring applications.</p><p id="p-0050" num="0049">For example, in various implementations, the imaging systems disclosed herein do not include detectors configured to be cooled to a temperature below 300 Kelvin. As another example, in various implementations, the imaging systems disclosed herein do not include detectors configured to be cooled to a temperature below 273 Kelvin. As yet another example, in various implementations, the imaging systems disclosed herein do not include detectors configured to be cooled to a temperature below 250 Kelvin. As another example, in various implementations, the imaging systems disclosed herein do not include detectors configured to be cooled to a temperature below 200 Kelvin. Imaging systems including uncooled detectors can be capable of operating in extreme weather conditions, require less power, are capable of operation during day and night, and are less expensive. Some embodiments described herein can also be less susceptible to motion artifacts in comparison with spatially and/or spectrally scanning systems which can cause errors in either the spectral data, spatial data, or both.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>1</b></figref> provides a diagram schematically illustrating spatial and spectral division of incoming light by an embodiment <b>100</b> of a divided aperture infrared spectral imager (DAISI) system that can image an object <b>110</b> possessing IR spectral signature(s). The system <b>100</b> includes a front objective lens <b>124</b>, an array of optical filters <b>130</b>, an array of reimaging lenses <b>128</b> and a detector array <b>136</b>. In various embodiments, the detector array <b>136</b> can include a single FPA or an array of FPAs. Each detector in the detector array <b>136</b> can be disposed at the focus of each of the lenses in the array of reimaging lenses <b>128</b>. In various embodiments, the detector array <b>136</b> can include a plurality of photo-sensitive devices. In some embodiments, the plurality of photo-sensitive devices may comprise a two-dimensional imaging sensor array that is sensitive to radiation having wavelengths between 1 &#x3bc;m and 20 &#x3bc;m (for example, in near infra-red wavelength range, mid infra-red wavelength range, or long infra-red wavelength range). In various embodiments, the plurality of photo-sensitive devices can include CCD or CMOS sensors, bolometers, microbolometers or other detectors that are sensitive to infra-red radiation. Without any loss of generality the detector array <b>136</b> can also be referred to herein as an imaging system or a camera.</p><p id="p-0052" num="0051">An aperture of the system <b>100</b> associated with the front objective lens system <b>124</b> is spatially and spectrally divided by the combination of the array of optical filters <b>130</b> and the array of reimaging lenses <b>128</b>. In various embodiments, the combination of the array of optical filters <b>130</b> and the array of reimaging lenses <b>128</b> can be considered to form a spectrally divided pupil that is disposed forward of the optical detector array <b>136</b>. The spatial and spectral division of the aperture into distinct aperture portions forms a plurality of optical channels <b>120</b> along which light propagates. Various implementations of the system can include at least two spatially and spectrally different optical channels. For example, various implementations of the system can include at least three, at least four, at least five, at least six, at least seven, at least eight, at least nine, at least ten, at least eleven or at least twelve spatially and spectrally different optical channels. The number of spatially and spectrally different optical channels can be less than 50 in various implementations of the system. In various embodiments, the array <b>128</b> of re-imaging lenses <b>128</b><i>a </i>and the array of spectral filters <b>130</b> can respectively correspond to the distinct optical channels <b>120</b>. The plurality of optical channels <b>120</b> can be spatially and/or spectrally distinct. The plurality of optical channels <b>120</b> can be formed in the object space and/or image space. The spatially and spectrally different optical channels can be separated angularly in space. The array of spectral filters <b>130</b> may additionally include a filter-holding aperture mask (comprising, for example, IR light-blocking materials such as ceramic, metal, or plastic).</p><p id="p-0053" num="0052">Light from the object <b>110</b> (for example a cloud of gas), the optical properties of which in the IR are described by a unique absorption, reflection and/or emission spectrum, is received by the aperture of the system <b>100</b>. This light propagates through each of the plurality of optical channels <b>120</b> and is further imaged onto the optical detector array <b>136</b>. In various implementations, the detector array <b>136</b> can include at least one FPA. In various embodiments, each of the re-imaging lenses <b>128</b><i>a </i>can be spatially aligned with a respectively-corresponding spectral region. In the illustrated implementation, each filter element from the array of spectral filters <b>130</b> corresponds to a different spectral region. Each re-imaging lens <b>128</b><i>a </i>and the corresponding filter element of the array of spectral filter <b>130</b> can coincide with (or form) a portion of the divided aperture and therefore with respectively-corresponding spatial channel <b>120</b>. Accordingly, in various embodiments an imaging lens <b>128</b><i>a </i>and a corresponding spectral filter can be disposed in the optical path of one of the plurality of optical channels <b>120</b>. Radiation from the object <b>110</b> propagating through each of the plurality of optical channels <b>120</b> travels along the optical path of each re-imaging lens <b>128</b><i>a </i>and the corresponding filter element of the array of spectral filter <b>130</b> and is incident on the detector array (e.g., FPA component) <b>136</b> to form a single image (e.g., sub-image) of the object <b>110</b>.</p><p id="p-0054" num="0053">The image formed by the detector array <b>136</b> generally includes a plurality of sub-images formed by each of the optical channels <b>120</b>. Each of the plurality of sub-images can provide different spatial and spectral information of the object <b>110</b>. The different spatial information results from some parallax because of the different spatial locations of the smaller apertures of the divided aperture. In various embodiments, adjacent sub-images can be characterized by close or substantially equal spectral signatures.</p><p id="p-0055" num="0054">The detector array (e.g., FPA component) <b>136</b> is further operably connected with a data-processing unit that includes a processor <b>150</b> (not shown). The processor can comprise processing electronics. The data-processing unit can be located remotely from the detector array <b>136</b>. For example, in some implementations, the data-processing unit can be located at a distance of about 10-3000 feet from the detector array <b>136</b>. As another example, in some other implementations, the data-processing unit can be located at a distance less than about 10 feet from the detector array <b>136</b> or greater than about 3000 feet. The data-processing unit can be connected to the detector array by a wired or a wireless communication link. The detector array (e.g., FPA component) <b>136</b> and/or the data-processing unit can be operably connected with a display device.</p><p id="p-0056" num="0055">The processor or processing electronics <b>150</b> can be programmed to aggregate the data acquired with the system <b>100</b> into a spectral data cube. The data cube represents, in spatial (x, y) and spectral (&#x3bb;) coordinates, an overall spectral image of the object <b>110</b> within the spectral region defined by the combination of the filter elements in the array of spectral filters <b>130</b>. Additionally, in various embodiments, the processor or processing electronics <b>150</b> may be programmed to determine the unique absorption characteristic of the object <b>110</b>. Also, the processor <b>150</b> can, alternatively or in addition, map the overall image data cube into a cube of data representing, for example, spatial distribution of concentrations, c, of targeted chemical components within the field of view associated with the object <b>110</b>. The processor</p><p id="p-0057" num="0056">Various implementations of the embodiment <b>100</b> can include an optional moveable temperature-controlled reference source <b>160</b> including, for example, a shutter system comprising one or more reference shutters maintained at different temperatures. The reference source <b>160</b> can include a heater, a cooler or a temperature-controlled element configured to maintain the reference source <b>160</b> at a desired temperature. For example, in various implementations, the embodiment <b>100</b> can include two reference shutters maintained at different temperatures. In various implementations including more than one reference shutter, some of the shutters may not be temperature controlled. The reference source <b>160</b> is removably and, in one implementation, periodically inserted into an optical path of light traversing the system <b>100</b> from the object <b>110</b> to the detector array (e.g., FPA component)<b>136</b> along at least one of the channels <b>120</b>. The removable reference source <b>160</b> thus can block such optical path. Moreover, this reference source <b>160</b> can provide a reference IR spectrum to recalibrate various components including the detector array <b>136</b> of the system <b>100</b> in real time.</p><p id="p-0058" num="0057">In the embodiment <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the front objective lens system <b>124</b> is shown to include a single front objective lens positioned to establish a common field-of-view (FOV) for the reimaging lenses <b>128</b><i>a </i>and to define an aperture stop for the whole system. In this specific case, the aperture stop substantially spatially coincides with and/or is about the same size or slightly larger, as the plurality of smaller limiting apertures corresponding to different optical channels <b>120</b>. As a result, the positions for spectral filters of the different optical channels <b>120</b> coincide with the position of the aperture stop of the whole system, which in this example is shown as a surface between the lens system <b>124</b> and the array <b>128</b> of the reimaging lenses <b>128</b><i>a</i>. In various implementations, the lens system <b>124</b> can be an objective lens <b>124</b>. However, the objective lens <b>124</b> is optional and various embodiments of the system <b>100</b> need not include the objective lens <b>124</b>. In various embodiments, the objective lens <b>124</b> can slightly shift the images obtained by the different detectors in the array <b>136</b> spatially along a direction perpendicular to optical axis of the lens <b>124</b>, thus the functionality of the system <b>100</b> is not necessarily compromised when the objective lens <b>124</b> is not included. Generally, however, the field apertures corresponding to different optical channels may be located in the same or different planes. These field apertures may be defined by the aperture of the reimaging lens <b>128</b><i>a </i>and/or filters in the divided aperture <b>130</b> in certain implementations. In one implementation, the field apertures corresponding to different optical channels can be located in different planes and the different planes can be optical conjugates of one another. Similarly, while all of the filter elements in the array of spectral filters <b>130</b> of the embodiment <b>100</b> are shown to lie in one plane, generally different filter elements of the array of spectral filter <b>130</b> can be disposed in different planes. For example, different filter elements of the array of spectral filters <b>130</b> can be disposed in different planes that are optically conjugate to one another. However, in other embodiments, the different filter elements can be disposed in non-conjugate planes.</p><p id="p-0059" num="0058">In various implementations, the front objective lens <b>124</b> need not be a single optical element, but instead can include a plurality of lenses <b>224</b> as shown in an embodiment <b>200</b> of the DAISI imaging system in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. These lenses <b>224</b> are configured to divide an incoming optical wavefront from the object <b>110</b>. For example, the array of front objective lenses <b>224</b> can be disposed so as to receive an IR wavefront emitted by the object that is directed toward the DAISI system. The plurality of front objective lenses <b>224</b> divide the wavefront spatially into non-overlapping sections. <figref idref="DRAWINGS">FIG. <b>2</b></figref> shows three objective lenses <b>224</b> in a front optical portion of the optical system contributing to the spatial division of the aperture of the system in this example. The plurality of objective lenses <b>224</b>, however, can be configured as a two-dimensional (2D) array of lenses.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>2</b></figref> presents a general view of the imaging system <b>200</b> and the resultant field of view of the imaging system <b>200</b>. An exploded view <b>202</b> of the imaging system <b>200</b> is also depicted in greater detail in a figure inset of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. As illustrated in the detailed view <b>202</b>, the embodiment of the imaging system <b>200</b> includes a field reference <b>204</b> at the front end of the system. The field reference <b>204</b> can be used to truncate the field of view. The configuration illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> has an operational advantage over embodiment <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> in that the overall size and/or weight and/or cost of manufacture of the embodiment <b>200</b> can be greatly reduced because the objective lens is smaller. Each pair of the lenses in the array <b>224</b> and the array <b>128</b> is associated with a field of view (FOV). Each pair of lenses in the array <b>224</b> and the array <b>128</b> receives light from the object from a different angle. While the lenses <b>224</b> are shown to be disposed substantially in the same plane, optionally different objective lenses in the array of front objective lenses <b>224</b> can be disposed in more than one plane. For example, some of the individual lenses <b>224</b> can be displaced with respect to some other individual lenses <b>224</b> along the axis <b>226</b> (not shown) and/or have different focal lengths as compared to some other lenses <b>224</b>. As discussed below, the field reference <b>204</b> can be useful in calibrating the multiple detectors <b>236</b>.</p><p id="p-0061" num="0060">In one implementation, the front objective lens system such as the array of lenses <b>224</b> is configured as an array of lenses integrated or molded in association with a monolithic substrate. Such an arrangement can reduce the costs and complexity otherwise accompanying the optical adjustment of individual lenses within the system. An individual lens <b>224</b> can optionally include a lens with varying magnification. As one example, a pair of thin and large diameter Alvarez plates can be used in at least a portion of the front objective lens system. Without any loss of generality, the Alvarez plates can produce a change in focal length when translated orthogonally with respect to the optical beam.</p><p id="p-0062" num="0061">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the detector array <b>136</b> (e.g., FPA component) configured to receive the optical data representing spectral signature(s) of the imaged object <b>110</b> can be configured as a single imaging array (e.g., FPA) <b>136</b>. This single array may be adapted to acquire mom than one image (formed by mom than one optical channel <b>120</b>) simultaneously. Alternatively, the detector array <b>136</b> may include a FPA unit. In various implementations, the FPA unit can include a plurality of optical FPAs. At least one of these plurality of FPAs can be configured to acquire more than one spectrally distinct image of the imaged object. For example, as shown in the embodiment <b>200</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in various embodiments, the number of FPAs included in the FPA unit may correspond to the number of the front objective lenses <b>224</b>. In the embodiment <b>200</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, for example, three FPAs <b>236</b> are provided corresponding to the three objective lenses <b>224</b>. In one implementation of the system, the FPA unit can include an array of microbolometers. The use of multiple microbolometers advantageously allows for an inexpensive way to increase the total number of detection elements (i.e. pixels) for recording of the three-dimensional data cube in a single acquisition event (i.e. one snapshot). In various embodiments, an array of microbolometers more efficiently utilizes the detector pixels of the array of FPAs (e.g., each FPA) as the number of unused pixels is reduced, minimized and/or eliminated between the images that may exist when using a single microbolometer. The optical filters, used in various implementations of the system, that provide spectrally-distinct IR image (e.g., sub-image) of the object can employ absorption filters, interference filters, and Fabry-Perot etalon based filters, to name just a few. When interference filters are used, the image acquisition through an individual imaging channel defined by an individual re-imaging lens (such as a lens <b>128</b><i>a </i>of <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>) may be carried out in a single spectral bandwidth or multiple spectral bandwidths.</p><p id="p-0063" num="0062">The optical filtering configuration of various embodiments disclosed herein may advantageously use a bandpass filter having a specified spectral band. The filters may be placed in front of the optical FPA (or generally, between the optical FPA and the object). In implementations of the system that include microbolometers, the predominant contribution to noise associated with image acquisition can be attributed to detector noise. To compensate and/or reduce the noise, various embodiments disclosed herein utilize spectrally-multiplexed filters. In various implementations, the spectrally-multiplexed filters can comprise a plurality of long pass (LP) filters, a plurality of band pass filters and any combinations thereof. A LP filter generally attenuates shorter wavelengths and transmits (passes) longer wavelengths (e.g., over the active range of the target IR portion of the spectrum). In various embodiments, short-wavelength-pass (SP) filters, may also be used. A SP filter generally attenuates longer wavelengths and transmits (passes) shorter wavelengths (e.g., over the active range of the target IR portion of the spectrum). At least in part due to the snap-shot/non-scanning mode of operation, embodiments of the imaging system described herein can use less sensitive microbolometers without compromising the SNR. The use of microbolometers, as detector-noise-limited devices, in turn not only benefits from the use of spectrally multiplexed filters, but also does not require cooling of the imaging system during normal operation.</p><p id="p-0064" num="0063">As discussed above, various embodiments may optionally, and in addition to a temperature-controlled reference unit (for example temperature controlled shutters such as shutter <b>160</b>), employ a field reference component, or an array of field reference components (e.g., filed reference apertures), to enable dynamic calibration. Such dynamic calibration can be used for spectral acquisition of one or more or every data cube. Such dynamic calibration can also be used for a spectrally-neutral camera-to-camera combination to enable dynamic compensation of parallax artifacts. The use of the temperature-controlled reference unit (for example, temperature-controlled shutter system <b>160</b>) and field-reference component(s) facilitates maintenance of proper calibration of each of the FPAs individually and the entire FPA unit as a whole.</p><p id="p-0065" num="0064">In particular, and in further reference to <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>, the temperature-controlled unit generally employs a system having first and second temperature zones maintained at first and second different temperatures. For example, shutter system of each of the embodiments <b>100</b> and <b>200</b> can employ not one but at least two temperature-controlled shutters that are substantially parallel to one another and transverse to the general optical axis <b>226</b> of the embodiment(s) <b>100</b> and <b>200</b>. Two shutters at two different temperatures may be employed to provide more information for calibration; for example, the absolute value of the difference between FPAs at one temperature as well as the change in that difference with temperature change can be recorded. As discussed above, only one of the two shutters can be temperature controlled in various implementations while the other is not. In various implementations, multiple shutters can be employed to create a known reference temperature difference perceived by the FPA. This reference temperature difference is provided by the IR radiation emitted by the multiple shutters when they are positioned to block the radiation from the object <b>110</b>. As a result, not only the offset values corresponding to each of the individual FPAs pixels can be adjusted but also the gain values of these FPAs. In an alternative embodiment, the system having first and second temperature zones may include a single or multi-portion piece. This single or multi-portion piece may comprise for example a plate. This piece may be mechanically-movable across the optical axis with the use of appropriate guides and having a first portion at a first temperature and a second portion at a second temperature.</p><p id="p-0066" num="0065">Various implementations of the DAISI system can include a variety of temperature calibration elements to facilitate dynamic calibration of the FPAs. The temperature calibration elements can include mirrors as well as reference sources. The use of optically-filtered FPAs in various embodiments of the system described herein can provide a system with higher number of pixels. For example, embodiments including a single large format microbolometer FPA array can provide a system with large number of pixels. Various embodiments of the systems described herein can also offer a high optical throughput for a substantially low number of optical channels. For example, the systems described herein can provide a high optical throughput for a number of optical channels between 4 and 50. By having a lower number of optical channels (e.g., between 4 and 50 optical channels), the systems described herein have wider spectral bins which allows the signals acquired within each spectral bin to have a greater integrated intensity.</p><p id="p-0067" num="0066">B. Gas Leak Quantification with a Gas Cloud Imager</p><p id="p-0068" num="0067">The idea of using passive infrared absorption spectroscopy to detect and analyze gas clouds is an idea that has been pursued for decades, but whose implementation in an autonomous setting has remained out of reach. The primary difficulty with adapting these instruments to industrial use has been their low data rate&#x2014;gas clouds are dynamic phenomena and require video analytics to properly detect them. As discussed herein, recently, advanced spectral imaging instruments have become available that improve light collection capacity and allow for video-rate imaging. Even with these new instruments, however, existing computational methods are incapable of performing autonomous operation, as they require supervision from an operator in order to function. In the discussion below, we provide alternative methods for detection and quantification of gas clouds that allow fully autonomous operation. 1. Conventional Measurement Model</p><p id="p-0069" num="0068">For a passive infrared sensor, the typical gas cloud measurement model is a three-layer radiative transfer system, in which the ray path is divided into three regions: (1) a layer of atmosphere between the sensor and the gas cloud. (2) a layer containing one or more of the target gases, and (3) an atmosphere behind the gas. Layer (3) is followed by a radiation source, which may either be an opaque surface or the sky itself. In the following discussion, we use the following definitions:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0069">L<sub>f</sub>, L<sub>b</sub>, L<sub>s</sub>: radiances originating from foreground, background, and source layers</li>        <li id="ul0002-0002" num="0070">&#x3c4;<sub>f</sub>, &#x3c4;<sub>b</sub>, &#x3c4;<sub>c</sub>: transmission of foreground, background, and cloud layers</li>        <li id="ul0002-0003" num="0071">T<sub>f</sub>, T<sub>b</sub>, T<sub>c</sub>: temperatures of foreground, background, and cloud layers</li>        <li id="ul0002-0004" num="0072">M<sup>(0)</sup>, M<sup>(1)</sup>: at-sensor radiance in the absence (0) or presence (1) of the cloud</li>        <li id="ul0002-0005" num="0073">&#x3c3;<sub>m</sub>: absorption cross-section of target gas m</li>        <li id="ul0002-0006" num="0074">&#x3b7;<sub>m</sub>: concentration of target gas m</li>        <li id="ul0002-0007" num="0075">l: path length through the gas cloud</li>    </ul>    </li></ul></p><p id="p-0070" num="0076"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example of the measurement geometry for a gas cloud imager (GCI). As just discussed, the field of view of each pixel (with line of sight indicated by &#x201c;LOS&#x201d;) is divided into three layers and an external source.</p><p id="p-0071" num="0077">A spectral imager measures the at-sensor radiance given by the line integral of the light extending from the source, through each of the three layers of the system (see <figref idref="DRAWINGS">FIG. <b>3</b></figref>). When no gas cloud is present, radiative transfer of a ray along the line of sight gives</p><p id="p-0072" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>M</i><sup>(0)</sup><i>=L</i><sub>f</sub>+&#x3c4;<sub>f</sub><i>L</i><sub>b</sub>+&#x3c4;<sub>f</sub>&#x3c4;<sub>b</sub><i>L</i><sub>s </sub><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0073" num="0000">When a gas cloud is present, this becomes</p><p id="p-0074" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>M</i><sup>(1)</sup><i>=L</i><sub>f</sub>+&#x3c4;<sub>f</sub>(1&#x2212;&#x3c4;<sub>c</sub>)<i>B</i>(<i>T</i><sub>c</sub>)+&#x3c4;<sub>f</sub>&#x3c4;<sub>c</sub>&#x3c4;<sub>b</sub><i>+L</i><sub>s </sub><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0075" num="0000">Subtracting M<sup>(0) </sup>from Me<sup>(1) </sup>gives the radiance difference in the presence of the target gas cloud:</p><p id="p-0076" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x394;<i>M=M</i><sup>(1)</sup><i>&#x2212;M</i><sup>(0)</sup>=&#x2212;&#x3c4;<sub>f</sub>(1&#x2212;&#x3c4;<sub>c</sub>)[<i>L</i><sub>b</sub>+&#x3c4;<sub>b</sub><i>L</i><sub>s</sub><i>&#x2212;B</i>(<i>T</i><sub>c</sub>)],&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0077" num="0000">where &#x394;L, the term [L<sub>b</sub>+&#x3c4;<sub>b </sub>L<sub>s</sub>&#x2212; B(T<sub>c</sub>)], is the &#x201c;thermal radiance contrast.&#x201d; the sign of which indicates whether the cloud is observed in emission (&#x394;L&#x3c;0) or absorption (&#x394;L&#x3e;0). When the background may be approximated as a homogeneous layer at thermal equilibrium, we can further write that L<sub>b</sub>=(1&#x2212;&#x3c4;<sub>b</sub>) B(T<sub>b</sub>). Note that all of these quantities have an implicit spectral dependence (i.e. M<sup>(0)</sup>=M<sup>(0)</sup>)(&#x3bb;) etc.).</p><p id="p-0078" num="0078">Thus, if we measure the change in at-sensor radiance. &#x394;M, and we can estimate the thermal radiance contrast &#x394;L and foreground transmission &#x3c4;<sub>f</sub>, then we can obtain the gas cloud transmission &#x3c4;<sub>c </sub>as</p><p id="p-0079" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>1&#x2212;&#x3c4;<sub>c</sub><i>=&#x2212;&#x394;M</i>/(&#x3c4;<sub>f</sub><i>&#x394;L</i>)&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0080" num="0000">When the gas concentration is low, the transmission can be modeled with a linearized version of the Beer-Lambert equation obtained by Taylor expansion:</p><p id="p-0081" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mn>1</mn>      <mo>-</mo>      <msub>       <mi>&#x3c4;</mi>       <mi>c</mi>      </msub>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <mn>1</mn>       <mo>-</mo>       <msup>        <mi>e</mi>        <mrow>         <mo>-</mo>         <msub>          <mi>&#x3b1;</mi>          <mi>c</mi>         </msub>        </mrow>       </msup>      </mrow>      <mo>=</mo>      <mrow>       <mrow>        <msub>         <mi>&#x3b1;</mi>         <mi>c</mi>        </msub>        <mo>+</mo>        <mrow>         <mfrac>          <mn>1</mn>          <mrow>           <mn>2</mn>           <mo>!</mo>          </mrow>         </mfrac>         <mo>&#x2062;</mo>         <msubsup>          <mi>&#x3b1;</mi>          <mi>c</mi>          <mn>2</mn>         </msubsup>        </mrow>        <mo>+</mo>        <mo>&#x2026;</mo>       </mrow>       <mo>&#x2248;</mo>       <msub>        <mi>&#x3b1;</mi>        <mi>c</mi>       </msub>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>3</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0082" num="0000">for absorbance &#x3b1;<sub>c</sub>. For a single gas, the absorbance can be written in terms of the absorption cross-section &#x3c3;, the number density (or &#x201c;concentration&#x201d;) n, and the path length l through the layer as &#x3b1;<sub>c</sub>=&#x3c3;nl. Using (3) to substitute this into (2) gives</p><p id="p-0083" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>nl</mi>      <mo>&#x2248;</mo>      <mfrac>       <mrow>        <mi>&#x394;</mi>        <mo>&#x2062;</mo>        <mi>M</mi>       </mrow>       <mrow>        <msub>         <mi>&#x3c4;</mi>         <mi>j</mi>        </msub>        <mo>&#x2062;</mo>        <mi>&#x3c3;&#x394;</mi>        <mo>&#x2062;</mo>        <mi>L</mi>       </mrow>      </mfrac>     </mrow>     <mo>,</mo>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>4</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0084" num="0000">where the left hand side represents the quantity we want to know&#x2014;the concentration&#xd7;path length, or &#x201c;column density.&#x201d;</p><p id="p-0085" num="0079">In order to use (4), the approach taken in the existing literature is generally the following. First we either take &#x3c4;<sub>f</sub>=1; &#x3c4;<sub>b</sub>=1 or the operator provides independent estimates of the transmission spectra &#x3c4;<sub>f </sub>(&#x3bb;) and &#x3c4;<sub>b</sub>(&#x3bb;). The gas absorption cross-section spectrum &#x3c3;(&#x3bb;) is easily obtained from a spectral library. The remaining unknowns are T<sub>b</sub>, L<sub>s</sub>, and T<sub>c</sub>. The temperature of the gas cloud T<sub>c </sub>and the atmosphere behind it T<sub>b </sub>am often taken as being the same and estimated by the operator using an independent measurement of the air temperature. Finally, the source radiance L<sub>s </sub>is generally taken to be either a greybody (if the background is an opaque surface) or is estimated from radiative transfer modelling software, such as MODTRAN.</p><p id="p-0086" num="0080">2. General Approach for Autonomous Operation</p><p id="p-0087" num="0081">The computational approach proceeds as follows:</p><p id="p-0088" num="0082">1. Rather that attempting to estimate the absolute quantity of the gas present in a scene, we attempt to estimate the change in the gas, relative to either an initial time or to a running average. This allows for a simplification of the measurement model, so that many of the unknown quantities no longer need to be estimated.</p><p id="p-0089" num="0083">2. We have found that using a running average of the scene is important not only for gas detection (as in the step above) but also for discriminating moving objects (such as people, cars, birds, etc.) from potential gas clouds. Some care must be taken when calculating the running mean, however, in order to prevent gas clouds and moving objects from &#x201c;burning in&#x201d; their signal into the running mean.</p><p id="p-0090" num="0084">3. From the difference between the current frame's radiance spectrum to that of the running mean, we can calculate the absorption spectrum at each pixel. From the absorption spectrum, we can estimate the gas column density by either averaging the absorption over a few selected bands or by fitting the cross-section spectrum to the measured absorption value.</p><p id="p-0091" num="0085">4. if the distance to the gas cloud is known or can be estimated by the camera, then we can scale the detected gas column density (ppm&#xb7;m units) into absolute quantity units (kg). Summing over all pixels in the scene therefore gives an estimate of the total gas quantity (in kg) within the cloud at a given time.</p><p id="p-0092" num="0086">5. In order to estimate total emission, one cannot simply use the value obtained in the previous step (the total gas quantity at a single snapshot in time), since the same cloud can be obtained by either a slow leak into an environment with little wind, or a fast leak into an environment with strong wind conditions. Rather, total emission is better measured by first estimating the emission rate over a period of time, and then integrating over that time period to get the total gas emission.</p><p id="p-0093" num="0087">6. For the gas emission rate, we start by taking a running average of the total detected gas in a scene. We then use a heuristic method for estimating how much of the gas cloud in the previous frame we expect to have lost measurement sensitivity to, and add that value to the current frame's total gas volume. Finally, if we have knowledge of the wind direction and speed relative to the camera's pointing direction, then we can easily estimate how much gas is left in the field of view in the previous frame. This value is also added to the current frame's total gas volume. If we take this &#x201c;augmented&#x201d; estimate of the current frame's total gas volume, any changes in this value (if positive) indicate emission.</p><p id="p-0094" num="0088">7. If we monitor a gas cloud over a period of time and sum the emission rate over the monitor period, we have an estimate for the total gas quantity emitted.</p><p id="p-0095" num="0089">3. New Measurement Model</p><p id="p-0096" num="0090">As shown above, the conventional method uses a number of steps in which an operator must manually specify quantities in order for the computation to proceed. This type of method cannot be performed autonomously under conditions of changing weather, temperature, etc. It also makes the assumption that the source (if an opaque surface) is a greybody&#x2014;an assumption that we see violated in much of our own testing. We develop an alternative model that does not require these assumptions for the measurement to proceed. Rather than attempting to measure the absolute gas absorption spectrum &#x394;M(&#x3bb;), we instead measure only the change in the spectrum, with respect to either an initial measurement, or with respect to a running average of the scene. This allows us to drop all of the background layer from the measurement model, so that the no-gas at-sensor radiance, with-gas at-sensor radiance, and their difference are now</p><p id="p-0097" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>M</i><sup>(0)</sup><i>=L</i><sub>f</sub>+&#x3c4;<sub>f</sub><i>L</i><sub>s </sub><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0098" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>M</i><sup>(1)</sup><i>=L</i><sub>f</sub>+&#x3c4;<sub>f</sub>(1-&#x3c4;<sub>c</sub>)<i>B</i>(<i>T</i><sub>c</sub>)+<i>t</i><sub>f</sub><i>t</i><sub>c</sub><i>L</i><sub>s </sub><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0099" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x394;<i>M=M</i>(1)&#x2212;<i>M</i><sup>(0)</sup>=&#x3c4;<sub>f</sub>(1&#x2212;&#x3c4;<sub>c</sub>)[<i>B</i>(<i>T</i><sub>c</sub>)&#x2212;<i>L</i><sub>s</sub>],<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0100" num="0091">If we ignore the path absorption in the foreground (i.e. set &#x3c4;<sub>f</sub>=1), then the at-sensor radiance without gas is now equal to the source radiance (M<sup>(0)</sup>=L<sub>s</sub>), so that solving for the gas transmission gives</p><p id="p-0101" num="0000"><maths id="MATH-US-00003" num="00003"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mrow>       <mrow>        <mn>1</mn>        <mo>-</mo>        <msub>         <mi>&#x3c4;</mi>         <mi>c</mi>        </msub>       </mrow>       <mo>&#x2248;</mo>       <msub>        <mi>&#x3b1;</mi>        <mi>c</mi>       </msub>      </mrow>      <mo>=</mo>      <mfrac>       <mrow>        <msup>         <mi>M</mi>         <mrow>          <mo>(</mo>          <mn>1</mn>          <mo>)</mo>         </mrow>        </msup>        <mo>-</mo>        <msup>         <mi>M</mi>         <mrow>          <mo>(</mo>          <mn>0</mn>          <mo>)</mo>         </mrow>        </msup>       </mrow>       <mrow>        <mrow>         <mi>B</mi>         <mo>&#x2061;</mo>         <mo>(</mo>         <msub>          <mi>T</mi>          <mi>c</mi>         </msub>         <mo>)</mo>        </mrow>        <mo>-</mo>        <msup>         <mi>M</mi>         <mrow>          <mo>(</mo>          <mn>0</mn>          <mo>)</mo>         </mrow>        </msup>       </mrow>      </mfrac>     </mrow>     <mo>,</mo>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>5</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0102" num="0000">Here we can interpret the quantity M<sup>(0)</sup>(&#x3bb;) as being either the at-sensor radiance spectrum measured at an initial time, or as a running mean of the at-sensor radiance, so that what we choose to measure will be fluctuations about a mean value. Since gas clouds on this scale are dynamic and fast-moving phenomena, this method still produces excellent gas cloud detection, as we will show below. Finally, for estimation of the gas column density nl from measurements, we use</p><p id="p-0103" num="0000"><maths id="MATH-US-00004" num="00004"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>nl</mi>      <mo>=</mo>      <mfrac>       <mrow>        <msup>         <mi>M</mi>         <mrow>          <mo>(</mo>          <mn>1</mn>          <mo>)</mo>         </mrow>        </msup>        <mo>-</mo>        <msup>         <mi>M</mi>         <mrow>          <mo>(</mo>          <mn>0</mn>          <mo>)</mo>         </mrow>        </msup>       </mrow>       <mrow>        <mi>&#x3c3;</mi>        <mo>[</mo>        <mrow>         <mrow>          <mi>B</mi>          <mo>&#x2061;</mo>          <mo>(</mo>          <msub>           <mi>T</mi>           <mi>c</mi>          </msub>          <mo>)</mo>         </mrow>         <mo>-</mo>         <msup>          <mi>M</mi>          <mrow>           <mo>(</mo>           <mn>0</mn>           <mo>)</mo>          </mrow>         </msup>        </mrow>        <mo>]</mo>       </mrow>      </mfrac>     </mrow>     <mo>,</mo>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>6</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0104" num="0092">4. Calculating a Running Average of a Scene</p><p id="p-0105" num="0093">Experimentally, we have found that using a running average of the scene spectral distribution (M(x, y, &#x3bb;, t), provides much better results than using the scene spectral distribution at an initial time M(x, y, &#x3bb;, t<sub>0</sub>). From here on, we will refer to the scene spectral distribution as the scene &#x201c;datacube.&#x201d; Calculating the running average comprises several steps, as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, which is a flowchart of an example method <b>400</b> for calculating a running average of the scene spectral distribution:</p><p id="p-0106" num="0094">1. First, as illustrated in block <b>410</b>, the system needs to acquire an initial estimate of the scene reference datacube M<sup>(0)</sup>(x, y, &#x3bb;). For this we simply collect a sequence of datacubes of the scene and average them together. Until a reliable initial estimate is formed, the system cannot attempt gas cloud detection, since the results are no more reliable than the reference datacube is.</p><p id="p-0107" num="0095">2. After the initial estimate of M<sup>(0)</sup>(x, y, &#x3bb;) is formed, as illustrated in block <b>420</b>, we can add subsequent datacubes into our running average using the well-known updating algorithm (given here in pseudocode):</p><p id="p-0108" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x394;<i>x=x</i><sub>i</sub><i>&#x2212;<o ostyle="single">x</o></i>&#x2003;&#x2003;(a)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0109" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>x+=&#x394;x/i</i>&#x2003;&#x2003;(b)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0110" num="0000">where x is the quantity to average (such as the scene datacube), x<sub>mean </sub>is its running mean, and i is the frame counter (i.e. if the current frame is the 15th, then i=14, since the counter starts at zero.</p><p id="p-0111" num="0096">3. While the simple running average improves detection, over what can be achieved with a simple initial estimate that is not updated, problems can occur as a result of moving objects in the scene. For example, if a car drives through the scene, the radiance of the car is likely to be quite different from that of the radiance of the scene behind the car (and now being blocked by the car). Since the car will soon exit that region of the scene, leaving the original background exposed once more, it will degrade performance of the system if it were allowed to change the reference datacube. Since moving objects generally cause large signal changes, a powerful method to mitigate their effect on the reference datacube is to allow the moving average update to occur only if a given pixel experiences a small signal change and not a large one. Empirically, what we have found to work best is to place a threshold on the estimated SNR of a pixel: if a pixel's estimated SNR value is above 2.5, do not use the current frame to update that pixel in the reference datacube. If a pixel's estimated SNR is below 2.5, then go ahead and allow it to be updated.</p><p id="p-0112" num="0097">4. This method therefore uses a running estimate of the SNR, which is calculated as follows. Along with the algorithm that continuously updates the reference datacube with each new frame, we also calculate and continuously update an estimated variance with each new frame, as illustrated in blocks <b>430</b> and <b>440</b>. The above algorithm therefore becomes</p><p id="p-0113" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x394;<i>x=x</i><sub>i</sub><i>&#x2212;x</i>&#x2003;&#x2003;(a)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0114" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>x</i><sub>mean</sub><i>+&#x394;x/i</i>&#x2003;&#x2003;(b)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0115" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>m</i><sub>2</sub><i>+=&#x394;x</i>*(<i>x&#x2212;x</i><sub>mean</sub>)&#x2003;&#x2003;(c)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0116" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>var<sub>x</sub><i>=m</i><sub>2</sub>/(<i>i</i>&#x2212;1)&#x2003;&#x2003;(d)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0117" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>SNR</i><sub>x</sub>=(<i>x&#x2212;x</i><sub>mean</sub>)/&#x221a;{square root over (var<sub>x</sub>)}&#x2003;&#x2003;(e)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0118" num="0000">where var<sub>x </sub>is the estimated variance for the pixel at the current frame, &#x221a;{square root over (var)}, is the corresponding estimated standard deviation. Thus, as illustrated in block <b>450</b>, for any pixel whose SNR value is above the threshold (we typically use 2.5), the previous frame's value at that pixel is the one used in the &#x201c;updated&#x201d; reference datacube. For any pixel whose SNR is at or below the threshold, the above algorithm applies the update (i.e. it uses the new value for x<sub>mean </sub>rather than the previous frame's x<sub>mean </sub>for the pixel's value in the reference datacube).</p><p id="p-0119" num="0098">5. Calculating the Absorption. Gas Column Density, and Absolute Quantity of Gas</p><p id="p-0120" num="0099"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart of an example method <b>500</b> for detecting a gas cloud. For passive absorption spectroscopy, measuring the absorption by a gas requires knowing the quantity of light reaching the sensor both with and without the gas. For autonomous measurement, since we can never ensure that we have available a measurement in which no gas is present, we instead attempt to measure only the changes in the gas concentration, rather than the absolute concentration values, as illustrated in block <b>510</b>. Thus, the absorption spectrum at a pixel is given by (5), where M<sup>(0) </sup>represents the reference datacube, M<sup>(1) </sup>is the datacube obtained in the current frame. B(T<sub>c</sub>) is the Planck blackbody spectrum at temperature T<sub>c</sub>, and T<sub>c </sub>is the gas cloud temperature. As shown in block <b>520</b>, from the absorption spectrum at a pixel, we can perform spectral matching to estimate the probability that the absorption indicates presence of a gas. If the gas detection algorithm indicates that there is a high probability of there being a gas cloud at a given pixel, then we can go to the next step and calculate the gas column density at the pixel.</p><p id="p-0121" num="0100">As shown in block <b>530</b>, there are two basic techniques for estimating the gas column density. The first technique is to average the absorption over one or more spectral bands in which the gas absorption cross-section is significant (i.e. not close to zero). A second technique is to use a statistical method to fit the gas cross-section spectrum to the measured absorption spectrum. Both of these techniques work, with the former requiring less computation, and the latter being more accurate but also more in need of regularization. Once we have the column density (in, say, units of ppm&#xb7;m), the next step is to convert the measurement units to an absolute quantity. In order to convert a measurement in ppm&#xb7;m units to one in ppm&#xb7;m<sup>3 </sup>units, we need only calculate the effective area of a pixel projected onto the gas cloud.</p><p id="p-0122" num="0101"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a gas cloud imager detector pixel projected to the location of the gas cloud. Using the known dimensions of the detector array pixels (p<sub>x</sub>, p<sub>y</sub>), the focal length f of the objective lens, and the gas cloud distance z, we can calculate the projected dimension of the pixel at the plane of the gas cloud as</p><p id="p-0123" num="0000"><maths id="MATH-US-00005" num="00005"><math overflow="scroll"> <mrow>  <mfrac>   <msub>    <mi>P</mi>    <mi>x</mi>   </msub>   <mi>z</mi>  </mfrac>  <mo>=</mo>  <mrow>   <mrow>    <mfrac>     <msub>      <mi>p</mi>      <mi>x</mi>     </msub>     <mi>f</mi>    </mfrac>    <mo>&#x2192;</mo>    <msub>     <mi>P</mi>     <mi>x</mi>    </msub>   </mrow>   <mo>=</mo>   <mrow>    <msub>     <mi>p</mi>     <mi>x</mi>    </msub>    <mo>&#x2062;</mo>    <mrow>     <mi>zlf</mi>     <mo>.</mo>    </mrow>   </mrow>  </mrow> </mrow></math></maths></p><p id="p-0124" num="0000">Since most detectors have p<sub>x</sub>=p<sub>y</sub>, we can write that the projected area of the pixel is therefore</p><p id="p-0125" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>A</i><sub>proj</sub>=(<i>p</i><sub>x</sub><i>z/f</i>)<sup>2</sup>&#x2003;&#x2003;(7)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0126" num="0102"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart of an example method <b>70</b>) for calculating the absolute quantity of gas present in a gas cloud. While the pixel dimension p<sub>x </sub>and f are known as a result of the hardware design, the gas cloud distance z varies and must be estimated. When setting up a gas cloud imaging camera at a facility, one of the early setup procedures is to measure the distances from the camera to the primary items to be monitored. These items are often things such as a collection of tightly interwound pipes, the wall of a gas container tank, the opening of a gas separator tank, etc. The important thing is that the general region in which potential leaks may occur is known a priori, and thus the distance to any gas leak can be estimated to reasonable accuracy by using that distance as measured during the system setup. As shown in block <b>710</b>, with distance z known, we can apply (7) to scale the measured gas column density to absolute units. As shown in block <b>720</b>, simple multiplication leads to units of ppm&#xb7;m<sup>3</sup>. But, as shown in block <b>730</b>, multiplying this result by the number of molecules per cubic meter in standard atmospheric temperature and pressure, and then dividing by 1&#xd7;10<sup>6 </sup>(because the units is parts per million), we now have a measurement in units of numbers of gas molecules. Since each gas has a known molecular weight, we can also convert &#x201c;number of gas molecules&#x201d; directly to kilograms, as shown in block <b>740</b>, or equivalently to an equivalent volume of pure gas at atmospheric pressure (e.g. units of in), as shown in block <b>750</b>.</p><p id="p-0127" num="0103">This calculation gives the absolute gas quantity at each pixel in the image, and if we sum over all pixels in the image we obtain the total volume of gas at one snapshot in time.</p><p id="p-0128" num="0104">While the distance to the gas cloud can be estimated by assuming that the cloud will occur near the equipment being monitored. There are other techniques which are also available. One can use multiple infrared cameras viewing the same scene to triangulate on the gas cloud. Another method is the use a laser tracker (or &#x201c;laser range finder&#x201d;) tuned to a wavelength that is absorbed by the gas.</p><p id="p-0129" num="0105">6. Emission Rate Quantization</p><p id="p-0130" num="0106"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart of an example method <b>800</b> for quantizing the emission rate of a gas leak. As shown in block <b>810</b>, the method begins with an estimate of the quantity of gas present at each pixel of the image (which can be determined using the method illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>). At block <b>820</b>, the total volume of gas present in the image can be calculated by summing over all pixels in the frame.</p><p id="p-0131" num="0107">From the previous step, we know the total amount of gas in the scene during each measurement frame. As shown in block <b>840</b>, from a safety perspective, this measure of the gas volume, and an estimate of its concentration (not column density) are the two most important measures. The former determines the scale of the danger, and the latter determines whether the cloud is capable of igniting. If we are using the gas cloud imager not for safety monitoring but for environmental monitoring or for gas leak detection and repair (LDAR), then the primary quantities of interest are emission rate (units of kg/hr, for example) and total emission (units of kg). At block <b>830</b>, the emission rate and/or total emission of the gas leak can be calculated. Estimating these quantities requires some additional work.</p><p id="p-0132" num="0108">Researchers have attempted to estimate gas emission rates from gas cloud imaging, but all of the currently published work of which we are aware use supervised methods. That is, they use optical flow techniques to estimate the speed of each tiny parcel of gas within the gas cloud, draw a line or a box somewhere in the image such that the leak source is on one side, and all of the gas passes across the line or box. Not only is this method unsatisfactory from the point of view that it incorporates user supervision or some kind of prior knowledge about the location of the leak source, but optical flow techniques are also computationally intensive and require special care when working with noisy data. We develop a new method that is computationally easy, requires no supervision or knowledge of the leak source location, and can work with surprisingly noisy data.</p><p id="p-0133" num="0109">As shown at block <b>850</b>, with low-noise data, one could measure the amount of gas present in each frame of a video sequence, and then say that any increase in the gas indicates an emission source. For noisy data, one can use temporal smoothing and look for changes in the temporally smoothed value for total gas present in the scene. Thus, in principle, one need only monitor the steady increase in total gas from the beginning to end of the monitoring period. However, two competing effects work against this. If there is wind in the scene, or if the gas is moving rapidly, then part of the gas cloud may exit the field of view and reduce the total amount of gas in the scene. If this were to happen while a leak were constantly emitting new gas, then the two would compete for each other and the net effect would be no change in total gas observed, and zero estimated gas emission. Thus, we will need to compensate for any gas that leaves the field of view. Secondly, another effect is that some of the gas will drop below the sensitivity limit of the camera. If, for example, there were a momentary leak that created a stationary gas cloud within the scene. As the gas cloud slowly dissipates by mixing with the ambient air, losing concentration but growing in size, the gas cloud imager will lose sensitivity to the lower concentrations and will see a steady decline in the total gas, even though none of it has left the field of view. Clearly, we need to compensate for this effect as well in order to get accurate estimates of gas emission rates.</p><p id="p-0134" num="0110"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart of an example method <b>900</b> for compensating an estimate of emission rate based on gas exiting the field of view of the camera and absorption dropping below sensitivity limits of the camera. As shown at block <b>910</b>. A temporally-smoothed moving average of the total gas in the scene is efficiently implemented using an exponentially-weighted mean average (EWMA). Using the EWMA the measured gas volume as our best estimate of the true gas volume in the scene, at block <b>940</b>, we next add our estimate of the amount of gas lost by exiting the field of view (calculated at block <b>920</b>), and also the amount of gas lost due to dropping below our sensitivity limit (calculated at block <b>930</b>). From this &#x201c;augmented&#x201d; estimate of the current frame's total gas volume, we estimate the emission rate as the amount by which this gas volume has increased since the last frame, as shown at block <b>950</b>. If this (augmented) gas volume has decreased, then we say that the estimated emission is zero. (That is, the estimate is biased to accept only positive values.)</p><p id="p-0135" num="0111">Estimating the amount of gas that we expect to lose detection to by the time of the next frame is determined using a simple heuristic model that is adjusted to match experimental data. In the model, we first calculate the range of gas column density values detected within the gas cloud. A threshold is set to be some fraction of the range of ppm&#xb7;m values above the minimum detected value. Thus, if the maximum ppm&#xb7;m value detected within a gas cloud were calculated as 5000 ppm&#xb7;m, and the lowest value were 100 ppm&#xb7;m, then the range would be 4900 ppm&#xb7;m. If we set a threshold as 20% of the range, then the threshold in units of ppm&#xb7;m would be (ppm&#xb7;m threshold)=(minimum ppm&#xb7;m)+0.2 (ppm&#xb7;m range)=100+0.2(4900)=1080.</p><p id="p-0136" num="0000">Next we locate the set of all &#x201c;edge pixels&#x201d; in the gas cloud&#x2014;all pixels that lie no more than two pixels away from a pixel without gas detected. We expect that some fraction of edge pixels whose column density lies below the calculated threshold will drop below the detection limit of the camera. Using experimental data, we determined that the best value for our camera was 0.25. (As we will see, the final result is usually not very sensitive to the values chosen for use in this heuristic model.) So, say we find all of the edge pixels that lie below the threshold, sum up all of their ppm&#xb7;m values, and multiply the result by 0.25. This is the total amount of gas we expect to lose sensitivity to by the next frame. Store that value at block <b>930</b>. When we try to estimate the total gas present in a frame, we will augment it using this value.</p><p id="p-0137" num="0112">The next step attempts to estimate how much gas will exit the field of view. This either requires knowing the wind speed and direction in terms of the gas cloud imager's optical axis, or using video analytics to estimate the speed of motion of the gas. <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a top view of an example scene measured by a gas cloud imager camera, with the gas cloud at a distance z (left). <figref idref="DRAWINGS">FIG. <b>10</b></figref> also illustrates the example scene as viewed from the gas cloud imager camera itself (right). The hatched region at the right hand side of the image indicates the area in which any detected gas is expected to leave the field of view by the next frame (due to being pushed out by wind).</p><p id="p-0138" num="0113">If the wind speed and direction are known (for example with an external wind gauge that communicates with the camera), then we can calculate the projection onto the image and estimate the amount that the gas will move in terms of pixels in the image. For example, say we find a result that the wind motion will cause the gas to move 2 pixels in the horizontal direction and 0 pixels in the vertical. At block <b>920</b>, in order to estimate the amount of gas we expect to lose detection to by the time of the next frame, we need only sum the total amount of gas that lies within the 2-pixel band next to the edge of the image. (This is the hatched region shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>.) For normal situations, the wind speed is such that the number of pixels of motion before the next frame (when imaging at 15 Hz) is less than 2 pixels, so that interpolation of the pixel values is important.</p><p id="p-0139" num="0114">The method <b>900</b> above provides an estimate of the gas emission rate, for each frame within the video sequence, as shown at block <b>960</b>. If we sum over all of the images within the sequence then we obtain the total gas emission volume, as shown at block <b>970</b>, providing the second of the quantities of interest for environmental and leak detection and repair (LDAR) monitoring.</p><p id="p-0140" num="0115">C. Gas Cloud Imager Software Interface</p><p id="p-0141" num="0116"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows an example of the gas cloud imager (GCI) live viewer graphical user interface. The interface includes a manual record button toward the lower right. Recorded videos can be uploaded to a webserver for easy viewing from a web browser or downloading to a local computer. The interface also includes a countdown bar that informs the operator when the camera is ready to move. To extend time at a particular field of view, an operator can click on the &#x201c;Extend Time&#x201d; button to the right of the countdown bar. The system automatically resumes its scan after the extended time period is finished. If the operator wants to scan before the extend time has finished he/she can click on the resume scan button.</p><p id="p-0142" num="0117"><figref idref="DRAWINGS">FIG. <b>12</b></figref> shows an example of the mosaic viewer interface. The GCI's mosaic viewer can be located right next to the live viewer on a separate monitor and displays the entire monitored area, as shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>. Operators can move the camera to any location in the monitored area by simply clicking on that portion of the mosaic viewer. The camera will stay at that field until the countdown bar has finished (typically 60 secs) and then resumes its automatic motion path. When an alarm has occurred in a particular field a red box will highlight in the mosaic viewer until it has returned to that field and not had an alarm event.</p><p id="p-0143" num="0118"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows an example of the graphical user interface with an alarm condition. In the event of an alarm, several notifications occur in the software interface as shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>. First, the banner at the top of the Live Viewer changes to RED. Second, the detected gas is shown in the Gases Detected List. Third, a concentration color bar in ppm-m units is displayed to the right of the viewer. And fourth, the gas cloud is false colored in terms of its concentration and shown in real time on the live viewer screen. Behind the scenes, an email is also sent out to all users with a link to view the gas release from the web server.</p><p id="p-0144" num="0119"><figref idref="DRAWINGS">FIG. <b>14</b></figref> shows an example of an alarm thresholds settings window. At any time an operator can view the alarm thresholds for each gas being monitored by clicking on the settings button in the lower left corner of the live viewer, as shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>. To adjust the thresholds an authorized user can login to the dialog window and adjust the thresholds from the same dialog window.</p><p id="p-0145" num="0120">D. Additional Embodiment of Gas Leak Quantification with a Gas Cloud (Video-Rate Infrared) Imager</p><p id="p-0146" num="0121">The gas cloud imager (GCI) system uses low-resolution spectroscopy to achieve higher SNR than available with high-resolution spectroscopy. While this has the disadvantage of making the system less capable of discriminating among different spectra, it also has the important advantage that it is less sensitive to saturation. That is, in high-resolution spectroscopy, the sharp absorption/emission features of gases will tend to saturate (i.e. e<sup>&#x2212;&#x3b1;</sup>&#x2260;&#x3b1; for absorption coefficient &#x3b1;) even on smaller gas clouds. With low-resolution spectra, however, saturation of these features tends to have little effect on the overall intensity across a measured spectral channel because the sharp features tend to be too small to dominate the signal. As a result, one can often ignore saturation effects entirely when working with low-resolution spectra.</p><p id="p-0147" num="0122">1. Introduction</p><p id="p-0148" num="0123">There is a real need to develop an algorithm oriented towards real-time autonomous operation. In brief, various spectral infrared gas detection algorithms may operate roughly as follows. The algorithm monitors the pixel in the scene and looks for spectral radiance changes. Changes that correspond closely to spectral features of a known gas are classified as a detection, and quantification of the pixel's gas column density follows. Summing and scaling all detected pixels within an image provides an estimate of the total cloud volume, so that tracking the total gas volume over a sequence of frames allows for emissions monitoring. Thus, one can think of a certain hierarchy to the measurement sequence. The primary task is simple detection&#x2014;the most important thing is to determine whether a gas cloud is present, what gas it is made of, and where it is. The secondary task is concentration estimation and quantification&#x2014;we want to know how much gas is present and what hazards the detected gas poses. The tertiary task is to monitor the gas overtime and form an emission rate estimate.</p><p id="p-0149" num="0124">In the discussion below, we present the measurement model that the algorithm is based on and compare it with the similar model typically used in the existing literature. After providing practical details for implementation and quantification, we compare the results of lab and open-air outdoor experiments to known gas quantities to verify the accuracy of the method. Finally, we also provide examples of the algorithm operating on live data streams.</p><p id="p-0150" num="0125">2. Measurement Model</p><p id="p-0151" num="0126"><figref idref="DRAWINGS">FIG. <b>15</b></figref> shows the measurement geometry for a single pixel in a gas cloud imager. The camera line of sight views (1) the background infrared radiation through (2) a gas cloud layer and (3) a foreground atmospheric layer. The gas cloud measurement model is a two-layer radiative transfer system (<figref idref="DRAWINGS">FIG. <b>15</b></figref>), in which (1) spectral radiance is generated within a source region which can be either an opaque object such as the ground, or the atmosphere itself, such as when viewing the cloudless sky, or a combination of the two. (2) The source spectral radiance next traverses the gas cloud layer, and is either attenuated or increased by absorption or emission of gases located there. (3) Finally, the radiation passes through a final atmospheric layer before reaching the camera. This measurement model is simpler than the three-layer version often used in the literature, in which there is an additional background atmospheric layer between the gas and an opaque radiation source. The simpler model used here reflects the fact that the autonomous algorithm is agnostic to the spectrum of the background light, whether the atmospheric layer behind the gas is absorbing light from an opaque background source or is itself the source of radiation is information that is not used by the algorithm. Following the literature, we do model both the gas and the foreground layers as being homogeneous (uniform in temperature and gas concentration).</p><p id="p-0152" num="0127">In the discussion below, we use the following variable definitions<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0128">L<sub>f</sub>, L<sub>g</sub>, L<sub>b</sub>: radiances originating from foreground, gas, and background layers</li>        <li id="ul0004-0002" num="0129">M: at-sensor radiance</li>        <li id="ul0004-0003" num="0130">&#x3c4;<sub>f</sub>, &#x3c4;<sub>g</sub>: transmission of foreground and gas layers</li>        <li id="ul0004-0004" num="0131">T<sub>f</sub>, T<sub>g</sub>: temperatures of foreground and gas layers<br/>Thus, for a pixel in the scene, using the measurement model shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, we can write the radiative transfer equation of a ray along the line of sight to given at-sensor radiance M of</li>    </ul>    </li></ul></p><p id="p-0153" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>M=Lf+&#x3c4;</i><sub>f</sub>&#x3b5;<sub>g</sub><i>B</i>(<i>T</i><sub>g</sub>)+&#x3c4;<sub>f</sub><i>&#x3c4;g L</i><sub>b</sub>,<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0154" num="0000">where &#x3b5;<sub>g </sub>is the spectral emissivity of the gas. Note that all of these quantities have an implicit spectral dependence (i.e. M=M(&#x3bb;) etc.). Using Kirchoff's law and an assumption of local thermodynamic equilibrium, we can also make the substitution &#x3b5;<sub>g</sub>=1&#x2212; T<sub>g</sub>. Since the pixels in the scene can be treated independently, we need not include the pixel's spatial location within the scene as a variable to model, and thus we can drop the (x, y) dependence from all of the variables and consider only a single pixel at a time.</p><p id="p-0155" num="0132">For passive absorption/emission spectroscopy, the absorption values given by taking a measurement spectrum and comparing it with a reference spectrum. In the case of gas cloud imaging, we therefore look for spectral radiance changes in the scene that may indicate absorption or emission by a gas cloud by comparing the current frame against a reference frame. The reference frame may be a frame obtained at a previous point in time, or a kind of running average. We write the measurement at the current frame of the video sequence as MO) and the radiance measurement of the reference frame as M<sup>(0)</sup>. Next, if the time difference between the current frame and the reference frame is short (e.g. not long enough to allow substantial changes in background radiance) then we can take the background and foreground quantities as constant, while the gas concentration itself varies on shorter timescales:</p><p id="p-0156" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>M</i><sup>(0)</sup><i>=L</i><sub>f</sub>+&#x3c4;<sub>f</sub>(1&#x2212;&#x3c4;<sub>s</sub><sup>(0)</sup>)<i>B</i>(<i>T</i><sub>K</sub>)+&#x3c4;<sub>f</sub>&#x3c4;<sub>g</sub><sup>(0)</sup><i>L</i><sub>b</sub>,<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0157" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>M</i><sup>(1)</sup><i>=L</i><sub>f</sub>+&#x3c4;<sub>f</sub>(1&#x2212;&#x3c4;<sub>g</sub><sup>(1)</sup>)<i>B</i>(<i>T</i><sub>g</sub>)+&#x3c4;<sub>f</sub>&#x3c4;<sub>g</sub><sup>(1)</sup><i>L</i><sub>b</sub>.<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0158" num="0133">Empirically, we rind that a useful timescale for this is on the order of 1 or 2 minutes, beyond which background radiance changes begin to have a significant influence on the estimated absorption value. Thus, the reference spectral radiance M<sup>(0) </sup>is reset approximately every 1-2 minutes to minimize error. (Section 3 below discusses methods for obtaining M<sup>(0)</sup>.) Taking the difference between the current and reference frames and simplifying leads to</p><p id="p-0159" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x394;<i>M=M</i><sup>(1)</sup><i>&#x2212;M</i><sup>(0)</sup>)=&#x2212;&#x3c4;<sub>j</sub>(&#x3c4;<sub>g</sub><sup>(1)</sup>&#x2212;&#x3c4;<sub>g</sub><sup>(0)</sup>)[<i>B</i>(<i>T</i><sub>g</sub>)&#x2212;<i>L</i><sub>b</sub>],&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0160" num="0000">where we use &#x394;L, which equals L<sub>b</sub>, for the &#x201c;radiance contrast&#x201d; between the gas cloud layer and the background. The sign of the radiance contrast indicates whether the cloud is observed in emission (&#x394;L&#x3e;0) or absorption (&#x394;L&#x3c;0). Next, we can correlate the measured spectral radiance change at the sensor &#x394;M(&#x3bb;) With the known spectral shape of various library gases, and if the correlation is high enough, and the spectral radiance changes large enough to warrant the change being a result of true signal and not noise, then the pixel is labeled as a &#x201c;detection&#x201d; and we can continue on to quantify the detected gas. As we will see below, a low signal strength can result from either a low gas concentration or a poor radiance contrast, and in the latter case it is difficult to obtain an accurate estimate of the concentration, so that one can either assume a concentration of 0 or use spatial and temporal correlations in the data to infer the concentration at a pixel given the value at its neighbors. (Note that spatial-temporal correlations among gas cloud pixels can extend across large regions of the image, and over many frames of data, so that more than just the nearest neighbors can be used to infer the concentration at an unknown pixel.)</p><p id="p-0161" num="0134"><figref idref="DRAWINGS">FIG. <b>16</b></figref> shows an example absorption spectrum measurement for propylene gas, showing the measured spectrum M(&#x3bb;). When the background sources a blackbody at T<sub>b</sub>=0&#xb0; C., the gas temperature is at T<sub>g</sub>=30&#xb0; C. and the gas column density produces a peak absorption value of A=0.95 (i.e. T=0.05). Note that the measurement spectrum shows a somewhat different shape than the cross-section spectrum due to the nonlinearity of the relation between absorption and cross-section (&#x3b1;=1&#x2212; e<sup>&#x3c3;nl</sup>).</p><p id="p-0162" num="0135">Once a gas cloud is detected, we can next go on to determine the gas quantity within the pixel. Equation 1 relates the transmission of the gas layer to the measured changes in radiance at the sensor. Using the Beer-Lambert-Bouguer law, the transmission is related to the concentration and size of the gas as</p><p id="p-0163" num="0000"><maths id="MATH-US-00006" num="00006"><math overflow="scroll"> <mrow>  <mrow>   <msub>    <mi>&#x3c4;</mi>    <mi>g</mi>   </msub>   <mo>=</mo>   <mrow>    <mrow>     <mi>exp</mi>     <mtext>  </mtext>     <mo>[</mo>     <mrow>      <mo>-</mo>      <mrow>       <mi>&#x3c3;</mi>       <mo>&#x2061;</mo>       <mo>(</mo>       <mrow>        <munderover>         <mo>&#x222b;</mo>         <mn>0</mn>         <mn>1</mn>        </munderover>        <mrow>         <mrow>          <mi>n</mi>          <mo>&#x2061;</mo>          <mo>(</mo>          <mi>z</mi>          <mo>)</mo>         </mrow>         <mo>&#x2062;</mo>         <mi>dz</mi>        </mrow>       </mrow>       <mo>)</mo>      </mrow>     </mrow>     <mo>]</mo>    </mrow>    <mo>&#x2248;</mo>    <mrow>     <mi>exp</mi>     <mo>&#x2062;</mo>     <mtext>  </mtext>     <mrow>      <mo>(</mo>      <mrow>       <mrow>        <mo>-</mo>        <mi>&#x3c3;</mi>       </mrow>       <mo>&#x2062;</mo>       <mi>nl</mi>      </mrow>      <mo>)</mo>     </mrow>    </mrow>   </mrow>  </mrow>  <mo>,</mo> </mrow></math></maths></p><p id="p-0164" num="0000">where &#x3c3; is the absorption cross-section, n the gas concentration (number density), and l the path length through the gas. The above approximation becomes valid when the gas layer is approximately homogeneous. Since the measurement involves an integral through the gas layer, it is difficult to separate the contribution of the gas concentration n from the cloud path length l using the radiance value alone, and so we group these two together into a single quantity&#x2014;the column density &#x3b6;=nl.</p><p id="p-0165" num="0136">When the gas concentration is low, the transmission can be modeled with a linearized version of the Beer-Lambert-Bouguer equation obtained by Taylor expansion:</p><p id="p-0166" num="0000"><maths id="MATH-US-00007" num="00007"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mn>1</mn>      <mo>-</mo>      <msub>       <mi>&#x3c4;</mi>       <mi>c</mi>      </msub>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <mn>1</mn>       <mo>-</mo>       <msup>        <mi>e</mi>        <mrow>         <mo>-</mo>         <mi>&#x3b1;</mi>        </mrow>       </msup>      </mrow>      <mo>=</mo>      <mrow>       <mrow>        <mi>&#x3b1;</mi>        <mo>+</mo>        <mrow>         <mfrac>          <mn>1</mn>          <mrow>           <mn>2</mn>           <mo>!</mo>          </mrow>         </mfrac>         <mo>&#x2062;</mo>         <msup>          <mi>&#x3b1;</mi>          <mn>2</mn>         </msup>        </mrow>        <mo>+</mo>        <mo>&#x2026;</mo>       </mrow>       <mo>&#x2248;</mo>       <mi>&#x3b1;</mi>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>2</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0167" num="0000">so that &#x3b1;=&#x3c3;&#x3b6;. From (1), the quantity we use during measurement is (&#x3c4;<sub>g</sub><sup>(l)</sup>- &#x3c4;<sub>g</sub><sup>(0)</sup>), which in the thin gas approximation gives</p><p id="p-0168" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x3c4;<sub>g</sub>&#x2212;&#x3c4;<sub>g</sub>&#x2248;&#x3b1;<sup>(0)</sup>&#x2212;&#x3b1;<sup>(1)</sup>=&#x3c3;&#x3b6;<sup>(0)</sup>&#x2212;&#x3c3;&#x3b6;<sup>(1)</sup>=&#x2212;&#x3c3;&#x394;&#x3b6;<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0169" num="0137">The change in gas column density &#x394;&#x3b6; is the quantity we are looking for. Substituting the above equation into (1), we obtain our estimate of the column density in terms of the measured radiance change and estimated background radiance:</p><p id="p-0170" num="0000"><maths id="MATH-US-00008" num="00008"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>&#x394;</mi>      <mo>&#x2062;</mo>      <mi>&#x3b6;</mi>     </mrow>     <mo>=</mo>     <mrow>      <mfrac>       <mrow>        <mrow>         <mo>-</mo>         <mi>&#x394;</mi>        </mrow>        <mo>&#x2062;</mo>        <mi>M</mi>       </mrow>       <mrow>        <mi>&#x3c3;</mi>        <mo>&#x2062;</mo>        <mrow>         <msub>          <mi>&#x3c4;</mi>          <mi>f</mi>         </msub>         <mo>[</mo>         <mrow>          <msub>           <mi>L</mi>           <mi>b</mi>          </msub>          <mo>-</mo>          <mrow>           <mi>B</mi>           <mo>&#x2061;</mo>           <mo>(</mo>           <msub>            <mi>T</mi>            <mi>g</mi>           </msub>           <mo>)</mo>          </mrow>         </mrow>         <mo>]</mo>        </mrow>       </mrow>      </mfrac>      <mo>.</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>3</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0171" num="0138">Finally, we can estimate the background radiance L<sub>b </sub>by substituting an hour measurement of the reference radiance value M<sup>(0)</sup>, so that the final equation becomes</p><p id="p-0172" num="0000"><maths id="MATH-US-00009" num="00009"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>&#x394;</mi>      <mo>&#x2062;</mo>      <mi>&#x3b6;</mi>     </mrow>     <mo>=</mo>     <mrow>      <mfrac>       <mrow>        <mrow>         <mo>-</mo>         <mi>&#x394;</mi>        </mrow>        <mo>&#x2062;</mo>        <mi>M</mi>       </mrow>       <mrow>        <msub>         <mi>&#x3c3;&#x3c4;</mi>         <mi>f</mi>        </msub>        <mo>[</mo>        <mrow>         <msup>          <mi>M</mi>          <mrow>           <mo>(</mo>           <mn>0</mn>           <mo>)</mo>          </mrow>         </msup>         <mo>-</mo>         <mrow>          <mi>B</mi>          <mo>&#x2061;</mo>          <mo>(</mo>          <msub>           <mi>T</mi>           <mi>g</mi>          </msub>          <mo>)</mo>         </mrow>        </mrow>        <mo>]</mo>       </mrow>      </mfrac>      <mo>.</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>4</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0173" num="0139">All of the variables on the right-hand side of the equation are quantities that we can estimate. The temperature of the gas T<sub>g </sub>is commonly assumed to be equal to that of the ambient air, under the assumption that the gas quickly entrains into the local air. For long wave infrared wavelengths (8-12 &#x3bc;m) systems, the important quantities that typically impact &#x3c4;<sub>f </sub>for path lengths less than 1 km are those of water vapor and dust. Ignoring the presence of spatially-dependent water vapor variation caused by steam, fog, or rain, the overall average concentration of water vapor in the ambient air can be estimated with a humidity sensor, so that together with an estimate of the distance to a gas cloud, one can then estimate &#x3c4;<sub>f</sub>. For shorter measurement distances, and for those guesses whose absorption features like completely outside the water band, &#x3c4;<sub>f </sub>can be taken as equal to 1. Finally, the value for a is determined from the type of gas detected, and can be obtained from a spectral library, such as the NIST Infrared Database.</p><p id="p-0174" num="0140">An assumption made in going from (3) to (4) is that the reference spectral radiance M<sup>(0)</sup>(&#x3bb;) Is an accurate representation of the background spectral radiance L<sub>b</sub>(&#x3bb;). Section 3 provides details on how this can be achieved in practice. A second assumption used is that the quantity of interest is the relative change in absorption and not the absolute absorption value. This makes the system agnostic to the spectral shape of the background source. For continuous monitoring situations in outdoor environments, this is an important feature, since many environmental effects&#x2014;rain, wind-induced motion of partially reflecting surfaces such as tree leaves and man-made signs&#x2014;create spectral features that can be confused with gas spectral features when evaluated with low-resolution spectroscopy. And low-resolution spectroscopy is, in turn, important for providing the camera with measurements of sufficient SNR to apply the gas detection algorithms. One can say that this approach prioritizes detection above that of quantification, so that it allows detection to take place under a wide set of possible conditions, but allows the estimated gas column density to have more error.</p><p id="p-0175" num="0141">Equation 4 provides the relationships between the change in gas column density &#x394;&#x3b6;, the measured radiance properties, and the known gas absorption spectrum &#x3c3;(&#x3bb;). However, there are two basic methods for implementing the estimates with an algorithm. The first technique is to average the measured absorption &#x394;M/[M<sup>(0)</sup>&#xb0;&#x2212;B(T<sub>g</sub>)] over one or more spectral bands in which the gas absorption cross-section is significant (i.e. not close to zero). If the other quantities on the right-hand side of (4) are likewise averaged across the same bands, then one obtains an estimate for &#x394;&#x3b6; with minimal computational effort. A second technique is to use a statistical method to set the gas cross-section spectrum to the measured absorption spectrum, which is more accurate but involves careful regularization in the presence of noisy data and (especially) background clutter.</p><p id="p-0176" num="0142">In the presence of multiple gas species, each of which is weakly absorbing, the overall absorption can be written as a linear sum over the component observances of each species. Thus, for N gases, in the thin gas and homogeneous layer approximations</p><p id="p-0177" num="0000"><maths id="MATH-US-00010" num="00010"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msub>      <mi>&#x3c4;</mi>      <mi>min</mi>     </msub>     <mo>=</mo>     <mrow>      <mrow>       <mi>exp</mi>       <mtext>  </mtext>       <mo>[</mo>       <mrow>        <mo>-</mo>        <mrow>         <munderover>          <mo>&#x2211;</mo>          <mrow>           <mi>i</mi>           <mo>=</mo>           <mn>1</mn>          </mrow>          <mi>N</mi>         </munderover>         <mtext> </mtext>         <mrow>          <msub>           <mi>&#x3c3;</mi>           <mi>i</mi>          </msub>          <mo>(</mo>          <mrow>           <munderover>            <mo>&#x222b;</mo>            <mn>0</mn>            <mi>l</mi>           </munderover>           <mrow>            <mrow>             <msub>              <mi>n</mi>              <mi>i</mi>             </msub>             <mo>(</mo>             <mi>z</mi>             <mo>)</mo>            </mrow>            <mo>&#x2062;</mo>            <mi>dz</mi>           </mrow>          </mrow>          <mo>)</mo>         </mrow>        </mrow>       </mrow>       <mo>]</mo>      </mrow>      <mo>&#x2248;</mo>      <mrow>       <munderover>        <mo>&#x2211;</mo>        <mrow>         <mi>i</mi>         <mo>=</mo>         <mn>1</mn>        </mrow>        <mi>N</mi>       </munderover>       <mtext> </mtext>       <mrow>        <msub>         <mi>&#x3c3;</mi>         <mi>i</mi>        </msub>        <mo>&#x2062;</mo>        <msub>         <mi>n</mi>         <mi>i</mi>        </msub>        <mo>&#x2062;</mo>        <mrow>         <mi>l</mi>         <mo>.</mo>        </mrow>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>5</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0178" num="0143">If the ratios of the various constituent species within the gas mixture remain constant, then the gas mixture can be characterized with single effective cross-section: &#x3c4;<sub>min</sub>=<o ostyle="single">&#x3c3;</o> &#xb7;<o ostyle="single">n</o>&#xb7;l. Thus, while one may use spectral unmixing and matched filtering algorithms to estimate the column densities of multiple gases simultaneously, we limit the current example to gases in which the mixture ratios are constant, and so can be modeled with a single effective absorption cross-section.</p><p id="p-0179" num="0144">So far all of the discussion has been in terms of absorption, that if the radiance emitted by the gas is brighter than that of the background, then we use emittance &#x3b5; in place of absorption 1&#x2212;&#x3c4;, but the equivalence between the two under Kirchoff's law means that the only change to the result is a change in sign. Thus, we can use the same expression for emission as for absorption, where &#x394;M will be positive in the case of observing the gas in absorption, and negative when observing in emission. An important case where observation of gas is commonly seen in emission is that of a sky background. Not only does the sky occupy a large portion of the field of view in many situations, but it also can have a large radiance contrast. A clear blue sky background can provide over 100 degrees of thermal contrast for most spectral bands across the 8-12 &#x3bc;m spectral range.</p><p id="p-0180" num="0145">3. Estimating the Reference Spectrum of a Scene Pixel</p><p id="p-0181" num="0146">The previous section left out a discussion of how to obtain a good model for the reference spectrum of a scene pixel. One simple way of doing this is to take the reference spectrum as that of a pixel at an initial point in time, M<sup>(0)</sup>(&#x3bb;)=M(&#x3bb;, t<sub>0</sub>), before the measurements themselves begin. For clarity, we show the explicit X-dependence here, and we will also write the reference at-sensor radiant spectrum as <o ostyle="single">M</o> rather than M<sup>(0) </sup>to make explicit the fact that we are using a temporal mean for the reference spectrum. In order to improve the SNR of <o ostyle="single">M</o>, one can of course take the mean spectrum from the first N+1 frames of data rather than just the frame: <o ostyle="single">M</o>(&#x3bb;)=(M(&#x3bb;, t))<sub>t=t</sub><sub><sub2>0</sub2></sub><sub>. . . </sub><sub><sup2>1</sup2></sub><sub>N-1</sub>. Taking this another step further, one can use a continuously updated running mean, and we have found empirically that this provides good results.</p><p id="p-0182" num="0147">However, while the running average improves detection by improving SNR, problems can occur. Any moving object (such as a car, or a bird) that enters the scene will likely have a radiance very different from that of the background, and so the algorithm might choose between either discarding the existing reference spectrum for the new, incorporating the change into the running mean update, or of maintaining the existing reference and ignoring the update in this case. Since such objects are moving, they produce rapid radiance changes across those pixels that they obscure, and so we find that in practice it is better to maintain the existing reference without performing an update in this case. The trick is to find a criterion by which to discriminate between objects that have moved in front of the background, thereby obscuring it in which case an update should not be performed&#x2014;and a change to the background itself&#x2014;in which case the update should be performed. Another problem that can occur with a running update is that if a gas cloud is present in a scene, then its spectral signature can quickly get &#x201c;burned into&#x201d; the reference spectrum, so that the system loses sensitivity. We also want a criterion to minimize this from occurring.</p><p id="p-0183" num="0148">The method we use is an SNR threshold based masking of the update procedure. That is, along with the reference spectrum of the pixel, we also calculate a running estimate of the variance of each spectral channel of the pixel. Taking the ratio of the running mean with the square root of the running variance estimate gives an SNR value at each spectral channel. The above algorithm therefore becomes, in pseudocode.<ul id="ul0005" list-style="none">    <li id="ul0005-0001" num="0000">    <ul id="ul0006" list-style="none">        <li id="ul0006-0001" num="0149">while new_data:</li>    </ul>    </li></ul></p><p id="p-0184" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>D=M</i>_<i>i&#x2212;Mbar </i><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0185" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Mbar+=D/i </i><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0186" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>B+=D</i>*(<i>M&#x2212;Mbar</i>)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0187" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>var_<i>M=V</i>/(<i>i&#x2212;</i>1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0188" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>SNR</i>_<i>M</i>=(<i>M</i>_<i>i&#x2212;Mbar</i>)/<i>sqrt</i>(var_<i>M</i>)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0189" num="0000">where <o ostyle="single">M</o> is written as Mbar. and the at-sensor radiance of the current frame as M_i, with i the frame counter. The results var_M and SNR_M are the variance and SNR of the at-sensor radiance. The parameters D and V are the difference value and statistical second moment, used to calculate the variance. For the first second of time in which data is collected, the SNR is calculated over the scene, allowing for all pixels to be updated. Following that, with each new frame we create a binary mask such that for any pixel spectral channel whose SNR value is above a selected threshold, the running update is not applied. This is the simple criterion by which the algorithm determines that a new object has entered the field of view and blocked the background source. For any pixel whose SNR is at or below the threshold, the algorithm applies the running update to <o ostyle="single">M</o> and var(M<sup>(0)</sup>.</p><p id="p-0190" num="0150">4. Estimating the Total Gas Quantity</p><p id="p-0191" num="0151">From Section 2, we can determine whether a gas cloud has been detected in its column density in ppm&#xb7;m (parts-per-million times meter), or similar units. For emissions monitoring and leak rate estimation, we take a few more steps, the first of which is to convert a gas cloud measurement to absolute quantity units. That is, if we know the effective area of a given pixel, together the column density of gas detected there, then by multiplying the two we obtain the total volume that the gas would occupy if it were a constant 1 ppm&#xb7;m column density. Dividing by 10<sup>6 </sup>gives the effective volume the pure gas would have at standard atmospheric temperature and pressure. The resulting units can be given as an equivalent volume of pure gas (e.g. L, m<sup>3</sup>, or ft<sup>3</sup>), or, by using the known density of molecules at the gas temperature and pressure, one can estimate the total number of molecules in the cloud. Or, more useful still, one can use the molecular mass of the gas to convert the number of molecules to a total mass of gas (g, kg, or lbs).</p><p id="p-0192" num="0152">The initial step of this calculation, estimating the projected area of a pixel at the cloud, is easily obtained by multiplying the known dimensions of the detector array pixels (p<sub>x</sub>, p<sub>y</sub>) by the image magnification, which is a function of the focal length f of the camera objective lens and the distance z to the gas cloud. <figref idref="DRAWINGS">FIG. <b>17</b></figref> shows a detector pixel projected to the location of the gas cloud. We can calculate the projected dimension of the pixel P<sub>x </sub>at the plane of the gas cloud as</p><p id="p-0193" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>P</i><sub>x</sub><i>=p</i><sub>x</sub><i>z/f. </i><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0194" num="0000">Since most detectors have p<sub>x</sub>=p<sub>y</sub>, we can write that the projected area of the pixel is therefore</p><p id="p-0195" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>A</i><sub>proj</sub>=(<i>p</i><sub>x</sub><i>z/f</i>)<sup>2</sup>&#x2003;&#x2003;(6)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0196" num="0153">While the pixel dimension p<sub>x </sub>and f are known as a result of the hardware design, the gas cloud distance z varies and can be estimated. When setting up a gas card imaging camera at a facility, one of the early set up procedures is to measure the distances from the camera to the primary items to be monitored. These items are often things such as a collection of tightly interwoven pipes, the wall of a gas container tank, the valves of a gas separator tank, etc. The important thing is that the general region in which potential leaks may occur is known a priori, and thus the distance to any gas leak can be estimated to reasonable accuracy by using that distance is measured during the system set up.</p><p id="p-0197" num="0154">While the distance to the gas cloud can be estimated by assuming that the gas cloud will occur near the equipment being monitored. There are other techniques which are also available. One can use multiple infrared cameras viewing the same scene to triangulate on the gas cloud. Another method is the use of a laser tracker (or &#x201c;laser rangefinder&#x201d;) tuned to a wavelength that is absorbed by the gas.</p><p id="p-0198" num="0155">With distance z known, we can apply (6) to scale the measured gas column density to units of equivalent volume of pure gas (L, m<sup>3</sup>, or ft<sup>3</sup>) simply by dividing by 10<sup>6</sup>. If the total number of gas molecules is the unit desired, then one can multiply the equivalent pure gas volume by the number of molecules per cubic meter at the ambient atmospheric temperature and pressure. Converting the total number of molecules to the total gas cloud mass then requires only multiplication by the gas' known molecular weight.</p><p id="p-0199" num="0156">5. Emission Rate Quantification</p><p id="p-0200" num="0157">Once we have an estimate of the total gas volume in a video frame, we can then start monitoring the gas volume over many frames in an attempt to estimate the rate at which the gas is being emitted from its source.</p><p id="p-0201" num="0158">What is needed is an autonomous algorithm that is amenable to rapid computation, and which can estimate this loss of sensitivity to the gas as it entrains into the local air. Our approach is to avoid optical flow computations everywhere except the edges of the field of view, and instead to monitor the measured gas volume together with a heuristic estimate of the sensitivity loss from frame to frame. In the vast majority of cases&#x2014;in which the gas leak source is more than a few pixels away from the edge of the field of view&#x2014;the sensitivity loss term dominates over the optical flow term. This means that the optical flow calculations can be entirely neglected when the amount of gas near the edge of the field of view is small in proportion to the total gas detected, and this helps to ease the computational burden.</p><p id="p-0202" num="0159">We start by measuring the total amount of gas present in each frame of a video sequence, and then say that any increase in the total gas measured indicates the presence of an emission source, with the increase since the previous frame giving the leak rate. In an ideal measurement environment, this would be all that is needed. The algorithm also monitors the edges of the field of view, so that if there is wind in the scene, or if the gas is moving rapidly due to buoyancy effects, then it can estimate the volume of gas exiting the camera's field of view and add this amount back into the leak rate. Similarly, if any gas enters the field of view from outside, then that portion of the gas volume is subtracted from the leak rate estimate. The final step is to develop a method for measuring sensitivity loss, and augment the leak rate estimate with the corresponding loss term.</p><p id="p-0203" num="0160">Estimating the gas volume decline from frame to frame due to sensitivity limits is determined using a simple heuristic model, developed as follows. The algorithm first calculates the range of gas column density values detected within the gas cloud. The threshold is set to be a fraction of the range of column density (ppm&#xb7;m) values above the minimum detected value. Thus, if the maximum column density value detected within a gas cloud is 5000 ppm&#xb7;m, and the lowest 100 ppm&#xb7;m, then the calculated range is 4900 ppm&#xb7;m. If we set a threshold as 20% of the range, then the threshold value in units of ppm&#xb7;m would be</p><p id="p-0204" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>(ppm&#xb7;m threshold)=(minimum&#x3b6;)+0.2(&#x3b6;range)=100+0.2(4900)=1080.<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0205" num="0161">Next we locate the set of all &#x201c;edge pixels&#x201d; in the gas cloud&#x2014;pixels in a cloud that are no more than two pixels away from a pixel where gas is not detected. We expect that some fraction of edge pixels whose column density lies below the calculated threshold will drop below the detection limit of the camera. Using a series of experimental data, we determined empirically that the best value for our camera was 0.25. Thus, the algorithm locates all of the edge pixels that lie below the threshold, sums up the total gas quantity within them, and multiplies the result by 0.25. This is the total amount of gas we expect to lose sensitivity to by the next frame&#x2014;the &#x201c;loss term&#x201d; that is used to augment the leak rate estimate.</p><p id="p-0206" num="0162">The next step attempts to estimate how much gas will exit the edges of the field of view between the current and the next frame, or how much has entered the field of view from outside it since the previous frame. This either involves knowing the wind speed and direction in terms of the GCI's optical axis, or using video analytics to estimate the speed of motion of the gas. If the wind speed and direction are known (for example with an external wind gauge), then it is a simple calculation to determine the speed in terms of pixels in the image, and estimate gas motion in that way. Wind, however, is generally not as well-behaved as this, so that a unidirectional model of motion will fail to capture the swirls and rapid changes of direction that occur in real life. Thus, estimating flow by modeling the gas motion can be useful for an accurate measure. Because flow estimation is known to be computationally intensive, an important means of reducing the size of the problem is to realize that we need only model flow within the outer boundaries of the image, and not the image as a whole.</p><p id="p-0207" num="0163">Once we add the estimated &#x201c;sensitivity loss&#x201d; and &#x201c;flow loss.&#x201d; and subtract the estimated &#x201c;inward flow&#x201d; from the current frame's total gas volume, we can track the changes in this &#x201c;augmented&#x201d; estimate of the volume from frame to frame. The estimated leak emission rate is the amount by which the augmented gas volume has increased since the last frame. If the augmented gas volume has decreased, then we say that the estimated emission is zero. (That is, the estimate is biased to accept only positive values.) Performing this procedure for every frame over an extended period of observation &#x2014;such as a 10-second period of a video sequence&#x2014;the algorithm can obtain the average emission rate over that period.</p><p id="p-0208" num="0164">The embodiments described throughout the attached specification, drawings, claims, and appendix have been described at a level of detail to allow one of ordinary skill in the art to make and use the devices, systems, methods, etc. described herein. A wide variety of variation is possible. Components, elements, and/or steps may be altered, added, removed, or rearranged. For example, method steps shown in the block diagrams can be practiced all together or in any sub-combination. Similarly, claim limitations can be separated and/or combined and included in any combination or sub-combination.</p><p id="p-0209" num="0165">The devices, systems, and methods described herein can advantageously be implemented using, for example, computer software, hardware, firmware, or any combination of software, hardware, and firmware. Software modules can comprise computer executable code for performing the functions described herein. In some embodiments, computer-executable code is executed by one or more general purpose computers (including desktop computers, notebook computers, tablet computers, smart phones, etc). However, a skilled artisan will appreciate, in light of this disclosure, that any module that can be implemented using software to be executed on a general purpose computer can also be implemented using a different combination of hardware, software, or firmware. For example, such a module can be implemented completely in hardware using a combination of integrated circuits. Alternatively or additionally, such a module can be implemented completely or partially using specialized computers designed to perform the particular functions described herein rather than by general purpose computers. In addition, where methods are described that are, or could be, at least in part carried out by computer software, it should be understood that such methods can be provided on non-transitory computer-readable media (e.g., optical disks such as CDs or DVDs, hard disk drives, flash memories, diskettes, or the like) that, when read by a computer or other processing device, cause it to carry out the method.</p><p id="p-0210" num="0166">A skilled artisan will also appreciate, in light of this disclosure, that multiple distributed computing devices can be substituted for any one computing device illustrated herein. In such distributed embodiments, the functions of the one computing device are distributed such that some functions are performed on each of the distributed computing devices.</p><p id="p-0211" num="0167">The devices described herein can exchange information with each other, or with other devices, via one or more communication channels. Such communication channels can be wired or wireless, and can include networks, such as a Local Area Network, a Wide Area Network, the Internet, etc.</p><p id="p-0212" num="0168">While certain embodiments have been explicitly described, other embodiments will become apparent to those of ordinary skill in the art based on this disclosure. Therefore, the scope of the invention is intended to be defined by reference to the claims and not simply with regard to the explicitly described embodiments.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230003640A1-20230105-M00001.NB"><img id="EMI-M00001" he="5.67mm" wi="76.20mm" file="US20230003640A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230003640A1-20230105-M00002.NB"><img id="EMI-M00002" he="6.35mm" wi="76.20mm" file="US20230003640A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00003" nb-file="US20230003640A1-20230105-M00003.NB"><img id="EMI-M00003" he="6.69mm" wi="76.20mm" file="US20230003640A1-20230105-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00004" nb-file="US20230003640A1-20230105-M00004.NB"><img id="EMI-M00004" he="7.37mm" wi="76.20mm" file="US20230003640A1-20230105-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00005" nb-file="US20230003640A1-20230105-M00005.NB"><img id="EMI-M00005" he="6.01mm" wi="76.20mm" file="US20230003640A1-20230105-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00006" nb-file="US20230003640A1-20230105-M00006.NB"><img id="EMI-M00006" he="9.91mm" wi="76.20mm" file="US20230003640A1-20230105-M00006.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00007" nb-file="US20230003640A1-20230105-M00007.NB"><img id="EMI-M00007" he="5.67mm" wi="76.20mm" file="US20230003640A1-20230105-M00007.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00008" nb-file="US20230003640A1-20230105-M00008.NB"><img id="EMI-M00008" he="6.35mm" wi="76.20mm" file="US20230003640A1-20230105-M00008.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00009" nb-file="US20230003640A1-20230105-M00009.NB"><img id="EMI-M00009" he="6.69mm" wi="76.20mm" file="US20230003640A1-20230105-M00009.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00010" nb-file="US20230003640A1-20230105-M00010.NB"><img id="EMI-M00010" he="9.91mm" wi="76.20mm" file="US20230003640A1-20230105-M00010.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An infrared (IR) imaging system for quantifying one or more parameters of a gas cloud, the IR imaging system comprising:<claim-text>an optical system comprising an optical focal plane array (FPA) unit, the optical system having components defining at least two optical channels thereof, the at least two optical channels being spatially and spectrally different from one another, each of the at least two optical channels positioned to transfer IR radiation incident on the optical system towards the optical FPA unit; and</claim-text><claim-text>a data-processing unit comprising one or more processors, the data-processing unit configured to acquire spectral optical data from <b>1</b>R radiation received at the optical FPA unit,</claim-text><claim-text>wherein the data-processing unit is configured to determine an estimate of loss caused by a portion of the gas cloud being blown out of a field of view of the optical system.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The IR imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the data-processing unit is configured to estimate a leak rate of the gas cloud based on the estimate of loss.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The IR imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the optical system and FPA unit together with the data-processing unit are associated with a detection sensitivity for detecting absorption.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The IR imaging system of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the data-processing unit is configured to determine a second estimate of loss caused by a portion of the gas cloud having absorption less than the detection sensitivity.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The JR imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>a communication subsystem for receiving optical data produced by a camera.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The IR imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the data-processing unit is configured to use noise as a criteria for determining whether to de-emphasize or exclude data for a particular frame.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The IR imaging system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the data-processing unit is configured to assess the noise based on variation in spectral data of the particular frame at a particular pixel.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The IR imaging system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the data-processing unit is configured to determine absorption spectra data at one or more given pixels of a given frame by determining a mathematical difference of the spectral data compared to a running average computed from prior frames.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The IR imaging system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein determining the mathematical difference comprises subtracting radiance spectral data for a pixel for a current frame and a running average of radiance spectrum for the pixel for prior frames.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The IR imaging system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising spectrally-multiplexed filters to compensate for the noise.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The IR imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said data-processing unit is configured to determine an estimate of atmospheric absorption between the gas cloud and the optical system.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The IR imaging system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the data-processing unit is configured to:<claim-text>receive a time series of data from a sensor, the time series of data being capable of quantifying an absorption spectrum of the gas cloud located within a field of view of the sensor, the time series of data comprising a frame for each time series, each frame comprising optical signal values corresponding to different locations within the field of view for each of a plurality of spectral wavelengths of electromagnetic radiation;</claim-text><claim-text>compare a subsequent frame of data with at least one prior frame of data in the time series;</claim-text><claim-text>analyze at least one property of gas cloud located within the field of view of the sensor based on a comparison between the subsequent frame of data and the at least one prior frame of data; and</claim-text><claim-text>output an indicator of the at least one property of the gas cloud to a user interface.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The IR imaging system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the data-processing unit is configured to determine absorption spectra data at one or more given pixels of a given frame by comparing spectral data with a statistical value based on the time series of data from prior frames.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The IR imaging system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the statistical value comprises a running average.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The IR imaging system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the data-processing unit is configured to continuously update a reference data cube based on the running average.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The IR imaging system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the data-processing unit is configured to:<claim-text>estimate a total amount of gas within the field of view of the sensor.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The IR imaging system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the data-processing unit is configured to:<claim-text>temporally smooth the estimate of the total amount of gas within the field of view; and</claim-text><claim-text>combine the temporally smoothed estimate of the total amount of gas within the field of view with an estimate of an amount of gas that has exited the field of view.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The IR imaging system of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the data-processing unit is configured to:<claim-text>combine the temporally smoothed estimate of the total amount of gas within the field of view of the sensor with an estimate of the amount of gas that has dropped below a sensitivity limit of the sensor.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The IR imaging system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the data-processing unit is configured to:<claim-text>output the indicator of an emission rate of the gas cloud to the user interface.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The IR imaging system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein a temporally-smoothed moving average of total gas in a scene is implemented using an exponentially-weighted mean average (EWMA).</claim-text></claim></claims></us-patent-application>
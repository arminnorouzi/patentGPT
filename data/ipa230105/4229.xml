<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004230A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004230</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17856278</doc-number><date>20220701</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>FR</country><doc-number>FR 21 07196</doc-number><date>20210702</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>246</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>017</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>011</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>248</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30196</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">ELECTRONIC DEVICE AND METHOD FOR DISPLAYING DATA ON A DISPLAY SCREEN, RELATED DISPLAY SYSTEM, VEHICLE AND COMPUTER PROGRAM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>FAURECIA INTERIEUR INDUSTRIE</orgname><address><city>Nanterre</city><country>FR</country></address></addressbook><residence><country>FR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>PEGORIER</last-name><first-name>Nicolas</first-name><address><city>PARMAIN</city><country>FR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>AYCOBERRY</last-name><first-name>Fabrice</first-name><address><city>SAINT GERMAIN EN LAYE</city><country>FR</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An electronic device for displaying data on a display screen, the device being connectable to the display screen and to an image sensor, the image sensor being operable to capture at least two images of a user. The electronic device includes: a module for displaying data, in particular icons, on the display screen; a module for detecting, via the at least two images taken, a movement towards the screen by at least one finger of the user, and then for calculating a direction of the movement; a module for determining, from a page displayed on the screen and depending on the direction of movement, an area of the screen corresponding to the direction; and a module for controlling an enlargement of the area when the at least one finger approaches the screen.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="109.73mm" wi="158.75mm" file="US20230004230A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="213.70mm" wi="148.34mm" orientation="landscape" file="US20230004230A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="199.31mm" wi="146.39mm" orientation="landscape" file="US20230004230A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="229.87mm" wi="158.92mm" orientation="landscape" file="US20230004230A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="194.99mm" wi="154.69mm" file="US20230004230A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a U.S. non-provisional application claiming the benefit of French Application No. 21 07196, filed on Jul. 2, 2021, which is incorporated herein by reference in its entirety.</p><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present invention relates to an electronic device for displaying data on a display screen, the device being adapted to be connected to the display screen and to an image sensor, the image sensor being adapted to take at least two images of a user of the display screen. The device includes a display module configured to display data, in particular icons, on the display screen.</p><p id="p-0004" num="0003">The invention also relates to an electronic data display system, the system comprising a display screen, an image sensor adapted to take at least two images of a user of the display screen, and such an electronic device for displaying data on the display screen.</p><p id="p-0005" num="0004">The invention also relates to a vehicle, in particular a motor vehicle, comprising such an electronic system for displaying data.</p><p id="p-0006" num="0005">The invention also relates to a method for displaying data on a display screen, the method being implemented by such an electronic display device; and to a non-transitory computer-readable medium including a computer program comprising software instructions which, when executed by a computer, implement such a display method.</p><p id="p-0007" num="0006">The invention relates to the field of human-machine (or man-machine) interfaces, also known as HMI or MMI, and in particular to electronic data display systems for the user.</p><p id="p-0008" num="0007">The invention also relates to the field of vehicles, in particular automobiles, wherein the electronic display system described above is more particularly configured to be carried on board a vehicle, such as a motor vehicle, and the user then typically being the driver of the vehicle.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0009" num="0008">EP 2 474 885 A1 provides an information display device including a screen with a capacitive touch screen function, wherein a sensor measures a capacitance change of the screen, and then provides the measured capacitance change and positional information of the capacitance change to a controller which then determines whether or not a finger is in proximity to the screen based on the capacitance change provided by the sensor. If it is determined that the finger is in the vicinity of the screen, the on-screen coordinates corresponding to the position of the finger are determined on the basis of the positional information provided by the measurement sensor, and an area displayed on the screen centered on these determined coordinates is then enlarged so as to facilitate selection of the object under the finger, this enlargement being maintained for as long as the finger is detected as being in the vicinity of the screen.</p><p id="p-0010" num="0009">U.S. Pat. No. 9,772,757 B2 also describes a display device with a touch screen, in which an area displayed on the screen is enlarged when the presence of a user's finger near the screen is detected. This document also teaches how to change the magnified area when the user's finger moves parallel to the touch screen.</p><p id="p-0011" num="0010">However, with such displays, the interaction between the user and the display is not always optimal, and a tactile selection of an icon displayed on the screen is sometimes tricky, resulting in a cognitive load for the user.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0012" num="0011">One purpose of the invention is then to provide an electronic device, and an associated method, for displaying data on a display screen, allowing the selection of an icon displayed on the screen to be facilitated, and thus reducing the cognitive load for the user, which makes it possible to reduce the risks of an accident in a vehicle when the electronic display device is on board this vehicle and the user is then typically the driver of said vehicle.</p><p id="p-0013" num="0012">To this end, the invention relates to an electronic device for displaying data on a display screen, the device being adapted to be connected to the display screen and to an image sensor, the image sensor being adapted to capture at least two images of a user of the display screen, the device comprising:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0013">a display module configured to display the data, in particular icons, on the display screen;</li>        <li id="ul0002-0002" num="0014">a detection module configured to detect, via the at least two images taken, a movement towards said screen by at least one finger of the user, and then to calculate a direction of the movement;</li>        <li id="ul0002-0003" num="0015">a determination module configured to determine, from a page displayed on the screen and depending on the direction of movement, an area of the screen corresponding to said direction; and</li>        <li id="ul0002-0004" num="0016">a control module configured to control an enlargement of said area when said at least one finger approaches the screen.</li>    </ul>    </li></ul></p><p id="p-0014" num="0017">With this electronic display device, the detection module makes it possible, via the at least two images taken by the image sensor, to detect when the user is moving at least one of their fingers toward the display screen, and to detect in particular the movement of the at least one finger in the direction of the screen, and then to calculate the direction of said movement. The determination module is then used to determine an area displayed on the screen from the direction of movement calculated via the at least two captured images; and the control module is then used to modify the appearance of said area, in particular to enlarge said area, when said at least one finger approaches the screen, in order to facilitate the user's subsequent selection of an item included in that area, such as an icon.</p><p id="p-0015" num="0018">The skilled person will in particular understand that this detection of the movement of the at least one finger towards the screen, carried out on the basis of the at least two images taken by the image sensor, allows for early detection, compared to a detection carried out via a capacitive sensor with the display device of the state of the art.</p><p id="p-0016" num="0019">Preferably, movement detection is performed as soon as a distance between the at least one finger of the user and the display screen is less than a predefined detection threshold, this detection threshold being for example less than 10 cm, and preferably less than 5 cm.</p><p id="p-0017" num="0020">Even more preferably, the enlargement of the area pointed to by the at least one finger of the user, i.e. in the direction of movement of the at least one finger, is performed with increasing intensity as the distance between the at least one detected finger and the display screen decreases, thereby indicating to the user the area to which their finger is pointing, and this in an increasingly distinct manner as their finger approaches the screen. If this area does not correspond to what the user wishes to select, then the user can easily shift their finger laterally so that their finger points to another area, which will then result in an enlargement of that other area, corresponding to the new direction of movement of the at least one finger. The enlargement of said area is then progressive with an increasing amplification of said area enlargement as said at least one finger gets closer and closer to the screen, i.e. as the distance between the detected at least one finger and the display screen decreases.</p><p id="p-0018" num="0021">In other beneficial aspects of the invention, the electronic display device comprises one or more of the following features, taken in isolation or in any technically possible combination:<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0022">the detection module is configured to detect a distance between said at least one finger and said screen, and the control module is configured to control the enlargement of said area when said distance is below a predefined threshold;</li>        <li id="ul0004-0002" num="0023">the movement is a substantially rectilinear movement;</li>        <li id="ul0004-0003" num="0024">the detection module is configured to calculate the direction of movement from a tip of the at least one finger; the direction of movement preferably being calculated only from the tip of the at least one finger;</li>        <li id="ul0004-0004" num="0025">the control module is configured to control the enlargement of said area with increasing intensity as said at least one finger moves closer and closer to the screen;</li>        <li id="ul0004-0005" num="0026">the control module is configured to further control highlighting and/or colour modification of said area; and</li>        <li id="ul0004-0006" num="0027">the display screen is a touch screen, and the device further comprises an acquisition module configured to acquire a touch selection, from the user, of an icon displayed in said area; the acquisition module preferably being further configured to generate a signal to the user confirming the acquisition of the selection; and the acquisition confirmation signal being preferably further selected from the group consisting of: a vibratory signal, a visual signal and an audible signal.</li>    </ul>    </li></ul></p><p id="p-0019" num="0028">The invention also relates to an electronic data display system, the system comprising a display screen, an image sensor adapted to capture at least two images of a user of the display screen, and an electronic device for displaying data on the display screen, the electronic display device being as defined above, the electronic display device being connected to the display screen and the image sensor.</p><p id="p-0020" num="0029">In other beneficial aspects of the invention, the electronic display system comprises one or more of the following features, taken in isolation or in any technically possible combination:<ul id="ul0005" list-style="none">    <li id="ul0005-0001" num="0000">    <ul id="ul0006" list-style="none">        <li id="ul0006-0001" num="0030">the system is configured to be carried in a vehicle; the vehicle preferably being a motor vehicle; and</li>        <li id="ul0006-0002" num="0031">the user is a driver of the vehicle.</li>    </ul>    </li></ul></p><p id="p-0021" num="0032">The invention also relates to a vehicle, in particular a motor vehicle, comprising an electronic system for displaying data, the electronic display system being as defined above.</p><p id="p-0022" num="0033">The invention also relates to a method for displaying data on a display screen, the method being implemented by an electronic display device adapted to be connected to the display screen and to an image sensor, the image sensor being adapted to take at least two images of a user of the display screen, the method comprising:<ul id="ul0007" list-style="none">    <li id="ul0007-0001" num="0000">    <ul id="ul0008" list-style="none">        <li id="ul0008-0001" num="0034">displaying data, in particular icons, on the display screen;</li>        <li id="ul0008-0002" num="0035">detecting, via the at least two images taken, a movement towards said screen by at least one finger of the user, and then calculating a direction of the movement;</li>        <li id="ul0008-0003" num="0036">determining, from a page displayed on the screen and depending on the direction of movement, an area of the screen corresponding to said direction; and</li>        <li id="ul0008-0004" num="0037">controlling an enlargement of said area as said at least one finger approaches the screen.</li>    </ul>    </li></ul></p><p id="p-0023" num="0038">The invention also relates to a non-transitory computer-readable medium including a computer program comprising software instructions, which, when carried out by a computer, implement a display method as defined above.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0024" num="0039">These features and advantages of the invention will appear more clearly upon reading the following description, given solely as a non-limiting example, and made in reference to the attached drawings, in which:</p><p id="p-0025" num="0040"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic representation of a vehicle, in particular a motor vehicle, comprising an electronic system for displaying data according to an embodiment of the invention, the display system comprising a display screen, an image sensor of a user of the display screen, and an electronic device for displaying data on the display screen, said device being connected to the screen and to the image sensor;<ul id="ul0009" list-style="none">    <li id="ul0009-0001" num="0000">    <ul id="ul0010" list-style="none">        <li id="ul0010-0001" num="0041"><figref idref="DRAWINGS">FIG. <b>2</b></figref> represents a schematic perspective view of the interior of the vehicle of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, with the display screen facing a user, such as the driver of the vehicle, and the image sensor adapted to take at least two images of the user, in particular when they extend one of their hands towards the screen;</li>    </ul>    </li></ul></p><p id="p-0026" num="0042"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic representation of four interaction situations between the electronic display system of <figref idref="DRAWINGS">FIG. <b>1</b></figref> and a user's finger; and<ul id="ul0011" list-style="none">    <li id="ul0011-0001" num="0000">    <ul id="ul0012" list-style="none">        <li id="ul0012-0001" num="0043"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of a method according to an embodiment of the invention for displaying data on the display screen, the method being implemented by the electronic display device of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</li>    </ul>    </li></ul></p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0027" num="0044">In the following of the description, the phrase &#x201c;substantially equal to&#x201d; means being equal within 10%, and preferably within 5%.</p><p id="p-0028" num="0045">In <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>, a vehicle <b>10</b> comprises a passenger compartment <b>12</b>; and within the passenger compartment <b>12</b>, a seat <b>14</b> for a user <b>16</b>, such as a driver, and a steering wheel <b>18</b> for driving the vehicle, as is known per se.</p><p id="p-0029" num="0046">The vehicle <b>10</b> further comprises an electronic system <b>20</b> for displaying data to the user <b>16</b>, the display system <b>20</b> being adapted to be carried on board the vehicle <b>10</b>.</p><p id="p-0030" num="0047">The skilled person will understand that the vehicle <b>10</b> is broadly understood to be a vehicle that allows a driver, also called a pilot, and additionally one or more passengers, to travel. The vehicle <b>10</b> is then typically selected from the group consisting of: a motor vehicle, such as a car, bus or truck; a rail vehicle, such as a train or tram; a marine vehicle, such as a ship; and an aviation vehicle, such as an aircraft.</p><p id="p-0031" num="0048">The electronic display system <b>20</b> comprises a display screen <b>22</b>, an image sensor <b>24</b> adapted to capture at least two images of the user <b>16</b>, and an electronic device <b>30</b> for displaying data on the display screen <b>22</b>, the display device <b>30</b> being connected to the screen <b>22</b> and the image sensor <b>24</b>.</p><p id="p-0032" num="0049">The display screen <b>22</b> is adapted to display data to the user <b>16</b>, in particular icons <b>32</b>, visible in <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>. The display screen <b>22</b> is typically a touch screen, and is then configured to detect a tactile touch against the screen from the user <b>16</b>, and typically a touch by at least one finger <b>34</b> of the user against a portion of the surface of the screen <b>22</b>, such as a portion of the surface where a respective icon <b>32</b> is displayed. The touch screen is for example a capacitive touch screen or a resistive touch screen, as known per se.</p><p id="p-0033" num="0050">The image sensor <b>24</b> is known per se, and is configured to acquire at least two images of the user <b>16</b>, in particular of one of the user's hands <b>36</b>, and typically at least one of the user's fingers <b>34</b>, in particular when the user <b>16</b> extends their hand <b>36</b> towards the display screen <b>22</b>.</p><p id="p-0034" num="0051">The image sensor <b>24</b> is, for example, positioned facing the screen <b>22</b>, so that at least two images of the hand <b>36</b> can be taken when it is in the vicinity of the screen <b>22</b>, and so that it is furthermore possible to determine via the at least two images taken, which is the direction of the approach movement of the hand <b>36</b>, and in particular of the at least one finger <b>34</b>, towards the screen <b>22</b>.</p><p id="p-0035" num="0052">The image sensor <b>24</b> is typically positioned substantially parallel to the screen <b>22</b>, an axis of sight of the image sensor <b>24</b> being substantially perpendicular to the surface of the screen <b>22</b>, the axis of sight itself being substantially perpendicular to an active surface, not shown, of the image sensor <b>24</b>.</p><p id="p-0036" num="0053">The electronic display device <b>30</b>, shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, is configured to display data on the display screen <b>22</b> to the user <b>16</b>. The electronic display device <b>30</b> comprises a module <b>40</b> for displaying data, in particular icons <b>32</b>, on the display screen <b>22</b>.</p><p id="p-0037" num="0054">The electronic display device <b>30</b> further comprises a module <b>42</b> for detecting, via the at least two images taken by the image sensor <b>24</b>, a movement towards the screen <b>22</b> of the at least one finger <b>34</b> of the user, the detection module <b>42</b> being then configured to calculate a direction M of the detected movement; a module <b>44</b> for determining an area <b>48</b>, from a page <b>46</b> displayed on the screen <b>22</b> and based on the direction M of the movement, the area <b>48</b> typically including at least one icon <b>32</b>; and a module <b>50</b> for controlling a change in appearance of the determined area <b>48</b>.</p><p id="p-0038" num="0055">As an optional addition, the electronic display device <b>30</b> further comprises a module <b>52</b> for acquiring a tactile selection by the user <b>16</b> of an icon <b>32</b> displayed on the screen <b>22</b>.</p><p id="p-0039" num="0056">In the example shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the electronic display device <b>30</b> comprises an information processing unit <b>60</b> formed for example by a memory <b>62</b> and a processor <b>64</b> associated with the memory <b>62</b>.</p><p id="p-0040" num="0057">In the example shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the display module <b>40</b>, the detection module <b>42</b>, the determination module <b>44</b> and the control module <b>50</b>, and in the optional addition the acquisition module <b>52</b>, are each in the form of software, or a software brick, which can be executed by the processor <b>64</b>. The memory <b>62</b> of the display device <b>30</b> is then able to store software for displaying data on the display screen <b>22</b>; software for detecting, via the at least two images taken by the sensor <b>24</b>, the movement towards the screen <b>22</b> of the respective at least one finger <b>34</b> of the user, and then for calculating the direction M of said movement; software for determining, from among the page <b>46</b> displayed on the screen <b>22</b> and as a function of the direction M of said movement, a respective area <b>48</b>; and software for controlling a change in the appearance of the determined area <b>48</b>. As an optional addition, the memory <b>62</b> of the display device <b>30</b> is able to store software for acquiring a tactile selection by the user <b>16</b> of a respective icon <b>32</b> displayed on the display screen <b>22</b>. The processor <b>64</b> is then able to execute each one of the display software, the detection software, the determination software and the control software, and in the optional addition the acquisition software.</p><p id="p-0041" num="0058">In a variant not shown, the display module <b>40</b>, the detection module <b>42</b>, the determination module <b>44</b> and the control module <b>50</b>, and in the optional addition the acquisition module <b>52</b>, are each in the form of a programmable logical component, such as a FPGA (Field-Programmable Gate Array), or as a dedicated integrated circuit, such as an ASIC (Application-Specific Integrated Circuit).</p><p id="p-0042" num="0059">When the display device <b>30</b> is in the form of one or more software, that is to say in the form of a computer program, also called a computer program product, it is also capable of being stored on a computer-readable medium, not shown. The computer-readable medium is, for example, a medium that can store electronic instructions and be coupled with a bus from a computer system. For example, the readable medium is an optical disk, magneto-optical disk, ROM memory, RAM memory, any type of non-volatile memory (for example EPROM, EEPROM, FLASH, NVRAM), magnetic card or optical card. The readable medium in such a case stores a computer program comprising software instructions.</p><p id="p-0043" num="0060">It will be understood by the skilled person that an icon, referred to by the general reference <b>32</b>, is any graphical object intended to be displayed on the display screen <b>22</b>, and in particular any graphical object capable of being tactile-selected by the user <b>16</b>. In the examples of <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>, the icons <b>32</b> are&#x2014;schematically and for the sake of simplification of the drawing&#x2014;shown with a rectangular shape, and the skilled person will of course understand that each icon <b>32</b> may have any geometric shape, not necessarily rectangular.</p><p id="p-0044" num="0061">The display module <b>40</b> is configured to display data, in particular icons <b>32</b>, on the display screen <b>22</b>. The display module <b>40</b> is known per se, and is capable of generating the graphical information corresponding to the data to be displayed, and then transmitting it to the display screen <b>22</b> for display on said screen.</p><p id="p-0045" num="0062">The detection module <b>42</b> is configured to detect, via the at least two images of the user <b>16</b>, and in particular of their hand <b>34</b>, taken by the image sensor <b>24</b>, a movement towards the screen <b>22</b> of the hand <b>36</b> of the user <b>16</b>, and in particular of the at least one of their fingers <b>34</b>. The detection module <b>42</b> is then configured to calculate the direction M of the movement of the hand <b>36</b>, and in particular of the at least one finger <b>34</b>, towards the display screen <b>22</b>. The direction M of movement is typically calculated from an end of the at least one finger <b>34</b>, i.e. a tip of the at least one finger <b>34</b>; said direction M of movement preferably being calculated only from the end of the at least one finger <b>34</b>. Said direction M of movement is then calculated solely from the trajectory of the tip of the or each finger <b>34</b>, this trajectory being determined from said at least two images taken by the image sensor <b>24</b>.</p><p id="p-0046" num="0063">As an optional addition, the detection module <b>42</b> is configured to detect movement of the at least one finger <b>34</b> of the user <b>16</b> toward the display <b>22</b> only if a distance between the finger <b>34</b> and the display <b>22</b> is less than a predefined detection threshold. The detection threshold is, for example, less than or equal to ten centimeters, or less than or equal to five centimeters, the detection threshold typically being an integer of centimeters less than or equal to the above values.</p><p id="p-0047" num="0064">The detection module <b>42</b> is for example configured to calculate the distance between at least one finger <b>34</b> and a reference point based on a number of pixels between the at least one finger <b>34</b> and the reference point in a corresponding image, wherein a predefined distance for two known points is associated or correlated with a predefined number of pixels as a reference or matching relationship.</p><p id="p-0048" num="0065">As an optional addition, at least three reference points are taken into account for the calculation of said distance to make the analysis, according to the respective numbers of pixels for the same object, such as the same finger <b>34</b>, with respect to the different reference points, a 3-dimensional coordinate system is created. According to this optional addition, the detection module <b>42</b> is then configured to determine, via said 3-dimensional coordinate system, the direction of movement of the object, in particular of the at least one finger <b>34</b>, relative to the reference, typically associated with the screen <b>22</b>. According to this optional addition, the detection module <b>42</b> is also configured to determine, via said 3-dimensional coordinate system, the distance of the object, in particular of the at least one finger <b>34</b>, from the reference, typically associated with the screen <b>22</b>.</p><p id="p-0049" num="0066">The determination module <b>44</b> is configured to determine a respective area <b>48</b> of the page <b>46</b> displayed on the display screen <b>22</b>, the area <b>48</b> typically including at least one icon <b>32</b>, based on the direction M of the movement previously calculated by the detection module <b>42</b>.</p><p id="p-0050" num="0067">The movement is, for example, a substantially rectilinear movement. In particular, the skilled person will observe that the movement is distinct from conventional hand or multi-finger gestures, such as a pinch-to-zoom gesture, a swipe gesture, etc.</p><p id="p-0051" num="0068">The control module <b>50</b> is then configured to control a change in an appearance of the area <b>48</b> when the at least one finger <b>34</b> approaches the screen <b>22</b>.</p><p id="p-0052" num="0069">The change in appearance of the area <b>48</b> is typically an enlargement of the area <b>48</b>.</p><p id="p-0053" num="0070">As an optional addition, the modification of the appearance of the area <b>48</b> further comprises a highlighting and/or a color modification of said area <b>48</b>.</p><p id="p-0054" num="0071">The change in appearance of the area <b>48</b> is then typically selected from the group consisting of: an enlargement of the area <b>48</b>, a highlighting of the area <b>48</b>, and a color change to the area <b>48</b>.</p><p id="p-0055" num="0072">In the example shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the control module <b>50</b> is configured to control a change in the size, and preferably an enlargement, of the area <b>48</b>, and typically of the at least one icon <b>32</b> included in the area <b>48</b>. The enlargement of the area <b>48</b> is preferably a homothety with respect to a center of the area <b>48</b>. In other words, the size of the area <b>48</b> is increased in all directions. Alternatively, only one dimension of the area <b>48</b> in a single direction is increased.</p><p id="p-0056" num="0073">In addition, the enlargement of each icon <b>32</b> is preferably a homothety with respect to a center of said icon <b>32</b>. In other words, the size of the icon <b>32</b> is increased in all directions. Alternatively, only one dimension of the icon <b>32</b> in a single direction is increased.</p><p id="p-0057" num="0074">As an optional addition, the control module <b>50</b> is configured to control said change in appearance with increasing intensity upon a decrease in a distance between the detected finger <b>34</b> and the display screen <b>22</b>. In other words, according to this optional addition, the control module <b>50</b> is configured to control the change in appearance with increasing intensity as the distance between the finger <b>34</b> and the display <b>22</b> decreases.</p><p id="p-0058" num="0075">According to this optional addition, the skilled person will understand that when the appearance modification is an enlargement, the intensity corresponds to an enlargement ratio, i.e. a ratio between the post-enlargement and pre-enlargement dimensions of the icon <b>32</b>. When the appearance change is a highlight, the intensity corresponds to a highlight level, or light intensity. Where the change in appearance is a color change, the intensity corresponds, for example, to a color tone, with higher intensities typically associated with bright colors, and lower intensities with pastel colors.</p><p id="p-0059" num="0076">As a further optional addition, the control module <b>50</b> is configured to control the change in appearance with a greater intensity for an icon <b>32</b> located near the center of the defined area <b>48</b> than for an icon located away from said center and thus closer to a peripheral edge of said defined area <b>48</b>.</p><p id="p-0060" num="0077">According to this optional addition, the control module <b>50</b> is then configured to control the change in appearance with a greater intensity for an icon <b>32</b> directly facing the at least one detected finger <b>34</b>, i.e. along a pointing direction P of said finger <b>34</b>, than for icons <b>32</b> on either side of said icon <b>32</b> targeted by the finger <b>34</b>. The icons <b>32</b> on either side of said icon <b>32</b> targeted by the finger <b>34</b>, while included within the specified area <b>48</b>, also have a modified appearance relative to the icons <b>32</b> outside said area <b>48</b>.</p><p id="p-0061" num="0078">As a further optional addition, the control module <b>50</b> is configured to control said change in appearance temporarily, for example for a predefined period of time. The predefined time is for example between one tenth of a second and one second.</p><p id="p-0062" num="0079">Alternatively, the control module <b>50</b> is configured to control said change in appearance as long as a distance between the detected finger <b>34</b> and the display screen <b>22</b> is less than a predefined hold threshold. The hold threshold is, for example, less than or equal to ten centimeters, or less than or equal to five centimeters, the hold threshold typically being equal to an integer of centimeters less than or equal to the above values.</p><p id="p-0063" num="0080">As an optional addition, the acquisition module <b>52</b> is configured to acquire a tactile selection of a respective icon <b>32</b> displayed on the screen <b>22</b>, in particular an icon <b>32</b> whose appearance is changed via the control module <b>50</b>, the tactile selection, typically via a tactile touch against the screen <b>22</b>, having been made by the user <b>16</b>, in particular following said appearance change.</p><p id="p-0064" num="0081">As an optional addition, the acquisition module <b>52</b> is configured to, following acquisition of said tactile selection, generate an acquisition confirmation signal to the user <b>16</b>. The acquisition confirmation signal is, for example, a vibratory signal, such as a haptic signal or a mechanical vibration; a visual signal; or a sound signal. The confirmation signal then informs the user <b>16</b> that their tactile selection has been acquired and thus taken into account by the electronic display device <b>30</b>.</p><p id="p-0065" num="0082">The operation of the electronic display system <b>20</b>, and in particular of the electronic display device <b>30</b>, will now be described with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref> showing a flow chart of the method of displaying data on the display screen <b>22</b> to the driver <b>16</b>.</p><p id="p-0066" num="0083">In an initial and recurring step <b>100</b>, the display device <b>30</b> displays the data, in particular icons <b>32</b>, on the display screen <b>22</b> via its display module <b>40</b>. As is known per se, in this display step <b>100</b>, the display module <b>40</b> generates graphical information corresponding to said data and transmits it to the display screen <b>22</b> for display.</p><p id="p-0067" num="0084">When the user <b>16</b> makes an approaching movement towards the display screen <b>22</b>, in particular with one of their hands <b>36</b>, and in particular with one of their fingers <b>34</b>, the display device <b>30</b> then detects, in the next step <b>110</b> and via its detection module <b>42</b>, this movement of the user <b>16</b> towards the display screen <b>22</b>, this detection being carried out on the basis of the at least two images acquired by the image sensor <b>24</b>.</p><p id="p-0068" num="0085">As an optional addition, the detection module <b>42</b> detects the movement of the at least one finger <b>34</b> of the user <b>16</b> toward the display <b>22</b> only if the distance between the finger <b>34</b> and the display <b>22</b> is less than the predefined detection threshold. The skilled person will then understand that the distance between the finger <b>34</b> and the screen <b>22</b> is more precisely the distance between the end of the finger <b>34</b>, i.e. the tip of the finger <b>34</b>, and the screen <b>22</b>.</p><p id="p-0069" num="0086">In this step <b>110</b>, the detection module <b>42</b> then calculates the direction M of this movement, also from the at least two images taken by the image sensor(s) <b>24</b>. The direction M of movement is typically calculated from the end of the at least one finger <b>34</b>, i.e. the tip of the at least one finger <b>34</b>; said direction M of movement preferably being calculated only from the end of the at least one finger <b>34</b>. Said direction M of movement is then calculated solely from the trajectory of the tip of the or each finger <b>34</b>, this trajectory being determined from said at least two images taken by the image sensor <b>24</b>.</p><p id="p-0070" num="0087">The detection module <b>42</b> calculates, for example, the distance between at least one finger <b>34</b> and a respective reference point, based on a number of pixels between the at least one finger <b>34</b> and the reference point in a corresponding image.</p><p id="p-0071" num="0088">As an optional addition, at least three reference points are taken into account for the calculation of said distance to make the analysis, according to the respective numbers of pixels for the same object, such as the same finger <b>34</b>, with respect to the different reference points, a 3-dimensional coordinate system is created. According to this optional addition, the detection module <b>42</b> then determines, via said 3-dimensional coordinate system, the direction of movement of the object, in particular of the at least one finger <b>34</b>, and the distance of the object, in particular of the at least one finger <b>34</b>, from the reference, typically associated with the screen <b>22</b>.</p><p id="p-0072" num="0089">After calculating the direction M, the display device <b>30</b> proceeds to the next step <b>120</b>, in which it determines, via its determination module <b>44</b>, the area <b>48</b> based on the direction M of the movement of the at least one finger <b>34</b> towards the screen <b>22</b>, said area <b>48</b> typically including at least one icon <b>32</b>. The area <b>48</b> determined is, for example, an area centered on the intersection between the direction M of movement and the surface of the display screen <b>22</b>.</p><p id="p-0073" num="0090">Following the determination step <b>120</b>, the display device <b>30</b> controls, via its control module <b>50</b>, a change in appearance of the area <b>48</b> determined in the previous determination step <b>120</b>. The appearance modification is typically an enlargement of the area <b>48</b>, and optionally a highlighting and/or color modification of the area <b>48</b>.</p><p id="p-0074" num="0091">In this control step <b>130</b>, the change in appearance is preferably controlled with increasing intensity as the distance between the display screen <b>22</b> and the user's hand <b>36</b>, in particular their finger <b>34</b>, decreases.</p><p id="p-0075" num="0092">Even more preferably, this change in appearance is performed with a higher intensity for the icon <b>32</b> that is closest to the center of the area <b>48</b>, determined in the previous determination step <b>120</b>.</p><p id="p-0076" num="0093">In this control step <b>130</b>, the controlled change in appearance is for example temporary, such change in appearance typically being controlled as long as the distance between the display screen <b>22</b> and the detected finger <b>34</b>, in particular the end of that finger <b>34</b> that is closest to the display screen <b>22</b>, is less than the predefined hold threshold, described above. Alternatively, this change in appearance is temporary by being controlled for the predefined period of time described above.</p><p id="p-0077" num="0094">After the control step <b>130</b>, if the user <b>16</b> has made a tactile selection of a respective icon <b>32</b> displayed on the display screen <b>22</b>, in particular an icon <b>32</b> whose appearance is changed as a result of the control step <b>130</b>, then the display device <b>30</b> proceeds to the next step <b>140</b> in which it acquires, via its acquisition module <b>52</b>, said tactile selection.</p><p id="p-0078" num="0095">In addition, during this acquisition step <b>140</b>, the acquisition module <b>52</b> also generates an acquisition confirmation signal for the user <b>16</b>, in order to inform them that their tactile selection of the icon <b>32</b> has been taken into account by the display device <b>30</b>. This acquisition confirmation signal is, for example, a vibratory signal, such as a haptic signal or a mechanical vibration; a visual signal; or a sound signal.</p><p id="p-0079" num="0096">At the end of the acquisition step <b>40</b>, the display device <b>30</b> returns to the display step <b>100</b>.</p><p id="p-0080" num="0097">Alternatively, if at the end of the control step <b>130</b>, no tactile selection is made by the user <b>16</b>, then the display device <b>30</b> returns directly to the display step <b>100</b>.</p><p id="p-0081" num="0098">In the example of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, schematically representing four situations of interaction between the display system <b>20</b> and a finger <b>34</b> of the user <b>16</b>, namely a first situation S<b>1</b>, a second situation S<b>2</b>, a third situation S<b>3</b> and a fourth situation S<b>4</b>, the first situation S<b>1</b> corresponds to the case where the hand <b>36</b> of the user <b>16</b> is too far away from the display screen <b>22</b>, so that no approaching movement towards the screen <b>22</b> is detected by the detection module <b>42</b> during the detection step <b>110</b>.</p><p id="p-0082" num="0099">In the second situation S<b>2</b>, the user <b>16</b> moves their hand <b>36</b> closer to the display screen <b>22</b> in the direction M. In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the final position of the hand <b>36</b> is shown as a solid line, and the initial position of the hand <b>36</b> is shown as a dashed line. In this second situation S<b>2</b>, the detection module <b>42</b> detects this approaching movement of the hand <b>36</b>, and then calculates the direction M of this movement. The determination module <b>44</b> then determines that the area <b>48</b>, calculated according to the direction M and corresponding to this approach movement, is the one with the two icons <b>32</b> at the bottom left of the page <b>46</b>. Then, the control module <b>50</b> controls a change in appearance of the two icons <b>32</b> included in the determined area <b>48</b>, the change in appearance illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> for the second situation S<b>2</b> being an enlargement of said icons <b>32</b>. In addition, the change in appearance is performed with greater intensity for the icon <b>32</b> near the lower-left corner of the page <b>46</b> than for the other icon included in the area <b>48</b>, this lower-left icon <b>32</b> being the one closest to the center of the area <b>48</b>, in particular to a point of intersection between the direction M of movement and the surface of the display screen <b>22</b>.</p><p id="p-0083" num="0100">In the third situation S<b>3</b>, the user <b>16</b> then performs a lateral movement with their hand <b>36</b> along the direction M which is then substantially parallel to the display screen <b>22</b>. In this third situation S<b>3</b>, the detection module <b>42</b> detects that the hand <b>36</b> is still close to the screen <b>22</b>, and then calculates the direction M of the movement performed by the hand <b>36</b>, in particular by the finger <b>34</b>. The determination module <b>44</b> then determines a new area <b>48</b> according to the direction M of the movement. In the example shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the determination module <b>44</b> determines that in the third situation S<b>3</b> the direction M of the movement is substantially parallel to the screen <b>22</b> and is lateral, so that the newly determined area <b>48</b> is laterally offset, here to the right, from the area <b>48</b> determined in the second situation S<b>2</b>. The control module <b>50</b> then controls a change in appearance of the three icons <b>32</b> included in the area <b>48</b> determined in this third situation S<b>3</b>. This change in appearance is preferably also carried out with a higher intensity for the icon <b>32</b> located in the center of the determined area <b>48</b>. In this third situation S<b>3</b>, the change in appearance is also an enlargement of the three icons <b>32</b> within the determined area <b>48</b>, and the enlargement is then greater for the icon <b>32</b> in the center of this area <b>48</b>.</p><p id="p-0084" num="0101">The fourth situation S<b>4</b> corresponds to the case where the user, after having shifted their hand <b>36</b> laterally to the left, brings it closer to the screen <b>22</b>, along the direction M, in order to carry out at the end of the movement a tactile selection of the icon <b>32</b> whose appearance has been modified the most. In this fourth situation S<b>4</b>, the detection module <b>42</b> then detects this additional approaching movement of the hand <b>36</b>, and in particular of the at least one finger <b>34</b>, towards the screen <b>22</b>; then calculates the direction M of said movement. The determination module <b>44</b> then determines, according to the direction M of the detected movement, the area <b>48</b> including at least one icon <b>32</b>, and in particular three icons <b>32</b> in the example of this <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The control module <b>50</b> then controls the change in appearance of the icon(s) <b>32</b> included in the determined area <b>48</b>. The change in appearance is preferably furthermore more intense as the distance between the screen <b>22</b> and the hand <b>36</b>, and in particular the finger <b>34</b>, decreases. In the example of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, and in the fourth situation S<b>4</b>, the dimensions of the icon(s) <b>32</b> included in the area <b>48</b> then increase as the user <b>16</b> moves their hand <b>36</b>, and in particular their finger <b>34</b>, closer to the display screen <b>22</b>.</p><p id="p-0085" num="0102">In this fourth situation S<b>4</b>, the user <b>16</b> also tactilely presses the icon <b>32</b> in the center of the area <b>48</b> at the end of their movement, and the acquisition module <b>52</b> then acquires the tactile selection of this icon <b>32</b>, made by the user <b>16</b>. The icon <b>32</b> selected by the user <b>16</b> is then typically the one whose appearance is modified, this modification of appearance making it possible to highlight this icon <b>32</b>, and to facilitate its selection by the user <b>16</b>, thus reducing the cognitive load for the user <b>16</b>.</p><p id="p-0086" num="0103">Thus, the display system <b>20</b>, and in particular the display device <b>30</b>, makes it possible to help the user <b>16</b> to identify and then more easily select the icon <b>32</b> corresponding to a function, or feature, that they wish to control, i.e. activate or launch.</p><p id="p-0087" num="0104">This further reduces the safety risk due to distraction of the user <b>16</b>, especially when the display system <b>20</b> is carried in the vehicle <b>10</b> and the user <b>16</b> is the driver of said vehicle <b>10</b>.</p><p id="p-0088" num="0105">With the display device <b>30</b>, the detection of the movement of the at least one finger <b>34</b> towards the screen <b>22</b> is carried out from the at least two images taken by the image sensor <b>24</b>, which allows for early detection, compared to that carried out via a capacitive sensor with the display device of the prior art.</p><p id="p-0089" num="0106">Preferably, the detection of the movement is carried out as soon as the distance between the user's finger <b>34</b> and the display screen <b>22</b> is less than the predefined detection threshold, this detection threshold being of the order of a few centimeters. The skilled person will then understand that the distance between the finger <b>34</b> and the screen <b>22</b> is more precisely the distance between the end of the finger <b>34</b>, i.e. the tip of the finger <b>34</b>, and the screen <b>22</b>.</p><p id="p-0090" num="0107">The direction M of movement is also preferably calculated from the end of the at least one finger <b>34</b>, i.e. the tip of the at least one finger <b>34</b>, and even more preferably only from the end of the at least one finger <b>34</b>. Said direction M of movement is then calculated solely from the trajectory of the tip of the or each finger <b>34</b>, this trajectory being determined from said at least two images taken by the image sensor <b>24</b>. Thus, the area <b>48</b> on the display <b>22</b> determined according to the direction M of the movement is much more reliable, as it is determined according to the trajectory of the fingertip.</p><p id="p-0091" num="0108">Even more preferably, the change in appearance of the area <b>48</b> pointed to by the finger <b>34</b> of the user <b>16</b>, i.e. the area <b>48</b> lying in the direction of movement of the at least one finger <b>34</b>, is effected with increasing intensity as the distance between the finger <b>34</b> and the screen <b>22</b> decreases, thereby providing the user <b>16</b> with an even better indication of the area <b>48</b> to which their finger <b>34</b> is pointing, which indication becomes increasingly distinct as the finger <b>34</b> approaches the screen <b>22</b>. If this area <b>48</b> does not correspond to what the user <b>16</b> wishes to select, then they can easily shift their finger <b>34</b> laterally so that it points to another area <b>48</b>, which will then cause a change in appearance of this other area <b>48</b>, corresponding to the new direction of movement of the at least one finger <b>34</b>.</p><p id="p-0092" num="0109">The display device <b>30</b> and the display method also make it possible to reduce the risk of an erroneous selection of an icon <b>32</b>, for example due to a deformation of the roadway on which the vehicle <b>10</b> is travelling at the time the user <b>16</b> selects the icon <b>32</b>. This reduction in the risk of mis-selection is particularly effective when the change in appearance is an enlargement of the icon <b>32</b>, especially as the change in appearance increases in intensity as the distance between the finger <b>34</b> and the display screen <b>22</b> decreases.</p><p id="p-0093" num="0110">It is thus conceived that the electronic display device <b>30</b> and the display method make it possible to facilitate the selection of an icon <b>32</b> displayed on the screen <b>22</b>, and thus to reduce the cognitive load for the user <b>16</b>, which limits the risks of an accident of the vehicle <b>10</b> when the electronic display device <b>30</b> is on board the vehicle <b>10</b> and the user <b>16</b> is typically the driver of said vehicle.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An electronic device for displaying data on a display screen, the device being adapted to be connected to the display screen and to an image sensor, the image sensor being adapted to capture at least two images of a user of the display screen, the device comprising:<claim-text>a display module configured to display the data on the display screen;</claim-text><claim-text>a detection module configured to detect, via the at least two images taken, a movement towards said screen by at least one finger of the user, and then to calculate a direction of the movement;</claim-text><claim-text>a determination module configured to determine, from a page displayed on the screen and depending on the direction of movement, an area of the screen corresponding to said direction; and</claim-text><claim-text>a control module configured to control an enlargement of said area when said at least one finger approaches the screen.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the detection module is configured to detect a distance between said at least one finger and said display, and the control module is configured to control the enlargement of said area when said distance is below a predefined threshold.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the movement is a substantially rectilinear movement.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the detection module is configured to calculate the direction of movement from a tip of the at least one finger.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The device according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the direction of movement is calculated only from the tip of the at least one finger.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the control module is configured to control the enlargement of said area with increasing intensity as said at least one finger moves closer and closer to the screen.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the control module is configured to further control highlighting and/or color modification of said area.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the display screen is a touch screen, and the device further comprises an acquisition module configured to acquire a touch selection, from the user, of an icon displayed in said area.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The device according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the acquisition module is further configured to generate a signal to the user confirming the acquisition of the selection.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The device according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the signal is selected from the group consisting of: a vibratory signal, a visual signal and an audible signal.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. An electronic data display system, the system comprising a display screen, an image sensor adapted to capture at least two images of a user of the display screen, and an device for displaying electronic data on the display screen, the electronic display device being according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, and the electronic display device being connected to the display screen and to the image sensor.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A vehicle comprising an electronic data display system, the electronic display system being according to <claim-ref idref="CLM-00011">claim 11</claim-ref>.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A method for displaying data on a display screen, the method being implemented by an electronic display device adapted to be connected to the display screen and to an image sensor, the image sensor being adapted to capture at least two images of a user of the display screen, the method comprising:<claim-text>displaying the data on the display screen;</claim-text><claim-text>detecting, via the at least two images taken, a movement towards said screen by at least one finger of the user, and then calculating a direction of the movement;</claim-text><claim-text>determining, among a page displayed on the screen and depending on the direction of the movement, an area of the screen corresponding to said direction;</claim-text><claim-text>controlling an enlargement of said area as said at least one finger approaches the screen.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A non-transitory computer-readable medium including a computer program comprising software instructions which, when executed by a computer, implement the method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>.</claim-text></claim></claims></us-patent-application>
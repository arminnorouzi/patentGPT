<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005458A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005458</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17940539</doc-number><date>20220908</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-046516</doc-number><date>20200317</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>10</class><subclass>H</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>H</subclass><main-group>1</main-group><subgroup>0008</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>H</subclass><main-group>2210</main-group><subgroup>091</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">Parameter Inference Method, Parameter Inference System, and Parameter Inference Program</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/010272</doc-number><date>20210315</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17940539</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Yamaha Corporation</orgname><address><city>Hamamatsu-shi</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MAEZAWA</last-name><first-name>Akira</first-name><address><city>Hamamatsu-shi</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>IGUCHI</last-name><first-name>Katsuhiro</first-name><address><city>Hamamatsu-shi</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A parameter inference method realized by a computer, includes obtaining target performance information indicating a performance of music using an electronic musical instrument; inferring assist information from the target performance information with use of a trained inference model generated through machine learning, the assist information being related to setting of a parameter of the electronic musical instrument that conforms to a tendency of the performance; and outputting the inferred assist information related to the setting of the parameter.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="107.95mm" wi="158.75mm" file="US20230005458A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="208.62mm" wi="154.52mm" orientation="landscape" file="US20230005458A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="148.08mm" wi="161.46mm" file="US20230005458A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="122.94mm" wi="160.78mm" file="US20230005458A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="137.16mm" wi="159.68mm" file="US20230005458A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="208.20mm" wi="156.21mm" orientation="landscape" file="US20230005458A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="209.47mm" wi="154.86mm" orientation="landscape" file="US20230005458A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="236.56mm" wi="123.36mm" file="US20230005458A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="210.99mm" wi="155.36mm" orientation="landscape" file="US20230005458A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="221.23mm" wi="159.94mm" file="US20230005458A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of International Application No. PCT/JP2021/010272, filed Mar. 15, 2021, which claims priority to Japanese Application No. 2020-046516, filed Mar. 17, 2020, the entire disclosures of each of which are herein expressly incorporated by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present invention relates to a parameter inference method, a parameter inference system, and a parameter inference program for obtaining parameters of an electronic musical instrument that correspond to performance information.</p><heading id="h-0003" level="1">BACKGROUND ART</heading><p id="p-0004" num="0003">A variety of electronic musical instruments, such as electronic pianos, electronic organs, and synthesizers, for instance, are used in various scenes. Electronic musical instruments are configured in such a manner that the values of parameters that define the responses to performance operations can be changed. Accordingly, a user of an electronic musical instrument can change the response of the electronic musical instrument to the same performance operation by adjusting the parameters of the electronic musical instrument.</p><p id="p-0005" num="0004">For example, Patent Literature 1 suggests a technique to change the conversion characteristic (a touch curve indicating the relationship between the operation speed and the sound volume), which is one type of parameters of electronic musical instruments, in accordance with the result of analysis of performance information corresponding to a performance operation.</p><heading id="h-0004" level="1">CITATION LIST</heading><heading id="h-0005" level="1">Patent Literature</heading><p id="p-0006" num="0005">Patent Literature 1: JP 2-137890A</p><heading id="h-0006" level="1">SUMMARY OF INVENTION</heading><heading id="h-0007" level="1">Technical Problem</heading><p id="p-0007" num="0006">With the technique suggested by Patent Literature 1, the touch curve can be adjusted in accordance with a predetermined algorithm. However, the types of parameters of electronic musical instruments are not limited to the touch curve, and come in a wide variety of types. Also, the values of parameters that conform to the performance tendency can vary with each user. With the conventional method, the algorithm is adjusted on a per-parameter basis and on a per-user basis, which is problematic in that it takes an effort to obtain the values of parameters that conform to the performance tendency.</p><p id="p-0008" num="0007">The present invention has been made in view of the aforementioned issue, and an object thereof is to provide a technique to alleviate the effort required to obtain the values of parameters of an electronic musical instrument that conform to the user's tendency in a performance.</p><heading id="h-0008" level="1">Solution to Problem</heading><p id="p-0009" num="0008">In order to achieve the aforementioned object, a parameter inference method realized by one or more computers, which pertains to one aspect of the present invention, includes processing for: obtaining target performance information indicating a performance of music using an electronic musical instrument; inferring assist information from the target performance information with use of a trained inference model generated through machine learning, the assist information being related to setting of a parameter of the electronic musical instrument that conforms to a tendency of the performance; and outputting the inferred assist information related to the setting of the parameter.</p><heading id="h-0009" level="1">Advantageous Effects of Invention</heading><p id="p-0010" num="0009">According to the present invention, the effort required to obtain the values of parameters of an electronic musical instrument that conform to the user's tendency in a performance can be alleviated.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0010" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows one example of a configuration of an information processing system according to a first embodiment;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows one example of a hardware configuration of an electronic musical instrument according to the first embodiment;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows one example of a hardware configuration of an information processing apparatus according to the first embodiment;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows one example of a hardware configuration of a server according to the first embodiment;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows one example of a software configuration of the information processing system according to the first embodiment;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a sequence diagram showing one example of a processing procedure related to machine learning in the first embodiment;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a sequence diagram showing one example of a processing procedure related to parameter inference in the first embodiment;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows one example of a software configuration of an information processing system according to a second embodiment; and</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows one example of a processing procedure related to parameter inference in the second embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0011" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0020" num="0019">The following describes embodiments of the present invention in detail with reference to the attached drawings. Each of the embodiments to be described below is merely one example of configurations with which the present invention can be realized. Each of the following embodiments can be modified or altered as appropriate in accordance with the configuration of an apparatus to which the present invention is applied and various types of conditions. Also, not all of the combinations of elements included in each of the following embodiments are indispensable to realize the present invention, and a part of the elements can be omitted as appropriate. Therefore, the scope of the present invention is not limited by the configurations described in each of the following embodiments. Furthermore, it is possible to adopt a configuration in which a plurality of configurations described in the embodiments are combined, as long as there is no mutual inconsistency.</p><heading id="h-0012" level="1">1. First Embodiment</heading><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows one example of a configuration of an information processing system S according to a first embodiment. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the information processing system S according to the present embodiment includes an electronic musical instrument <b>100</b>, an information processing apparatus <b>200</b>, and a server <b>300</b>. The information processing system S is one example of a parameter inference system.</p><p id="p-0022" num="0021">The electronic musical instrument <b>100</b> is an apparatus that is used by a user when performing music. The electronic musical instrument <b>100</b> may be, for example, an electronic keyboard instrument (e.g., an electronic piano and the like), an electronic string instrument (e.g., an electric guitar and the like), an electronic wind instrument (e.g., a wind synthesizer and the like), etc. The type of the electronic musical instrument <b>100</b> need not be limited to a particular type as long as it is configured to be capable of changing the responses by changing the values of parameters. The electronic musical instrument <b>100</b> may also be realized by, for example, software on a general-purpose computer such as a tablet terminal and a mobile terminal (e.g., a smartphone).</p><p id="p-0023" num="0022">The information processing apparatus <b>200</b> is a computer that is used by a user when performing an operation related to the settings on the electronic musical instrument <b>100</b>. The information processing apparatus <b>200</b> is, for example, a computer such as a tablet terminal and a personal computer (PC). The electronic musical instrument <b>100</b> and the information processing apparatus <b>200</b> may be configured to be capable of communicating with each other wirelessly or by wire. Alternatively, the electronic musical instrument <b>100</b> and the information processing apparatus <b>200</b> may be configured integrally.</p><p id="p-0024" num="0023">The server <b>300</b> is a computer that exchanges data with the information processing apparatus <b>200</b>. The server <b>300</b> may be, for example, a cloud server, an edge server, or the like. The server <b>300</b> is configured to be capable of communicating with the information processing apparatus <b>200</b> via a network NW.</p><p id="p-0025" num="0024">Roughly, in a learning stage, in the information processing system S of the present embodiment, the server <b>300</b> generates a plurality of data sets DS that are each composed of a pair of first performance information A<b>1</b> and correct answer information L<b>1</b> based on data collected from the electronic musical instrument <b>100</b> and the information processing apparatus <b>200</b>. The first performance information A<b>1</b> is configured to represent a music performance using the electronic musical instrument <b>100</b>. The correct answer information L<b>1</b> is configured to indicate the true values of assist information related to the settings of parameters of the electronic musical instrument that were provided during that performance (i.e., that conform to the performance tendency presented by the first performance information A<b>1</b>). It is sufficient for the assist information to include, for example, later-described instruction information B and information that can be used for the settings of parameters that define the responses of the electronic musical instrument <b>100</b>, such as the settings of tones during a performance), and the configuration and form thereof may be determined as appropriate in accordance with an embodiment. The server <b>300</b> executes machine learning of a learning model M<b>1</b> with use of the generated plurality of data sets DS. The learning model M<b>1</b> is equivalent to an inference model. In the machine learning, the server <b>300</b> trains the learning model M<b>1</b> so that, for each data set DS, the result of inferring assist information from the first performance information A<b>1</b> based on the learning model M<b>1</b> conforms to the corresponding correct answer information L<b>1</b>. Consequently, the trained learning model M<b>1</b> can be generated. The trained learning model M<b>1</b> that has been generated may be provided to the information processing apparatus <b>200</b> at an arbitrary timing. The server <b>300</b> is one example of a model generation apparatus.</p><p id="p-0026" num="0025">On the other hand, in an inference stage, the information processing apparatus <b>200</b> obtains second performance information A<b>2</b> that represents a music performance using the electronic musical instrument <b>100</b>. Using the aforementioned, trained learning model M<b>1</b> that has been generated through machine learning, the information processing apparatus <b>200</b> infer, from the second performance information A<b>2</b>, assist information related to the settings of parameters of the electronic musical instrument <b>100</b> that conform to the performance tendency. The information processing apparatus <b>200</b> outputs the inferred assist information related to the settings of parameters. The information processing apparatus <b>200</b> is one example of a parameter inference apparatus. Note that as described above, in the present embodiment, performance information A in the learning stage is referred to as &#x201c;first performance information A<b>1</b>&#x201d;, whereas performance information A in the inference stage is referred to as &#x201c;second performance information A<b>2</b>&#x201d;. In a case where the stages are not distinguished, it is simply referred to as &#x201c;performance information A&#x201d;. The first performance information A<b>1</b> may be referred to as &#x201c;training performance information&#x201d;. The second performance information A<b>2</b> is equivalent to target performance information.</p><p id="p-0027" num="0026">For example, performers who are similar to each other in terms of the level of performance on the same musical instrument exhibit similar performance operations, and thus their settings on the electronic musical instrument are also similar. That is to say, in a case where the users' tendencies in performances are similar, these users' settings of parameters of the electronic musical instrument also tend to be similar. Therefore, it is possible to generate a trained model that can appropriately infer assist information from performance information A. Also, with the trained model (trained learning model M<b>1</b>) that has been generated, at least a part of a task to obtain the values of parameters of the electronic musical instrument <b>100</b> can be automated. Therefore, according to the present embodiment, the effort required to obtain the values of parameters of the electronic musical instrument <b>100</b> that conform to the user's tendency in a performance can be alleviated.</p><heading id="h-0013" level="1">2. Examples of Hardware Configurations</heading><p id="p-0028" num="0027">(Electronic Musical Instrument)</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows one example of a hardware configuration of the electronic musical instrument <b>100</b> according to the present embodiment. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the electronic musical instrument <b>100</b> is a computer in which a CPU (Central Processing Unit) <b>101</b>, a RAM (Random Access Memory) <b>102</b>, a storage <b>103</b>, a performance operation unit <b>104</b>, a setting operation unit <b>105</b>, a display unit <b>106</b>, a sound source unit <b>107</b>, a sound system <b>108</b>, and a transmission/reception unit <b>109</b> are electrically connected via a bus U<b>1</b>.</p><p id="p-0030" num="0029">The CPU <b>101</b> is composed of one or more processing circuits (processors) for executing various types of calculations in the electronic musical instrument <b>100</b>. The CPU <b>101</b> is one example of a processor resource. The type of the processor may be selected as appropriate in accordance with an embodiment. The RAM <b>102</b> is a volatile storage medium, and operates as a working memory which holds information used by the CPU <b>101</b>, such as set values, and to which various types of programs are deployed. The storage <b>103</b> is a nonvolatile storage medium, and stores various types of programs and data used by the CPU <b>101</b>. The RAM <b>102</b> and the storage <b>103</b> are examples of a memory resource that holds a program executed by a processor resource.</p><p id="p-0031" num="0030">In the present embodiment, the storage <b>103</b> stores various types of information, such as a program <b>81</b>. The program <b>81</b> is a program for causing the electronic musical instrument <b>100</b> to execute information processing related to performances and parameter settings. The program <b>81</b> includes a sequence of instructions for this information processing.</p><p id="p-0032" num="0031">The performance operation unit <b>104</b> is configured to accept a user operation during a music performance, generate performance information A in accordance with the accepted operation, and supplies the CPU <b>101</b> with the generated performance information A. In one example, in a case where the electronic musical instrument <b>100</b> is an electronic keyboard instrument, the performance operation unit <b>104</b> may be an electronic keyboard.</p><p id="p-0033" num="0032">The setting operation unit <b>105</b> is configured to accept a user operation related to parameter settings, generate setting operation data in accordance with the accepted operation, and supply the CPU <b>101</b> with the generated setting operation data. The setting operation unit <b>105</b> may be, for example, an operation switch or the like.</p><p id="p-0034" num="0033">The display unit <b>106</b> is configured to, for example, execute processing for causing an output apparatus to display various types of information, such as information of the parameter settings on the electronic musical instrument <b>100</b>. In one example, in a case where the electronic musical instrument <b>100</b> includes a display (not shown), the display unit <b>106</b> may be configured to transmit video signals corresponding to various types of information to the display.</p><p id="p-0035" num="0034">The sound source unit <b>107</b> is configured to generate sound signals based on performance information A supplied from the CPU <b>101</b> and parameters (parameters P<b>1</b>) that have been set, and input the generated sound signals to the sound system <b>108</b>.</p><p id="p-0036" num="0035">The sound system <b>108</b> is configured to produce a sound corresponding to the sound signals input from the sound source unit <b>107</b>. In one example, the sound system <b>108</b> may be composed of an amplifier and a speaker.</p><p id="p-0037" num="0036">The transmission/reception unit <b>109</b> is configured to exchange data with another apparatus (e.g., the information processing apparatus <b>200</b>) wirelessly or by wire. The transmission/reception unit <b>109</b> may be composed of a module, such as a Bluetooth&#xae; module, a Wi-Fi&#xae; module, a USB (Universal Serial Bus) port, and a special-purpose port, for example. The transmission/reception unit <b>109</b> may include a plurality of modules.</p><p id="p-0038" num="0037">The bus U<b>1</b> is a signal transmission path via which the aforementioned hardware constituent elements of the electronic musical instrument <b>100</b> are mutually and electrically connected. Note that regarding the specific hardware configuration of the electronic musical instrument <b>100</b>, constituent elements can be omitted, replaced, and added as appropriate in accordance with an embodiment.</p><p id="p-0039" num="0038">(Information Processing Apparatus)</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows one example of a hardware configuration of the information processing apparatus <b>200</b> according to the present embodiment. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the information processing apparatus <b>200</b> is a computer in which a CPU <b>201</b>, a RAM <b>202</b>, a storage <b>203</b>, an input/output unit <b>204</b>, a transmission/reception unit <b>205</b>, and a drive <b>206</b> are electrically connected via a bus U<b>2</b>.</p><p id="p-0041" num="0040">The CPU <b>201</b> is composed of one or more processing circuits (processors) for executing various types of calculations in the information processing apparatus <b>200</b>. The CPU <b>201</b> is one example of a processor resource. The type of the processor may be selected as appropriate in accordance with an embodiment. The RAM <b>202</b> is a volatile storage medium, and operates as a working memory which holds various types of information used by the CPU <b>201</b>, such as set values, and to which various types of programs are deployed. The storage <b>203</b> is a nonvolatile storage medium, and stores various types of programs and data used by the CPU <b>201</b>. The RAM <b>202</b> and the storage <b>203</b> are examples of a memory resource that holds a program executed by a processor resource.</p><p id="p-0042" num="0041">In the present embodiment, the storage <b>203</b> stores various types of information, such as a program <b>82</b> and data indicating the trained learning model M<b>1</b>. The program <b>82</b> is a program for causing the information processing apparatus <b>200</b> to execute information processing for inferring assist information of the electronic musical instrument <b>100</b> with use of the trained learning model M<b>1</b> (later-described <figref idref="DRAWINGS">FIG. <b>7</b></figref> and <figref idref="DRAWINGS">FIG. <b>9</b></figref>). The program <b>82</b> includes a sequence of instructions for this information processing. The program <b>82</b> is one example of a parameter inference program.</p><p id="p-0043" num="0042">The input/output unit <b>204</b> is configured to, as a user interface, accept a user operation on the information processing apparatus <b>200</b>, and display various types of information. The input/output unit <b>204</b> may be, for example, configured integrally with a touchscreen display and the like. Alternatively, the input/output unit <b>204</b> may be, for example, configured to include input units and output units that are separate from each other, such as a keyboard, a mouse, a display, and a speaker.</p><p id="p-0044" num="0043">The transmission/reception unit <b>205</b> is configured to exchange data with another apparatus (e.g., the electronic musical instrument <b>100</b>, the server <b>300</b>, or the like) wirelessly or by wire, similarly to the above-described transmission/reception unit <b>109</b>. The transmission/reception unit <b>205</b> may include a plurality of modules (e.g., a Bluetooth&#xae; module, a Wi-Fi&#xae; module, a USB (Universal Serial Bus) port, a special-purpose port, and the like). In one example, the transmission/reception unit <b>205</b> may be configured to communicate with the electronic musical instrument <b>100</b> via the Bluetooth&#xae; module, and communicate with the server <b>300</b> via the Wi-Fi&#xae; module.</p><p id="p-0045" num="0044">The drive <b>206</b> is a drive apparatus for reading in various types of information stored in a storage medium <b>92</b>, such as a program. The storage medium <b>92</b> is a medium in which, in order to allow a computer or another apparatus, machine, or the like to read various types of information stored, such as a program, these pieces of information, such as a program, are accumulated by an electrical, magnetic, optical, mechanical, or chemical action. The storage medium <b>92</b> may be, for example, a floppy disk, an optical disc (e.g., a compact disc, a digital versatile disk, or a Blu-ray disc), a magneto-optical disc, a magnetic tape, a nonvolatile memory card (e.g., a flash memory), or the like. The type of the drive <b>206</b> may be selected arbitrarily in accordance with the type of the storage medium <b>92</b>. At least one of the pieces of data indicating the aforementioned program <b>82</b> and trained learning model M<b>1</b> may be stored in the storage medium <b>92</b>, and the information processing apparatus <b>200</b> may read out at least one of the pieces of data indicating the program <b>82</b> and trained learning model M<b>1</b> from this storage medium <b>92</b>.</p><p id="p-0046" num="0045">The bus U<b>2</b> is a signal transmission path via which the aforementioned hardware constituent elements of the information processing apparatus <b>200</b> are mutually and electrically connected. Note that regarding the specific hardware configuration of the information processing apparatus <b>200</b>, constituent elements can be omitted, replaced, and added as appropriate in accordance with an embodiment.</p><p id="p-0047" num="0046">(Server)</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows one example of a hardware configuration of the server <b>300</b> according to the present embodiment. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the server <b>300</b> is a computer in which a CPU <b>301</b>, a RAM <b>302</b>, a storage <b>303</b>, an input unit <b>304</b>, an output unit <b>305</b>, a transmission/reception unit <b>306</b>, and a drive <b>307</b> are electrically connected via a bus U<b>3</b>.</p><p id="p-0049" num="0048">The CPU <b>301</b> is composed of one or more processing circuits (processors) for executing various types of calculations in the server <b>300</b>. The CPU <b>301</b> is one example of a processor resource. The type of the processor may be selected as appropriate in accordance with an embodiment. The RAM <b>302</b> is a volatile storage medium, and operates as a working memory which holds various types of information used by the CPU <b>301</b>, such as set values, and to which various types of programs are deployed. The storage <b>303</b> is a nonvolatile storage medium, and stores various types of programs and data used by the CPU <b>301</b>. The RAM <b>302</b> and the storage <b>303</b> are examples of a memory resource that holds a program executed by a processor resource.</p><p id="p-0050" num="0049">In the present embodiment, the storage <b>303</b> stores various types of information, such as a program <b>83</b> and data indicating the trained learning model M<b>1</b>. The program <b>83</b> is a program for causing the server <b>300</b> to execute information processing related to machine learning of the learning model M<b>1</b> (later-described <figref idref="DRAWINGS">FIG. <b>6</b></figref>). The program <b>83</b> includes a sequence of instructions for this information processing. The program <b>83</b> is one example of a model generation program. In the present embodiment, the data indicating the trained learning model M<b>1</b> is generated as a result of execution of the sequence of instructions included in the program <b>83</b> by the server <b>300</b>.</p><p id="p-0051" num="0050">The input unit <b>304</b> is composed of an input apparatus for accepting an operation on the server <b>300</b>. The input unit <b>304</b> may be, for example, configured to accept input signals from one or more input apparatuses connected to the server <b>300</b>, such as a keyboard and a mouse.</p><p id="p-0052" num="0051">The output unit <b>305</b> is composed of an output apparatus for outputting various types of information. The output unit <b>305</b> may be, for example, configured to output information (e.g., video signals, sound signals, and the like) to one or more output apparatuses connected to the server <b>300</b>, such as a liquid crystal display and a speaker.</p><p id="p-0053" num="0052">The transmission/reception unit <b>306</b> is configured to exchange data with another apparatus (e.g., the information processing apparatus <b>200</b>) wirelessly or by wire, similarly to the above-described transmission/reception unit <b>109</b> and the like. The transmission/reception unit <b>308</b> may be composed of, for example, a network card (NIC).</p><p id="p-0054" num="0053">The drive <b>307</b> is a drive apparatus for reading in various types of information stored in a storage medium <b>93</b>, such as a program, similarly to the above-described drive <b>206</b>. The type of the drive <b>307</b> may be selected arbitrarily in accordance with the type of the storage medium <b>93</b>. Similarly to the above-described storage medium <b>92</b>, the storage medium <b>93</b> is a medium in which, in order to allow a computer or another apparatus, machine, or the like to read various types of information stored, such as a program, these pieces of information, such as a program, are accumulated by an electrical, magnetic, optical, mechanical, or chemical action. The aforementioned program <b>83</b> may be stored in the storage medium <b>93</b>, and the server <b>300</b> may read out the program <b>83</b> from this storage medium <b>92</b>.</p><p id="p-0055" num="0054">The bus U<b>3</b> is a signal transmission path via which the aforementioned hardware constituent elements of the server <b>300</b> are mutually and electrically connected. Note that regarding the specific hardware configuration of the server <b>300</b>, constituent elements can be omitted, replaced, and added as appropriate in accordance with an embodiment.</p><heading id="h-0014" level="1">3. Example of Software Configuration</heading><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows one example of a software configuration of the information processing system S according to the first embodiment.</p><p id="p-0057" num="0056">(Electronic Musical Instrument)</p><p id="p-0058" num="0057">The electronic musical instrument <b>100</b> includes a control unit <b>150</b> and a storage unit <b>160</b>. The control unit <b>150</b> is configured to perform integrative control on the operations of the electronic musical instrument <b>100</b> with use of the CPU <b>101</b> and the RAM <b>102</b>. The storage unit <b>160</b> is composed of the RAM <b>102</b> and the storage <b>103</b>. The CPU <b>101</b> of the electronic musical instrument <b>100</b> deploys the program <b>81</b> stored in the storage <b>103</b> to the RAM <b>102</b>, and executes the instructions included in the program <b>81</b> deployed to the RAM <b>102</b>. In this way, the electronic musical instrument <b>100</b> (control unit <b>150</b>) operates as a computer that includes a performance obtainment unit <b>151</b> and a parameter setting unit <b>152</b> as software modules.</p><p id="p-0059" num="0058">The performance obtainment unit <b>151</b> is configured to obtain performance information A that has been generated by the performance operation unit <b>104</b> in accordance with a performance operation of a user. The performance information A may be configured as appropriate to include, for example, information that can present performance tendencies, such as a performance operation, the sounds of a performance, and acoustic characteristics included in the sounds of a performance. In one example, the performance information A may include information indicating the times of sound production of a plurality of sounds and the pitches thereof during the user's performance. Furthermore, the performance information A may include information indicating the durations and intensities that respectively correspond to the plurality of sounds. The performance information A may be composed of high-dimensional chronological data that represents the user's performance. The performance obtainment unit <b>151</b> may be configured to supply the sound source unit <b>107</b> with the obtained performance information A. In addition, the performance obtainment unit <b>151</b> may be configured to supply the information processing apparatus <b>200</b> (performance reception unit <b>252</b>) with the obtained performance information A via the transmission/reception unit <b>109</b>.</p><p id="p-0060" num="0059">The parameter setting unit <b>152</b> is configured to set parameters of the electronic musical instrument <b>100</b> (sound source unit <b>107</b>) based on information supplied from the information processing apparatus <b>200</b> (e.g., later-described instruction information B or parameters P<b>1</b>).</p><p id="p-0061" num="0060">(Information Processing Apparatus)</p><p id="p-0062" num="0061">The information processing apparatus <b>200</b> includes a control unit <b>250</b> and a storage unit <b>260</b>. The control unit <b>250</b> is configured to perform integrative control on the operations of the information processing apparatus <b>200</b> with use of the CPU <b>201</b> and the RAM <b>202</b>. The storage unit <b>260</b> is configured to store various types of data used by the control unit <b>250</b> with use of the RAM <b>202</b> and the storage <b>203</b>. The CPU <b>201</b> of the information processing apparatus <b>200</b> deploys the program <b>82</b> stored in the storage <b>203</b> to the RAM <b>202</b>, and executes the instructions included in the program <b>82</b> deployed to the RAM <b>202</b>. In this way, the information processing apparatus <b>200</b> (control unit <b>250</b>) operates as a computer that includes an authentication unit <b>251</b>, a performance reception unit <b>252</b>, an instruction obtainment unit <b>253</b>, a data preprocessing unit <b>254</b>, an inference processing unit <b>255</b>, and an adjustment unit <b>256</b> as software modules.</p><p id="p-0063" num="0062">The authentication unit <b>251</b> is configured to authenticate a user in coordination with an external apparatus, such as the server <b>300</b> (later-described authentication unit <b>351</b>). In one example, the authentication unit <b>251</b> is configured to transmit authentication information that has been input by the user with use of the input/output unit <b>204</b>, such as a user identifier and a password, to the server <b>300</b>, and permit or deny the user's access based on the authentication result received from the server <b>300</b>. The authentication unit <b>251</b> may be configured to supply another software module with the user identifier of the authenticated user (who has been permitted to have access).</p><p id="p-0064" num="0063">The performance reception unit <b>252</b> is configured to receive performance information A supplied from the electronic musical instrument <b>100</b> (performance obtainment unit <b>151</b>), and store the received performance information A into the storage unit <b>260</b> as second performance information A<b>2</b>, or supply the data preprocessing unit <b>254</b> with the same. The performance reception unit <b>252</b> may be configured to store the user identifier supplied from the authentication unit <b>251</b> into the storage unit <b>260</b> in association with the second performance information A<b>2</b>. Also, the performance reception unit <b>252</b> is configured to transmit the performance information A to the server <b>300</b> with use of the transmission/reception unit <b>205</b>. The server <b>300</b> obtains the performance information A transmitted from the information processing apparatus <b>200</b> as first performance information A<b>1</b>. This first performance information A<b>1</b> may be associated with the user identifier, similarly to the above-described second performance information A<b>2</b>.</p><p id="p-0065" num="0064">The instruction obtainment unit <b>253</b> is configured to generate instruction information B in accordance with a user's instruction operation on the input/output unit <b>204</b>, and store the generated instruction information B into the storage unit <b>260</b>. The instruction obtainment unit <b>253</b> may be configured to store the user identifier supplied from the authentication unit <b>251</b> into the storage unit <b>260</b> in association with the instruction information B (or parameters designated by the instruction information B). The instruction information B may be configured as appropriate to include information that designates the values of parameters of the electronic musical instrument <b>100</b>). In one example, the instruction information B may be configured to include the time and the contents (e.g., a position touched on the touchscreen display, a tone designated by the operation, and the like) of the user operation. That is to say, the instruction information B may be configured to indicate a history of user operations related to the parameter settings. In the present embodiment, the instruction information B makes it possible to specify the values of parameters that conform to the user's tendency in a performance at the time of execution of that operation. The parameters define responses related to a performance of the electronic musical instrument <b>100</b>. The types of the parameters may be determined as appropriate in accordance with, for example, the type of the electronic musical instrument <b>100</b>. The parameters may be, for example, tones (types of musical instruments) during a performance of the electronic musical instrument <b>100</b> (sound source unit <b>107</b>), the settings of an operation screen, equalizer settings, touch curve settings on an electronic piano, effecter settings on an electric guitar, and so on. The instruction obtainment unit <b>253</b> is configured to supply the electronic musical instrument <b>100</b> (parameter setting unit <b>152</b>) with the instruction information B or the values of the parameters specified from the instruction information B with use of the transmission/reception unit <b>205</b>. Also, the instruction obtainment unit <b>253</b> is configured to transmit the instruction information B or the values of the parameters specified from the instruction information B to the server <b>300</b> with use of the transmission/reception unit <b>205</b>. The user identifier may be associated with the instruction information B or the values of the parameters that are supplied to each of the electronic musical instrument <b>100</b> and the server <b>300</b>.</p><p id="p-0066" num="0065">In order to make the second performance information A<b>2</b> conform to the input format of the trained learning model M<b>1</b>, the data preprocessing unit <b>254</b> is configured to execute, for example, data preprocessing, such as scaling, with respect to this second performance information A<b>2</b>. The second performance information A<b>2</b> may be supplied from either of the storage unit <b>260</b> and the performance reception unit <b>252</b>.</p><p id="p-0067" num="0066">The inference processing unit <b>255</b> is configured to, with use of the trained learning model M<b>1</b>, infer assist information related to the settings of parameters of the electronic musical instrument <b>100</b> that conform to the performance tendency from the second performance information A<b>2</b>. Specifically, the inference processing unit <b>255</b> inputs the preprocessed second performance information A<b>2</b> to the trained learning model M<b>1</b>, and executes calculation processing for the trained learning model M<b>1</b>. The inference processing unit <b>255</b> obtains the inferred assist information from the trained learning model M<b>1</b> as a result of this calculation processing. In one example, the assist information is composed of the same type of data as the aforementioned instruction information B (i.e., data for giving an instruction related to the values of parameters to the electronic musical instrument <b>100</b>) or the values of parameters. An arbitrary machine learning model may be adopted as the learning model M<b>1</b> according to the present embodiment. Preferably, at least one of a recurrent neural network (RNN) that conforms to chronological data and the constituents of its derivative (long short-term memory (LSTM), gated recurrent unit (GRU), and the like) is adopted as the learning model M<b>1</b>.</p><p id="p-0068" num="0067">The adjustment unit <b>256</b> is configured to cause the parameter setting unit <b>152</b> of the electronic musical instrument <b>100</b> to adjust the values of parameters (e.g., set the values of parameters of the sound source unit <b>107</b>) based on the assist information inferred by the inference processing unit <b>255</b>. The adjustment unit <b>256</b> is one example of an output processing unit that is configured to output the inferred assist information, and causing the electronic musical instrument <b>100</b> to adjust the values of parameters based on the inferred assist information is one example of outputting of the inferred assist information. At this time, the adjustment unit <b>256</b> may cause the input/output unit <b>204</b> to display the values of parameters (e.g., tones of the sound source unit <b>107</b>) designated by the inferred assist information. In response, the adjustment unit <b>256</b> may accept a user's operation to select whether to use these values of parameters. Then, in response to the acceptance of the operation to select the use of the values of parameters designated by the inferred assist information via the input/output unit <b>204</b>, the adjustment unit <b>256</b> may transmit the assist information or these values of parameters to the electronic musical instrument <b>100</b> (parameter setting unit <b>152</b>). In this way, the adjustment unit <b>256</b> may cause the electronic musical instrument <b>100</b> to adjust set values of parameters on the electronic musical instrument <b>100</b> to the values designated by the assist information. In one example, outputting of the assist information may include an adjustment of the settings of tones of the electronic musical instrument <b>100</b> based on the inferred assist information related to the settings of parameters. Also, outputting of the assist information may include an adjustment of an operation screen of the electronic musical instrument <b>100</b> based on the inferred assist information related to the settings of parameters. Note that the method of adjusting the values of parameters based on the inferred assist information may not be limited to the foregoing example. In another example, the adjustment unit <b>256</b> may be configured to suggest the user to manipulate the parameter settings on the electronic musical instrument <b>100</b> by displaying the values of parameters designated by the inferred assist information on the input/output unit <b>204</b>.</p><p id="p-0069" num="0068">(Server)</p><p id="p-0070" num="0069">The server <b>300</b> includes a control unit <b>350</b> and a storage unit <b>360</b>. The control unit <b>350</b> is configured to perform integrative control on the operations of the server <b>300</b> with use of the CPU <b>301</b> and the RAM <b>302</b>. The storage unit <b>360</b> is configured to store various types of data used by the control unit <b>350</b> (e.g., first performance information A<b>1</b> and instruction information B supplied from the information processing apparatus <b>200</b>) with use of the RAM <b>302</b> and the storage <b>303</b>. Note that in a case where each of a plurality of users uses the electronic musical instrument <b>100</b> and the information processing apparatus <b>200</b>, it is preferable that the storage unit <b>360</b> store pieces of first performance information A<b>1</b> and pieces of instruction information B (or the values of parameters), which are generated on a per-user basis, in distinction from one another based on user identifiers. The CPU <b>301</b> of the server <b>300</b> deploys the program <b>83</b> stored in the storage <b>303</b> to the RAM <b>302</b>, and executes the instructions included in the program <b>83</b> deployed to the RAM <b>302</b>. In this way, the server <b>300</b> (control unit <b>350</b>) operates as a computer that includes an authentication unit <b>351</b>, a data preprocessing unit <b>352</b>, a learning processing unit <b>353</b>, and a model distribution unit <b>354</b> as software modules.</p><p id="p-0071" num="0070">The authentication unit <b>351</b> is configured to authenticate a user in coordination with the information processing apparatus <b>200</b> (authentication unit <b>251</b>). The authentication unit <b>351</b> is configured to determine whether authentication information supplied from the information processing apparatus <b>200</b> matches authentication information stored in the storage unit <b>360</b>, and transmit the authentication result (permission or denial) to the information processing apparatus <b>200</b>.</p><p id="p-0072" num="0071">In order to make the first performance information A<b>1</b> conform to the input format of the learning model M<b>1</b>, the data preprocessing unit <b>352</b> is configured to execute, for example, data preprocessing, such as scaling, with respect to this first performance information A<b>1</b>. The first performance information A<b>1</b> may be supplied from the storage unit <b>360</b>.</p><p id="p-0073" num="0072">The learning processing unit <b>353</b> is configured to specify the true values of assist information from instruction information B supplied from the information processing apparatus <b>200</b> or the values of parameters designated by the instruction information B, and generate correct answer information L<b>1</b> that indicates the specified true values. In one example, the learning processing unit <b>353</b> may use the instruction information B or the values of parameters designated by the instruction information B, as is, as the correct answer information L<b>1</b>. In another example, the learning processing unit <b>353</b> may generate the correct answer information L<b>1</b> by executing arbitrary calculation processing with respect to the instruction information B or the values of parameters designated by the instruction information B (e.g., correcting the values). The learning processing unit <b>353</b> is configured to generate each data set DS by associating the generated correct answer information L<b>1</b> with corresponding first performance information A<b>1</b>. Also, the learning processing unit <b>353</b> is configured to execute machine learning of the learning model M<b>1</b> by using the first performance information A<b>1</b> in each generated data set DS after the data preprocessing as training data (input data), and using corresponding correct answer information L<b>1</b> as supervisory signals (correct answer data). Consequently, the trained learning model M<b>1</b> can be generated. The learning processing unit <b>353</b> generates learning result data for reproducing the generated, trained learning model M<b>1</b>, and stores the generated learning result data into an arbitrary storage region.</p><p id="p-0074" num="0073">In one example, the learning processing unit <b>353</b> may execute machine learning of the learning model M<b>1</b> by referring to an associated user identifier and using a plurality of data sets DS that have been collected in correspondence with the specific user. The learning processing unit <b>353</b> may generate the trained learning model M<b>1</b> for a specific user in the foregoing manner. Alternatively, when generating the trained learning model M<b>1</b> for a specific user, the learning processing unit <b>353</b> may arbitrarily use a data set DS corresponding to another user, in addition to the data set DS corresponding to the specific user, in machine learning. When the number of data sets DS associated with the specific user is small, the inference accuracy of the trained learning model M can be increased by using the data set DS associated with another user as well in machine learning in the foregoing manner.</p><p id="p-0075" num="0074">The model distribution unit <b>354</b> is configured to distribute the trained learning model M<b>1</b> to a user by transmitting the learning result data generated by the learning processing unit <b>353</b> to the information processing apparatus <b>200</b>. The model distribution unit <b>354</b> may be configured to, in a case where the trained learning model M<b>1</b> has been generated for a specific user, distribute the learning result data (trained learning model M<b>1</b>) corresponding to the information processing apparatus <b>200</b> of a user specified by a user identifier.</p><p id="p-0076" num="0075">(Others)</p><p id="p-0077" num="0076">The present embodiment has been described using an example in which each of the software modules of the electronic musical instrument <b>100</b>, the information processing apparatus <b>200</b>, and the server <b>300</b> is realized with use of a general-purpose CPU. However, a part or all of the foregoing software modules may be realized with use of one or more special-purpose processors. Each of the foregoing modules may be realized as a hardware module. Also, regarding the software configuration of each of the electronic musical instrument <b>100</b>, the information processing apparatus <b>200</b>, and the server <b>300</b>, software modules can be omitted, replaced, and added as appropriate in accordance with an embodiment.</p><heading id="h-0015" level="1">4. Example of Operations</heading><p id="p-0078" num="0077">(Machine Learning of Learning Model)</p><p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a sequence diagram showing one example of a processing procedure related to machine learning of the learning model M<b>1</b> in the information processing system S according to the first embodiment. The following processing procedure is one example of a method of establishing a trained inference model. Note that regarding the following processing procedure, steps can be omitted, replaced, and added as appropriate in accordance with an embodiment.</p><p id="p-0080" num="0079">Before the execution of learning processing, the CPU <b>301</b> of the server <b>300</b> collects first performance information A<b>1</b> in the electronic musical instrument <b>100</b> via the information processing apparatus <b>200</b>. Also, the CPU <b>301</b> collects instruction information B (or the values of parameters designated by the instruction information B) corresponding to the first performance information A<b>1</b>. The collected first performance information A<b>1</b> and instruction information B (or values of parameters) (hereinafter also referred to as &#x201c;various types of data&#x201d;) are stored into the storage unit <b>360</b> in association with each other. The various types of data may be stored in association with a user identifier.</p><p id="p-0081" num="0080">When executing learning processing, the CPU <b>301</b> operates as the learning processing unit <b>353</b>, and generates a plurality of data sets DS with use of various types of data accumulated in the storage unit <b>360</b>. In the present embodiment, in order to include information related to the settings of tones during a performance in inferred assist information, the true values of assist information indicated by correct answer information L<b>1</b> may include the true values of tones during a performance, which are indicated by corresponding first performance information A<b>1</b>. Also, in order to include information related to the settings of the operation screen of the electronic musical instrument <b>100</b> in inferred assist information, the true values of assist information indicated by correct answer information L<b>1</b> may include the true values of the operation screen of the electronic musical instrument <b>100</b> that conform to the performance tendency presented by corresponding first performance information A<b>1</b>.</p><p id="p-0082" num="0081">In step S<b>610</b>, the CPU <b>301</b> operates as the data preprocessing unit <b>352</b>, and executes data preprocessing with respect to first performance information A<b>1</b> of each data set DS.</p><p id="p-0083" num="0082">In step S<b>620</b>, the CPU <b>301</b> operates as the learning processing unit <b>353</b>, and executes machine learning of the learning model M<b>1</b> by using the first performance information A<b>1</b> of each data set DS after the data preprocessing as training data, and using corresponding correct answer information L<b>1</b> as supervisory signals. Specifically, the CPU <b>301</b> trains the learning model M<b>1</b> (adjusts the values of calculation parameters that compose the learning model M<b>1</b>) so that, for each data set DS, the result of inferring assist information from the first performance information A<b>1</b> after the data preprocessing with use of the learning model M<b>1</b> conforms to corresponding correct answer information L<b>1</b>. As a result of this machine learning, the trained learning model M<b>1</b> can be generated that has gained the capability to infer, from the performance information A, assist information (instruction information or values of parameters) related to the settings of parameters of the electronic musical instrument <b>100</b> that conform to the performance tendency presented by the performance information A. The CPU <b>301</b> may generate learning result data indicating the trained learning model M<b>1</b>, and store the generated learning result data into the storage unit <b>360</b>.</p><p id="p-0084" num="0083">In step S<b>630</b>, the CPU <b>301</b> operates as the model distribution unit <b>354</b>, and transmits the generated learning result data indicating the trained learning model M<b>1</b> to the information processing apparatus <b>200</b> via the network NW. In this way, the server <b>300</b> distributes the trained learning model M<b>1</b> to the information processing apparatus <b>200</b>. The CPU <b>201</b> of the information processing apparatus <b>200</b> stores the received learning model M<b>1</b> (learning result data) into the storage unit <b>260</b>.</p><p id="p-0085" num="0084">This concludes the processing procedure related to machine learning of the learning model M<b>1</b> according to the present example of operations. The foregoing processing of machine learning may be executed regularly, or may be executed in response to a request from a user (information processing apparatus <b>200</b>). Note that before the execution of processing of step S<b>610</b>, the CPU <b>201</b> of the information processing apparatus <b>200</b> and the CPU <b>301</b> of the server <b>300</b> may respectively operate as the authentication units (<b>251</b>, <b>351</b>) and authenticate users. In the foregoing manner, with use of data associated with the user identifier of the authenticated user, the server <b>300</b> may generate the trained learning model M<b>1</b> for this authenticated user.</p><p id="p-0086" num="0085">(Parameter Inference Processing)</p><p id="p-0087" num="0086"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a sequence diagram showing one example of a processing procedure related to inference of parameters in the information processing system S according to the first embodiment. The following processing procedure is one example of a parameter inference method. Note that regarding the following processing procedure, steps can be omitted, replaced, and added as appropriate in accordance with an embodiment. Also note that in the present embodiment, the information processing apparatus <b>200</b> is configured to execute parameter inference processing. Also, the information processing apparatus <b>200</b> is configured to set the values of parameters P<b>1</b> in the electronic musical instrument <b>100</b> based on the obtained inference result as one example of processing for outputting assist information.</p><p id="p-0088" num="0087">In step S<b>710</b>, the CPU <b>201</b> of the information processing apparatus <b>200</b> operates as the performance reception unit <b>252</b>, and obtains second performance information A<b>2</b> that indicates a performance of music using the electronic musical instrument <b>100</b>. In one example, the CPU <b>201</b> receives, from the electronic musical instrument <b>100</b>, second performance information A<b>2</b> obtained by the performance obtainment unit <b>151</b>. The CPU <b>201</b> supplies the data preprocessing unit <b>254</b> with the obtained second performance information A<b>2</b>. In another example, the CPU <b>201</b> may operate as the performance reception unit <b>252</b>, receive second performance information A<b>2</b> from the electronic musical instrument <b>100</b> in advance, and store the received second performance information A<b>2</b> into the storage unit <b>260</b>. In this case, the CPU <b>201</b> may read out the second performance information A<b>2</b> from the storage unit <b>260</b>, and supply the data preprocessing unit <b>254</b> with the second performance information A<b>2</b> that has been read out.</p><p id="p-0089" num="0088">In step S<b>720</b>, the CPU <b>201</b> operates as the data preprocessing unit <b>254</b>, and executes data preprocessing with respect to the second performance information A<b>2</b> supplied from the performance reception unit <b>252</b>. Then, the CPU <b>201</b> supplies the inference processing unit <b>255</b> with the second performance information A<b>2</b> after the data preprocessing.</p><p id="p-0090" num="0089">In step S<b>730</b>, the CPU <b>201</b> operates as the inference processing unit <b>255</b>, and infers assist information related to the settings of parameters of the electronic musical instrument <b>100</b> that conform to the performance tendency from the second performance information A<b>2</b> with use of the trained learning model M<b>1</b> generated through the above-described machine learning. The CPU <b>201</b> sets the trained learning model M<b>1</b> with reference to learning result data stored in the storage unit <b>260</b>. The CPU <b>201</b> inputs the preprocessed second performance information A<b>2</b> to the trained learning model M<b>1</b>, and executes calculation processing for the trained learning model M<b>1</b>. The CPU <b>201</b> obtains an output corresponding to the result of inferring the assist information from the trained learning model M<b>1</b> as a result of this calculation processing. In the present embodiment, the inferred assist information is composed of the same type of data as the instruction information B or estimated values of parameters. In a case where the correct answer information L<b>1</b> used in machine learning includes the true values of tones during a performance, the inferred assist information includes information related to the settings of tones during the performance. In a case where the correct answer information L<b>1</b> used in machine learning includes the true values of the operation screen, the inferred assist information (the result of inferring the assist information) includes information related to the settings of the operation screen of the electronic musical instrument <b>100</b> that conform to the performance tendency presented by the second performance information A<b>2</b>. The CPU <b>201</b> supplies the adjustment unit <b>256</b> with the result of inferring the assist information.</p><p id="p-0091" num="0090">In step S<b>740</b>, the CPU <b>201</b> operates as the adjustment unit <b>256</b>, and displays the result of inferring the assist information, which has been obtained in processing of step S<b>730</b>, with use of the input/output unit <b>204</b> (display). In this way, a user is suggested to confirm whether to use the values of the parameters P<b>1</b> designated by the inferred assist information.</p><p id="p-0092" num="0091">In step S<b>750</b>, the CPU <b>201</b> operates as the adjustment unit <b>256</b>, and receives, from the input/output unit <b>204</b>, the user's response (operation) to whether to use the values of the parameters P<b>1</b>, which is displayed as a result of processing of step S<b>740</b>.</p><p id="p-0093" num="0092">In step S<b>760</b>, the CPU <b>201</b> operates as the adjustment unit <b>256</b>, and determines whether to adjust parameters of the electronic musical instrument <b>100</b> based on the user's response obtained in processing of step S<b>750</b>. In a case where the CPU <b>201</b> has received the user's response that indicates the use (acceptance) of the values of the parameters P<b>1</b> designated by the inferred assist information, processing proceeds to step S<b>770</b>. On the other hand, in a case where the user's response that indicates non-use (denial) of the values of the parameters P<b>1</b> has been received, processing of step S<b>779</b> is omitted, and the processing procedure according to the present example of operations is ended.</p><p id="p-0094" num="0093">In step S<b>770</b>, the CPU <b>201</b> operates as the adjustment unit <b>256</b>, and transmits, to the electronic musical instrument <b>100</b> (parameter setting unit <b>152</b>), an instruction for changing set values of the parameters P<b>1</b> on the electronic musical instrument <b>100</b> to the values of the parameters P<b>1</b> designated by the inferred assist information. Note that in the present step S<b>770</b>, the CPU <b>201</b> may transmit the designated values of the parameters P<b>1</b> directly to the electronic musical instrument <b>100</b>, or may transmit instruction information corresponding to the values of the parameters P<b>1</b> to the electronic musical instrument <b>100</b>.</p><p id="p-0095" num="0094">In step S<b>780</b>, the CPU <b>101</b> of the electronic musical instrument <b>100</b> operates as the parameter setting unit <b>152</b>, and changes the values of the parameters P<b>1</b> on the electronic musical instrument <b>100</b> to the values designated by the instruction received from the information processing apparatus <b>200</b>. In a case where the inferred assist information includes information related to the settings of tones during a performance, the CPU <b>101</b> sets tones of the sound source unit <b>107</b> in accordance with the instruction from the information processing apparatus <b>200</b>. In a case where the inferred assist information includes information related to the settings of the operation screen of the electronic musical instrument <b>100</b>, the CPU <b>101</b> sets the operation screen of the electronic musical instrument <b>100</b> in accordance with the instruction from the information processing apparatus <b>200</b>.</p><p id="p-0096" num="0095">(Features)</p><p id="p-0097" num="0096">According to the present embodiment, the use of the trained learning model M<b>1</b> makes it possible to obtain the values of parameters P<b>1</b> of the electronic musical instrument <b>100</b> that conform to the user's tendency in a performance, and the effort required to set parameters P<b>1</b> can be alleviated due to the obtained values. Also, it is possible to provide the information processing system S that can automatically adjust the settings on the electronic musical instrument <b>100</b> in accordance with a change in the user's tendency in a performance indicated by performance information A.</p><p id="p-0098" num="0097">Furthermore, in the present embodiment, as the assist information includes at least one of information related to the settings of tones in a performance and information related to the settings of the operation screen, the effort required to set at least one of the tones and the operation screen of the electronic musical instrument <b>100</b> can be alleviated. Furthermore, according to the present embodiment, the trained learning model M<b>1</b> can be generated for each user identified by a user identifier, and the generated, trained learning model M<b>1</b> can be provided to the information processing apparatus <b>200</b> of each user. A user can keep using the trained learning model M<b>1</b> for inferring parameters P<b>1</b> that conform to his/her own tendency in a performance, even if at least one of the electronic musical instrument <b>100</b> and the information processing apparatus <b>200</b> is replaced.</p><heading id="h-0016" level="1">5. Second Embodiment</heading><p id="p-0099" num="0098">The following describes a second embodiment of the present invention. In each of the embodiments to be exemplarily described below, regarding the constituents that are equal to those of the first embodiment in terms of actions and operations, a description of each of such constituents may be omitted as appropriate while using the reference numeral mentioned in the foregoing description therefor.</p><p id="p-0100" num="0099">The information processing system S according to the above-described first embodiment executes processing for displaying the values of parameters P<b>1</b> designated by inferred assist information and adjusting the values of parameters P<b>1</b> of the electronic musical instrument <b>100</b> in accordance with an acceptance response from a user by way of processing of step S<b>740</b> to step S<b>770</b>, which acts as processing for outputting assist information. In contrast, in the second embodiment, parameters P<b>2</b> of the electronic musical instrument <b>100</b> include, for example, parameters corresponding to the characteristics of a performance (the characteristics related to a performance), such as a music genre and the degree of proficiency of a user. Inferred assist information includes characteristics information C that indicates the characteristics of a performance. A learning model M<b>2</b> is trained so as to gain the capability to infer such assist information from performance information A with use of a plurality of data sets DS. The information processing apparatus <b>200</b> presents information to a user (e.g., displays an advertisement and the like) based on the inferred assist information. Other than these points, the second embodiment may be configured similarly to the above-described first embodiment. Note that the presentation of information in the second embodiment may be executed in place of the setting of parameters in the first embodiment, or may be executed simultaneously with the setting of parameters in the first embodiment.</p><p id="p-0101" num="0100">(Software Configuration)</p><p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows one example of a software configuration of an information processing system S according to the second embodiment. In the second embodiment, the configurations of software modules included in the electronic musical instrument <b>100</b>, the information processing apparatus <b>200</b>, and the server <b>300</b> partially differ from the configurations in the above-described first embodiment.</p><p id="p-0103" num="0102">A characteristics obtainment unit <b>283</b> is configured to obtain characteristics information C related to parameters P<b>2</b> pertaining to a performance, and store the obtained characteristics information C into the storage unit <b>260</b>. The characteristics obtainment unit <b>283</b> may be configured to store a user identifier supplied from the authentication unit <b>251</b> into the storage unit <b>260</b> in association with characteristics information C (or the values of parameters P<b>2</b> indicated by characteristics information C). Parameters P<b>2</b> according to the present embodiment are related to, for example, the characteristics of a performance, such as a music genre indicated by performance information A, and the degree of proficiency of a user who carried out a performance equivalent to performance information A. Characteristics information C is composed of data that is used to specify the values of parameters P<b>2</b>. The characteristics obtainment unit <b>283</b> is configured to transmit the obtained characteristics information C to the server <b>300</b> with use of the transmission/reception unit <b>205</b>. A user identifier may be associated with the characteristics information C transmitted to the server <b>300</b>.</p><p id="p-0104" num="0103">Similarly to the above-described data preprocessing unit <b>254</b>, in order to make second performance information A<b>2</b> conform to the input format of a trained learning model M<b>2</b>, a data preprocessing unit <b>284</b> is configured to execute, for example, data preprocessing, such as scaling, with respect to this second performance information A<b>2</b>. The second performance information A<b>2</b> may be supplied from either of the storage unit <b>260</b> and the performance reception unit <b>252</b>.</p><p id="p-0105" num="0104">An inference processing unit <b>285</b> is configured to, with use of the trained learning model M<b>2</b>, infer assist information related to parameters P<b>2</b> of the electronic musical instrument <b>100</b> that conform to the performance tendency from the second performance information A<b>2</b>. Specifically, the inference processing unit <b>285</b> inputs the preprocessed second performance information A<b>2</b> to the trained learning model M<b>2</b>, and executes calculation processing for the trained learning model M<b>2</b>. The inference processing unit <b>285</b> obtains the inferred assist information from the trained learning model M<b>2</b> as a result of this calculation processing. In the second embodiment, the inferred assist information is configured to include the same type of data as the characteristics information C or estimated values of parameters P<b>2</b>. The result of inferring the assist information is supplied to a display control unit <b>286</b>. A machine learning model that composes the learning model M<b>2</b> may be similar to the above-described learning model M<b>1</b>.</p><p id="p-0106" num="0105">The display control unit <b>286</b> is configured to execute arbitrary display control based on the result of inferring the assist information obtained from the inference processing unit <b>285</b>. In a case where the inferred assist information is composed of the same type of data as the characteristics information C, the display control unit <b>286</b> may, for example, specify the values of parameters P<b>2</b> from the result of inferring the assist information by using an arbitrary method, such as the application of rule-based processing and the use of a learned model.</p><p id="p-0107" num="0106">The display control unit <b>286</b> is one example of an output processing unit that is configured to output the inferred assist information. As one example of processing for outputting the assist information, the display control unit <b>286</b> may obtain advertisement information that conforms to the inferred assist information related to the parameters P<b>2</b>, and output the obtained advertisement information (display the same with use of the input/output unit <b>204</b>). In a case where the parameters P<b>2</b> are related to a music genre, the display control unit <b>286</b> may display such advertisement information as tone data and accompaniment pattern (backing) data that conform to the inferred genre. In a case where the parameters P<b>2</b> are related to the degree of proficiency of a user, the display control unit <b>286</b> may display advertisement information for an electronic musical instrument <b>100</b> that conforms to the degree of proficiency.</p><p id="p-0108" num="0107">Also, the display control unit <b>286</b> may be configured to adjust an operation screen (user interface) that is displayed on the information processing apparatus <b>200</b> for a user of the electronic musical instrument <b>100</b> based on the result of inferring the assist information. In a case where the parameters P<b>2</b> are related to the degree of proficiency of the user, the display control unit <b>286</b> may adjust the operation screen so that a menu that suits the degree of proficiency (e.g., a menu for a beginner with a small number of items, a menu for the experienced that enable special settings, and so on) is displayed on the input/output unit <b>204</b>.</p><p id="p-0109" num="0108">Note that although <figref idref="DRAWINGS">FIG. <b>8</b></figref> does not show the instruction obtainment unit <b>253</b> to the adjustment unit <b>256</b> in the first embodiment, the information processing apparatus <b>200</b> according to the second embodiment may include the instruction obtainment unit <b>253</b> to the adjustment unit <b>256</b> as software modules in a configuration that obtains parameters P<b>1</b> in addition to parameters P<b>2</b>.</p><p id="p-0110" num="0109">Similarly to the above-described data preprocessing unit <b>352</b>, in order to make first performance information A<b>1</b> conform to the input format of the trained learning model M<b>2</b>, a data preprocessing unit <b>382</b> is configured to execute, for example, data preprocessing, such as scaling, with respect to this first performance information A<b>1</b>. The first performance information A<b>1</b> may be supplied from the storage unit <b>360</b>.</p><p id="p-0111" num="0110">A learning processing unit <b>383</b> is configured to specify the true values of assist information from the characteristics information C supplied from the information processing apparatus <b>200</b> or the values of parameters P<b>2</b> specified from the characteristics information C, and generate correct answer information L<b>1</b> that indicates the specified true values. The learning processing unit <b>383</b> is configured to generate each data set DS by associating the generated correct answer information L<b>1</b> with corresponding first performance information A<b>1</b>. Also, the learning processing unit <b>383</b> is configured to execute machine learning of the learning model M<b>2</b> by using the first performance information A<b>1</b> in each generated data set DS after the data preprocessing as training data (input data), and using corresponding correct answer information L<b>1</b> as supervisory signals (correct answer data). The trained learning model M<b>2</b> is generated as a result of this machine learning. The learning processing unit <b>383</b> generates learning result data for reproducing the generated, trained learning model M<b>2</b>, and stores the generated learning result data into an arbitrary storage region. Similarly to the above-described learning processing unit <b>353</b>, the learning processing unit <b>383</b> may execute machine learning of the learning model M<b>2</b> by referring to an associated user identifier and using a plurality of data sets DS that have been collected in correspondence with the specific user. Also, in generating the trained learning model M<b>2</b> for a specific user, a data set DS corresponding to another user may be arbitrarily used in machine learning, in addition to the data set DS corresponding to the specific user.</p><p id="p-0112" num="0111">Similarly to the above-described model distribution unit <b>354</b>, the model distribution unit <b>384</b> is configured to distribute the trained learning model M<b>2</b> to a user by transmitting the learning result data generated by the learning processing unit <b>383</b> to the information processing apparatus <b>200</b>. The model distribution unit <b>384</b> may be configured to, in a case where the trained learning model M<b>2</b> has been generated for a specific user, distribute the learning result data (trained learning model M<b>2</b>) corresponding to the information processing apparatus <b>200</b> of a user specified by a user identifier.</p><p id="p-0113" num="0112">(Machine Learning of Learning Model)</p><p id="p-0114" num="0113">Through a processing procedure similar to that of the above-described first embodiment, the information processing system S according to the second embodiment generates a trained learning model M<b>2</b>, and distributes the generated, trained learning model M<b>2</b> to the information processing apparatus <b>200</b>.</p><p id="p-0115" num="0114">Before the execution of learning processing, the CPU <b>301</b> of the server <b>300</b> collects first performance information A<b>1</b> in the electronic musical instrument <b>100</b> via the information processing apparatus <b>200</b>. Also, the CPU <b>301</b> collects characteristics information C corresponding to the first performance information A<b>1</b> (or the values of parameters P<b>2</b> specified by the characteristics information C). The collected various types of data are stored into the storage unit <b>360</b> in association with one another. The various types of data may be associated with a user identifier. When executing learning processing, the CPU <b>301</b> generates a plurality of data sets DS with use of various types of data accumulated in the storage unit <b>360</b>.</p><p id="p-0116" num="0115">In step S<b>610</b>, the CPU <b>301</b> operates as the data preprocessing unit <b>382</b>, and executes data preprocessing with respect to first performance information A<b>1</b> of each data set DS.</p><p id="p-0117" num="0116">In step S<b>620</b>, the CPU <b>301</b> operates as the learning processing unit <b>383</b>, and executes machine learning of the learning model M<b>2</b> by using the first performance information A<b>1</b> of each data set DS after the data preprocessing as training data, and using corresponding correct answer information L<b>1</b> as supervisory signals. Specifically, the CPU <b>301</b> trains the learning model M<b>2</b> (adjusts the values of calculation parameters that compose the learning model M<b>2</b>) so that, for each data set DS, the result of inferring assist information from the first performance information A<b>1</b> after the data preprocessing with use of the learning model M<b>2</b> conforms to corresponding correct answer information L<b>1</b>. As a result of this machine learning, the trained learning model M<b>2</b> can be generated that has gained the capability to infer, from the performance information A, assist information (characteristics information or values of parameters) related to parameters P<b>2</b> of the electronic musical instrument <b>100</b> that conform to the performance tendency presented by the performance information A. The CPU <b>301</b> may generate learning result data indicating the trained learning model M<b>2</b>, and store the generated learning result data into the storage unit <b>360</b>.</p><p id="p-0118" num="0117">In step S<b>630</b>, the CPU <b>301</b> transmits the learning result data indicating the generated, trained learning model M<b>2</b> to the information processing apparatus <b>200</b> via the network NW. In this way, the server <b>300</b> distributes the trained learning model M<b>2</b> to the information processing apparatus <b>200</b>. The CPU <b>201</b> of the information processing apparatus <b>200</b> stores the received learning model M<b>2</b> (learning result data) into the storage unit <b>260</b>. This concludes the processing procedure related to machine learning of the learning model M<b>2</b> according to the present example of operations.</p><p id="p-0119" num="0118">(Parameter Inference Processing)</p><p id="p-0120" num="0119"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a sequence diagram showing one example of a processing procedure related to inference of parameters in the information processing system S according to the second embodiment. The following processing procedure is one example of a parameter inference method. Note that regarding the following processing procedure, steps can be omitted, replaced, and added as appropriate in accordance with an embodiment.</p><p id="p-0121" num="0120">In step S<b>910</b>, the CPU <b>201</b> of the information processing apparatus <b>200</b> operates as the performance reception unit <b>252</b>, and obtains second performance information A<b>2</b> that indicates a performance of music using the electronic musical instrument <b>100</b>. Similarly to the above-described first embodiment, the CPU <b>201</b> may receive, from the electronic musical instrument <b>100</b>, second performance information A<b>2</b> obtained by the performance obtainment unit <b>151</b>. Alternatively, the CPU <b>201</b> may read out the second performance information A<b>2</b> from the storage unit <b>260</b>. The CPU <b>201</b> supplies the data preprocessing unit <b>284</b> with the obtained second performance information A<b>2</b>.</p><p id="p-0122" num="0121">In step S<b>920</b>, the CPU <b>201</b> operates as the data preprocessing unit <b>284</b>, and executes data preprocessing with respect to the second performance information A<b>2</b> supplied from the performance reception unit <b>252</b>. Then, the CPU <b>201</b> supplies the inference processing unit <b>285</b> with the second performance information A<b>2</b> after the data preprocessing.</p><p id="p-0123" num="0122">In step S<b>930</b>, the CPU <b>201</b> operates as the inference processing unit <b>285</b>, and infers assist information related to parameters P<b>2</b> of the electronic musical instrument <b>100</b> that conform to the performance tendency from the second performance information A<b>2</b> with use of the trained learning model M<b>2</b> generated through the above-described machine learning. The CPU <b>201</b> sets the trained learning model M<b>2</b> with reference to learning result data stored in the storage unit <b>260</b>. The CPU <b>201</b> inputs the preprocessed second performance information A<b>2</b> to the trained learning model M<b>2</b>, and executes calculation processing for the trained learning model M<b>2</b>. The CPU <b>201</b> obtains an output corresponding to the result of inferring the assist information from the trained learning model M<b>2</b> as a result of this calculation processing. The CPU <b>201</b> supplies the display control unit <b>286</b> with the result of inferring the assist information.</p><p id="p-0124" num="0123">In step S<b>940</b>, the CPU <b>201</b> operates as the display control unit <b>286</b>, and controls the contents displayed on the input/output unit <b>204</b> in the above-described manner based on the assist information inferred through the processing of step S<b>930</b>. As one example, the CPU <b>201</b> may obtain advertisement information that conforms to the inferred assist information related to the parameters P<b>2</b>, and display the obtained advertisement information with use of the input/output unit <b>204</b>. Also, the CPU <b>201</b> may adjust an operation screen that is displayed on the information processing apparatus <b>200</b> for a user of the electronic musical instrument <b>100</b> based on the result of inferring the assist information.</p><p id="p-0125" num="0124">(Features)</p><p id="p-0126" num="0125">According to the second embodiment, by using the trained learning model M<b>2</b>, the contents displayed on a display apparatus (in the present embodiment, the input/output unit <b>204</b>) can be controlled so as to display information that conforms to the user's tendency in a performance (e.g., advertisement information, the operation screen, and so on). This can alleviate the effort required to present information that suits the characteristics of the user's performance.</p><p id="p-0127" num="0126">Also, according to the second embodiment, the trained learning model M<b>2</b> can be generated for each user identified by a user identifier, and the generated, trained learning model M<b>2</b> can be provided to the information processing apparatus <b>200</b> of each user, similarly to the above-described first embodiment. A user can keep using the trained learning model M<b>2</b> for inferring parameters P<b>2</b> that conform to his/her own tendency in a performance, even if at least one of the electronic musical instrument <b>100</b> and the information processing apparatus <b>200</b> is replaced.</p><heading id="h-0017" level="1">Modification Examples</heading><p id="p-0128" num="0127">Although the embodiments of the present invention have been described in detail thus far, the foregoing description is merely an exemplary illustration of the present invention in any aspect. It goes without saying that various improvements or modifications can be made without departing from the scope of the present invention. For example, the following changes can be made. Note that the following modification examples can be combined as appropriate.</p><p id="p-0129" num="0128">In the machine learning processing and the inference processing of the above-described embodiments, information other than performance information A may be further input to each of the above-described learning models (M<b>1</b>, M<b>2</b>) as input data. As another example, each of the above-described learning models (M<b>1</b>, M<b>2</b>) may be configured to accept an input of, in addition to the above-described performance information A, accompanying information that indicates an accompanying operation for a music performance using the electronic musical instrument <b>100</b> (e.g., a pedal operation on an electronic piano, an effecter operation on an electric guitar, and so on). Accordingly, each of the above-described data sets DS may further include accompanying information that is used as training data. The obtainment of the second performance information A<b>2</b> may include a further obtainment of accompanying information that indicates an accompanying operation on the electronic musical instrument <b>100</b> in a music performance, in addition to second performance information A<b>2</b>. The inference may be composed of inference of assist information related to the settings of parameters of the electronic musical instrument <b>100</b> that conform to the performance tendency from second performance information A<b>2</b> and accompanying information with use of the trained learning model (M<b>1</b>, M<b>2</b>). By further using accompanying information as an explanatory variable, the improvement in the accuracy of inference of the parameter settings that conform to the user's tendency in a performance can be expected.</p><p id="p-0130" num="0129">In the above-described embodiments, the trained learning model (M<b>1</b>, M<b>2</b>) generated by the server <b>300</b> is provided to the information processing apparatus <b>200</b> and used in inference processing on the information processing apparatus <b>200</b>. However, a computer that executes inference processing is not limited to the information processing apparatus <b>200</b>. As another example, the trained learning model (M<b>1</b>, M<b>2</b>) may be provided from the server <b>300</b> to the electronic musical instrument <b>100</b> via the information processing apparatus <b>200</b>. In this case, the control unit <b>150</b> of the electronic musical instrument <b>100</b> may include software modules that correspond to the data preprocessing unit <b>254</b>, the inference processing unit <b>255</b>, and the adjustment unit <b>256</b> (or the display control unit <b>286</b>) of the information processing apparatus <b>200</b>. According to the present modification example, the electronic musical instrument <b>100</b> itself can execute inference processing based on the learning model (M<b>1</b>, M<b>2</b>) that uses performance information A as input data.</p><p id="p-0131" num="0130">In the above-described embodiments, performance information A is generated by the performance operation unit <b>104</b> that accepts a user operation in a music performance. However, the method and configuration for generating performance information A need not be limited to this example. In another example, the electronic musical instrument <b>100</b> may include a performance analysis unit, either in place of the performance operation unit <b>104</b>, or together with the performance operation unit <b>104</b>. The performance analysis unit may be configured, as appropriate, to generate performance information A by accepting an input of audio information and analyzing the input audio information with use of an arbitrary method (e.g., pitch analysis and audio analysis). The performance analysis unit may be provided in the information processing apparatus <b>200</b>.</p><p id="p-0132" num="0131">In the above-described embodiments, instruction information B is generated by the instruction obtainment unit <b>253</b> of the information processing apparatus <b>200</b> in accordance with the user's instruction operation on the input/output unit <b>204</b>. However, the method and configuration for generating instruction information B need not be limited to this example. In another example, the control unit <b>150</b> of the electronic musical instrument <b>100</b> may include a software module that corresponds to the instruction obtainment unit <b>253</b>, and instruction information B may be generated in accordance with the user's setting operation on the setting operation unit <b>105</b>.</p><p id="p-0133" num="0132">In the above-described first embodiment, processing for confirming with a user in steps S<b>740</b> to S<b>760</b> may be omitted. That is to say, after the result of inferring assist information has been obtained, the information processing apparatus <b>200</b> may automatically transmit, to the electronic musical instrument <b>100</b> (parameter setting unit <b>152</b>), an instruction for setting parameters P<b>1</b> based on the inferred assist information with use of the adjustment unit <b>256</b>. According to the present modification, the effort that a user makes in a confirmation task can be alleviated. On the other hand, the inferred values of parameters P<b>1</b> do not always conform to the user's preference. According to the configuration of the above-described first embodiment that executes processing of steps S<b>740</b> to S<b>760</b>, a change in the settings of parameters P<b>1</b> that does not conform to the user's preference can be suppressed.</p><p id="p-0134" num="0133">The setting of parameters after the aforementioned confirmation processing and the automatic setting of parameters may be used in combination. As one example, regarding the parameters P<b>1</b> to be adjusted, a change in parameters that are easily recognized by a user (e.g., a change in the types of tones and the like) may be made after confirming the user's permission or denial as per the above-described first embodiment, whereas a change in parameters that are difficult for the user to recognize (e.g., an adjustment of a touch curve and the like) may be automatically made.</p><p id="p-0135" num="0134">In the configuration of the above-described second embodiment, the information processing apparatus <b>200</b> may include the adjustment unit <b>256</b> of the above-described first embodiment, and the adjustment unit <b>256</b> may be configured to adjust parameters P<b>1</b> of the electronic musical instrument <b>100</b> based on parameters P<b>2</b> specified by assist information inferred by the inference processing unit <b>285</b>. The adjustment unit <b>256</b> may be configured to, in a case where parameters P<b>2</b> are related to a music genre, transmit an instruction for setting the values of parameters P<b>1</b> indicating the tones that conform to a genre on the sound source unit <b>107</b> to the electronic musical instrument <b>100</b> (parameter setting unit <b>152</b>). The adjustment unit <b>256</b> may be configured to, in a case where parameters P<b>2</b> are related to the degree of proficiency of a user, transmit an instruction for setting the values of parameters P<b>1</b> indicating a touch curve that conforms to the degree of proficiency on the sound source unit <b>107</b> to the electronic musical instrument <b>100</b> (parameter setting unit <b>152</b>).</p><p id="p-0136" num="0135">Note that each of the above-described storage mediums (<b>92</b>, <b>93</b>) may be composed of a non-transitory computer-readable recording medium. Also, the programs (<b>82</b>, <b>83</b>) may be supplied via a transmission medium and the like. Note that in a case where, for example, the programs are transmitted via a communication network, such as the Internet and a telephone line, the &#x201c;non-transitory computer-readable recording medium&#x201d; may include, for example, a recording medium that holds the programs for a certain period of time, such as a volatile memory inside a computer system that composes a server, a client, and the like (e.g., a DRAM (Dynamic Random Access Memory)).</p><heading id="h-0018" level="1">LIST OF REFERENCE NUMERALS</heading><p id="p-0137" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0136"><b>100</b> electronic musical instrument</li>        <li id="ul0002-0002" num="0137"><b>150</b> control unit</li>        <li id="ul0002-0003" num="0138"><b>160</b> storage unit</li>        <li id="ul0002-0004" num="0139"><b>200</b> information processing apparatus</li>        <li id="ul0002-0005" num="0140"><b>250</b> control unit</li>        <li id="ul0002-0006" num="0141"><b>260</b> storage unit</li>        <li id="ul0002-0007" num="0142"><b>300</b> server</li>        <li id="ul0002-0008" num="0143"><b>350</b> control unit</li>        <li id="ul0002-0009" num="0144"><b>360</b> storage unit</li>        <li id="ul0002-0010" num="0145">A performance information</li>        <li id="ul0002-0011" num="0146">A<b>1</b> first performance information</li>        <li id="ul0002-0012" num="0147">A<b>2</b> second performance information</li>        <li id="ul0002-0013" num="0148">B instruction information</li>        <li id="ul0002-0014" num="0149">M<b>1</b> learning model</li>        <li id="ul0002-0015" num="0150">M<b>2</b> learning model</li>        <li id="ul0002-0016" num="0151">P<b>1</b> parameter</li>        <li id="ul0002-0017" num="0152">P<b>2</b> parameter</li>        <li id="ul0002-0018" num="0153">S information processing system</li>    </ul>    </li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>We claim:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A parameter inference method realized by a computer, the parameter inference method comprising:<claim-text>obtaining target performance information indicating a performance of music using an electronic musical instrument;</claim-text><claim-text>inferring assist information from the target performance information with use of a trained inference model generated through machine learning, the assist information being related to setting of a parameter of the electronic musical instrument that conforms to a tendency of the performance; and</claim-text><claim-text>outputting the inferred assist information related to the setting of the parameter.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The parameter inference method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the obtaining of the target performance information comprises obtaining accompanying information in addition to the target performance information, the accompanying information indicating an accompanying operation on the electronic musical instrument in the performance of the music, and</claim-text><claim-text>the inferring comprises inferring, from the target performance information and the accompanying information, the assist information related to the setting of the parameter of the electronic musical instrument that conforms to the tendency of the performance with use of the trained inference model.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The parameter inference method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the assist information related to the setting of the parameter includes information related to setting a tone in the performance.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The parameter inference method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the outputting of the inferred assist information comprises obtaining advertisement information that conforms to the inferred assist information related to the setting of the parameter, and outputting the obtained advertisement information.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The parameter inference method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the outputting of the inferred assist information comprises adjusting an operation screen of the electronic musical instrument based on the inferred assist information related to the setting of the parameter.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. A parameter inference system, comprising:<claim-text>a processor; and</claim-text><claim-text>a memory configured to hold a program executed by the processor,</claim-text><claim-text>wherein</claim-text><claim-text>the processor is configured to execute the program to:<claim-text>obtain target performance information indicating a performance of music using an electronic musical instrument,</claim-text><claim-text>infer assist information from the target performance information with use of a trained inference model generated through machine learning, the assist information being related to setting of a parameter of the electronic musical instrument that conforms to a tendency of the performance, and</claim-text><claim-text>output the inferred assist information related to the setting of the parameter.</claim-text></claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The parameter inference system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein<claim-text>the processor is configured to execute the program to:</claim-text><claim-text>obtain the target performance information by obtaining accompanying information in addition to the target performance information, the accompanying information indicating an accompanying operation on the electronic musical instrument in the performance of the music, and</claim-text><claim-text>infer the assist information related to the setting of the parameter of the electronic musical instrument that conforms to the tendency of the performance from the target performance information and the accompanying information with use of the trained inference model.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The parameter inference system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein<claim-text>the assist information related to the setting of the parameter includes information related to setting of a tone in the performance.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The parameter inference system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein<claim-text>the processor is configured to execute the program to:</claim-text><claim-text>output the assist information by obtaining advertisement information that conforms to the inferred assist information related to the setting of the parameter, and outputting the obtained advertisement information.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The parameter inference system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein<claim-text>the processor is configured to execute the program to:</claim-text><claim-text>output the assist information by adjusting an operation screen of the electronic musical instrument based on the inferred assist information related to the setting of the parameter.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A non-transitory computer readable medium having stored thereon a parameter inference program that, when executed by a computer, cause the computer to execute processing comprising:<claim-text>obtaining target performance information indicating a performance of music using an electronic musical instrument;</claim-text><claim-text>inferring assist information from the target performance information with use of a trained inference model generated through machine learning, the assist information being related to setting of a parameter of the electronic musical instrument that conforms to a tendency of the performance; and</claim-text><claim-text>outputting the inferred assist information related to the setting of the parameter.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The parameter inference method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the assist information related to the setting of the parameter includes information related to setting a tone in the performance.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The parameter inference method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the outputting of the inferred assist information comprises obtaining advertisement information that conforms to the inferred assist information related to the setting of the parameter, and outputting the obtained advertisement information.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The parameter inference method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the outputting of the inferred assist information comprises adjusting an operation screen of the electronic musical instrument based on the inferred assist information related to the setting of the parameter.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The parameter inference method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein<claim-text>the outputting of the inferred assist information comprises obtaining advertisement information that conforms to the inferred assist information related to the setting of the parameter, and outputting the obtained advertisement information.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The parameter inference method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein<claim-text>the outputting of the inferred assist information comprises adjusting an operation screen of the electronic musical instrument based on the inferred assist information related to the setting of the parameter.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The parameter inference method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein<claim-text>the outputting of the inferred assist information comprises adjusting an operation screen of the electronic musical instrument based on the inferred assist information related to the setting of the parameter.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The parameter inference system according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein<claim-text>the assist information related to the setting of the parameter includes information related to setting of a tone in the performance.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The parameter inference system according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein<claim-text>the processor is configured to execute the program to:</claim-text><claim-text>output the assist information by obtaining advertisement information that conforms to the inferred assist information related to the setting of the parameter, and outputting the obtained advertisement information.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The parameter inference system according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein<claim-text>the processor is configured to execute the program to:</claim-text><claim-text>output the assist information by adjusting an operation screen of the electronic musical instrument based on the inferred assist information related to the setting of the parameter.</claim-text></claim-text></claim></claims></us-patent-application>
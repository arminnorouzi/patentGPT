<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005276A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005276</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17738353</doc-number><date>20220506</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2021-110557</doc-number><date>20210702</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>20</main-group><subgroup>58</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>24</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>20</main-group><subgroup>584</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>243</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30252</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">SIGNAL RECOGNIZING APPARATUS</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>TOYOTA JIDOSHA KABUSHIKI KAISHA</orgname><address><city>Toyota-shi</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>SAITO</last-name><first-name>Hiroki</first-name><address><city>Sunto-gun</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>TOYOTA JIDOSHA KABUSHIKI KAISHA</orgname><role>03</role><address><city>Toyota-shi</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A signal recognizing apparatus detects a target traffic light from an image showing surroundings of a host vehicle and generates traffic light detecting information including a traffic light image. The apparatus recognizes a lighting state of the target traffic light and specifies a positional relationship between the host vehicle and the target traffic light on the basis of position information of the host vehicle and the traffic light detecting information, and determines a center of a lighting area corresponding to a lighting portion of the target traffic light in the traffic light image, and performs a predetermined conversion process on the traffic light image on the basis of the positional relationship in order to compare with the lighting pattern information, and recognizes the lighting state by comparing the center of the lighting area in a traffic light image with the lighting pattern information.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="90.85mm" wi="52.15mm" file="US20230005276A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="203.88mm" wi="142.83mm" file="US20230005276A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="140.55mm" wi="146.56mm" file="US20230005276A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="182.20mm" wi="76.88mm" file="US20230005276A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is based upon and claims the benefit of priority of the prior Japanese Patent Application No. 2021-110557, filed on Jul. 2, 2021, the entire contents of which are incorporated herein by reference.</p><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">1. Technical Field</heading><p id="p-0003" num="0002">The present invention relates to a technical field of a signal recognizing apparatus for recognizing a signal from an image.</p><heading id="h-0004" level="1">2. Description of the Related Art</heading><p id="p-0004" num="0003">As this type of apparatus, for example, it has been proposed that an apparatus recognizes the lighting state of a traffic light by comparing an image of the traffic light with a lighting pattern information of the traffic light (see JP2021-002275A as Patent Literature 1).</p><p id="p-0005" num="0004">There is room for improvement in the technique described in Patent Document 1.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0006" num="0005">The present disclosure has been made in view of the above circumstances, and an object thereof is to provide a signal recognizing apparatus capable of recognizing the lighting state of the traffic light.</p><p id="p-0007" num="0006">A signal recognizing apparatus according to an aspect of the present disclosure is that signal recognizing apparatus, which comprises a detector configured to detect a target traffic light from an image showing surroundings of a host vehicle and generate traffic light detecting information including a traffic light image showing an appearance of the target traffic light, and a recognizer configured to recognize a lighting state of the target traffic light by comparing the traffic light detecting information and lighting pattern information of the target traffic light, further comprising: a specifier configured to specify a positional relationship between the host vehicle and the target traffic light on the basis of position information of the host vehicle and the traffic light detecting information; a determinator configured to determine a center of a lighting area corresponding to a lighting portion of the target traffic light in the traffic light image; and an image convertor configured to perform a predetermined conversion process on the traffic light image on the basis of the positional relationship in order to compare with the lighting pattern information, wherein the recognizing device recognizes the lighting state by comparing the center of the lighting area in a traffic light image, which is performed by the predetermined conversion process, with the lighting pattern information.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a diagram showing a configuration of a vehicle according to the embodiment.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a flowchart showing the operation of the recognition processing unit according to the embodiment.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a diagram showing an example of a lighting pattern information.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> illustrates a diagram for explaining a concept of an image conversion process according to the embodiment.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> illustrates a diagram for explaining a concept of an image conversion process according to the embodiment.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>4</b>C</figref> illustrates a diagram for explaining a concept of an image conversion process according to the embodiment.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b>D</figref> illustrates a diagram for explaining a concept of an image conversion process according to the embodiment.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>4</b>E</figref> illustrates a diagram for explaining a concept of an image conversion process according to the embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION OF THE EMBODIMENT</heading><p id="p-0016" num="0015">An embodiment of the signal recognizing apparatus will be described with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>3</b></figref>. Here, a signal recognizing apparatus is mounted on the vehicle <b>1</b>. In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the vehicle <b>1</b> includes the camera <b>10</b>, the recording device <b>20</b>, the self-position sensor <b>30</b>, and the recognition processing unit <b>100</b>. The recognition processing unit <b>100</b> corresponds to a specific example of the signal recognizing apparatus according to the embodiment.</p><p id="p-0017" num="0016">The camera <b>10</b>, for example, is capable of imaging the front of the vehicle <b>1</b> through the front window. The recording device <b>20</b> may be constituted by, for example, a nonvolatile memory, a hard disk drive, or the like. The self-position sensor <b>30</b> is configured to be able to acquire position information indicating the position and orientation of the vehicle <b>1</b>. Since various existing aspects can be applied to the camera <b>10</b>, the recording device <b>20</b>, and the self-position sensor <b>30</b>, a description thereof will be omitted.</p><p id="p-0018" num="0017">The recognition processing unit <b>100</b> includes the detecting unit <b>110</b>, the specifying unit <b>120</b>, the determining unit <b>130</b>, the image converting unit <b>140</b> and the recognizing unit <b>150</b>. The detecting unit <b>110</b>, the specifying unit <b>120</b>, the determining unit <b>130</b>, the image converting unit <b>140</b> and the recognizing unit <b>150</b> may be logically implemented as, for example, a logic block. Alternatively, the detecting unit <b>110</b>, the specifying unit <b>120</b>, the determining unit <b>130</b>, the image converting unit <b>140</b> and the recognizing unit <b>150</b> may be physically implemented as, for example, a processing circuit.</p><p id="p-0019" num="0018">In addition to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the recognition processing unit <b>100</b> will be described with reference to a flowchart in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the recognition processing unit <b>100</b> acquires an image captured by the camera <b>10</b> (step S<b>101</b>).</p><p id="p-0020" num="0019">Next, the detecting unit <b>110</b> of the recognition processing unit <b>100</b> detects the traffic light around the vehicle <b>1</b> from the image captured by the camera <b>10</b>. Here, since various existing aspects can be applicable to the method of detecting the traffic light from the image, a description thereof will be omitted. The traffic light detected by the detecting unit <b>110</b> is hereinafter referred to as &#x201c;target traffic light&#x201d;. Incidentally, when a plurality of traffic lights from the image is detected, the detecting unit <b>110</b>, for example, is present in the traveling direction front of the vehicle <b>1</b>, and the traffic light closest to the vehicle <b>1</b> may be referred to as the target traffic light.</p><p id="p-0021" num="0020">The detecting unit <b>110</b> generates traffic light detection information including an image showing the appearance of the target traffic light. Consequently, the recognition processing unit <b>100</b> acquires the traffic light detecting information (step S<b>102</b>). The traffic light detection information may include, for example, information indicating the type and shape of the target traffic light. The traffic light detection information may include, for example, information indicating the color of the light of the target traffic light. The traffic light detection information may include, for example, information indicating the position of the target traffic light with respect to the vehicle <b>1</b>.</p><p id="p-0022" num="0021">The recognizing unit <b>150</b> of the recognition processing unit <b>100</b> selects the lighting pattern information (step S<b>103</b>). For example, the lighting pattern information may be recorded in the recording device <b>20</b>. In this case, the recognizing unit <b>150</b> may acquire the lighting pattern information from the recording device <b>20</b>. For example, lighting pattern information may be recorded in a device external to the vehicle <b>1</b>. In this case, the recognizing unit <b>150</b> may acquire the lighting pattern information from an external device.</p><p id="p-0023" num="0022">Here, the lighting pattern information is information indicating the pattern of the light part of the traffic light. &#x201c;Light part&#x201d; means a light emitting portion of a traffic light. The traffic light has multiple light parts. Each light part shall be turned on or off according to the operation status of the traffic light.</p><p id="p-0024" num="0023">The lighting pattern information may include information indicative of the arrangement of the plurality of light parts. The lighting pattern information may include information indicative of the appearance of each of the plurality of light parts. The information indicating the appearance may include information indicating the col or and shape of each light part (e.g., circles, arrows, etc.). The lighting pattern information may include information indicative of the relative positional relationship between the plurality of light parts.</p><p id="p-0025" num="0024">A specific example of the lighting pattern information will be described with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, which shows the lighting pattern information of a traffic light having six light parts. Light parts L<b>1</b> to L<b>3</b> are parts corresponding to circular traffic lights. Light parts L<b>1</b> to L<b>3</b> are arranged horizontally at the upper stage. Light parts L<b>4</b> to L<b>6</b> are parts corresponding to arrow traffic lights. Light parts L<b>4</b> to L<b>6</b> are arranged horizontally at the lower stage. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the light parts L<b>1</b> and L<b>4</b> are adjacent in the vertical direction. The light parts L<b>2</b> and L<b>5</b> are adjacent in the vertical direction. The light parts L<b>3</b> and L<b>6</b> are adjacent in the vertical direction.</p><p id="p-0026" num="0025">When lit, the appearance in lighting of the light part L<b>1</b> is a blue circle. The appearance in lighting of the light part L<b>2</b> is a yellow circle. The appearance in lighting of the light part L<b>3</b> is a red circle. The appearance in lighting of the light part L<b>4</b> is a blue left-hand arrow. The appearance in lighting of the light part L<b>5</b> is a blue upper arrow. The appearance in lighting of the light part L<b>6</b> is a blue right-hand arrow. When not lit, the color of each of the light parts L<b>1</b> to L<b>6</b> in non-lighting is black. In addition, the color of the light part in non-lighting (i.e., when not lit) may not be specified in the lighting pattern information.</p><p id="p-0027" num="0026">A plurality of types of lighting pattern information may be prepared in advance so that the lighting pattern information can correspond to various types of traffic lights. For example, the lighting pattern information in which the light part corresponding to the circular traffic light is arranged vertically may be provided. For example, as a light part corresponding to the arrow traffic light, the lighting pattern information having only the right arrow traffic light (corresponding to the light p art L<b>6</b> in <figref idref="DRAWINGS">FIG. <b>3</b></figref>) may be prepared.</p><p id="p-0028" num="0027">In parallel with the processing of the step S<b>103</b>, the processing of the step S<b>104</b> described below is performed. The specifying unit <b>120</b> of the recognition processing unit <b>100</b> specifies the positional relationship between the vehicle <b>1</b> and the target traffic light. Specifically, the specifying unit <b>120</b> first acquires the position information acquired by the self-position sensor <b>30</b> and the map information. Here, the map information may be a map information showing a planar (i.e., two-dimensional) map, or may be a high-precision three-dimensional map information. When the map information is high-precision three-dimensional map information, the specifying unit <b>120</b> may acquire the map information from an external device, for example, via a network.</p><p id="p-0029" num="0028">The specifying unit <b>120</b> then identifies (or estimates) the position of the target traffic light from the position and the map information of the vehicle <b>1</b> indicated by the position information. The position of the target traffic light identified at this time may be an absolute position (or absolute coordinates). The specifying unit <b>120</b> identifies (or estimates) the inclination of the surface including the light part (or the light emitting portion) of the target traffic light with respect to the vehicle <b>1</b> from the position and orientation of the vehicle <b>1</b> indicated by the position information and the position of the specific target traffic light.</p><p id="p-0030" num="0029">The determining unit <b>130</b> of the recognition processing unit <b>100</b>, from an image showing the appearance of the target traffic light included in the traffic light detection information, detects a lighting area corresponding to the portion (hereinafter, appropriately referred to as &#x201c;lighting portion&#x201d;) which is lighting out of the light parts of the target traffic light. The determining unit <b>130</b> determines the center of the detected lighting area. When there is a plurality of light areas, the determining unit <b>130</b> determines the center of each lighting area. The determining unit <b>130</b> may determine the center of the lighting area on the basis of the luminance value according to the lighting area, for example. In this case, the determining unit <b>130</b> may determine the center of the lighting area on the basis of the brightness value, which may be the maximum pixel. Alternatively, the determining unit <b>130</b> may determine the center of the lighting area on the basis of, for example, the size of the lighting area (e.g., width and height).</p><p id="p-0031" num="0030">Here, the operation of the determining unit <b>130</b> will be described with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. For example, at night, when a traffic light is imaged by the camera <b>10</b>, flare may occur because the light of the traffic light (i.e., the light of the lighting light part) is relatively strong. Then, for example, as shown in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>, the region corresponding to the light of the traffic light in the image (see shaded portion) may be larger than the size of the lighting light part.</p><p id="p-0032" num="0031">The determining unit <b>130</b>, for example, in order to reduce the influence of the flare, determines the center of the lighting area described above. For example, the shaded portion in the image shown in <figref idref="DRAWINGS">FIG. <b>4</b>B</figref> corresponds to the center of the lighting area determined by the determining unit <b>130</b>.</p><p id="p-0033" num="0032">The image converting unit <b>140</b> of the recognition processing unit <b>100</b> performs image conversion processing on an image indicating the appearance of the target traffic light on the basis of the inclination of the surface including the light part of the target traffic light specified by the specifying unit <b>120</b> with respect to the vehicle <b>1</b>. Specifically, the image converting unit <b>140</b>, so as to be able to compare the image and the light pattern indicating the appearance of the target traffic light, as an image conversion process, for example, the angle conversion of the image indicating the appearance of the target traffic light.</p><p id="p-0034" num="0033">As a result, an image captured from a position inclined with respect to the front of the target traffic light (see <figref idref="DRAWINGS">FIG. <b>4</b>C</figref>), for example, can be converted to an image captured from the front of the target traffic light (see <figref idref="DRAWINGS">FIG. <b>4</b>D</figref>). Incidentally, since various existing aspects can be applied to the image conversion process, a description thereof will be omitted.</p><p id="p-0035" num="0034">Thereafter, the recognizing unit <b>150</b> recognizes the lighting state of the target traffic light (step S<b>105</b>). Specifically, the recognizing unit <b>150</b> extracts a predetermined area including the target traffic light (e.g., an area surrounded by a dotted line frame in <figref idref="DRAWINGS">FIG. <b>4</b>E</figref>) from the image to which the image conversion process is performed in the processing of the step S<b>104</b>. The recognizing unit <b>150</b> compares the center of the lighting area in the extracted area with the lighting pattern information selected in the process of the step S<b>103</b>.</p><p id="p-0036" num="0035">The recognizing unit <b>150</b>, for example, as shown in the image of <figref idref="DRAWINGS">FIGS. <b>4</b>A-<b>4</b>E</figref>, recognizes the light parts L<b>3</b> and L<b>4</b> (see <figref idref="DRAWINGS">FIG. <b>3</b></figref>) are turned on, and the light parts L<b>1</b>, L<b>2</b>, L<b>5</b> and L<b>6</b> (see <figref idref="DRAWINGS">FIG. <b>3</b></figref>) are turned off. That is, the recognizing unit <b>150</b> recognizes that the red circular traffic light and the blue left arrow traffic light is lit up.</p><p id="p-0037" num="0036">Thereafter, the recognition processing unit <b>100</b> generates the recognition result information indicating the lighting state recognized by the recognizing unit <b>150</b> (step S<b>106</b>). The recognition result information may be utilized for, for example, a red traffic light alerting function for notifying a red traffic light to the driver of the vehicle <b>1</b>, a deceleration support function for automatically decelerating the vehicle <b>1</b> when it is a red traffic light, or the like.</p><heading id="h-0008" level="1">Technical Effects</heading><p id="p-0038" num="0037">For example, when recognizing the lighting state of the traffic light from an image captured by a camera such as the camera <b>10</b>, the following problems may occur. Recognition result of the lighting state of the traffic light may be utilized, for example, for driving assistance or the like. In order to appropriately implement driving support, etc., it is necessary to recognize the lighting state of the target traffic light from the image captured at a position several tens of meters away from the target traffic light. On the other hand, in the image captured at a relatively distant position from the target traffic light, for example, there is a possibility that the lighting state of the arrow traffic light is not correctly recognized. In contrast, the technique of improving the resolution of the camera is considered. However, increasing camera resolution poses a new problem of increased product cost.</p><p id="p-0039" num="0038">By comparing the image and the lighting pattern information obtained by imaging the target traffic light, the recognition processing unit <b>100</b> recognizes the lighting state of the target traffic light. According to this technique, from the image captured by the camera <b>10</b>, for example, even when the direction of the arrow of the arrow traffic light can not be recognized, it is possible to appropriately recognize the lighting state of the target traffic light. That is, with the recognition processing unit <b>100</b>, even from an image captured by a relatively low resolution camera, it is possible to appropriately recognize the lighting state of the target traffic light.</p><p id="p-0040" num="0039">Furthermore, the following problems may occur. For example, if a vehicle is running on a road with multiple lanes, a traffic light may not be located in front of the vehicle. In other words, it is not always possible to image the target traffic light from its front. Also, for example, at night, there is a possibility that flare is generated due to the light of the target traffic light. Therefore, it may be difficult to appropriately compare the image and the lighting pattern information obtained by imaging the target traffic light.</p><p id="p-0041" num="0040">In contrast, in the recognition processing unit <b>100</b> described above, together with the center of the lighting area that is determined by the determining unit <b>130</b>, the image conversion process is performed by the image converting unit <b>140</b>. Therefore, according to the recognition processing unit <b>100</b>, or when the target traffic light can not be imaged directly from its front, or even when flare occurs, it is possible to appropriately compare the image captured by the camera <b>10</b> and the lighting pattern. As a result, the recognition processing unit <b>100</b> can appropriately recognize the lighting state of the target traffic light.</p><p id="p-0042" num="0041">Aspects of the invention derived from the embodiments described above will be described below.</p><p id="p-0043" num="0042">A signal recognizing apparatus according to an aspect of the present disclosure comprises a detector configured to detect a target traffic light from an image showing surroundings of a host vehicle and generate traffic light detecting information including a traffic light image showing an appearance of the target traffic light, and a recognizer configured to recognize a lighting state of the target traffic light by comparing the traffic light detecting information and lighting pattern information of the target traffic light, further comprising: a specifier configured to specify a positional relationship between the host vehicle and the target traffic light on the basis of position information of the host vehicle and the traffic light detecting information; a determinator configured to determine a center of a lighting area corresponding to a lighting portion of the target traffic light in the traffic light image; and an image converter configured to perform a predetermined conversion process on the traffic light image on the basis of the positional relationship in order to compare with the lighting pattern information, wherein the recognizer recognizes the lighting state by comparing the center of the lighting area in a traffic light image, which is performed the predetermined conversion process, with the lighting pattern information.</p><p id="p-0044" num="0043">In the above-described embodiment, the &#x201c;recognition processing unit <b>100</b>&#x201d; corresponds to an example of the &#x201c;signal recognizing apparatus&#x201d;, the &#x201c;detecting unit <b>110</b>&#x201d; corresponds to an example of the &#x201c;detector&#x201d;, the &#x201c;recognizing unit <b>150</b>&#x201d; corresponds to an example of the &#x201c;recognizer&#x201d;, the &#x201c;specifying unit <b>120</b>&#x201d; corresponds to an example of the &#x201c;specifier&#x201d;, the &#x201c;determining unit <b>130</b>&#x201d; corresponds to an example of the &#x201c;determinator&#x201d;, and the &#x201c;image converting unit <b>140</b>&#x201d; corresponds to an example of the &#x201c;image converter&#x201d;.</p><p id="p-0045" num="0044">In the signal recognizing apparatus, the determinator may determine the center of the lighting area on the basis of the brightness value according to the lighting area. Alternatively, in the signal recognizing apparatus, the determinator may determine the center of the lighting area on the basis of the size of the lighting area.</p><p id="p-0046" num="0045">In the signal recognizing apparatus, the predetermined conversion process may include an angle conversion process on the basis of a relative angle between the host vehicle and the target traffic light indicated by the positional relationship.</p><p id="p-0047" num="0046">The present invention is not limited to the embodiments described above, but can be appropriately changed to the extent that it is not contrary to the summary or philosophy of the invention that can be read from the scope of the claims and the entire description, and a signal recognizing apparatus with such a change is also included in the technical scope of the present invention.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A signal recognizing apparatus, comprising:<claim-text>a detector configured to detect a target traffic light from an image showing surroundings of a host vehicle and generate traffic light detecting information including a traffic light image showing an appearance of the target traffic light;</claim-text><claim-text>a recognizer configured to recognize a lighting state of the target traffic light by comparing the traffic light detecting information and lighting pattern information of the target traffic light;</claim-text><claim-text>a specifier configured to specify a positional relationship between the host vehicle and the target traffic light on the basis of position information of the host vehicle and the traffic light detecting information;</claim-text><claim-text>a determinator configured to determine a center of a lighting area corresponding to a lighting portion of the target traffic light in the traffic light image; and</claim-text><claim-text>an image converter configured to perform a predetermined conversion process on the traffic light image on the basis of the positional relationship in order to compare with the lighting pattern information,</claim-text><claim-text>wherein the recognizer recognizes the lighting state by comparing the center of the lighting area in a traffic light image, which is performed the predetermined conversion process, with the lighting pattern information.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The signal recognizing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determinator determines the center of the lighting area on the basis of brightness value of the lighting area.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The signal recognizing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determinator determines the center of the lighting area on the basis of size of the lighting area.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The signal recognizing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the predetermined conversion process includes an angle conversion process on the basis of a relative angle between the host vehicle and the target traffic light indicated by the positional relationship.</claim-text></claim></claims></us-patent-application>
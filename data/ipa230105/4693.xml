<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004694A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221220" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004694</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17735884</doc-number><date>20220503</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>30</main-group><subgroup>20</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>17</main-group><subgroup>11</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>30</main-group><subgroup>20</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>17</main-group><subgroup>11</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>2111</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">LOW-DIMENSIONAL PROBABILISTIC DENSITY OF HIGH-DIMENSIONAL DATA MANIFOLD</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63210957</doc-number><date>20210615</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>THE TORONTO-DOMINION BANK</orgname><address><city>Toronto</city><country>CA</country></address></addressbook><residence><country>CA</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Ross</last-name><first-name>Brendan Leigh</first-name><address><city>Toronto</city><country>CA</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Cresswell</last-name><first-name>Jesse Cole</first-name><address><city>Toronto</city><country>CA</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A computer models a high-dimensional data with a low-dimensional manifold in conjunction with a low-dimensional base probability density. A first transform (a manifold transform) may be used to transform the high-dimensional data to a low-dimensional manifold, and a second transform (a density transform) may be used to transform the low-dimensional manifold to a low-dimensional probability distribution. To enable the model to tractably learn the manifold transformation from the high-dimensional to low-dimensional spaces, the manifold transformation includes conformal flows, which simplify the probabilistic volume transform and enables tractable learning of the transform. This may also allow the manifold transform to be jointly learned with density transform.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="86.78mm" wi="158.75mm" file="US20230004694A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="191.35mm" wi="145.63mm" orientation="landscape" file="US20230004694A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="191.69mm" wi="143.76mm" orientation="landscape" file="US20230004694A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="204.72mm" wi="146.47mm" orientation="landscape" file="US20230004694A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="197.02mm" wi="143.76mm" orientation="landscape" file="US20230004694A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="191.09mm" wi="155.70mm" orientation="landscape" file="US20230004694A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="177.38mm" wi="154.69mm" orientation="landscape" file="US20230004694A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This application claims the benefit of provisional U.S. application No. 63/210,957, filed Jun. 15, 2021, the contents of which are incorporated herein by reference in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">This disclosure relates generally to computer modeling of high-dimension data spaces, and more particularly to probabilistic modeling of the high-dimensional data in a low-dimensional space.</p><p id="p-0004" num="0003">As machine learning techniques and infrastructures become more sophisticated and increase performance on data sets, machine models are increasingly tasked with processing high-dimensional data sets and to generate new instances (also termed data points). Existing solutions struggle with effectively representing the complete range of high-dimensional data set or in doing so in a low-dimensional space (e.g., representing a manifold of the relatively higher-dimensional data in a lower-dimensional space) while simultaneously permitting effective probabilistic modeling of the data and with an approach that is actually computable (i.e., tractable). For example, while generative adversarial network (GAN) models have been used to learn to generate data in conjunction with feedback from a discriminative model, the generative model can neglect to learn how to generate certain types of content from the training data and do not model underlying probabilities. In other examples, some models like variational autoencoders (VAE) may be used to model high-dimensional data points in low-dimensional spaces without consideration of probabilistic distribution.</p><p id="p-0005" num="0004">Alternative solutions, such as normalizing flows, that do provide probabilistic information maintain the same data dimensionality and do not effectively learn complex high-dimensional spaces in which the high-dimensional data is better characterized as a manifold describable with a low-dimensional representation.</p><p id="p-0006" num="0005">As such, there is a need for an approach to tractably model data points of a high-dimensional space while accounting for a manifold of the data within the high-dimensional space while also providing effective density/probabilistic modeling.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0007" num="0006">A computer model provides an approach for describing high-dimensional data in a high-dimensional space as a manifold described by a low-dimensional space and also modeled by a probability distribution. To model the data effectively and tractably, a first transform (also termed a manifold transform) between the high-dimensional space and the low-dimensional space includes one or more conformal flows. Various conformal flows provide operations for transforming data points in the high-dimensional space to the low-dimensional space. The low-dimensional space describing the manifold of the high-dimensional space is termed a low-dimensional manifold space to designate the coordinate system in which the high-dimensional manifold is represented. The manifold transformation (as applied to data points in the high-dimensional space) describes a manifold of the high-dimensional space in the low-dimensional space as a corresponding low-dimensional manifold. To provide density estimation, a second transformation (a density transformation) transforms between the low-dimensional manifold space and a low-dimensional density space, in which a base probability distribution (e.g., a gaussian) is readily determined.</p><p id="p-0008" num="0007">The parameters of the first transformation (the manifold transformation) and the second transformation (the density transform) are learned based on training data in the high-dimensional space. After training, the model may be used to transform to and from the high-dimensional space and the base probability distribution in the low-dimensional density space. For example, a data point from the high-dimensional space may be transformed to the density space for comparison with the base distribution (e.g., to evaluate a new sample with respect to the learned probability distribution as in- or out-of-distribution) or an output of the model may be sampled by sampling a point from the base probability distribution and transforming the sampled point to the high-dimensional space as an output.</p><p id="p-0009" num="0008">By transforming between the high and low-dimensional spaces to represent the manifold of the high-dimensional space, the actual regions of data distribution in the high-dimensional space may be effectively modeled, while the transformation to the density space permits the data to also be modeled with respect to the base probability distribution. In addition, the use of conformal flows enables the transformation between high- and low-dimensional spaces to be tractable, invertible, and include multiple layers (e.g., multiple conformal operations may be sequentially applied and maintain these properties).</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a computer modeling system including components for probabilistic modeling of a high-dimensional space.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an example of data points and a learned probability density.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a high-dimensional space in which data points lie along a manifold.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows an example structure for a probabilistic computer model for modeling high-dimensional data with a manifold and probability density in low-dimensional space, according to one embodiment.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIGS. <b>5</b>A-E</figref> show example conformal flows in a two-dimensional space.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an example of a manifold and an off-manifold data point.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0016" num="0015">The figures depict various embodiments of the present invention for purposes of illustration only. One skilled in the art will readily recognize from the following discussion that alternative embodiments of the structures and methods illustrated herein may be employed without departing from the principles of the invention described herein.</p><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><heading id="h-0006" level="1">Architecture Overview</heading><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a computer modeling system <b>110</b> including components for probabilistic modeling of a high-dimensional space. The computer modeling system <b>110</b> includes computing modules and data stores for generating and using a computer model <b>160</b>. In particular, the computer model <b>160</b> is configured to represent high-dimensional data with a low-dimensional manifold and as a probability density. The probabilistic computer model <b>160</b> is trained by the training module <b>120</b> to learn parameters for a model learned probability density describing the training data of training data store <b>140</b>. Individual training data items are referred to as data points or data instances and may be represented in a &#x201c;high-dimensional&#x201d; space. The computer model <b>160</b> represents points in the high-dimensional space as a manifold in a low-dimensional space along with a probability density for the data. This enables the model to simultaneously address the appearance of the training data within a sub-region of the high-dimensional space while also enabling effective probabilistic applications for the model. To tractably convert the data from the high-dimensional space to a low-dimensional space, the model uses one or more conformal flows, which enables the transformation between high- and low-dimensional spaces to be effectively learned and allows the learning of a transformation in the low-dimensional space to a base probability density to learn the probability density with respect to the low-dimensional space. In various embodiments, these transformations are jointly learned such that the probability density and the manifold directly reflect the high-dimensional training data distribution.</p><p id="p-0018" num="0017">After training, the sampling module <b>130</b> may sample outputs from the probabilistic computer model <b>160</b> by sampling a value from a base probability density in a low-dimensional space and transforming the sampled value to an output in the high-dimensional space, enabling the model to generatively create outputs similar in structure and distribution to the data points of the training data <b>140</b>. Similarly, an inference module <b>150</b> may receive a new data point in the high-dimensional space and convert it a point with respect to the base probability density for determination of the expected frequency of the data point given the learned probability density. This may be used to determine, for example, whether the new data point may be considered &#x201c;in-distribution&#x201d; or &#x201c;out-of-distribution&#x201d; with respect to the trained probability density. Further details of each of these aspects is discussed further below.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an example of data points and a learned probability density <b>220</b>. In general, data points for which the model is trained are considered to be sampled from an unknown probability density <b>200</b>. Each of the data points <b>210</b> has a set of values in the dimensions of a high-dimensional space, and thus can be considered to represent a position in the high-dimensional space. Formally, the data points <b>210</b> may also be represented as a set of points, {x<sub>i</sub>} drawn from the unknown probability density p<sub>x</sub>*(x). The model is trained to learn a probability density p<sub>x</sub>(x) as represented by trained/learned parameters of the computer model based on the data points {x<sub>i</sub>}. In many cases, however, high-dimensional data lies on a manifold of the high-dimensional space that may be more effectively modeled when described in a low-dimensional space, such that directly learning a probability density on the high-dimensional data may prove both ineffective and require many parameters to describe in particularly high-dimensional data sets. In general, the high-dimensional space has a number of dimensions referred to as n, and the low-dimensional space has a number of dimensions referred to as m. While the concepts discussed herein may apply to situations in which the high-dimensional space is relatively higher than the low-dimensional space (e.g., m&#x3c;n), and may thus apply to dimensions of n=3 and m=2, in many cases the high-dimensional space may have tens or hundreds of thousands, or millions of dimensions, and the low-dimensional space may have fewer dimensions by an order of magnitude or more.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a high-dimensional space in which data points lie along a manifold. In this example, the high-dimensional space <b>300</b> represents image data in two dimensions. Each point of high-dimensional image data represents an image having dimensions that may have a value for each channel (e.g., 3 channels for RGB color) for each pixel across a length and width of the image. Hence, the total dimensional space for an image data point in the high-dimensional space <b>300</b> for this example is the image length times the width times the number of channels times the bit length representing the color value: L&#xd7;W&#xd7;C&#xd7;B. Stated another way, each color channel for each pixel across the image can have any value according to the bit length. In practice, however, only some portions of the complete dimensional space may be of interest and are represented in the training set. While the range of the complete high-dimensional image space can be used for any possible image, individual data sets typically describe a range across a subset of the high-dimensional space <b>300</b>. In this example, a data set of human faces include data points <b>310</b>A-C. However, many points in the image data space do not represent human faces and may have no visually meaningful information at all, such as data points <b>320</b>A-C, depicting points in the high-dimensional space that have no relation to the type of data of the human face data set. As such, while the high-dimensional data space <b>300</b> may permit a large number of possible positions of data points, in practice data sets (e.g., human faces) represent some portion of the high-dimensional space that may be characterized in fewer parameters (i.e., in lower dimensions). The region of the high-dimensional space may be described as a manifold <b>330</b> of the high-dimensional space. As discussed below, the shape of the manifold <b>330</b> in the high-dimensional space may be learned and represented in a low-dimensional space to characterize the actual positions of data points in the high-dimensional space <b>300</b>. The manifold <b>330</b> is thus learned to generally describe the &#x201c;shape&#x201d; of the data points within the high-dimensional space and may thus be considered to describe constraints on the areas in which data points exist and interactions between them. For example, a data set of human faces may generally exist in a region of possible images in which there is a nose, eyes, mouth, and the image is mostly symmetrical.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows an example structure for a probabilistic computer model for modeling high-dimensional data with a manifold and a probability density in low-dimensional space, according to one embodiment. As a general overview, the computer model performs a probability estimation with respect to a base probability density <b>400</b> in a low-dimensional density space <b>410</b> and models a probability density for a high-dimensional manifold <b>470</b> with a low-dimensional manifold density <b>440</b> in a low-dimensional manifold space <b>430</b>. The low-dimensional manifold space <b>430</b> is a space that may model a manifold of the high-dimensional data in a low-dimensional space based on the manifold transformation <b>450</b>. In addition, the low-dimensional manifold space <b>430</b>, in conjunction with a density transformation <b>420</b> from the base probability density <b>400</b>, provides a low-dimensional manifold density <b>440</b> describing density information in the low-dimensional manifold space <b>430</b>. Probability density information may be determined for the low-dimensional manifold density <b>440</b> by applying a density transformation <b>420</b> to the base probability density <b>400</b>. Similarly, the low-dimensional manifold density <b>440</b> may be changed to the high-dimensional space <b>460</b> by applying the manifold transformation <b>450</b> to the low-dimensional manifold density <b>440</b>.</p><p id="p-0022" num="0021">The individual &#x201c;spaces&#x201d; may be considered to represent different coordinate systems for which the manifold transformation <b>450</b> and density transformation <b>420</b> provide change-of-variable equations for changing coordinates with respect to one space to coordinates with respect to another space. In this sense, the low-dimensional manifold space <b>430</b> provides a bridge between 1) the low-dimensional manifold learned for the high-dimensional data and 2) the probabilistic density of the base probability density <b>400</b>. The transformations may also be referred to as &#x201c;flows&#x201d; between the different data representations in the different spaces. Considered this way, the base probability density <b>400</b> flows through the density transformation <b>420</b> and then the manifold transformation <b>450</b> to provide a probability density in the high-dimensional space within the region of the learned high-dimensional manifold <b>470</b>. As such, while the low-dimensional density space <b>410</b> may have the same number of dimensions as the low-dimensional manifold space <b>430</b>, it represents a distinct coordinate system such that a position in one space must be translated to the other via the appropriate density transformation <b>420</b> (e.g., h or h<sup>&#x2212;1</sup>). As discussed more fully below, the training data in high-dimensional space <b>460</b> and the known base probability density <b>400</b> is used to learn the respective transformations and corresponding density distributions, permitting the model to effectively model high-dimensional data probabilistically with a low-dimensional manifold.</p><p id="p-0023" num="0022">In some embodiments, the density transformation <b>420</b> and manifold transformation <b>450</b> generally apply one or more layers of operations in sequence, and in practice may be applied together without explicit designation of a low-dimensional manifold space <b>430</b>. As such, the low-dimensional manifold space <b>430</b> and the respective low-dimensional manifold density <b>440</b> may reflect an intermediate state within a general sequence of transformations between the base probability density <b>400</b> in a low-dimensional space relative to a high-dimensional space of a data set/output. The manifold transformation <b>450</b> may thus refer to a transformation (one or more functions/layers) that changes the dimensionality of the high-dimensional space to describe an embedding in a low-dimensional space, while the density transformation <b>420</b> may refer to a transformation (one or more functions/layers) that retains dimensionality between a known probability density (e.g., the base probability density <b>400</b>) and the manifold transformation <b>450</b>.</p><p id="p-0024" num="0023">In this example model structure, the computer model represents data with respect to a high-dimensional space <b>460</b>, describing the high-dimensional space in which training data exists and for which sampled outputs from the model may be generated. The high-dimensional space may also be formally referred to as <img id="CUSTOM-CHARACTER-00001" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/>. The model learns a manifold transformation <b>450</b> between a high-dimensional manifold <b>470</b> and a low-dimensional manifold density <b>440</b> in a low-dimensional manifold space <b>430</b>. The low-dimensional manifold space <b>430</b> (and its respective coordinate system) may be referred to as <img id="CUSTOM-CHARACTER-00002" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/>. The low-dimensional manifold density <b>440</b> describes the location of the high-dimensional manifold <b>470</b> with respect to the reduced dimensionality of the low-dimensional manifold space <b>430</b>.</p><p id="p-0025" num="0024">The manifold transformation <b>450</b> is includes functions g and inverse g<sup>&#x2020;</sup> for transforming between the high-dimensional space <b>460</b> and the low-dimensional manifold space <b>430</b>. The function g<sup>&#x2020;</sup> transforms points in the high-dimensional space <b>460</b> to the low-dimensional manifold space <b>430</b>: g<sup>&#x2020;</sup>: <img id="CUSTOM-CHARACTER-00003" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/>&#x2192;<img id="CUSTOM-CHARACTER-00004" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/>. The inverse function g transforms points in the low-dimensional space <b>430</b> to the high-dimensional space <b>460</b>: g: <img id="CUSTOM-CHARACTER-00005" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/>&#x2192;<img id="CUSTOM-CHARACTER-00006" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/>. The range of outputs of the manifold transformation g (a subset of the high-dimensional space <b>460</b>) is the high-dimensional manifold <b>470</b>. Stated another way, the high-dimensional manifold <b>470</b> (as learned by the transformation) is defined by the manifold transformation g applied to coordinates in the low-dimensional manifold space <b>430</b>: <img id="CUSTOM-CHARACTER-00007" he="3.22mm" wi="3.89mm" file="US20230004694A1-20230105-P00003.TIF" alt="custom-character" img-content="character" img-format="tif"/>=g (<img id="CUSTOM-CHARACTER-00008" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/>). As discussed further below, the manifold transformation <b>450</b> includes one or more conformal flows, which permit the manifold transformation to be tractable and learnable by automated training processes, along with permitting it to optionally be combined with the density transformation <b>420</b> in the training.</p><p id="p-0026" num="0025">Similarly, the low-dimensional density space <b>410</b> is also referred to as Z, with a density transformation <b>420</b> having functions h and its inverse h<sup>&#x2212;1 </sup>for transforming between the low-dimensional density space <b>410</b> and the low-dimensional manifold space <b>430</b>, with corresponding equations <img id="CUSTOM-CHARACTER-00009" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/>=h(Z) and Z=h<sup>&#x2212;1</sup>(<img id="CUSTOM-CHARACTER-00010" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/>) respectively. In particular, the low-dimensional density space <b>410</b> is the coordinate system in which the base probability density <b>400</b> may be sampled. The base probability density <b>400</b> is a known probability density, such as a Standard multivariate probability density (e.g., a Gaussian). The base probability density <b>400</b> is generally continuous, such that the probability density at a particular point may be described by a derivative. In addition, the probability of a region (e.g., a range of points) may be determined by the integral of that region with respect to the base probability density <b>400</b>. In a standard distribution centered at an origin of the low-dimensional density space, a region having a particular distance from the origin may be evaluated to determine the relative accumulated probability of the points in the distribution having that distance or less to the origin. For example, a point having a distance to the origin corresponding to a 20% accumulated probability reflects that the point is more likely than 80% of the points in the probability distribution; while a point having a distance corresponding to a 95% accumulated probability reflects that the point is less likely than that 95% of accumulated points, and more likely than only 5% of points in the distribution. In other known probability densities, the respective accumulated probability may be determined based on another metric, such as an accumulated probability relative to a mean, median, or mode of the base probability density <b>400</b>.</p><p id="p-0027" num="0026">As such, the density transformation <b>420</b> may be considered as changing the positions in the known probability density to positions of the low-dimensional manifold space <b>430</b>, such that the probability information of the base probability density <b>400</b> may be represented as a low-dimensional manifold density <b>440</b>. As one application, points may be sampled from the base probability density <b>400</b> and transformed to the low-dimensional manifold density <b>440</b> with the density transformation <b>420</b>. Similarly, points in the low-dimensional manifold density <b>440</b> may be transformed to the base probability density <b>400</b> for calculation of the respective likelihood of the point in the base probability density <b>400</b>. In some embodiments, the density transformation <b>420</b> is a bijective flow.</p><p id="p-0028" num="0027">Generally, the density transformation and the manifold transformation are invertible, continuous, and differentiable, such that the base probability density <b>400</b> may be converted forward to the respective manifolds while providing the equivalent probabilistic volume in the translated coordinate spaces. That is, the differential probabilistic volume dz of a point z in low-dimensional density space <img id="CUSTOM-CHARACTER-00011" he="3.22mm" wi="2.46mm" file="US20230004694A1-20230105-P00004.TIF" alt="custom-character" img-content="character" img-format="tif"/> should remain equivalent when converted to positions in low-dimensional manifold space <b>430</b> (<img id="CUSTOM-CHARACTER-00012" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/>) and high-dimensional space <b>460</b> (<img id="CUSTOM-CHARACTER-00013" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/>). Thus, the volume over equivalent regions across <img id="CUSTOM-CHARACTER-00014" he="3.22mm" wi="2.46mm" file="US20230004694A1-20230105-P00004.TIF" alt="custom-character" img-content="character" img-format="tif"/>, <img id="CUSTOM-CHARACTER-00015" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/>, and <img id="CUSTOM-CHARACTER-00016" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> conserve the same probabilistic value. Similarly, the transformations should be invertible such that the transformations can be learned based on the training data in the high-dimensional manifold <b>470</b>.</p><p id="p-0029" num="0028">In the discussion below, the various spaces and transformations may be referred to with reference numbers as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> or with respective symbols. Table 1 provides a correspondence table for the avoidance of ambiguity:</p><p id="p-0030" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="112pt" align="left"/><colspec colname="2" colwidth="28pt" align="center"/><colspec colname="3" colwidth="77pt" align="left"/><thead><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row><row><entry>Name</entry><entry>Ref No.</entry><entry>Symbol</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>High-dimensional space</entry><entry>460</entry><entry><img id="CUSTOM-CHARACTER-00017" he="2.46mm" wi="2.12mm" file="US20230004694A1-20230105-P00005.TIF" alt="custom-character" img-content="character" img-format="tif"/> </entry></row><row><entry>High-dimensional manifold</entry><entry>470</entry><entry><img id="CUSTOM-CHARACTER-00018" he="2.46mm" wi="2.79mm" file="US20230004694A1-20230105-P00006.TIF" alt="custom-character" img-content="character" img-format="tif"/> </entry></row><row><entry>Low-dimensional manifold space</entry><entry>430</entry><entry><img id="CUSTOM-CHARACTER-00019" he="2.46mm" wi="2.12mm" file="US20230004694A1-20230105-P00007.TIF" alt="custom-character" img-content="character" img-format="tif"/> </entry></row><row><entry>Low-dimensional density space</entry><entry>410</entry><entry><img id="CUSTOM-CHARACTER-00020" he="2.46mm" wi="1.78mm" file="US20230004694A1-20230105-P00008.TIF" alt="custom-character" img-content="character" img-format="tif"/> </entry></row><row><entry>Base probability density</entry><entry>400</entry><entry>p<sub>z</sub>( )</entry></row><row><entry>Low-dimensional manifold density</entry><entry>440</entry><entry>P<sub>u</sub>( )</entry></row><row><entry>Density Transformation</entry><entry>420</entry><entry>h: <img id="CUSTOM-CHARACTER-00021" he="2.46mm" wi="1.78mm" file="US20230004694A1-20230105-P00008.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2002;&#x2192;&#x2002;<img id="CUSTOM-CHARACTER-00022" he="2.46mm" wi="2.12mm" file="US20230004694A1-20230105-P00007.TIF" alt="custom-character" img-content="character" img-format="tif"/> </entry></row><row><entry/><entry/><entry>hr<sup>&#x2212;1</sup>: <img id="CUSTOM-CHARACTER-00023" he="2.46mm" wi="2.12mm" file="US20230004694A1-20230105-P00007.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2002;&#x2192;&#x2002;<img id="CUSTOM-CHARACTER-00024" he="2.46mm" wi="1.78mm" file="US20230004694A1-20230105-P00008.TIF" alt="custom-character" img-content="character" img-format="tif"/> </entry></row><row><entry>Manifold Transformation</entry><entry>450</entry><entry>g: <img id="CUSTOM-CHARACTER-00025" he="2.46mm" wi="2.12mm" file="US20230004694A1-20230105-P00007.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2002;&#x2192;&#x2002;<img id="CUSTOM-CHARACTER-00026" he="2.46mm" wi="2.79mm" file="US20230004694A1-20230105-P00006.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2002;&#x2208;&#x2002;<img id="CUSTOM-CHARACTER-00027" he="2.46mm" wi="2.12mm" file="US20230004694A1-20230105-P00005.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2009;</entry></row><row><entry/><entry/><entry>g<sup>&#x2020;</sup>: <img id="CUSTOM-CHARACTER-00028" he="2.46mm" wi="2.12mm" file="US20230004694A1-20230105-P00005.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2002;&#x2192;&#x2002;<img id="CUSTOM-CHARACTER-00029" he="2.46mm" wi="2.79mm" file="US20230004694A1-20230105-P00006.TIF" alt="custom-character" img-content="character" img-format="tif"/> </entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0031" num="0029">In general cases, the transformations of such spaces have been difficult to learn, and in many cases may be intractable and cannot be automatically solved in the general case by a trained model. In particular, the transformations are generally smooth and account for the volumetric change in density as the coordinates are transformed across spaces. This may be particularly challenging when converting from <img id="CUSTOM-CHARACTER-00030" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/> to <img id="CUSTOM-CHARACTER-00031" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> as the number of dimensions increases from the low-dimensional manifold space <b>430</b> to the high-dimensional space <b>460</b>. In the general case, the differential change in volume du when changing variables to the n-dimensional space <img id="CUSTOM-CHARACTER-00032" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> from the m-dimensional low-dimensional manifold space <img id="CUSTOM-CHARACTER-00033" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/> may be expressed by an n&#xd7;m Jacobian matrix J<sub>g</sub>, describing the differential change in variables of the coordinates in <img id="CUSTOM-CHARACTER-00034" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> relative to differential change in variables of <img id="CUSTOM-CHARACTER-00035" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/>. To determine the change in probability density of p<sub>u</sub>(u) for a point u in <img id="CUSTOM-CHARACTER-00036" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/> when converted to corresponding coordinates of <img id="CUSTOM-CHARACTER-00037" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> as point x as a probability density P<sub>x</sub>(x), the instantaneous change in density across coordinate spaces can be described by a change in volume of <img id="CUSTOM-CHARACTER-00038" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00009.TIF" alt="custom-character" img-content="character" img-format="tif"/> relative to the change in volume in <img id="CUSTOM-CHARACTER-00039" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00010.TIF" alt="custom-character" img-content="character" img-format="tif"/>:</p><p id="p-0032" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mfrac>       <mrow>        <mo>&#x2202;</mo>        <mi>X</mi>       </mrow>       <mrow>        <mo>&#x2202;</mo>        <mi>U</mi>       </mrow>      </mfrac>      <mo>&#x2062;</mo>      <mrow>       <mo>(</mo>       <mi>u</mi>       <mo>)</mo>      </mrow>     </mrow>     <mo>=</mo>     <msqrt>      <mrow>       <mi>det</mi>       <mo>[</mo>       <mrow>        <mrow>         <msubsup>          <mi>J</mi>          <mi>g</mi>          <mi>T</mi>         </msubsup>         <mo>(</mo>         <mi>u</mi>         <mo>)</mo>        </mrow>        <mo>&#x2062;</mo>        <mrow>         <msub>          <mi>J</mi>          <mi>g</mi>         </msub>         <mo>(</mo>         <mi>u</mi>         <mo>)</mo>        </mrow>       </mrow>       <mo>]</mo>      </mrow>     </msqrt>    </mrow>   </mtd>   <mtd>    <mrow>     <mi>Equation</mi>     <mo>&#x2062;</mo>     <mtext>   </mtext>     <mn>1</mn>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0033" num="0000">Eq. 1 shows that the Jacobian J<sub>g </sub>(u) of the transform g, and its transpose J<sub>g</sub><sup>T</sup>(u) are multiplied to obtain a square matrix with respect to the coordinates of <img id="CUSTOM-CHARACTER-00040" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00009.TIF" alt="custom-character" img-content="character" img-format="tif"/>, for which the determinant can be determined as a scalar. As shown in Eq. 1, the square root of the determinant of the Jacobian transpose J<sub>g</sub><sup>T </sup>multiplied by the Jacobian J<sub>9 </sub>may be used to determine the equivalent probability density when converting from <img id="CUSTOM-CHARACTER-00041" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00010.TIF" alt="custom-character" img-content="character" img-format="tif"/> to <img id="CUSTOM-CHARACTER-00042" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00009.TIF" alt="custom-character" img-content="character" img-format="tif"/> (more precisely, the instantaneous change in probability density volume at point u when converted from a volume in <img id="CUSTOM-CHARACTER-00043" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00010.TIF" alt="custom-character" img-content="character" img-format="tif"/> to a volume in <img id="CUSTOM-CHARACTER-00044" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00009.TIF" alt="custom-character" img-content="character" img-format="tif"/> at the corresponding point x). Generally, for the probability density of points u on the low-dimensional manifold density <b>440</b>, the probability density for points x may thus be determined by converting points in <img id="CUSTOM-CHARACTER-00045" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00009.TIF" alt="custom-character" img-content="character" img-format="tif"/> to <img id="CUSTOM-CHARACTER-00046" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00010.TIF" alt="custom-character" img-content="character" img-format="tif"/>, determining the probability density in <img id="CUSTOM-CHARACTER-00047" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00010.TIF" alt="custom-character" img-content="character" img-format="tif"/> and converting the density volume to <img id="CUSTOM-CHARACTER-00048" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00009.TIF" alt="custom-character" img-content="character" img-format="tif"/> per Equation 1:</p><p id="p-0034" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <msub>       <mi>p</mi>       <mi>x</mi>      </msub>      <mo>(</mo>      <mi>x</mi>      <mo>)</mo>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <msub>        <mi>p</mi>        <mi>u</mi>       </msub>       <mo>(</mo>       <mi>u</mi>       <mo>)</mo>      </mrow>      <mo>&#x2062;</mo>      <msup>       <mrow>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>        </semantics>        <mrow>         <mi>det</mi>         <mo>[</mo>         <mrow>          <mrow>           <msubsup>            <mi>J</mi>            <mi>g</mi>            <mi>T</mi>           </msubsup>           <mo>(</mo>           <mi>u</mi>           <mo>)</mo>          </mrow>          <mo>&#x2062;</mo>          <mrow>           <msub>            <mi>J</mi>            <mi>g</mi>           </msub>           <mo>(</mo>           <mi>u</mi>           <mo>)</mo>          </mrow>         </mrow>         <mo>]</mo>        </mrow>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>        </semantics>       </mrow>       <mrow>        <mo>-</mo>        <mfrac>         <mn>1</mn>         <mn>2</mn>        </mfrac>       </mrow>      </msup>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mi>Equation</mi>     <mo>&#x2062;</mo>     <mtext>   </mtext>     <mn>2</mn>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0035" num="0000">In Equation 2, as an abbreviation, &#x201c;u&#x201d; may represent the conversion of a point x in <img id="CUSTOM-CHARACTER-00049" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00009.TIF" alt="custom-character" img-content="character" img-format="tif"/> to the low-dimensional manifold space <b>430</b> (i.e., <img id="CUSTOM-CHARACTER-00050" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00010.TIF" alt="custom-character" img-content="character" img-format="tif"/>) with the high-to-low density manifold transformation <b>450</b>: u=g<sup>&#x2020;</sup>(x). For example, p<sub>u</sub>(g<sup>&#x2020;</sup>(x)) was substituted as p<sub>u</sub>(u) in Equation 2. As such, the probability density for <img id="CUSTOM-CHARACTER-00051" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00009.TIF" alt="custom-character" img-content="character" img-format="tif"/> is defined in Eq. 2 after converting points in high-dimensional manifold space <img id="CUSTOM-CHARACTER-00052" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00009.TIF" alt="custom-character" img-content="character" img-format="tif"/> to low-dimensional manifold space <img id="CUSTOM-CHARACTER-00053" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00010.TIF" alt="custom-character" img-content="character" img-format="tif"/>, determining the probability density in <img id="CUSTOM-CHARACTER-00054" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00010.TIF" alt="custom-character" img-content="character" img-format="tif"/> and applying Eq. 1 to the density to determine the equivalent change in density volume after change-of-variables back to the high-dimensional space <img id="CUSTOM-CHARACTER-00055" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/>.</p><p id="p-0036" num="0030">Similarly, and more simply, the probability density p<sub>u </sub>of points in <img id="CUSTOM-CHARACTER-00056" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/> based on the probability density p<sub>z </sub>in <img id="CUSTOM-CHARACTER-00057" he="3.22mm" wi="2.46mm" file="US20230004694A1-20230105-P00004.TIF" alt="custom-character" img-content="character" img-format="tif"/> may be simplified when the low-dimensional spaces have the same dimensionality, and can be given by:</p><p id="p-0037" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>P</i><sub>u</sub>(<i>u</i>)=<i>p</i><sub>z</sub>(<i>h</i><sup>&#x2212;1</sup>(<i>u</i>))|det <i>J</i><sub>h</sub>(<i>h</i><sup>&#x2212;1</sup>(<i>u</i>))|<sup>&#x2212;1</sup>&#x2003;&#x2003;Equation 3<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0038" num="0000">To combine the density transformation <b>420</b> and manifold transformation <b>450</b> in equations 2 and 3 for transforming the base probability density <b>400</b> in <img id="CUSTOM-CHARACTER-00058" he="3.22mm" wi="2.46mm" file="US20230004694A1-20230105-P00004.TIF" alt="custom-character" img-content="character" img-format="tif"/> to <img id="CUSTOM-CHARACTER-00059" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> applies transformations g and h sequentially: g&#x2218;h. Applying the chain rule J<sub>g&#x2218;h</sub>=J<sub>g</sub>J<sub>h </sub>provides a determinant det [J<sub>h</sub><sup>T</sup>J<sub>g</sub><sup>T</sup>J<sub>g</sub>J<sub>h</sub>]=(detJ<sub>h</sub>)<sup>2</sup>det[J<sub>g</sub><sup>T</sup>J<sub>g</sub>] due to the square Jacobian of the outer h density transformation <b>420</b>. As such, the probability density of the high-dimensional manifold <b>470</b> in the high-dimensional space <img id="CUSTOM-CHARACTER-00060" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> may be defined as:</p><p id="p-0039" num="0000"><maths id="MATH-US-00003" num="00003"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <msub>       <mi>p</mi>       <mi>x</mi>      </msub>      <mo>(</mo>      <mi>x</mi>      <mo>)</mo>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <msub>        <mi>p</mi>        <mi>z</mi>       </msub>       <mo>(</mo>       <mi>z</mi>       <mo>)</mo>      </mrow>      <mo>&#x2062;</mo>      <msup>       <mrow>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>        </semantics>        <mrow>         <mi>det</mi>         <mo>&#x2062;</mo>         <mrow>          <msub>           <mi>J</mi>           <mi>h</mi>          </msub>          <mo>(</mo>          <mi>z</mi>          <mo>)</mo>         </mrow>        </mrow>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>        </semantics>       </mrow>       <mrow>        <mo>-</mo>        <mn>1</mn>       </mrow>      </msup>      <mo>&#x2062;</mo>      <msup>       <mrow>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>        </semantics>        <mrow>         <mi>det</mi>         <mo>&#x2062;</mo>         <mrow>          <msubsup>           <mi>J</mi>           <mi>g</mi>           <mi>T</mi>          </msubsup>          <mo>(</mo>          <mi>u</mi>          <mo>)</mo>         </mrow>         <mo>&#x2062;</mo>         <mrow>          <msub>           <mi>J</mi>           <mi>g</mi>          </msub>          <mo>(</mo>          <mi>u</mi>          <mo>)</mo>         </mrow>        </mrow>        <semantics definitionURL="">         <mo>&#x2758;</mo>         <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>        </semantics>       </mrow>       <mrow>        <mo>-</mo>        <mfrac>         <mn>1</mn>         <mn>2</mn>        </mfrac>       </mrow>      </msup>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mi>Equation</mi>     <mo>&#x2062;</mo>     <mtext>   </mtext>     <mn>4</mn>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0040" num="0000">In Equation 4, points &#x201c;z&#x201d; may represent points x transformed to Z: z=h<sup>&#x2212;1</sup>(g<sup>&#x2020;</sup>(x)). In this formulation, however, to properly learn both the manifold itself and its density transformation, the transformations may be trained to maximize a log-likelihood of the transformations based on the training data. However, the log det [J<sub>g</sub><sup>T</sup>J<sub>g</sub>] term is generally intractable in training and cannot be effectively learned, preventing effective automated machine learning for the general case.</p><p id="p-0041" num="0031">To enable this term to be tractable (i.e., computable) and to permit layering of individual transformational layers (e.g., such that g includes layers g<sub>1</sub>, . . . g<sub>k</sub>: g=g<sub>1 </sub>g<sub>k</sub>), the manifold transform includes one or more conformal flows. A conformal flow is a transformation in which the Jacobian satisfies:</p><p id="p-0042" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>J</i><sub>g</sub><sup>T</sup>(<i>u</i>)<i>J</i><sub>g</sub>(<i>u</i>)=&#x3bb;<sup>2</sup>(<i>u</i>)<i>I</i><sub>m</sub>&#x2003;&#x2003;Equation 5<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0043" num="0000">As shown in Eq. 5, the Jacobian transpose multiplied by the Jacobian in a conformal flow are equal to a scalar &#x3bb; (a function of u) squared and an Identity matrix of m (the dimensionality of the origin space, here the low-dimensional manifold space <img id="CUSTOM-CHARACTER-00061" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/>). The relationship of Eq. 5 is also illustrated in the following matrix in which m=3 (i.e., I<sub>m</sub>=I<sub>3</sub>):</p><p id="p-0044" num="0000"><maths id="MATH-US-00004" num="00004"><math overflow="scroll"> <mrow>  <mrow>   <msubsup>    <mi>J</mi>    <mi>g</mi>    <mi>T</mi>   </msubsup>   <mo>&#x2062;</mo>   <msub>    <mi>J</mi>    <mi>g</mi>   </msub>  </mrow>  <mo>=</mo>  <mrow>   <mo>(</mo>   <mtable>    <mtr>     <mtd>      <mrow>       <msup>        <mi>&#x3bb;</mi>        <mn>2</mn>       </msup>       <mo>(</mo>       <mi>u</mi>       <mo>)</mo>      </mrow>     </mtd>     <mtd>      <mn>0</mn>     </mtd>     <mtd>      <mn>0</mn>     </mtd>    </mtr>    <mtr>     <mtd>      <mn>0</mn>     </mtd>     <mtd>      <mrow>       <msup>        <mi>&#x3bb;</mi>        <mn>2</mn>       </msup>       <mo>(</mo>       <mi>u</mi>       <mo>)</mo>      </mrow>     </mtd>     <mtd>      <mn>0</mn>     </mtd>    </mtr>    <mtr>     <mtd>      <mn>0</mn>     </mtd>     <mtd>      <mn>0</mn>     </mtd>     <mtd>      <mrow>       <msup>        <mi>&#x3bb;</mi>        <mn>2</mn>       </msup>       <mo>(</mo>       <mi>u</mi>       <mo>)</mo>      </mrow>     </mtd>    </mtr>   </mtable>   <mo>)</mo>  </mrow> </mrow></math></maths></p><p id="p-0045" num="0000">The scalar &#x3bb; is non-zero and may be referred to as the conformal factor. By selecting layers of the manifold transformation <b>450</b> as conformal flows, multiple such layers may be sequentially applied (g<sub>1 </sub>then g<sub>2 </sub>etc.) and the transformation becomes tractable for automated learning of the manifold transformation with the density transformation. With conformal flows, the probability density of <img id="CUSTOM-CHARACTER-00062" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> transformed from <img id="CUSTOM-CHARACTER-00063" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/> (Equation 2) simplifies to a transformation based on the scalar as shown in Equation 6:</p><p id="p-0046" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i><sub>x</sub>(<i>x</i>)=<i>p</i><sub>u</sub>(<i>u</i>)&#x3bb;<sup>&#x2212;m</sup>(<i>u</i>)&#x2003;&#x2003;Equation 6<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0047" num="0032"><figref idref="DRAWINGS">FIGS. <b>5</b>A-E</figref> show example conformal flows in a two-dimensional space. As shown in these figures, the transformation of a space is shown along with a field showing the relative movement within a space. In <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, a translation moves points a constant amount. <figref idref="DRAWINGS">FIG. <b>5</b>B</figref> shows an orthogonal transformation, in which points are rotated about an axis (e.g., the origin). <figref idref="DRAWINGS">FIG. <b>5</b>C</figref> shows scaling, in which points are scaled outward or inward from an origin. <figref idref="DRAWINGS">FIG. <b>5</b>D</figref> shows a special conformal transformation (&#x201c;SCT&#x201d;) in which an inversion is followed by a translation and then another inversion. <figref idref="DRAWINGS">FIG. <b>5</b>E</figref> shows an inversion, in which points are inverted, e.g., about a unit circle. As shown by these example conformal flows, another property of conformal flows is that orthogonal intersections between lines remain orthogonal after transformation. Stated another way, conformal flows preserve local angles during transformation.</p><p id="p-0048" num="0033">Using a transformation with conformal flows, the transformation of the probability density from <img id="CUSTOM-CHARACTER-00064" he="3.22mm" wi="2.46mm" file="US20230004694A1-20230105-P00004.TIF" alt="custom-character" img-content="character" img-format="tif"/> to <img id="CUSTOM-CHARACTER-00065" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> from Equation 4 simplifies to:</p><p id="p-0049" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>p</i><sub>x</sub>(<i>x</i>)=<i>p</i><sub>z</sub>(<i>z</i>)|det <i>J</i><sub>h</sub>(<i>z</i>)|<sup>&#x2212;1</sup>&#x3bb;<sup>&#x2212;m</sup>(<i>u</i>)&#x2003;&#x2003;Equation 7<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0050" num="0000">As shown in Equation 7, the density and manifold inverse transforms are applied to convert points in <img id="CUSTOM-CHARACTER-00066" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> to <img id="CUSTOM-CHARACTER-00067" he="3.22mm" wi="2.46mm" file="US20230004694A1-20230105-P00004.TIF" alt="custom-character" img-content="character" img-format="tif"/> as before, the Jacobian of the density transform J<sub>h </sub>remains, while the Jacobian of the manifold transform is simplified to the scalar &#x3bb;<sup>&#x2212;m</sup>(u) term as a function of u and the dimensionality m. As discussed below, this also permits a mixed loss function that permits joint training of the density transformation and manifold transformation because the probability density conversion between <img id="CUSTOM-CHARACTER-00068" he="3.22mm" wi="2.46mm" file="US20230004694A1-20230105-P00004.TIF" alt="custom-character" img-content="character" img-format="tif"/> and <img id="CUSTOM-CHARACTER-00069" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> is tractable. It is possible when sequentially training the transformations (e.g., the manifold transformation followed by the density transformation) for the manifold transformation to learn a configuration that is not effectively learned by the density transformation relative to other possible manifold transformations. Because the transforms <img id="CUSTOM-CHARACTER-00070" he="3.22mm" wi="2.46mm" file="US20230004694A1-20230105-P00004.TIF" alt="custom-character" img-content="character" img-format="tif"/> to <img id="CUSTOM-CHARACTER-00071" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> are tractable, the two may be jointly learned and thus increase the likelihood that the manifold transform learns a configuration effective for representing the density.</p><heading id="h-0007" level="2">Conformal Layers</heading><p id="p-0051" num="0034">The manifold transform may include a number of layers (e.g., of individual transform operations) that together transform and change the dimensionality from the high-dimensional space to the low-dimensional space. In one embodiment, the manifold transform includes one or more of the transformations shown in <figref idref="DRAWINGS">FIGS. <b>5</b>A-E</figref>, namely translation, orthogonal transformation, inversion, scaling, and SCT (special conformal transform). The manifold transform may include various layers performing individual transformational operations. The layers may include operations that change the dimensionality of the input and output (e.g., the transformational matrix is non-square) and layers which maintain the dimensionality through the operation (e.g., the transformational matrix is square). The layers are parametrizable conformal flows such that the layers maintain the simplification shown by Equations 6 and 7 and the respective parameters may be learned during training. As layered conformal flows maintain the conformality, many such layers may be stacked to modify dimensionality between the low-dimensional space to the high-dimensional space while learning the parameters describing the manifold in <img id="CUSTOM-CHARACTER-00072" he="3.22mm" wi="3.22mm" file="US20230004694A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> and maintaining the conformal properties through the layers of the manifold transformation <b>450</b> (e.g., the complete sequence of layers in g and its inverse).</p><p id="p-0052" num="0035">The layers that preserve dimensionality may include the transformations shown in <figref idref="DRAWINGS">FIGS. <b>5</b>A-<b>5</b>E</figref>, namely, translation, orthogonal transformation, inversion, scaling, and SCT. These layers provide transforms for transforming an input space u to an output space v, and are parametrizable with respective scalar values as shown in Table 1:</p><p id="p-0053" num="0000"><tables id="TABLE-US-00002" num="00002"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="322pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 1</entry></row></thead><tbody valign="top"><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>Conformal Mappings</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="5"><colspec colname="1" colwidth="42pt" align="left"/><colspec colname="2" colwidth="91pt" align="left"/><colspec colname="3" colwidth="35pt" align="left"/><colspec colname="4" colwidth="84pt" align="left"/><colspec colname="5" colwidth="70pt" align="left"/><tbody valign="top"><row><entry>TYPE</entry><entry>FUNCTIONAL FORM</entry><entry>PARAMS</entry><entry>INVERSE</entry><entry>&#x3bb;(u)</entry></row><row><entry namest="1" nameend="5" align="center" rowsep="1"/></row><row><entry>Translation</entry><entry>u <img id="CUSTOM-CHARACTER-00073" he="1.44mm" wi="2.46mm" file="US20230004694A1-20230105-P00011.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2009; u + a</entry><entry>a &#x3f5; <img id="CUSTOM-CHARACTER-00074" he="2.46mm" wi="1.78mm" file="US20230004694A1-20230105-P00012.TIF" alt="custom-character" img-content="character" img-format="tif"/> <sup>d</sup></entry><entry>v <img id="CUSTOM-CHARACTER-00075" he="1.44mm" wi="2.46mm" file="US20230004694A1-20230105-P00011.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2009; v &#x2212; a</entry><entry>1</entry></row><row><entry>Orthogonal</entry><entry>u <img id="CUSTOM-CHARACTER-00076" he="1.44mm" wi="2.46mm" file="US20230004694A1-20230105-P00011.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2009; Qu</entry><entry>Q &#x3f5; O(d)</entry><entry>v <img id="CUSTOM-CHARACTER-00077" he="1.44mm" wi="2.46mm" file="US20230004694A1-20230105-P00011.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2009; Q<sup>T</sup>v</entry><entry>1</entry></row><row><entry>Scaling</entry><entry>u <img id="CUSTOM-CHARACTER-00078" he="1.44mm" wi="2.46mm" file="US20230004694A1-20230105-P00011.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2009; &#x3bb;u</entry><entry>&#x3bb; &#x3f5; &#x2009;<img id="CUSTOM-CHARACTER-00079" he="2.46mm" wi="1.78mm" file="US20230004694A1-20230105-P00012.TIF" alt="custom-character" img-content="character" img-format="tif"/> </entry><entry>v <img id="CUSTOM-CHARACTER-00080" he="1.44mm" wi="2.46mm" file="US20230004694A1-20230105-P00011.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2009; &#x3bb;<sup>&#x2212;1</sup>v</entry><entry>&#x3bb;</entry></row><row><entry>Inversion</entry><entry>u <img id="CUSTOM-CHARACTER-00081" he="1.44mm" wi="2.46mm" file="US20230004694A1-20230105-P00011.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2009; u/&#x2225;u&#x2225;<sup>2</sup></entry><entry/><entry>v <img id="CUSTOM-CHARACTER-00082" he="1.44mm" wi="2.46mm" file="US20230004694A1-20230105-P00011.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2009; v/&#x2225;v&#x2225;<sup>2</sup></entry><entry>&#x2225;u&#x2225;<sup>&#x2212;2</sup></entry></row><row><entry> </entry></row><row><entry>SCT</entry><entry><maths id="MATH-US-00005" num="00005"><math overflow="scroll"> <mrow>  <mi>u</mi>  <mo>&#x21a6;</mo>  <mfrac>   <mrow>    <mi>u</mi>    <mo>+</mo>    <mrow>     <msup>      <mrow>       <mi>a</mi>       <mo>[</mo>       <mrow>        <mo>[</mo>        <mi>u</mi>        <mo>]</mo>       </mrow>       <mo>]</mo>      </mrow>      <mn>2</mn>     </msup>     <mo>&#x2062;</mo>     <mi>b</mi>    </mrow>   </mrow>   <mrow>    <mn>1</mn>    <mo>-</mo>    <mrow>     <mn>2</mn>     <mo>&#x2062;</mo>     <mrow>      <mi>b</mi>      <mo>&#xb7;</mo>      <mi>u</mi>     </mrow>    </mrow>    <mo>+</mo>    <msup>     <mrow>      <msup>       <mrow>        <mo>[</mo>        <mrow>         <mo>[</mo>         <mi>b</mi>         <mo>]</mo>        </mrow>        <mo>]</mo>       </mrow>       <mn>2</mn>      </msup>      <mo>[</mo>      <mrow>       <mo>[</mo>       <mi>u</mi>       <mo>]</mo>      </mrow>      <mo>]</mo>     </mrow>     <mn>2</mn>    </msup>   </mrow>  </mfrac> </mrow></math></maths></entry><entry>b &#x3f5; <img id="CUSTOM-CHARACTER-00083" he="2.46mm" wi="1.78mm" file="US20230004694A1-20230105-P00012.TIF" alt="custom-character" img-content="character" img-format="tif"/> &#x2009;<sup>d</sup></entry><entry><maths id="MATH-US-00006" num="00006"><math overflow="scroll"> <mrow>  <mi>v</mi>  <mo>&#x21a6;</mo>  <mfrac>   <mrow>    <mi>v</mi>    <mo>+</mo>    <mrow>     <msup>      <mrow>       <mi>a</mi>       <mo>[</mo>       <mrow>        <mo>[</mo>        <mi>v</mi>        <mo>]</mo>       </mrow>       <mo>]</mo>      </mrow>      <mn>2</mn>     </msup>     <mo>&#x2062;</mo>     <mi>b</mi>    </mrow>   </mrow>   <mrow>    <mn>1</mn>    <mo>+</mo>    <mrow>     <mn>2</mn>     <mo>&#x2062;</mo>     <mrow>      <mi>b</mi>      <mo>&#xb7;</mo>      <mi>v</mi>     </mrow>    </mrow>    <mo>+</mo>    <msup>     <mrow>      <msup>       <mrow>        <mo>[</mo>        <mrow>         <mo>[</mo>         <mi>b</mi>         <mo>]</mo>        </mrow>        <mo>]</mo>       </mrow>       <mn>2</mn>      </msup>      <mo>[</mo>      <mrow>       <mo>[</mo>       <mi>v</mi>       <mo>]</mo>      </mrow>      <mo>]</mo>     </mrow>     <mn>2</mn>    </msup>   </mrow>  </mfrac> </mrow></math></maths></entry><entry>1 &#x2212; 2b &#xb7; u + &#x2225;b&#x2225;<sup>2 </sup>&#x2225;u&#x2225;<sup>2</sup></entry></row><row><entry namest="1" nameend="5" align="center" rowsep="1"/></row></tbody></tgroup></table></tables><br/>Each of these conformal mapping is briefly discussed in turn.</p><p id="p-0054" num="0036">The translation may learn a parameter a describing the relative movement of points in the input as a shift relative to the origin, which may be inverted by subtracting the value of a values.</p><p id="p-0055" num="0037">The orthogonal transformation uses matrix Q to rotate about an origin. The matrix Q as a parameter for the orthogonal transformation is selected from the orthonormal matrices O(d) (of the respective layer dimensionality d) that preserve local angles and where Q multiplied by its transpose yields the identity (QQ<sup>t</sup>=I<sub>d</sub>). The orthogonal matrix Q may be parameterized for training, including the use of a Householder matrix and by parameterizing the special orthogonal group with a matrix exponential of skew-symmetric matrices. Equation 8 shows a definition of a Householder Matrix in which v may be learned for constructing Q:</p><p id="p-0056" num="0000"><maths id="MATH-US-00007" num="00007"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mi>Q</mi>     <mo>=</mo>     <mrow>      <mi>I</mi>      <mo>-</mo>      <mrow>       <mn>2</mn>       <mo>&#x2062;</mo>       <mfrac>        <mrow>         <mi>v</mi>         <mo>&#x2062;</mo>         <msup>          <mi>v</mi>          <mi>T</mi>         </msup>        </mrow>        <msup>         <mrow>          <semantics definitionURL="">           <mo>&#x2758;</mo>           <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>          </semantics>          <mrow>           <semantics definitionURL="">            <mo>&#x2758;</mo>            <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>           </semantics>           <mi>v</mi>           <semantics definitionURL="">            <mo>&#x2758;</mo>            <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>           </semantics>          </mrow>          <semantics definitionURL="">           <mo>&#x2758;</mo>           <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>          </semantics>         </mrow>         <mn>2</mn>        </msup>       </mfrac>       <mo>&#x2062;</mo>       <mrow>        <mo>(</mo>        <mrow>         <mi>v</mi>         <mo>&#x2208;</mo>         <msup>          <mi>&#x211d;</mi>          <mi>m</mi>         </msup>        </mrow>        <mo>)</mo>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mi>Equation</mi>     <mo>&#x2062;</mo>     <mtext>   </mtext>     <mn>8</mn>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0057" num="0038">In the skew-symmetric parameterization, Q may be parameterized with Equation 9:</p><p id="p-0058" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Q</i>=exp(<i>A</i>)(<i>A</i><sup>T</sup><i>=&#x2212;A</i>)&#x2003;&#x2003;Equation 9<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0059" num="0039">The scaling transform increases or decreases the distance of point from the origin based on the scaling amount.</p><p id="p-0060" num="0040">The inversion inverts the values of points about a distance from the origin, typically but not always the unit distance. In one embodiment, the inversion may be numerically instable, such that the SCT may be used as an alternative. As discussed above, the SCT (special conformal transform) includes, sequentially, an inversion followed by a translation followed by an inversion.</p><p id="p-0061" num="0041">As such, to learn a conformal mapping at a particular dimensionality (without changing the dimensionality), the translation, orthogonal transform, scaling, and inversion layers may be stacked.</p><p id="p-0062" num="0042">Various transforms may also be used to modify the dimensionality of the input and output for a layer. For example, the example transforms above may also be modified to versions which modify dimensionality while maintaining conformal properties. As additional examples, a layer may include non-square matrices with orthonormal columns (which are conformal) to modify the dimensionality of a layer. As another example, a layer may include zero-padding to modify the dimensionality of a layer by adding zeros in additional dimensions. By following the zero-padding layer with additional transformations, the additional dimensions in a relatively higher-dimensional space may be populated based on information from the lower-dimensional layers.</p><p id="p-0063" num="0043">As an additional example, a layer may include convolutions within the transformation. As one embodiment of a conformal convolutional (which is also invertible), the convolutional layer may include a k&#xd7;k convolution with a stride of k, such that the convolutional layer has a block diagonal Jacobian. The layer may thus implement a set of convolutional filters that together form an orthogonal matrix to provide a conformal layer. Similarly, the blocks may be inverted with a transposed convolution of the same filter.</p><p id="p-0064" num="0044">In addition, to account for additional types of manifold transform layers, the conformality in some embodiments may be relaxed and allow layers which are not completely smooth. As one example, a manifold transformation layer may be required to be conformal with respect to regions of <img id="CUSTOM-CHARACTER-00084" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/> to which the density transformation may transform points from <img id="CUSTOM-CHARACTER-00085" he="3.22mm" wi="2.46mm" file="US20230004694A1-20230105-P00004.TIF" alt="custom-character" img-content="character" img-format="tif"/>. I.e., conformal at h(z), such that g(u) remains conformal from the positions of <img id="CUSTOM-CHARACTER-00086" he="3.22mm" wi="2.79mm" file="US20230004694A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/> corresponding to h(z). As another example, the conformal layers may include piecewise conformal layers, such as a piecewise activation (ReLU) layer or a conditional Orthogonal layer. Examples of these piecewise layers are shown in Table 2:</p><p id="p-0065" num="0000"><tables id="TABLE-US-00003" num="00003"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="322pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 2</entry></row></thead><tbody valign="top"><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>Piecewise Conformal Embeddings</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="5"><colspec colname="1" colwidth="77pt" align="left"/><colspec colname="2" colwidth="84pt" align="left"/><colspec colname="3" colwidth="49pt" align="left"/><colspec colname="4" colwidth="84pt" align="left"/><colspec colname="5" colwidth="28pt" align="left"/><tbody valign="top"><row><entry>TYPE</entry><entry>FUNCTIONAL FORM</entry><entry>PARAMS</entry><entry>LEFT INVERSE</entry><entry>&#x3bb;(u)</entry></row><row><entry namest="1" nameend="5" align="center" rowsep="1"/></row><row><entry>Conformal ReLu</entry><entry><maths id="MATH-US-00008" num="00008"><math overflow="scroll"> <mrow>  <mi>u</mi>  <mo>&#x21a6;</mo>  <mrow>   <mi>ReLU</mi>   <mo>[</mo>   <mtable>    <mtr>     <mtd>      <mi>Qu</mi>     </mtd>    </mtr>    <mtr>     <mtd>      <mrow>       <mo>-</mo>       <mi>Qu</mi>      </mrow>     </mtd>    </mtr>   </mtable>   <mo>]</mo>  </mrow> </mrow></math></maths></entry><entry>Q &#x3f5; O(d)</entry><entry><maths id="MATH-US-00009" num="00009"><math overflow="scroll"> <mrow>  <mrow>   <mo>[</mo>   <mtable>    <mtr>     <mtd>      <msub>       <mi>v</mi>       <mn>1</mn>      </msub>     </mtd>    </mtr>    <mtr>     <mtd>      <msub>       <mi>v</mi>       <mn>2</mn>      </msub>     </mtd>    </mtr>   </mtable>   <mo>]</mo>  </mrow>  <mo>&#x21a6;</mo>  <mrow>   <msup>    <mi>Q</mi>    <mi>T</mi>   </msup>   <mo>&#x2062;</mo>   <mrow>    <mo>(</mo>    <mrow>     <msub>      <mi>v</mi>      <mn>1</mn>     </msub>     <mo>-</mo>     <msub>      <mi>v</mi>      <mn>2</mn>     </msub>    </mrow>    <mo>)</mo>   </mrow>  </mrow> </mrow></math></maths></entry><entry>1</entry></row><row><entry> </entry></row><row><entry>Conditional Orthogonal</entry><entry><maths id="MATH-US-00010" num="00010"><math overflow="scroll"> <mrow>  <mi>u</mi>  <mo>&#x21a6;</mo>  <mrow>   <mo>{</mo>   <mtable>    <mtr>     <mtd>      <mrow>       <msub>        <mi>Q</mi>        <mn>1</mn>       </msub>       <mo>&#x2062;</mo>       <mi>u</mi>      </mrow>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>if</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <mo>&#xf605;</mo>         <mi>u</mi>         <mo>&#xf606;</mo>        </mrow>       </mrow>       <mo>&#x3c;</mo>       <mn>1</mn>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mrow>       <msub>        <mi>Q</mi>        <mn>2</mn>       </msub>       <mo>&#x2062;</mo>       <mi>u</mi>      </mrow>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>if</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <mo>&#xf605;</mo>         <mi>u</mi>         <mo>&#xf606;</mo>        </mrow>       </mrow>       <mo>&#x2265;</mo>       <mn>1</mn>      </mrow>     </mtd>    </mtr>   </mtable>  </mrow> </mrow></math></maths></entry><entry>Q<sub>1</sub>, Q<sub>2 </sub>&#x3f5; O(d)</entry><entry><maths id="MATH-US-00011" num="00011"><math overflow="scroll"> <mrow>  <mi>v</mi>  <mo>&#x21a6;</mo>  <mrow>   <mo>{</mo>   <mtable>    <mtr>     <mtd>      <mrow>       <msubsup>        <mi>Q</mi>        <mn>1</mn>        <mi>T</mi>       </msubsup>       <mo>&#x2062;</mo>       <mi>u</mi>      </mrow>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>if</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <mo>&#xf605;</mo>         <mi>v</mi>         <mo>&#xf606;</mo>        </mrow>       </mrow>       <mo>&#x3c;</mo>       <mn>1</mn>      </mrow>     </mtd>    </mtr>    <mtr>     <mtd>      <mrow>       <msubsup>        <mi>Q</mi>        <mn>2</mn>        <mi>T</mi>       </msubsup>       <mo>&#x2062;</mo>       <mi>u</mi>      </mrow>     </mtd>     <mtd>      <mrow>       <mrow>        <mi>if</mi>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <mo>&#xf605;</mo>         <mi>v</mi>         <mo>&#xf606;</mo>        </mrow>       </mrow>       <mo>&#x2265;</mo>       <mn>1</mn>      </mrow>     </mtd>    </mtr>   </mtable>  </mrow> </mrow></math></maths></entry><entry>1</entry></row><row><entry namest="1" nameend="5" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0066" num="0045">As shown by the foregoing discussion, many types of conformal flows (e.g., individual layers) may be included while providing the simplified and overall tractable transformation for the manifold transformation that was not previously effective to analyze. While conformal layers provide some constraint on the types of transform that may be considered in modeling the manifold in the high-dimensional space, the various types of transforms permit complex transformations of the space while reducing the dimensionality. The model structure may include a large number of different layers for which parameters are learned and may be constructed according to the particular type of data.</p><heading id="h-0008" level="2">Training</heading><p id="p-0067" num="0046">The parameters of the model may be learned to optimize the manifold transform, which characterizes the manifold of the high-dimensional space, and the density transform, which characterizes the probability density on the manifold. Thus, generally, the transforms must achieve two objectives: align the learned manifold with the training data and evaluate densities for off-manifold points.</p><p id="p-0068" num="0047"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an example of a manifold <b>610</b> and an off-manifold data point <b>600</b>. As shown, the data point x <b>600</b> is not accurately captured by the manifold. As one way of describing the error in the manifold transformation, the high-dimensional training data may be converted to the low-dimensional space with the inverse transform and then re-converted to the high-dimensional space with g (g<sup>&#x2020;</sup>(x)). As a result, the point converted back to high-dimensional space will be located on the respective manifold according to the values of the transform, allowing a reconstruction loss to be described by the difference between the original position of x and its position when the manifold transforms and its inverse are applied. In one embodiment, the manifold transformation may be learned based on minimizing such a reconstruction error given the high-dimensional points in the training set. The density manifold may then be sequentially learned to describe the probability density with respect to the low-dimensional manifold based on the manifold transform applied to the training data.</p><p id="p-0069" num="0048">However, when using conformal flows, because the manifold transform is tractable, it may be jointly learned in conjunction with the density transform. As one example training loss, the loss may be defined as:</p><p id="p-0070" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><img id="CUSTOM-CHARACTER-00087" he="3.22mm" wi="2.46mm" file="US20230004694A1-20230105-P00013.TIF" alt="custom-character" img-content="character" img-format="tif"/>=<img id="CUSTOM-CHARACTER-00088" he="3.22mm" wi="1.78mm" file="US20230004694A1-20230105-P00014.TIF" alt="custom-character" img-content="character" img-format="tif"/><sub>x&#x2dc;p</sub><sub><sub2>x</sub2></sub><sub><sup2>*</sup2></sub>[&#x2212;log <i>p</i><sub>x</sub>(<i>x</i>)+&#x3b1;&#x2225;<i>x&#x2212;g</i>(<i>g</i><sup>&#x2020;</sup>(<i>x</i>))&#x2225;<sup>2</sup>]&#x2003;&#x2003;Equation 10<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0071" num="0000">As shown in Equation 10, the loss may minimize the log-likelihood directly for the manifold transformation, a result which is now possible because the manifold transformation is actually computable, allowing the parameters for both the density transform and manifold transform to be jointly learned. In some embodiments, the manifold transform may be initialized with reconstruction loss before applying the joint loss such that the low-dimensional manifold has a more effective starting value for the joint learning. As another example training approach, the transforms may be trained a loss function to minimize the Wasserstein distance between the training data distribution and the learned probability density.</p><heading id="h-0009" level="2">Model Application</heading><p id="p-0072" num="0049">After training the model, the model may then be used for inference or sampling by the inference module <b>150</b> and sampling module <b>130</b>, respectively. To perform inference, a new data point may be converted through the transforms to the low-dimensional density space <img id="CUSTOM-CHARACTER-00089" he="3.22mm" wi="2.46mm" file="US20230004694A1-20230105-P00004.TIF" alt="custom-character" img-content="character" img-format="tif"/> and compared with the probability density (e.g., the accumulated probability) to determine the respective likelihood of the point relative to the training data. This may be used, for example, to describe the relative portion of points that are more or less likely than the new point, or to determine whether the point may be considered to be in or out of distribution based on its likelihood. To perform sampling from the model, a point may be sampled from the base probability density and passed through the transforms to a point in the high-dimensional space, which may be output as a sample of the model.</p><p id="p-0073" num="0050">The foregoing description of the embodiments of the invention has been presented for the purpose of illustration; it is not intended to be exhaustive or to limit the invention to the precise forms disclosed. Persons skilled in the relevant art can appreciate that many modifications and variations are possible in light of the above disclosure.</p><p id="p-0074" num="0051">Some portions of this description describe the embodiments of the invention in terms of algorithms and symbolic representations of operations on information. These algorithmic descriptions and representations are commonly used by those skilled in the data processing arts to convey the substance of their work effectively to others skilled in the art. These operations, while described functionally, computationally, or logically, are understood to be implemented by computer programs or equivalent electrical circuits, microcode, or the like. Furthermore, it has also proven convenient at times, to refer to these arrangements of operations as modules, without loss of generality. The described operations and their associated modules may be embodied in software, firmware, hardware, or any combinations thereof.</p><p id="p-0075" num="0052">Any of the steps, operations, or processes described herein may be performed or implemented with one or more hardware or software modules, alone or in combination with other devices. In one embodiment, a software module is implemented with a computer program product comprising a computer-readable medium containing computer program code, which can be executed by a computer processor for performing any or all of the steps, operations, or processes described.</p><p id="p-0076" num="0053">Embodiments of the invention may also relate to an apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes, and/or it may comprise a general-purpose computing device selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a non-transitory, tangible computer readable storage medium, or any type of media suitable for storing electronic instructions, which may be coupled to a computer system bus. Furthermore, any computing systems referred to in the specification may include a single processor or may be architectures employing multiple processor designs for increased computing capability.</p><p id="p-0077" num="0054">Embodiments of the invention may also relate to a product that is produced by a computing process described herein. Such a product may comprise information resulting from a computing process, where the information is stored on a non-transitory, tangible computer readable storage medium and may include any embodiment of a computer program product or other data combination described herein.</p><p id="p-0078" num="0055">Finally, the language used in the specification has been principally selected for readability and instructional purposes, and it may not have been selected to delineate or circumscribe the inventive subject matter. It is therefore intended that the scope of the invention be limited not by this detailed description, but rather by any claims that issue on an application based hereon. Accordingly, the disclosure of the embodiments of the invention is intended to be illustrative, but not limiting, of the scope of the invention, which is set forth in the following claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230004694A1-20230105-M00001.NB"><img id="EMI-M00001" he="5.67mm" wi="76.20mm" file="US20230004694A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230004694A1-20230105-M00002.NB"><img id="EMI-M00002" he="4.57mm" wi="76.20mm" file="US20230004694A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00003" nb-file="US20230004694A1-20230105-M00003.NB"><img id="EMI-M00003" he="4.57mm" wi="76.20mm" file="US20230004694A1-20230105-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00004" nb-file="US20230004694A1-20230105-M00004.NB"><img id="EMI-M00004" he="10.24mm" wi="76.20mm" file="US20230004694A1-20230105-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00005" nb-file="US20230004694A1-20230105-M00005.NB"><img id="EMI-M00005" he="6.69mm" wi="28.19mm" file="US20230004694A1-20230105-M00005.TIF" alt="embedded image " img-content="table" img-format="tif"/></us-math><us-math idrefs="MATH-US-00006" nb-file="US20230004694A1-20230105-M00006.NB"><img id="EMI-M00006" he="6.69mm" wi="27.52mm" file="US20230004694A1-20230105-M00006.TIF" alt="embedded image " img-content="table" img-format="tif"/></us-math><us-math idrefs="MATH-US-00007" nb-file="US20230004694A1-20230105-M00007.NB"><img id="EMI-M00007" he="6.69mm" wi="76.20mm" file="US20230004694A1-20230105-M00007.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00008" nb-file="US20230004694A1-20230105-M00008.NB"><img id="EMI-M00008" he="5.67mm" wi="18.37mm" file="US20230004694A1-20230105-M00008.TIF" alt="embedded image " img-content="table" img-format="tif"/></us-math><us-math idrefs="MATH-US-00009" nb-file="US20230004694A1-20230105-M00009.NB"><img id="EMI-M00009" he="5.67mm" wi="20.07mm" file="US20230004694A1-20230105-M00009.TIF" alt="embedded image " img-content="table" img-format="tif"/></us-math><us-math idrefs="MATH-US-00010" nb-file="US20230004694A1-20230105-M00010.NB"><img id="EMI-M00010" he="5.67mm" wi="22.61mm" file="US20230004694A1-20230105-M00010.TIF" alt="embedded image " img-content="table" img-format="tif"/></us-math><us-math idrefs="MATH-US-00011" nb-file="US20230004694A1-20230105-M00011.NB"><img id="EMI-M00011" he="6.69mm" wi="22.61mm" file="US20230004694A1-20230105-M00011.TIF" alt="embedded image " img-content="table" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system for probabilistic manifold modeling, comprising:<claim-text>a processor; and</claim-text><claim-text>a computer-readable medium having instructions executable by the processor for:<claim-text>identifying a high-dimensional output space;</claim-text><claim-text>identifying a low-dimensional space with a base probability distribution;</claim-text><claim-text>applying a first transformation comprising one or more conformal flows between the high-dimensional output space and a first position in the low-dimensional space, the first transformation describing a manifold of the high-dimensional output space in the low-dimensional space; and</claim-text><claim-text>applying a second transformation between the first position and a second position corresponding to the base probability distribution in the low-dimensional space.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first transformation consists of one or more conformal flows.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the high-dimensional space is an image space having dimensions describing a plurality of pixels at a resolution.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions are further executable for learning the first transformation and second transformation based on a training set of data points in the high-dimensional space.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the first transformation and second transformation are jointly learned.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions are further executable for determining the second point by sampling from the base probability distribution; and wherein applying the first and second transformation comprises applying the second transformation to the second point to determine the first position and applying the first transformation to the first position to generate a sampled output in the high-dimensional output space.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions are further executable for:<claim-text>receiving a test data point in the high-dimensional output space, the first transformation being applied to the test data point to determine the first position and the second transformation being applied to the first position to determine the second position; and</claim-text><claim-text>determining a likelihood of the test data point with respect to an unknown distribution in the high-dimensional output space based on a likelihood of the second data point with respect to the base distribution.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A method for probabilistic manifold modeling, comprising:<claim-text>identifying a high-dimensional output space;</claim-text><claim-text>identifying a low-dimensional space with a base probability distribution;</claim-text><claim-text>applying a first transformation comprising one or more conformal flows between the high-dimensional output space and a first position in the low-dimensional space, the first transformation describing a manifold of the high-dimensional output space in the low-dimensional space; and</claim-text><claim-text>applying a second transformation between the first position and a second position corresponding to the base probability distribution in the low-dimensional space.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first transformation consists of one or more conformal flows.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the high-dimensional space is an image space having dimensions describing a plurality of pixels at a resolution, each pixel having one or more color channels.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising learning the first transformation and second transformation based on a training set of data points in the high-dimensional space.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the first transformation and second transformation are jointly learned.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising determining the second point by sampling from the base probability distribution; and wherein applying the first and second transformation comprises applying the second transformation to the second point to determine the first position and applying the first transformation to the first position to generate a sampled output in the high-dimensional output space.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:<claim-text>receiving a test data point in the high-dimensional output space, the first transformation being applied to the test data point to determine the first position and the second transformation being applied to the first position to determine the second position; and</claim-text><claim-text>determining a likelihood of the test data point with respect to an unknown distribution in the high-dimensional output space based on a likelihood of the second data point with respect to the base distribution.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A non-transitory computer-readable medium for probabilistic manifold modeling, the non-transitory computer-readable medium comprising instructions executable by a processor for:<claim-text>identifying a high-dimensional output space;</claim-text><claim-text>identifying a low-dimensional space with a base probability distribution;</claim-text><claim-text>applying a first transformation comprising one or more conformal flows between the high-dimensional output space and a first position in the low-dimensional space, the first transformation describing a manifold of the high-dimensional output space in the low-dimensional space; and</claim-text><claim-text>applying a second transformation between the first position and a second position corresponding to the base probability distribution in the low-dimensional space.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the first transformation consists of one or more conformal flows.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the high-dimensional space is an image space having dimensions describing a plurality of pixels at a resolution, each pixel having one or more color channels.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the instructions are further executable for learning the first transformation and second transformation based on a training set of data points in the high-dimensional space.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the instructions are further executable for determining the second point by sampling from the base probability distribution; and wherein applying the first and second transformation comprises applying the second transformation to the second point to determine the first position and applying the first transformation to the first position to generate a sampled output in the high-dimensional output space.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the instructions are further executable for:<claim-text>receiving a test data point in the high-dimensional output space, the first transformation being applied to the test data point to determine the first position and the second transformation being applied to the first position to determine the second position; and</claim-text><claim-text>determining a likelihood of the test data point with respect to an unknown distribution in the high-dimensional output space based on a likelihood of the second data point with respect to the base distribution.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004329A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004329</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17940598</doc-number><date>20220908</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0659</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0629</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0658</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0679</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">MANAGED FETCHING AND EXECUTION OF COMMANDS FROM SUBMISSION QUEUES</invention-title><us-related-documents><division><relation><parent-doc><document-id><country>US</country><doc-number>16425835</doc-number><date>20190529</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11467769</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17940598</doc-number></document-id></child-doc></relation></division><continuation-in-part><relation><parent-doc><document-id><country>US</country><doc-number>15908710</doc-number><date>20180228</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10642500</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16425835</doc-number></document-id></child-doc></relation></continuation-in-part><continuation-in-part><relation><parent-doc><document-id><country>US</country><doc-number>14868373</doc-number><date>20150928</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>9927983</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>15908710</doc-number></document-id></child-doc></relation></continuation-in-part></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>SanDisk Technologies LLC</orgname><address><city>Addison</city><state>TX</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Benisty</last-name><first-name>Shay</first-name><address><city>Beer Sheva</city><country>IL</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The disclosure relates in some aspects to managing the fetching and execution of commands stored in submission queues. For example, execution of a command may be blocked at a data storage apparatus due to an internal blocking condition (e.g., a large number of commands of a particular type are pending for execution at the data storage device). As another example, execution of a command may be blocked at a data storage apparatus due to an external blocking condition (e.g., a host device may specify that certain commands are to be executed immediately one after another). The disclosure relates in some aspects to controlling how commands are fetched and executed so that commands that cannot be executed by the data storage apparatus in the near future do not prevent other commands (that are not subject to the same blocking condition) from being executed.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="190.58mm" wi="158.75mm" file="US20230004329A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="236.64mm" wi="163.83mm" file="US20230004329A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="245.70mm" wi="163.49mm" orientation="landscape" file="US20230004329A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="240.45mm" wi="164.42mm" file="US20230004329A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="260.43mm" wi="167.72mm" file="US20230004329A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="233.34mm" wi="164.34mm" orientation="landscape" file="US20230004329A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="223.18mm" wi="167.39mm" file="US20230004329A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="241.38mm" wi="162.64mm" file="US20230004329A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="242.49mm" wi="162.56mm" file="US20230004329A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="174.50mm" wi="162.56mm" file="US20230004329A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="259.33mm" wi="167.47mm" orientation="landscape" file="US20230004329A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="188.98mm" wi="166.54mm" orientation="landscape" file="US20230004329A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="236.22mm" wi="168.83mm" file="US20230004329A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="237.41mm" wi="150.62mm" file="US20230004329A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="236.30mm" wi="168.83mm" file="US20230004329A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="208.20mm" wi="150.11mm" file="US20230004329A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION(S)</heading><p id="p-0002" num="0001">This application is a divisional of U.S. patent application Ser. No. 16/425,835, filed on May 29, 2019 and having attorney docket number WDT-1237CIP3 (SDA-2644-2US), which is a continuation-in-part of U.S. patent application Ser. No. 15/908,710, filed on Feb. 28, 2018, now U.S. Pat. No. 10,642,500, which is a continuation-in-part of U.S. patent application Ser. No. 14/868,373, filed on Sep. 28, 2015, now U.S. Pat. No. 9,927,983, the entire content of each of which is incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">The disclosure relates, in some embodiments, to non-volatile memory (NVM) devices and memory controllers and host devices for use therewith. More specifically, but not exclusively, the disclosure relates to a data storage apparatus that fetches commands from host-side submission queues and executes those commands.</p><heading id="h-0003" level="1">INTRODUCTION</heading><p id="p-0004" num="0003">Data storage apparatuses incorporating NVM devices, such as flash NAND memories, are replacing or supplementing conventional rotating hard disk drives for mass storage in many consumer or industrial electronics and computers. Typically, a host device may include or communicate with a device controller that in turn controls access to one or more NVM devices (e.g., NVM arrays). For example, the host device may issues write command and read command to a device controller of a data storage apparatus incorporating an NVM device to write data to and read data from the NVM device.</p><p id="p-0005" num="0004">In an NVM express (NVMe) system, a host device writes data storage apparatus commands, such as read commands, write commands, and administrative commands, in submission queues, which are implemented in a memory of the host device. The data storage apparatus fetches the commands from the submission queues and executes the commands. The data storage apparatus then places entries in completion queues, which are also implemented in host memory, to notify the host device of completion of the commands. There are typically multiple submission queues allocated by the host device. Accordingly, during each round of submission queue access, the data storage apparatus determines which submission queue is to be accessed to obtain the next command to be processed.</p><p id="p-0006" num="0005">The NVMe standard, the current version of which is NVM Express, Revision 1.3d, Mar. 20, 2019, the disclosure of which is incorporated herein by reference in its entirety, describes two techniques by which a device controller may select commands from submission queues. One technique uses a round-robin arbiter, in which the device controller selects commands from the submission queues in round-robin order. Another technique uses a weighted round-robin arbiter where the submission queues are assigned static priorities or weights, and commands are selected from submission queues in round-robin order using weights to determine the selection order in each round.</p><p id="p-0007" num="0006">In either case, the next command to be fetched from a submission queue is based on static arbitration logic that either implements no priorities, as in the round-robin case, or that implements only static, host-defined priorities, as in the weighted round-robin case. Such static arbitration logic may be sufficient if the storage device has sufficient resources to handle all host I/O requests. In practice, however, the storage resources of a data storage apparatus may be limited and the demands of the host device on those resources may exceed the capability of the data storage apparatus to promptly process host commands. Accordingly, there is a need for more effective techniques for managing the use of data storage apparatus commands stored in submission queues.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0008" num="0007">The following presents a simplified summary of some aspects of the disclosure to provide a basic understanding of such aspects. This summary is not an extensive overview of all contemplated features of the disclosure, and is intended neither to identify key or critical elements of all aspects of the disclosure nor to delineate the scope of any or all aspects of the disclosure. Its sole purpose is to present various concepts of some aspects of the disclosure in a simplified form as a prelude to the more detailed description that is presented later.</p><p id="p-0009" num="0008">One embodiment of the disclosure provides a data storage apparatus that includes a non-volatile memory array, an interface, and a processor coupled to the non-volatile memory array and the interface. In one example, the processor is configured to: fetch a command from a submission queue of another apparatus via the interface, determine that execution of the command is currently blocked, and control the execution of the command based on the determination that execution of the command is currently blocked.</p><p id="p-0010" num="0009">One embodiment of the disclosure provides a data storage method. In one example, the method includes: fetching a command from a submission queue of another apparatus via the interface, determining that execution of the command is currently blocked, and controlling the execution of the command based on the determination that execution of the command is currently blocked.</p><p id="p-0011" num="0010">One embodiment of the disclosure provides a data storage apparatus. In one example, the apparatus includes: means for fetching a command from a submission queue, optional means for storing the command in a command slot of the data storage apparatus; means for determining that execution of the command is currently blocked (e.g., due to a condition internal to the data storage apparatus or due to a condition external to the data storage apparatus), and means for controlling the execution of the command based on the determination that execution of the command is currently blocked.</p><p id="p-0012" num="0011">One embodiment of the disclosure provides a non-transitory computer-readable medium storing computer-executable code for storing data. In one example, the computer-readable medium includes code to: fetch a command from a submission queue of another apparatus via the interface, determine that execution of the command is currently blocked, and control the execution of the command based on the determination that execution of the command is currently blocked.</p><p id="p-0013" num="0012">One embodiment of the disclosure provides a data storage apparatus that includes a non-volatile memory array, an interface, and a processor coupled to the non-volatile memory array and the interface. In one example, the processor is configured to: receive an indication from another apparatus via the interface, wherein the indication indicates that at least one submission queue of a plurality of submission queues of the other apparatus contains at least one command, estimate, based on the indication, whether a first submission queue of the plurality of submission queues contains a plurality of commands having a defined execution order, and collectively fetch the plurality of commands from the first submission queue as a result of the estimation.</p><p id="p-0014" num="0013">One embodiment of the disclosure provides a data storage method. In one example, the method includes: receiving an indication from another apparatus via the interface, wherein the indication indicates that at least one submission queue of a plurality of submission queues of the other apparatus contains at least one command; estimating, based on the indication, whether a first submission queue of the plurality of submission queues contains a plurality of commands having a defined execution order; and collectively fetching the plurality of commands from the first submission queue as a result of the estimation.</p><p id="p-0015" num="0014">One embodiment of the disclosure provides a data storage apparatus. In one example, the apparatus includes: means for receiving an indication, wherein the indication indicates that at least one submission queue of a plurality of submission queues of the other apparatus contains at least one command; optional means for storing the command in a command slot of the data storage apparatus; means for estimating, based on the indication, whether a first submission queue of the plurality of submission queues contains a plurality of commands having a defined execution order; and means for collectively fetching the plurality of commands from the first submission queue as a result of the estimation.</p><p id="p-0016" num="0015">One embodiment of the disclosure provides a non-transitory computer-readable medium storing computer-executable code for storing data. In one example, the computer-readable medium includes code to: receive an indication from another apparatus via the interface, wherein the indication indicates that at least one submission queue of a plurality of submission queues of the other apparatus contains at least one command; estimate, based on the indication, whether a first submission queue of the plurality of submission queues contains a plurality of commands having a defined execution order; and collectively fetch the plurality of commands from the first submission queue as a result of the estimation.</p><p id="p-0017" num="0016">These and other aspects of the disclosure will become more fully understood upon a review of the detailed description, which follows. Other aspects, features, and implementations of the disclosure will become apparent to those of ordinary skill in the art, upon reviewing the following description of specific implementations of the disclosure in conjunction with the accompanying figures. While features of the disclosure may be discussed relative to certain implementations and figures below, all implementations of the disclosure can include one or more of the advantageous features discussed herein. In other words, while one or more implementations may be discussed as having certain advantageous features, one or more of such features may also be used in accordance with the various implementations of the disclosure discussed herein. In similar fashion, while certain implementations may be discussed below as device, system, or method implementations it should be understood that such implementations can be implemented in various devices, systems, and methods.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0018" num="0017">A more particular description is included below with reference to specific embodiments illustrated in the appended drawings. Understanding that these drawings depict only certain embodiments of the disclosure and are not therefore to be considered to be limiting of its scope, the disclosure is described and explained with additional specificity and detail through the use of the accompanying drawings, in which:</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example memory system including a data storage apparatus configured in accordance with one or more aspects of the disclosure.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example of a host device and a data storage apparatus according to the NVMe architecture.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example of a round-robin command fetching according to the NVMe standard.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example of weighted round-robin command scheduling according to the NVMe standard.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example of operations for controlling command execution in the event of internal blocking and/or or external blocking in accordance with one or more aspects of the disclosure.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an example of increasing the priority for a submission queue in accordance with one or more aspects of the disclosure.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example of operations for controlling command execution in the event of external blocking in accordance with one or more aspects of the disclosure.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates another example of operations for controlling command execution in the event of external blocking in accordance with one or more aspects of the disclosure.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an example of operations for controlling command fetching in the event of external blocking in accordance with one or more aspects of the disclosure.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates an example of a host device and an NVMe device in accordance with one or more aspects of the disclosure.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates an example of a solid state device (SSD) configured in accordance with one or more aspects of the disclosure.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates an example hardware implementation for an apparatus (e.g., an electronic device) for data storage in accordance with one or more aspects of the disclosure.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates an example process for controlling command execution in accordance with one or more aspects of the disclosure.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates an example hardware implementation for an apparatus (e.g., an electronic device) for data storage in accordance with one or more aspects of the disclosure.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates an example process for controlling command fetching in accordance with one or more aspects of the disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0034" num="0033">In the following detailed description, reference is made to the accompanying drawings, which form a part thereof. In addition to the illustrative aspects, embodiments, and features described above, further aspects, embodiments, and features will become apparent by reference to the drawings and the following detailed description. The description of elements in each figure may refer to elements of proceeding figures. Like numbers may refer to like elements in the figures, including alternate embodiments of like elements.</p><p id="p-0035" num="0034">The disclosure relates in some aspects to various apparatuses, systems, methods, and media for managing command fetching and execution by a data storage apparatus. For example, a data storage apparatus may determine whether execution of a command is blocked. If the execution is blocked, the data storage apparatus controls the execution of the command to prevent the blocked command from unduly preventing execution of other commands. For example, if the command will be blocked for more than a threshold period of time, the data storage apparatus may free up a command memory location (e.g., a command slot) currently allocated for the command and take action to execute the command at a later point in time. In this way, the freed-up command memory location may be used to execute another command (e.g., another type of command). As another example, a data storage apparatus may estimate (e.g., predict) whether a particular submission queue contains commands that require a particular execution order. Upon determining (e.g., estimating) that the submission queue likely contains such commands, the data storage apparatus collectively fetches the commands (e.g., at the same time or in succession) so that the data storage apparatus can execute the commands according to the prescribed execution order.</p><p id="p-0036" num="0035">For purposes of illustration, various aspects of the disclosure will be described in the context of a memory system that includes NAND memory technology. A NAND device may be referred to herein as a NAND Flash memory, a NAND memory device, a NAND flash, or a NAND. Generally speaking, a NAND device is a non-volatile memory having high storage density, fast access time, low power requirements in operation and advantageous shock resistance, compared to more conventional memory platforms. Raw NAND devices may be equipped (e.g., configured) with a serial interface such as Open NAND Flash Interface (ONFi), Common Flash Memory Interface (CFI), and the like. NAND devices may be configured as discrete memory chips or packaged with a controller to form a secure digital (SD) memory card, Multi Media Card (MMC), or a solid state disk. A NAND device may be configured with a single flash die, or a plurality of dies. In addition to memory cells, a NAND device may include other components, such as control/address logic components, I/O components, and data register components. It should be appreciated that the teachings herein are also applicable to other forms of memory (e.g., NVM other than NAND devices).</p><heading id="h-0007" level="1">Example Memory System</heading><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an embodiment of a memory system <b>100</b> that includes a host device <b>102</b> and data storage apparatus <b>104</b> communicatively coupled to the host device <b>102</b>. In some embodiments, the data storage apparatus <b>104</b> may be a solid state device (SSD). In some embodiments, an SSD may be a solid state drive.</p><p id="p-0038" num="0037">The host device (e.g., a host computer) <b>102</b> provides commands to the data storage apparatus <b>104</b> for transferring data between the host device <b>102</b> and the data storage apparatus <b>104</b>. For example, the host device <b>102</b> may provide a write command to the data storage apparatus <b>104</b> for writing data to the data storage apparatus <b>104</b> or a read command to the data storage apparatus <b>104</b> for reading data from the data storage apparatus <b>104</b>. The host device <b>102</b> may be any system or device having a need for data storage or retrieval and a compatible interface for communicating with the data storage apparatus <b>104</b>. For example, the host device <b>102</b> may a computing device, a personal computer, a portable computer, or workstation, a server, a personal digital assistant, a digital camera, a digital phone, or the like.</p><p id="p-0039" num="0038">The data storage apparatus <b>104</b> includes a host interface <b>106</b>, a controller <b>108</b>, an optional memory <b>110</b>, and a non-volatile memory (NVM) <b>112</b>. The host interface <b>106</b> is coupled to the controller <b>108</b> and facilitates communication between the host device <b>102</b> and the controller <b>108</b>. Additionally, the controller <b>108</b> is coupled to the memory <b>110</b> and the NVM <b>112</b>. The host interface <b>106</b> may be any type of communication interface, such as an Integrated Drive Electronics (IDE) interface, a Universal Serial Bus (USB) interface, a Serial Peripheral (SP) interface, an Advanced Technology Attachment (ATA) interface, a Small Computer System Interface (SCSI), an IEEE 1394 (Firewire) interface, or the like. In some embodiments, the host device <b>102</b> includes the data storage apparatus <b>104</b> (e.g., the host device <b>102</b> and the data storage apparatus <b>104</b> are implemented as a single component). In other embodiments, the data storage apparatus <b>104</b> is remote with respect to the host device <b>102</b> or is contained in a remote computing system coupled in communication with the host device <b>102</b>. For example, the host device <b>102</b> may communicate with the data storage apparatus <b>104</b> through a wireless communication link.</p><p id="p-0040" num="0039">The controller <b>108</b> controls operation of the data storage apparatus <b>104</b>. In various embodiments, the controller <b>108</b> receives commands <b>114</b> from the host device <b>102</b> through the host interface <b>106</b> and performs the commands to transfer data <b>116</b> between the host device <b>102</b> and the NVM <b>112</b>. In addition, the controller <b>108</b> performs internal operations such as garbage collection operations, data integrity operations, and wear leveling operations. The controller <b>108</b> may include any type of processing device, such as a microprocessor, a microcontroller, an embedded controller, a logic circuit, software, firmware, or the like, for controlling operation of the data storage apparatus <b>104</b>.</p><p id="p-0041" num="0040">In some embodiments, some or all of the functions described herein as being performed by the controller <b>108</b> may instead be performed by another element of the data storage apparatus <b>104</b>. For example, the data storage apparatus <b>104</b> may include a microprocessor, a microcontroller, an embedded controller, a logic circuit, software, firmware, or any kind of processing device, for performing one or more of the functions described herein as being performed by the controller <b>108</b>. In some embodiments, one or more of the functions described herein as being performed by the controller <b>108</b> are instead performed by the host device <b>102</b>. In some embodiments, some or all of the functions described herein as being performed by the controller <b>108</b> may instead be performed by another element such as a controller in a hybrid drive including both non-volatile memory elements and magnetic storage elements.</p><p id="p-0042" num="0041">The memory <b>110</b> may be any memory, computing device, or system capable of storing data. For example, the memory <b>110</b> may be a random-access memory (RAM), a dynamic random-access memory (DRAM), a static random-access memory (SRAM), a synchronous dynamic random-access memory (SDRAM), a flash storage, an erasable programmable read-only-memory (EPROM), an electrically erasable programmable read-only-memory (EEPROM), or the like. In various embodiments, the controller <b>108</b> uses the memory <b>110</b>, or a portion thereof, to store data during the transfer of data between the host device <b>102</b> and the NVM <b>112</b>. For example, the memory <b>110</b> or a portion of the memory <b>110</b> may be a cache memory.</p><p id="p-0043" num="0042">The host device <b>102</b> includes submission queues <b>114</b> for storing commands to be fetched and executed by the data storage apparatus <b>104</b>. The host device <b>102</b> also includes completion queues <b>116</b> for storing information received from the data storage apparatus <b>104</b> regarding successful or unsuccessful execution of the commands. After queueing one or more commands in one of the submission queues <b>114</b>, the host device <b>102</b> initiates a so-called doorbell transaction <b>118</b> to inform the data storage apparatus <b>102</b> that one or more commands are queued in that submission queue. For example, the doorbell transaction <b>118</b> may write to a memory location (e.g., an NVMe register) in the data storage apparatus <b>104</b>, setting bits that indicate that a particular submission queue contains at least one command and the number of commands queued in that submission queue.</p><p id="p-0044" num="0043">The controller <b>108</b> includes a module (e.g., hardware and/or software) for command fetching, arbitration, and execution <b>120</b>. The controller <b>108</b> also includes commands slots <b>126</b> (e.g. buffers, registers, etc.) that are used to temporarily store commands (and, optionally, associated information) to be executed by the controller <b>108</b>.</p><p id="p-0045" num="0044">The module for command fetching, arbitration, and execution <b>120</b> controls how commands are fetched from the submission queues <b>114</b> and controls how the commands are executed by the controller <b>108</b>. For example, in response to a doorbell transaction <b>118</b>, the module for command fetching, arbitration, and execution <b>120</b> may issue a request <b>122</b> to read the submission queue identified by the doorbell transaction <b>118</b>. In response to the request, the host device <b>102</b> sends the corresponding command <b>124</b> (and associated information, if applicable) to the data storage apparatus <b>104</b>.</p><p id="p-0046" num="0045">The module for command fetching, arbitration, and execution <b>120</b> may then place the command <b>124</b> into one of the command slots <b>126</b> of the controller <b>108</b> and the controller <b>108</b> executes the command from the command slot. For example, a command to be executed and associated information (e.g., host pointers for the command) may be parsed (e.g., by logic of the controller <b>108</b>) and loaded into a particular command slot. As execution resources of the controller <b>108</b> are freed-up (e.g., execution of another command is completed), the controller <b>108</b> will execute one of the commands from one of the command slots <b>126</b>.</p><p id="p-0047" num="0046">In the event the module for command fetching, arbitration, and execution <b>120</b> determines that execution of the command <b>124</b> is blocked at the controller <b>108</b>, the module for command fetching, arbitration, and execution <b>120</b> may control execution of the command <b>124</b> to ensure that the command <b>124</b> does not occupy a command slot for too long. For example, only some types of commands (e.g., write commands) may be blocked at a given point in time. Thus, the module for command fetching, arbitration, and execution <b>120</b> may free-up a command slot holding a blocked command if the command will not be executed in the near future. In this way, other types of commands (e.g., read commands) that can be executed at this time can be loaded into the freed-up command slot, thereby more efficiently using the resources of the data storage apparatus <b>104</b>.</p><p id="p-0048" num="0047">The module for command fetching, arbitration, and execution <b>120</b> may also proactively fetch multiple commands from a submission queue. For example, some commands may need to be executed in a defined order (e.g., commands may need to be executed successively such that no other command is executed between the execution of these commands). A FUSED command defined for NVMe is one example of this type of controlled execution command. The host device <b>102</b> does not tell the data storage device <b>104</b> which type of commands are stored in the submission queues <b>114</b>. Thus, in accordance with the teachings herein, the module for command fetching, arbitration, and execution <b>120</b> predicts whether a particular submission queue contains a plurality of commands with controlled execution (e.g., a FUSED command). If it is likely that the submission queue contains such a plurality of commands, the module for command fetching, arbitration, and execution <b>120</b> collectively fetches the commands from the submission queue and places the commands in command slots to enable the controller <b>108</b> to execute the commands in succession. For example, the module for command fetching, arbitration, and execution <b>120</b> may request that the host device <b>104</b> send all of the commands together, or the module for command fetching, arbitration, and execution <b>120</b> may successively fetch the commands from the submission queues (e.g., with no other intervening fetches).</p><heading id="h-0008" level="1">Example NVMe Architecture</heading><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example of an NVMe architecture <b>200</b> in which the subject matter described herein may be implemented. According to the NVMe standard, a host device <b>202</b> communicates memory device commands, such as read commands, write commands, and admin commands, to a data storage apparatus <b>204</b> (e.g., with nonvolatile storage) using submission queues.</p><p id="p-0050" num="0049">The host device <b>202</b> may be any suitable computing platform that is capable of accessing memory on a storage device. For example, host device <b>202</b> may be a desktop personal computer, a laptop computer, a tablet computer, a mobile telephone, or a front end to a storage array. The host device <b>202</b> includes a host processor <b>206</b> and a memory <b>208</b> (e.g., DRAM). The host device <b>202</b> may store data in the data storage apparatus <b>204</b>.</p><p id="p-0051" num="0050">The data storage apparatus <b>204</b> may be any suitable device that provides nonvolatile memory storage for the host device <b>202</b>. The data storage apparatus <b>204</b> may be a removable storage device, such as a solid state drive (e.g., that is removably connectable to host device <b>202</b>). In an alternate example, the data storage apparatus <b>204</b> may be non-removable or integrated within host device <b>202</b>.</p><p id="p-0052" num="0051">In the example of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the data storage apparatus <b>204</b> includes a device controller <b>210</b> and a nonvolatile memory <b>212</b>. The device controller <b>210</b> controls access to nonvolatile memory <b>212</b>. In one embodiment, the device controller <b>210</b> may be a nonvolatile memory controller that implements or supports the NVMe protocol, and the nonvolatile memory <b>212</b> may be 2D or 3D NAND flash memory.</p><p id="p-0053" num="0052">To read data from or write data to the data storage apparatus <b>204</b>, the host processor <b>206</b> generates commands and stores the commands in submission queues <b>214</b>-<b>1</b>, <b>214</b>-<b>2</b>, and <b>214</b>-<b>3</b>. Three submission queues are shown for illustrative purposes. It is understood that there may be more or fewer than three submission queues at any given time depending on NVMe device usage by the host system. The device controller <b>210</b> fetches the commands from the submission queues <b>214</b>-<b>1</b>, <b>214</b>-<b>2</b>, and <b>214</b>-<b>3</b> and then executes the commands. Upon completion of the commands, the device controller <b>210</b> writes completion entries to completion queues <b>216</b>-<b>1</b>, <b>216</b>-<b>2</b>, and <b>216</b>-<b>3</b>.</p><p id="p-0054" num="0053">The NVMe standard defines three arbitration techniques for etching commands from the submission queues. The first technique uses round-robin arbitration and is mandatory. The second technique uses weighted round-robin with urgent priority class command arbitration and is optional. The last technique is vendor-specific.</p><p id="p-0055" num="0054">In the round-robin arbitration technique, the data storage apparatus provides round-robin command arbitration amongst all submission queues, including an admin submission queue. In this case, all of the submission queues are treated with equal priority. The data storage apparatus may select multiple candidate commands for processing from each submission queue per round based on an arbitration burst setting.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a communication system <b>300</b> including a host device <b>302</b> and a data storage apparatus <b>304</b> where a round-robin technique is used for selecting or fetching commands from submission queues (SQs) <b>306</b>-<b>1</b>-<b>306</b>-N. A round-robin arbiter <b>308</b> statically selects a command from one of the submission queues <b>306</b>-<b>1</b>-<b>306</b>-N based on a round-robin selection algorithm regardless of device state, the status of the corresponding completion queues, or any other information. The round-robin selection involves selecting from each queue <b>306</b>-<b>1</b>-<b>306</b>-N in order from 1 to N and continually repeating the selection in the same order. The round-robin arbiter <b>308</b> instructs command fetching logic <b>310</b> to select each command. The command fetching logic <b>310</b> provides the command to command processing logic (not shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>) that processes the command. While round-robin selection can ensure equal serving of submission queues, storage device resources might not be optimally utilized, especially when commands from the submission queues are fetched but cannot be processed due to storage device resource constraints. For example, if the data storage apparatus <b>304</b> is unable to process a write command fetched from a submission queue, the data storage apparatus <b>304</b> may wait until resources are available to process the write command. If the data storage apparatus <b>304</b> processing resources for processing a read command were available but not used during the wait period, then such resources are not being efficiently utilized.</p><p id="p-0057" num="0056">In the weighted round-robin with urgent priority class command arbitration technique, there are three strict priority classes and three weighted round robin priority levels. If submission queue A is of higher strict priority than submission queue B, then all candidate commands in submission queue A will start processing before candidate commands from submission Queue B start processing.</p><p id="p-0058" num="0057">The highest strict priority class is the admin class that includes any command submitted to the admin submission queue. This class has the highest strict priority above commands submitted to any other submission queue.</p><p id="p-0059" num="0058">The next highest strict priority class is the urgent class. Any I/O submission queue assigned to the urgent priority class is serviced next after commands submitted to the admin submission queue, and before any commands submitted to a weighted round robin priority level. In general, host device software will use care in assigning any submission queue to the urgent priority class since there is the potential to starve I/O submission queues in the weighted round robin priority levels as there is no fairness protocol between the urgent and non-urgent I/O submission queues.</p><p id="p-0060" num="0059">The lowest strict priority class is the weighed round robin class. This class consists of the three weighted round robin priority levels (high, medium, and low) that share the remaining bandwidth using weighted round robin arbitration. The host device software controls the weights for the high, medium, and low service classes via set features. Round robin is used to arbitrate within multiple submission queues assigned to the same weighted round robin level. The number of candidate commands that may start processing from each submission queue per round is either the arbitration burst setting or the remaining weighted round robin credits, whichever is smaller.</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a communication system <b>400</b> including a host device <b>402</b> and a data storage apparatus <b>404</b> where a weighted round-robin technique is used for selecting or fetching commands from submission queues (SQs) <b>406</b>-<b>1</b>-<b>406</b>-N. The submission queues <b>406</b>-<b>1</b>-<b>406</b>-N are grouped according to priorities. Round-robin arbiters (RRs) <b>408</b>-<b>1</b>-<b>408</b>-N each implement round-robin selection for their respective queues and pass the selected queue to the next level in the hierarchy. A weighted round-robin arbiter (WRR) <b>410</b> selects commands from the candidates selected by round-robin arbiters <b>408</b>-<b>2</b>-<b>408</b>-N at the previous level using assigned weights to order the candidates in each round of round-robin selection. The weighted round-robin arbiter <b>410</b> passes its selected queue as a selection candidate to the next level in the hierarchy, which is the highest level in this example. A priority arbiter <b>412</b> at the highest level in the hierarchy selects from the output of weighted round-robin arbiter <b>410</b>, an admin queue <b>406</b>-<b>1</b>, and the output of round-robin arbiter <b>406</b>-<b>1</b>, using host assigned priorities. While the technique illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> allows for prioritization of commands, the priorities are statically set by the host device <b>402</b>. As a result, the data storage apparatus <b>404</b> may fetch commands that cannot be immediately processed while other commands that could be immediately processed remain queued in the submission queues <b>406</b>-<b>1</b>-<b>406</b>-N.</p><p id="p-0062" num="0061">The NVMe standard also supports so-called FUSED operations that enable use of a more complex command by &#x201c;fusing&#x201d; together two simpler commands. Conventionally, these commands are collectively referred to as a FUSED command.</p><p id="p-0063" num="0062">In a FUSED operation, the commands are executed in sequence as an atomic unit. For example, the NVMe controller may ensure that no other operations are executed between these two commands.</p><p id="p-0064" num="0063">The commands are inserted next to each other in the same submission queue. The submission queue tail doorbell pointer update indicates both commands as part of one doorbell update.</p><p id="p-0065" num="0064">A compare and write is one example of a FUSED operation. This operation compares the contents of the logical block(s) specified in the compare command to the data stored at the indicated logical block address (LBA) range. If the compare is successful, then the LBA range is updated with the data provided in the write command. If the compare operation is not successful, then the write operation is aborted with a status of command aborted due to a failed FUSED command and the contents in the LBA range are not modified.</p><heading id="h-0009" level="2">Enhanced NVMe Command Selection</heading><p id="p-0066" num="0065">In an NVMe system environment, host software places NVMe commands in submission queues allocated in host memory as discussed above. An NVMe controller in a data storage apparatus fetches the NVMe commands from the submission queues based on a queue priority.</p><p id="p-0067" num="0066">In general, it is preferable to fetch the commands early enough so the overall performance can be increased (e.g., by avoiding command timeout at the host device). However, holding a command internally in the NVMe controller waiting to start the execution phase may waste expensive resources of the NVMe controller such as internal command slots, internal buffers, and associated logic. Moreover, holding unexecuted commands for a long period of time may lead to performance degradation since other commands that can be executed immediately could have used those resources. For example, when an NVMe controller fetches a command, a previously free command slot is occupied with the command while the command is pending for execution. If the NVMe controller cannot start the execution phase for the command at this point, this command slot is wasted and not fully utilized since during this period other commands might have used this slot. Thus, performance of not only of this specific command is adversely affected by the delayed execution, but the performance of other I/O commands may be adversely affected as well.</p><p id="p-0068" num="0067">Moreover, using conventional techniques, an NVMe controller may be subjected to possible command execution deadlocks, especially for FUSED command operations. The NVMe controller architecture is optimized for normal operations, not FUSED command operations. After fetching the first part (e.g., a first command) of a FUSED command, the corresponding command is held internally (occupying a command slot) until the second part (e.g., second command) of the FUSED command is fetched. Only when the NVMe controller has both parts of the FUSED commands will the NVMe controller start the execution phase for this FUSED command. Thus, holding the first part of a FUSED command internally in the NVMe controller while waiting to start the execution phase may waste expensive resources of the NVMe controller. If the maximum number of outstanding commands in the NVMe controller is less than the maximum number of supported submission queues, deadlock may occur in the case where when all submission queues have FUSED commands.</p><p id="p-0069" num="0068">The disclosure relates in some aspects to managing the above trade-offs by providing better command utilization and better utilization of internal resources. For example, after fetching a command, but before allocating a command slot for this command, the NVMe controller checks whether the command is blocked by at least one event (e.g., an internal event and/or an external event). When command execution is blocked by an internal event, the NVMe controller determines when the blocking will be removed. If the blocking will not be removed for a relatively long period of time, the NVMe controller may store this command internally in DRAM or host device memory (e.g., a host memory buffer (HMB)) the release the command slot until the blocking is removed.</p><p id="p-0070" num="0069">In some implementations, the NVMe controller compares the remaining blocking duration (e.g., the amount of time that execution of the command will be delayed) with a threshold to determine whether a blocking condition is indicated. This threshold may be defined, for example, based on one or more of: the maximum number of commands that can be stored for execution (e.g., in the NVMe controller or other suitable device), the number of commands that are stored for execution that are currently blocked, the amount of time that it takes to execute commands, or other execution-related information. This threshold may be defined, for example, based on empirical testing and/or simulation to identify a threshold period of time that provides the best performance. Different thresholds may be used in some implementations (e.g., different thresholds for different commands). In some implementations, a threshold on the order of 10-20 microseconds may be used. Other threshold values may be used in other implementations.</p><p id="p-0071" num="0070">An LBA collision is one example of an internal blocking condition. For example, if the host device issues a read for data that is current cached in DRAM, the controller may need to flush the DRAM and write the data back to the NAND device (e.g., the controller might not be able to return data directly from the DRAM to the host device). Thus, the controller will not be able to start the execution phase for the read operation immediately, thereby resulting in a temporary blocking condition.</p><p id="p-0072" num="0071">Another example of an internal blocking condition relates to commands associated with a specific name space (e.g., a group of LB As). The commands in a name space may share the same attributes (e.g., security zone, LBA size, quality of service (QoS), etc.). If a name space is currently saturated, the controller may temporarily stop execution of all commands for that name space (e.g., to maintain consistent service (e.g., QoS) for all commands of the name space). Thus, execution of these commands may be temporarily blocked.</p><p id="p-0073" num="0072">Execution of a defined execution order command is one example of an external blocking condition. For example, if the controller has loaded only the first part of a FUSED command into a command slot, the controller need to wait to receive the second part of the FUSED command before executing the first part of the FUSED command. Thus, execution of the first part of the FUSED command is blocked in this case due to the execution order requirement externally imposed by the host device.</p><p id="p-0074" num="0073">As mentioned above, the NVMe controller architecture is optimized for non-FUSED operations. The disclosure relates in some aspects to optimizing NVMe FUSED operations. These optimizations may include optimization of internal resources used for FUSED command execution such as SRAM, NVMe command slots, internal flops, etc. These optimizations may include avoiding deadlocks while executing FUSED commands. These optimizations may include intelligent NVMe arbitration which takes into account FUSED operations. These optimizations may include queueing both parts of a FUSED command to NVMe controller firmware as single entry so that the firmware can start the execution as soon as the entry is received without any extra flows. These optimizations may include NVMe FUSED command rule verification required by the NVMe controller.</p><p id="p-0075" num="0074">As an example of the above optimizations, when command execution is blocked by an external event (such as having fetched only the first command of a FUSED command), the NVMe controller may either shorten the blocking period (e.g., by increasing the priority of the submission queue) or release the command slot and execute the FUSED command at a later time. In a first embodiment, after fetching the first part of a FUSED command, the priority of the relevant submission queue is increased so that the second part of the FUSED command will be fetched as soon as possible. In a second embodiment, the first part of the FUSED command is dropped while setting an indication that this submission queue holds a FUSED command. In the next round of the command fetching arbitration, since the NVMe controller knows that this submission queue holds a FUSED command, the NVMe controller fetches both parts of the FUSED command (e.g., in one fetch operation). In a third embodiment, the NVMe controller predicts when a submission queue holds a FUSED command and fetches the commands of the FUSED command as a single unit. This prediction is based, at least in part, on the way the host device does the doorbell transactions. Any of these embodiments may work in parallel.</p><p id="p-0076" num="0075">The disclosure thus relates in some aspects to reducing the amount of time that a command that cannot be executed immediately is held internally (e.g., in an NVMe controller). These aspects and other aspects of the disclosure will now be described in more detail in conjunction with the operations for controlling command execution set forth in <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>9</b></figref>. All of the disclosed embodiments can work in parallel while switching dynamically among them.</p><heading id="h-0010" level="1">Example Command Execution Control Operations</heading><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an embodiment of operations <b>500</b> that may be performed in conjunction with controlling command execution in accordance with the teachings herein. The operations <b>500</b> may take place within a data storage apparatus, a host device, an NVM device, or some other suitable apparatus or apparatuses. For example, one or more of these operations may be performed by the controller <b>108</b> (e.g., the module for command fetching, arbitration, and execution <b>120</b>) of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0078" num="0077">At block <b>502</b>, a data storage apparatus (or other suitable apparatus) fetches a command. For example, the data storage apparatus may fetch a command from a submission queue of a host device in response to a doorbell transaction.</p><p id="p-0079" num="0078">At block <b>504</b>, before allocating a command slot for this command, the data storage apparatus determined whether the command is blocked by one or more conditions. Such a condition could relate to a condition internal to the data storage apparatus (an internal event) or a condition external to the data storage apparatus (an external event). For example, internal conditions may include one or more of a lack of internal resources, a NAND being busy with internal management, or LBA overlaps. External conditions may include the scenario where the data storage apparatus has fetched only one part of a FUSED command.</p><p id="p-0080" num="0079">If the command is not blocked (e.g., the execution phase for the command can start immediately), at block <b>506</b> the data storage apparatus starts the execution of the command.</p><p id="p-0081" num="0080">If the command is blocked, at block <b>508</b> the data storage apparatus determines whether the blocking is due to an internal condition or an external condition.</p><p id="p-0082" num="0081">If the blocking is due to an internal condition, at block <b>510</b> the data storage apparatus evaluates the blocking period to determine when the blocking will be removed.</p><p id="p-0083" num="0082">At block <b>512</b>, if the blocking period is relatively short (e.g., less than a threshold amount of time), the operation flow proceeds to block <b>514</b>.</p><p id="p-0084" num="0083">At block <b>514</b>, the data storage apparatus waits until the command execution is no longer blocked and then starts the execution of the command.</p><p id="p-0085" num="0084">If it is determined at block <b>512</b> that the blocking period is too long (e.g., greater than a threshold amount of time), at block <b>516</b> the data storage apparatus holds this command internally in memory (e.g., DRAM or HMB) and, if applicable, releases the command slot. Once the blocking is removed, the data storage apparatus copies the command information from the memory to a command slot and executes the command.</p><p id="p-0086" num="0085">If it is determined at block <b>508</b> that the blocking is due to an external condition, at block <b>518</b> the data storage apparatus may shorten the blocking period using any of three techniques. In a first technique, the data storage apparatus changes the priority scheme of the command fetching (e.g., by increasing the priority of the submission queue that contains the FUSED command). In the second technique, the data storage apparatus drops the first part of the FUSED command and then fetches it at a later point in time with the other part of the FUSED command. In the third technique, the data storage apparatus holds the first part of the FUSED command internally in memory (e.g., DRAM or HMB) and, if applicable, releases the command slot. Once the blocking is removed (e.g., once the data storage device fetches the second part of the FUSED command), the data storage apparatus copies the command information from the memory to a command slot and executes the command.</p><p id="p-0087" num="0086">The NVMe standard specifies that the data storage apparatus should make sure that the host device does not violate FUSED command rules while executing FUSED commands. One verification technique is to make sure both parts of a FUSED command were submitted in adjacent slots in the submission queue. This verification is relatively simple when using the techniques described herein since a FUSED command might be queued as a single entry to the data storage device firmware.</p><p id="p-0088" num="0087">In some aspects, a process in accordance with the teachings herein may include any combination of the above operations.</p><heading id="h-0011" level="1">Example Priority-Based Command Execution Control</heading><p id="p-0089" num="0088"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an example of priority levels used the first technique for mitigating external blocking described above. In the example of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, an NVMe controller (not shown) implements two levels of NVMe submission queue arbitration logic for FUSED operations. A first NVMe arbitration level 602 is for the normal commands (non-FUSED commands) as defined in NVMe standard. A second NVMe arbitration level 604 has a higher priority and is for FUSED operations. In some implementations, the NVMe arbitration logic may be duplicated, where one set of NVMe arbitration logic is used for normal commands while the other set of NVMe arbitration logic is used for the second part of the FUSED command.</p><p id="p-0090" num="0089">When the NVMe controller detects that only part of a FUSED command is held internally, the NVMe controller increases the priority of the relevant submission queue (from the first NVMe arbitration level 602 to the second NVMe arbitration level 604) so the second part of the FUSED command will be fetched as soon as possible.</p><p id="p-0091" num="0090">For example, at the next round of arbitration, the submission queue selected by any arbitration for FUSED operations at the second NVMe arbitration level 604 will have higher priority than the submission queue selected by any arbitration for non-FUSED operations at the first NVMe arbitration level 602. Consequently, fixed arbitration logic <b>606</b> will select the higher priority submission queue for the FUSED operations as the submission queue to be accessed for this round of the arbitration.</p><heading id="h-0012" level="1">Example Priority-Based Command Execution Control Operations</heading><p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an embodiment of operations <b>700</b> that may be performed in conjunction with the first technique for mitigating external blocking described above. The operations <b>700</b> may take place within a data storage apparatus, a host device, an NVM device, or some other suitable apparatus or apparatuses. For example, one or more of these operations may be performed by the controller <b>108</b> (e.g., the module for command fetching, arbitration, and execution <b>120</b>) of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0093" num="0092">At block <b>702</b>, a data storage apparatus (or other suitable apparatus) fetches a command. For example, the data storage apparatus may fetch a command from a submission queue of a host device in response to a doorbell transaction.</p><p id="p-0094" num="0093">At block <b>704</b>, the data storage apparatus determines whether the command is a FUSED command.</p><p id="p-0095" num="0094">If the command is not is a FUSED command (e.g., the execution phase for the command can start immediately), at block <b>706</b> the data storage apparatus executes the command in the normal manner.</p><p id="p-0096" num="0095">If it is determined at block <b>704</b> that the command is a FUSED command, at block <b>708</b> the data storage apparatus determines whether the command is the first part of the FUSED command.</p><p id="p-0097" num="0096">If the command is NOT the first part of the FUSED command (e.g., the command is the second part of the FUSED command), at block <b>710</b> the data storage apparatus changes the priority of the corresponding submission queue based to normal. For example, the priority of this submission queue would have been increased during a prior arbitration round when the first part of the FUSED command was fetched. Thus, the operations of block <b>710</b> decrease the priority of this submission queue back to normal. These operations may be done immediately after sending the relevant fetch request to the host device and before getting the command.</p><p id="p-0098" num="0097">If it is determined at block <b>708</b> that the command is the first part of the FUSED command, at block <b>712</b> the data storage apparatus determines whether another fetch request was already issued to the relevant submission queue.</p><p id="p-0099" num="0098">At block <b>714</b>, if no further fetch requests were posted to this submission queue, the priority of this submission queue is increased so the second part of this FUSED command will be fetched as soon as possible.</p><p id="p-0100" num="0099">At block <b>716</b>, if another fetch request was already issued to the relevant submission queue, the data storage apparatus continues with normal operations. That is, the command is executed in the normal manner.</p><p id="p-0101" num="0100">In some aspects, a process in accordance with the teachings herein may include any combination of the above operations.</p><heading id="h-0013" level="1">Example Retry-Based Command Execution Control Operations</heading><p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an embodiment of operations <b>800</b> that may be performed in conjunction with the second technique for mitigating external blocking described above. The operations <b>800</b> may take place within a data storage apparatus, a host device, an NVM device, or some other suitable apparatus or apparatuses. For example, one or more of these operations may be performed by the controller <b>108</b> (e.g., the module for command fetching, arbitration, and execution <b>120</b>) of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0103" num="0102">At block <b>802</b>, a data storage apparatus (or other suitable apparatus) fetches a command. For example, the data storage apparatus may fetch a command from a submission queue of a host device in response to a doorbell transaction.</p><p id="p-0104" num="0103">At block <b>804</b>, the data storage apparatus determines whether the command is a FUSED command.</p><p id="p-0105" num="0104">If the command is not is a FUSED command (e.g., the execution phase for the command can start immediately), at block <b>806</b> the data storage apparatus executes the command in the normal manner.</p><p id="p-0106" num="0105">If it is determined at block <b>804</b> that the command is a FUSED command, at block <b>808</b> the data storage apparatus determines whether the command is the first part of the FUSED command that was fetched alone (e.g., in a single fetch command).</p><p id="p-0107" num="0106">If the command is NOT the first part of the FUSED command that was fetched alone, at block <b>810</b> the data storage apparatus processes the command in the normal manner. For example, if the associated fetch request asked for the two commands in a single PCIe packet, the second FUSED command will come in the next few hardware cycles. In this case, the data storage apparatus simply can execute the command as it normally would. As another example, the command may be the second part of the FUSED command. In this case, the data storage apparatus may successively execute the previously fetched first part of the FUSED command and the second part of the FUSED command.</p><p id="p-0108" num="0107">If it is determined at block <b>808</b> that the command is the first part of the FUSED command that was fetched alone, at block <b>812</b> the data storage apparatus determines whether another fetch request was already issued to the relevant submission queue.</p><p id="p-0109" num="0108">At block <b>814</b>, if no further fetch requests were posted to this submission queue, the command is dropped while marking this submission queue as containing a FUSED command. In the next round of the NVMe arbitration logic, the data storage device knows that the next command in this submission queue is a FUSED command and fetches at least two commands from this submission queue one after one. This may be done, for example, using a single request to host device memory or using two read requests one after the other.</p><p id="p-0110" num="0109">At block <b>816</b>, if another fetch request was already issued to the relevant submission queue, the data storage apparatus marks this submission queue as normal. This resets any marking of the submission queue as containing a FUSED command that may have occurred at block <b>814</b> during a previous arbitration round.</p><p id="p-0111" num="0110">In some aspects, a process in accordance with the teachings herein may include any combination of the above operations.</p><heading id="h-0014" level="1">Example Prediction-Based Command Fetching Operations</heading><p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an embodiment of operations <b>900</b> that may be performed in conjunction with predicting whether a submission queue contains a FUSED command as described above. The operations <b>900</b> may take place within a data storage apparatus, a host device, an NVM device, or some other suitable apparatus or apparatuses. For example, one or more of these operations may be performed by the controller <b>108</b> (e.g., the module for command fetching, arbitration, and execution <b>120</b>) of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0113" num="0112">At block <b>902</b>, a data storage apparatus (or other suitable apparatus) determines that a host device issues a doorbell write for submission queue.</p><p id="p-0114" num="0113">At block <b>904</b>, the data storage apparatus determines whether the host device queued two or more commands in the submission queue.</p><p id="p-0115" num="0114">If the host device did not queue two or more commands, at block <b>906</b> the data storage apparatus processes the command in the submission queue in the normal manner.</p><p id="p-0116" num="0115">If it is determined at block <b>904</b> that the host device did queue two or more commands, at block <b>908</b> the data storage apparatus fetches all of the commands in the submission queue one after the other, without fetching from other submission queue in the interim.</p><p id="p-0117" num="0116">Thus, the data storage apparatus predicts when there is a FUSED command based on the way the host device writes to the doorbell register. According to the NVMe standard, the doorbell for FUSED commands must be written using a single transaction. The data storage apparatus detects that a doorbell transaction indicates that a submission queue holds multiple commands. In this case, the data storage apparatus tries to fetch all commands (e.g., one after the other) that were updated by a single doorbell access. In this way, the data storage apparatus may be able to fetch all of the parts of a FUSED command one after the other while not fetching any other commands between them.</p><p id="p-0118" num="0117">In some embodiments, the data storage apparatus may monitor doorbell transactions to identify any submission queues into which the host device tends to write FUSED commands. In this case, the data storage apparatus may include logic that captures the host device submission queue doorbell write transactions over time. Based on this information, the submission queues that are likely to contain a FUSED command are identified. For example, the logic may generate an estimate (e.g., based on collected doorbell statistics) of whether a submission queue contains a FUSED command based on how frequently the host device queued FUSED commands in that submission queue.</p><p id="p-0119" num="0118">Thus, a decision regarding whether to fetch multiple commands from a submission queue (e.g., at block <b>906</b>) may be based on: 1) whether the host device queues two or more commands in that submission queue (e.g., as determined at block <b>904</b>); and/or 2) an estimate (e.g., based on collected statistics) regarding whether the submission queue is likely to contain a FUSED command.</p><p id="p-0120" num="0119">In some aspects, a process in accordance with the teachings herein may include any combination of the above operations.</p><heading id="h-0015" level="1">Example Fetching and Execution Components</heading><p id="p-0121" num="0120"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates an example of a memory system <b>1000</b> that incorporates command fetching and execution as taught herein. In the example of <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the memory system <b>1000</b> is an NVMe system. However, the teachings herein are applicable to other types of systems. The memory system <b>1000</b> includes a host device <b>1002</b> and an NVMe device <b>1004</b> (e.g., an example of a data storage device). The host device <b>1002</b> includes a host memory <b>1006</b>, which includes host queues <b>1008</b> (such as the aforementioned SQs and CQs), data buffers <b>1010</b>, and other memory components <b>1012</b>. The NVMe device <b>1004</b> includes memory arrays <b>1014</b>, an NVMe device controller <b>1016</b>, and a DRAM <b>1018</b>. The NVMe device controller <b>1016</b> includes one or more processors <b>1020</b> that are responsible for the execution of Front-End and Back-End tasks and other task, The NVMe device controller <b>1016</b> includes a command fetcher (e.g., and SQ selector) <b>1022</b> configured to fetch commands from the submission queues (SQs) at the host device <b>1002</b>, parse the commands, and queue the commands internally. The NVMe device controller <b>1016</b> includes a command executor <b>1024</b> for arbitrating the commands and handling the execution of the commands (e.g., as discussed herein). The NVMe device controller <b>1016</b> includes doorbell storage <b>1026</b> for monitoring doorbell transactions, storing historical doorbell transaction information (e.g., a history of host device submission queue doorbell writes) and statistics thereon, and generating a prediction (e.g., an estimate) as to whether a particular submission queue contains a FUSED command or other similar command (e.g., as discussed herein).</p><p id="p-0122" num="0121">The NVMe device controller <b>1016</b> also includes various support components. These components include a control path module <b>1028</b>, a scheduler <b>1030</b>, a PCIe MAC PHY interface <b>1032</b>, DMAs <b>1034</b>, an error correction module <b>1036</b>, a flash interface module <b>1038</b>, and a DRAM controller <b>1040</b>. In operation, the control path module <b>1028</b> may be responsible for managing the host completion queues. Among other functions, the control path module <b>1028</b> routes completion entries received from the scheduler <b>1030</b> to a completion queue (CQ) within the host device <b>1002</b> via the PCIe MAC PHY interface <b>1032</b>. Pages of data to be delivered to the host device (such as the result of read commands) may be delivered using one or more of the DMAs <b>1034</b>. The flash interface module <b>1038</b> is responsible for controlling and accessing the memory arrays <b>1014</b>. The error correction module <b>1036</b> is responsible for error correction on data handled by the NVMe device controller <b>1016</b>. Ingress and egress from the NVMe device <b>1004</b> are illustrated via arrows <b>1042</b> and <b>1044</b>, respectively.</p><p id="p-0123" num="0122">In some aspects, the command fetcher <b>1022</b> and the command executer <b>1024</b> may implement the command fetching and executing control functionality described herein. The command fetcher <b>1022</b> is responsible for fetching NVMe commands from the host device <b>1002</b> while managing and arbitrating the supported submission queues. The command executer <b>1024</b> gets NVMe commands from the command fetcher, parses them, and starts their execution phase. In accordance with the teachings herein, the command executer <b>1024</b> detects that a first part of a FUSED command has arrived and, based on that detection, the arbitration scheme is dynamically change by increasing the priority of the relevant submission queue (e.g., the command executer <b>1024</b> sends an indication of the increased submission queue priority to the command fetcher <b>1022</b>). In some embodiments, the command executer <b>1024</b> may drop the first part of a FUSED command and trigger the command fetcher <b>1022</b> to re-fetch the first part of the FUSED command with the second part of a FUSED command during a subsequent arbitration round. In some embodiments, the command fetcher <b>1022</b> predicts when a FUSED command is located in a submission queue and fetches the two parts of the FUSED command together (e.g., as a single entity) in advanced.</p><p id="p-0124" num="0123">Commands may be held temporarily in the DRAM <b>1018</b> or memory of the host device <b>1002</b> (e.g., HMB) until blocking is released. During this period, a command slot (e.g., a register in the NVMe controller <b>1016</b>) is free and available for the execution of other commands.</p><heading id="h-0016" level="1">Example SSD Storage Device</heading><p id="p-0125" num="0124"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates an embodiment of an SSD <b>1102</b> that may report available physical storage space as taught herein. The SSD <b>1102</b> includes a controller <b>1104</b> that writes data to and reads data from a memory device <b>1106</b> (e.g., an NVM), and performs other associated data storage operations.</p><p id="p-0126" num="0125">The controller <b>1104</b> and the memory device <b>1106</b> communicate with one another via corresponding interfaces. The controller <b>1104</b> includes a memory device input/output (I/O) interface <b>1108</b> for sending commands to the memory device (e.g., via a command bus), sending data to and receiving data from the memory device <b>1106</b> (e.g., via a data bus), and for sending and receiving other signaling as applicable (e.g., a read/busy indication (RBx) generated by the memory device <b>1106</b>). Similarly, the memory device <b>1106</b> includes a controller interface <b>1110</b> for receiving commands from the controller <b>1104</b> (e.g., via a command bus), sending data to and receiving data from the controller <b>1104</b> (e.g., via a data bus), and for sending and receiving other signaling as applicable (e.g., RBx).</p><p id="p-0127" num="0126">The memory device <b>1106</b> includes an NVM core array <b>1112</b> for storing data, an external interface data latch <b>1114</b> for outputting stored data to and receiving data to be stored from the controller interface <b>1110</b>, and a set of internal data latches <b>1116</b> for storing operational data that is used by the memory device <b>1106</b>. The memory device <b>1106</b> also includes a read circuit <b>1118</b> for reading data from the multi-tier NVM core array <b>1112</b>, a program circuit <b>1120</b> for writing data to the multi-tier NVM core array <b>1112</b>, and an erase circuit <b>1122</b> for erasing data in the multi-tier NVM core array <b>1112</b>.</p><p id="p-0128" num="0127">In accordance with the teachings herein, the controller <b>1104</b> includes a module for command fetching, arbitration, and execution <b>1126</b> that may be configured to perform one or more of the operations described herein. For example, the module for command fetching, arbitration, and execution <b>1126</b> may correspond to the module for command fetching, arbitration, and execution <b>120</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> and perform one or more of the reporting-related operations described herein in conjunction with <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>9</b>, <b>13</b>, and <b>15</b></figref>.</p><heading id="h-0017" level="1">First Example Apparatus</heading><p id="p-0129" num="0128"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates an embodiment of an apparatus <b>1200</b> configured to communicate according to one or more aspects of the disclosure. The apparatus <b>1200</b> could embody or be implemented within a data storage device, an SSD, a memory controller, a solid state drive, a host device, an NVM device, a NAND die, or some other type of device that supports data storage. In various implementations, the apparatus <b>1200</b> could embody or be implemented within a computing device, a personal computer, a portable device, or workstation, a server, a personal digital assistant, a digital camera, a digital phone, an entertainment device, a medical device, or any other electronic device that stores data.</p><p id="p-0130" num="0129">The apparatus <b>1200</b> includes a communication interface <b>1202</b>, a storage medium <b>1204</b>, a memory device (e.g., an NVM device) <b>1208</b>, and a processing circuit <b>1210</b> (e.g., at least one processor and/or other suitable circuitry). These components can be coupled to and/or placed in electrical communication with one another via a signaling bus or other suitable component, represented generally by the connection lines in <figref idref="DRAWINGS">FIG. <b>12</b></figref>. The signaling bus may include any number of interconnecting buses and bridges depending on the specific application of the processing circuit <b>1210</b> and the overall design constraints. The signaling bus links together various circuits such that each of the communication interface <b>1202</b>, the storage medium <b>1204</b>, and the memory device <b>1208</b> are coupled to and/or in electrical communication with the processing circuit <b>1210</b>. The signaling bus may also link various other circuits (not shown) such as timing sources, peripherals, voltage regulators, and power management circuits, which are well known in the art, and therefore, will not be described any further.</p><p id="p-0131" num="0130">The communication interface <b>1202</b> provides a means for communicating with other apparatuses over a transmission medium. In some implementations, the communication interface <b>1202</b> includes circuitry and/or programming (e.g., a program) adapted to facilitate the communication of information bi-directionally with respect to one or more devices in a system. In some implementations, the communication interface <b>1202</b> may be configured for wire-based communication. For example, the communication interface <b>1202</b> could be a bus interface, a send/receive interface, or some other type of signal interface including drivers, buffers, or other circuitry for outputting and/or obtaining signals (e.g., outputting signal from and/or receiving signals into an integrated circuit). The communication interface <b>1202</b> serves as one example of a means for receiving and/or a means for transmitting. In some implementations, the communication interface <b>1202</b> may be configured for wireless communication. In some implementations, the communication interface includes a host interface <b>1214</b>. In some implementations, the communication interface may include at least one other interface <b>1216</b>. For example, the communication interface <b>1202</b> may include at least one radio frequency (RF) receiver and/or RF transmitter (e.g., collectively an RF transceiver).</p><p id="p-0132" num="0131">The memory device <b>1208</b> may represent one or more memory devices. As indicated, the memory device <b>1208</b> may maintain mapping information <b>1218</b> along with other information used by the apparatus <b>1200</b>. In some implementations, the memory device <b>1208</b> and the storage medium <b>1204</b> are implemented as a common memory component. The memory device <b>1208</b> may also be used for storing data that is manipulated by the processing circuit <b>1210</b> or some other component of the apparatus <b>1200</b>.</p><p id="p-0133" num="0132">The storage medium <b>1204</b> may represent one or more computer-readable, machine-readable, and/or processor-readable devices for storing programming, such as processor executable code or instructions (e.g., software, firmware), electronic data, databases, or other digital information. The storage medium <b>1204</b> may also be used for storing data that is manipulated by the processing circuit <b>1210</b> when executing programming. The storage medium <b>1204</b> may be any available media that can be accessed by a general purpose or special purpose processor, including portable or fixed storage devices, optical storage devices, and various other mediums capable of storing, containing or carrying programming.</p><p id="p-0134" num="0133">By way of example and not limitation, the storage medium <b>1204</b> may include a magnetic storage device (e.g., hard disk, floppy disk, magnetic strip), an optical disk (e.g., a compact disc (CD) or a digital versatile disc (DVD)), a smart card, a flash memory device (e.g., a card, a stick, or a key drive), a random access memory (RAM), a read only memory (ROM), a programmable ROM (PROM), an erasable PROM (EPROM), an electrically erasable PROM (EEPROM), a register, a removable disk, and any other suitable medium for storing software and/or instructions that may be accessed and read by a computer. The storage medium <b>1204</b> may be embodied in an article of manufacture (e.g., a computer program product). By way of example, a computer program product may include a computer-readable medium in packaging materials. In view of the above, in some implementations, the storage medium <b>1204</b> may be a non-transitory (e.g., tangible) storage medium. For example, the storage medium <b>1204</b> may be a non-transitory computer-readable medium storing computer-executable code, including code to perform operations as described herein.</p><p id="p-0135" num="0134">The storage medium <b>1204</b> may be coupled to the processing circuit <b>1210</b> such that the processing circuit <b>1210</b> can read information from, and write information to, the storage medium <b>1204</b>. That is, the storage medium <b>1204</b> can be coupled to the processing circuit <b>1210</b> so that the storage medium <b>1204</b> is at least accessible by the processing circuit <b>1210</b>, including examples where at least one storage medium is integral to the processing circuit <b>1210</b> and/or examples where at least one storage medium is separate from the processing circuit <b>1210</b> (e.g., resident in the apparatus <b>1200</b>, external to the apparatus <b>1200</b>, distributed across multiple entities, etc.).</p><p id="p-0136" num="0135">Programming stored by the storage medium <b>1204</b>, when executed by the processing circuit <b>1210</b>, causes the processing circuit <b>1210</b> to perform one or more of the various functions and/or process operations described herein. For example, the storage medium <b>1204</b> may include operations configured for regulating operations at one or more hardware blocks of the processing circuit <b>1210</b>, as well as to utilize the communication interface <b>1202</b> for wireless communication utilizing their respective communication protocols.</p><p id="p-0137" num="0136">The processing circuit <b>1210</b> is generally adapted for processing, including the execution of such programming stored on the storage medium <b>1204</b>. As used herein, the terms &#x201c;code&#x201d; or &#x201c;programming&#x201d; shall be construed broadly to include without limitation instructions, instruction sets, data, code, code segments, program code, programs, programming, subprograms, software modules, applications, software applications, software packages, routines, subroutines, objects, executables, threads of execution, procedures, functions, etc., whether referred to as software, firmware, middleware, microcode, hardware description language, or otherwise.</p><p id="p-0138" num="0137">The processing circuit <b>1210</b> is arranged to obtain, process and/or send data, control data access and storage, issue commands, and control other desired operations. The processing circuit <b>1210</b> may include circuitry configured to implement desired programming provided by appropriate media in at least one example. For example, the processing circuit <b>1210</b> may be implemented as one or more processors, one or more controllers, and/or other structure configured to execute executable programming. Examples of the processing circuit <b>1210</b> may include a general purpose processor, a digital signal processor (DSP), an application-specific integrated circuit (ASIC), a field programmable gate array (FPGA) or other programmable logic component, discrete gate or transistor logic, discrete hardware components, or any combination thereof designed to perform the functions described herein. A general purpose processor may include a microprocessor, as well as any conventional processor, controller, microcontroller, or state machine. The processing circuit <b>1210</b> may also be implemented as a combination of computing components, such as a combination of a controller and a microprocessor, a number of microprocessors, one or more microprocessors in conjunction with an ASIC and a microprocessor, or any other number of varying configurations. These examples of the processing circuit <b>1210</b> are for illustration and other suitable configurations within the scope of the disclosure are also contemplated.</p><p id="p-0139" num="0138">According to one or more aspects of the disclosure, the processing circuit <b>1210</b> may be adapted to perform any or all of the features, processes, functions, operations and/or routines for any or all of the apparatuses described herein. For example, the processing circuit <b>1210</b> may be configured to perform any of the steps, functions, and/or processes described with respect to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>9</b> and <b>13</b></figref>. As used herein, the term &#x201c;adapted&#x201d; in relation to the processing circuit <b>1210</b> may refer to the processing circuit <b>1210</b> being one or more of configured, employed, implemented, and/or programmed to perform a particular process, function, operation and/or routine according to various features described herein.</p><p id="p-0140" num="0139">The processing circuit <b>1210</b> may be a specialized processor, such as an application-specific integrated circuit (ASIC) that serves as a means for (e.g., structure for) carrying out any one of the operations described in conjunction with <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>9</b> and <b>13</b></figref>. The processing circuit <b>1210</b> serves as one example of a means for sending and/or a means for receiving. In various implementations, the processing circuit <b>1210</b> may provide and/or incorporate, at least in part, the functionality described above for the controller <b>108</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0141" num="0140">According to at least one example of the apparatus <b>1200</b>, the processing circuit <b>1210</b> may include one or more of a circuit/module for fetching <b>1220</b>, a circuit/module for determining <b>1222</b>, a circuit/module for controlling <b>1224</b>, a circuit/module for executing <b>1226</b>, or a circuit/module for storing <b>1228</b>.</p><p id="p-0142" num="0141">As mentioned above, a program stored by the storage medium <b>1204</b>, when executed by the processing circuit <b>1210</b>, causes the processing circuit <b>1210</b> to perform one or more of the various functions and/or process operations described herein. For example, the program may cause the processing circuit <b>1210</b> to perform the various functions, steps, and/or processes described herein with respect to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>9</b> and <b>13</b></figref> in various implementations. As shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the storage medium <b>1204</b> may include one or more of code for fetching <b>1240</b>, code for determining <b>1242</b>, code for controlling <b>1244</b>, code for executing <b>1246</b>, or code for storing <b>1248</b>.</p><heading id="h-0018" level="1">First Example Process</heading><p id="p-0143" num="0142"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates a process <b>1300</b> for communication in accordance with some aspects of the disclosure. The process <b>1300</b> may take place within a processing circuit (e.g., the processing circuit <b>1210</b> of <figref idref="DRAWINGS">FIG. <b>12</b></figref>), which may be located in a data storage device, a controller, an SSD, a host device, an NVM device, a NAND die, or some other suitable apparatus. Of course, in various aspects within the scope of the disclosure, the process <b>1300</b> may be implemented by any suitable apparatus capable of supporting memory-related operations.</p><p id="p-0144" num="0143">At block <b>1302</b>, an apparatus (e.g., a controller of a data storage apparatus) fetches a command from a submission queue of another apparatus.</p><p id="p-0145" num="0144">At optional block <b>1304</b>, the apparatus may store the command in a command slot after the command is retrieved from the submission queue.</p><p id="p-0146" num="0145">At block <b>1306</b>, the apparatus determines that execution of the command is currently blocked. In some aspects, the determination that execution of the command is currently blocked may include a determination that the execution is blocked due to a condition internal to the data storage apparatus. In some aspects, to determine that execution of the command is currently blocked, the apparatus may determine a quantity of commands that are currently blocked in command slots of the data storage apparatus, and determine that the quantity is greater than or equal to a threshold. In some aspects, the determination that execution of the command is currently blocked may include a determination that the execution is blocked due to a condition external to the data storage apparatus. In some aspects, to determine that execution of the command is currently blocked, the apparatus may determine that the command is part of a plurality of commands having a defined execution order, and determine that the command precedes at least one command of the plurality of commands. In some aspects, the plurality of commands may include (e.g., may be) a FUSED command.</p><p id="p-0147" num="0146">At block <b>1308</b>, the apparatus controls the execution of the command based on the determination that execution of the command is currently blocked.</p><p id="p-0148" num="0147">At optional block <b>1310</b>, the apparatus may successively execute a plurality of commands (e.g., the commands of a FUSED command).</p><p id="p-0149" num="0148">In some aspects, the process <b>1300</b> may include storing the command in a command slot after the command is retrieved from the submission queue. In some aspects, to control the execution of the command, the apparatus may: estimate a period of time that the command will remain blocked, determine that the period of time is less than or equal to a threshold, and as a result of the determination that the period of time is less than or equal to the threshold, wait to execute the command from the command slot until the command ceases to be blocked. In some aspects, to control the execution of the command, the apparatus may: estimate a period of time that the command will remain blocked, determine that the period of time is greater than or equal to a threshold, store the command in a memory as a result of the determination that the period of time is greater than or equal to a threshold, free-up the command slot after the command is stored, determine, subsequent to the command slot being freed-up, that the command is no longer blocked, and copy the command from the memory into the freed-up command slot or another command slot in response to the determination that the command is no longer blocked.</p><p id="p-0150" num="0149">In some aspects, the process <b>1300</b> may include determining that the command is part of a plurality of commands having a defined execution order, and determining that the command precedes at least one command of the plurality of commands. In some aspects, the process <b>1300</b> may further include increasing a priority of the submission queue as a result of the determination that the command precedes at least one command of the plurality of commands. In some aspects, the process <b>1300</b> may further include storing the command in a command slot after the command is retrieved from the submission queue; freeing-up the command slot as a result of the determination that the command precedes at least one command of the plurality of commands, and collectively fetching the command and the at least one command from the submission queue after the command slot is freed-up. In some aspects, the process <b>1300</b> may further include storing the command in a command slot after the command is retrieved from the submission queue, storing the command in a memory as a result of the determination that the command precedes at least one command of the plurality of commands, freeing-up the command slot after the command is stored, determining, subsequent to the command slot being freed-up, that the command is no longer blocked, and as a result of the determination that the command is no longer blocked, copying the command for execution into the freed-up command slot or another command slot.</p><p id="p-0151" num="0150">In some aspects, a process in accordance with the teachings herein may include any combination of the above operations.</p><heading id="h-0019" level="1">Second Example Apparatus</heading><p id="p-0152" num="0151"><figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates an embodiment of an apparatus <b>1400</b> configured to communicate according to one or more aspects of the disclosure. The apparatus <b>1400</b> could embody or be implemented within a data storage device, an SSD, a memory controller, a solid state drive, a host device, an NVM device, a NAND die, or some other type of device that uses data storage. In various implementations, the apparatus <b>1400</b> could embody or be implemented within a computing device, a personal computer, a portable device, or workstation, a server, a personal digital assistant, a digital camera, a digital phone, an entertainment device, a medical device, or any other electronic device that stores data.</p><p id="p-0153" num="0152">The apparatus <b>1400</b> includes a communication interface <b>1402</b>, a storage medium <b>1404</b>, a user interface <b>1406</b>, a memory device <b>1408</b> (e.g., storing report information <b>1418</b>), and a processing circuit <b>1410</b> (e.g., at least one processor and/or other suitable circuitry). In various implementations, the user interface <b>1406</b> may include one or more of: a keypad, a display, a speaker, a microphone, a touchscreen display, of some other circuitry for receiving an input from or sending an output to a user. In some implementations, the communication interface <b>1402</b> includes an SSD storage device interface <b>1414</b>. In some implementations, the communication interface <b>1402</b> may include a user interface <b>1416</b>. In some implementations, the communication interface <b>1402</b> may include at least one other interface. For example, the communication interface <b>1402</b> may include at least one radio frequency (RF) receiver and/or RF transmitter (e.g., collectively an RF transceiver). In general, the components of <figref idref="DRAWINGS">FIG. <b>14</b></figref> may be similar to corresponding components of the apparatus <b>1200</b> of <figref idref="DRAWINGS">FIG. <b>12</b></figref>.</p><p id="p-0154" num="0153">According to one or more aspects of the disclosure, the processing circuit <b>1410</b> may be adapted to perform any or all of the features, processes, functions, operations and/or routines for any or all of the apparatuses described herein. For example, the processing circuit <b>1410</b> may be configured to perform any of the steps, functions, and/or processes described with respect to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>9</b> and <b>15</b></figref>. As used herein, the term &#x201c;adapted&#x201d; in relation to the processing circuit <b>1410</b> may refer to the processing circuit <b>1410</b> being one or more of configured, used, implemented, and/or programmed to perform a particular process, function, operation and/or routine according to various features described herein.</p><p id="p-0155" num="0154">The processing circuit <b>1410</b> may be a specialized processor, such as an application-specific integrated circuit (ASIC) that serves as a means for (e.g., structure for) carrying out any one of the operations described in conjunction with <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>9</b> and <b>15</b></figref>. The processing circuit <b>1410</b> serves as one example of a means for sending and/or a means for receiving. In various implementations, the processing circuit <b>1410</b> may provide and/or incorporate, at least in part, the functionality described above for the controller <b>108</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0156" num="0155">According to at least one example of the apparatus <b>1400</b>, the processing circuit <b>1410</b> may include one or more of a circuit/module for receiving <b>1420</b>, a circuit/module for determining <b>1422</b>, a circuit/module for fetching <b>1424</b>, a circuit/module for executing <b>1426</b>, or a circuit/module for issuing <b>1428</b>.</p><p id="p-0157" num="0156">As mentioned above, programming stored by the storage medium <b>1404</b>, when executed by the processing circuit <b>1410</b>, causes the processing circuit <b>1410</b> to perform one or more of the various functions and/or process operations described herein. For example, the programming may cause the processing circuit <b>1410</b> to perform the various functions, steps, and/or processes described herein with respect to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>9</b> and <b>15</b></figref> in various implementations. As shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, the storage medium <b>1404</b> may include one or more of code for receiving <b>1440</b>, code for determining <b>1442</b>, code for fetching <b>1444</b>, code for executing <b>1446</b>, or code for issuing <b>1448</b>.</p><heading id="h-0020" level="1">Second Example Process</heading><p id="p-0158" num="0157"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates a process <b>1500</b> for communication in accordance with some aspects of the disclosure. The process <b>1500</b> may take place within a processing circuit (e.g., the processing circuit <b>1410</b> of <figref idref="DRAWINGS">FIG. <b>14</b></figref>), which may be located in a data storage device, an SSD, a memory controller, a solid state drive, a host device, an NVM device, a NAND die, or some other suitable apparatus. Of course, in various aspects within the scope of the disclosure, the process <b>1500</b> may be implemented by any suitable apparatus capable of supporting memory-related operations.</p><p id="p-0159" num="0158">At block <b>1502</b>, an apparatus (e.g., a controller of a data storage apparatus) receives an indication that indicates that at least one submission queue of another apparatus contains at least one command.</p><p id="p-0160" num="0159">At block <b>1504</b>, the apparatus estimates, based on the indication received at block <b>1502</b>, whether a first submission queue of the plurality of submission queues contains a plurality of commands having a defined execution order. In some aspects, the plurality of commands may include (e.g., may be) a FUSED command. In some aspects, the indication may be a result of a doorbell transaction by the other apparatus. In some aspects, the estimation of whether the first submission queue contains a plurality of commands having a defined execution order may include: a determination that the indication indicates that the first submission queue contains more than one command.</p><p id="p-0161" num="0160">At block <b>1506</b>, the apparatus collectively fetches the plurality of commands from the first submission queue as a result of the determination. In some aspects, to collectively fetch the plurality of commands from the first submission queue, the apparatus may issue a single read request to the other apparatus for the plurality of commands. In some aspects, to collectively fetch the plurality of commands from the first submission queue, the apparatus may issue successive read requests to the other apparatus.</p><p id="p-0162" num="0161">At optional block <b>1508</b>, the apparatus may successively execute a plurality of commands (e.g., the commands of a FUSED command).</p><p id="p-0163" num="0162">In some aspects, the process <b>1500</b> may include determining that the other apparatus has repeatedly written commands having a defined execution order to the first submission queue, wherein the estimation of whether the first submission queue contains a plurality of commands having a defined execution order is further based on the determination that the other apparatus has repeatedly written commands having a defined execution order to the first submission queue.</p><p id="p-0164" num="0163">In some aspects, the process <b>1500</b> may include determining a rate at which the other apparatus has written commands having a defined execution order to the first submission queue, and determining that the rate is greater than or equal to a threshold, wherein the estimation of whether the first submission queue contains a plurality of commands having a defined execution order is further based on the determination that the rate is greater than or equal to a threshold.</p><p id="p-0165" num="0164">In some aspects, a process in accordance with the teachings herein may include any combination of the above operations.</p><heading id="h-0021" level="2">Additional Aspects</heading><p id="p-0166" num="0165">An example of another process for communication in accordance with some aspects of the disclosure follows. This process may take place within a processing circuit (e.g., the processing circuit <b>1210</b> of <figref idref="DRAWINGS">FIG. <b>12</b></figref>), which may be located in a data storage device, a controller, an SSD, a host device, an NVM device, a NAND die, or some other suitable apparatus. Of course, in various aspects within the scope of the disclosure, this process may be implemented by any suitable apparatus capable of supporting memory-related operations.</p><p id="p-0167" num="0166">At a first block, an apparatus (e.g., a controller of a data storage apparatus) fetches a command from a submission queue of a host device.</p><p id="p-0168" num="0167">At a second block, the apparatus stores the command in a command slot.</p><p id="p-0169" num="0168">At a third block, the apparatus determines that execution of the command is currently blocked. In some aspects, the determination that execution of the command is currently blocked may include determining whether the execution is blocked due to a condition internal to the data storage apparatus or a condition external to the data storage apparatus. In some aspects, the determination that execution of the command is currently blocked may include estimating a period of time that the command will remain blocked, and determining that the period of time is greater than or equal to a threshold. In some aspects, the determination that execution of the command is currently blocked may include determining a quantity of commands that are currently blocked in command slots of the data storage apparatus, and determining that the quantity is greater than or equal to a threshold. In some aspects, the determination that execution of the command is currently blocked may be based on at least one period of time associated with execution of the quantity of commands. In some aspects, the determination that execution of the command is currently blocked may include determining that the command is part of a plurality of commands having a defined execution order, and determining that at least one command of the plurality of commands has not been fetched from the submission queue. In some aspects, the plurality of commands may include (e.g., may be) a FUSED command.</p><p id="p-0170" num="0169">At a fourth block, the apparatus controls the execution of the command based on the determination that execution of the command is currently blocked. In some aspects, the controlling of the execution of the command may include: determining that a period of time that the command will remain blocked is less than or equal to a threshold, and as a result of the determination that the period of time is less than or equal to the threshold, leaving the command in the command slot for execution after the command ceases to be blocked. In some aspects, the controlling of the execution of the command may include: determining that a period of time that the command will remain blocked is greater than or equal to a threshold, storing the command in a memory, reallocating the command slot for another command, determining that the command is no longer blocked, and copying the command from the memory to another command slot for execution. In some aspects, the controlling of the execution of the command may include: determining that the command is part of a plurality of commands having a defined execution order, determining that at least one command of the plurality of commands has not been fetched from the submission queue, increasing a priority of the submission queue as a result of the determination that at least one command of the plurality of commands has not been fetched from the submission queue, fetching the at least one command from the submission queue, and successively executing the command and the at least one command. In some aspects, the controlling of the execution of the command may include: determining that the command is part of a plurality of commands having a defined execution order, determining that at least one command of the plurality of commands has not been fetched from the submission queue, reallocating the command slot to another command as a result of the determination that at least one command of the plurality of commands has not been fetched from the submission queue, collectively fetching the command and the at least one command from the submission queue, and successively executing the command and the at least one command. In some aspects, the controlling of the execution of the command may include: determining that the command is part of a plurality of commands having a defined execution order, determining that at least one command of the plurality of commands has not been fetched from the submission queue, storing the command in a memory as a result of the determination that at least one command of the plurality of commands has not been fetched from the submission queue, reallocating the command slot for another command after the command is stored, subsequently determining that the command is no longer blocked, copying the command from the memory into another command slot for execution, fetching the at least one command from the submission queue, and successively executing the command and the at least one command.</p><p id="p-0171" num="0170">In some aspects, a process in accordance with the teachings herein may include any combination of the above operations.</p><p id="p-0172" num="0171">Another example of a process for communication in accordance with some aspects of the disclosure follows. This process may take place within a processing circuit (e.g., the processing circuit <b>1410</b> of <figref idref="DRAWINGS">FIG. <b>14</b></figref>), which may be located in a data storage device, an SSD, a memory controller, a solid state drive, a host device, an NVM device, a NAND die, or some other suitable apparatus. Of course, in various aspects within the scope of the disclosure, this process may be implemented by any suitable apparatus capable of supporting memory-related operations.</p><p id="p-0173" num="0172">At a first block, an apparatus (e.g., a controller of a data storage apparatus) receives an indication that at least one submission queue of a plurality of submission queues of a host device contains at least one command. In some aspects, the indication may be a result of the host device invoking a doorbell transaction that involves a write to a memory location in a data storage device.</p><p id="p-0174" num="0173">At a second block, the apparatus estimates, based on the indication, whether a first submission queue of the plurality of submission queues contains a plurality of commands having a defined execution order. In some aspects, the plurality of commands may include (e.g., may be) a FUSED command. In some aspects, the estimation of whether the first submission queue contains a plurality of commands having a defined execution order may include determining whether the indication indicates that more than one command has been queued in the first submission queue. In some aspects, the plurality of commands may include (e.g., may be) a FUSED command. In some aspects, the estimation of whether the first submission queue contains a plurality of commands having a defined execution order may include determining whether the host device has repeatedly written commands having a defined execution order to the first submission queue. In some aspects, the estimation of whether the first submission queue contains a plurality of commands having a defined execution order may include determining whether a rate at which the host device has written commands having a defined execution order to the first submission queue is greater than or equal to a threshold.</p><p id="p-0175" num="0174">At a third block, the apparatus collectively fetches the plurality of commands from the first submission queue as a result of the estimation. In some aspects, collectively fetching the plurality of commands from the first submission queue may include issuing a single read request to the host device for the plurality of commands or successively issuing read requests to the host device for individual ones of the plurality of commands.</p><p id="p-0176" num="0175">At a fourth block, the apparatus executes each command of the plurality of commands in succession.</p><p id="p-0177" num="0176">In some aspects, a process in accordance with the teachings herein may include any combination of the above operations.</p><p id="p-0178" num="0177">Yet another example of a process for communication in accordance with some aspects of the disclosure follows. This process may take place within a processing circuit (e.g., the processing circuit <b>1410</b> of <figref idref="DRAWINGS">FIG. <b>14</b></figref>), which may be located in a data storage device, an SSD, a memory controller, a solid state drive, a host device, an NVM device, a NAND die, or some other suitable apparatus. Of course, in various aspects within the scope of the disclosure, this process may be implemented by any suitable apparatus capable of supporting memory-related operations.</p><p id="p-0179" num="0178">At a first block, an apparatus (e.g., a controller of a data storage apparatus) collects information indicative of types of commands written to a plurality of submission queues of a host device. For example, the apparatus may determine, for each submission queue, a rate at which a host device writes commands having a defined execution order to the submission queue.</p><p id="p-0180" num="0179">At a second block, the apparatus determines at least one statistic regarding whether a command of a certain type is written to a first submission queue of the plurality of submission queues. For example, the apparatus may determine a rate at which the host device writes commands having a defined execution order to the first submission queue.</p><p id="p-0181" num="0180">At a third block, the apparatus estimates, based on the at least one statistic, whether the first submission queue contains a plurality of commands having a defined execution order.</p><p id="p-0182" num="0181">At an optional fourth block, the apparatus may further estimate, based on whether the first submission queue contains aa plurality of commands, whether the first submission queue contains a plurality of commands having a defined execution order.</p><p id="p-0183" num="0182">In some aspects, a process in accordance with the teachings herein may include any combination of the above operations.</p><heading id="h-0022" level="2">Other Aspects</heading><p id="p-0184" num="0183">The examples set forth herein are provided to illustrate certain concepts of the disclosure. The apparatuses, devices, or components illustrated above may be configured to perform one or more of the methods, features, or steps described herein. Those of ordinary skill in the art will comprehend that these are merely illustrative in nature, and other examples may fall within the scope of the disclosure and the appended claims. Based on the teachings herein those skilled in the art should appreciate that an aspect disclosed herein may be implemented independently of any other aspects and that two or more of these aspects may be combined in various ways. For example, an apparatus may be implemented or a method may be practiced using any number of the aspects set forth herein. In addition, such an apparatus may be implemented or such a method may be practiced using other structure, functionality, or structure and functionality in addition to or other than one or more of the aspects set forth herein.</p><p id="p-0185" num="0184">Aspects of the present disclosure have been described above with reference to schematic flowchart diagrams and/or schematic block diagrams of methods, apparatuses, systems, and computer program products according to embodiments of the disclosure. It will be understood that each block of the schematic flowchart diagrams and/or schematic block diagrams, and combinations of blocks in the schematic flowchart diagrams and/or schematic block diagrams, can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a computer or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor or other programmable data processing apparatus, create means for implementing the functions and/or acts specified in the schematic flowchart diagrams and/or schematic block diagrams block or blocks.</p><p id="p-0186" num="0185">The subject matter described herein may be implemented in hardware, software, firmware, or any combination thereof. As such, the terms &#x201c;function,&#x201d; &#x201c;module,&#x201d; and the like as used herein may refer to hardware, which may also include software and/or firmware components, for implementing the feature being described. In one example implementation, the subject matter described herein may be implemented using a computer readable medium having stored thereon computer executable instructions that when executed by a computer (e.g., a processor) control the computer to perform the functionality described herein. Examples of computer readable media suitable for implementing the subject matter described herein include non-transitory computer-readable media, such as disk memory devices, chip memory devices, programmable logic devices, and application specific integrated circuits. In addition, a computer readable medium that implements the subject matter described herein may be located on a single device or computing platform or may be distributed across multiple devices or computing platforms.</p><p id="p-0187" num="0186">It should also be noted that, in some alternative implementations, the functions noted in the block may occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. Other steps and methods may be conceived that are equivalent in function, logic, or effect to one or more blocks, or portions thereof, of the illustrated figures. Although various arrow types and line types may be employed in the flowchart and/or block diagrams, they are understood not to limit the scope of the corresponding embodiments. For instance, an arrow may indicate a waiting or monitoring period of unspecified duration between enumerated steps of the depicted embodiment.</p><p id="p-0188" num="0187">The various features and processes described above may be used independently of one another, or may be combined in various ways. All possible combinations and sub-combinations are intended to fall within the scope of this disclosure. In addition, certain method, event, state or process blocks may be omitted in some implementations. The methods and processes described herein are also not limited to any particular sequence, and the blocks or states relating thereto can be performed in other sequences that are appropriate. For example, described tasks or events may be performed in an order other than that specifically disclosed, or multiple may be combined in a single block or state. The example tasks or events may be performed in serial, in parallel, or in some other suitable manner. Tasks or events may be added to or removed from the disclosed example embodiments. The example systems and components described herein may be configured differently than described. For example, elements may be added to, removed from, or rearranged compared to the disclosed example embodiments.</p><p id="p-0189" num="0188">Those of skill in the art will appreciate that information and signals may be represented using any of a variety of different technologies and techniques. For example, data, instructions, commands, information, signals, bits, symbols, and chips that may be referenced throughout the above description may be represented by voltages, currents, electromagnetic waves, magnetic fields or particles, optical fields or particles, or any combination thereof.</p><p id="p-0190" num="0189">The word &#x201c;exemplary&#x201d; is used herein to mean &#x201c;serving as an example, instance, or illustration.&#x201d; Any aspect described herein as &#x201c;exemplary&#x201d; is not necessarily to be construed as preferred or advantageous over other aspects. Likewise, the term &#x201c;aspects&#x201d; does not require that all aspects include the discussed feature, advantage or mode of operation.</p><p id="p-0191" num="0190">While the above descriptions contain many specific embodiments of the invention, these should not be construed as limitations on the scope of the invention, but rather as examples of specific embodiments thereof. Accordingly, the scope of the invention should be determined not by the embodiments illustrated, but by the appended claims and their equivalents. Moreover, reference throughout this specification to &#x201c;one embodiment,&#x201d; &#x201c;an embodiment,&#x201d; or similar language means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the present disclosure. Thus, appearances of the phrases &#x201c;in one embodiment,&#x201d; &#x201c;in an embodiment,&#x201d; and similar language throughout this specification may, but do not necessarily, all refer to the same embodiment, but mean &#x201c;one or more but not all embodiments&#x201d; unless expressly specified otherwise.</p><p id="p-0192" num="0191">The terminology used herein is for the purpose of describing particular aspects only and is not intended to be limiting of the aspects. As used herein, the singular forms &#x201c;a,&#x201d; &#x201c;an&#x201d; and &#x201c;the&#x201d; are intended to include the plural forms as well (i.e., one or more), unless the context clearly indicates otherwise. An enumerated listing of items does not imply that any or all of the items are mutually exclusive and/or mutually inclusive, unless expressly specified otherwise. It will be further understood that the terms &#x201c;comprises,&#x201d; &#x201c;comprising,&#x201d; &#x201c;includes&#x201d; &#x201c;including,&#x201d; &#x201c;having,&#x201d; and variations thereof when used herein mean &#x201c;including but not limited to&#x201d; unless expressly specified otherwise. That is, these terms may specify the presence of stated features, integers, steps, operations, elements, or components, but do not preclude the presence or addition of one or more other features, integers, steps, operations, elements, components, or groups thereof. Moreover, it is understood that the word &#x201c;or&#x201d; has the same meaning as the Boolean operator &#x201c;OR,&#x201d; that is, it encompasses the possibilities of &#x201c;either&#x201d; and &#x201c;both&#x201d; and is not limited to &#x201c;exclusive or&#x201d; (&#x201c;XOR&#x201d;), unless expressly stated otherwise. It is also understood that the symbol &#x201c;/&#x201d; between two adjacent words has the same meaning as &#x201c;or&#x201d; unless expressly stated otherwise. Moreover, phrases such as &#x201c;connected to,&#x201d; &#x201c;coupled to&#x201d; or &#x201c;in communication with&#x201d; are not limited to direct connections unless expressly stated otherwise.</p><p id="p-0193" num="0192">Any reference to an element herein using a designation such as &#x201c;first,&#x201d; &#x201c;second,&#x201d; and so forth does not generally limit the quantity or order of those elements. Rather, these designations may be used herein as a convenient method of distinguishing between two or more elements or instances of an element. Thus, a reference to first and second elements does not mean that only two elements may be used there or that the first element must precede the second element in some manner. Also, unless stated otherwise a set of elements may include one or more elements. In addition, terminology of the form &#x201c;at least one of a, b, or c&#x201d; or &#x201c;a, b, c, or any combination thereof&#x201d; used in the description or the claims means &#x201c;a or b or c or any combination of these elements.&#x201d; For example, this terminology may include a, or b, or c, or a and b, or a and c, or a and b and c, or 2a, or 2b, or 2c, or 2a and b, and so on.</p><p id="p-0194" num="0193">As used herein, the term &#x201c;determining&#x201d; encompasses a wide variety of actions. For example, &#x201c;determining&#x201d; may include calculating, computing, processing, deriving, investigating, looking up (e.g., looking up in a table, a database or another data structure), ascertaining, and the like. Also, &#x201c;determining&#x201d; may include receiving (e.g., receiving information), accessing (e.g., accessing data in a memory), and the like. Also, &#x201c;determining&#x201d; may include resolving, selecting, choosing, establishing, and the like.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A data storage apparatus, comprising:<claim-text>a non-volatile memory array;</claim-text><claim-text>an interface; and</claim-text><claim-text>a processor coupled to the non-volatile memory array and the interface and configured to:<claim-text>receive an indication from another apparatus via the interface, wherein the indication indicates that at least one submission queue of a plurality of submission queues of the other apparatus contains at least one command,</claim-text><claim-text>estimate, based on the indication, whether a first submission queue of the plurality of submission queues contains a plurality of commands having a defined execution order, and</claim-text><claim-text>collectively fetch the plurality of commands from the first submission queue as a result of the estimation.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of commands comprises a FUSED command.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The apparatus of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the indication is a result of a doorbell transaction by the other apparatus.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the estimation of whether the first submission queue contains a plurality of commands having a defined execution order comprises:<claim-text>a determination that the indication indicates that the first submission queue contains more than one command.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is further configured to:<claim-text>determine that the other apparatus has repeatedly written commands having a defined execution order to the first submission queue,</claim-text><claim-text>wherein the estimation of whether the first submission queue contains a plurality of commands having a defined execution order is further based on the determination that the other apparatus has repeatedly written commands having a defined execution order to the first submission queue.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is further configured to:<claim-text>determine a rate at which the other apparatus has written commands having a defined execution order to the first submission queue; and</claim-text><claim-text>determine that the rate is greater than or equal to a threshold,</claim-text><claim-text>wherein the estimation of whether the first submission queue contains a plurality of commands having a defined execution order is further based on the determination that the rate is greater than or equal to a threshold.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, to collectively fetch the plurality of commands from the first submission queue, the processor is further configured to:<claim-text>issue a single read request to the other apparatus for the plurality of commands.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, to collectively fetch the plurality of commands from the first submission queue, the processor is further configured to:<claim-text>issue successive read requests to the other apparatus.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is further configured to:<claim-text>successively execute the plurality of commands.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A data storage apparatus, comprising:<claim-text>means for receiving an indication that indicates that at least one submission queue of a plurality of submission queues of a host device contains at least one command;</claim-text><claim-text>means for estimating, based on the indication, whether a first submission queue of the plurality of submission queues contains a plurality of commands having a defined execution order;</claim-text><claim-text>means for collectively fetching a first command and a second command of the plurality of commands from the first submission queue as a result of the estimation; and</claim-text><claim-text>means for successively executing the first command and the second command.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the means for estimating is configured to:<claim-text>determine whether the indication indicates that more than one command is queued in the first submission queue; and</claim-text><claim-text>generate an indication that the first submission queue is estimated to contain a plurality of commands having a defined execution order based on the determination of whether the indication indicates that more than one command is queued in the first submission queue.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the means for estimating is further configured to:<claim-text>determine whether the host device has repeatedly written commands having a defined execution order to the first submission queue; and</claim-text><claim-text>generate an indication that the first submission queue is estimated to contain a plurality of commands having a defined execution order based on the determination of whether the host device has repeatedly written commands having a defined execution order to the first submission queue.</claim-text></claim-text></claim></claims></us-patent-application>
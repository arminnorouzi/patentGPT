<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007233A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007233</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17781057</doc-number><date>20201202</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>CN</country><doc-number>201911231397.4</doc-number><date>20191205</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>398</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>383</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>302</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>167</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20180501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>398</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20180501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>383</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>302</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>167</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">METHOD FOR REALIZING 3D IMAGE DISPLAY, AND 3D DISPLAY DEVICE</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Beijing Ivisual 3D Technology Co., Ltd.</orgname><address><city>Beijing</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant><us-applicant sequence="01" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>VISIOTECH VENTURES PTE. LTD.</orgname><address><city>Singapore</city><country>SG</country></address></addressbook><residence><country>SG</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>DIAO</last-name><first-name>Honghao</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>HUANG</last-name><first-name>Lingxi</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/CN2020/133331</doc-number><date>20201202</date></document-id><us-371c12-date><date>20220531</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Provided is a method for realizing 3D image display, comprising: detecting a posture change of a 3D display device, wherein the 3D display device comprises a multi-viewpoint 3D display screen, the multi-viewpoint 3D display screen comprises a plurality of composite pixels and a plurality of spherical gratings covering the plurality of composite pixels, each composite pixel of the plurality of composite pixels comprises a plurality of composite subpixels, and each composite subpixel of the plurality of composite subpixels comprises a plurality of subpixels corresponding to a plurality of viewpoints; and when detecting the posture change of the 3D display device, adjusting a display orientation of a displayed 3D image so that the 3D image is kept in an initial display orientation before the posture change of the 3D display device. A 3D display device, a computer-readable storage medium, and a computer program product are further provided.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="78.57mm" wi="144.36mm" file="US20230007233A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="237.07mm" wi="169.50mm" orientation="landscape" file="US20230007233A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="226.06mm" wi="164.93mm" orientation="landscape" file="US20230007233A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="238.08mm" wi="173.23mm" orientation="landscape" file="US20230007233A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="220.73mm" wi="153.84mm" file="US20230007233A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="214.21mm" wi="125.39mm" file="US20230007233A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="132.84mm" wi="140.46mm" file="US20230007233A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="194.39mm" wi="163.24mm" file="US20230007233A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="167.72mm" wi="158.67mm" file="US20230007233A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="217.68mm" wi="153.59mm" file="US20230007233A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="232.92mm" wi="140.38mm" file="US20230007233A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="219.54mm" wi="146.39mm" file="US20230007233A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="102.11mm" wi="133.69mm" file="US20230007233A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><p id="p-0002" num="0001">The present disclosure claims priority to the Chinese Patent Application with an application number of 2019112313974 and a title of &#x201c;Method for Realizing 3D Image Display, and 3D Display Device&#x201d;, filed to China National Intellectual Property Administration on Dec. 5, 2019, the disclosures of which are hereby incorporated by reference.</p><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present disclosure relates to the technical field of 3D display, and for example, relates to a method for realizing 3D image display, and a 3D display device.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0004" num="0003">At present, 3D display devices refract light emitted by pixels through gratings to achieve a 3D display effect.</p><p id="p-0005" num="0004">In the process of realizing embodiments of the present disclosure, at least the following problems are found in the related technologies: a display device is configured to display a suitable 3D effect in one posture, but does not have the function of displaying the 3D effect in another posture.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0006" num="0005">In order to provide a basic understanding of some aspects of the disclosed embodiments, a brief summary is given below. The summary is not intended to be a general comment, nor to identify key/important components or describe the scope of protection of the embodiments, but to be a preface to the following detailed description.</p><p id="p-0007" num="0006">Embodiments of the present disclosure provide a method for realizing 3D image display, a 3D display device, a computer-readable storage medium, and a computer program product, to solve the technical problem that a 3D display device cannot display a 3D image after posture adjustment.</p><p id="p-0008" num="0007">In some embodiments, a method for realizing 3D image display is provided, comprising: detecting a posture change of a 3D display device, wherein the 3D display device comprises a multi-viewpoint 3D display screen, the multi-viewpoint 3D display screen comprises a plurality of composite pixels and a plurality of spherical gratings covering the plurality of composite pixels, each composite pixel of the plurality of composite pixels comprises a plurality of composite subpixels, and each composite subpixel of the plurality of composite subpixels comprises a plurality of subpixels corresponding to a plurality of viewpoints; and when detecting the posture change of the 3D display device, adjusting a display orientation of a displayed 3D image so that the 3D image is kept in an initial display orientation before the posture of the 3D display device changes.</p><p id="p-0009" num="0008">In some embodiments, detecting a posture change of a 3D display device comprises: detecting a rotational angular velocity of the 3D display device, and determining the posture change of the 3D display device according to the rotational angular velocity; and adjusting a display orientation of a 3D image comprises: rotating the display orientation of the 3D image in a plane, in which the 3D image is located, so that the 3D image is kept in an initial display orientation before the posture of the 3D display device changes.</p><p id="p-0010" num="0009">In some embodiments, the posture of the 3D display device comprises at least one of: a transverse screen display posture, a vertical screen display posture, and an oblique screen display posture.</p><p id="p-0011" num="0010">In some embodiments, a first posture of the 3D display device before the posture change comprises: any one of the transverse screen display posture, the vertical screen display posture, and the oblique screen display posture; a second posture of the 3D display device after the posture change comprises: any one, different from the first posture, of the transverse screen display posture, the vertical screen display posture, and the oblique screen display posture; and adjusting a display orientation of a 3D image comprises: rotating the 3D image so that the 3D image is kept in an initial display orientation corresponding to the first posture.</p><p id="p-0012" num="0011">In some embodiments, when any one of the first posture and the second posture is the oblique screen display posture, adjusting a display orientation of a 3D image further comprises: displaying the 3D image in a full screen display mode.</p><p id="p-0013" num="0012">In some embodiments, adjusting a display orientation of a 3D image comprises: rotating the display orientation of the 3D image in a plane in which the 3D image is located, so that the 3D image is kept within an initial display orientation range, wherein the initial display orientation range comprises the initial display orientation.</p><p id="p-0014" num="0013">In some embodiments, the method for realizing 3D image display further comprises: adjusting the display orientation of the 3D image according to a viewing orientation of a user, so that the display orientation of the 3D image coincides with the viewing orientation of the user.</p><p id="p-0015" num="0014">In some embodiments, the viewing orientation of the user comprises: any one of a transverse viewing orientation, a vertical viewing orientation, and an oblique viewing orientation; and the method for realizing 3D image display further comprises: performing eye positioning for the user, and determining the viewing orientation of the user according to the obtained eye positioning data.</p><p id="p-0016" num="0015">In some embodiments, adjusting a display orientation of a 3D image comprises: rendering corresponding subpixels in composite subpixels in the multi-viewpoint 3D display screen, based on the adjusted display orientation of the 3D image.</p><p id="p-0017" num="0016">In some embodiments, rendering corresponding subpixels in composite subpixels in the multi-viewpoint 3D display screen comprises: rendering the subpixels, corresponding to the viewpoints, in each composite subpixel, based on the viewpoints corresponding to the subpixels in each composite subpixel after the posture change of the 3D display device.</p><p id="p-0018" num="0017">In some embodiments, a plurality of subpixels in each composite subpixel are arranged in an i&#xd7;j array, wherein subpixels in the i&#xd7;j array of each composite subpixel correspond to i viewpoints before the posture change of the 3D display device; or subpixels in the i&#xd7;j array of each composite subpixel correspond to j viewpoints after the posture change of the 3D display device.</p><p id="p-0019" num="0018">In some embodiments, a 3D display device is provided, comprising: a processor, and a memory storing program instructions, wherein the processor is configured to implement the above method when executing the program instructions.</p><p id="p-0020" num="0019">In some embodiments, a 3D display device is provided, comprising: a multi-viewpoint 3D display screen, comprising a plurality of composite pixels and a plurality of spherical gratings covering the plurality of composite pixels, wherein each composite pixel of the plurality of composite pixels comprises a plurality of composite subpixels, and each composite subpixel of the plurality of composite subpixels comprises a plurality of subpixels corresponding to a plurality of viewpoints; a posture detection apparatus, configured to detect a posture change of the 3D display device; and a 3D processing apparatus, configured to adjust a display orientation of a displayed 3D image based on the detected posture change of the 3D display device so that the 3D image is kept in an initial display orientation before the posture change of the 3D display device.</p><p id="p-0021" num="0020">In some embodiments, the posture detection apparatus is configured to detect a rotational angular velocity of the 3D display device, and determine the posture change of the 3D display device according to the rotational angular velocity; and the 3D processing apparatus is configured to rotate the display orientation of a 3D image in a plane, in which the 3D image is located, so that the 3D image is kept in an initial display orientation before the posture change of the 3D display device.</p><p id="p-0022" num="0021">In some embodiments, the posture of the 3D display device comprises at least one of: a transverse screen display posture, a vertical screen display posture, and an oblique screen display posture.</p><p id="p-0023" num="0022">In some embodiments, a first posture of the 3D display device before the posture change comprises: any one of a transverse screen display posture, a vertical screen display posture, and an oblique screen display posture; a second posture of the 3D display device after the posture change comprises: any one, different from the first posture, of a transverse screen display posture, a vertical screen display posture, and an oblique screen display posture; and the 3D processing apparatus is configured to rotate the 3D image so that the 3D image is kept in an initial display orientation corresponding to the first posture.</p><p id="p-0024" num="0023">In some embodiments, the 3D processing apparatus is configured to display the 3D image in a full screen display mode when any one of the first posture and the second posture is the oblique screen display posture.</p><p id="p-0025" num="0024">In some embodiments, the 3D processing apparatus is configured to rotate the display orientation of a 3D image in a plane, in which the 3D image is located, so that the 3D image is kept within an initial display orientation range, wherein the initial display orientation range comprises the initial display orientation.</p><p id="p-0026" num="0025">In some embodiments, the 3D processing apparatus is configured to adjust the display orientation of the 3D image according to a viewing orientation of a user, so that the display orientation of the 3D image coincides with the viewing orientation of the user.</p><p id="p-0027" num="0026">In some embodiments, the viewing orientation of user comprises any one of: a transverse viewing orientation, a vertical viewing orientation, and an oblique viewing orientation; the 3D display device further comprises an eye positioning apparatus or an eye positioning data interface, configured to acquire eye positioning data; and the 3D processing apparatus is configured to determine the viewing orientation of the user according to the obtained eye positioning data.</p><p id="p-0028" num="0027">In some embodiments, the 3D processing apparatus is configured to render composite pixels in the multi-viewpoint 3D display screen of the 3D display device based on the adjusted display orientation of the 3D image.</p><p id="p-0029" num="0028">In some embodiments, the 3D processing apparatus is configured to render the subpixels, corresponding to the viewpoints in composite subpixels contained in the multi-viewpoint 3D display screen, based on the viewpoints corresponding to the subpixels in each composite subpixel after the posture change of the 3D display device.</p><p id="p-0030" num="0029">In some embodiments, a plurality of subpixels in each composite subpixel are arranged in an i&#xd7;j array, wherein subpixels in the i&#xd7;j array of each composite subpixel correspond to i viewpoints before the posture change of the 3D display device; or subpixels in the i&#xd7;j array of each composite subpixel correspond to j viewpoints after the posture change of the 3D display device.</p><p id="p-0031" num="0030">The computer-readable storage medium provided by the embodiments of the present disclosure stores computer-executable instructions; and the computer-executable instructions are configured to implement the method for realizing 3D image display.</p><p id="p-0032" num="0031">The computer program product provided by the embodiments of the present disclosure comprises computer programs stored on the computer-readable storage medium; the computer programs comprise program instructions; and when the program instructions are executed by a computer, the computer is allowed to implement the above method for realizing 3D image display.</p><p id="p-0033" num="0032">The method for realizing 3D image display, the 3D display device, the computer-readable storage medium, and the computer program product provided by the embodiments of the present disclosure may achieve the following technical effects:</p><p id="p-0034" num="0033">The 3D display device can display suitable 3D effects in different postures, and cannot be affected by the posture adjustment of the 3D display device.</p><p id="p-0035" num="0034">The above general description and the following description are exemplary and explanatory only, and are not intended to limit the present disclosure.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">DESCRIPTION OF DRAWINGS</heading><p id="p-0036" num="0035">One or more embodiments are illustrated by the corresponding drawings, and the illustrations and drawings do not limit the embodiments. Elements having the same reference numerals in the drawings are shown as similar elements, and the drawings are not intended to limit the scale, wherein:</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIGS. <b>1</b>A to <b>1</b>C</figref> are structural schematic diagrams of a 3D display device according to embodiments of the present disclosure;</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram of the correspondence between spherical gratings and composite subpixels according to an embodiment of the present disclosure;</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>3</b>B</figref> are schematic diagrams of the correspondence between composite subpixels and viewpoints in different postures of a 3D display device according to embodiments of the present disclosure;</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic diagram of arrangement of composite subpixels in composite pixels according to an embodiment of the present disclosure;</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a structural schematic diagram of hardware of a 3D display device according to an embodiment of the present disclosure;</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a structural schematic diagram of software of a 3D display device according to an embodiment of the present disclosure;</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a schematic diagram of formats and contents of images contained in video frames of 3D video signals according to an embodiment of the present disclosure;</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIGS. <b>8</b>A and <b>8</b>B</figref> are schematic diagrams of a 3D display device rendering subpixels in a first posture according to an embodiment of the present disclosure;</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIGS. <b>9</b>A and <b>9</b>B</figref> are schematic diagrams of a 3D display device rendering subpixels in a second posture according to an embodiment of the present disclosure;</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart of switching display of 3D images in a 3D display device according to an embodiment of the present disclosure; and</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a structural schematic diagram of a 3D display device according to an embodiment of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0048" num="0047">REFERENCE NUMERALS</p><p id="p-0049" num="0048"><b>100</b>: 3D display device; <b>110</b>: multi-viewpoint 3D display screen; <b>120</b>: processor; <b>121</b>: register; <b>130</b>: 3D processing apparatus; <b>131</b>: buffer; <b>140</b>: video signal interface; <b>150</b>: eye positioning apparatus; <b>160</b>: eye positioning data interface; <b>171</b>: first posture playing region; <b>172</b>: second posture playing region; <b>180</b>: posture detection apparatus; <b>190</b>: spherical grating; <b>200</b>: 3D display device; <b>201</b>: processor; <b>202</b>: multi-viewpoint 3D display screen; <b>203</b>: 3D processing apparatus; <b>204</b>: video signal interface; <b>205</b>: eye positioning apparatus; <b>206</b>: shooting apparatus; <b>207</b>: indicator; <b>208</b>: motor; <b>209</b>: button; <b>210</b>: memory; <b>211</b>: subscriber identity module (SIM) card interface; <b>212</b>: external memory interface; <b>213</b>: universal serial bus (USB) interface; <b>214</b>: charging management module; <b>215</b>: power management module; <b>216</b>: battery; <b>217</b>: register; <b>218</b>: GPU; <b>219</b>: codec; <b>220</b>: sensor module; <b>221</b>: proximity light sensor; <b>222</b>: ambient light sensor; <b>223</b>: pressure sensor; <b>224</b>: air pressure sensor; <b>225</b>: magnetic sensor; <b>226</b>: gravity sensor; <b>227</b>: gyro sensor; <b>228</b>: acceleration sensor; <b>229</b>: distance sensor; <b>230</b>: temperature sensor; <b>231</b>: fingerprint sensor; <b>232</b>: touch sensor; <b>233</b>: bone conduction sensor; <b>234</b>: audio module; <b>235</b>: loudspeaker; <b>236</b>: receiver; <b>237</b>: microphone; <b>238</b>: earphone interface; <b>239</b>: antenna; <b>240</b>: mobile communication module; <b>241</b>: antenna; <b>242</b>: wireless communication module; <b>300</b>: 3D display device; <b>310</b>: memory; <b>320</b>: processor; <b>330</b>: bus; <b>340</b>: communication interface; <b>400</b>: composite pixel; <b>410</b>: red composite subpixel; <b>420</b>: green composite subpixel; <b>430</b>: blue composite subpixel; <b>510</b>: application program layer; <b>520</b>: framework layer; <b>530</b>: core class library and runtime; <b>540</b>: kernel layer; <b>601</b>: one of two images contained in video frames of a 3D video signal; and <b>602</b>: one of two images contained in video frames of a 3D video signal.</p><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0050" num="0049">For more detailed understanding of characteristics and technical contents of embodiments of the present disclosure, the implementation of the embodiments of the present disclosure will be described in detail below with reference to the accompanying drawings, and the accompanying drawings are used for reference only, instead of limiting the embodiments of the present disclosure.</p><p id="p-0051" num="0050">Embodiments of the present disclosure provide a 3D display device, comprising a multi-viewpoint 3D display screen (such as: a multi-viewpoint naked-eye 3D display screen), a posture detection apparatus, a 3D signal interface, and a 3D processing apparatus. The 3D display device has a plurality of viewpoints, and has viewpoints corresponding to postures based on the postures of the 3D display device.</p><p id="p-0052" num="0051">The multi-viewpoint 3D display screen comprises a plurality of composite pixels and a plurality of spherical gratings. Each composite pixel comprises a plurality of composite subpixels. The plurality of composite subpixels are covered by the plurality of spherical gratings. In some embodiments, the composite subpixels and the spherical gratings are arranged in one-to-one correspondence. Each composite subpixel comprises a plurality of subpixels, for example, comprises a plurality of subpixels in the form of i&#xd7;j array. In some embodiments, each composite subpixel comprises a plurality of homochromatic subpixels in the form of i&#xd7;j array. In some embodiments, subpixels in the i&#xd7;j array or homochromatic subpixels in the i&#xd7;j array correspond to i first posture viewpoints in a first posture of the 3D display device and j second posture viewpoints in a second posture of the 3D display device. In some embodiments, i&#x2265;3, and j&#x3e;3. The multi-viewpoint 3D display screen may define a first posture playing region of the 3D display device in the first posture and a second posture playing region of the 3D display device in a second posture. The first posture playing region and the second posture playing region may be the same or different, or overlapped in positions.</p><p id="p-0053" num="0052">The posture detection apparatus is configured to detect a posture of the 3D display device, comprising: detecting a posture change of the 3D display device, or detecting a posture in which the 3D display device is, or detecting the both. The 3D signal interface is configured to receive 3D signals.</p><p id="p-0054" num="0053">The 3D processing apparatus is configured to adjust the display of a 3D image based on the posture of the 3D display device or the posture change of the 3D display device or the both, so that a display orientation of the 3D image is kept in an initial display orientation before the posture change of the 3D display device. Thus, the display orientation of the 3D image may always be consistent with an orientation of the user.</p><p id="p-0055" num="0054">In some embodiments, the 3D processing apparatus processes 3D signals to play the 3D images from 3D contents in the first posture playing region and the 3D images from the 3D contents in the second posture playing region. As for the user, display orientations of the 3D images played in the first posture playing region and the second posture playing region are consistent.</p><p id="p-0056" num="0055">In embodiments of the present disclosure, the &#x201c;posture&#x201d; of the 3D display device is equivalent to the &#x201c;orientation&#x201d; of the 3D display device.</p><p id="p-0057" num="0056">In some embodiments, the 3D processing apparatus is communicatively connected with the multi-viewpoint 3D display screen. In some embodiments, the 3D processing apparatus is communicatively connected with a driving apparatus of the multi-viewpoint 3D display screen. In some embodiments, the 3D processing apparatus is communicatively connected with the posture detection apparatus.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> shows a 3D display device <b>100</b> according to embodiments of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, the 3D display device <b>100</b> comprises a multi-viewpoint 3D display screen <b>110</b>, a 3D processing apparatus <b>130</b>, a 3D signal interface (e.g., a video signal interface <b>140</b>) configured to receive video frames of 3D signals such as 3D video signals, a processor <b>120</b>, and a posture detection apparatus <b>180</b>. In an embodiment shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, the multi-viewpoint 3D display screen <b>110</b> may comprise a display panel and gratings covering the display panel. The display panel may comprise m columns and n rows (m&#xd7;n) of composite pixels and thus define a display resolution of m&#xd7;n.</p><p id="p-0059" num="0058">In some embodiments, each composite pixel comprises red composite subpixels composed of red subpixels in the i&#xd7;j array, blue composite subpixels composed of blue subpixels in the i&#xd7;j array, and green composite subpixels composed of green subpixels in the i&#xd7;j array. <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> shows an example of a red composite subpixel <b>410</b> composed of red subpixels in the i&#xd7;j array.</p><p id="p-0060" num="0059">In embodiments of the present disclosure, each composite subpixel has corresponding subpixels corresponding to viewpoints. The plurality of subpixels of each composite subpixel are arranged in rows in a transverse direction of the multi-viewpoint 3D display screen; and colors of the plurality of subpixels in rows are the same. Because the multiple viewpoints of the 3D display device are roughly arranged along the transverse direction of the multi-viewpoint 3D display screen, when the user moves to make eyes be in different viewpoints, different subpixels, corresponding to the corresponding viewpoints, in each composite subpixel need to be rendered dynamically. Because the homochromatic subpixels of each composite subpixel are arranged in rows, a cross-color problem caused by persistence of vision can be avoided. In addition, due to refraction of the grating, a part of currently displayed subpixels may be seen at an adjacent viewpoint. However, through arrangement of subpixels with the same color in the same row, a problem of color mixing is absent even if a part of the currently displayed subpixels are seen.</p><p id="p-0061" num="0060">In some embodiments, the gratings comprise a plurality of spherical gratings, and each composite subpixel in the display panel is covered by a corresponding spherical grating. <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates the correspondence between a red composite subpixel <b>410</b> and a spherical grating <b>190</b>. The gratings may be composed of a plurality of spherical gratings <b>190</b> arranged in an array, and each spherical grating <b>190</b> covers a corresponding composite subpixel. Although <figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a spherical grating with a square bottom surface and a circular arc top surface, other configurations of the spherical grating are conceivable. For example, the bottom surface of the spherical grating may be rectangular or hexagonal. For another example, the top surface of the spherical grating may be a circular arc surface or an elliptical arc surface. For another example, the top surface of the spherical grating is directly bonded to the bottom surface. For another example, other planes are connected between the top surface and the bottom surface of the spherical grating; and as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, four cross-sectional planes are defined between the circular arc top surface and the square bottom surface of the spherical grating <b>190</b>.</p><p id="p-0062" num="0061">In some embodiments, the top surface of the spherical grating is provided with another refractive layer with a refractive index different from that of the spherical grating; a surface, facing the spherical grating, of the another refractive layer is bonded with the top surface of the spherical grating in a concave-convex matching manner; and the surface facing away from the spherical grating is a plane, such as a plane parallel to the bottom surface of the spherical grating.</p><p id="p-0063" num="0062">In some embodiments, the 3D display device <b>100</b> may be a mobile terminal. Referring to <figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>3</b>B</figref>, examples of the posture (orientation) of the 3D display device <b>100</b> in the form of mobile terminal are shown. As shown in figures, the 3D display device <b>100</b> has a first posture (see <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>) such as a transverse screen display posture and a second posture (see <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>) such as a vertical screen display posture. The 3D display device <b>100</b> may be switched between the first posture and the second posture. The multi-viewpoint 3D display screen <b>110</b> defines a first posture playing region <b>171</b> adapted to the first posture and a second posture playing region <b>172</b> adapted to the second posture. In the illustrated embodiments, the first posture playing region <b>171</b> and the second posture playing region <b>172</b> have different dimensions. The area of the first posture playing region <b>171</b>, for example, may account for 80% to 100% of the area of the multi-viewpoint 3D display screen. The area of the second posture playing region <b>172</b>, for example, may account for 30% to 60% of the area of the multi-viewpoint 3D display screen. When the 3D display device is in the second posture, the second posture playing region <b>172</b>, for example, may be located in the middle of the multi-viewpoint 3D display screen.</p><p id="p-0064" num="0063">The 3D display device <b>100</b> may have i first posture viewpoints Vi corresponding to the first posture, and have j second posture viewpoints Vj corresponding to the second posture. Correspondingly, the homochromatic subpixels in the i&#xd7;j array of each composite subpixel correspond to i first posture viewpoints of the 3D display device in the first posture and correspond to j second posture viewpoints of the 3D display device in the second posture. In embodiments shown in <figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>3</b>B</figref>, the 3D display device <b>100</b> has six first posture viewpoints Vi<b>1</b>-Vi<b>6</b>, and three second posture viewpoints Vj<b>1</b>-Vj<b>3</b>; and the subpixels of each composite subpixel are arranged in the form of 6&#xd7;3 array. The figures illustrate only the correspondence between the red subpixels in the i&#xd7;j array of one red composite subpixel <b>410</b> and the viewpoints in two postures. In the illustrated embodiments, i=6 and j=3; and conceivably, i and j are other values equal to or greater than 3, respectively.</p><p id="p-0065" num="0064">In some embodiments, the posture of the 3D display device comprises at least one of: a transverse screen display posture, a vertical screen display posture, and an oblique screen display posture.</p><p id="p-0066" num="0065">In some embodiments, the first posture of the 3D display device comprises: any one, different from the first posture, of the transverse screen display posture, the vertical screen display posture, and the oblique screen display posture; and the second posture of the 3D display device comprises any one of: the transverse screen display posture, the vertical screen display posture, and the oblique screen display posture.</p><p id="p-0067" num="0066">In embodiments shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A, <b>2</b>, <b>3</b>A and <b>3</b>B</figref>, each composite subpixel in the display panel is roughly square; i&#x3e;j is satisfied in the homochromatic subpixels in the i&#xd7;j array of each composite subpixel; and an aspect ratio of each subpixel of each composite subpixel is equal to i/j. Conceivably, the composite subpixels and the subpixels may have other suitable shapes. In some embodiments, each composite subpixel is roughly square; i=j is satisfied in the homochromatic subpixels in the i&#xd7;j array of each composite subpixel; and the aspect ratio of each subpixel is roughly equal to 1. In some embodiments, each composite subpixel is rectangular; each subpixel of each composite subpixel is square or roughly square; and i/j is equal to the aspect ratio of the display panel.</p><p id="p-0068" num="0067">In some embodiments, composite subpixels in different colors are alternately arranged in the display panel; and the plurality of composite subpixels of each composite pixel are arranged in a triangle. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, in the display panel, red composite subpixels <b>410</b>, green composite subpixels <b>420</b>, and blue composite subpixels <b>430</b> are alternately arranged; and the red composite subpixels <b>410</b>, the green composite subpixels <b>420</b> and the blue composite subpixels <b>430</b> of each composite pixel <b>400</b> are arranged in a triangle.</p><p id="p-0069" num="0068">In some embodiments, the 3D processing apparatus <b>130</b> may optionally comprise a buffer <b>131</b>, to buffer the received video frames.</p><p id="p-0070" num="0069">Referring to <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, the 3D display device <b>100</b> may further comprise a processor <b>120</b> communicatively connected to the 3D processing apparatus <b>130</b> through a video signal interface <b>140</b>. In some embodiments, the processor <b>120</b> is contained in a computer or an intelligent terminal such as a mobile terminal, or serves as a processor unit.</p><p id="p-0071" num="0070">In some embodiments, the video signal interface <b>140</b> is an internal interface for connecting the processor <b>120</b> with the 3D processing apparatus <b>130</b>. Such a 3D display device <b>100</b>, for example, may be a mobile terminal; and the video signal interface <b>140</b> may be a mobile industry processor interface (MIPI), a mini-MIPI, a low voltage differential signaling (LVDS) interface, a min-LVDS interface or a Display Port interface.</p><p id="p-0072" num="0071">In some embodiments, as shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, the processor <b>120</b> of the 3D display device <b>100</b> may further comprise a register <b>121</b>. The register <b>121</b> may be configured to temporarily store instructions, data and addresses.</p><p id="p-0073" num="0072">In some embodiments, the posture detection apparatus <b>180</b> is communicatively connected with the processor <b>120</b>. The posture detection apparatus <b>180</b> may be a gravity sensor or a gyro sensor.</p><p id="p-0074" num="0073">In some embodiments, the 3D display device further comprises an eye positioning apparatus or an eye positioning data interface, configured to acquire eye positioning data. For example, in embodiments shown in <figref idref="DRAWINGS">FIGS. <b>1</b>B, <b>3</b>A and <b>3</b>B</figref>, the 3D display device <b>100</b> comprises an eye positioning apparatus <b>150</b> communicatively connected to the 3D processing apparatus <b>130</b>, so that the 3D processing apparatus <b>130</b> may directly receive eye positioning data. In an embodiment shown in <figref idref="DRAWINGS">FIG. <b>1</b>C</figref>, an eye positioning apparatus (not shown), for example, may be directly connected to the processor <b>120</b>; and the 3D processing apparatus <b>130</b> acquires eye positioning data from the processor <b>120</b> through an eye positioning data interface <b>160</b>. In other embodiments, the eye positioning apparatus may be simultaneously connected with the processor and the 3D processing apparatus, so that on the one hand, the 3D processing apparatus <b>130</b> may directly acquire eye positioning data from the eye positioning apparatus, and on the other hand, other information acquired by the eye positioning apparatus may be processed by the processor.</p><p id="p-0075" num="0074">Exemplarily, <figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a structural schematic diagram of hardware of a 3D display device <b>200</b> implemented as a mobile terminal such as a smart cell phone, or a tablet personal computer (PC). In the illustrated embodiment, the 3D display device <b>200</b> may comprise a processor <b>201</b>, an external memory interface <b>211</b>, an (internal) memory <b>210</b>, a USB interface <b>213</b>, a charging management module <b>214</b>, a power management module <b>215</b>, a battery <b>216</b>, a mobile communication module <b>240</b>, a wireless communication module <b>242</b>, antennas <b>239</b> and <b>241</b>, an audio module <b>234</b>, a loudspeaker <b>235</b>, a receiver <b>233</b>, a microphone <b>237</b>, an earphone interface <b>238</b>, a button <b>209</b>, a motor <b>208</b>, an indicator <b>207</b>, a SIM card interface <b>221</b>, a multi-viewpoint 3D display screen <b>202</b>, a 3D processing apparatus <b>203</b>, a 3D signal interface (such as a video signal interface <b>204</b>), a shooting apparatus <b>206</b>, an eye positioning apparatus <b>205</b>, and a sensor module <b>220</b>.</p><p id="p-0076" num="0075">In some embodiments, the sensor module <b>220</b> may comprise a proximity light sensor <b>221</b>, an ambient light sensor <b>222</b>, a pressure sensor <b>223</b>, an air pressure sensor <b>224</b>, a magnetic sensor <b>225</b>, a gravity sensor <b>226</b>, a gyro sensor <b>227</b>, an acceleration sensor <b>228</b>, a distance sensor <b>229</b>, a temperature sensor <b>230</b>, a fingerprint sensor <b>231</b>, a touch sensor <b>232</b>, and a bone conduction sensor <b>233</b>.</p><p id="p-0077" num="0076">In some embodiments, the processor <b>201</b> may comprise one or more processing units. In some embodiments, the processor <b>201</b> may comprise one or a combination of at least two of: an application processor (AP), a modem processor, a baseband processor, a graphics processing unit (GPU), an image signal processor (ISP), a controller, a memory, a video codec, a digital signal processor (DSP), a baseband processor, a neural network processor (NPU) and the like. Different processing units may be independent elements, and may also be integrated in one or more processors.</p><p id="p-0078" num="0077">In some embodiments, the processor <b>201</b> may comprise one or more interfaces. Interfaces may comprise an integrated circuit (I2C) interface, an integrated circuit built-in audio (I2S) interface, a pulse code modulation (PCM) interface, a universal asynchronous receiver-transmitter (UART) interface, a mobile industry processor interface (MIPI), a general purpose input-output (GPIO) interface, an SIM interface, a USB interface and the like.</p><p id="p-0079" num="0078">The USB interface <b>213</b> is an interface compliant with USB standard specifications, and may be a Mini USB interface, a Micro USB interface, a USB Type C interface or the like. The USB interface <b>213</b> may be used for connecting with the charger to charge the 3D display device <b>200</b>, and may also be used for transmitting data between the 3D display device <b>200</b> and the peripheral devices. The USB interface <b>213</b> may also be used for connecting with earphones and playing audio through the earphones.</p><p id="p-0080" num="0079">A wireless communication function of the 3D display device <b>200</b> may be realized by the antennas <b>241</b> and <b>239</b>, the mobile communication module <b>240</b>, the wireless communication module <b>242</b>, the modem processor, the baseband processor or the like.</p><p id="p-0081" num="0080">In some embodiments, the antenna <b>239</b> of the 3D display device <b>200</b> is coupled with the mobile communication module <b>240</b>, and the antenna <b>241</b> is coupled with the wireless communication module <b>242</b>, so that the 3D display device <b>200</b> may communicate with the network and other devices through wireless communication technology.</p><p id="p-0082" num="0081">In some embodiments, the external interface for receiving 3D video signals may comprise the USB interface <b>213</b>, the mobile communication module <b>240</b>, the wireless communication module <b>242</b>, or any combination thereof.</p><p id="p-0083" num="0082">The memory <b>210</b> may be used for storing computer-executable program codes, which comprise instructions. The processor <b>201</b> implements application of various functions and data processing of the 3D display device <b>200</b> by running the instructions stored in the memory <b>210</b>.</p><p id="p-0084" num="0083">The external memory interface <b>212</b> may be used for connecting with an external memory card, such as a Micro SD card, to expand storage capacity of the 3D display device <b>200</b>. The external memory card communicates with the processor <b>201</b> through the external memory interface <b>212</b>, to realize a data storage function.</p><p id="p-0085" num="0084">In some embodiments, memories of the 3D display device may comprise the (internal) memory <b>210</b>, an external memory card connected with the external memory interface <b>212</b>, or a combination thereof.</p><p id="p-0086" num="0085">In embodiments of the present disclosure, the shooting apparatus <b>206</b> may capture images or videos.</p><p id="p-0087" num="0086">In some embodiments, the 3D display device <b>200</b> realizes a display function through the video signal interface <b>204</b>, the 3D processing apparatus <b>203</b>, the multi-viewpoint 3D display screen <b>202</b>, and the application processor.</p><p id="p-0088" num="0087">In some embodiments, the 3D display device <b>200</b> may comprise a GPU <b>218</b>, for example, be used for processing 3D video images in the processor <b>201</b>, and be also used for processing 2D video images.</p><p id="p-0089" num="0088">In some embodiments, the 3D display device <b>200</b> further comprises a video codec <b>219</b> configured to compress or decompress digital videos.</p><p id="p-0090" num="0089">In some embodiments, the video signal interface <b>204</b> is configured to output a video frame of a 3D video signal, such as a decompressed 3D video signal, processed by the GPU <b>218</b> or the codec <b>219</b> or both to the 3D processing apparatus <b>203</b>.</p><p id="p-0091" num="0090">In some embodiments, the GPU <b>218</b> or the codec <b>219</b> is integrated with a format adjuster. The multi-viewpoint 3D display screen <b>202</b> is used for displaying 3D images or videos. The multi-viewpoint 3D display screen <b>202</b> comprises a display panel and spherical gratings covering the display panel.</p><p id="p-0092" num="0091">In some embodiments, the eye positioning apparatus <b>205</b> is communicatively connected to the 3D processing apparatus <b>203</b>, so that the 3D processing apparatus <b>203</b> may render the corresponding subpixels in the composite pixels (composite subpixels) based on the eye positioning data. In some embodiments, the eye positioning apparatus <b>205</b> may further be connected to the processor <b>201</b>, such as be in by-passing connection with the processor <b>201</b>.</p><p id="p-0093" num="0092">The 3D display device <b>200</b> may realize audio functions through the audio module <b>234</b>, the loudspeaker <b>235</b>, the receiver <b>236</b>, the microphone <b>237</b>, the earphone interface <b>238</b>, the application processor and the like,</p><p id="p-0094" num="0093">The button <b>209</b> comprises a power button, a volume button and the like. The button <b>209</b> may be a mechanical button, and may also be a touch button. The 3D display device <b>200</b> may receive button input, and generate button signal input related to user settings and function control of the 3D display device <b>200</b>.</p><p id="p-0095" num="0094">The motor <b>208</b> may generate a vibration alert. The motor <b>208</b> may be configured to vibrate to prompt an incoming call, and may also be configured to vibrate to feed touch back.</p><p id="p-0096" num="0095">The SIM card interface <b>211</b> is configured to connect with a SIM card. In some embodiments, the 3D display device <b>200</b> adopts an embedded SIM card (eSIM).</p><p id="p-0097" num="0096">The pressure sensor <b>223</b> is configured to sense pressure signals, and may convert the pressure signals into electrical signals.</p><p id="p-0098" num="0097">The air pressure sensor <b>224</b> is used for measuring air pressure.</p><p id="p-0099" num="0098">The magnetic sensor <b>225</b> comprises a Hall sensor.</p><p id="p-0100" num="0099">The gravity sensor <b>226</b>, as a posture detection apparatus, can convert motion or gravity into electrical signals, and is configured to measure parameters, such as tilt angle, inertia force, impact and vibration.</p><p id="p-0101" num="0100">The gyro sensor <b>227</b>, as a posture detection apparatus, is configured to determine a motion posture of the 3D display device <b>200</b>.</p><p id="p-0102" num="0101">In some embodiments, the posture detection apparatus detects a rotational angular velocity of the 3D display device, and determines the posture change of the 3D display device according to the rotational angular velocity.</p><p id="p-0103" num="0102">The gravity sensor <b>226</b> or the gyro sensor <b>227</b> may be adopted to detect that the 3D display device <b>200</b> is in a first posture or a second posture different from the first posture, or the 3D display device is converted between the first posture and the second posture.</p><p id="p-0104" num="0103">The acceleration sensor <b>228</b> may detect acceleration of the 3D display device <b>200</b> in various directions (generally three axes).</p><p id="p-0105" num="0104">The distance sensor <b>229</b> may be configured to measure a distance.</p><p id="p-0106" num="0105">The temperature sensor <b>230</b> may be configured to detect a temperature.</p><p id="p-0107" num="0106">The fingerprint sensor <b>231</b> may be configured to collect fingerprints.</p><p id="p-0108" num="0107">The touch sensor <b>232</b> may be arranged in the multi-viewpoint 3D display screen <b>202</b>; and the touch sensor <b>232</b> and the multi-viewpoint 3D display screen <b>202</b> form a touch screen, also called a &#x201c;touch panel&#x201d;.</p><p id="p-0109" num="0108">The bone conduction sensor <b>233</b> may acquire vibration signals.</p><p id="p-0110" num="0109">The charging management module <b>214</b> is configured to receive charging input from the charger.</p><p id="p-0111" num="0110">The power management module <b>215</b> is configured to connect the battery <b>216</b> and the charging management module <b>214</b> to the processor <b>201</b>. The power management module <b>215</b> receives input from at least one of the battery <b>216</b> and the charging management module <b>214</b>, and supplies power to the processor <b>201</b>, the memory <b>210</b>, the external memory, the multi-viewpoint 3D display screen <b>202</b>, the shooting apparatus <b>206</b>, the wireless communication module <b>242</b> and the like. In other embodiments, the power management module <b>215</b> and the charging management module <b>214</b> may also be arranged in the same device.</p><p id="p-0112" num="0111">A software system of the 3D display device <b>200</b> may adopt a hierarchical architecture, an event-driven architecture, a microkernel architecture, a micro-service architecture or a cloud architecture. In embodiments shown in the present disclosure, an Android system with the hierarchical architecture is taken as an example, to illustrate a structure of software of the 3D display device <b>200</b>. However, conceivably, the embodiments of the present disclosure may be implemented in different software systems, such as an operating system.</p><p id="p-0113" num="0112"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a structural schematic diagram of the software of the 3D display device <b>200</b> according to an embodiment of the present disclosure. The hierarchical architecture divides software into several layers. The layers communicate with each other through a software interface. In some embodiments, the Android system is divided into four layers, from top to bottom, comprising an application program layer <b>510</b>, a framework layer <b>520</b>, core class library and runtime <b>530</b>, and a kernel layer <b>540</b>.</p><p id="p-0114" num="0113">The application program layer <b>510</b> may comprise a series of application packages. As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the application packages may comprise application programs, such as Bluetooth, WLAN, navigation, music, camera, calendar, call, video, gallery, map and short message.</p><p id="p-0115" num="0114">The framework layer <b>520</b> provides an application programming interface (API) and a programming framework for application programs in the application program layer. As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the framework layer <b>520</b> may comprise a resource manager, a phone manager, a content manager, a notification manager, a window manager, a view system installation package and manager and the like.</p><p id="p-0116" num="0115">Android Runtime comprises a core library and a virtual machine. The Android Runtime is responsible for scheduling and management of an Android system. The core library comprises two parts: one is performance functions to be called by java language, and the other is the core library of Android.</p><p id="p-0117" num="0116">The application program layer and the framework layer run in the virtual machine. The virtual machine executes java files of the application program layer and the framework layer as binary files. The virtual machine is used for implementing functions of object life cycle management, stack management, thread management, security and exception management, garbage collection and the like.</p><p id="p-0118" num="0117">The core class library may comprise a plurality of functional modules, such as a 3D graphics processing library (such as OpenGL ES), a surface manager, an image processing library, a media library and a graphics engine (such as SGL).</p><p id="p-0119" num="0118">The kernel layer <b>540</b> is a layer between hardware and software. The kernel layer at least comprises a camera driver, an audio and video interface, a call interface, a Wifi interface, a sensor driver, a power management and a GPS interface.</p><p id="p-0120" num="0119">Transmission and display of a 3D video signal in the 3D display device according to embodiments of the present disclosure are described below with reference to <figref idref="DRAWINGS">FIG. <b>7</b></figref>. As described above, the 3D display device respectively corresponds to a plurality of viewpoints in different postures. Eyes of the user may see the display of corresponding subpixels in composite subpixels of each composite pixel in the display panel of the display screen at each viewpoint (spatial position) corresponding to each posture. Two different pictures seen by both eyes of the user at different viewpoints form parallax, to composite a 3D picture in the brain.</p><p id="p-0121" num="0120">In some embodiments of the present disclosure, the 3D processing apparatus <b>130</b> receives, for example, video frames of a decompressed 3D video signal from the processor <b>120</b> through, for example, the video signal interface <b>140</b> as the internal interface. Each video frame may contain two images, or contain composite images, or be composed of the above images.</p><p id="p-0122" num="0121">In some embodiments, the two images or the composite images may comprise different types of images and may be in various arrangement forms.</p><p id="p-0123" num="0122">As shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, each video frame of the 3D video signal contains or is composed of two images <b>601</b> and <b>602</b> in parallel. In some embodiments, the two images may be a left-eye parallax image and a right-eye parallax image, respectively. In some embodiments, the two images may be a rendered color image and a depth of field (DOF) image, respectively.</p><p id="p-0124" num="0123">In some embodiments, each video frame of the 3D video signal contains interlaced composite images. In some embodiments, the composite images may be interlaced left-eye and right-eye parallax composite images, and interlaced rendered color and DOF composite images.</p><p id="p-0125" num="0124">In some embodiments, after receiving a video frame comprising two images <b>601</b> and <b>602</b>, at least one 3D processing apparatus <b>130</b> renders at least one subpixel in each composite subpixel based on one of the two images and at least another subpixel in each composite subpixel based on the other of the two images.</p><p id="p-0126" num="0125">In other embodiments, after receiving a video frame comprising composite images, at least one 3D processing apparatus renders at least two subpixels in each composite subpixel based on the composite images. For example, at least one subpixel is rendered according to a first image (part) in the composite images, and at least another subpixel is rendered according to a second image (part).</p><p id="p-0127" num="0126">As described above, the 3D display device according to embodiments of the present disclosure has a plurality of different postures, and different playing regions formed with adaption to the postures. In some embodiments, the 3D display device has a transverse screen display posture and a vertical screen display posture, and has two playing regions defined with adaption to the two postures. The posture detection apparatus, such as a gravity sensor or a gyro sensor, is configured to detect the posture in which the 3D display device is, or the switch/change of the posture of the 3D display device. The 3D processing apparatus is configured to process video frames of 3D signals, such as 3D video signals, to play 3D images from 3D contents in a first posture playing region and the 3D images from the 3D contents in a second posture playing region.</p><p id="p-0128" num="0127">In some embodiments, the 3D display device <b>100</b> is provided with an eye positioning apparatus <b>150</b>; and the eye positioning apparatus <b>150</b> is configured to acquire eye positioning data.</p><p id="p-0129" num="0128">In some embodiments, the eye positioning apparatus is configured to be communicatively connected with the posture detection apparatus to acquire positions of viewpoints, at which the eyes of the user are, in relation to the posture of the 3D display device.</p><p id="p-0130" num="0129">In some embodiments, the eye positioning apparatus is configured to acquire positions of first posture viewpoints at which the eyes of the user are, in response to a signal that the 3D display device is in the first posture.</p><p id="p-0131" num="0130">In some embodiments, the 3D processing apparatus is configured to render relevant subpixels of homochromatic subpixels in the i&#xd7;j array of each composite subpixel in the first posture playing region according to the 3D images from the 3D contents, based on the first posture viewpoints at which the eyes of the user are.</p><p id="p-0132" num="0131">In some embodiments, the relevant subpixels rendered in the first posture playing region may comprise all subpixels, corresponding to the first posture viewpoints at which the eyes of the user are, in a jth row of subpixels in each composite subpixel.</p><p id="p-0133" num="0132">Referring to <figref idref="DRAWINGS">FIGS. <b>3</b>A, <b>3</b>B and <b>8</b>A</figref>, in the illustrated embodiments, the 3D display device <b>100</b> may have first posture viewpoints Vi<b>1</b>-Vi<b>6</b> corresponding to the first posture, and second posture viewpoints Vj<b>1</b>-Vj<b>3</b> corresponding to the second posture. Each composite pixel in the display panel may comprise red composite subpixels having red subpixels in the i&#xd7;j array, green composite subpixels having green subpixels in the i&#xd7;j array, and blue composite subpixels having blue subpixels in the i&#xd7;j array. In homochromatic subpixels in the i&#xd7;j array of each composite subpixel, corresponding to the first posture viewpoints Vi<b>1</b>-Vi<b>6</b> of the first posture, i=6 is satisfied; and corresponding to the second posture viewpoints Vj<b>1</b>-Vj<b>3</b> of the second posture, j=3 is satisfied. For the sake of clarity, only a correspondence between one red composite subpixel <b>410</b> with i=6 and j=3 and each of the first posture viewpoints Vi<b>1</b>-Vi<b>6</b> and the second posture viewpoints Vj<b>1</b>-Vj<b>3</b> of the 3D display device <b>100</b> is shown in the figures.</p><p id="p-0134" num="0133">In the case that the 3D display device <b>100</b> is in the first posture or switched from the second posture to the first posture, when the eye positioning apparatus <b>150</b> detects the first posture viewpoints at which both eyes of the user are, for example, a left eye is at the first posture viewpoint Vi<b>2</b> and a right eye corresponds to the first posture viewpoint Vi<b>4</b>, images of the first posture viewpoints, corresponding to both eyes of the user, are generated based on the video frames of the 3D video signals; and all red subpixels, corresponding to the first posture viewpoint Vi<b>2</b>, in a jth row of red subpixels in the red composite subpixel <b>410</b> and all red subpixels, corresponding to the first posture viewpoint Vi<b>4</b>, in the jth row of red subpixels are rendered in the first playing region <b>171</b>.</p><p id="p-0135" num="0134">In some embodiments, the relevant subpixels rendered in the first posture playing region may comprise one subpixel, corresponding to the first posture viewpoints at which the eyes of the user are, in the jth row of subpixels in each composite subpixel. For example, one subpixel, corresponding to the first posture viewpoint at which the left eye of the user is, in the jth row of subpixels, and one subpixel, corresponding to the first posture viewpoint at which the right eye of the user is, in the jth row of subpixels may be rendered.</p><p id="p-0136" num="0135">In some embodiments, when the 3D display device is in the first posture, in response to a signal that the 3D display device is in the first posture, the eye positioning apparatus acquires the first posture viewpoints at which the eyes of the user are, and further acquires the second posture viewpoints at which the eyes of the user are. The relevant subpixels rendered in the first posture playing region comprise a subpixel corresponding to an intersection between the first posture viewpoint, at which the eyes of the user are, in the jth row of subpixels of the homochromatic subpixels in the i&#xd7;j array of each composite subpixel, and the second posture viewpoint, at which the eyes of the user are, in an ith row of subpixels.</p><p id="p-0137" num="0136">Referring to <figref idref="DRAWINGS">FIGS. <b>3</b>A, <b>3</b>B and <b>8</b>B</figref>, unlike the embodiment shown in <figref idref="DRAWINGS">FIG. <b>8</b>A</figref>, when the 3D display device <b>100</b> is in the first posture or switched from the second posture to the first posture, the eye positioning apparatus <b>150</b> detects the first posture viewpoints at which both eyes of the user are, for example, the left eye corresponds to the first posture viewpoint Vi<b>2</b> and the right eye corresponds to the first posture viewpoint Vi<b>4</b>, and further detects the second posture viewpoints at which both eyes of the user are, for example, the left eye and the right eye correspond to the same second posture viewpoint Vj<b>2</b>. Based on the video frames of the 3D video signals, the images of the first posture viewpoints corresponding to both eyes of the user are generated; and a red subpixel corresponding to the intersection between the first posture viewpoint Vi<b>2</b>, at which the eyes of the user are, in a jth row of red subpixels in the red composite subpixel <b>410</b>, and the second posture viewpoint Vj<b>2</b>, at which the eyes of the user are, in an ith row of red subpixels, as well as a red subpixel corresponding to an intersection between the first posture viewpoint Vi<b>4</b>, at which the eyes of the user are, in the jth row of red subpixels, and the second posture viewpoint Vj<b>2</b>, at which the eyes of the user are, in the ith row of red subpixels, are rendered in the first playing region <b>171</b>.</p><p id="p-0138" num="0137">In some embodiments, the eye positioning apparatus is configured to acquire positions of second posture viewpoints at which the eyes of the user are, in response to a signal that the 3D display device is in the second posture.</p><p id="p-0139" num="0138">In some embodiments, the 3D processing apparatus is configured to render relevant subpixels of homochromatic subpixels in the i&#xd7;j array of each composite subpixel in the second posture playing region according to the 3D images from the 3D contents, based on the second posture viewpoints at which the eyes of the user are.</p><p id="p-0140" num="0139">In some embodiments, the relevant subpixels rendered in the second posture playing region comprise all subpixels, corresponding to the second posture viewpoints at which the eyes of the user are, in the ith row of subpixels in each composite subpixel.</p><p id="p-0141" num="0140">Referring to <figref idref="DRAWINGS">FIGS. <b>3</b>A, <b>3</b>B and <b>9</b>A</figref>, in the illustrated embodiments, the 3D display device <b>100</b> may have first posture viewpoints Vi<b>1</b>-Vi<b>6</b> corresponding to the first posture, and second posture viewpoints Vj<b>1</b>-Vj<b>3</b> corresponding to the second posture. Each composite pixel in the display panel may comprise red composite subpixels having red subpixels in the i&#xd7;j array, green composite subpixels having green subpixels in the i&#xd7;j array, and blue composite subpixels having blue subpixels in the i&#xd7;j array. In homochromatic subpixels in the i&#xd7;j array of each composite subpixel, corresponding to the first posture viewpoints Vi<b>1</b>-Vi<b>6</b> of the first posture, i=6 is satisfied; and corresponding to the second posture viewpoints Vj<b>1</b>-Vj<b>3</b> of the second posture, j=3 is satisfied. For the sake of clarity, only a correspondence between one red composite subpixel <b>410</b> with i=6 and j=3 and each of the first posture viewpoints Vi<b>1</b>-Vi<b>6</b> and the second posture viewpoints Vj<b>1</b>-Vj<b>3</b> of the 3D display device <b>100</b> is shown in the figures.</p><p id="p-0142" num="0141">When the 3D display device <b>100</b> is in the second posture or switched from the first posture to the second posture, the eye positioning apparatus <b>150</b> detects the second posture viewpoints corresponding to both eyes of the user, for example, the left eye corresponds to the second posture viewpoint Vj<b>1</b>, and the right eye corresponds to the second posture viewpoint Vj<b>3</b>. Based on the video frames of the 3D video signals, images of the second posture viewpoints corresponding to both eyes of the user are generated; and all red subpixels, corresponding to the viewpoint Vj<b>1</b>, in the ith row of red subpixels in the red composite subpixel <b>410</b>, and all red subpixels, corresponding to the viewpoint Vj<b>3</b>, in the ith row of red subpixels, are rendered in the second playing region <b>172</b>.</p><p id="p-0143" num="0142">In some embodiments, the relevant subpixels rendered in the second posture playing region comprise one subpixel, corresponding to the second posture viewpoints at which the eyes of the user are, in the ith row of subpixels in each composite subpixel. For example, one subpixel, corresponding to the second posture viewpoint at which the left eye of the user is, in the ith row of subpixels, and one subpixel, corresponding to the second posture viewpoint at which the right eye of the user is, in the ith row of subpixels may be rendered.</p><p id="p-0144" num="0143">In some embodiments, when the 3D display device is in the second posture, in response to a signal that the 3D display device is in the second posture, the eye positioning apparatus acquires positions of the second posture viewpoints at which the eyes of the user are, and acquires positions of the first posture viewpoints at which the eyes of the user are. The relevant subpixels rendered in the second posture playing region comprise a subpixel corresponding to an intersection between the second posture viewpoint, at which the eyes of the user are, in the ith row of subpixels of the homochromatic subpixels in the i&#xd7;j array of each composite subpixel, and the first posture viewpoint, at which the eyes of the user are, in the jth row of subpixels.</p><p id="p-0145" num="0144">Referring to <figref idref="DRAWINGS">FIGS. <b>3</b>A, <b>3</b>B and <b>9</b>B</figref>, in the illustrated embodiments, unlike the embodiment shown in <figref idref="DRAWINGS">FIG. <b>9</b>A</figref>, when the 3D display device <b>100</b> is in the second posture or switched from the first posture to the second posture, the eye positioning apparatus <b>150</b> detects the second posture viewpoints corresponding to both eyes of the user, for example, the left eye corresponds to the second posture viewpoint Vj<b>1</b> and the right eye corresponds to the second posture viewpoint Vj<b>3</b>, and detects the first posture viewpoints corresponding to both eyes of the user, for example, the left eye and the right eye correspond to the same second posture viewpoint Vi<b>3</b>. Based on the video frames of the 3D video signals, the images of the second posture viewpoints corresponding to both eyes of the user are generated; and a red subpixel corresponding to an intersection between the second posture viewpoint Vj<b>1</b>, at which the eyes of the user are, in the ith row of red subpixels, and the first posture viewpoint Vi<b>3</b>, at which the eyes of the user are, in the jth row of red subpixels, as well as a red subpixel corresponding to an intersection between the second posture viewpoint Vi<b>3</b>, at which the eyes of the user are, in the ith row of red subpixels, and the first posture viewpoint Vi<b>3</b>, at which the eyes of the user are, in the jth row of red subpixels, are rendered in the second playing region <b>172</b>.</p><p id="p-0146" num="0145">In some embodiments, the 3D display device <b>100</b> further comprises a format adjuster (not shown), configured to adjust the format of the 3D contents, for example, preprocess the video frames of the 3D video signals, to be suitable for playing the 3D images in the first posture playing region and the second posture playing region. For example, when the resolution of the 3D contents is inconsistent with a display resolution of the first posture playing region or the second posture playing region, the format adjuster preprocesses the resolution of the 3D contents, to adapt to the display resolution of the first posture playing region or the second posture playing region.</p><p id="p-0147" num="0146">A method for switching the display of 3D images in the 3D display device is provided according to embodiments of the present disclosure. A method for realizing 3D image display in the 3D display device comprises:</p><p id="p-0148" num="0147">detecting a posture of the 3D display device, comprising, detecting a posture in which the 3D display device is, or detecting a posture change of the 3D display device, or detecting the both; and</p><p id="p-0149" num="0148">adjusting a display orientation of a displayed 3D image based on the posture in which the 3D display device is or the change of posture, so that the 3D image is kept in an initial display orientation before the posture change of the 3D display device.</p><p id="p-0150" num="0149">In some embodiments, as shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the method for realizing 3D image display comprises:</p><p id="p-0151" num="0150">S<b>10</b>, detecting a posture change of the 3D display device; and</p><p id="p-0152" num="0151">S<b>20</b>, adjusting a display orientation of a displayed 3D image when detecting the posture change of the 3D display device, so that the 3D image is kept in an initial display orientation before the posture change of the 3D display device.</p><p id="p-0153" num="0152">In some embodiments, the step S<b>20</b> may comprise: when detecting the posture change of the 3D display device, adjusting the display of a 3D image so that a display orientation of the 3D image is kept in an initial display orientation before the posture change of the 3D display device.</p><p id="p-0154" num="0153">In some embodiments, detecting the posture change of the 3D display device may be completed by the posture detection apparatus; and adjusting the display of a 3D image so that a display orientation of the 3D image is kept in an initial display orientation before the posture change of the 3D display device may be completed by the 3D processing apparatus.</p><p id="p-0155" num="0154">In some embodiments, detecting a posture change of the 3D display device comprises: detecting a rotational angular velocity of the 3D display device, and determining the posture change of the 3D display device according to the rotational angular velocity.</p><p id="p-0156" num="0155">In some embodiments, adjusting a display orientation of a 3D image comprises: rotating the display orientation of the 3D image in a plane, in which the 3D image is located, so that the 3D image is kept in the initial display orientation before the posture change of the 3D display device.</p><p id="p-0157" num="0156">In some embodiments, the posture of the 3D display device comprises at least one of: a transverse screen display posture, a vertical screen display posture, and an oblique screen display posture.</p><p id="p-0158" num="0157">In some embodiments, the first posture of the 3D display device before the posture change comprises any one of: the transverse screen display posture, the vertical screen display posture, and the oblique screen display posture; and the second posture of the 3D display device after the posture change comprises: any one, different from the first posture, of the transverse screen display posture, the vertical screen display posture, and the oblique screen display posture.</p><p id="p-0159" num="0158">In some embodiments, adjusting a display orientation of a 3D image comprises: rotating the 3D image to keep the 3D image in the initial display orientation corresponding to the first posture. Thus, for the user, no matter how to adjust the posture of the 3D display device, the display orientations of the seen 3D images are consistent.</p><p id="p-0160" num="0159">In some embodiments, when any one of the first posture and the second posture is the oblique screen display posture, adjusting a display orientation of a 3D image further comprises: displaying the 3D image in a full screen display mode.</p><p id="p-0161" num="0160">In some embodiments, adjusting a display orientation of a 3D image comprises: rotating the display orientation of the 3D image in a plane, in which the 3D image is located, so that the 3D image is kept within an initial display orientation range, wherein the initial display orientation range comprises the initial display orientation. Thus, the display orientation of the displayed 3D image may be fine-adjusted or adjusted according to motion of the user, to adapt to the motion of the user.</p><p id="p-0162" num="0161">In some embodiments, the method for realizing 3D image display further comprises: adjusting the display orientation of the 3D image according to a viewing orientation of the user, so that the display orientation of the 3D image coincides with the viewing orientation of the user. The viewing orientation of the user may comprise any one of a transverse viewing orientation, a vertical viewing orientation, and an oblique viewing orientation.</p><p id="p-0163" num="0162">In some embodiments, eye positioning may further be performed for the user; and the viewing orientation of the user is determined according to the obtained eye positioning data. The above, for example, may be implemented by an eye positioning apparatus.</p><p id="p-0164" num="0163">In some embodiments, adjusting the display orientation of the 3D image comprises: based on the adjusted display orientation (or the display orientation after the posture change of the 3D display device) of the 3D image, rendering composite pixels in a multi-viewpoint 3D display screen of the 3D display device. For example, based on a correspondence between subpixels of each composite subpixel of each composite pixel in the multi-viewpoint 3D display screen and viewpoints after the posture change of the 3D display device, the subpixels corresponding to the viewpoints determined by the eye positioning data are rendered according to a to-be-displayed 3D image.</p><p id="p-0165" num="0164">The adjusting of the display orientation of the 3D image and the rendering of the subpixels may be completed by the 3D processing apparatus.</p><p id="p-0166" num="0165">In some embodiments, the method for realizing 3D image display comprises:</p><p id="p-0167" num="0166">acquiring 3D signals; and</p><p id="p-0168" num="0167">switching and playing the 3D images from the 3D contents in the 3D display device, in response to the posture change of the 3D display device.</p><p id="p-0169" num="0168">In some embodiments, switching and playing the 3D images from the 3D contents in the 3D display device in response to the posture change of the 3D display device comprises: playing the 3D images from the 3D contents in the first posture playing region defined by the multi-viewpoint 3D display screen, in response to a signal that the 3D display device is changed to the first posture or is in the first posture.</p><p id="p-0170" num="0169">In some embodiments, switching and playing the 3D images from the 3D contents in the 3D display device in response to the posture change of the 3D display device comprises: playing the 3D images from the 3D contents in the second posture playing region defined by the multi-viewpoint 3D display screen, in response to a signal that the 3D display device is changed to the second posture or is in the second posture.</p><p id="p-0171" num="0170">In some embodiments, the first posture is a transverse posture of the display device; and the second posture is a vertical posture of the display device.</p><p id="p-0172" num="0171">In some embodiments, the 3D contents comprise 3D videos, such as video frames of the 3D videos.</p><p id="p-0173" num="0172">In some embodiments, a method for switching the display of the 3D images in the 3D display device further comprises: acquiring real-time eye positioning data in relation to the posture of the 3D display device.</p><p id="p-0174" num="0173">In some embodiments, acquiring real-time eye positioning data in relation to the posture of the 3D display device comprises: in response to the signal that the 3D display device is in the first posture, acquiring positions of first posture viewpoints at which the eyes of the user are.</p><p id="p-0175" num="0174">In some embodiments, playing the 3D images from the 3D contents in the first posture playing region defined by the multi-viewpoint 3D display screen comprises: rendering relevant subpixels of homochromatic subpixels in the i&#xd7;j array of each composite subpixel in the first posture playing region according to the 3D images from the 3D contents, based on positions of the first posture viewpoints at which the eyes of the user are.</p><p id="p-0176" num="0175">In some embodiments, the relevant subpixels rendered in the first posture playing region comprise at least one subpixel, corresponding to the first posture viewpoints at which the eyes of the user are, in the jth row of subpixels in each composite subpixel.</p><p id="p-0177" num="0176">In some embodiments, acquiring real-time eye positioning data in relation to the posture of the 3D display device comprises: acquiring positions of second posture viewpoints at which the eyes of the user are, in response to the signal that the 3D display device is in the second posture.</p><p id="p-0178" num="0177">In some embodiments, playing the 3D images from the 3D contents in the second posture playing region defined by the multi-viewpoint 3D display screen comprises: rendering relevant subpixels of homochromatic subpixels in the i&#xd7;j array of each composite subpixel in the second posture playing region according to the 3D images from the 3D contents, based on positions of the second posture viewpoints at which the eyes of the user are.</p><p id="p-0179" num="0178">In some embodiments, the relevant subpixels rendered in the second posture playing region comprise at least one subpixel, corresponding to the second posture viewpoints at which the eyes of the user are, in the ith row of subpixels in each composite subpixel.</p><p id="p-0180" num="0179">Embodiments of the present disclosure provide a 3D display device <b>300</b>; and referring to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the 3D display device <b>300</b> comprises a processor <b>320</b> and a memory <b>310</b>. The 3D display device <b>300</b> may further comprise a communication interface <b>340</b> and a bus <b>330</b>. The processor <b>320</b>, the communication interface <b>340</b>, and the memory <b>310</b> communicate with each other through the bus <b>330</b>. The communication interface <b>340</b> may be configured to transmit information. The processor <b>320</b> may call logic instructions in the memory <b>310</b>, to implement the method for switching the display of 3D images in the 3D display device of the above embodiment. The logic instructions in the memory <b>310</b> may be implemented in the form of software functional units, and may be stored in a computer-readable storage medium when being sold or used as an independent product.</p><p id="p-0181" num="0180">The computer-readable storage medium provided by the embodiments of the present disclosure stores the computer-executable instructions; and the computer-executable instructions are configured to implement the method for realizing 3D image display.</p><p id="p-0182" num="0181">The computer program product provided by the embodiments of the present disclosure comprises computer programs stored on the computer-readable storage medium; the computer programs comprise program instructions; and when the program instructions are executed by a computer, the computer is allowed to implement the above method for realizing 3D image display.</p><p id="p-0183" num="0182">Technical solutions of embodiments of the present disclosure may be reflected in the form of a software product, which is stored in a storage medium and comprises one or more instructions for enabling computer equipment (which may be a personal computer, a server, network equipment or the like) to perform all or some steps of the method in embodiments of the present disclosure. The storage medium may be a non-transient storage medium, comprising a plurality of media capable of storing program codes, such as a U disk, a mobile hard disk, a read-only memory (ROM), a RAM, a diskette or an optical disk, and may also be a transient storage medium.</p><p id="p-0184" num="0183">The above description and drawings sufficiently illustrate the embodiments of the present disclosure to enable those skilled in the art to practice them. Other embodiments may comprise structural, logical, electrical, process, and other changes. Unless expressly required, individual components and functions are optional and the order of operations may be changed. Parts and features of some embodiments may be included in or substituted for parts and features of other embodiments. The scope of the disclosed embodiments includes the full scope of the claims, and all available equivalents of the claims. The terms used in the present disclosure are used to describe the embodiments only and not to limit the claims. When used in the present disclosure, the terms &#x201c;comprise&#x201d;, etc. refer to the presence of at least one of stated features, but does not preclude the presence of other features.</p><p id="p-0185" num="0184">In the embodiments disclosed herein, the disclosed method and product (including, but not limited to the apparatus and the device) may be realized in other ways. For example, the device embodiments described above are merely schematic. For example, the division of the units may be only a logical functional division, and may be an additional division manner in actual realization. For example, multiple units or components may be combined or integrated into another system, or some features may be ignored or not executed. In addition, the displayed or discussed mutual coupling or direct coupling or communication connection may be indirect coupling or communication connection through some interfaces, devices or units, and may be electrical, mechanical or other forms. The units described as separate components may or may not be physically separated, and the components shown as the units may or may not be physical units. The present embodiments may be implemented by selecting some or all of the units according to actual needs. In addition, each functional unit in the embodiments of the present disclosure may be integrated into one processing unit, or each unit may exist physically alone, or two or more units may be integrated into one unit.</p><p id="p-0186" num="0185">The flow charts and block diagrams in the drawings show architectures, functions and operations possibly implemented by systems, methods and computer program products according to the embodiments of the present disclosure. In this regard, each block in the flow charts or block diagrams may represent a part of a module, program segment or code, and part of the module, program segment or code contains one or more executable instructions for implementing specified logical functions. In some alternative implementations, the functions marked in the blocks may also occur in an order different from the order marked in the drawings. For example, two continuous blocks may actually be executed substantially concurrently, or sometimes may be executed in a reverse order, depending on the functions involved. In the descriptions corresponding to the flow charts and the block diagrams in the drawings, operations or steps corresponding to different blocks may also occur in different orders than those disclosed, and sometimes there is no specific order between different operations or steps. For example, two continuous operations or steps may be actually performed substantially concurrently, or sometimes may be performed in the reverse order, depending on the functions involved. Each block in the block diagrams and/or flow charts, and combinations of the blocks in the block diagrams and/or flow charts, can be implemented by special hardware-based systems that perform specified functions or actions, or implemented by combinations of special hardware and computer instructions. </p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for realizing 3D image display, comprising:<claim-text>detecting a posture change of a 3D display device, wherein the 3D display device comprises a multi-viewpoint 3D display screen, the multi-viewpoint 3D display screen comprises a plurality of composite pixels and a plurality of spherical gratings covering the plurality of composite pixels, each composite pixel of the plurality of composite pixels comprises a plurality of composite subpixels, and each composite subpixel of the plurality of composite subpixels comprises a plurality of subpixels corresponding to a plurality of viewpoints; and</claim-text><claim-text>adjusting a display orientation of a displayed 3D image when detecting that a posture of the 3D display device changes, so that the 3D image is kept in an initial display orientation before a posture the 3D display device changes.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>detecting a posture change of a 3D display device comprises:</claim-text><claim-text>detecting a rotational angular velocity of the 3D display device, and determining a posture change of the 3D display device according to the rotational angular velocity;</claim-text><claim-text>adjusting a display orientation of the 3D image comprises:</claim-text><claim-text>rotating a display orientation of the 3D image in a plane in which the 3D image is located, so that the 3D image is kept in an initial display orientation before a posture of the 3D display device changes.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein a posture of the 3D display device comprises at least one of:<claim-text>a transverse screen display posture, a vertical screen display posture, and an oblique screen display posture;</claim-text><claim-text>wherein</claim-text><claim-text>a first posture of the 3D display device before a posture change comprises: any one of a transverse screen display posture, a vertical screen display posture, and an oblique screen display posture;</claim-text><claim-text>a second posture of the 3D display device after a posture change comprises: any one, different from the first posture, of a transverse screen display posture, a vertical screen display posture, and an oblique screen display posture;</claim-text><claim-text>adjusting a display orientation of the 3D image comprises: rotating the 3D image so that the 3D image is kept in an initial display orientation corresponding to the first posture.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. (canceled)</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to claim <b>34</b>, wherein when any one of the first posture and the second posture is an oblique screen display posture, adjusting a display orientation of the 3D image further comprises:<claim-text>displaying the 3D image in a full screen display mode.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein adjusting a display orientation of the 3D image comprises:<claim-text>rotating a display orientation of the 3D image in a plane in which the 3D image is located, so that the 3D image is kept within an initial display orientation range;</claim-text><claim-text>wherein the initial display orientation range comprises the initial display orientation.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>adjusting a display orientation of the 3D image according to a viewing orientation of a user, so that a display orientation of the 3D image coincides with a viewing orientation of the user.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein<claim-text>a viewing orientation of the user comprises: any one of a transverse viewing orientation, a vertical viewing orientation, and an oblique viewing orientation;</claim-text><claim-text>the method further comprises: performing eye positioning for the user, and determining a viewing orientation of the user according to obtained eye positioning data.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein adjusting a display orientation of the 3D image comprises:<claim-text>rendering corresponding subpixels in composite subpixels in the multi-viewpoint 3D display screen based on an adjusted display orientation of the 3D image.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein rendering corresponding subpixels in composite subpixels in the multi-viewpoint 3D display screen comprises:<claim-text>rendering subpixels, corresponding to the viewpoints, in each composite subpixel based on viewpoints corresponding to subpixels in each composite subpixel after a posture change of a 3D display device.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of subpixels in each composite subpixel are in an i&#xd7;j array, i and j are integers of greater than or equal to 1, wherein<claim-text>subpixels in the i&#xd7;j array of each composite subpixel correspond to i viewpoints before a posture change of the 3D display device; or</claim-text><claim-text>subpixels in the i&#xd7;j array of each composite subpixel correspond to j viewpoints after a posture change of the 3D display device.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A 3D display device, comprising:<claim-text>a processor; and</claim-text><claim-text>a memory storing program instructions;</claim-text><claim-text>wherein the processor is configured to implement the method of <claim-ref idref="CLM-00001">claim 1</claim-ref> when executing the program instructions.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A 3D display device, comprising:<claim-text>a multi-viewpoint 3D display screen, comprising a plurality of composite pixels and a plurality of spherical gratings covering the plurality of composite pixels, wherein each composite pixel of the plurality of composite pixels comprises a plurality of composite subpixels, and each composite subpixel of the plurality of composite subpixels comprises a plurality of subpixels corresponding to a plurality of viewpoints;</claim-text><claim-text>a posture detection apparatus, configured to detect a posture change of the 3D display device; and</claim-text><claim-text>a 3D processing apparatus, configured to adjust a display orientation of a displayed 3D image based on a detected posture change of the 3D display device, so that the 3D image is kept in an initial display orientation before a posture change of the 3D display device.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The 3D display device according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the posture detection apparatus is configured to detect a rotational angular velocity of the 3D display device, and determine a posture change of the 3D display device according to the rotational angular velocity;<claim-text>the 3D processing apparatus is configured to rotate a display orientation of the 3D image in a plane in which the 3D image is located, so that the 3D image is kept in an initial display orientation before a posture of the 3D display device changes.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The 3D display device according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein a posture of the 3D display device comprises at least one of: a transverse screen display posture, a vertical screen display posture, and an oblique screen display posture;<claim-text>wherein</claim-text><claim-text>a first posture of the 3D display device before a posture change comprises: any one of a transverse screen display posture, a vertical screen display posture, and an oblique screen display posture;</claim-text><claim-text>a second posture of the 3D display device after a posture change comprises: any one, different from the first posture, of a transverse screen display posture, a vertical screen display posture, and an oblique screen display posture;</claim-text><claim-text>the 3D processing apparatus is configured to rotate the 3D image so that the 3D image is kept in an initial display orientation corresponding to the first posture.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. (canceled)</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The 3D display device according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the 3D processing apparatus is configured to display the 3D image in a full screen display mode when any one of the first posture and the second posture is an oblique screen display posture.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The 3D display device according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the 3D processing apparatus is configured to rotate a display orientation of the 3D image in a plane in which the 3D image is located, so that the 3D image is kept within an initial display orientation range, wherein the initial display orientation range comprises the initial display orientation.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The 3D display device according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the 3D processing apparatus is configured to adjust a display orientation of the 3D image according to a viewing orientation of a user, so that a display orientation of the 3D image coincides with a viewing orientation of the user.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The 3D display device according to <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein a viewing orientation of the user comprises: any one of a transverse viewing orientation, a vertical viewing orientation, and an oblique viewing orientation;<claim-text>the 3D display device further comprises an eye positioning apparatus or an eye positioning data interface, configured to acquire eye positioning data;</claim-text><claim-text>the 3D processing apparatus is configured to determine a viewing orientation of the user according to obtained eye positioning data.</claim-text></claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The 3D display device according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the 3D processing apparatus is configured to render composite pixels in a multi-viewpoint 3D display screen of the 3D display device based on an adjusted display orientation of the 3D image.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The 3D display device according to <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the 3D processing apparatus is configured to render subpixels, corresponding to viewpoints, in composite subpixels contained in the multi-viewpoint 3D display screen based on viewpoints corresponding to subpixels in each composite subpixel after a posture change of the 3D display device.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The 3D display device according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the plurality of subpixels in each composite subpixel are in an i&#xd7;j array, i and j are integers of greater than or equal to 1, wherein<claim-text>subpixels in the i&#xd7;j array of each composite subpixel correspond to i viewpoints before a posture of the 3D display device changes; or</claim-text><claim-text>subpixels in the i&#xd7;j array of each composite subpixel correspond to j viewpoints after a posture of the 3D display device changes.</claim-text></claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. A computer-readable storage medium, storing computer-executable instructions, wherein the computer-executable instructions are configured to implement the method of <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. A computer program product, comprising computer programs stored on a computer-readable storage medium, wherein the computer programs comprise program instructions, and make a computer implements the method of <claim-ref idref="CLM-00001">claim 1</claim-ref> when the program instructions are executed by the computer.</claim-text></claim></claims></us-patent-application>
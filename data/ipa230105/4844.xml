<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004845A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004845</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17854352</doc-number><date>20220630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>045</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>022</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">AI-AUGMENTED AUDITING PLATFORM INCLUDING TECHNIQUES FOR PROVIDING AI-EXPLAINABILITY FOR PROCESSING DATA THROUGH MULTIPLE LAYERS</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63217119</doc-number><date>20210630</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>63217123</doc-number><date>20210630</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>63217127</doc-number><date>20210630</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>63217131</doc-number><date>20210630</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>63217134</doc-number><date>20210630</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>PricewaterhouseCoopers LLP</orgname><address><city>New York</city><state>NY</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>LI</last-name><first-name>Chung-Sheng</first-name><address><city>Scarsdale</city><state>NY</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>CHENG</last-name><first-name>Winnie</first-name><address><city>West New York</city><state>NJ</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>FLAVELL</last-name><first-name>Mark John</first-name><address><city>Madison</city><state>NJ</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>HALLMARK</last-name><first-name>Lori Marie</first-name><address><city>Xenia</city><state>OH</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>LIZOTTE</last-name><first-name>Nancy Alayne</first-name><address><city>Saline</city><state>MI</state><country>US</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>LEONG</last-name><first-name>Kevin Ma</first-name><address><city>Randolph</city><state>NJ</state><country>US</country></address></addressbook></inventor><inventor sequence="06" designation="us-only"><addressbook><last-name>O'ROURKE</last-name><first-name>Kevin Michael</first-name><address><city>New York</city><state>NY</state><country>US</country></address></addressbook></inventor><inventor sequence="07" designation="us-only"><addressbook><last-name>HILL</last-name><first-name>Robert Michael</first-name><address><city>Glassboro</city><state>NJ</state><country>US</country></address></addressbook></inventor><inventor sequence="08" designation="us-only"><addressbook><last-name>DELILLE</last-name><first-name>Timothy</first-name><address><city>New York</city><state>NY</state><country>US</country></address></addressbook></inventor><inventor sequence="09" designation="us-only"><addressbook><last-name>RAMIREZ</last-name><first-name>Maria Jesus Perez</first-name><address><city>New York</city><state>NY</state><country>US</country></address></addressbook></inventor><inventor sequence="10" designation="us-only"><addressbook><last-name>GIACOMUCCI</last-name><first-name>Thomas Vincent</first-name><address><city>Malvern</city><state>PA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>PricewaterhouseCoopers LLP</orgname><role>02</role><address><city>New York</city><state>NY</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Systems and methods for providing explainability for processing data through multiple layers are provided. An input layer is configured to receive an evidence data set comprising a plurality of evidence items, apply evidence processing models to the evidence data set to generate evidence understanding data, and generate input-layer explainability data, wherein the input-layer explainability data represents information about the processing of the evidence data set by the input layer. A presentation layer is configured to receive data (the evidence understanding data and/or data generated based on the evidence understanding data), apply one or more presentation generation models to the received data to generate presentation data, and generate presentation-layer explainability data for presentation to the user, wherein the presentation-layer explainability data represents information about the processing of the received data set by the presentation layer.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="70.44mm" wi="158.75mm" file="US20230004845A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="181.27mm" wi="104.82mm" orientation="landscape" file="US20230004845A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="224.71mm" wi="162.14mm" orientation="landscape" file="US20230004845A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="224.71mm" wi="162.05mm" orientation="landscape" file="US20230004845A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="209.89mm" wi="153.50mm" orientation="landscape" file="US20230004845A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="238.08mm" wi="167.47mm" orientation="landscape" file="US20230004845A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="238.84mm" wi="160.87mm" orientation="landscape" file="US20230004845A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="244.09mm" wi="155.36mm" orientation="landscape" file="US20230004845A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="127.51mm" wi="147.40mm" orientation="landscape" file="US20230004845A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims the benefit of U.S. Provisional Application No. 63/217,119 filed Jun. 30, 2021; U.S. Provisional Application No. 63/217,123 filed Jun. 30, 2021; U.S. Provisional Application No. 63/217,127 filed Jun. 30, 2021; U.S. Provisional Application No. 63/217,131 filed Jun. 30, 2021; and U.S. Provisional Application No. 63/217,134, filed Jun. 30, 2021, the entire contents of each of which are incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">This related generally to AI explainability, and more specifically to AI-augmented auditing platform including techniques for providing AI-explainability for processing data through multiple layers.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Known techniques for processing data and generating adjudications based on the processed data include enterprise resource planning (ERP) systems with data-warehouse and/or data mart capabilities, which allow drill-down and rollup of digital data. These systems may provide direct linkage of aggregated digital data or data processed by simple mathematical formulas only. Furthermore, known techniques include content description frameworks for multimedia content including text, images, and video (see, e.g., &#x201c;Multimedia Content Description Framework&#x201d; U.S. Pat. No. 6,564,263 (L. D. Bergman, M.Y. Y. Kim, C.-S. Li, R. Mohan, J. R. Smith), which forms the basis for the multimedia metadata standard MPEG-7. Furthermore, known techniques include business rules engines that allow forward and backward chaining of business rules as part of reasoning processes. Furthermore, known techniques include conducting testing with tick-marks, pulldown menus, and manual entries of explanations on workpaper, or with circling or highlighting areas of interest. Known automation approaches use ad hoc approaches for identifying results needing follow-up, or are based on single-layer taxonomy/vocabulary for defining outputs.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0005" num="0004">As explained above, known techniques for processing data and generating adjudications include enterprise resource planning (ERP) systems and may provide direct linkage of aggregated data or data processed by simple mathematical formulas only. Furthermore, known techniques include content description frameworks for multimedia content including text, images, and video. Furthermore, known techniques include business rules engines and include conducting testing manual entries of explanations. Known automation approaches use ad hoc approaches for identifying results needing follow-up, or are based on single-layer taxonomy/vocabulary for defining outputs.</p><p id="p-0006" num="0005">However, known business rules engines do not retain a provenance of the deduction processes that they apply&#x2014;e.g., they do not retain a log of rules that have been applied by the engine. Moreover, known techniques do not provide for traceability (including full traceability) and provenance of interpretation, reasoning, deliberation, and adjudication through various layers, including from raw evidence through final observation, conclusion, and recommendation. Furthermore, known techniques do not provide flexibility in presenting generated recommendations and/or remediations, adaptability in light of evolving needs, nor minimization and localization of necessary changes within systems. Furthermore, known techniques do not provide robust and flexible frameworks for applying different taxonomy/vocabulary/logic at each of a plurality of layers, generating output data and explainability outputs at each of the plurality of layers, and allowing localized modification of any of the layers without modification of other layers.</p><p id="p-0007" num="0006">Accordingly, there is a need for improved systems and methods for tracking the reasoning and adjudication processes by which data is processed through a plurality of interconnected layers, wherein said improved systems address one or more of the above-identified shortcomings.</p><p id="p-0008" num="0007">Disclosed herein are systems and methods for tracking the reasoning and adjudication processes by which data is processed through a plurality of interconnected layers. In some embodiments, the techniques disclosed herein may be applied to tracking the reasoning and adjudication processes by which evidence data and information are processed through a plurality of layers during an audit process. The fine-grained explainability of the reasoning process is critical for the human auditor to understand and believe in the conclusion and recommendation. The decoupling of the tracking at each stage of the deliberation enable maximal flexibility while minimize the necessary modification when frequent changes of the required summary, conclusion, and recommendation are required.</p><p id="p-0009" num="0008">In some embodiments, a first system for providing explainability for processing data through multiple layers is provided, the first system comprising one or more processors configured to cause the first system to provide: an input layer configured to: receive an evidence data set comprising a plurality of evidence items; apply one or more evidence processing models to the evidence data set to generate evidence understanding data; and generate an input-layer output for presentation to a user, wherein the input layer output represents the processing of the evidence data set by the input layer; a presentation layer configured to: receive data, wherein the received data includes one of: the evidence understanding data, and data generated based on the evidence understanding data; apply one or more presentation generation models to the received data to generate presentation data; and generate a presentation output for presentation to the user, wherein the presentation output comprises the presentation data.</p><p id="p-0010" num="0009">In some embodiments of the first system, the one or more processors are configured to provide: one or more intermediate layers configured to: receive the evidence understanding data generated by the input layer; apply one or more intermediate-layer processing models to the evidence understanding data to generate the data received by the presentation layer; provide the data received by the presentation layer to the presentation layer; and generate an intermediate-layer output for presentation to the user, wherein the intermediate-layer output represents the processing of the evidence understanding data by the one or more intermediate layers.</p><p id="p-0011" num="0010">In some embodiments of the first system, the input layer and the presentation layer are each configured to apply a respective ontology.</p><p id="p-0012" num="0011">In some embodiments of the first system, the one or more processors are configured to: receive a user input comprising an instruction to modify the input layer; modify the input layer in accordance with the user input without modifying the presentation layer.</p><p id="p-0013" num="0012">In some embodiments of the first system, the one or more processors are configured to: receive a user input comprising an instruction to modify the presentation layer; and modify the presentation layer in accordance with the user input without modifying the input layer.</p><p id="p-0014" num="0013">In some embodiments of the first system, the one or more processors are configured to initialize the presentation layer by applying one or more machine learning models to classify output data from one or more prior analyses performed by the system.</p><p id="p-0015" num="0014">In some embodiments of the first system, the one or more processors are configured to: receive utilization data representing a manner in which the presentation output is utilized by one or more users; and automatically modify the presentation layer in accordance with the utilization data.</p><p id="p-0016" num="0015">In some embodiments, a non-transitory computer-readable storage medium storing instructions for providing explainability for processing data through multiple layers is provided, wherein the instructions are configured to be executed by a system comprising one or more processors to cause the system to provide: an input layer configured to: receive an evidence data set comprising a plurality of evidence items; apply one or more evidence processing models to the evidence data set to generate evidence understanding data; and generate an input-layer output for presentation to a user, wherein the input layer output represents the processing of the evidence data set by the input layer; a presentation layer configured to: receive data, wherein the received data includes one of: the evidence understanding data, and data generated based on the evidence understanding data; apply one or more presentation generation models to the received data to generate presentation data; and generate a presentation output for presentation to the user, wherein the presentation output comprises the presentation data.</p><p id="p-0017" num="0016">In some embodiments, a method for providing explainability for processing data through multiple layers is provided, wherein the method is performed by a system comprising one or more processors, the method comprising: by an input layer of the system: receiving an evidence data set comprising a plurality of evidence items; applying one or more evidence processing models to the evidence data set to generate evidence understanding data; and generating an input-layer output for presentation to a user, wherein the input layer output represents the processing of the evidence data set by the input layer; by a presentation layer of the system: receiving data, wherein the received data includes one of: the evidence understanding data, and data generated based on the evidence understanding data; applying one or more presentation generation models to the received data to generate presentation data; and generating a presentation output for presentation to the user, wherein the presentation output comprises the presentation data.</p><p id="p-0018" num="0017">In some embodiments, a second system for providing explainability for processing data through multiple data-processing layers is provided, the second system comprising one or more processors configured to cause the second system to cause the second system to: at an input layer: receive an evidence data set comprising a plurality of evidence items; apply one or more evidence processing models to the evidence data set to generate evidence understanding data; and generate input-layer explainability data, wherein the input-layer explainability data represents information about the processing of the evidence data set by the input layer; at a presentation layer: receive data, wherein the received data includes one of: the evidence understanding data, and data generated based on the evidence understanding data; apply one or more presentation generation models to the received data to generate presentation data; and generate presentation-layer explainability data, wherein the presentation-layer explainability data represents information about the processing of the received data by the input layer; cause display of the presentation data; and cause display of one or more of: the input-layer explainability data and the presentation-layer explainability data.</p><p id="p-0019" num="0018">In some embodiments, any one or more of the features, characteristics, or aspects of any one or more of the above systems, methods, or non-transitory computer-readable storage media may be combined, in whole or in part, with one another and/or with any one or more of the features, characteristics, or aspects (in whole or in part) of any other embodiment or disclosure herein.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE FIGURES</heading><p id="p-0020" num="0019">Various embodiments are described with reference to the accompanying figures, in which:</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows one example of data processing of revenue account data, in accordance with some embodiments.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a capture of a sales order, in accordance with some embodiments.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows vouching of a sales order against the purchase order, a shipment against a Bill of Lading, and a payment against a variety of payment details, in accordance with some embodiments.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a schematic diagram of a system for tracking reasoning and adjudication processes for processing data through a plurality of interconnected layers, in accordance with some embodiments.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a diagram of a different classes of data, in accordance with some embodiments.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an ontology for explanation of evidence evaluation, in accordance with some embodiments.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows a schematic diagram of data processing for financial data, in accordance with some embodiments.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example of a computer, according to some embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0029" num="0028">As explained above, known techniques for processing data and generating adjudications include enterprise resource planning (ERP) systems and may provide direct linkage of aggregated data or data processed by simple mathematical formulas only. Furthermore, known techniques include content description frameworks for multimedia content including text, images, and video. Furthermore, known techniques include business rules engines and include conducting testing manual entries of explanations. Known automation approaches use ad hoc approaches for identifying results needing follow-up, or are based on single-layer taxonomy/vocabulary for defining outputs.</p><p id="p-0030" num="0029">However, known business rules engines do not retain a provenance of the deduction processes that they apply&#x2014;e.g., they do not retain a log of rules that have been applied by the engine. Moreover, known techniques do not provide for traceability (including full traceability) and provenance of interpretation, reasoning, deliberation, and adjudication through various layers, including from raw evidence through final observation, conclusion, and recommendation. Furthermore, known techniques do not provide flexibility in presenting generated recommendations and/or remediations, adaptability in light of evolving needs, nor minimization and localization of necessary changes within systems. Furthermore, known techniques do not provide robust and flexible frameworks for applying different taxonomy/vocabulary/logic at each of a plurality of layers, generating output data and explainability outputs at each of the plurality of layers, and allowing localized modification of any of the layers without modification of other layers.</p><p id="p-0031" num="0030">Accordingly, there is a need for improved systems and methods for tracking the reasoning and adjudication processes by which data is processed through a plurality of interconnected layers, wherein said improved systems address one or more of the above-identified shortcomings.</p><p id="p-0032" num="0031">Disclosed herein are systems and methods for tracking the reasoning and adjudication processes by which data is processed through a plurality of interconnected layers. In some embodiments, the techniques disclosed herein may be applied to tracking the reasoning and adjudication processes by which evidence data and information are processed through a plurality of layers during an audit process. The fine-grained explainability of the reasoning process is critical for the human auditor to understand and believe in the conclusion and recommendation. The decoupling of the tracking at each stage of the deliberation enable maximal flexibility while minimize the necessary modification when frequent changes of the required summary, conclusion, and recommendation are required.</p><p id="p-0033" num="0032">In some embodiments, the systems and methods disclosed herein provide full explainability for digitizing evidence that is not yet in digital form, for example by applying one or more document-understanding techniques to ingested documents for which the included data is not yet in digital form. In some embodiments, documents may be processed via one or more document understanding operations comprising one or more of structural, semantic, and/or linguistic analysis of the documents. In some embodiments, the systems may apply one or more natural-language understanding (NLU) techniques to extract information from received documents and to generate structured data based on said ingested documents, such that said structured data can be further processed by one or more data processing models, including by being processed through a plurality of layers and by being used to generate explainable outputs at one or more of the plurality of layers, as described herein. (Any data processing operation referenced herein may include application of one or more models trained by machine-learning.)</p><p id="p-0034" num="0033">In some embodiments, the systems and methods disclosed herein provide full explainability for interpretation of processes and results during cross-validation between and/or among evidence.</p><p id="p-0035" num="0034">In some embodiments, the systems and methods disclosed herein provide full explainability for reporting results from one or more final adjudications (e.g., assessments, classifications, quantifications, characterizations, and/or scores made on the basis of evidence provided) based on input data regarding available evidence. For example, adjudications based on available evidence may include adjudications as to whether one or more accounting policies and/or auditing standards are satisfied.</p><p id="p-0036" num="0035">In some embodiments, the systems and methods disclosed herein provide full explainability for describing patterns, trends, and/or insights gained from evaluations of integrity of evidence, including evaluations made based on an individual piece of evidence and/or evaluations made based on multiple pieces of evidence.</p><p id="p-0037" num="0036">In some embodiments, the systems and methods disclosed herein provide full explainability for describing final recommendations (e.g., outputs provided to one or more systems or users wherein the output indicates a recommended action) based on input data regarding available evidence, including recommendations generated based on an individual piece of evidence and/or based on multiple pieces of evidence.</p><p id="p-0038" num="0037">In some embodiments, a system for providing explainability for data processing may define a plurality of layers through which data may be processed. Each layer may be provided by one or more processors, including embodiments in which layers are provided by separate processors and in which layers are provided by the same processors. Each layer may receive input data to the layer, apply one or more data processing operations to the received input data to generate output data, and may generate explainability data to be presented to a user to explain the input data, processing operations, and/or output data of the layer. The layers may be communicatively interconnected with one another such that output data from one layer may form all or part of the input data for another layer.</p><p id="p-0039" num="0038">The plurality of layers may include an input layer which is communicatively coupled with one or more data sources for providing raw evidence data as input to the input layer. The input layer may apply one or more data processing operations to the received evidence data to generate output data of the input layer. The input layer may then provide the generated output data to one or more subsequent layers to which it is communicatively connected, such that the generated output data may be used by the one or more subsequent layers as input data. The input layer may additionally generate an explainability output, such as a user-facing visualization, report, or other human-readable information that may be displayed, transmitted, and/or presented to one or more users. The explainability output for the input layer may indicate information regarding the manner in which the input layer received evidence data, processed said evidence data, generated output data based on said evidence data, and/or provided said generated output data to one or more subsequent layers. In some embodiments, the input layer may be configured for providing fine-grained precision interpretation of evidence data.</p><p id="p-0040" num="0039">The plurality of layers may include one or more intermediate layers that may be directly and/or indirectly communicatively coupled with and downstream of the input layer. The intermediate layers may be disposed in series and/or in parallel with one another. An intermediate layer may receive, as input data, the output data that is generated by the input layer. Alternatively or additionally, the intermediate layer may receive, as input data, output data that was generated by another intermediate layer. An intermediate layer may apply one or more data processing operations to the received data to generate output data of the intermediate layer. An intermediate layer may then provide the generated output data to one or more subsequent layers to which it is communicatively connected, such that the generated output data may be used by the one or more subsequent layers (e.g., another intermediate layer and/or a presentation layer, as described below) as input data. An intermediate layer may additionally generate an explainability output for the intermediate layer, such as a user-facing visualization, report, or other human-readable information that may be displayed, transmitted, and/or presented to one or more users. The explainability output for the intermediate layer may indicate information regarding the manner in which the intermediate layer received data, processed said received data, generated output data based on said received data, and/or provided said generated output data to one or more subsequent layers. In some embodiments, an intermediate layer may be configured for providing visibility and traceability of intermediate reasoning and adjudication of multiple related pieces of evidence.</p><p id="p-0041" num="0040">The plurality of layers may include a presentation layer that may be directly and/or indirectly communicatively coupled with and downstream of one or more of the intermediate layers and/or the input layer. The presentation layer may receive, as input data, the output data that is generated by the input layer and/or by one or more of the input layers. The presentation layer may apply one or more data processing operations to the received data to generate output data of the presentation layer, wherein the output data of the presentation layer may include actionable insights, observations, interpretations, recommendations, and/or remediations. The output data of the presentation layer may be displayed, transmitted, and/or presented to one or more users. The output data of the presentation layer may be stored, transmitted to one or more other systems, and/or used to selectively trigger one or more automated actions by the system. The presentation layer may additionally generate an explainability output for the presentation layer, such as a user-facing visualization, report, or other human-readable information that may be displayed, transmitted, and/or presented to one or more users. The explainability output for the presentation layer may indicate information regarding the manner in which the presentation layer received data, processed said received data, generated output data based on said received data, and/or presented or provided said generated output data to one or more users and/or one or more other systems. In some embodiments, the presentation layer may be configured for presenting actionable insight, observation, interpretation, recommendation, and remediation.</p><p id="p-0042" num="0041">The system may be configured such that a respective ontology (e.g., taxonomy and/or vocabulary) is established for each layer. The system may store data representing the respective ontology for each layer. In some embodiments, the system may store definition ontology data for a respective layer to enable explanations within the environment are standardized. In some embodiments, the ontology for a respective layer may be codified into reason code; codification of ontological data into reason code may simplify the tracing of deduction and reasoning processes.</p><p id="p-0043" num="0042">In some embodiments, data stored for a respective layer (including, e.g., the ontology for a respective layer) may define a manner in which the layer is interconnected (e.g., configured to receive data from and/or provide data to) one or more other layers of the system.</p><p id="p-0044" num="0043">In some embodiments, data stored for a respective layer (including, e.g., the ontology for a respective layer) may define deductive reasoning processes able to be applied by the layer, including one or more deterministic reasoning frameworks and/or one or more probabilistic reasoning frameworks. In some embodiments, data stored for a respective layer (including, e.g., the ontology for a respective layer) may define inductive reasoning processes able to be applied by the layer, including one or more machine learning models and/or one or more deep learning models. In some embodiments, data stored for a respective layer (including, e.g., the ontology for a respective layer) may define abductive reasoning processes able to be applied by the layer. In some embodiments, data stored for a respective layer (including, e.g., the ontology for a respective layer) may define general-purpose logic processes able to be applied by the layer.</p><p id="p-0045" num="0044">In some embodiments, the system may be configured to be able to be modified/reconfigured in accordance with instructions received from a user, in accordance with performance data regarding the performance of the system, and/or in accordance with data received from one or more other systems. In some embodiments, the system may be configured such that modification of codification may be made with localized impact. The system may be configured such that information defining the ontology, data processing operations, explainability output generation, and/or layer interconnectedness of any one layer is able to be modified without modifying any of the other layers in the system. In one example, modification of the presentation layer may be achieved by modifying logic rules that connect the presentation layer to one or more upstream layers (e.g., intermediate layer(s) and/or input layer) without modifying the upstream layers themselves. In another example, modification of the input layer may be achieved by modifying logic rules that connect the input layer one or more downstream layers (e.g., intermediate layer(s) and/or presentation layer) without modifying the downstream layers themselves. In another example, modification of an intermediate layer may be achieved by modifying logic rules that connect the intermediate layer to one or more upstream or downstream layers (e.g., input layer, other intermediate layer(s), and/or presentation layer) without modifying the upstream or downstream layers themselves.</p><p id="p-0046" num="0045">In some embodiments, the presentation layer may be configured in accordance with results of one or more supervised or unsupervised machine learning models, such as one or more clustering models and/or classification models. The presentation layer may be initialized, in some embodiments, based at least in part on historical data (e.g., data taken from one or more prior projects and/or prior analyses). The system may apply a supervised or unsupervised learning model to cluster/classify output data from one or more prior analyses, for example by applying the model(s) to data representing commentary, observations, summaries, conclusions, and/or recommendations from one or more prior analyses. The resulting output data from applying the model(s) to said data may be used to initialize the presentation layer.</p><p id="p-0047" num="0046">In some embodiments, the system may be configured to continuously/iteratively learn via utilization of one or more of the layers. For example, the system may be configured to monitor user engagement with output data and/or with explainability data generated by one or more of the layers; user utilization of output data and/or of explainability data generated by one or more of the layers; and/or explicit user feedback regarding presentation layer output data and/or explainability data generate by one or more of the layers. For example, the system may track which portions of output data and/or explainability data are selected by the user to cause the system to &#x201c;drill down&#x201d; to display additional information. On the basis of the monitored engagement, utilization, and/or feedback data, the system may automatically update configurations of one or more of the layers (e.g., to adjust future explainability outputs and/or to adjust future recommendations). Updates made on this basis may include updates as described elsewhere herein, for example updates to individual layers and/or updates to the manner in which layers are interconnected with one another. In this way, the system may be configured to apply a feedback loop such that output data and explainability outputs generated by the system may be continuously/iteratively improved over time.</p><p id="p-0048" num="0047">Some embodiments of the systems and methods described herein may be applied in the audit of financial data, such as data regarding revenue and receivable for an entity. While the figures below may describe the systems and methods disclosed herein as they relate to an audit of financial data, a person of ordinary skill in the art will understand, in light of the disclosure herein, that the systems and methods described herein may be applicable to any financial statement line item (FSLI)&#x2014;including expense and payable, property, plant and equipment (PPE) (including lease accounting), cash and cash equivalent, JE, etc.&#x2014;and may also be applicable to automatically processing any kind of data and providing explainability therefor, including processing and providing explainability for data that is not financial data.</p><p id="p-0049" num="0048">Herein, the disclosed embodiments demonstrate how the systems and methods disclosed herein may be applied to an audit of financial data.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows one example of data processing, in accordance with some embodiments. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, revenue account data may be processed to extract data corresponding to each of a plurality of individual transactions therein. As further shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, data corresponding to an individual transaction may then be further processed to extract data corresponding to various aspects of the individual transaction, such as sales order creation data, shipping preparation data, invoice data, and payment receipt data.</p><p id="p-0051" num="0050">Account receivable and revenue accounts within the chart of accounts capture the revenue generated through the order to cash process, as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The order to cash process includes the creation of sales order, prepare shipping (if the order involves a shipment), invoice the customer, and receive the payment when the customer pay. This process may be repeated for all the transactions that are recorded in the revenue account within the general ledger. As shown, a single revenue account may include data representing a plurality of individual transactions. The data for any individual transaction may include data representing one or more stages of a process associated with the transaction. In some embodiments, any one or more of the data processing operations described herein may be performed on a per-transaction basis and/or on the basis of a set of transactions. Information may be visualized or otherwise presented (e.g., via a presentation layer) to a user for a single transaction, multiple transactions, a single set of transactions, and/or multiple sets of transactions.</p><p id="p-0052" num="0051">During the order to cash process, various information systems may participate in the process. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, sales order data may be captured in an order management system (which may be part of the ERP system) and may trigger a warehouse management system (e.g., comprising one or more processors) to generate data usable for preparing the shipment according to the delivery date. When a product is shipped, an inventory management system (e.g., comprising one or more processors) may record the reduction of the inventory, and an order management system (e.g., comprising one or more processors) may generate invoice data and may transmit said invoice data to the customer (e.g., based on the delivery term). While invoicing the customer, data regarding this transaction may be posted in a data store associated with the revenue account (credit) and/or in a data store associated with the account receivable account (debit). When payment is received, data regarding the payment may be generated and may be recorded in the data store associated with the account receivable (credit) and/or in a data store associated with cash account (debit) within general ledger.</p><p id="p-0053" num="0052">An audit of revenue account, as a result, may include one or more data processing operations that validate data values associated with the account by tracing the transaction through the system in conjunction with corroborating evidence to ensure that each transaction has been posted correctly according to one or more criteria, for example criteria associated with accounting standards such as accounting policy ASC 606 (IFRS 15).</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows how a transaction may be traces end-to-end to detect any discrepancies.</p><p id="p-0055" num="0054">As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a sales order may be vouched against a purchase order (e.g., by comparing sales order data against purchase order data), a shipment may be vouched against the bill of lading (e.g., by comparing shipment data against bill of lading data), and a payment may be vouched against a variety of payment details such as bank statement, credit card processor settlement report, ACH daily report, etc. (e.g., by comparing payment data against data associated with one or more of the variety of payment details).</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a schematic diagram of a system for tracking reasoning and adjudication processes for processing data through a plurality of interconnected layers, in accordance with some embodiments. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a plurality of pieces of evidence data <b>402</b> (comprising <b>4102</b><i>a, </i><b>402</b><i>b, </i>and <b>402</b><i>c</i>) (e.g., documents, files, structured data, unstructured data, partially structured data, ERP representations, endogenous data, exogenous data, etc.) may be received by the system and may be subject to one or more data processing techniques (e.g., document understanding techniques, AI models, etc.) to generate evidence understanding data <b>404</b>. In some embodiments, evidence understanding data <b>404</b> may comprise data extracted from evidence data <b>402</b> and/or may comprise normalized or otherwise processed data resulting from applying one or more data processing techniques to evidence data <b>402</b>. In some embodiments, system <b>400</b> may process the input evidence data <b>402</b> via an input layer of the system comprising one or more processors, applying one or more data processing operations to evidence data <b>402</b> to generate the evidence understanding data <b>404</b>. In some embodiments, the input layer may also generate explainability output data (not shown) that may be provided (e.g., displayed, visualized, etc.) for a user to indicate information regarding the evidence data <b>402</b> received, the manner of processing of said received data <b>402</b>, and/or the evidence understanding data generated <b>404</b>.</p><p id="p-0057" num="0056">As further shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, evidence understanding data <b>404</b> may then be processed via one or more reasoning/adjudication logic layers in order to generate one or more instances of intermediate results data. Each reasoning/adjudication logic layer may comprise one or more processors configured to apply one or more data processing operations to process input data and to generate output data and explainability output data. In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, reasoning/adjudication logic layer <b>406</b> may comprise one or more processors configured to accept evidence understanding data <b>404</b> as input data, to process said input data, and to generate intermediate results data <b>408</b> as output data. In some embodiments, an intermediate layer may also generate an explainability output that may be provided (e.g., displayed, visualized, etc.) for a user to indicate information regarding the input data for the intermediate layer, the manner of processing said input data, and/or the intermediate results data generated. For example, reasoning/adjudication logic layer <b>406</b> may also produce explainability output data (not shown) that may be provided (e.g., displayed, visualized, etc.) for a user to indicate information regarding the data <b>404</b> received, the manner of processing of said received data <b>404</b>, and/or the generated output data <b>408</b>.</p><p id="p-0058" num="0057">In some embodiments, system <b>400</b> may include a plurality of intermediate layers arranged in series and/or in parallel, and system <b>400</b> may apply one or more data processing operations to the data processed through the intermediate layers. In some embodiments, multiple intermediate layers may receive the same input data. In some embodiments, one intermediate layer may forward received input data to another intermediate layer in the same format that it was received. In some embodiments, an upstream intermediate layer (e.g., layer <b>406</b>) may generate output data (e.g., <b>408</b>) that may itself be used as input data for a downstream intermediate layer (e.g., layer <b>410</b>) to produce downstream intermediate output data (e.g., <b>412</b>).</p><p id="p-0059" num="0058">As further shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, intermediate results data (e.g., intermediate results data from one or more of the intermediate layers) such as results data <b>408</b> and/or <b>412</b> may be processed via one or more reasoning/adjudication logic layers in order to generate recommendation and remediation data. System <b>400</b> may process the intermediate results data (e.g., the intermediate results data from the final intermediate layer) via one or more presentation layers of the system, applying one or more data processing operations to the intermediate results data to generate recommendation and remediation data. For example, in system <b>400</b>, reasoning/adjudication logic layer <b>414</b> may receive intermediate results data <b>412</b> as input data and may process said received input data via one or more data processing operations in order to generate recommendation and remediation data <b>416</b>. In some embodiments, a presentation layer may also generate an explainability output that may be provided (e.g., displayed, visualized, etc.) for a user to indicate information regarding the input data for the presentation layer, the manner of processing said input data, and/or the recommendation &#x26; remediation data generated. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the recommendation and remediation data itself may also be provided (e.g., displayed, visualized, etc.) to a human user, such as a human user of user system <b>418</b>.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows an overall architecture of a multilayer reasoning process and a manner in which output data and/or explanation data may be generated at each of a plurality of layers. The leftmost layer may interprets raw evidence to generate understanding data <b>404</b>, and may generate associated explainability data that may be stored and/or presented to a user. The rightmost layer <b>414</b> may generate output data representing an overall observation, conclusion, and/or recommendation for a user such as an auditor, and may also generate associated explainability data. Intermediate layers capture the explanation of the intermediate results. The logic applied by one or more layers of system <b>400</b> may include deductive, inductive, abductive, and/or general-purpose logic to take input from one layer and produce out data for presentation to a user, storage, and/or use by another layer.</p><p id="p-0061" num="0060">In some embodiments, a multilayer data processing such as system <b>400</b> may be configured to process data through one or more an input layers, a plurality of intermediate layers, and one or more presentation layers.</p><p id="p-0062" num="0061">An input layer may be configured to receive input data from one or more external data sources, such as one or more databases, data stores, data repositories, live data feeds, or the like. The data may be received in structured, unstructured, and/or partially-structured (e.g., semi-structured) format. The data may be received by the input layer on a scheduled basis, in response to a user input, in response to one or more trigger conditions being met, and/or in response to the data being manually sent.</p><p id="p-0063" num="0062">The input layer may comprise one or more processors configured to apply one or more data processing operations to some or all of the received input data to thereby generate output data. The output data may comprise, for example, data extracted from raw input data and/or normalized data generated based on input data. The generated output data may be stored locally, transmitted to one or more other system components, and/or forwarded to one or more downstream layers in the multilayer system for further processing.</p><p id="p-0064" num="0063">In addition to the output data, the one or more processors of the input layer may additionally generate explainability output data, which may include metadata indicating a manner in which the output data was generated, for example including an indication of the input data, an indication of the data processing operation(s) applied, an indicating of a time and/or place of data processing, and/or an indication of one or more configurations associated with said data processing. The generated explainability output data may be stored locally or remotely and/or transmitted to one or more other system components.</p><p id="p-0065" num="0064">An intermediate layer may be configured to receive input data from an input layer and/or from another intermediate layer that is upstream of the intermediate layer. In some embodiments, an intermediate layer may also receive input data from one or more external data sources, in a same or similar manner as described above with respect to an input layer. The data may be received in structured, unstructured, and/or partially-structured (e.g., semi-structured) format. The data may be received by the intermediate layer on a scheduled basis, in response to a user input, in response to one or more trigger conditions being met, in response to the data being manually sent, and/or in response to the data being generated by an upstream layer including an input layer and/or another intermediate layer.</p><p id="p-0066" num="0065">The intermediate layer may comprise one or more processors configured to apply one or more data processing operations to some or all of the received input data to thereby generate output data. The output data may comprise, for example, one or more adjudications, scores, calculations, classifications, identified events, and/or identified content generated based on the input data. The generated output data may be stored locally, transmitted to one or more other system components, and/or forwarded to one or more downstream layers in the multilayer system for further processing.</p><p id="p-0067" num="0066">In addition to the output data, the one or more processors of the intermediate layer may additionally generate explainability output data, which may include metadata indicating a manner in which the output data was generated, for example including an indication of the input data, an indication of the data processing operation(s) applied, an indicating of a time and/or place of data processing, and/or an indication of one or more configurations associated with said data processing. The generated explainability output data may be stored locally or remotely and/or transmitted to one or more other system components.</p><p id="p-0068" num="0067">A presentation layer may be configured to receive input data from an input layer and/or from an intermediate layer upstream of the presentation layer. In some embodiments, a presentation layer may also receive input data from one or more external data sources, in a same or similar manner as described above with respect to an input layer. The data may be received in structured, unstructured, and/or partially-structured (e.g., semi-structured) format. The data may be received by the presentation layer on a scheduled basis, in response to a user input, in response to one or more trigger conditions being met, in response to the data being manually sent, and/or in response to the data being generated by an upstream layer including an input layer and/or an intermediate layer.</p><p id="p-0069" num="0068">The presentation layer may comprise one or more processors configured to apply one or more data processing operations to some or all of the received input data to thereby generate output data. The output data may comprise, for example, one or more adjudications, scores, calculations, classifications, identified events, identified content, alerts, user interface objects, and/or visualizations generated based on the input data. In some embodiments, output data from a presentation layer may comprise an indication of classification, such as a risk classification. In some embodiments, output data from a presentation layer may indicate a risk classification for a transaction represented by the original input data received by the system. In some embodiments, output data from a presentation layer may indicate an irregularity, anomaly, and/or inconsistency for data that was received by and processed by the system. In some embodiments, output data from a presentation layer may indicate whether one or more criteria (e.g., vouching criteria, tracing criteria, related-party transaction criteria, data integrity criteria, process integrity criteria, and/or policy integrity criteria) are satisfied by the data that was received by and processed by the system. In some embodiments, output data from a presentation layer may comprise a confidence score associated with one or more indications (e.g., labels or classifications) of the output data. The generated output data may be stored locally, transmitted to one or more other system components, and/or presented (e.g., displayed on a display of a user system) to a user.</p><p id="p-0070" num="0069">In addition to the output data, the one or more processors of the presentation layer may additionally generate explainability output data, which may include metadata indicating a manner in which the output data was generated, for example including an indication of the input data, an indication of the data processing operation(s) applied, an indicating of a time and/or place of data processing, and/or an indication of one or more configurations associated with said data processing. The generated explainability output data may be stored locally or remotely and/or transmitted to one or more other system components.</p><p id="p-0071" num="0070">In some embodiments, different layers in a multilayer data processing system may leverage one or more of the same processors for data processing operations performed at different layers; in some embodiments, one or more separate processors may be used for data processing operations performed at different layers.</p><p id="p-0072" num="0071">In some embodiments, a multilayer data processing system may only present (e.g., display) output data generated by a presentation layer to a user. In some embodiments, the system may additionally present some or all output data generated by one or more upstream layers to the user. In some embodiments, the system may present some or all of the original input data received by the system.</p><p id="p-0073" num="0072">In some embodiments, in addition to output data, the system may present some or all of the explainability data generated by one or more of the layers (including input layers, intermediate layers, and/or presentation layers). In some embodiments, explainability data may be presented (e.g., displayed, for example as part of a visualization) to a user upon being generated, upon presentation to the user of output data associated with the explainability data, and/or in response to one or more requests from the user requesting the display of explainability data. In some embodiments, a user interface may initially display output data generated by one or more presentation layers, and the interface may afford the user the opportunity to execute one or more user inputs requesting display of explainability data associated with the displayed output data. For example, a user execute an input by clicking on a visualization, selecting one or more affordances, and/or entering one or more input strings into one or more fields. The user input may indicate a request for explainability data to be presented, for example by indicating (e.g., clicking on) a piece of output data for which associated explainability data should be requested. The user input may indicate a request for explainability data to be presented, for example by indicating a type of explainability data, an explainability visualization type, and/or one or more layer of the system for which to display explainability data. In some embodiments, a user may click on output data in order to &#x201c;drill down&#x201d; into associated explainability data, for example causing the system to display explainability data for the layer that generated the output data that was clicked, and/or causing the system to display output data for one or more upstream layers that was used as input to generate the output data that was clicked. In some embodiment, a user may execute a plurality of successive drill-down inputs, clicking on newly-displayed output data and/or newly-displayed explainability data to drill down further into the data that was processed through the multilayer system. By execute a plurality of successive drill-down inputs, a user may move backwards from the final output data (initially displayed to the user) back through all of the layers of the system, such that the system displays all intermediate data and the original input data that was used to arrive at the selected output data and/or such that the system displays explainability data for all system layers leveraged to arrive at the output data.</p><p id="p-0074" num="0073">In some embodiments, the one or more processors of a layer of the system may be configured to apply one or more data processing operations that may include deductive reasoning data processing operations, inductive reasoning data processing operations, and/or abductive reasoning data processing operations.</p><p id="p-0075" num="0074">In some embodiments, input data originally provided to an input layer of the system may include data indicating time information, and the data-processing operations performed by one or more layers of the system may include generating time-dependent output data. Time dependent information can be presented to the input either sequentially (e.g., for information that belong to the same point in time) or concurrently (e.g., for information that belongs to more than one point in time).</p><p id="p-0076" num="0075">In some embodiments, (alternatively to or in addition to time-dependency as described above) input data originally provided to an input layer of the system may data indicating location information, and the data-processing operations performed by one or more layers of the system may include generating location-dependent output data. In some embodiments, location may be expressed by a two-dimensional description (x, y), which may for example represent a latitude and longitude; or location may be expressed by a three-dimensional description (x, y, z), where the third dimension indicates a vertical position, altitude, as measured from sea-level, and/or height off of the ground.</p><p id="p-0077" num="0076">In some embodiments, when the system generates output data that is time-dependent and/or location-dependent, a user may execute one or more inputs to request display of output data (and/or associated explainability data) for period of time and/or for a location that is specified by the input. In some embodiments, the system may responsively update the displayed output data in order to display information relevant to the user-specified time and/or location. In some embodiments, the system may display output data that has already been generated; in some embodiments, the system may activate one or more of the data processing layers in order to process data to generate output data for the user-specified time and/or location.</p><p id="p-0078" num="0077">In some embodiments, the one or more processors of a layer of the system may be configured to determine which of a plurality of data processing operations should be applied. The one or more processors may automatically select one or more data processing operations to apply based on system settings, user input, and/or based on input data generated by one or more upstream layers of the system. In some embodiments, the input data (e.g., data format, data type, data content, etc.) may dictate which one or more data processing operations are applied by a layer (and/or may dictate whether the layer applies any data processing operations or alternatively simply forwards the input data to another layer).</p><p id="p-0079" num="0078">In some embodiments, the system may be configurable according to one or more user inputs, which may be provided to the system by an end user and/or administrator. In some embodiments, the system may be configurable according to one or more user inputs that specify a manner in which one or more layers processes data. For example some embodiments, a user input may indicate a type or identity of analysis, a type or identity of test, a type or identity of model, one or more weight values, and/or one or more threshold values, and the system may configure a specified layer in accordance with the user input. In some embodiments, reconfiguring a layer of the multilayer system may be done without reconfiguring any other layers of the system, including upstream layers that provide input data to the reconfigured layer and including downstream layers that accept the output data of the reconfigured layer. In some embodiments, a layer may be reconfigured (e.g., by adjusting data processing operations applied by the layer) without changing the format of data accepted as input by the layer and without changing the format of data generated as output by the layer. In this manner, a layer may be adjusted and may continue to interact with upstream and downstream layers in the same manner as before the adjustment was made.</p><p id="p-0080" num="0079">In some embodiments, a layer of the system may be reconfigurable to change the amount, type, and/or content of explainability data generated by a layer. In some embodiments, the explainability data generated by a layer may be changed without changing the output data itself that is generated by the layer, such that downstream layers that receive the output data from that layer are not affected by the reconfiguration.</p><p id="p-0081" num="0080">In some embodiments, a layer may be reconfigured in accordance with a change to an ontology that is leveraged by a data processing operation applied by the layer. For example, if an additional class is identified, then the additional class may be added to an ontology used by a classifier of the layer. In some embodiments, the addition of the new class cause the layer to generate output data in a same format (e.g., using a same language and/or a same set of symbols) as before the addition, such that downstream layers do not need to be adjusted to interpret output data that is generated in accordance with the new class. In some embodiments, the layer to which an additional class is added may be configured such that it applies one or more translation operations, normalization operations, and/or other data processing operations to convert data generated in accordance with the new class into a format that can be interpreted by downstream layers without requiring adjustments to the downstream layers. (In some embodiments, a downstream layer may be adjusted in order to ensure that the downstream layer can process all possible upstream output data when an upstream layer is reconfigured to generate output data comprising one or more new classes, new symbols, or the like.)</p><p id="p-0082" num="0081">In some embodiments, the system may be configurable according to one or more user inputs that specify a manner in which one or more layers are interconnected with one or more other layers. For example, a user input may indicate: (a) from which upstream layers and/or other data sources a certain layer should accept input; and/or (b) to which downstream layers a certain layer should provide output data for further processing by the downstream layers. In some embodiments, a user input may specify whether a given layer should (or should not) forward any received data (without processing) to one or more subsequent layers. In some embodiments, a user input may indicate whether receipt of input data from a given source and/or provision of output data to a given source is optional or required. In some embodiments, a user may configure the interconnections between the layers by selecting one or more layers to be linked downstream or upstream to a given layer from a menu, and/or by using a drag-and-drop user interface to rearrange layers and/or to place, rearrange, and/or remove connecting links between visualizations representing respective layers.</p><p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows data layer schema <b>500</b>, which may comprise a plurality of data layers that may be processed through layers of a multilayer data-processing system such as system <b>400</b> shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. As shown, schema <b>500</b> may include raw data <b>502</b>, information data <b>504</b>, integrity observation data <b>506</b>, insight data <b>508</b>, actionable insight data <b>510</b>, and recommendation data <b>512</b>. Each of the different data layers in schema <b>500</b> may be stored in one or more databases, together or separately from one another, optionally in association with metadata including explainability metadata indicating the manner in which data in the corresponding was derived (and/or the underlying data from which it was derived).</p><p id="p-0084" num="0083">In some embodiments of a multilayer data-processing schema such as schema <b>500</b>, raw evidence data may be ingested and may be processed through one or more normalization operations with respect to context (such as customer/vendor/product master data) for being evaluated as evidence. Data and process integrity validation (see Disclosure on Composable Data-Process-Policy integrity framework for FSLI audit) data processing operations may be applied in order to perform validation and produce integrity observation data. This observation data may include report mismatches of various fields, such as customer name, address, shipping term, payment term, line items, unit price, and/or total amount. The interpretation of evidence evaluation data that belongs to the same transaction may then combined through deductive, inductive, and/or abductive reasoning data processing operations. Further aggregation data processing operations may be applied based on customer, location, and/or product, and said data processing operations may generate insight data. Insight data, such as data indicating one or more distinct out-of-ordinary behaviors or events, may be subject to one or more data processing operations to generate actionable insight data, which itself may be processed by one or more data processing operations to generate recommendation data indicating one or more potential solutions for such behaviors and/or events.</p><p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a diagram of a different classes of data that may be input into, processed by, generated by, and/or output by a system (e,g., system <b>400</b>) for tracking reasoning and adjudication processes for processing data through a plurality of interconnected layers, in accordance with some embodiments.</p><p id="p-0086" num="0085">As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, a system may be figured to receive raw data <b>502</b> (e.g., evidence data) including, for example, sales order data, purchase order data, invoice data, inventory ledger data, and credit memo data. In some embodiments, raw data <b>502</b> may be the original data provided to a multilayer data-processing system.</p><p id="p-0087" num="0086">As further shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the system may be configured to generate information data <b>504</b> based at least in part on all or part of the raw data <b>502</b> received. Information data generated <b>504</b> may include, for example, normalized data (e.g., normalized sales order data, normalized purchase order data, etc.). The system may further be configured to receive information data, including for example customer information, vendor information, and/or product information. Raw data <b>502</b> may be processed by an input data layer to generate information data <b>504</b>. The process of processing raw data <b>502</b> to produce information data <b>504</b> may share any one or more characteristics in common with the processing of evidence data <b>402</b> to produce evidence understanding data <b>404</b> as described above with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>. In some embodiments, raw data may <b>502</b> share any one or more characteristics in common with evidence <b>402</b> and information data <b>504</b> may share any one or more characteristics in common with evidence understanding data <b>404</b>. In some embodiments, processing raw data <b>502</b> to produce information data <b>504</b> may also include generating explainability data indicating the manner in which information data <b>504</b> was produced. In some embodiments, customer master data, vendor master data, and/or product master data may include data that is included in raw data <b>502</b> and/or in information data <b>504</b>.</p><p id="p-0088" num="0087">As further shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the system may be configured to generate integrity observation data <b>506</b> based on all or part of the information data <b>504</b> (and/or based on other upstream data). Integrity observation data <b>506</b> may include, for example, data regarding one or more inventory relief mismatches and/or regarding one or more credit memo/refund mismatches. The process of processing information data <b>504</b> to produce integrity observation data <b>506</b> may share any one or more characteristics in common with the processing of data by one or more intermediate layers of system <b>400</b> as described above with respect to <figref idref="DRAWINGS">FIG. <b>4</b></figref>. In some embodiments, the system may generate explainability data indicating the manner in which integrity observation data <b>506</b> was produced.</p><p id="p-0089" num="0088">As further shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the system may be configured to generate insight data <b>508</b> based on all or part of integrity observation data <b>506</b> (and/or based on other upstream data). Insight data may include, for example, data indicating one or more irregular inventory clusters and/or indicating one or more irregular refund clusters. The process of processing integrity observation data <b>506</b> to produce insight data <b>508</b> may share any one or more characteristics in common with the processing of data by one or more intermediate layers of system <b>400</b> as described above with respect to <figref idref="DRAWINGS">FIG. <b>4</b></figref>. In some embodiments, the system may generate explainability data indicating the manner in which insight data <b>508</b> was produced.</p><p id="p-0090" num="0089">As further shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the system may be configured to generate actionable insight data <b>510</b> based on all or part of insight data <b>508</b> (and/or based on other upstream data). Actionable insight data <b>510</b> may include, for example, data indicating irregular invent and refund activities. The process of processing insight data <b>508</b> to produce actionable insight data <b>510</b> may share any one or more characteristics in common with the processing of data by one or more intermediate layers of system <b>400</b> as described above with respect to <figref idref="DRAWINGS">FIG. <b>4</b></figref>. In some embodiments, the system may generate explainability data indicating the manner in which actionable insight data <b>510</b> was produced.</p><p id="p-0091" num="0090">As further shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the system may be configured to generate recommendation data <b>512</b> based on all or part of actionable insight data <b>510</b> (and/or based on other upstream data). Recommendation data <b>512</b> may include, for example, data indicating a specific recommended course of action, for example a recommendation to monitor a specific office (e.g., due to irregular inventory and refund activities in that office). The process of processing actionable insight data <b>510</b> to produce recommendation data <b>512</b> may share any one or more characteristics in common with the processing of data by a presentation layer such as layer <b>414</b> of system <b>400</b> as described above with respect to <figref idref="DRAWINGS">FIG. <b>4</b></figref>. In some embodiments, the system may generate explainability data indicating the manner in which recommendation data <b>512</b> was produced.</p><p id="p-0092" num="0091">In some embodiments, a system for tracking reasoning and adjudication processes for processing data through a plurality of interconnected layers may process each of the different classes of data described with respect to <figref idref="DRAWINGS">FIG. <b>5</b></figref> via a different layer of the system, such that each class of data is processed by one or more data processing operations that are configured to operate on data of that type.</p><p id="p-0093" num="0092"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the ontology for the explanation of evidence evaluation. In terms of the order process, the potential observation from evidence evaluation could include shipped before order placed, invoiced before order placed, invoiced but not shipped, shipped but not invoiced. In terms of Payment, Refund and Collection process, the observation could include un-vouched payment, unusual refund, refund without inventory return, Refund for shipping discrepancy, refund for product damage In terms of the accounting process, the observation could include A/R reversal, JE reversal/adjustment, mismatch between invoice and AR and between payment and payment journal.</p><p id="p-0094" num="0093">In some embodiments, a system for tracking reasoning and adjudication processes for processing data through a plurality of interconnected layers, such as those described herein, may identify one or more of the anomalous classifications shown in the bottom portion of <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0095" num="0094"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows a schematic diagram of data processing for financial data, in accordance with some embodiments. In some embodiments, the data processing depicted in <figref idref="DRAWINGS">FIG. <b>7</b></figref> may be performed by a system for tracking reasoning and adjudication processes for processing data through a plurality of interconnected layers, such as those described herein.</p><p id="p-0096" num="0095">In some embodiments of a system architecture <b>700</b>, evidence data such as purchase order data <b>708</b>, bill of lading data <b>706</b>, and bank statement data <b>704</b> may be processed through a plurality of data processing operations (e.g., document-understanding models, AI models, machine learning models, etc.) to generate one or more instances of intermediate data (e.g., data regarding vouching, invoices, revenue, contracts, and/or prices). The intermediate data may additionally be generated on the basis of ERP data. In some embodiments, the intermediate data may be used to generate recommendation data <b>716</b>, such as a recommendation to perform a revenue audit.</p><p id="p-0097" num="0096"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows logic from input layer to data integrity evaluation and process integrity evaluation. The output from both data and process integrity may feed into a semi-final layer in policy integrity and then the final observation and adjudication whether revenue from a specific transaction can be included for revenue recognition.</p><p id="p-0098" num="0097">In the arrangement shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, purchase order data <b>708</b>, bill of lading data <b>706</b>, and bank statement data <b>704</b> may be received by data integrity system <b>710</b>, which may include one or more processors configured to perform one or more data integrity data processing operations including, for example, purchase order vouching, bill-of-lading vouching, and/or payment vouching. Data integrity system <b>710</b> may additionally receive ERP data from ERP data source <b>702</b>, and may use said ERP data to apply the one or more data integrity data processing operations. Data integrity system <b>710</b> may validate one or more assertions (e.g., existence, completeness, and/or accuracy) by comparing external evidence (e.g., document data) to ERP data. The one or more data integrity data processing operations may include any of those performed by data integrity system <b>120</b> as described in U.S. Patent Application titled &#x201c;AI-AUGMENTED AUDITING PLATFORM INCLUDING TECHNIQUES FOR APPLYING A COMPOSABLE ASSURANCE INTEGRITY FRAMEWORK,&#x201d; filed Jun. 30, 2022, Attorney Docket No. 13574-20070.00.</p><p id="p-0099" num="0098">ERP data from ERP data source <b>702</b> may additionally be received by process integrity system <b>712</b>, which may include one or more processors configured to perform one or more process integrity data processing operations. Process integrity system <b>712</b> may validate assertions (e.g., accuracy, cutoff, and/or classification) by tracing transactions based on ERP data from data source <b>702</b>, for example by following a process (e.g., an order-to-cash transaction process, or a procure-to-pay transaction process) end to end. The one or more process integrity data processing operations may include any of those performed by process integrity system <b>110</b> as described in U.S. Patent Application titled &#x201c;AI-AUGMENTED AUDITING PLATFORM INCLUDING TECHNIQUES FOR APPLYING A COMPOSABLE ASSURANCE INTEGRITY FRAMEWORK,&#x201d; filed Jun. 30, 2022, Attorney Docket No. 13574-20070.00.</p><p id="p-0100" num="0099">The output data generated by data integrity system <b>710</b> and/or process integrity system <b>712</b> may be received by policy integrity system <b>714</b>, which may include one or more processors configured to perform one or more policy integrity data processing operations. Policy integrity system <b>714</b> may validates and adjudicate whether the input data (e.g., representing an overall transaction) is consistent with one or more predefined criteria, for example including accounting standards criteria and/or policy standards criteria. The one or more policy integrity data processing operations may include any of those performed by process integrity system <b>110</b> as described in U.S. Patent Application titled &#x201c;AI-AUGMENTED AUDITING PLATFORM INCLUDING TECHNIQUES FOR APPLYING A COMPOSABLE ASSURANCE INTEGRITY FRAMEWORK,&#x201d; filed Jun. 30, 2022, Attorney Docket No. 13574-20070.00. The output data generated by policy integrity system <b>714</b> may include, or may be used to in turn generate, recommendation data <b>716</b>.</p><p id="p-0101" num="0100"><figref idref="DRAWINGS">FIG. <b>7</b></figref> demonstrates an example of an architecture that may conform with the multilayer explainability techniques described herein, for example by allowing the decomposition of verification of whether the revenue from a transaction can be recognized according to the accounting principles and auditing standards (e.g., by system <b>714</b>) into whether the revenue actually exists (e.g., by data integrity verification system <b>710</b>) and whether there is any discrepancy during the execution of an associated business process (e.g., by systems <b>710</b> and <b>712</b>).</p><p id="p-0102" num="0101">Below are steps for, in some embodiments, establishing summary/recommendation data to be presented to a human user:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0102">1. Collect historical summary/observation for the specific audit area (such as revenue &#x26; receivable audit)</li>        <li id="ul0002-0002" num="0103">2. Provide supervised classification or unsupervised clustering using appropriate ML models to establish the appropriate ontology and/or classification tree for the observation &#x26; recommendation. This becomes the initial set of the observation &#x26; recommendation</li>        <li id="ul0002-0003" num="0104">3. Monitor the usage statistics of the observation and recommendation when the observation/recommendation is used by the human user and collect additional observations/recommendation</li>        <li id="ul0002-0004" num="0105">4. Continuous learning and evolving the observation &#x26; recommendation based on the usage statistics and the augmentation/curation by human users</li>    </ul>    </li></ul></p><p id="p-0103" num="0106">Below are steps for, in some embodiments, tracing a reasoning process. For a specific order to cash transaction, we could potentially go through the following evaluation:<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0107">1. Data integrity        <ul id="ul0005" list-style="none">            <li id="ul0005-0001" num="0108">a. PO was vouched successfully in terms of the existence of PO#, customer name, total amount, and date</li>            <li id="ul0005-0002" num="0109">b. BoL was missing&#x2014;so there is no independent validation of the shipment</li>            <li id="ul0005-0003" num="0110">c. Payment was vouched partially with respect to the payment journal and account receivable as separate entries of payment journal related to the same invoice was not vouched</li>        </ul>        </li>        <li id="ul0004-0002" num="0111">2. Process integrity        <ul id="ul0006" list-style="none">            <li id="ul0006-0001" num="0112">a. Sales order was cross validated with invoice, after identifying potential typo when entering the PO# into the sales order</li>            <li id="ul0006-0002" num="0113">b. Cross validation between invoice and inventory, AR rollforward, AR remove extended, and other modules all indicate consistency</li>        </ul>        </li>        <li id="ul0004-0003" num="0114">3. Policy integrity        <ul id="ul0007" list-style="none">            <li id="ul0007-0001" num="0115">a. Transfer of control was evaluated only based on the shipping term specified by the PO and Sales order to be FOB, and hence the date of title transfer was the date when the products leaving the shipping dock</li>            <li id="ul0007-0002" num="0116">b. Collectability based on the previous payment behavior indicating no delinquent payment, but with a trend of paying closer to the due date.</li>            <li id="ul0007-0003" num="0117">c. Recalculating of recognizable revenue in terms of unit price x quantity seems to indicate consistency</li>        </ul>        </li>        <li id="ul0004-0004" num="0118">4. Final recommendation        <ul id="ul0008" list-style="none">            <li id="ul0008-0001" num="0119">a. The revenue recognized is consistent with the accounting policy and will be included in the final recognizable revenue</li>        </ul>        </li>    </ul>    </li></ul></p><p id="p-0104" num="0120"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example of a computer, according to some embodiments. Computer <b>800</b> can be a component of a system for providing an AI-augmented auditing platform including techniques for providing AI-explainability for processing data through multiple layers. In some embodiments, computer <b>800</b> may execute any one or more of the methods described herein.</p><p id="p-0105" num="0121">Computer <b>800</b> can be a host computer connected to a network. Computer <b>800</b> can be a client computer or a server. As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, computer <b>800</b> can be any suitable type of microprocessor-based device, such as a personal computer, workstation, server, or handheld computing device, such as a phone or tablet. The computer can include, for example, one or more of processor <b>810</b>, input device <b>820</b>, output device <b>830</b>, storage <b>840</b>, and communication device <b>860</b>. Input device <b>820</b> and output device <b>830</b> can correspond to those described above and can either be connectable or integrated with the computer.</p><p id="p-0106" num="0122">Input device <b>820</b> can be any suitable device that provides input, such as a touch screen or monitor, keyboard, mouse, or voice-recognition device. Output device <b>830</b> can be any suitable device that provides an output, such as a touch screen, monitor, printer, disk drive, or speaker.</p><p id="p-0107" num="0123">Storage <b>840</b> can be any suitable device that provides storage, such as an electrical, magnetic, or optical memory, including a random access memory (RAM), cache, hard drive, CD-ROM drive, tape drive, or removable storage disk. Communication device <b>860</b> can include any suitable device capable of transmitting and receiving signals over a network, such as a network interface chip or card. The components of the computer can be connected in any suitable manner, such as via a physical bus or wirelessly. Storage <b>840</b> can be a non-transitory computer-readable storage medium comprising one or more programs, which, when executed by one or more processors, such as processor <b>810</b>, cause the one or more processors to execute methods described herein.</p><p id="p-0108" num="0124">Software <b>850</b>, which can be stored in storage <b>840</b> and executed by processor <b>810</b>, can include, for example, the programming that embodies the functionality of the present disclosure (e.g., as embodied in the systems, computers, servers, and/or devices as described above). In some embodiments, software <b>850</b> can include a combination of servers such as application servers and database servers.</p><p id="p-0109" num="0125">Software <b>850</b> can also be stored and/or transported within any computer-readable storage medium for use by or in connection with an instruction execution system, apparatus, or device, such as those described above, that can fetch and execute instructions associated with the software from the instruction execution system, apparatus, or device. In the context of this disclosure, a computer-readable storage medium can be any medium, such as storage <b>840</b>, that can contain or store programming for use by or in connection with an instruction execution system, apparatus, or device.</p><p id="p-0110" num="0126">Software <b>850</b> can also be propagated within any transport medium for use by or in connection with an instruction execution system, apparatus, or device, such as those described above, that can fetch and execute instructions associated with the software from the instruction execution system, apparatus, or device. In the context of this disclosure, a transport medium can be any medium that can communicate, propagate, or transport programming for use by or in connection with an instruction execution system, apparatus, or device. The transport-readable medium can include but is not limited to, an electronic, magnetic, optical, electromagnetic, or infrared wired or wireless propagation medium.</p><p id="p-0111" num="0127">Computer <b>800</b> may be connected to a network, which can be any suitable type of interconnected communication system. The network can implement any suitable communications protocol and can be secured by any suitable security protocol. The network can comprise network links of any suitable arrangement that can implement the transmission and reception of network signals, such as wireless network connections, T1 or T3 lines, cable networks, DSL, or telephone lines.</p><p id="p-0112" num="0128">Computer <b>800</b> can implement any operating system suitable for operating on the network. Software <b>850</b> can be written in any suitable programming language, such as C, C++, Java, or Python. In various embodiments, application software embodying the functionality of the present disclosure can be deployed in different configurations, such as in a client/server arrangement or through a Web browser as a Web-based application or Web service, for example.</p><p id="p-0113" num="0129">Following is a list of embodiments:<ul id="ul0009" list-style="none">    <li id="ul0009-0001" num="0000">    <ul id="ul0010" list-style="none">        <li id="ul0010-0001" num="0130">Embodiment 1. A system for providing explainability for processing data through multiple data-processing layers, the system comprising one or more processors configured to cause the system to cause the system to:        <ul id="ul0011" list-style="none">            <li id="ul0011-0001" num="0131">at an input layer:            <ul id="ul0012" list-style="none">                <li id="ul0012-0001" num="0132">receive an evidence data set comprising a plurality of evidence items;</li>                <li id="ul0012-0002" num="0133">apply one or more evidence processing models to the evidence data set to generate evidence understanding data; and</li>                <li id="ul0012-0003" num="0134">generate input-layer explainability data, wherein the input-layer explainability data represents information about the processing of the evidence data set by the input layer;</li>            </ul>            </li>            <li id="ul0011-0002" num="0135">at a presentation layer:            <ul id="ul0013" list-style="none">                <li id="ul0013-0001" num="0136">receive data, wherein the received data includes one of: the evidence understanding data, and data generated based on the evidence understanding data;</li>                <li id="ul0013-0002" num="0137">apply one or more presentation generation models to the received data to generate presentation data; and</li>                <li id="ul0013-0003" num="0138">generate presentation-layer explainability data, wherein the presentation-layer explainability data represents information about the processing of the received data by the input layer;</li>            </ul>            </li>            <li id="ul0011-0003" num="0139">cause display of the presentation data; and</li>            <li id="ul0011-0004" num="0140">cause display of one or more of: the input-layer explainability data and the presentation-layer explainability data.</li>        </ul>        </li>        <li id="ul0010-0002" num="0141">Embodiment 2. The system of embodiment 1, wherein the one or more processors are configured to cause the system to:        <ul id="ul0014" list-style="none">            <li id="ul0014-0001" num="0142">at one or more intermediate layers:            <ul id="ul0015" list-style="none">                <li id="ul0015-0001" num="0143">receive the evidence understanding data generated by the input layer;</li>                <li id="ul0015-0002" num="0144">apply one or more intermediate-layer processing models to the evidence understanding data to generate the data received by the presentation layer;</li>                <li id="ul0015-0003" num="0145">provide the data received by the presentation layer to the presentation layer; and</li>                <li id="ul0015-0004" num="0146">generate intermediate-layer explainability data, wherein the intermediate-layer explainability data represents information about the processing of the evidence understanding data by the one or more intermediate layers.</li>            </ul>            </li>        </ul>        </li>        <li id="ul0010-0003" num="0147">Embodiment 3. The system of any one of embodiments 1-2, wherein the input layer and the presentation layer are each configured to apply a respective ontology.</li>        <li id="ul0010-0004" num="0148">Embodiment 4. The system of any one of embodiments 1-3, wherein the one or more processors are configured to cause the system to:        <ul id="ul0016" list-style="none">            <li id="ul0016-0001" num="0149">receive a user input comprising an instruction to modify the input layer; and</li>            <li id="ul0016-0002" num="0150">modify the input layer in accordance with the user input without modifying the presentation layer.</li>        </ul>        </li>        <li id="ul0010-0005" num="0151">Embodiment 5. The system of any one of embodiments 1-4, wherein the one or more processors are configured to:        <ul id="ul0017" list-style="none">            <li id="ul0017-0001" num="0152">receive a user input comprising an instruction to modify the presentation layer; and</li>            <li id="ul0017-0002" num="0153">modify the presentation layer in accordance with the user input without modifying the input layer.</li>        </ul>        </li>        <li id="ul0010-0006" num="0154">Embodiment 6. The system of embodiment 5, wherein modifying the presentation layer comprises modifying the one or more presentation generation models while maintaining an input data format for the one or more presentation generation models and maintain an output data format for the one or more presentation generation models.</li>        <li id="ul0010-0007" num="0155">Embodiment 7. The system of any one of embodiments 5-6, wherein modifying the presentation layer comprises modifying one or more connections of the presentation layer to one or more other layers of the system.</li>        <li id="ul0010-0008" num="0156">Embodiment 8. The system of any one of embodiments 1-7, wherein the one or more processors are configured to initialize the presentation layer by applying one or more machine learning models to classify output data from one or more prior analyses performed by the system.</li>        <li id="ul0010-0009" num="0157">Embodiment 9. The system of any one of embodiments 1-8, wherein the one or more processors are configured to cause the system to:        <ul id="ul0018" list-style="none">            <li id="ul0018-0001" num="0158">receive utilization data representing a manner in which the presentation output is utilized by one or more users; and</li>            <li id="ul0018-0002" num="0159">automatically modify the presentation layer in accordance with the utilization data.</li>        </ul>        </li>        <li id="ul0010-0010" num="0160">Embodiment 10. The system of any one of embodiments 1-9, wherein the one or more processors are configured to cause the system to:        <ul id="ul0019" list-style="none">            <li id="ul0019-0001" num="0161">receive a user input comprising a selection of a portion of the displayed presentation data,</li>            <li id="ul0019-0002" num="0162">wherein causing display of one or more of the input-layer explainability data and the presentation-layer explainability data is performed in accordance with the user input.</li>        </ul>        </li>        <li id="ul0010-0011" num="0163">Embodiment 11. The system of any one of embodiments 1-10, wherein the one or more processors are configured to cause the system to, at the presentation layer, select, based on the received data, the one or more presentation generation models from a superset of presentation generation models.</li>        <li id="ul0010-0012" num="0164">Embodiment 12. A non-transitory computer-readable storage medium storing instructions for providing explainability for processing data through multiple data-processing layers, wherein the instructions are configured to be executed by a system comprising one or more processors to cause the system to:        <ul id="ul0020" list-style="none">            <li id="ul0020-0001" num="0165">at an input layer:            <ul id="ul0021" list-style="none">                <li id="ul0021-0001" num="0166">receive an evidence data set comprising a plurality of evidence items;</li>                <li id="ul0021-0002" num="0167">apply one or more evidence processing models to the evidence data set to generate evidence understanding data; and</li>                <li id="ul0021-0003" num="0168">generate input-layer explainability data, wherein the input-layer explainability data represents information about the processing of the evidence data set by the input layer;</li>            </ul>            </li>            <li id="ul0020-0002" num="0169">at a presentation layer:            <ul id="ul0022" list-style="none">                <li id="ul0022-0001" num="0170">receive data, wherein the received data includes one of: the evidence understanding data, and data generated based on the evidence understanding data;</li>                <li id="ul0022-0002" num="0171">apply one or more presentation generation models to the received data to generate presentation data; and</li>                <li id="ul0022-0003" num="0172">generate presentation-layer explainability data, wherein the presentation-layer explainability data represents information about the processing of the received data by the input layer;</li>            </ul>            </li>            <li id="ul0020-0003" num="0173">cause display of the presentation data; and</li>            <li id="ul0020-0004" num="0174">cause display of one or more of: the input-layer explainability data and the presentation-layer explainability data.</li>        </ul>        </li>        <li id="ul0010-0013" num="0175">Embodiment 13. A method for providing explainability for processing data through multiple data-processing layers, wherein the method is performed by a system comprising one or more processors, the method comprising:        <ul id="ul0023" list-style="none">            <li id="ul0023-0001" num="0176">at an input layer:            <ul id="ul0024" list-style="none">                <li id="ul0024-0001" num="0177">receiving an evidence data set comprising a plurality of evidence items;</li>                <li id="ul0024-0002" num="0178">applying one or more evidence processing models to the evidence data set to generate evidence understanding data; and</li>                <li id="ul0024-0003" num="0179">generating input-layer explainability data, wherein the input-layer explainability data represents information about the processing of the evidence data set by the input layer;</li>            </ul>            </li>            <li id="ul0023-0002" num="0180">at a presentation layer:            <ul id="ul0025" list-style="none">                <li id="ul0025-0001" num="0181">receiving data, wherein the received data includes one of: the evidence understanding data, and data generated based on the evidence understanding data;</li>                <li id="ul0025-0002" num="0182">applying one or more presentation generation models to the received data to generate presentation data; and</li>                <li id="ul0025-0003" num="0183">generating presentation-layer explainability data, wherein the presentation-layer explainability data represents information about the processing of the received data by the input layer;</li>            </ul>            </li>            <li id="ul0023-0003" num="0184">causing display of the presentation data; and</li>            <li id="ul0023-0004" num="0185">causing display of one or more of: the input-layer explainability data and the presentation-layer explainability data.</li>        </ul>        </li>    </ul>    </li></ul></p><p id="p-0114" num="0186">This application incorporates by reference the entire contents of the U.S. Patent Application titled &#x201c;AI-AUGMENTED AUDITING PLATFORM INCLUDING TECHNIQUES FOR AUTOMATED ASSESSMENT OF VOUCHING EVIDENCE&#x201d;, filed Jun. 30, 2022, Attorney Docket no. 13574-20068.00.</p><p id="p-0115" num="0187">This application incorporates by reference the entire contents of the U.S. Patent Application titled &#x201c;AI-AUGMENTED AUDITING PLATFORM INCLUDING TECHNIQUES FOR AUTOMATED ADJUDICATION OF COMMERCIAL SUBSTANCE, RELATED PARTIES, AND COLLECTABILITY&#x201d;, filed Jun. 30, 2022, Attorney Docket no. 13574-20069.00.</p><p id="p-0116" num="0188">This application incorporates by reference the entire contents of the U.S. Patent Application titled &#x201c;AI-AUGMENTED AUDITING PLATFORM INCLUDING TECHNIQUES FOR APPLYING A COMPOSABLE ASSURANCE INTEGRITY FRAMEWORK&#x201d;, filed Jun. 30, 2022, Attorney Docket no. 13574-20070.00.</p><p id="p-0117" num="0189">This application incorporates by reference the entire contents of the U.S. Patent Application titled &#x201c;AI-AUGMENTED AUDITING PLATFORM INCLUDING TECHNIQUES FOR AUTOMATED DOCUMENT PROCESSING&#x201d;, filed Jun. 30, 2022, Attorney Docket no. 13574-20071.00.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system for providing explainability for processing data through multiple data-processing layers, the system comprising one or more processors configured to cause the system to cause the system to:<claim-text>at an input layer:<claim-text>receive an evidence data set comprising a plurality of evidence items;</claim-text><claim-text>apply one or more evidence processing models to the evidence data set to generate evidence understanding data; and</claim-text><claim-text>generate input-layer explainability data, wherein the input-layer explainability data represents information about the processing of the evidence data set by the input layer;</claim-text></claim-text><claim-text>at a presentation layer:<claim-text>receive data, wherein the received data includes one of: the evidence understanding data, and data generated based on the evidence understanding data;</claim-text><claim-text>apply one or more presentation generation models to the received data to generate presentation data; and</claim-text><claim-text>generate presentation-layer explainability data, wherein the presentation-layer explainability data represents information about the processing of the received data by the input layer;</claim-text></claim-text><claim-text>cause display of the presentation data; and</claim-text><claim-text>cause display of one or more of: the input-layer explainability data and the presentation-layer explainability data.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more processors are configured to cause the system to:<claim-text>at one or more intermediate layers:<claim-text>receive the evidence understanding data generated by the input layer;</claim-text><claim-text>apply one or more intermediate-layer processing models to the evidence understanding data to generate the data received by the presentation layer;</claim-text><claim-text>provide the data received by the presentation layer to the presentation layer; and</claim-text><claim-text>generate intermediate-layer explainability data, wherein the intermediate-layer explainability data represents information about the processing of the evidence understanding data by the one or more intermediate layers.</claim-text></claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the input layer and the presentation layer are each configured to apply a respective ontology.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more processors are configured to cause the system to:<claim-text>receive a user input comprising an instruction to modify the input layer; and</claim-text><claim-text>modify the input layer in accordance with the user input without modifying the presentation layer.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more processors are configured to:<claim-text>receive a user input comprising an instruction to modify the presentation layer; and</claim-text><claim-text>modify the presentation layer in accordance with the user input without modifying the input layer.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein modifying the presentation layer comprises modifying the one or more presentation generation models while maintaining an input data format for the one or more presentation generation models and maintain an output data format for the one or more presentation generation models.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein modifying the presentation layer comprises modifying one or more connections of the presentation layer to one or more other layers of the system.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more processors are configured to initialize the presentation layer by applying one or more machine learning models to classify output data from one or more prior analyses performed by the system.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more processors are configured to cause the system to:<claim-text>receive utilization data representing a manner in which the presentation output is utilized by one or more users; and</claim-text><claim-text>automatically modify the presentation layer in accordance with the utilization data.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more processors are configured to cause the system to:<claim-text>receive a user input comprising a selection of a portion of the displayed presentation data,</claim-text><claim-text>wherein causing display of one or more of the input-layer explainability data and the presentation-layer explainability data is performed in accordance with the user input.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more processors are configured to cause the system to, at the presentation layer, select, based on the received data, the one or more presentation generation models from a superset of presentation generation models.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A non-transitory computer-readable storage medium storing instructions for providing explainability for processing data through multiple data-processing layers, wherein the instructions are configured to be executed by a system comprising one or more processors to cause the system to:<claim-text>at an input layer:<claim-text>receive an evidence data set comprising a plurality of evidence items;</claim-text><claim-text>apply one or more evidence processing models to the evidence data set to generate evidence understanding data; and</claim-text><claim-text>generate input-layer explainability data, wherein the input-layer explainability data represents information about the processing of the evidence data set by the input layer;</claim-text></claim-text><claim-text>at a presentation layer:<claim-text>receive data, wherein the received data includes one of: the evidence understanding data, and data generated based on the evidence understanding data;</claim-text><claim-text>apply one or more presentation generation models to the received data to generate presentation data; and</claim-text><claim-text>generate presentation-layer explainability data, wherein the presentation-layer explainability data represents information about the processing of the received data by the input layer;</claim-text></claim-text><claim-text>cause display of the presentation data; and</claim-text><claim-text>cause display of one or more of: the input-layer explainability data and the presentation-layer explainability data.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A method for providing explainability for processing data through multiple data-processing layers, wherein the method is performed by a system comprising one or more processors, the method comprising:<claim-text>at an input layer:<claim-text>receiving an evidence data set comprising a plurality of evidence items;</claim-text><claim-text>applying one or more evidence processing models to the evidence data set to generate evidence understanding data; and</claim-text><claim-text>generating input-layer explainability data, wherein the input-layer explainability data represents information about the processing of the evidence data set by the input layer;</claim-text></claim-text><claim-text>at a presentation layer:<claim-text>receiving data, wherein the received data includes one of: the evidence understanding data, and data generated based on the evidence understanding data;</claim-text><claim-text>applying one or more presentation generation models to the received data to generate presentation data; and</claim-text><claim-text>generating presentation-layer explainability data, wherein the presentation-layer explainability data represents information about the processing of the received data by the input layer;</claim-text></claim-text><claim-text>causing display of the presentation data; and</claim-text><claim-text>causing display of one or more of: the input-layer explainability data and the presentation-layer explainability data.</claim-text></claim-text></claim></claims></us-patent-application>
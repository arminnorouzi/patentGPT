<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005282A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005282</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17942858</doc-number><date>20220912</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-052183</doc-number><date>20200324</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>12</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>30</main-group><subgroup>12</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>2201</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">INFORMATION PROCESSING APPARATUS, INFORMATION PROCESSING METHOD, COMPUTER PROGRAM PRODUCT, AND RECORDING MEDIUM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/007410</doc-number><date>20210226</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17942858</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>KABUSHIKI KAISHA TOSHIBA</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant><us-applicant sequence="01" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>TOSHIBA DIGITAL SOLUTIONS CORPORATION</orgname><address><city>Kawasaki-shi Kanagawa</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>TANAKA</last-name><first-name>Ryohei</first-name><address><city>Kawasaki Kanagawa</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>KABUSHIKI KAISHA TOSHIBA</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee><assignee><addressbook><orgname>TOSHIBA DIGITAL SOLUTIONS CORPORATION</orgname><role>03</role><address><city>Kawasaki-shi Kanagawa</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An information processing apparatus according to one embodiment includes a memory and one or more hardware processors. The memory stores order information in which an order of pieces of meta-information for a character to be recognized is defined. The one or more hardware processors are connected to the memory and function as a recognition unit and an update unit. The recognition unit serves to perform character recognition on an image including a character string by using first meta-information specified from the pieces of the meta-information. The update unit serves to update the first meta-information to second meta-information. in accordance with the order information in a case when a confidence score of the character recognition satisfies a predetermined condition. The character recognition is performed by using the second meta-information.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="72.81mm" wi="100.58mm" file="US20230005282A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="213.70mm" wi="146.98mm" file="US20230005282A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="106.93mm" wi="152.06mm" file="US20230005282A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="214.21mm" wi="159.26mm" file="US20230005282A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="205.06mm" wi="140.97mm" file="US20230005282A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="214.21mm" wi="146.22mm" file="US20230005282A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="202.52mm" wi="159.26mm" file="US20230005282A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="214.12mm" wi="121.84mm" file="US20230005282A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="211.16mm" wi="158.67mm" file="US20230005282A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="234.53mm" wi="155.45mm" file="US20230005282A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of PCT International Application No. PCT/JP2021/007410 filed on Feb. 26, 2021 which claims the benefit of priority from Japanese Patent Application No. 2020-052183, filed on Mar. 24, 2020, the entire contents of which are incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">Embodiments described herein relate generally to an information processing apparatus, an information processing method, a computer program product, and a recording medium.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">In character string recognition for predicting a likely character string with a character string image as an input, a method has been proposed to improve recognition accuracy by considering information added to the character string image. For example, in recognition of a ledger sheet image, more accurate recognition is achieved by performing different recognition processes for each of field types such as an address field, a date field, and a name field. The field type is input, as meta-information added to the character string image, to a character recognition system. The meta-information is used for identification between homomorphic characters and selection of a character that can be taken as a result of the recognition.</p><p id="p-0005" num="0004">However, in such a conventional art, if the meta-information is wrong and if an image that is not expected by the meta-information is input, there is a possibility that the recognition accuracy is lowered.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0006" num="0005">FIG. I is a block diagram illustrating an example of a configuration of an information processing apparatus according to a first embodiment;</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a graph illustrating an example of a data structure of order information;</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a table illustrating an example of a data structure of the order information stored in a storage unit;</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating an example of a recognition process according to the first embodiment;</p><p id="p-0010" num="0009">FIG. .<b>5</b> is a diagram illustrating an example of GUI for specifying the meta-information;</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a graph illustrating an example of a data structure of the order information;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram illustrating an example of a configuration of an information processing apparatus according to a second embodiment;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a graph illustrating an example of a data structure of order information according to the second embodiment;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example of a recognition process according to the second embodiment;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram illustrating an example of a configuration of an information processing apparatus according to a third embodiment;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart illustrating an example of a correction process according to the third embodiment;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a graph illustrating an example of corrected order information;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a block diagram illustrating an example of a configuration of an information processing apparatus according to a fourth embodiment;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart illustrating an example of an estimation process according to the fourth embodiment; and</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is an explanatory diagram illustrating a hardware configuration example of each of the information processing apparatuses according to the first to fourth embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0021" num="0020">An information processing apparatus according to one embodiment includes a memory and one or more hardware processors. The memory is configured to store order information in which an order of pieces of meta-information for a character to be recognized is defined. The one or more hardware processors are connected to the memory and configured to function as a recognition unit and an update unit. The recognition unit serves to perform character recognition on an image including a character string by using first meta-information specified from the pieces of the meta-information. The update unit serves to update the first meta-information to second meta-information in accordance with the order information in a case when a confidence score of the character recognition satisfies a predetermined condition. The recognition unit performs the character recognition by using the second meta-information.</p><p id="p-0022" num="0021">Embodiments of an information processing apparatus according to the present invention will be described in detail below with reference to the accompanying drawings.</p><heading id="h-0006" level="1">First Embodiment</heading><p id="p-0023" num="0022">Recognition accuracy using meta-information may be lowered in the following cases. For example, it is assumed bere that &#x201c;MAIKERU&#x201d; (corresponding to &#x201c;Michael&#x201d; in the English language) is filled in a field of first name to be written in katakana characters (katakana is one of character types of the Japanese language) and &#x201c;first name written in katakana characters&#x201d; is specified as the meta-information. However, in a case where a first name of a foreigner such as &#x201c;MAIKERU&#x201d; above is not expected in a recognition process associated with the first name written in katakana characters, the recognition accuracy decreases.</p><p id="p-0024" num="0023">Therefore, in a first embodiment, the meta-information is structured in advance so as to determine the order of pieces of meta-information. In the first embodiment, when a specified piece of meta-information (hereinafter, referred to as a piece of specified meta-information) has a lower confidence score in a result of the recognition, character recognition is performed again using a piece of meta-information that is updated in accordance with the order. This configuration makes it possible to obtain a more accurate result of the recognition.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating an example of a configuration of an information processing apparatus <b>100</b> according to the first embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the information processing apparatus <b>100</b> includes a display unit <b>111</b>, a storage unit <b>121</b>, a reception unit <b>101</b>, a recognition unit <b>102</b>, an update unit <b>103</b>, and an output control unit <b>104</b>.</p><p id="p-0026" num="0025">The display unit <b>111</b> is an example of an output device that outputs various information processed by the information processing apparatus <b>100</b>. The display unit <b>111</b> is, for example, a display device, such as a display, that displays information. The output device that outputs information is not limited to the display unit <b>111</b> (display device), and may be any device. For example, the output device may be another information processing apparatus connected via a network (wired or wireless) such as the Internet.</p><p id="p-0027" num="0026">The storage unit <b>121</b> is a storage medium that stores various information to be processed by the information processing apparatus <b>100</b>. For example, the storage unit <b>121</b> stores order information in which the order of pieces of meta-information for a character to be recognized is defined. The storage unit <b>121</b> can include any storage medium generally used, such as a flash memory, memory card, random access memory (RAM), hard disk drive (HDD), or optical disk.</p><p id="p-0028" num="0027">Here, a data structure of the order information will be described. <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a graph illustrating an example of the data structure of the order information. <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example of the order information represented by a directed acyclic graph in which the pieces of meta-information are defined as nodes and the nodes are connected by directed edges. Note that the data structure of the order information is not limited to the directed acyclic graph.</p><p id="p-0029" num="0028">The directed acyclic graph refers to a graph structure having no closed loop out of directed graphs including nodes and directed edges. In other words, in the directed acyclic graph, following the edges from any node does not return to the same node again. In the following, out of two nodes connected by a directed edge, a node serving as a connection source (start point) is referred to as a start node, and a node (a node serving as an end point and a connection destination node) to which the directed edge points is referred to as an end node. Of the nodes of the directed acyclic graph, a node that is not the connection source (start point) for any node is referred to as a top node, and a node that is not the connection destination (end point) for any node is referred to as a bottom node.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example of the directed acyclic graph depicting the order information in which the meta-information closer to the bottom node has subdivided sets represented by the meta-information. The order information may form a directed acyclic graph in which the meta-information closer to the top node has subdivided sets represented by the meta-information.</p><p id="p-0031" num="0030">The directed acyclic graph of <figref idref="DRAWINGS">FIG. <b>2</b></figref> includes nodes for which &#x201c;unspecified&#x201d;, &#x201c;address&#x201d;, &#x201c;alphanumeric characters and symbols&#x201d;, &#x201c;katakana characters&#x201d;, &#x201c;English word&#x201d;, &#x201c;numerals&#x201d;, &#x201c;family name written in katakana characters&#x201d;, and &#x201c;first name written in katakana characters&#x201d; are defined as meta-information indicating field types. When attention is paid to two pieces of meta-information connected by the directed edge, the directed acyclic graph is defined such that the meta-information of the start node represents a subset of the meta-information of the end node.</p><p id="p-0032" num="0031">For example, in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the top node has the field type &#x201c;unspecified&#x201d; and represents the largest set (total set) having no assumption in the field type. The nodes &#x201c;address&#x201d;, &#x201c;alphanumeric characters and symbols&#x201d;, and &#x201c;katakana characters&#x201d; corresponding to the node &#x201c;unspecified&#x201d; as the end point are equivalent to subsets of &#x201c;unspecified&#x201d;. The nodes &#x201c;English word&#x201d; and &#x201c;numerals&#x201d; corresponding to the node &#x201c;alphanumeric characters and symbols&#x201d; as the end point are equivalent to subsets of &#x201c;alphanumeric characters and symbols&#x201d;. The nodes &#x201c;family name written in katakana characters&#x201d; and &#x201c;first name written in katakana characters&#x201d; corresponding to the node &#x201c;katakana characters&#x201d; as the end point are equivalent to subsets of &#x201c;katakana characters&#x201d;, As described above, the meta-information closer to the bottom node represents the subdivided sets.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a table illustrating an example of a data structure of the order information stored in the storage unit <b>121</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the storage unit <b>121</b> stores the directed acyclic graph in the form of a table in which the connection destination node (end node) for each of all nodes constituting the directed acyclic graph. Note that the data structure of <figref idref="DRAWINGS">FIG. <b>3</b></figref> is an example, and the order information may be stored in another structure.</p><p id="p-0034" num="0033">Returning to FIG. I, other functions will be described.</p><p id="p-0035" num="0034">The reception unit <b>101</b> receives inputs of various information used by the information processing apparatus <b>100</b>. For example, the reception unit <b>101</b> receives an image (an image including a character string) to be subjected to the recognition process. Any method may be employed as a method of receiving each data by the reception unit <b>101</b>. For example, a method of acquiring data from an external device via a network, a method of reading data stored in a storage medium, and the like can be applied. The network is a local area network (LAN), the Internet, or the like, but may be any other network. The network may be any of a wired network and a wireless network.</p><p id="p-0036" num="0035">Moreover, the reception unit <b>101</b> receives, for example, the specified piece of meta-information that is specified by a user. Any method may be employed as a method of specifying information by the user, but, for example, a method of specifying the information by using an input device such as a keyboard or a mouse can be applied.</p><p id="p-0037" num="0036">The recognition unit <b>102</b> performs character recognition on the image including a character string. The recognition unit <b>102</b> performs the character recognition according to the meta-information by using the specified piece of meta-information, For example, when the meta-information (field type) indicates &#x201c;unspecified&#x201d;, the recognition unit <b>102</b> performs the character recognition on the assumption of all character types and character sequences. When the meta-information indicates &#x201c;katakana characters&#x201d;, the recognition unit <b>102</b> performs the character recognition by limiting the character type to katakana characters, Moreover, when the meta-information indicates &#x201c;family name written in katakana characters&#x201d;, the recognition unit <b>102</b> performs the character recognition by limiting the character string to a character string having a sequence corresponding to the family name written in katakana characters. Specifying an appropriate piece of meta-information can improve the recognition accuracy.</p><p id="p-0038" num="0037">While any method may be employed as a. method of switching the recognition process according to the meta-information, the following three methods (M<b>1</b>) to (M<b>3</b>) can be applied, for example,</p><p id="p-0039" num="0038">(M<b>1</b>) A character string recognition model is prepared for each piece of meta-information. The character string recognition model is, for example, a neural network and a hidden markov model (HMM).</p><p id="p-0040" num="0039">(M<b>2</b>) For character shape recognition, candidates are estimated by a common algorithm that does not use the meta-information, and different ranking processes are performed according to the meta-information upon selecting a character string candidate afterward,</p><p id="p-0041" num="0040">(M<b>3</b>) A character string recognition model to which the meta-information can be input as a vector in addition to a character string image is used. For example, a neural network to which the meta-information and the character string image is input and from which a result of the recognition is output can be used as the character string recognition model.</p><p id="p-0042" num="0041">In order to transform the meta-information to the vector, for example, a one-hot vector is preferably used. The one-hot vector is a vector in Which, for example, only a dimension corresponding to a dimension number of a corresponding node becomes &#x201c;<b>1</b>&#x201d; the other dimensions become &#x201c;<b>0</b>&#x201d;, and the number of dimensions is the same as the number of nodes. The dimension number is a number assigned to each node as unique identification information, for example, as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. In the graph structure of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the vector representing &#x201c;family name written in katakana characters&#x201d; is (0,0,0,0,0,0,1,0)<sup>T</sup>.</p><p id="p-0043" num="0042">The update unit <b>103</b> updates the meta-information in accordance with the order defined in the order information. For example, when the confidence score of the character recognition by the recognition unit <b>102</b> by using the specified piece of meta-information (first meta-information) satisfies a predetermined condition, the update unit <b>103</b> updates the specified piece of meta-information to another piece of meta-information (second meta-information) in accordance with the order information. More specifically, the update unit <b>103</b> updates a specified piece of meta-information, to a piece of meta-information connected to the specified piece of meta-information by a corresponding directed edge.</p><p id="p-0044" num="0043">The predetermined condition is, for example, a condition where the confidence score is equal to or higher than a threshold. The condition is not limited thereto, and for example, another condition that enables determination of small confidence score may be used. For example, a condition that a difference in the confidence score between a result of the recognition haying the best confidence score and a result of the recognition haying the second best confidence score is equal to or lower than the threshold may be used.</p><p id="p-0045" num="0044">The output control unit <b>104</b> controls output of various information by the information processing apparatus <b>100</b>. For example, the output control unit <b>104</b> outputs a result of the recognition to the display unit <b>111</b> and another device that uses the result of the recognition. In addition, the output control unit <b>104</b> may have a function of displaying the pieces of meta-information on the display unit <b>111</b> in accordance with the order defined in the order information (details will be described later).</p><p id="p-0046" num="0045">Each of the units described above (the reception unit <b>101</b>, the recognition unit <b>102</b>, update unit <b>103</b>, and the output control unit <b>104</b>) is implemented by, for example, one or more hardware processors. For example, each of the units described above may be implemented by causing the processor such as a central processing unit (CPU) to execute a program, that is, by software. Each of the units described above may be implemented by a processor such as a dedicated integrated circuit (IC), that is, hardware. Each of the units described above may be implemented by using software and hardware in combination. In a case where two or more processors are used, each of the processors may implement one of the units, or may implement two or more of the units.</p><p id="p-0047" num="0046">Next, the recognition process performed by the information processing apparatus <b>100</b> according to the first embodiment configured as described above will be described. <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating an example of the recognition process according to the first embodiment.</p><p id="p-0048" num="0047">The reception unit <b>101</b> receives an image to be recognized and the meta-information (Step S<b>101</b>). The recognition unit <b>102</b> performs the character recognition on the received image and meta-information, predicts a likely character string and the confidence score of the character string, and outputs the predicted confidence score and character string (Step S<b>102</b>). The recognition unit <b>102</b> determines whether the confidence score is equal to or higher than the threshold (Step S<b>103</b>).</p><p id="p-0049" num="0048">Note that the threshold may be a predetermined constant value or may be a value changed in accordance with a rule. The rule includes, for example, a rule of increasing the threshold every time the meta-information is updated (Step S<b>107</b> described later) and the character recognition in Step S<b>102</b> is performed. Examples of the rule of increasing the threshold include a rule of increasing the threshold by multiplying the threshold by a predetermined multiplying factor (for example, 1.1 times) every time the character recognition is performed, a rule of adding a predetermined value every time the character recognition is performed, and the like.</p><p id="p-0050" num="0049">In a case when the confidence score is equal to or higher than the threshold (Step S<b>103</b>: Yes), the recognition unit <b>102</b> outputs the predicted character string as a result of the recognition (Step S<b>104</b>), and finishes the recognition process. In a case when the confidence score is not equal to or higher than the threshold (Step S<b>103</b>: No), the recognition unit <b>102</b> stores the predicted confidence score and character string (result of the recognition) in the storage unit <b>121</b> (Step S<b>105</b>).</p><p id="p-0051" num="0050">The update unit <b>103</b> determines whether there is the connection destination for the specified piece of meta-information (meta-information used for the character recognition) (Step S<b>106</b>). For example, the update unit <b>103</b> refers to the order information and determines that there is no connection destination for the specified piece of meta-information in a case when the specified meta-information is the top node. When there is no connection destination (Step S<b>106</b>: No), the update unit <b>103</b> outputs a result of the recognition having the best confidence score from the results of the recognition having been stored in the storage unit <b>121</b> (Step S<b>107</b>), and finishes the recognition process,</p><p id="p-0052" num="0051">When there is the connection destination for the specified piece of meta-information (Step S<b>106</b>: Yes), the update unit <b>103</b> updates the meta-information in accordance with the order information (Step S<b>108</b>). For example, the update unit <b>103</b> updates the piece of meta-information to another piece of meta-information corresponding to the connection destination node defined in the order information. In the order information as illustrated in <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>, a piece of meta-information is updated to another piece of meta-information belonging to a larger set.</p><p id="p-0053" num="0052">After that, the process returns to Step S<b>102</b>, and the character recognition is performed again by the recognition unit <b>102</b> by using the updated meta-information.</p><p id="p-0054" num="0053">The result of the recognition output in Step S<b>107</b> may be determined in consideration of not only the confidence score but also another factor. For example, the update unit <b>103</b> may add the number of repetitions of the character recognition (Step S<b>102</b>) to an evaluation index in addition to the confidence score, select a result of the recognition having a smaller number of repetitions and better confidence score, and output the result. Moreover, for example, the update unit <b>103</b> may select a result of the recognition most frequently obtained, from the stored results of the recognition and output the result.</p><p id="p-0055" num="0054">A specific example of the recognition process will be described below. It is assumed that the image to be recognized is a character string image including a character string &#x201c;MAIKERU&#x201d;, the specified piece of meta-information is &#x201c;first name written in katakana characters&#x201d;, and a threshold of the confidence score is &#x201c;0.5&#x201d;. Moreover, in a case where the meta-information is &#x201c;first name written in katakana characters&#x201d;, a Japanese first name &#x201c;MAIKO&#x201d; is expected, whereas a foreign first name &#x201c;MAIKERU&#x201d; is unexpected. Meanwhile, &#x201c;MAIKERU&#x201d; is expected when the meta-information is &#x201c;katakana characters&#x201d;.</p><p id="p-0056" num="0055">It is assumed that the result of the recognition is &#x201c;MAIKO&#x201d; and the confidence score is &#x201c;0.3&#x201d; in the first time of character recognition (Step S<b>102</b>), on the above assumption. In this case, the confidence score is lower than the threshold (Step S<b>103</b>: No), the meta-information is updated to &#x201c;katakana characters&#x201d; that is the connection destination of &#x201c;first name written in katakana characters&#x201d; (Step S<b>108</b>). It is assumed that the character recognition (Step S<b>102</b>) is performed again with the updated meta-information and the result of the recognition is &#x201c;MAIKERU&#x201d; and the confidence score is &#x201c;0.8&#x201d;. The confidence score becomes equal to or higher than the threshold (Step S<b>103</b>: Yes), so that &#x201c;MAIKERU&#x201d; is output as the result of the recognition (Step S<b>104</b>).</p><p id="p-0057" num="0056">In a case where the present embodiment is not employed, &#x201c;MAIKO&#x201d; having the lower confidence score is output as the result of the recognition from the character recognition according to &#x201c;first name written in katakana characters&#x201d; that is the specified piece of meta-information. On the other hand, by employing the present embodiment, it is possible to update the meta-information to &#x201c;katakana characters&#x201d; and perform the character recognition again, so that &#x201c;MAIKERU&#x201d; having the higher confidence score can be output as the result of the recognition.</p><p id="p-0058" num="0057">The meta-information used in the recognition process is specified by, for example, the user. The output control unit <b>104</b> may display pieces of meta-information that can be specified by the user, in accordance with the order information. <figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating an example of a graphical user interface (GUI) for specifying a piece of meta-information.</p><p id="p-0059" num="0058">For example, the output control unit <b>104</b> sequentially displays the pieces of meta-information according to the following procedure. First, the output control unit <b>104</b> displays a piece of meta-information corresponding to the top node of the directed acyclic graph stored in the storage unit <b>121</b>, that is, a node for which there is no connection destination. When one of the displayed pieces of meta-information is selected by the user, the output control unit <b>104</b> further displays pieces of meta-information connected to the selected piece of meta-information. Hereinafter, similar processing is repeated according to selection by the user.</p><p id="p-0060" num="0059">In a case where there is only one top node, it is clear that the top node is selected, and therefore, nodes connected to the top node may also be displayed. <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example in which a piece of meta-information &#x201c;unspecified&#x201d; corresponding to the top node and the three pieces of meta-information &#x201c;address&#x201d;, &#x201c;alphanumeric characters and symbols&#x201d;, and &#x201c;katakana characters&#x201d; corresponding to the nodes connected to the top node are initially displayed. Moreover, <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example in which two pieces of meta-information &#x201c;family name written in katakana. characters&#x201d; and &#x201c;first name written in katakana characters&#x201d;, each corresponding to the nodes connected to &#x201c;katakana characters&#x201d;, are further displayed in response to the selection of &#x201c;katakana characters&#x201d;.</p><p id="p-0061" num="0060">Any method may be employed as a method for selection by the user. For example, a method of clicking a piece of meta-information, a method of pointing to a piece of meta-information (mouse over etc.), and the like can be applied.</p><p id="p-0062" num="0061">Displaying the pieces of meta-information hierarchically organized as described above makes it possible to facilitate selection of a piece of meta-information by the user, even when the number of pieces of meta-information is large and the graph structure is complicated.</p><p id="p-0063" num="0062">The example of the meta-information as the field type has been described above, whereas the meta-information may be any other information. For example, character shapes of handwriting character, typeface, and the like may be used as the meta-information. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a graph illustrating an example of a data structure of the order information with character shapes as the meta-information.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an example in which pieces of meta-information indicating writing persons such as &#x201c;writer A&#x201d; and &#x201c;writer B&#x201d; are set as subsets of &#x201c;handwriting character&#x201d;, and pieces of meta-information indicating fonts such as &#x201c;Gothic font&#x201d; and &#x201c;Mincho serif font&#x201d; are set as subsets of &#x201c;typeface&#x201d;,</p><heading id="h-0007" level="1">First Modification</heading><p id="p-0065" num="0064">The number of pieces of order information indicating the meta-information is not limited to one, and may be N or more (N is an integer of 2 or more). For example, two pieces of order information, that is, the order information illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> (<figref idref="DRAWINGS">FIG. <b>3</b></figref>) and the order information illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, may be used. In this configuration, the storage unit <b>121</b> stores two pieces of order information corresponding to two types of meta-information (field type and character shape) and represented by directed acyclic graphs.</p><p id="p-0066" num="0065">The recognition unit <b>102</b> performs a recognition process according to two pieces of meta-information. In a case where two pieces of order information of <figref idref="DRAWINGS">FIG. <b>2</b></figref> (field type) and <figref idref="DRAWINGS">FIG. <b>6</b></figref> (character shape) are used, recognition process is performed in 56 ways by combining eight field types and seven character shapes. In other words, the recognition unit <b>102</b> performs the character recognition by using N pieces of meta-information specified from each of pieces of meta-information defined in the N pieces of order information.</p><p id="p-0067" num="0066">The meta-information may be any type such as language and image capture condition, in addition to the field type and the character shape. By using plural types of meta-information, it is possible to assume more detailed conditions and further improve the prediction accuracy of the recognition unit <b>102</b>.</p><heading id="h-0008" level="1">Second Modification</heading><p id="p-0068" num="0067">The meta-information input by the user may be pieces of weighted meta-information. For example, in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, weights are assigned to the pieces of meta-information, for example, a weight of &#x201c;1.0&#x201d; is assigned to &#x201c;address&#x201d; and a weight of &#x201c;0.6&#x201d; is assigned to &#x201c;first name written in katakana characters&#x201d;.</p><p id="p-0069" num="0068">In this configuration, the recognition unit <b>102</b> preferably performs the character recognition by using all pieces of input meta-information to output a result of the recognition that is the best in evaluation value (for example, a product of the weight and the confidence score) obtained from the weight and the confidence score. Thereafter, the meta-information can be updated as described in the above embodiment.</p><p id="p-0070" num="0069">Specification of the pieces of weighted meta-information is useful when the meta-information (such as a field type) is limited to some extent but is not reliable. For example, it is possible to store the meta-information estimated in an estimation process or the like of estimating the meta-information, in association with the weight equivalent to the confidence score of the estimation, and perform the character recognition by using the stored meta-information. Using a system that estimates (predicts) the meta-information as described above often provides a result of the prediction having probability distribution, and thus, a function of specifying pieces of meta-information with weights is effective.</p><p id="p-0071" num="0070">As described above, in the information processing apparatus according to the first embodiment, the order information (or graph structure) indicating the order of the pieces of meta-information is used to flexibly update the meta-information even for an unexpected input, enabling more accurate recognition. Moreover, according to the present embodiment, sequentially displaying the pieces of meta-information in accordance with the order information makes it possible to implement the GUI from which the user can specify appropriate piece of meta-information.</p><heading id="h-0009" level="1">Second Embodiment</heading><p id="p-0072" num="0071">In the first embodiment, the number of connection destinations of one piece of meta-information that is one or less has been described. In a second embodiment, the number of connection destinations of one piece of meta-information that is two or more will be described.</p><p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram illustrating an example of a configuration of an information processing apparatus <b>100</b>-<b>2</b> according to the second embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the information processing apparatus <b>100</b>-<b>2</b> includes the display unit <b>111</b>, a storage unit <b>121</b>-<b>2</b>, the reception unit <b>101</b>, a recognition unit <b>102</b>-<b>2</b>, an update unit <b>103</b>-<b>2</b>, and the output control unit <b>104</b>.</p><p id="p-0074" num="0073">In the second embodiment, functions of the storage unit <b>121</b>-<b>2</b>, the recognition unit <b>102</b>-<b>2</b>, and the update unit <b>103</b>-<b>2</b> are different from those of the first embodiment. The other configurations and functions are similar to those of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, which illustrates a block diagram of the information processing apparatus <b>100</b> according to the first embodiment. Therefore, the other configurations and functions are denoted by the same reference numerals and description thereof will be omitted bere.</p><p id="p-0075" num="0074">The storage unit <b>121</b>-<b>2</b> is different from the storage unit <b>121</b> of the first embodiment in that, order information to which weights are assigned is stored. For example, in the second embodiment, the order information is represented by a weighted directed acyclic graph in which pieces of meta-information is are defined as nodes and the nodes are connected by weighted directed edges.</p><p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a graph illustrating an example of a data structure of the order information according to the second embodiment. The weighted directed acyclic graph is effective when there is a node connected to two or more nodes, such as &#x201c;numerals&#x201d; in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. Note that the first embodiment can be regarded as a special case in which all weights are set to 1 in the present embodiment.</p><p id="p-0077" num="0076">Any method may be employed as a method of determining the weight. For example, a method of statistically determining the weights on the basis of appearance frequencies of pieces of meta-information in an owned data set (learning data, recognized ledger sheet data, etc.) and a method of determining the weights on the basis of the degrees of importance of pieces of meta-information in an application can be applied.</p><p id="p-0078" num="0077">The recognition unit <b>102</b>-<b>2</b> is different from the recognition unit <b>102</b> of the first embodiment in that, an evaluation value is calculated on the basis of the weight and a confidence score to evaluate a result of the recognition by using the evaluation value. The update unit <b>103</b>-<b>2</b> is different from the update unit <b>103</b> of the first embodiment in that, the meta-information is updated using the evaluation value instead of the confidence score.</p><p id="p-0079" num="0078">Next, a recognition process by the information processing apparatus <b>100</b>-<b>2</b> according to the second embodiment configured as described above will be described with reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref>. <figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example of the recognition process according to the second embodiment.</p><p id="p-0080" num="0079">The reception unit <b>101</b> receives an image to be recognized and the meta-information (Step S<b>201</b>). The recognition unit <b>102</b>-<b>2</b> performs the character recognition on the received image and meta-information, predicts the likely character string and the confidence score of the character string, and outputs the predicted confidence score and character string (Step S<b>202</b>).</p><p id="p-0081" num="0080">In the character recognition initially performed, the weight is set to 1, and one piece of specified meta-information is used. In the second and subsequent character recognition, the number of connection destinations of the meta-information can be two or more, so that two or more pieces of specified meta-information is used in some cases. Moreover, a weight having been assigned to a directed edge connecting pieces of meta-information before and after update is set as the weight. The recognition unit <b>102</b>-<b>2</b> outputs a pair of a result of the character recognition and the confidence score, for one or more pieces of specified meta-information and the image.</p><p id="p-0082" num="0081">The recognition unit <b>102</b>-<b>2</b> selects a piece of meta-information having the best evaluation value that is calculated on the basis of the weight and the confidence score (Step S<b>203</b>). The recognition unit <b>102</b>-<b>2</b> selects a piece of meta-information according to, for example, the following procedure.</p><p id="p-0083" num="0082">The number of pieces of specified meta-information is set to M (M is an integer of 1 or more), and each piece of meta-information, weight, result of the recognition, and confidence score is expressed as m<sub>i</sub>, r<sub>i</sub>, and si (i=1, 2, . . . , and N), respectively. First, the recognition unit <b>102</b>-<b>2</b> calculates the evaluation value, for example, according to the following Formula (1), A symbol g is a predetermined function for calculating the evaluation value. The following &#x201c;g&#x201d; is an example of the function in which a product of the confidence score and the weight is treated as the evaluation value.</p><p id="p-0084" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>g</i>(<i>w</i><sub>i</sub><i>,s</i><sub>i</sub>)=<i>w&#xd7;s </i>&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0085" num="0083">Next, the recognition unit <b>102</b>-<b>2</b> selects a piece of meta-information m* having the best evaluation value, according to the following Formula (2) (Step S<b>203</b>).</p><p id="p-0086" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>m*=argmax<sub>1</sub>(g(w<sub>i</sub>,s<sub>1</sub>)) &#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0087" num="0084">The recognition unit <b>102</b>-<b>2</b> determines whether the evaluation value corresponding to the selected piece of meta-information m* is equal to or larger than a threshold (Step S<b>204</b>). When the evaluation value is equal to or larger than the threshold (Step S<b>204</b>: Yes), the recognition unit <b>102</b>-<b>2</b> outputs the predicted. character string as a result of the recognition (Step S<b>205</b>), and finishes the recognition process. When the evaluation value is not equal to or larger than the threshold (Step S<b>204</b>: No), the recognition unit <b>102</b>-<b>2</b> stores the pair of the result of the character recognition and the confidence score corresponding to the selected piece of meta-information m*, in the storage unit <b>121</b> (Step S<b>206</b>).</p><p id="p-0088" num="0085">The update unit <b>103</b>-<b>2</b> determines whether there is the connection destination for the specified piece of meta-information (meta-information used for the character recognition) (Step S<b>207</b>). When there is no connection destination for the specified piece of meta-information (Step S<b>207</b>: No), the update unit <b>103</b>-<b>2</b> outputs a result of the recognition having the best confidence score from the results of the recognition having been stored in the storage unit <b>121</b> (Step S<b>208</b>), and finishes the recognition process.</p><p id="p-0089" num="0086">When there is the connection destination for the specified piece of meta-information (Step S<b>207</b>: Yes), the update unit <b>103</b>-<b>2</b> updates the piece of meta-information in accordance with the order information (Step S<b>209</b>). For example, the update unit <b>103</b>-<b>2</b> updates the piece of meta-information to another piece of meta-information corresponding to the connection destination node defined in the order information.</p><p id="p-0090" num="0087">In the present embodiment, the update unit <b>103</b>-<b>2</b> outputs, to the recognition unit <b>102</b>-<b>2</b>, the updated piece of meta-information while associating it with the weight assigned to the directed edge before and after update. In a case where there are two or more connection destination nodes, the update unit <b>103</b>-<b>2</b> outputs pieces of meta-information corresponding to the nodes while associating those pieces of meta-information with the weights.</p><p id="p-0091" num="0088">After that, the process returns to Step S<b>202</b>, and the character recognition by the recognition unit <b>102</b>-<b>2</b> is executed again using the updated one or more pieces of meta-information.</p><p id="p-0092" num="0089">As described above, in the information processing apparatus according to the second embodiment, use of the weighted directed acyclic graph makes it possible to have more flexible design, implementing highly accurate recognition.</p><heading id="h-0010" level="1">Third Embodiment</heading><p id="p-0093" num="0090">An information processing apparatus according to a third embodiment has a function of correcting order information indicating the order of meta-information.</p><p id="p-0094" num="0091"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram illustrating an example of a configuration of an information processing apparatus <b>100</b>-<b>3</b> according to the third embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the information processing apparatus <b>100</b>-<b>3</b> includes the display unit <b>111</b>, a storage unit <b>121</b>-<b>3</b>, the reception unit <b>101</b>. the recognition unit <b>102</b>, an update unit <b>103</b>-<b>3</b>, an output control unit <b>104</b>, and a correction unit <b>105</b>-<b>3</b>.</p><p id="p-0095" num="0092">The third embodiment is different from the first embodiment in functions of the storage unit <b>121</b>-<b>3</b> and the update unit <b>103</b>-<b>3</b> and in that, the correction unit <b>105</b>-<b>3</b> is added. The other configurations and functions are similar to those of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, which illustrates a block diagram of the information processing apparatus <b>100</b> according to the first embodiment. Therefore, the other configurations and functions are denoted by the same reference numerals and description thereof will be omitted bere.</p><p id="p-0096" num="0093">The storage unit <b>121</b>-<b>3</b> is different from the storage unit <b>121</b> of the first embodiment in that, an update history showing update of the meta-information by the update unit <b>103</b>-<b>3</b> is further stored. For example, the storage unit <b>121</b>-<b>3</b> stores a history in which pieces of meta-information before and after update are associated with each other.</p><p id="p-0097" num="0094">The update unit <b>103</b>-<b>3</b> is different from the update unit <b>103</b> of the first embodiment in that, the update unit <b>103</b>-<b>3</b> has a function of storing the update history as described above, in the storage unit <b>121</b>, upon updating the meta-information,</p><p id="p-0098" num="0095">The correction unit <b>105</b>-<b>3</b> corrects at least part of the order of the pieces of meta-information, defined in the order information, on the basis of the update history of the meta-information in the past. For example, the correction unit <b>105</b>-<b>3</b> changes the direction of a directed edge in a directed acyclic graph, and corrects the order of pieces of meta.-information.</p><p id="p-0099" num="0096">Next, a correction process for the meta-information by the information processing apparatus <b>100</b>-<b>3</b> according to the third embodiment configured as described above will be described with reference to <figref idref="DRAWINGS">FIG. <b>11</b></figref>. <figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart illustrating an example of the correction process according to the third embodiment. Note that the correction process may be performed at any timing, for example, every certain period of time or every time the character recognition is performed certain number of times.</p><p id="p-0100" num="0097">The correction unit <b>105</b>-<b>3</b> identifies a piece of meta-information to be corrected with referring to the update history stored in the storage unit <b>121</b>-<b>3</b>. For example, the correction unit <b>105</b>-<b>3</b> identifies a piece of meta-information whose update count is equal to or larger than a threshold (Step S<b>301</b>). The correction unit <b>105</b>-<b>3</b> corrects a connection destination of the identified piece of meta-information in the order information (Step S<b>302</b>). For example, the correction unit <b>105</b>-<b>3</b> corrects the directed edge in the order information such that the connection destination of the identified piece of meta-information is changed to another start node connected to the same connection destination. A method for correction by the correction unit <b>105</b>-<b>3</b> is not limited to the above method, and any method may be employed.</p><p id="p-0101" num="0098">It is assumed, for example, that &#x201c;family name written in katakana characters&#x201d; is often erroneously filled in the field of &#x201c;first name written in katakana characters&#x201d; due to the influence of the design of a ledger sheet handled by the user. In this case, the update history has increased frequency of updating &#x201c;first name written in katakana characters&#x201d; to &#x201c;katakana characters&#x201d;, The correction unit <b>105</b>-<b>3</b> corrects, with referring to such update history, the directed edge such that the connection destination node of &#x201c;first name written katakana characters&#x201d; is changed to, for example, the node &#x201c;family name written in katakana characters&#x201d; that is the another start node connected to &#x201c;katakana characters&#x201d;. <figref idref="DRAWINGS">FIG. <b>12</b></figref> is a graph illustrating an example of the order information obtained by correcting the order information of <figref idref="DRAWINGS">FIG. <b>2</b></figref> in this manner.</p><p id="p-0102" num="0099">In the subsequent steps of the recognition process, the corrected order information is used. This configuration makes it possible to improve the possibility of correctly recognizing information about the family name written in katakana characters, erroneously filled.</p><p id="p-0103" num="0100">As described above, the information processing apparatus according to the third embodiment further includes the function of correcting the order information, thereby further improving the recognition accuracy.</p><heading id="h-0011" level="1">Fourth Embodiment</heading><p id="p-0104" num="0101">In the above description, the accuracy of the character recognition process using the meta-information is improved by correcting the meta-information by using the order information. A process using the order information is not limited to the recognition process, An example will be described in which an information processing apparatus according to a fourth embodiment improves the accuracy of an estimation process of estimating the meta-information by using order information.</p><p id="p-0105" num="0102">The estimation process for the meta-information is used, for example, to estimate a piece of meta-information to be set to each field in order to recognize characters from an image of a ledger sheet (character string image), on the basis of the character string image.</p><p id="p-0106" num="0103"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a block diagram illustrating an example of a configuration of an information processing apparatus <b>100</b>-<b>4</b> according to the fourth embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the information processing apparatus <b>100</b>-<b>4</b> includes the display unit <b>111</b>, the storage unit <b>121</b>, the reception unit <b>101</b>, the recognition unit <b>102</b>. an estimation unit <b>106</b>-<b>4</b>, and the output control unit <b>104</b>.</p><p id="p-0107" num="0104">The fourth embodiment is different from the first embodiment in that, the estimation unit <b>106</b>-<b>4</b> is provided instead of the update unit <b>103</b>. The other configurations and functions are similar to those of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, which illustrates a block diagram of the information processing apparatus <b>100</b> according to the first embodiment. Therefore, the other configurations and functions are denoted by the same reference numerals and description thereof will be omitted bere.</p><p id="p-0108" num="0105">The estimation unit <b>106</b>-<b>4</b> estimates the meta-information of the character string included in the image, from a result of the character recognition on the image. For example, the estimation unit <b>106</b>-<b>4</b> sequentially selects pieces of meta-information, on the basis of a specified piece of meta-information (e.g., a piece of meta-information corresponding to a top node) and the order information, and calculates confidence scores of the character recognition using the selected pieces of meta-information. The estimation unit <b>106</b>-<b>4</b> estimates the meta-information of the character string included in the image, on the basis of the calculated confidence scores. For example, the estimation unit <b>106</b>-<b>4</b> outputs, as a result of the estimation, a piece of meta-information having a better confidence score than the other pieces of meta-information,</p><p id="p-0109" num="0106">Next, the estimation process for the meta-information performed by the information processing apparatus <b>100</b>-<b>4</b> according to the fourth embodiment configured as described above will be described with reference to <figref idref="DRAWINGS">FIG. <b>14</b></figref>. <figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart illustrating an example of the estimation process according to the fourth embodiment.</p><p id="p-0110" num="0107">The reception unit <b>101</b> receives an image to be recognized (Step S<b>401</b>). The estimation unit <b>106</b>-<b>4</b> selects a piece of meta-information to be specified upon character recognition (Step S<b>402</b>). In the first character recognition, the estimation unit <b>106</b>-<b>4</b> selects, for example, one or more pieces of meta-information corresponding to the top node (node having no connection destination).</p><p id="p-0111" num="0108">The recognition unit <b>102</b> performs the character recognition on the received image and the selected pieces of meta-information, predicts a likely character string and the confidence score of the character string, and stores the predicted confidence score and character string (result of the recognition) in the storage unit <b>121</b> (Step S<b>403</b>), The recognition unit <b>102</b> selects a piece of meta-information having the best confidence score (Step S<b>404</b>).</p><p id="p-0112" num="0109">The estimation unit <b>106</b>-<b>4</b> determines whether there is a piece of meta-information that is connected to the piece of meta-information used for the character recognition (Step S<b>405</b>). For example, the estimation unit <b>106</b>-<b>4</b> makes a reference to the order information and searches for a piece of meta-information corresponding to a connection source node that has a connection destination being the piece of meta-information used for the character recognition. When there is the connection source node, the estimation unit <b>106</b>-<b>4</b> determines that there is the piece of meta-information that is connected to the piece of meta-information used for the character recognition. When the piece of meta-information used for the character recognition is a bottom node, the estimation unit <b>106</b>-<b>4</b> determines that there is no piece of meta-information that is connected to the piece of meta-information used for the character recognition.</p><p id="p-0113" num="0110">When there is no piece of meta-information that is connected to the piece of meta-information used for the character recognition (Step S<b>405</b>: No), the estimation unit <b>106</b>-<b>4</b> outputs, as the result of the estimation, a piece of meta-information for which a result of the recognition having the best confidence score is obtained, from the results of recognition having been stored in the storage unit <b>121</b> (Step S<b>407</b>), and finishes the estimation process. The estimation unit <b>106</b>-<b>4</b> may output the confidence score and the result of the recognition, together with the piece of meta-information that is the result of the estimation.</p><p id="p-0114" num="0111">When there is the connection destination (Step S<b>405</b>: Yes), the estimation unit <b>106</b>-<b>4</b> updates the piece of meta-information in accordance with the order information (Step S<b>406</b>). For example, the estimation unit <b>106</b>-<b>4</b> updates the selected piece of meta-information to the piece of meta-information corresponding to the connection source node that is defined in the order information. In the order information as illustrated in <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>, a piece of meta-information is updated to another piece of meta-information belonging to a smaller set.</p><p id="p-0115" num="0112">After that, the process returns to Step S<b>403</b>, and the character recognition is performed again by the recognition unit <b>102</b> by using the updated meta-information.</p><p id="p-0116" num="0113">A specific example of the estimation process will be described below. It is assumed that the order information as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is defined and the image to be recognized is the character string image including the character string &#x201c;MAIKERU&#x201d; (corresponding to &#x201c;Michael&#x201d; in the English language). First, the estimation unit <b>106</b>-<b>4</b> inputs, as the meta-information, &#x201c;unspecified&#x201d; to the recognition unit <b>102</b>. At this time, it is assumed that the confidence score is &#x201c;0.6&#x201d;.</p><p id="p-0117" num="0114">Next, the estimation unit <b>106</b>-<b>4</b> inputs, as the meta-information, &#x201c;address&#x201d;, &#x201c;alphanumeric characters and symbols&#x201d;, and &#x201c;katakana characters&#x201d; that are connected to &#x201c;unspecified&#x201d;, to the recognition unit <b>102</b>. At this time, it is assumed that the confidence scores are &#x201c;0.5&#x201d;, &#x201c;0.1&#x201d;, and &#x201c;0.8&#x201d;, respectively.</p><p id="p-0118" num="0115">In this case, the estimation unit <b>106</b>-<b>4</b> inputs, as the meta-information, &#x201c;family name written in katakana Characters&#x201d; and &#x201c;first name written in katakana characters&#x201d; that are connected to &#x201c;katakana characters&#x201d; having the best confidence score, to the recognition unit <b>102</b>. At this time, it is assumed that the confidence scores are &#x201c;0.6&#x201d; and &#x201c;0.3&#x201d;, respectively.</p><p id="p-0119" num="0116">There is no node connected to &#x201c;family name written in katakana characters&#x201d; or &#x201c;first name written in katakana characters&#x201d;. Thus, the estimation unit <b>106</b>-<b>4</b> outputs &#x201c;katakana characters&#x201d; having the best confidence score &#x201c;0.8&#x201d;, as the result of the estimation of the meta-information.</p><p id="p-0120" num="0117">The estimation process as described above may be performed for a single character string image or may be performed for plural character string images. For example, in a case where the meta-information is estimated from the plural character string images assumed to have the same meta-information, the above-described estimation process can be applied.</p><p id="p-0121" num="0118">For example, the estimation unit <b>106</b>-<b>4</b> performs processing similar to that performed upon inputting the single character string image, for all character string images. and outputs a mode value of the output meta-information, as the result of the estimation. The best evaluation of the result of the estimation is not limited to this method. For example, the estimation unit <b>106</b>-<b>4</b> may output, as the result of the estimation, meta-information having the best evaluation value in weighted voting with the confidence score as a weight. Majority voting using the results of the recognition on the plural character string images makes it possible to perform more highly accurate estimation of the meta.-information.</p><heading id="h-0012" level="1">Third Modification</heading><p id="p-0122" num="0119">As in the first modification of the first embodiment, the number of pieces of order information indicating the meta-information is not limited to one, and may be N or more (N is an integer of 2 or more). The estimation unit <b>106</b>-<b>4</b> selects pieces of meta-information sequentially from the top node, for each of the N pieces of order information, and inputs the selected pieces of meta-information to the recognition unit <b>102</b>. The estimation unit <b>1</b>.<b>06</b>-<b>4</b> estimates the meta-information having the best confidence score for each of the N pieces of order information, and outputs the meta information.</p><p id="p-0123" num="0120">In this way, in the information processing apparatus according to the fourth embodiment, a likely meta-information (node) is preferentially searched for in the order in accordance with the order information, such as a directed acyclic graph, and therefore, the estimation process for the meta-information can be implemented more efficiently.</p><p id="p-0124" num="0121">As described above, according to the first to fourth embodiments, the recognition accuracy of the character recognition process using the meta-information or the efficiency of the estimation process for the meta-information can be improved.</p><p id="p-0125" num="0122">Next, the information processing apparatus according to the first to fourth embodiments have a hardware configuration, and the hardware configuration will be described with reference to <figref idref="DRAWINGS">FIG. <b>15</b></figref>. <figref idref="DRAWINGS">FIG. <b>15</b></figref> is an explanatory diagram illustrating a hardware configuration example of each of the information processing apparatuses according to the first to fourth embodiments.</p><p id="p-0126" num="0123">The information processing apparatuses according to the first to fourth embodiments each includes a control device such as a central processing unit (CPU) <b>51</b>, a storage device such as a read only memory (ROM) <b>52</b> and a random access memory (RAM) <b>53</b>, a communication I/F <b>54</b> that is connected to a network to perform communication, and a bus <b>61</b> that connects the units.</p><p id="p-0127" num="0124">A computer program executed by each of the information processing apparatuses according to the first to fourth embodiments may be provided by being incorporated in the ROM <b>52</b> or the like in advance.</p><p id="p-0128" num="0125">A computer program executed by each of the information processing apparatuses according to the first to fourth embodiments may be configured to be provided as a computer program product, in the form of installable or executable file data and recorded on a computer-readable recording medium, such as a compact disk read only memory (CD-ROM), flexible disk (FD), compact disk recordable (CD-R), digital versatile disk (DVD).</p><p id="p-0129" num="0126">Moreover, a computer program executed by each of the information processing apparatuses according to the first to fourth embodiments may be configured to be stored on a computer connected to a network such as the Internet and provided by being downloaded via the network. Moreover, a computer program executed by each of the information processing apparatuses according to the first to fourth embodiments may be configured to be provided or distributed via a network such as the Internet.</p><p id="p-0130" num="0127">A computer program executed by each of the information processing apparatuses according to the first to fourth embodiments can cause a computer to function as the units of each information processing apparatus described above. In the computer, the CPU <b>51</b> is configured to read a computer program from a computer-readable storage medium into a main storage device and execute the program.</p><p id="p-0131" num="0128">While certain embodiments have been described, these embodiments have been presented by way of example only, and are not intended to limit the scope of the inventions. Indeed, the novel embodiments described herein may be embodied in a variety of other forms; moreover, various omissions, substitutions and changes in the form of the embodiments described herein may be made without departing from the spirit of the inventions. The accompanying claims and their equivalents are intended to cover such forms or modifications as would fall within the scope and spirit of the inventions.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An information processing apparatus comprising:<claim-text>a memory configured to store order information in which an order of pieces of meta-information for a character to be recognized is defined;</claim-text><claim-text>one or more hardware processors connected to the memory and configured to function as<claim-text>a recognition unit to perform character recognition on an image including a character string by using first meta-information specified from the pieces of the meta-information, and</claim-text><claim-text>an update unit to update the first meta-information to second meta-information in accordance with the order information in a case when a confidence score of the character recognition satisfies a predetermined condition,</claim-text></claim-text><claim-text>wherein the recognition unit performs the character recognition by using the second meta-information.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the order information is represented by a directed acyclic graph in which the pieces of the meta-information are defined as nodes and the nodes are connected by directed edges, and</claim-text><claim-text>the update unit updates the first meta-information to the second meta-information connected to the first meta-information by a corresponding directed edge.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>. wherein the recognition unit performs the character recognition by using a neural network into which the first meta-information and the image are input and from which a result of the recognition is output.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the memory is configured to store N pieces of order information (N is an integer of 2 or more), and<claim-text>the recognition unit performs the character recognition by using N pieces of first meta-information specified from N pieces of meta-information defined in the N pieces of the order information.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the order information is represented by a directed acyclic graph in which the pieces of the meta-information are defined as nodes and the nodes are connected by directed edges with weights, and</claim-text><claim-text>the update unit updates the first meta-information to second meta-information, on the basis of evaluation values obtained from the weights and the confidence scores.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the recognition unit performs the character recognition by using first meta-information specified from the pieces of the meta-information to which their respective weights are assigned, and</claim-text><claim-text>the update unit updates the first meta-information to the second meta-information in accordance with the order information in a case when an evaluation value obtained from the weight and the confidence score satisfies a predetermined condition.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more hardware processors are further configured to function as a correction unit to correct at least part of the order of the pieces of meta-information defined in the order information, on the basis of an update history showing update by the update unit.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more hardware processors are further configured to function as an output control unit to display the meta-information on a display device in accordance with the order defined in the order information.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. An information processing method comprising:<claim-text>performing character recognition on an image including a character string by using first meta-information specified from pieces of meta-information for a character to be recognized: and</claim-text><claim-text>updating the first meta-information to second meta-information in accordance with order information in which an order of the pieces of the meta-information is defined, the updating of the first meta-information being performed in a case when a confidence score of the character recognition satisfies a predetermined condition,</claim-text><claim-text>wherein the character recognition is performed by using the second meta-information.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A computer program product comprising a non-transitory computer-readable recording medium on which a program executable by a computer is recorded, the program instructing the computer to:<claim-text>perform character recognition on an image including a character string by using first meta-information specified from pieces of meta-information for a character to be recognized; and</claim-text><claim-text>update the first meta-information to second meta-information in accordance with order information in which an order of the pieces of the meta-information is defined, the update of the first meta-information being performed in a case when a confidence score of the character recognition satisfies a predetermined condition,</claim-text><claim-text>wherein the character recognition is performed by using the second meta-information.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. An information processing apparatus comprising:<claim-text>a memory configured to store order information in which an order of pieces of meta-information for a character to be recognized is defined;</claim-text><claim-text>one or more hardware processors connected to the memory and configured to function as<claim-text>a recognition unit to perform character recognition on an image including a character string by using first meta-information specified from the pieces of the meta-information and one or more pieces of second meta-information selected on the basis of the order information and the first meta-information, and</claim-text><claim-text>an estimation unit to estimate meta-information of the character string included in the image on the basis of a confidence score of the character recognition on the first meta-information and a confidence score of the character recognition on the second meta-information.</claim-text></claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The information processing apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the estimation unit estimates, as the meta-information of the character string included in the image, meta-information corresponding to the better confidence score than the other confidence score out of: the confidence score of the character recognition on the first meta-information, and the confidence score of the character recognition on the second meta-information.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The information processing apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the recognition unit performs the character recognition by using a neural network into which the meta-information and the image are input and from which a result of the recognition is output.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The information processing apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein<claim-text>the memory is configured to store N pieces of order information (N is an integer of 2 or more), and</claim-text><claim-text>the recognition unit performs the character recognition by using N pieces of first meta-information specified from N pieces of meta-information defined in the N pieces of the order information.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. An information processing method comprising:<claim-text>performing character recognition on an image including a character string by using first meta-information specified from pieces of meta-information for a character to be recognized and one or more pieces of second meta-information selected on the basis of order information in which an order of the pieces of the meta-information is defined and the first meta-information; and</claim-text><claim-text>estimating meta-information of the character string included in the image on the basis of a confidence score of the character recognition on the first meta-information and a confidence score of the character recognition on the second meta-information.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A computer program product comprising a non-transitory computer-readable recording medium on which a program executable by a computer is recorded, the program instructing the computer to:<claim-text>perform character recognition on an image including a character string by using first meta-information specified from pieces of meta-information for a character to be recognized and one or more pieces of second meta-information selected on the basis of order information in which an order of the pieces of the meta-information is defined and the first meta-information: and</claim-text><claim-text>estimate meta-information of the character string included in the image on the basis of a confidence score of the character recognition on the first meta-information and a confidence score of the character recognition on the second meta-information.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. A non-transitory computer-readable recording medium on which order information is recorded, wherein<claim-text>the order information is used for character recognition performed by an information processing apparatus including a hardware circuit and a memory,</claim-text><claim-text>the order information is stored in the memory, and</claim-text><claim-text>the order information is represented by a directed acyclic graph in which pieces of meta-information for a character to be recognized are defined as nodes and the nodes are connected by directed edges.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The order information according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the character recognition is performed on an image including a character string by the hardware circuit by using first meta-information specified from the pieces of the meta-information.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The order information according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the first meta-information is updated, by the hardware circuit, to second meta-information connected to the first meta-information by a corresponding directed edge in accordance with the order information, the first meta-information being updated in a case when a confidence score of the character recognition satisfies a predetermined condition.</claim-text></claim></claims></us-patent-application>
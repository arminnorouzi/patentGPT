<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004861A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004861</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17366773</doc-number><date>20210702</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>248</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>245</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>248</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>245</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEM FOR TIME BASED MONITORING AND IMPROVED INTEGRITY OF MACHINE LEARNING MODEL INPUT DATA</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>BANK OF AMERICA CORPORATION</orgname><address><city>Charlotte</city><state>NC</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Murray</last-name><first-name>Matthew Bruce</first-name><address><city>Roanoke</city><state>TX</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>BANK OF AMERICA CORPORATION</orgname><role>02</role><address><city>Charlotte</city><state>NC</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Embodiments of the invention are directed to systems, methods, and computer program products for providing intelligent system and methods for identifying and weighting volatile data in machine learning data sets. The system is adaptive, in that it can be adjusted based on the needs or goals of the user utilizing it, or may intelligently and proactively adapt based on the data set or machine learning model being employed. The system may be seamlessly embedded within existing applications or programs that the user may already use to interact with one or more entities, particularly those which aid in the managing of user resources.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="133.69mm" wi="158.75mm" file="US20230004861A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="186.18mm" wi="162.05mm" orientation="landscape" file="US20230004861A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="184.57mm" wi="156.21mm" file="US20230004861A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="197.19mm" wi="129.62mm" file="US20230004861A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="194.39mm" wi="128.44mm" orientation="landscape" file="US20230004861A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">With the usage of machine learning and artificial intelligence becoming more prevalent, the there is a need for systems and methods to analyze how data sets used to train various models may be affected by volatility in continuously updated data streams. Identifying and accounting for volatility in changing data sets can lead to more accurate machine learning modeling techniques.</p><heading id="h-0002" level="1">BRIEF SUMMARY</heading><p id="p-0003" num="0002">The following presents a simplified summary of one or more embodiments of the invention in order to provide a basic understanding of such embodiments. This summary is not an extensive overview of all contemplated embodiments, and is intended to neither identify key or critical elements of all embodiments, nor delineate the scope of any or all embodiments. Its sole purpose is to present some concepts of one or more embodiments in a simplified form as a prelude to the more detailed description that is presented later.</p><p id="p-0004" num="0003">The systems and methods described herein address the above needs by providing intelligent system and methods for identifying and weighting volatile data in machine learning data sets. The system is adaptive, in that it can be adjusted based on the needs or goals of the user utilizing it, or may intelligently and proactively adapt based on the data set or machine learning model being employed. The system may be seamlessly embedded within existing applications or programs that the user may already use to interact with one or more entities, particularly those which aid in the managing of user resources. For instance, the system may be adjusted to analyze transactions, deposits, withdrawals, or the like, in order to identify trends and patterns. The system may utilize this information in order to intelligently generate system output and create a more efficient project flow.</p><p id="p-0005" num="0004">The invention utilizes a process for machine learning volatility detection by continuously analyzing model output data to identify shifts. By analyzing and identifying how changing data over time affects the output of machine learning models, the system is able to project and account for data fluctuations in the future, essentially anticipating and proactively adapting for variable data input to improve the integrity and accuracy of machine learning models. This system identifies volatile data, and may apply one or more weighting factors to the data input to one or more machine learning models in order to discern effects on model output. The system begins with identification of volatility within a model. The system then assigns weighting to features and data. The system then compares the resultant output and discerns how often the output changes during a particular event or over a period of time. The system then assigns a weighted value to one or more data features as a predictor of future events. Once the system has identified volatility within a model, the system may employ a dampening application that makes volatile input data less significant as time goes on. In some embodiments, the system applies less weight to older data. As such, there are two key aspects to this invention: a machine learning volatility measuring component, and a dampening application to apply to the data within one or more models.</p><p id="p-0006" num="0005">Embodiments of the invention relate to systems, methods, and computer program products for dynamic feedback on resource usage, the system generally comprising the following steps: receive one or more data sets for machine learning model analysis; parse the one or more data sets and identify one or more features based on meta data of the one or more data sets; transmit the one or more data sets to a machine learning model; continuously monitor machine learning model analysis output; identify a shift in the machine learning model analysis output; correlate features of the one or more data sets with the identified shift in the machine learning model analysis output to identify one or more volatile features in the one or more data sets; and apply a weighting to the one or more volatile features in the one or more data sets to offset the shift in the machine learning model analysis output.</p><p id="p-0007" num="0006">In some embodiments, the one or more data sets comprises a continuous stream of data.</p><p id="p-0008" num="0007">In some embodiments, the one or more data sets comprises resource transaction information and meta data.</p><p id="p-0009" num="0008">In other embodiments, the machine learning model further comprises a predictive machine learning model or pattern recognition machine learning model.</p><p id="p-0010" num="0009">In further embodiments, the weighting further comprises a dampening variable lessening effect of the one or more volatile features on the machine learning model analysis output.</p><p id="p-0011" num="0010">In some embodiments, the weighting is applied dynamically to lessen effect of older data on the machine learning model analysis output over time.</p><p id="p-0012" num="0011">In still further embodiments, the invention is further configured to generate a prediction based on the one or more volatile features, wherein the prediction comprises an expected effect of the one or more volatile features on future machine learning model analysis output.</p><p id="p-0013" num="0012">The features, functions, and advantages that have been discussed may be achieved independently in various embodiments of the present invention or may be combined with yet other embodiments, further details of which can be seen with reference to the following description and drawings.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0014" num="0013">Having thus described embodiments of the invention in general terms, reference will now be made to the accompanying drawings, wherein:</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an operating environment for the model feedback system, in accordance with one embodiment of the present disclosure;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating components of the model feedback system, in accordance with one embodiment of the present disclosure;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating a user device associated with the model feedback system, in accordance with one embodiment of the present disclosure; and</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flow diagram illustrating a model feedback loop, in accordance with one embodiment of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION OF EMBODIMENTS OF THE INVENTION</heading><p id="p-0019" num="0018">Embodiments of the present invention will now be described more fully hereinafter with reference to the accompanying drawings, in which some, but not all, embodiments of the invention are shown. Indeed, the invention may be embodied in many different forms and should not be construed as limited to the embodiments set forth herein; rather, these embodiments are provided so that this disclosure will satisfy applicable legal requirements. Like numbers refer to elements throughout. Where possible, any terms expressed in the singular form herein are meant to also include the plural form and vice versa, unless explicitly stated otherwise. Also, as used herein, the term &#x201c;a&#x201d; and/or &#x201c;an&#x201d; shall mean &#x201c;one or more,&#x201d; even though the phrase &#x201c;one or more&#x201d; is also used herein.</p><p id="p-0020" num="0019">&#x201c;Entity&#x201d; or &#x201c;managing entity&#x201d; as used herein may refer to any organization, entity, or the like in the business of moving, investing, or lending money, dealing in financial instruments, or providing financial services. This may include commercial banks, thrifts, federal and state savings banks, savings and loan associations, credit unions, investment companies, insurance companies and the like. In some embodiments, the entity may allow a user to establish an account with the entity. An &#x201c;account&#x201d; may be the relationship that the user has with the entity. Examples of accounts include a deposit account, such as a transactional account (e.g., a banking account), a savings account, an investment account, a money market account, a time deposit, a demand deposit, a pre-paid account, a credit account, or the like. The account is associated with and/or maintained by the entity. In other embodiments, an entity may not be a financial institution. In still other embodiments, the entity may be the merchant itself</p><p id="p-0021" num="0020">&#x201c;Entity system&#x201d; or &#x201c;managing entity system&#x201d; as used herein may refer to the computing systems, devices, software, applications, communications hardware, and/or other resources used by the entity to perform the functions as described herein. Accordingly, the entity system may comprise desktop computers, laptop computers, servers, Internet-of-Things (&#x201c;IoT&#x201d;) devices, networked terminals, mobile smartphones, smart devices (e.g., smart watches), network connections, and/or other types of computing systems or devices and/or peripherals along with their associated applications.</p><p id="p-0022" num="0021">&#x201c;User&#x201d; as used herein may refer to an individual associated with an entity. As such, in some embodiments, the user may be an individual having past relationships, current relationships or potential future relationships with an entity. In some instances, a &#x201c;user&#x201d; is an individual who has a relationship with the entity, such as a customer or a prospective customer. Accordingly, as used herein the term &#x201c;user device&#x201d; or &#x201c;mobile device&#x201d; may refer to mobile phones, personal computing devices, tablet computers, wearable devices, and/or any portable electronic device capable of receiving and/or storing data therein and are owned, operated, or managed by a user.</p><p id="p-0023" num="0022">&#x201c;Transaction&#x201d; or &#x201c;resource transfer&#x201d; as used herein may refer to any communication between a user and a third party merchant or individual to transfer funds for purchasing or selling of a product. A transaction may refer to a purchase of goods or services, a return of goods or services, a payment transaction, a credit transaction, or other interaction involving a user's account. In the context of a financial institution, a transaction may refer to one or more of: a sale of goods and/or services, initiating an automated teller machine (ATM) or online banking session, an account balance inquiry, a rewards transfer, an account money transfer or withdrawal, opening a bank application on a user's computer or mobile device, a user accessing their e-wallet, or any other interaction involving the user and/or the user's device that is detectable by the financial institution. A transaction may include one or more of the following: renting, selling, and/or leasing goods and/or services (e.g., groceries, stamps, tickets, DVDs, vending machine items, and the like); making payments to creditors (e.g., paying monthly bills; paying federal, state, and/or local taxes; and the like); sending remittances; loading money onto stored value cards (SVCs) and/or prepaid cards; donating to charities; and/or the like.</p><p id="p-0024" num="0023">The system allows for use of a machine learning engine to intelligently identify patterns in received resource transaction data. The machine learning engine may be used to analyze historical data in comparison to real-time received transaction data in order to identify transaction patterns or potential issues. The machine learning engine may also be used to generate intelligent aggregation of similar data based on metadata comparison resource transaction characteristics, which in some cases may be used to generate a database visualization of identified patterns similarities.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an operating environment for decisioning resource usage based on real time feedback, in accordance with one embodiment of the present disclosure. As illustrated, the operating environment <b>100</b> may comprise a user <b>102</b> and/or a user device <b>104</b> in operative communication with one or more third party systems <b>400</b> (e.g., web site hosts, registry systems, financial entities, third party entity systems, or the like). The operative communication may occur via a network <b>101</b> as depicted, or the user <b>102</b> may be physically present at a location separate from the various systems described, utilizing the systems remotely. The operating environment also includes a managing entity system <b>500</b>, model feedback system <b>200</b>, a database <b>300</b>, and/or other systems/devices not illustrated herein and connected via a network <b>101</b>. As such, the user <b>102</b> may request information from or utilize the services of the model feedback system <b>200</b>, or the third party system <b>400</b> by establishing operative communication channels between the user device <b>104</b>, the managing entity system <b>500</b>, and the third party system <b>400</b> via a network <b>101</b>.</p><p id="p-0026" num="0025">Typically, the model feedback system <b>200</b> and the database <b>300</b> are in operative communication with the managing entity system <b>500</b>, via the network <b>101</b>, which may be the internet, an intranet or the like. In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the network <b>101</b> may include a local area network (LAN), a wide area network (WAN), a global area network (GAN), and/or near field communication (NFC) network. The network <b>101</b> may provide for wireline, wireless, or a combination of wireline and wireless communication between devices in the network. In some embodiments, the network <b>101</b> includes the Internet. In some embodiments, the network <b>101</b> may include a wireless telephone network. Furthermore, the network <b>101</b> may comprise wireless communication networks to establish wireless communication channels such as a contactless communication channel and a near field communication (NFC) channel (for example, in the instances where communication channels are established between the user device <b>104</b> and the third party system <b>400</b>). In this regard, the wireless communication channel may further comprise near field communication (NFC), communication via radio waves, communication through the internet, communication via electromagnetic waves and the like.</p><p id="p-0027" num="0026">The user device <b>104</b> may comprise a mobile communication device, such as a cellular telecommunications device (e.g., a smart phone or mobile phone, or the like), a computing device such as a laptop computer, a personal digital assistant (PDA), a mobile internet accessing device, or other mobile device including, but not limited to portable digital assistants (PDAs), pagers, mobile televisions, gaming devices, laptop computers, cameras, video recorders, audio/video player, radio, GPS devices, any combination of the aforementioned, or the like. The user device is described in greater detail with respect to <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0028" num="0027">The managing entity system <b>500</b> may comprise a communication module and memory not illustrated, and may be configured to establish operative communication channels with a third party system <b>400</b> and/or a user device <b>104</b> via a network <b>101</b>. The managing entity may comprise a data repository <b>256</b>. The data repository <b>256</b> may contain resource account data, and may also contain user data. This user data may be used by the managing entity to authorize or validate the identity of the user <b>102</b> for accessing the system (e.g., via a username, password, biometric security mechanism, two-factor authentication mechanism, or the like). In some embodiments, the managing entity system is in operative communication with the model feedback system <b>200</b> and database <b>300</b> via a private communication channel. The private communication channel may be via a network <b>101</b> or the model feedback system <b>200</b> and database <b>300</b> may be fully integrated within the managing entity system <b>500</b>, such as a virtual private network (VPN), or over a secure socket layer (SSL).</p><p id="p-0029" num="0028">The managing entity system <b>500</b> may communicate with the model feedback system <b>200</b> in order to transmit data associated with observed resource transaction or account data by or via a plurality of third party systems <b>400</b>. In some embodiments, the managing entity system <b>500</b> may utilize the features and functions of the model feedback system <b>200</b> to initialize advisory measures in response to identifying user interests or needs. In other embodiments, the managing entity and/or the one or more third party systems <b>400</b> may utilize the intelligent information sharing system to react to identified trends, patterns, or potential issues.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a block diagram of the model feedback system <b>200</b> associated with the operating environment <b>100</b>, in accordance with embodiments of the present invention. As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the model feedback system <b>200</b> may include a communication device <b>244</b>, a processing device <b>242</b>, and a memory device <b>250</b> having a pattern recognition module <b>253</b>, a processing system application <b>254</b> and a processing system datastore <b>255</b> stored therein. As shown, the processing device <b>242</b> is operatively connected to and is configured to control and cause the communication device <b>244</b>, and the memory device <b>250</b> to perform one or more functions. In some embodiments, the pattern recognition module <b>253</b> and/or the processing system application <b>254</b> comprises computer readable instructions that when executed by the processing device <b>242</b> cause the processing device <b>242</b> to perform one or more functions and/or transmit control instructions to the database <b>300</b>, the managing entity system <b>500</b>, or the communication device <b>244</b>. It will be understood that the pattern recognition module <b>253</b> or the processing system application <b>254</b> may be executable to initiate, perform, complete, and/or facilitate one or more portions of any embodiments described and/or contemplated herein. The pattern recognition module <b>253</b> may comprise executable instructions associated with data processing and analysis and may be embodied within the processing system application <b>254</b> in some instances. The model feedback system <b>200</b> may be owned by, operated by and/or affiliated with the same managing entity that owns or operates the managing entity system <b>500</b>. In some embodiments, the model feedback system <b>200</b> is fully integrated within the managing entity system <b>500</b>.</p><p id="p-0031" num="0030">The pattern recognition module <b>253</b> may further comprise a data analysis module <b>260</b>, a machine learning engine <b>261</b>, and a machine learning dataset(s) <b>262</b>. The data analysis module <b>260</b> may store instructions and/or data that may cause or enable the model feedback system <b>200</b> to receive, store, and/or analyze data received by the managing entity system <b>500</b> or the database <b>300</b>, as well as generate information and transmit responsive data to the managing entity system <b>500</b> in response to one or more requests or via a real-time data stream between the model feedback system <b>200</b> and the managing entity system <b>500</b>. The data analysis module may pre-process data before it is fed to the machine learning engine <b>261</b>. In this way, the model feedback system <b>200</b> may exercise control over relevance or weighting of certain data features, which in some embodiments may be determined based on a meta-data analysis of machine learning engine <b>261</b> output over time as time-dependent data is changed.</p><p id="p-0032" num="0031">For instance, in some embodiments, the data analysis module may receive a number of data files containing metadata which identifies the files as originating from a specific source, being created at a specific time, day, or the like, and may package this data to be analyzed by the machine learning engine <b>261</b>, as well as store the files in a catalog of data files in the data repository <b>256</b> or database <b>300</b> (e.g., files may be catalogued according to any metadata characteristic, including descriptive characteristics such as source, identity, time since creation, or the like, or including data characteristics such as file type, size, encryption type, or the like). The machine learning engine <b>261</b> and machine learning dataset(s) <b>262</b> may store instructions and/or data that cause or enable the model feedback system <b>200</b> to generate, in real-time and based on received information, new output in the form of prediction, current status, analysis, or the like of one or more transactions or transaction patterns. In some embodiments, the machine learning engine <b>261</b> and machine learning dataset(s) <b>262</b> may store instructions and/or data that cause or enable the model feedback system <b>200</b> to determine, in real-time and based on received information, recommended resource actions or prophylactic actions to be taken to benefit one or more specific users or systems.</p><p id="p-0033" num="0032">The machine learning dataset(s) <b>262</b> may contain data queried from database <b>300</b> or may be extracted or received from third party systems <b>400</b>, managing entity system <b>500</b>, or the like, via network <b>101</b>. The database <b>300</b> may also contain metadata, which may be generated at the time of data creation, onboarding to the managing entity system <b>500</b> or model feedback system <b>200</b>, or in some cases may be generated specifically by the data analysis module <b>260</b>. In some cases, the metadata may include statistics regarding each column of features in a dataset, which may be stored in a separate tabular dataset and tracked over a certain temporal period, such as a day, month, multi-month period, or the like, in order to provide the capability for meta-analysis on how data features affect modeling over time.</p><p id="p-0034" num="0033">In some embodiments, the machine learning dataset(s) <b>262</b> may also contain data relating to user activity or device information, which may be stored in a user account managed by the managing entity system. In some embodiments, the machine learning engine <b>261</b> may be a single-layer recurrent neural network (RNN) which utilizes sequential models to achieve results in audio and textual domains. Additionally, the machine learning engine <b>261</b> may serve an alternate or dual purpose of analyzing user resource account history, user preferences, user interests, or other user submitted or gathered data from managing entity system <b>500</b>, third party system <b>400</b>, or the like, in order to generate or locate intelligent recommendations or discoveries within datasets. For instance, the machine learning engine may consist of a multilayer perceptron neural network, recurrent neural network, or a modular neural network designed to process input variables related to one or more user characteristics and output recommendations or predictions. Given the nature of the managing entity system <b>500</b>, particularly in embodiments where the managing entity system <b>500</b> is a financial institution, the machine learning engine <b>261</b> may have a large dataset of user account information, resource transaction information, account resource amount information, or the like, from which to draw from and discern specific patterns or correlations related to resource spending, saving, or the like which may be beneficial or of interest to particular users. It is understood that such data may be anonymized or completely stripped of identifying characteristics in preferred embodiments with no negative impact the system's ability to generate accurate output or prediction data given certain variables. For instance, users with a resource deposit amount of X, and a resource outflow amount of Y, and whose transaction histories indicate an interest in product category Z, may be interested in a particular product, service, or the like offered by the managing entity system <b>500</b> (e.g., a user who has a certain amount of disposable resources who is known to have purchased home-improvement products in the preceding weeks or months may be interested in a specialized line of home equity credit, an additional specialized savings account, or the like).</p><p id="p-0035" num="0034">These intelligently generated recommendations may be related to products or services offered by one or more entities, while in other embodiments may be generally directed to beneficial tips or advice on increasing resource savings, resource inflow, or the like (e.g., a user which has a newly established resource savings account may be interested in saving a certain percentage of resource inflow per month, as recognized and recommended by the machine learning engine <b>261</b>). In this way, the system may analyze user activity and resources on a per-user basis, accurately forecast beneficial suggestions or recommendations relevant to the user based on a larger dataset of numerous users, and automatically generate tailored recommendations for specific users. Recommendations or advice may also be generated in response to an explicit question received from one or more users in real-time.</p><p id="p-0036" num="0035">In further embodiments, the machine learning engine <b>261</b> may have a large dataset of user account information, resource transaction information, account resource amount information, account access information, user authorization information, situational data, or the like, from which to draw from and discern specific patterns or correlations related to account security, system security, or the like. For instance, the machine learning engine <b>261</b> may be trained on a large dataset of confirmed malfeasant transactions or transaction attempts in order to identity relevant patterns and characteristics associated with certain users, communication channels, transactions themselves (e.g., frequency, resource amount, certain resource accounts, entities, or the like), which may be correlated with a probability of potential resource loss. In these situations, responsive measures taken to further investigate transactions or communications with a high degree of probability for malfeasance may be key in reducing potential resource loss. As such, it is imperative that the machine learning engine <b>261</b> operate in an accurate and predictable manner, and the model must have the capability to dynamically adapt over time in response to changing data characteristics. However, if one feature set of the incoming data stream is skewing the output of the machine learning engine <b>261</b>, it is necessary for the system to discern if the skew is natural or otherwise perhaps an intentionally levied method against the system in order to train the model to react to patterns or characteristics in a certain way. This is where the analysis of metadata in conjunction with machine learning output in order to identify feature sets which have the highest degree of impact on machine learning output over time may be most crucial.</p><p id="p-0037" num="0036">The machine learning engine <b>261</b> may receive data from a plurality of sources and, using one or more machine learning algorithms, may generate one or more machine learning datasets <b>262</b>. Various machine learning algorithms may be used without departing from the invention, such as supervised learning algorithms, unsupervised learning algorithms, regression algorithms (e.g., linear regression, logistic regression, and the like), instance based algorithms (e.g., learning vector quantization, locally weighted learning, and the like), regularization algorithms (e.g., ridge regression, least-angle regression, and the like), decision tree algorithms, Bayesian algorithms, clustering algorithms, artificial neural network algorithms, and the like. It is understood that additional or alternative machine learning algorithms may be used without departing from the invention.</p><p id="p-0038" num="0037">The communication device <b>244</b> may generally include a modem, server, transceiver, and/or other devices for communicating with other devices on the network <b>101</b>. The communication device <b>244</b> may be a communication interface having one or more communication devices configured to communicate with one or more other devices on the network <b>101</b>, such as the model feedback system <b>200</b>, the user device <b>104</b>, other processing systems, data systems, etc. Additionally, the processing device <b>242</b> may generally refer to a device or combination of devices having circuitry used for implementing the communication and/or logic functions of the model feedback system <b>200</b>. For example, the processing device <b>242</b> may include a control unit, a digital signal processor device, a microprocessor device, and various analog-to-digital converters, digital-to-analog converters, and other support circuits and/or combinations of the foregoing. Control and signal processing functions of the model feedback system <b>200</b> may be allocated between these processing devices according to their respective capabilities. The processing device <b>242</b> may further include functionality to operate one or more software programs based on computer-executable program code <b>252</b> thereof, which may be stored in a memory device <b>250</b>, such as the processing system application <b>254</b> and the pattern recognition module <b>253</b>. As the phrase is used herein, a processing device may be &#x201c;configured to&#x201d; perform a certain function in a variety of ways, including, for example, by having one or more general-purpose circuits perform the function by executing particular computer-executable program code embodied in computer-readable medium, and/or by having one or more application-specific circuits perform the function. The processing device <b>242</b> may be configured to use the network communication interface of the communication device <b>244</b> to transmit and/or receive data and/or commands to and/or from the other devices/systems connected to the network <b>101</b>.</p><p id="p-0039" num="0038">The memory device <b>250</b> within the model feedback system <b>200</b> may generally refer to a device or combination of devices that store one or more forms of computer-readable media for storing data and/or computer-executable program code/instructions. For example, the memory device <b>250</b> may include any computer memory that provides an actual or virtual space to temporarily or permanently store data and/or commands provided to the processing device <b>242</b> when it carries out its functions described herein.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating a user device associated with the model feedback system, in accordance with one embodiment of the present disclosure. The user device <b>104</b> may include a user mobile device, desktop computer, laptop computer, or the like. A &#x201c;mobile device&#x201d; <b>104</b> may be any mobile communication device, such as a cellular telecommunications device (i.e., a cell phone or mobile phone), personal digital assistant (PDA), a mobile Internet accessing device, or another mobile device including, but not limited to portable digital assistants (PDAs), pagers, mobile televisions, gaming devices, laptop computers, cameras, video recorders, audio/video player, radio, GPS devices, any combination of the aforementioned devices. The user device <b>104</b> may generally include a processing device or processor <b>310</b> communicably coupled to devices such as, a memory device <b>350</b>, user output devices <b>340</b> (for example, a user display or a speaker), user input devices <b>330</b> (such as a microphone, keypad, touchpad, touch screen, and the like), a communication device or network interface device <b>360</b>, a positioning system device <b>320</b>, such as a geo-positioning system device like a GPS device, an accelerometer, and the like, one or more chips, and the like.</p><p id="p-0041" num="0040">The processor <b>310</b> may include functionality to operate one or more software programs or applications, which may be stored in the memory device <b>350</b>. For example, the processor <b>310</b> may be capable of operating applications such as a user application <b>351</b>, an entity application <b>352</b>, or a web browser application. The user application <b>351</b> or the entity application may then allow the user device <b>104</b> to transmit and receive data and instructions to or from the third party system <b>400</b>, model feedback system <b>200</b>, and the managing entity system <b>500</b>, and display received information via the user interface of the user device <b>104</b>. The user application <b>351</b> may further allow the user device <b>104</b> to transmit and receive data to or from the managing entity system <b>500</b> data and instructions to or from the model feedback system <b>200</b>, web content, such as, for example, location-based content and/or other web page content, according to a Wireless Application Protocol (WAP), Hypertext Transfer Protocol (HTTP), and/or the like. The user application <b>351</b> may allow the managing entity system <b>500</b> to present the user <b>102</b> with a plurality of recommendations, identified trends, suggestions, transaction data, pattern data, graph data, statistics, and/or the like for the user to review. In some embodiments, the user interface displayed via the user application <b>351</b> or entity application <b>352</b> may be entity specific. For instance, while the model feedback system <b>200</b> may be accessed by multiple different entities, it may be configured to present information according to the preferences or overall common themes or branding of each entity system of third party system. In this way, each system accessing the model feedback system <b>200</b> may use a unique aesthetic for the entity application <b>352</b> or user application <b>351</b> portal.</p><p id="p-0042" num="0041">The processor <b>310</b> may be configured to use the communication device <b>360</b> to communicate with one or more devices on a network <b>101</b> such as, but not limited to the third party system <b>400</b>, the model feedback system <b>200</b>, and the managing entity system <b>500</b>. In this regard the processor <b>310</b> may be configured to provide signals to and receive signals from the communication device <b>360</b>. The signals may include signaling information in accordance with the air interface standard of the applicable BLE standard, cellular system of the wireless telephone network and the like, that may be part of the network <b>101</b>. In this regard, the user device <b>104</b> may be configured to operate with one or more air interface standards, communication protocols, modulation types, and access types. By way of illustration, the user device <b>104</b> may be configured to operate in accordance with any of a number of first, second, third, and/or fourth-generation communication protocols and/or the like. For example, the user device <b>104</b> may be configured to operate in accordance with second-generation (2G) wireless communication protocols IS-136 (time division multiple access (TDMA)), GSM (global system for mobile communication), and/or IS-95 (code division multiple access (CDMA)), or with third-generation (3G) wireless communication protocols, such as Universal Mobile Telecommunications System (UMTS), CDMA2000, wideband CDMA (WCDMA) and/or time division-synchronous CDMA (TD-SCDMA), with fourth-generation (4G) wireless communication protocols, and/or the like. The user device <b>104</b> may also be configured to operate in accordance with non-cellular communication mechanisms, such as via a wireless local area network (WLAN) or other communication/data networks. The user device <b>104</b> may also be configured to operate in accordance Bluetooth&#xae; low energy, audio frequency, ultrasound frequency, or other communication/data networks.</p><p id="p-0043" num="0042">The communication device <b>360</b> may also include a user activity interface presented in user output devices <b>340</b> in order to allow a user <b>102</b> to execute some or all of the processes described herein. The application interface may have the ability to connect to and communicate with an external data storage on a separate system within the network <b>101</b>. The user output devices <b>340</b> may include a display (e.g., a liquid crystal display (LCD) or the like) and a speaker or other audio device, which are operatively coupled to the processor <b>310</b> and allow the user device to output generated audio received from the model feedback system <b>200</b>. The user input devices <b>330</b>, which may allow the user device <b>104</b> to receive data from the user <b>102</b>, may include any of a number of devices allowing the user device <b>104</b> to receive data from a user <b>102</b>, such as a keypad, keyboard, touch-screen, touchpad, microphone, mouse, joystick, other pointer device, button, soft key, and/or other input device(s).</p><p id="p-0044" num="0043">The user device <b>104</b> may also include a memory buffer, cache memory or temporary memory device <b>350</b> operatively coupled to the processor <b>310</b>. Typically, one or more applications <b>351</b> and <b>352</b>, are loaded into the temporarily memory during use. As used herein, memory may include any computer readable medium configured to store data, code, or other information. The memory device <b>350</b> may include volatile memory, such as volatile Random Access Memory (RAM) including a cache area for the temporary storage of data. The memory device <b>350</b> may also include non-volatile memory, which can be embedded and/or may be removable. The non-volatile memory may additionally or alternatively include an electrically erasable programmable read-only memory (EEPROM), flash memory or the like.</p><p id="p-0045" num="0044">In some instances, various features and functions of the invention are described herein with respect to a &#x201c;system.&#x201d; In some instances, the system may refer to the model feedback system <b>200</b> performing one or more steps described herein in conjunction with other devices and systems, either automatically based on executing computer readable instructions of the memory device <b>250</b>, or in response to receiving control instructions from the managing entity system <b>500</b>. In some instances, the system refers to the devices and systems on the operating environment <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The features and functions of various embodiments of the invention are be described below in further detail.</p><p id="p-0046" num="0045">It is understood that the servers, systems, and devices described herein illustrate one embodiment of the invention. It is further understood that one or more of the servers, systems, and devices can be combined in other embodiments and still function in the same or similar way as the embodiments described herein.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flow diagram illustrating a model feedback loop, in accordance with one embodiment of the present disclosure. As shown in block <b>410</b>, the process begins wherein data is received by the model feedback system <b>200</b> and is fed to the data analysis module <b>260</b> for pre-processing and further analysis. It is understood that data may be received by the model feedback system <b>200</b> from any number of systems or entities, such as the managing entity system <b>500</b>, one or more third party system(s) <b>400</b>, user device(s) <b>104</b>, or a datastore, such as database <b>300</b>. In some embodiments, data is received by the model feedback system <b>200</b> in a continuous stream from one or more systems, devices, or entities (e.g., transaction data may be continuously received from the managing entity system <b>500</b> and processed continuously over time, or the like). In other embodiments, data may be received by the model feedback system <b>200</b> in batches, such as once per day, per week, or the like, and different output from the model feedback system <b>200</b> may be compared over time in order to discern differences in the resulting model output between these ongoing time periods.</p><p id="p-0048" num="0047">As shown in block <b>420</b>, the process proceeds whereby the model feedback system <b>200</b>, or in some embodiments, the data analysis module <b>260</b> in particular, is tasked with analyzing the metadata of received data, and characterizing a component feature set of the received data. For instance, the model feedback system <b>200</b> may receive a data set for day 1, and the data set for day 1 may include transaction data at a specific entity location. The metadata of this data set may indicate various features of each transaction. For instance, a transaction 1 may include a transaction resource amount, time of transaction, transaction accounts (e.g., receiving and sending, or the like), one or more additional entities involved with processing the transaction, resource channel (e.g., payment rail, or the like), one or more user identities or account holders, products, services, or the like. Each of these features may be characterized as a separate column, or the like, in which to catalogue metadata associated with transaction 1, and the same or similar feature categorization and characterization may be done for the remaining data in the data set.</p><p id="p-0049" num="0048">Furthermore, as shown in block <b>430</b>, the data set may be forwarded to machine learning engine <b>261</b> for analysis of the data set. As noted, the machine learning engine <b>261</b> may comprise any number or variations of machine learning models designed and trained to identify certain characteristics, features, or relationships between features, patterns, relevant data points, or the like. Output from the model(s) of machine learning engine <b>261</b> are continuously monitored, as shown in block <b>440</b>. Statistically significant shifts in the output from machine learning engine <b>261</b> over time may be recognized here by the model feedback system <b>200</b>. In this way, once the model feedback system <b>200</b> has detected a significant shift in the output from machine learning engine <b>261</b>, the system may return the data set to data analysis module <b>260</b> for further processing. The data analysis module <b>260</b> may detect features within the data set which are corelated with the rise in volatility in machine learning engine <b>261</b> output, and via comparison with previous data sets, or data processed at an earlier time which did not show this same volatility, and thus may automatically discern certain features which are responsible for the rise in output volatility. In some embodiments, the correlation between certain features and model output volatility may be partially or fully recognized based on how often the certain features change during a specific event or through a specific period of time.</p><p id="p-0050" num="0049">Based on the severity of the shift in the machine learning engine <b>261</b> output, the system <b>200</b> may then apply a proportionate counteractive weighting against the identified volatile feature(s) within the data set, and within future data sets, prior to forwarding the data set to the machine learning engine <b>261</b> for analysis, thereby stabilizing the output of the machine learning engine <b>261</b>. In this way, erratic or inaccurate output from the machine learning engine <b>261</b> may be accounted for and responded to in an automated, looped fashion, in order to reduce the chances of corrupting data being injected into the machine learning engine <b>261</b> and skewing its output in a potentially malfeasant manner.</p><p id="p-0051" num="0050">Once the system <b>200</b> has identified the volatile features of the data set, the system <b>200</b> may apply a dampening effect on the volatile features specifically, effectively making this data or other older data less significant as time progresses. In this way, the system applies less weight to older data in general, but may do so via the dampening of certain volatile features in particular. In some embodiments, identification of data that will be affected by the identified volatility is just as valuable as knowing what has been affected in the machine learning engine <b>261</b> output already. As such, the system <b>200</b> may also identify weights in order to inform on what data may be affected in the future, thereby proactively avoiding volatility in model output if similar significant shifts in model output or data input begin to arise, or if similar events occur as the events that were correlated with the previously identified volatility.</p><p id="p-0052" num="0051">As will be appreciated by one of ordinary skill in the art, the present invention may be embodied as an apparatus (including, for example, a system, a machine, a device, a computer program product, and/or the like), as a method (including, for example, a business process, a computer-implemented process, and/or the like), or as any combination of the foregoing. Accordingly, embodiments of the present invention may take the form of an entirely software embodiment (including firmware, resident software, micro-code, and the like), an entirely hardware embodiment, or an embodiment combining software and hardware aspects that may generally be referred to herein as a &#x201c;system.&#x201d; Furthermore, embodiments of the present invention may take the form of a computer program product that includes a computer-readable storage medium having computer-executable program code portions stored therein.</p><p id="p-0053" num="0052">As the phrase is used herein, a processor may be &#x201c;configured to&#x201d; perform a certain function in a variety of ways, including, for example, by having one or more general-purpose circuits perform the function by executing particular computer-executable program code embodied in computer-readable medium, and/or by having one or more application-specific circuits perform the function.</p><p id="p-0054" num="0053">It will be understood that any suitable computer-readable medium may be utilized. The computer-readable medium may include, but is not limited to, a non-transitory computer-readable medium, such as a tangible electronic, magnetic, optical, infrared, electromagnetic, and/or semiconductor system, apparatus, and/or device. For example, in some embodiments, the non-transitory computer-readable medium includes a tangible medium such as a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EEPROM or Flash memory), a compact disc read-only memory (CD-ROM), and/or some other tangible optical and/or magnetic storage device. In other embodiments of the present invention, however, the computer-readable medium may be transitory, such as a propagation signal including computer-executable program code portions embodied therein.</p><p id="p-0055" num="0054">It will also be understood that one or more computer-executable program code portions for carrying out the specialized operations of the present invention may be required on the specialized computer include object-oriented, scripted, and/or unscripted programming languages, such as, for example, Java, Perl, Smalltalk, C++, SQL, Python, Objective C, and/or the like. In some embodiments, the one or more computer-executable program code portions for carrying out operations of embodiments of the present invention are written in conventional procedural programming languages, such as the &#x201c;C&#x201d; programming languages and/or similar programming languages. The computer program code may alternatively or additionally be written in one or more multi-paradigm programming languages, such as, for example, F#.</p><p id="p-0056" num="0055">Embodiments of the present invention are described above with reference to flowcharts and/or block diagrams. It will be understood that steps of the processes described herein may be performed in orders different than those illustrated in the flowcharts. In other words, the processes represented by the blocks of a flowchart may, in some embodiments, be in performed in an order other that the order illustrated, may be combined or divided, or may be performed simultaneously. It will also be understood that the blocks of the block diagrams illustrated, in some embodiments, merely conceptual delineations between systems and one or more of the systems illustrated by a block in the block diagrams may be combined or share hardware and/or software with another one or more of the systems illustrated by a block in the block diagrams. Likewise, a device, system, apparatus, and/or the like may be made up of one or more devices, systems, apparatuses, and/or the like. For example, where a processor is illustrated or described herein, the processor may be made up of a plurality of microprocessors or other processing devices which may or may not be coupled to one another. Likewise, where a memory is illustrated or described herein, the memory may be made up of a plurality of memory devices which may or may not be coupled to one another.</p><p id="p-0057" num="0056">It will also be understood that the one or more computer-executable program code portions may be stored in a transitory or non-transitory computer-readable medium (e.g., a memory, and the like) that can direct a computer and/or other programmable data processing apparatus to function in a particular manner, such that the computer-executable program code portions stored in the computer-readable medium produce an article of manufacture, including instruction mechanisms which implement the steps and/or functions specified in the flowchart(s) and/or block diagram block(s).</p><p id="p-0058" num="0057">The one or more computer-executable program code portions may also be loaded onto a computer and/or other programmable data processing apparatus to cause a series of operational steps to be performed on the computer and/or other programmable apparatus. In some embodiments, this produces a computer-implemented process such that the one or more computer-executable program code portions which execute on the computer and/or other programmable apparatus provide operational steps to implement the steps specified in the flowchart(s) and/or the functions specified in the block diagram block(s). Alternatively, computer-implemented steps may be combined with operator and/or human-implemented steps in order to carry out an embodiment of the present invention.</p><p id="p-0059" num="0058">While certain exemplary embodiments have been described and shown in the accompanying drawings, it is to be understood that such embodiments are merely illustrative of, and not restrictive on, the broad invention, and that this invention not be limited to the specific constructions and arrangements shown and described, since various other changes, combinations, omissions, modifications and substitutions, in addition to those set forth in the above paragraphs, are possible. Those skilled in the art will appreciate that various adaptations and modifications of the just described embodiments can be configured without departing from the scope and spirit of the invention. Therefore, it is to be understood that, within the scope of the appended claims, the invention may be practiced other than as specifically described herein.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system for improved integrity of machine learning model input data, the system comprising:<claim-text>at least one non-transitory storage device; and</claim-text><claim-text>at least one processing device coupled to the at least one non-transitory storage device, wherein the at least one processing device is configured to:</claim-text><claim-text>receive one or more data sets for machine learning model analysis;</claim-text><claim-text>parse the one or more data sets and identify one or more features based on meta data of the one or more data sets;</claim-text><claim-text>transmit the one or more data sets to a machine learning model;</claim-text><claim-text>continuously monitor machine learning model analysis output;</claim-text><claim-text>identify a shift in the machine learning model analysis output;</claim-text><claim-text>correlate features of the one or more data sets with the identified shift in the machine learning model analysis output to identify one or more volatile features in the one or more data sets; and</claim-text><claim-text>apply a weighting to the one or more volatile features in the one or more data sets to offset the shift in the machine learning model analysis output.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more data sets comprises a continuous stream of data.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more data sets comprises resource transaction information and meta data.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the machine learning model further comprises a predictive machine learning model or pattern recognition machine learning model.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the weighting further comprises a dampening variable lessening effect of the one or more volatile features on the machine learning model analysis output.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the weighting is applied dynamically to lessen effect of older data on the machine learning model analysis output over time.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further configured to generate a prediction based on the one or more volatile features, wherein the prediction comprises an expected effect of the one or more volatile features on future machine learning model analysis output.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A computer program product for secured integrity of machine learning model input data, the computer program product comprising at least one non-transitory computer-readable medium having computer-readable program code portions embodied therein, the computer-readable program code portions comprising:<claim-text>an executable portion configured to receive one or more data sets for machine learning model analysis;</claim-text><claim-text>an executable portion configured to parse the one or more data sets and identify one or more features based on meta data of the one or more data sets;</claim-text><claim-text>an executable portion configured to transmit the one or more data sets to a machine learning model;</claim-text><claim-text>an executable portion configured to continuously monitor machine learning model analysis output;</claim-text><claim-text>an executable portion configured to identify a shift in the machine learning model analysis output;</claim-text><claim-text>an executable portion configured to correlate features of the one or more data sets with the identified shift in the machine learning model analysis output to identify one or more volatile features in the one or more data sets; and</claim-text><claim-text>an executable portion configured to apply a weighting to the one or more volatile features in the one or more data sets to offset the shift in the machine learning model analysis output.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the one or more data sets comprises a continuous stream of data.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the one or more data sets comprises resource transaction information and meta data.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the machine learning model further comprises a predictive machine learning model or pattern recognition machine learning model.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the weighting further comprises a dampening variable lessening effect of the one or more volatile features on the machine learning model analysis output.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the weighting is applied dynamically to lessen effect of older data on the machine learning model analysis output over time.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The computer program product of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further configured to generate a prediction based on the one or more volatile features, wherein the prediction comprises an expected effect of the one or more volatile features on future machine learning model analysis output.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A computer-implemented method for secured integrity of machine learning model input data, the method comprising:<claim-text>receiving one or more data sets for machine learning model analysis;</claim-text><claim-text>parsing the one or more data sets and identify one or more features based on meta data of the one or more data sets;</claim-text><claim-text>transmitting the one or more data sets to a machine learning model;</claim-text><claim-text>continuously monitoring machine learning model analysis output;</claim-text><claim-text>identifying a shift in the machine learning model analysis output;</claim-text><claim-text>correlating features of the one or more data sets with the identified shift in the machine learning model analysis output to identify one or more volatile features in the one or more data sets; and</claim-text><claim-text>applying a weighting to the one or more volatile features in the one or more data sets to offset the shift in the machine learning model analysis output.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The computer-implemented method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the one or more data sets comprises a continuous stream of data.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The computer-implemented method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the one or more data sets comprises resource transaction information and meta data.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The computer-implemented method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the machine learning model further comprises a predictive machine learning model or pattern recognition machine learning model.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The computer-implemented method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the weighting further comprises a dampening variable lessening effect of the one or more volatile features on the machine learning model analysis output.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The computer-implemented method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the weighting is applied dynamically to lessen effect of older data on the machine learning model analysis output over time.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004726A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004726</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17784843</doc-number><date>20191225</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>35</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>279</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>35</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>279</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">CONVERSION TABLE GENERATION DEVICE, CONVERSION TABLE GENERATION METHOD, AND RECORDING MEDIUM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>NEC Corporation</orgname><address><city>Minato-ku</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MORIBE</last-name><first-name>Shoujirou</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>NEC Corporation</orgname><role>03</role><address><city>Minato, Tokyo</city><country>JP</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2019/050798</doc-number><date>20191225</date></document-id><us-371c12-date><date>20220613</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A conversion table generation device includes a similar word extraction unit and a conversion table generation unit. The similar word extraction unit is configured to extract similar words similar to first words, for each of the first words included in a word group used in a dialogue. The conversion table generation unit is configured to associate any one of the first words with the extracted similar words, that are similar to the plurality of first words, as second words, on the basis of the priority, and generates a conversion table for voice recognition with the second word as a conversion source and the first word as a conversion destination.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="106.60mm" wi="158.75mm" file="US20230004726A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="217.25mm" wi="144.02mm" orientation="landscape" file="US20230004726A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="227.33mm" wi="153.42mm" orientation="landscape" file="US20230004726A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="235.71mm" wi="71.63mm" orientation="landscape" file="US20230004726A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="181.78mm" wi="89.66mm" orientation="landscape" file="US20230004726A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="232.58mm" wi="138.68mm" orientation="landscape" file="US20230004726A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="139.53mm" wi="52.75mm" orientation="landscape" file="US20230004726A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="229.45mm" wi="114.05mm" orientation="landscape" file="US20230004726A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="234.10mm" wi="85.77mm" orientation="landscape" file="US20230004726A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="221.40mm" wi="150.62mm" orientation="landscape" file="US20230004726A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="135.64mm" wi="145.80mm" orientation="landscape" file="US20230004726A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="217.17mm" wi="143.68mm" orientation="landscape" file="US20230004726A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="234.61mm" wi="132.33mm" orientation="landscape" file="US20230004726A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="142.66mm" wi="147.57mm" orientation="landscape" file="US20230004726A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="122.09mm" wi="110.49mm" orientation="landscape" file="US20230004726A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="147.74mm" wi="135.04mm" orientation="landscape" file="US20230004726A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="150.79mm" wi="113.20mm" orientation="landscape" file="US20230004726A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present invention relates to a voice dialogue technology, and particularly relates to a technology for correcting a voice recognition result.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">Voice dialogue systems that automatically respond to users are widely used in reservation systems, contact centers, and the like. The voice dialogue system recognizes the voice of the user, converts the voice into a sentence, and generates a sentence corresponding to the content of the utterance of the user by a voice dialogue control device also called a chatbot, thereby establishing a conversation. Therefore, it is important to accurately recognize the utterance of the user in order to improve the accuracy of the response.</p><p id="p-0004" num="0003">In voice recognition, it is difficult to correctly recognize homonyms and similar-sounding words. When the accuracy of voice recognition is improved for a word that is difficult to recognize as described above, a method is used in which a sequence of words appearing in one sentence is learned as statistical information and is estimated from preceding and following words. However, the user's answer is often made in a short sentence, and it is difficult to improve accuracy by estimating from preceding and subsequent sentences. Therefore, it is desirable to have a technique for improving the recognition accuracy of homonyms and similar-sounding words even for short utterances. As a technique for improving the accuracy of such voice recognition of homonyms and similar-sounding words, for example, a technique as disclosed in PTL 1 is disclosed.</p><p id="p-0005" num="0004">PTL 1 relates to a voice recognition system that corrects a character erroneously recognized by voice recognition. The voice recognition system of PTL 1 has a conversion data table in which a false recognition word candidate is associated with a candidate of a word of the conversion destination of the false recognition word candidate. The false recognition word candidate refers to a word that is erroneously recognized when the word of the conversion destination should be recognized. The voice recognition system of PTL 1 converts a false recognition word candidate into a word of the conversion destination when the false recognition word candidate is detected. PTL 1 describes that when a false recognition word candidate is detected, the false recognition can be reduced by converting the candidate into a word of the conversion destination.</p><heading id="h-0003" level="1">CITATION LIST</heading><heading id="h-0004" level="1">Patent Literature</heading><p id="p-0006" num="0005">[PTL 1] JP 2018-45001 A</p><heading id="h-0005" level="1">SUMMARY OF INVENTION</heading><heading id="h-0006" level="1">Technical Problem</heading><p id="p-0007" num="0006">However, the technique of PTL 1 is not sufficient in the following points. In PTL 1, the voice recognition result is corrected by replacing words on the basis of the conversion data table. In PTL 1, when the conversion data table used to correct a voice recognition result is generated, it is necessary for an operator to set in advance conversion data in which a false recognition word candidate and a candidate of a word of the conversion destination of the false recognition word candidate are associated with each other. However, for each word that may be used in the voice recognition system, it is difficult for an operator to estimate a word that is unlikely to be erroneously converted to generate a conversion table, and the workload required to create a highly reliable conversion data table can be enormous. Therefore, the technique of PTL 1 is not sufficient as a technique for correcting a voice recognition result in order to improve the accuracy of voice recognition.</p><p id="p-0008" num="0007">In order to solve the above problems, an object of the present invention is to provide a conversion table generation device, a voice dialogue system, a conversion table generation method, a voice dialogue method, and a recording medium capable of suppressing a workload necessary for generating a conversion table used when correcting a voice recognition result.</p><heading id="h-0007" level="1">Solution to Problem</heading><p id="p-0009" num="0008">In order to solve the above problem, a conversion table generation device of the present invention includes a similar word extraction unit and a conversion table generation unit. The similar word extraction unit extracts similar words similar to first words, each of the first words is included in a word group used in a dialogue. The conversion table generation unit associates a similar word, as a second word, similar to the plurality of first words among the extracted similar words with any one of the first words on the basis of the priority, and generates a conversion table for voice recognition with the second word as a conversion source and the first word as a conversion destination.</p><p id="p-0010" num="0009">The conversion table generation method of the present example embodiment extracts a similar word similar to the first word for each of the first words included in the word group used in the dialogue. The conversion table generation method of the present example embodiment associates a similar word, as a second word, similar to the plurality of first words among the extracted similar words with any one of the first words on the basis of the priority, and generates a conversion table for voice recognition with the second word as a conversion source and the first word as a conversion destination.</p><p id="p-0011" num="0010">The voice dialogue method of the present example embodiment extracts a similar word similar to the first word for each of the first words included in the word group used in the dialogue. The voice dialogue method of the present example embodiment associates a similar word, as a second word, similar to the plurality of first words among the extracted similar words with any one of the first words on the basis of the priority, and generates a conversion table with the second word as a conversion source and the first word as a conversion destination. The voice dialogue method of the present example embodiment converts input voice data into a sentence by voice recognition, and replaces the second word with the first word based on the conversion table when the second word included in the conversion table is detected from the sentence converted from the voice data. The voice dialogue method of the present example embodiment generates a sentence for responding to a sentence in which the second word is replaced with the first word.</p><p id="p-0012" num="0011">The recording medium of the present example embodiment records a computer program for causing a computer to execute processing. The computer program causes the computer to execute processing of extracting a similar word similar to the first word for each of the first words included in the word group used in the dialogue. The computer program causes the computer to associate a similar word, as a second word, similar to the plurality of first words among the extracted similar words with any one of the first words on the basis of the priority, and generate a conversion table for voice recognition with the second word as a conversion source and the first word as a conversion destination.</p><heading id="h-0008" level="1">Advantageous Effects of Invention</heading><p id="p-0013" num="0012">It is possible to suppress the workload required for generating the conversion table used when correcting the voice recognition result.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0009" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating a configuration of a first example embodiment of the present invention.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example of voice dialogue according to the first example embodiment of the present invention.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example of a conversion table according to the first example embodiment of the present invention.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating a configuration of a recognition result conversion device according to the first example embodiment of the present invention.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating a configuration of a conversion table generation device according to the first example embodiment of the present invention.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram illustrating an example of words of a conversion destination according to the first example embodiment of the present invention.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating an example of extraction of a similar word in the first example embodiment of the present invention.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating an example of a similar word extracted in the first example embodiment of the present invention.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating a criterion for generating the conversion table in the first example embodiment of the present invention.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating an operation flow of the conversion table generation device according to the first example embodiment of the present invention.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram illustrating a configuration of a second example embodiment of the present invention.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram illustrating a configuration of a conversion table generation device according to the second example embodiment of the present invention.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram illustrating an operation flow of the conversion table generation device according to the second example embodiment of the present invention.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram illustrating a configuration of a conversion table generation device according to a third example embodiment of the present invention.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram illustrating an operation flow of the conversion table generation device according to the third example embodiment of the present invention.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram illustrating an example of another configuration of the present invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0010" level="1">EXAMPLE EMBODIMENT</heading><heading id="h-0011" level="1">First Example Embodiment</heading><p id="p-0030" num="0029">A first example embodiment of the present invention will be described in detail with reference to the drawings. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating a configuration of a voice dialogue system of the present example embodiment. The voice dialogue system of the present example embodiment includes a voice capture device <b>10</b>, a voice recognition device <b>20</b>, a recognition result conversion device <b>30</b>, a voice dialogue control device <b>40</b>, a voice synthesis device <b>50</b>, and a conversion table generation device <b>60</b>.</p><p id="p-0031" num="0030">Before describing the configuration of the voice dialogue system of the present example embodiment, an example of an operation will be described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrating an example of dialogue. <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example of dialogue between a user and the voice dialogue system in a case where the voice dialogue system of the present example embodiment is provided in a reservation system such as a hotel or transportation facilities. The &#x201c;conversion&#x201d; in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is performed by the recognition result conversion device <b>30</b>. The voice dialogue system of the present example embodiment assumes the use of a dialogue device called a chatbot. The user may interact with the voice dialogue system illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> using a mobile terminal while communicating via a communication network. The user may directly interact with the voice dialogue system.</p><p id="p-0032" num="0031">When the user starts dialogue by operating, for example, a predetermined button or the like, the voice dialogue control device <b>40</b> generates a sentence &#x201c;Please tell me your business&#x201d;, for example, and transmits the sentence to the user as a synthesized voice via the voice synthesis device <b>50</b>. It is assumed that the user utters, for example, a voice of a request &#x201c;I want to make a reservation&#x201d; in response to &#x201c;Please tell me your business&#x201d;. At that time, the voice capture device <b>10</b> receives the voice of the user and outputs the voice data of the user to the voice recognition device <b>20</b>. It is assumed that the voice recognition device recognizes the voice data of the user and converts the voice data into text data, but the voice recognition device <b>20</b> cannot normally recognize the voice &#x201c;I want to make a reservation&#x201d; of the user and recognizes &#x201c;I want to summarize&#x201d;. In Japanese, &#x201c;reservation&#x201d; and &#x201c;summary&#x201d; are similar-sounding words. Text data that is a recognition result of the voice recognition device <b>20</b>, &#x201c;I want to summarize&#x201d;, is input to the recognition result conversion device <b>30</b>.</p><p id="p-0033" num="0032">Upon receiving the text data from the voice recognition device <b>20</b>, the recognition result conversion device <b>30</b> refers to the conversion table illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> and confirms whether there is a word included in the conversion table in &#x201c;I want to summarize&#x201d;. <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example of the conversion table. The conversion table is used when the word set as the conversion source word is included in the voice recognition result by the recognition result conversion device <b>30</b> and the conversion source word is replaced with the word set as the conversion destination. The conversion table is generated in advance by the conversion table generation device <b>60</b> and stored in the recognition result conversion device <b>30</b>, and the generation thereof will be described later.</p><p id="p-0034" num="0033">Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the recognition result conversion device <b>30</b> detects that the word &#x201c;summary&#x201d; set as the conversion source of the conversion table is included in &#x201c;I want to summarize&#x201d;. When &#x201c;summary&#x201d; set as the conversion source of the conversion table is detected from the voice recognition result, the recognition result conversion device <b>30</b> converts &#x201c;summary&#x201d; into &#x201c;reservation&#x201d; set as the conversion destination of &#x201c;summary&#x201d; in the conversion table. When converting &#x201c;summary&#x201d; into &#x201c;reservation&#x201d;, the recognition result conversion device <b>30</b> outputs a sentence in which the voice recognition result has been corrected to &#x201c;I want to make a reservation&#x201d; to the voice dialogue control device <b>40</b>.</p><p id="p-0035" num="0034">The voice dialogue control device <b>40</b> that has received the answer from the user which has been corrected to &#x201c;I want to make a reservation&#x201d; next outputs a response such as &#x201c;Please tell me the number of people&#x201d;. It is assumed that, in a case where the user answers &#x201c;We are <b>5</b> persons&#x201d; in response to &#x201c;Please tell me the number of people&#x201d;, the voice recognition device <b>20</b> converts the answer into &#x201c;misrecognized&#x201d;. In Japanese, &#x201c;<b>5</b> persons&#x201d; and &#x201c;misrecognition&#x201d; are homonym. The recognition result conversion device <b>30</b> that has acquired the text data that is the voice recognition result of &#x201c;misrecognized&#x201d; detects &#x201c;misrecognition&#x201d; of &#x201c;misrecognized&#x201d;, and when detecting that the text data is included in the &#x201c;misrecognition&#x201d; in the conversion table, converts the &#x201c;misrecognition&#x201d; into &#x201c;five persons&#x201d; of the conversion destination, and corrects the text data to &#x201c;We are five persons&#x201d;. The recognition result conversion device <b>30</b> outputs the voice recognition result corrected to &#x201c;We are five persons&#x201d; to the voice dialogue control device <b>40</b>.</p><p id="p-0036" num="0035">As described above, in the voice dialogue system of the present example embodiment, since the recognition result conversion device <b>30</b> corrects the voice recognition result of the voice recognition device <b>20</b> on the basis of the conversion table, even in a case where the voice recognition device <b>20</b> performs erroneous recognition, the dialogue can be stably continued. The voice dialogue system of the present example embodiment is characterized in that the conversion table generation device <b>60</b> automatically generates the conversion table used when correcting the voice recognition result as described above.</p><p id="p-0037" num="0036">First, each device constituting the voice dialogue system in <figref idref="DRAWINGS">FIG. <b>1</b></figref> will be described.</p><p id="p-0038" num="0037">The voice capture device <b>10</b> acquires a voice signal of the user's voice via a microphone or the like, samples the voice signal, and converts the voice signal into voice data of a digital signal. The voice capture device <b>10</b> outputs the voice data to the voice recognition device <b>20</b>. The voice capture device <b>10</b> may acquire voice data generated from the voice of the user by a terminal device possessed by the user such as a smartphone via a network.</p><p id="p-0039" num="0038">The voice recognition device <b>20</b> converts the user's voice data input from the voice capture device <b>10</b> into text data by voice recognition.</p><p id="p-0040" num="0039">The voice recognition device <b>20</b> performs voice recognition of the voice data using an acoustic model, a language model, and a word dictionary, and converts the voice data into text data.</p><p id="p-0041" num="0040">The recognition result conversion device <b>30</b> corrects the sentence included in the text data input from the voice recognition device <b>20</b> based on the conversion table. <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating a configuration of the recognition result conversion device <b>30</b>. The recognition result conversion device <b>30</b> includes a recognition result conversion unit <b>31</b> and a conversion table storage unit <b>32</b>.</p><p id="p-0042" num="0041">The recognition result conversion unit <b>31</b> confirms whether a word set as a conversion source in the conversion table is included in a sentence of the text data of the voice recognition result received from the voice recognition device <b>20</b>. When detecting the word included in the conversion source of the conversion table from the sentence of the voice recognition result, the recognition result conversion unit <b>31</b> replaces the detected word with the word of the conversion destination. For example, when the voice recognition result includes &#x201c;summary&#x201d;, the recognition result conversion unit <b>31</b> converts &#x201c;summary&#x201d; into &#x201c;reservation&#x201d; set as the conversion destination of &#x201c;summary&#x201d; in the conversion table.</p><p id="p-0043" num="0042">The conversion table storage unit <b>32</b> stores data of the conversion table. The data of the conversion table is generated by the conversion table generation device <b>60</b>.</p><p id="p-0044" num="0043">The voice dialogue control device <b>40</b> analyzes an utterance content of the user using a learning model generated by machine learning, and generates a response sentence according to an analysis result, thereby enabling dialogue. The voice dialogue control device <b>40</b> may perform a rule-type dialogue process in which a combination of a question and an answer is set in advance. The voice dialogue control device <b>40</b> controls the conversion table generation device <b>60</b>.</p><p id="p-0045" num="0044">The voice synthesis device <b>50</b> converts text data of a sentence of a question or a notification to be transmitted to the user which is input from the voice dialogue control device <b>40</b> into voice data, and outputs the voice data.</p><p id="p-0046" num="0045">Next, the configuration of the conversion table generation device <b>60</b> will be described. <figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating the configuration of the conversion table generation device <b>60</b> according to the present example embodiment. The conversion table generation device <b>60</b> includes a data acquisition unit <b>61</b>, an analysis unit <b>62</b>, a similar word extraction unit <b>63</b>, a conversion table generation unit <b>64</b>, a conversion table output unit <b>65</b>, and a dictionary data storage unit <b>66</b>.</p><p id="p-0047" num="0046">The data acquisition unit <b>61</b> acquires data including a word used for voice dialogue. The data acquisition unit <b>61</b> acquires, from the voice dialogue control device <b>40</b>, data for voice dialogue held inside the voice dialogue control device <b>40</b>, for example. The voice dialogue data held inside the voice dialogue control device <b>40</b> is also referred to as scenario data. For example, in a case where the voice dialogue system is used for a reservation system, the voice dialogue data includes words such as &#x201c;reservation&#x201d;, &#x201c;change&#x201d;, and &#x201c;cancel&#x201d; used for reservation. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram illustrating an example of words and phrases used for reservation held inside the voice dialogue control device <b>40</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the words and phrases include a phrase, a clause, and a short sentence in which a word and a particle are combined. These words and phrases need to be correctly input from the recognition result conversion device <b>30</b> to the voice dialogue control device <b>40</b>, and need to be correctly recognized by the voice dialogue control device <b>40</b>.</p><p id="p-0048" num="0047">The data acquisition unit <b>61</b> may acquire data (conversation history data of the response) of the log of the user's answer and the response output from the voice dialogue control device <b>40</b> to the voice synthesis device <b>50</b> as data including the word used for the voice dialogue. In the case of the rule-type voice dialogue control device <b>40</b>, the data acquisition unit <b>61</b> may acquire data in which a preset rule such as a relationship between a question and an answer is described.</p><p id="p-0049" num="0048">The analysis unit <b>62</b> performs morphological analysis with reference to dictionary data, and extracts a word from the data acquired by the data acquisition unit <b>61</b> from the voice dialogue control device <b>40</b>. The word extracted by the analysis unit <b>62</b> is used as a word of the conversion destination in the conversion table. The data acquired from the voice dialogue control device <b>40</b> is generated in accordance with a reservation system or the like which is an application field of the voice dialogue system. Therefore, by extracting the word from the data acquired from the voice dialogue control device <b>40</b>, it is possible to extract the word used in the reservation system without excess or deficiency.</p><p id="p-0050" num="0049">The similar word extraction unit <b>63</b> refers to the dictionary data and extracts a similar word of each word extracted by the analysis unit <b>62</b>. The word extracted by the analysis unit <b>62</b> is a word used as a conversion destination in the conversion table. The similar word extraction unit <b>63</b> extracts a homonym and a similar-sounding word as similar words for each word extracted by the analysis unit <b>62</b>.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example of a similar word extraction method. <figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example of extracting a similar word of &#x201c;reservation (YoYaKu)&#x201d;. (YoYaKu) of &#x201c;reservation (YoYaKu)&#x201d; is written to describe the reading of the word, and the same applies to other words. The similar word extraction unit <b>63</b> first refers to the dictionary data and extracts &#x201c;medication (YoYaKu)&#x201d;, which is a homonym of &#x201c;reservation (YoYaKu)&#x201d; in Japanese. When the homonym is extracted, the similar word extraction unit <b>63</b> extracts a similar-sounding word of &#x201c;reservation (YoYaKu)&#x201d;.</p><p id="p-0052" num="0051">The similar word extraction unit <b>63</b> first extracts, as a similar-sounding word of the word of the conversion destination, a similar-sounding word in which one character of &#x201c;reservation (YoYaKu)&#x201d; is replaced with another character. For example, the similar word extraction unit <b>63</b> extracts &#x201c;free translation (IYaKu)&#x201d; obtained by replacing the first character &#x201c;Yo&#x201d; of &#x201c;reservation (YoYaKu)&#x201d; with &#x201c;I&#x201d; as a similar-sounding word of &#x201c;reservation (YoYaKu)&#x201d;. The similar word extraction unit <b>63</b> extracts a similar-sounding word added to any one or a plurality of double consonants, syllabic nasals, contracted sounds, and long sounds in the character string of the word of the conversion destination. For example, the similar word extraction unit <b>63</b> extracts &#x201c;summary (YoUYaKu)&#x201d; as a similar-sounding word obtained by adding a long sound to &#x201c;reservation (YoYaKu)&#x201d; in Japanese among a double consonant, a syllabic nasal, a contracted sound, and a long sound.</p><p id="p-0053" num="0052">When extracting a similar word, the similar word extraction unit <b>63</b> does not extract a word to be recognized, that is, a word that matches the word of the conversion destination, as a similar word. For example, it is assumed that &#x201c;reservation (YoYaKu)&#x201d; and &#x201c;rule (KiYaKu)&#x201d; are used as words to be recognized, that is, words of the conversion destination. At this time, when detecting &#x201c;rule (KiYaKu)&#x201d; as a similar-sounding word of &#x201c;reservation (YoYaKu)&#x201d; from the dictionary data, the similar word extraction unit <b>63</b> does not extract &#x201c;rule (KiYaKu)&#x201d; as a similar-sounding word of &#x201c;reservation (YoYaKu)&#x201d;. This is because, when the &#x201c;rule (KiYaKu)&#x201d; is extracted as a similar-sounding word, &#x201c;rule (KiYaKu)&#x201d; is included in the conversion source of the &#x201c;reservation (YoYaKu)&#x201d; in the conversion table, and the voice recognition result is converted into the &#x201c;reservation (YoYaKu)&#x201d; in recognition result conversion device <b>30</b> although it is desired to recognize the &#x201c;rule (KiYaKu)&#x201d;.</p><p id="p-0054" num="0053">When extracting a similar word for each word to be recognized, the similar word extraction unit <b>63</b> sends data as illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> in which the extracted similar word is associated with the word to be recognized, that is, the word of the conversion destination to the conversion table generation unit <b>64</b>. <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example of data in which the extracted similar word is associated with the word to be recognized, that is, the word of the conversion destination. Although only five similar words are illustrated in the example of <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the number of similar words is not limited to the example of <figref idref="DRAWINGS">FIG. <b>8</b></figref>, and all the extracted similar words are associated with the word of the conversion destination.</p><p id="p-0055" num="0054">The conversion table generation unit <b>64</b> generates a conversion table from the data as illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> in which each of the similar words extracted by the similar word extraction unit <b>63</b> is associated with the word of the conversion destination. The conversion table generation unit <b>64</b> extracts words associated with a plurality of words of the conversion destination as similar words, and generates a conversion table by associating the extracted similar word with any one of the word of the conversion destinations.</p><p id="p-0056" num="0055">In the word replacement operation in the recognition result conversion device <b>30</b> using the conversion table, the same similar word is converted into any one word of the conversion destination. That is, the word extracted as the similar word is associated with one of the words of the conversion destination as the word of the conversion source in the conversion table.</p><p id="p-0057" num="0056">The conversion table generation unit <b>64</b> performs processing of associating any one of two or more, that is, words associated with a plurality of words of the conversion destination as similar words with any one of the words of the conversion destination on the basis of the priority.</p><p id="p-0058" num="0057">Based on the table of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the conversion table generation unit <b>64</b> determines with which word of the conversion destination the similar-sounding word similar to the plurality of words of the conversion destination is to be associated. <figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a table used as a criterion for determining a priority when the conversion table generation unit <b>64</b> associates the similar-sounding word with the word of the conversion destination in a case where the language is Japanese. In the table of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, characters having common consonants in the vertical direction are arranged as &#x201c;A-row&#x201d;, &#x201c;Ka-row&#x201d;, and the like. In addition, in the table of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, characters having common vowels in the lateral direction are arranged like &#x201c;A group&#x201d; and &#x201c;I group&#x201d;. Although the sonant is not illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, a table including the sonant may be used. For example, in the table of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, &#x201c;Ga-row&#x201d; may be included between &#x201c;Ka-row&#x201d; and &#x201c;Sa-row&#x201d;.</p><p id="p-0059" num="0058">With reference to the table of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, when a target character, that is, a character converted from an original character in extracting a similar-sounding word is converted into a sound, the conversion table generation unit <b>64</b> preferentially associates a similar word with a word in the same row or the same group as the original character. &#x201c;Free translation (IYaKu)&#x201d;, which is a similar-sounding word common to &#x201c;rule (KiYaKu)&#x201d; and &#x201c;reservation (YoYaKu)&#x201d; in Japanese, is obtained by converting the first characters of &#x201c;rule (KiYaKu)&#x201d; and &#x201c;reservation (YoYaKu)&#x201d;. At this time, the conversion table generation unit <b>64</b> determines the priority of which one of the &#x201c;rule (KiYaKu)&#x201d; and the &#x201c;reservation (YoYaKu)&#x201d; is to be associated with the &#x201c;free translation (IYaKu)&#x201d; on the basis of the similarity of the first character converted from the original character when extracting the similar-sounding word. The vowel &#x201c;I&#x201d; obtained by converting the first character of &#x201c;free translation (IYaKu)&#x201d; into a sound coincides with &#x201c;Ki&#x201d; obtained by converting the first character of the &#x201c;rule (KiYaKu)&#x201d; into a sound. The conversion table generation unit <b>64</b> preferentially associates the converted characters with the word of the conversion destination in the same row or the same group before and after conversion. Here, the same row as the original character means a character having the same vertical column in <figref idref="DRAWINGS">FIG. <b>9</b></figref> and a character having a common consonant. In addition, the same group as the original character means a character having the same horizontal column in <figref idref="DRAWINGS">FIG. <b>9</b></figref> and a character having a common vowel.</p><p id="p-0060" num="0059">Similarly, when associating a similar-sounding word with &#x201c;rule (KiYaKu)&#x201d; and &#x201c;reservation (YoYaKu)&#x201d;, the conversion table generation unit <b>64</b> associates &#x201c;useful (OYaKu)&#x201d;, which is a similar-sounding word common to both, with the same group, that is, &#x201c;reservation (YoYaKu)&#x201d; in which vowels are common. Further, the conversion table generation unit <b>64</b> associates &#x201c;medicine (IYaKu)&#x201d;, &#x201c;leaping (HiYaKu)&#x201d;, &#x201c;secret medicine (HiYaKu)&#x201d;, and &#x201c;reagent (ShiYaKu)&#x201d;, which are the similar-sounding words common to both, with the same row, that is, the common consonant &#x201c;rule (KiYaKu)&#x201d;.</p><p id="p-0061" num="0060">In a case where any one of the row and the group is overlapped in the table of <figref idref="DRAWINGS">FIG. <b>9</b></figref> and the priority is the same, for example, the conversion table generation unit <b>64</b> preferentially makes association with the word of the conversion destination having many similar words. Similarly, the conversion table generation unit <b>64</b> preferentially makes association with a word of the conversion destination having many similar words when the same homonym is common to two or more words of the conversion destination. For example, on the table of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the conversion table generation unit <b>64</b> associates &#x201c;child actor (KoYaKu)&#x201d; whose rows and group do not match with &#x201c;rule (KiYaKu)&#x201d; and &#x201c;reservation (YoYaKu)&#x201d; with &#x201c;rule (KiYaKu)&#x201d; having many similar words.</p><p id="p-0062" num="0061">When the number of similar words is large, or when neither a row nor a group overlaps on the table of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the conversion table generation unit <b>64</b> makes association with a word having a high use frequency. For a similar word for which the conversion table generation unit <b>64</b> cannot determine the priority of association, the operator may input a word of the conversion destination to be associated with. When the word of the conversion destination with which the similar word is associated is determined, the conversion table generation unit <b>64</b> generates the data conversion table as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> in which the similar word determined as the conversion source is associated with the word of the conversion destination. The conversion table generation unit <b>64</b> does not include, in the conversion table, the word of the conversion destination for which there is no similar word serving as a conversion source.</p><p id="p-0063" num="0062">The word of the conversion destination with which the similar word is associated with the priority as described above is determined, and the similar word similar to two or more words of the conversion destination is associated as a conversion source of any one word of the conversion destination.</p><p id="p-0064" num="0063">After generating the conversion table, the conversion table generation unit <b>64</b> outputs the conversion table to the conversion table output unit <b>65</b>.</p><p id="p-0065" num="0064">The conversion table output unit <b>65</b> outputs the conversion table generated by the conversion table generation unit <b>64</b> to the recognition result conversion device <b>30</b>.</p><p id="p-0066" num="0065">The dictionary data storage unit <b>66</b> stores dictionary data. In addition to a normal dictionary, the dictionary data in which technical terms in a field to which the voice dialogue system is applied are collected is used. For example, in the case of a voice dialogue system used for reservation or consultation of reservation at a counter in a hospital, dictionary data in the medical field is used.</p><p id="p-0067" num="0066">Each processing in the data acquisition unit <b>61</b>, the analysis unit <b>62</b>, the similar word extraction unit <b>63</b>, the conversion table generation unit <b>64</b>, the conversion table output unit <b>65</b>, and the dictionary data storage unit <b>66</b> is performed by executing a computer program on a central processing unit (CPU). The CPU executes a computer program stored in a storage device such as a hard disk drive by reading the computer program into a memory.</p><p id="p-0068" num="0067">The dictionary data storage unit <b>66</b> includes a storage device such as a non-volatile semiconductor storage device or a hard disk drive. The dictionary data storage unit <b>66</b> may be configured by a combination of a plurality of types of storage devices. In addition, the dictionary data storage unit <b>66</b> may be provided in a storage device outside the conversion table generation device <b>60</b> and connected to the conversion table generation device <b>60</b> via a network.</p><p id="p-0069" num="0068">Next, an operation of the conversion table generation device <b>60</b> will be described. <figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating an operation flow of the conversion table generation device <b>60</b>.</p><p id="p-0070" num="0069">When the conversion table generation device <b>60</b> starts the operation of generating a conversion table, the data acquisition unit <b>61</b> acquires data including a word to be recognized from the voice dialogue control device <b>40</b>. When acquiring data including a word to be recognized, the data acquisition unit <b>61</b> sends the acquired data to the analysis unit <b>62</b>.</p><p id="p-0071" num="0070">When the data including the word to be recognized is acquired, the analysis unit <b>62</b> extracts the word to be recognized in the voice recognition, that is, the word to be used as the word of the conversion destination in the conversion table from the acquired data (Step S<b>11</b>). The analysis unit <b>62</b> refers to the dictionary data stored in the dictionary data storage unit <b>66</b> and extracts the dictionary data as a candidate for the word of the conversion destination. When extracting a candidate of the word of the conversion destination, the analysis unit <b>62</b> also extracts words related to numbers such as the number of people and the date.</p><p id="p-0072" num="0071">When extracting a word, the analysis unit <b>62</b> sends data of the extracted word to the similar word extraction unit <b>63</b>. When receiving the data of the word, the similar word extraction unit <b>63</b> extracts a similar word for each received word (Step S<b>12</b>). After extracting the similar word, the similar word extraction unit <b>63</b> sends data of the similar word associated with each word of the conversion destination to the conversion table generation unit <b>64</b>. When receiving the data of the similar word, the conversion table generation unit <b>64</b> determines which word of the conversion destination the similar word is associated with on the basis of the priority (Step S<b>13</b>).</p><p id="p-0073" num="0072">The conversion table generation unit <b>64</b> determines, on the basis of the table as illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, which word of the conversion destination is to be associated with a similar-sounding word similar to two or more words of the conversion destination. When determining, on the basis of the priority, which word of the conversion destination the similar word is to be associated with, the conversion table generation unit <b>64</b> generates, as a conversion table, a data table in which the similar word determined as the conversion source is associated with the word of the conversion destination (Step S<b>14</b>). After generating the conversion table, the conversion table generation unit <b>64</b> outputs the conversion table to the conversion table output unit <b>65</b>. The conversion table output unit <b>65</b> sends the conversion table to the recognition result conversion device <b>30</b>. The conversion table sent to the recognition result conversion device <b>30</b> is used when the recognition result conversion device <b>30</b> corrects the voice recognition result.</p><p id="p-0074" num="0073">The voice capture device <b>10</b>, the voice recognition device <b>20</b>, the recognition result conversion device <b>30</b>, the voice dialogue control device <b>40</b>, the voice synthesis device <b>50</b>, and the conversion table generation device <b>60</b> constituting the voice dialogue system of the present example embodiment may be installed at different positions and connected via a network. In addition, two or more devices constituting the voice dialogue system may be configured as an integrated device.</p><p id="p-0075" num="0074">The voice dialogue system of the present example embodiment can be used for, for example, a reservation system. The reservation system using the voice dialogue system of the present example embodiment can be used for a system that receives a reservation, confirmation of the reservation, cancellation of the reservation, or the like from a user in an accommodation facility, a public transportation facility, a medical institution, a restaurant, or the like. The voice dialogue system of the present example embodiment can also be used in a diagnosis system or a medical interview system in a hospital. In addition, the voice dialogue system of the present example embodiment can also be used for an information guidance system such as tourist guidance, traffic guidance, and notification of disaster information. The application destination of the voice dialogue system of the present example embodiment is not limited to the above example as long as the system performs voice dialogue.</p><p id="p-0076" num="0075">In the above description, the Japanese word has been described, but the conversion table can be similarly generated also in other languages to correct the voice recognition result. For example, in English, the conversion table generation device <b>60</b> replaces a word of the conversion destination with a phonetic symbol, extracts a homonym and a similar-sounding word, and generates a conversion table. For example, when &#x201c;beach&#x201d; is a conversion destination, the conversion table generation device <b>60</b> generates a conversion table in which &#x201c;beech&#x201d; that is a homonym and &#x201c;reach&#x201d; that is a similar-sounding word are used as conversion sources. The priority when determining the destination to associate similar words similar to a plurality of words is set in advance on the basis of, for example, similarity in pronunciation.</p><p id="p-0077" num="0076">The conversion table generation device <b>60</b> of the voice dialogue system of the present example embodiment extracts a word to be recognized by voice recognition, that is, a similar word of a word used in dialogue, and generates a conversion table when the recognition result conversion device <b>30</b> corrects the voice recognition result, using the word used in the dialogue as a conversion destination and the similar word as a conversion source. The conversion table generation device <b>60</b> according to the present example embodiment extracts, as similar words, homonyms and similar-sounding words that are similar to a word to be recognized extracted from data acquired from the voice dialogue control device <b>40</b> and are likely to be erroneously recognized in voice recognition, and generates a conversion table for converting a voice recognition result. In addition, when generating the conversion table, the conversion table generation device <b>60</b> determines a similar word to be associated with the word of the conversion destination as the word of the conversion source according to the priority criterion, thereby automatically generating the conversion table indicating the correspondence between the conversion destination and the conversion source. Therefore, the conversion table generation device <b>60</b> of the present example embodiment can generate the conversion table for correcting the voice recognition result without requiring work by the operator.</p><p id="p-0078" num="0077">In addition, even in a case where the voice recognition result is erroneously recognized by being converted on the basis of the conversion table generated by the conversion table generation device <b>60</b>, the sentence corrected by being converted into a correct word is input to a voice dialogue control device. When the sentence converted into the correct word is input to the voice dialogue control device, rehearing and erroneous recognition are suppressed in the voice dialogue system, and the accuracy of dialogue in the voice dialogue system is improved. Therefore, the voice dialogue system of the present example embodiment can improve the accuracy of voice recognition while suppressing the necessary workload by automatically generating the conversion table of the word that may be erroneously recognized in voice recognition.</p><heading id="h-0012" level="1">Second Example Embodiment</heading><p id="p-0079" num="0078">A second example embodiment of the present invention will be described in detail with reference to the drawings. <figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram illustrating a configuration of a voice dialogue system of the present example embodiment. The voice dialogue system according to the first example embodiment replaces a word included in a sentence in text data output as a voice recognition result on the basis of the conversion table generated by the conversion table generation device <b>60</b>. In addition to such a configuration, the voice dialogue system of the present example embodiment has a function of updating the conversion table on the basis of the log of the use frequency.</p><p id="p-0080" num="0079">The voice dialogue system of the present example embodiment includes a voice capture device <b>10</b>, a voice recognition device <b>20</b>, a recognition result conversion device <b>30</b>, a voice dialogue control device <b>40</b>, a voice synthesis device <b>50</b>, and a conversion table generation device <b>70</b>. The configurations and functions of the voice capture device <b>10</b>, the voice recognition device <b>20</b>, the recognition result conversion device <b>30</b>, the voice dialogue control device <b>40</b>, and the voice synthesis device <b>50</b> of the present example embodiment are similar to those of the device having the same name in the second example embodiment.</p><p id="p-0081" num="0080">A configuration of the conversion table generation device <b>70</b> will be described. <figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram illustrating a configuration of the conversion table generation device <b>70</b>. The conversion table generation device <b>70</b> includes a data acquisition unit <b>61</b>, an analysis unit <b>62</b>, a similar word extraction unit <b>63</b>, a conversion table generation unit <b>71</b>, a conversion table output unit <b>65</b>, a dictionary data storage unit <b>66</b>, a log data acquisition unit <b>72</b>, and a conversion table storage unit <b>73</b>.</p><p id="p-0082" num="0081">The configurations and functions of the data acquisition unit <b>61</b>, the analysis unit <b>62</b>, the similar word extraction unit <b>63</b>, the conversion table output unit <b>65</b>, and the dictionary data storage unit <b>66</b> according to the present example embodiment are similar to the components having the same names in the conversion table generation device <b>60</b> according to the second example embodiment.</p><p id="p-0083" num="0082">The conversion table generation unit <b>71</b> has a function of updating the conversion table on the basis of the log acquired by the log data acquisition unit <b>72</b>, in addition to the same function as the conversion table generation unit <b>64</b> of the second example embodiment. The conversion table generation unit <b>71</b> outputs the generated conversion table to the conversion table output unit <b>65</b> and stores the table in the conversion table storage unit <b>73</b>.</p><p id="p-0084" num="0083">The log data acquisition unit <b>72</b> acquires a log from the voice dialogue system. The log data acquisition unit <b>72</b> acquires, as a log, data of the word converted by the recognition result conversion device <b>30</b> and the number of times of conversion.</p><p id="p-0085" num="0084">The conversion table storage unit <b>73</b> stores data of the conversion table generated by the conversion table generation unit <b>71</b>.</p><p id="p-0086" num="0085">Each processing in the conversion table generation unit <b>71</b> and the log data acquisition unit <b>72</b> is performed by executing a computer program on the CPU similarly to the processing of other parts. The CPU executes a computer program stored in a storage device such as a hard disk drive by reading the computer program into a memory.</p><p id="p-0087" num="0086">The conversion table storage unit <b>73</b> includes a storage device such as a non-volatile semiconductor storage device or a hard disk drive. The conversion table storage unit <b>73</b> may be configured by a combination of a plurality of types of storage devices.</p><p id="p-0088" num="0087">An operation of the voice dialogue system of the present example embodiment will be described. The operation of the entire voice dialogue system and the operation until the conversion table is first generated in the conversion table generation device <b>70</b> are similar to those in the second example embodiment. Therefore, only the operation of updating the conversion table in the conversion table generation device <b>70</b> will be described below with reference to <figref idref="DRAWINGS">FIG. <b>13</b></figref>. <figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram illustrating an operation flow when the conversion table is updated on the basis of the log in the conversion table generation device <b>70</b>.</p><p id="p-0089" num="0088">When the conversion table generation device <b>70</b> starts the operation of updating the conversion table, the log data acquisition unit <b>72</b> acquires the log data from the recognition result conversion device <b>30</b> (Step S<b>21</b>). The log is acquired as data in which the number of times the recognition result conversion device <b>30</b> has replaced the conversion source word with the word of the conversion destination in the conversion table is recorded for each word of the conversion source. The log data acquisition unit <b>72</b> sends the acquired log data to the conversion table generation unit <b>71</b>.</p><p id="p-0090" num="0089">When the log is acquired, the conversion table generation unit <b>71</b> starts the operation of updating the conversion table. The conversion table generation unit <b>71</b> counts the number of times of conversion in recognition result conversion device <b>30</b> for each similar word as a conversion source. The conversion table generation unit <b>71</b> checks whether there is a similar word whose number of times of use is less than a criterion within a preset period, and determines whether it is necessary to update the conversion table. When the number of times of conversion is equal to or more than the preset number of times and the conversion table is unnecessary (No in Step S<b>22</b>), the conversion table generation unit <b>71</b> ends the operation without updating the conversion table.</p><p id="p-0091" num="0090">When the number of times of conversion is less than the preset number of times and the conversion table is necessary to be updated (Yes in Step S<b>22</b>), the conversion table generation unit <b>71</b> deletes the similar word of which the number of times of conversion is less than the criterion from the word of the conversion source in the conversion table (Step S<b>23</b>). In a case where the word of the conversion destination in which the word of the conversion source disappears by the deletion is generated, the conversion table generation unit <b>71</b> deletes the word of the conversion destination in which the word of the conversion source disappears from the conversion table.</p><p id="p-0092" num="0091">When the similar word of which the number of times of conversion is less than the criterion is excluded from the conversion source word of the conversion table, the conversion table generation unit <b>71</b> updates the data of the conversion table stored in the conversion table storage unit <b>73</b> using the data of the conversion table in which the target similar word is excluded from the conversion source (Step S<b>24</b>). In addition, the conversion table generation unit <b>71</b> outputs the updated conversion table to the conversion table output unit <b>65</b>.</p><p id="p-0093" num="0092">When receiving the updated conversion table, the conversion table output unit <b>65</b> outputs the updated conversion table to the recognition result conversion device <b>30</b>. The updated conversion table input to the recognition result conversion device <b>30</b> is stored in the conversion table storage unit <b>32</b>. When a sentence in the text data input from the voice recognition device <b>20</b> includes a word for which the conversion table is set, the recognition result conversion unit <b>31</b> of the recognition result conversion device <b>30</b> converts the word according to the updated conversion table, and outputs the text data of the corrected sentence to the voice dialogue control device <b>40</b>.</p><p id="p-0094" num="0093">In the above description, the conversion table is updated based on the log in the recognition result conversion device <b>30</b>, but the conversion table generation unit <b>71</b> may determine whether the conversion result is appropriate based on the log and determine whether the conversion table needs to be updated. For example, the conversion table generation unit <b>71</b> may acquire the log of the voice dialogue control device <b>40</b> and review the word of the conversion source with respect to the word of the conversion destination in which the number of times the voice dialogue control device <b>40</b> has failed to correctly recognize is equal to or more than a preset criterion. In such a configuration, the conversion table generation unit <b>71</b> acquires data of the number of times the voice recognition of the answer result from the user has been not appropriate in the voice dialogue control device <b>40</b>. The number of times the voice recognition of the answer result from the user is not appropriate refers to, for example, the number of times the voice dialogue control device <b>40</b> has not been able to specify the answer result as the answer result of the user and has made re-inquiry.</p><p id="p-0095" num="0094">The conversion table generation unit <b>71</b> refers to the log of the recognition result conversion device <b>30</b> and checks the number of times of conversion for the word of the conversion destination that has not been correctly recognized. When the number of times of conversion is less than the preset number of times, the conversion table generation unit <b>71</b> determines that update of the conversion table is unnecessary. This is because when the number of times of conversion is less than the preset number of times, there is a low possibility that the conversion table has a factor that the voice dialogue control device <b>40</b> has failed to perform appropriate conversion.</p><p id="p-0096" num="0095">When the number of times of conversion is equal to or more than the preset number of times, the conversion table generation unit <b>71</b> excludes a word that may cause erroneous conversion from the word of the conversion source. For example, the conversion table generation unit <b>71</b> regards the word of the conversion source having a high conversion frequency in the recognition result conversion device <b>30</b> as a word having a possibility of erroneous conversion and excludes the word from the conversion source.</p><p id="p-0097" num="0096">The conversion table generation unit <b>71</b> may compare the logs of both the recognition result conversion device <b>30</b> and the voice dialogue control device <b>40</b> to confirm whether the voice dialogue control device <b>40</b> has appropriately responded when the recognition result conversion device <b>30</b> has performed conversion. The conversion table generation unit <b>71</b> may count the number of times of re-inquiry when the recognition result conversion device <b>30</b> has performed conversion, and may exclude the word of the conversion source of the recognition result conversion device <b>30</b> from the conversion table when the number of times of re-inquiry exceeds a preset criterion. In addition, in a case where the word excluded from the conversion table is a similar word of two words of the conversion destination, the conversion table generation unit <b>71</b> may update the conversion table by associating the word with another word of the conversion destination. In a case where there are further two or more candidates for the word of the conversion destination to be associated with the word excluded from the conversion table, the conversion table generation unit <b>71</b> determines association according to the same priority criterion as in the first example embodiment.</p><p id="p-0098" num="0097">The conversion table generation unit <b>71</b> may update the conversion table by reviewing the word of the conversion destination to be associated only with the similar word of which the priority cannot be specified on the basis of the table of <figref idref="DRAWINGS">FIG. <b>9</b></figref>. In addition, the conversion table generation unit <b>71</b> may randomly associate a similar word of which the priority cannot be determined by the priority criterion with any word of the conversion destinations, and update the association based on the log. With such a configuration, it is possible to automatically generate the conversion table without requiring correction of association or the like by the operator.</p><p id="p-0099" num="0098">The conversion table generation device <b>70</b> according to the present example embodiment acquires a log in the voice dialogue system and corrects the conversion table based on the log. For example, the conversion table generation device <b>70</b> acquires log data indicating the frequency of conversion in the voice recognition device, and deletes an unused similar word of the conversion source and an unused conversion table. In this way, by updating the conversion table, the amount of data when the recognition result conversion device refers to the recognition result can be suppressed, so that it is possible to suppress a decrease in processing speed when the voice recognition result is corrected. As a result, it is possible to improve the accuracy of the voice dialogue while suppressing a decrease in the response speed of the voice dialogue system to the answer of the user.</p><heading id="h-0013" level="1">Third Example Embodiment</heading><p id="p-0100" num="0099">A third example embodiment of the present invention will be described in detail with reference to the drawings. <figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram illustrating a configuration of a conversion table generation device <b>100</b> according to the present example embodiment. The conversion table generation device <b>100</b> according to the present example embodiment includes a similar word extraction unit <b>101</b> and a conversion table generation unit <b>102</b>.</p><p id="p-0101" num="0100">The similar word extraction unit <b>101</b> extracts similar words similar to first words, each of the first words is included in a word group used in a dialogue. The word used in the dialogue is, for example, a word included in text data after conversion when the voice recognition device correctly converts voice into text data without erroneous recognition. The word used in the dialogue is, for example, a word input to the voice dialogue control device <b>40</b> when the conversion table generation device <b>100</b> is used in the voice dialogue control devices of the first example embodiment and the second example embodiment. The first word corresponds to a word of the conversion destination in the conversion table generation units of the first example embodiment and the second example embodiment. The similar word refers to a homonym and a similar-sounding word of the first word.</p><p id="p-0102" num="0101">The conversion table generation unit <b>102</b> associates a similar word, as a second word, similar to the plurality of first words among the extracted similar words with any one of the first words on the basis of the priority, and generates a conversion table for voice recognition with the second word as a conversion source and the first word as a conversion destination. The priority refers to, for example, a criterion based on the table of <figref idref="DRAWINGS">FIG. <b>9</b></figref> of the first example embodiment. The conversion table generation unit <b>102</b> associates one similar word with only one first word. On the other hand, a plurality of similar words may be associated with one first word as a second word. The conversion table generation unit <b>102</b> generates, for voice recognition, a conversion table in which the first word is a conversion destination and the second word is a conversion source by using a result of association of similar words. The conversion table is used, for example, when correcting the voice recognition result in the recognition result conversion devices <b>30</b> of the first example embodiment and the second example embodiment.</p><p id="p-0103" num="0102">Each of the conversion table generation device <b>60</b> of the second example embodiment and the conversion table generation device <b>70</b> of the third example embodiment is an example of the conversion table generation device <b>100</b> of the present example embodiment. The similar word extraction units <b>63</b> of the second example embodiment and the third example embodiment are examples of the similar word extraction unit <b>101</b> of the present example embodiment. Further, each of the conversion table generation unit <b>64</b> of the second example embodiment and the conversion table generation unit <b>71</b> of the third example embodiment are examples of the conversion table generation unit <b>102</b> of the present example embodiment.</p><p id="p-0104" num="0103">An example of the operation of the conversion table generation device <b>100</b> of the present example embodiment will be described. <figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram illustrating an operation flow of the conversion table generation device <b>100</b> according to the present example embodiment. The similar word extraction unit <b>101</b> of the conversion table generation device <b>100</b> extracts a similar word similar to the first word for each of the first words included in the word group used in the dialogue (Step S<b>101</b>). The similar word extraction unit <b>101</b> repeats the operation of extracting a similar word for one of the plurality of first words included in the word group and extracting a similar word for another first word, and extracts a similar word of each of the first words included in the word group.</p><p id="p-0105" num="0104">When the similar word is extracted for each of the first words, the conversion table generation unit <b>102</b> associates the similar word similar to the plurality of first words among the extracted similar words with any one of the first words as the second word on the basis of the priority (Step S<b>102</b>). When the similar word extracted by the conversion table generation unit <b>102</b> corresponds to a similar word of the plurality of first words, the conversion table generation unit <b>102</b> determines which first word the similar word is associated with, for example, using a criterion as illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>. This is because the similar word is used as the second word of the conversion source in the conversion table, but it is necessary that any one of the first words of the conversion destination is determined for each of the second words of the conversion source. When a similar word similar to the plurality of first words is associated with any one of the first words, the conversion table generation unit <b>102</b> generates a conversion table for correcting the voice recognition result of the second word as the conversion source and the first word as the conversion destination on the basis of the association result (Step S<b>103</b>).</p><p id="p-0106" num="0105">The conversion table generation device <b>100</b> according to the present example embodiment generates a conversion table used for correcting a recognition result in voice recognition as table data in a format in which the first word as a conversion destination is associated with the second word as a conversion source. The conversion table generated in this manner can be used when the word to be recognized as the first word in the voice recognition is erroneously recognized as a similar word similar to the first word, and when the erroneously recognized similar word is the second word, the word is converted into the first word that is a correct word. Therefore, the accuracy of the voice recognition can be improved by correcting the voice recognition result using the conversion table generated by the conversion table generation device <b>100</b> of the present example embodiment.</p><p id="p-0107" num="0106">The conversion table generation device <b>100</b> of the present example embodiment determines which first word the similar word of the first word that is the word of the conversion destination is to be the conversion source by using the priority criterion based on the table illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>. Therefore, the conversion table generation unit <b>102</b> can automatically associate each of the similar words of the first words extracted by the similar word extraction unit <b>101</b> with any one of the first words to generate the conversion table in which the first word is the conversion destination and the second word that is the similar word of the first word is the conversion source. Therefore, the conversion table generation device <b>100</b> of the present example embodiment can automatically generate a conversion table used when replacing a word erroneously recognized in voice recognition. As a result, by using the conversion table generation device <b>100</b> of the present example embodiment, it is possible to suppress the workload necessary for generating the conversion table for correcting the voice recognition result.</p><p id="p-0108" num="0107">Each processing in the conversion table generation device according to the first to third example embodiments can be performed by executing a computer program on a computer. <figref idref="DRAWINGS">FIG. <b>16</b></figref> illustrates an example of a configuration of a computer <b>200</b> that executes a computer program for performing each processing in the conversion table generation device. The computer <b>200</b> includes a CPU <b>201</b>, a memory <b>202</b>, a storage device <b>203</b>, and an interface (I/F) unit <b>204</b>.</p><p id="p-0109" num="0108">The CPU <b>201</b> reads and executes the computer program for performing each processing from the storage device <b>203</b>. The arithmetic processing unit that executes the computer program may be configured by a combination of a CPU and a GPU instead of the CPU <b>201</b>. The memory <b>202</b> includes a dynamic random access memory (DRAM) or the like, and temporarily stores the computer program executed by the CPU <b>201</b> and data being processed. The storage device <b>203</b> stores the computer program executed by the CPU <b>201</b>. The storage device <b>203</b> includes, for example, a non-volatile semiconductor storage device. As the storage device <b>203</b>, another storage device such as a hard disk drive may be used. The I/F unit <b>204</b> is an interface that inputs and outputs data to and from another unit of the voice dialogue system, a terminal of the network to be managed, and the like. The computer <b>200</b> may further include a communication module that communicates with another information processing device via a communication network. In addition, the voice recognition devices <b>20</b>, the recognition result conversion devices <b>30</b>, and the voice dialogue control devices <b>40</b> of the first example embodiment and the second example embodiment can have similar configurations.</p><p id="p-0110" num="0109">The computer program performed in each processing can also be stored in a recording medium and distributed. As the recording medium, for example, a magnetic tape for data recording or a magnetic disk such as a hard disk can be used. As the recording medium, an optical disk such as a compact disc read only memory (CD-ROM) can also be used. A non-volatile semiconductor storage device may be used as a recording medium.</p><p id="p-0111" num="0110">Some or all of the above example embodiments may be described as the following supplementary notes, but are not limited to the following.</p><p id="p-0112" num="0111">(Supplementary Note 1)</p><p id="p-0113" num="0112">A conversion table generation device including:</p><p id="p-0114" num="0113">a similar word extraction means configured to extract a similar word similar to a first word for each of the first words included in a word group used in a dialogue; and</p><p id="p-0115" num="0114">a conversion table generation means configured to perform voice recognition that associates a similar word similar to a plurality of the first words among the extracted similar words as a second word with any one of the first words based on priority, and generate a conversion table having the second word as a conversion source and the first word as a conversion destination.</p><p id="p-0116" num="0115">(Supplementary Note 2)</p><p id="p-0117" num="0116">The conversion table generation device according to Supplementary Note 1, wherein</p><p id="p-0118" num="0117">the conversion table generation means determines the priority based on similarity between the first word and a vowel or a consonant of the similar word.</p><p id="p-0119" num="0118">(Supplementary Note 3)</p><p id="p-0120" num="0119">The conversion table generation device according to Supplementary Note 2, wherein</p><p id="p-0121" num="0120">the conversion table generation means refers to a table in which characters having vowels and consonants in common are arranged in rows and columns, and associates the similar word similar to the plurality of first words with the first word having a matching row or column.</p><p id="p-0122" num="0121">(Supplementary Note 4)</p><p id="p-0123" num="0122">The conversion table generation device according to any one of Supplementary Notes 1 to 3, further including:</p><p id="p-0124" num="0123">a log data acquisition means configured to acquire a log of an operation of replacing and correcting the first word included in a result of voice recognition with the second word using the conversion table, in which</p><p id="p-0125" num="0124">the conversion table generation means updates the conversion table based on the log.</p><p id="p-0126" num="0125">(Supplementary Note 5)</p><p id="p-0127" num="0126">The conversion table generation device according to any one of Supplementary Notes 1 to 4, further including:</p><p id="p-0128" num="0127">a data acquisition means configured to acquire data including a word group used in a dialogue; and</p><p id="p-0129" num="0128">an analysis means configured to extract a word from data including a word group used in the dialogue, in which</p><p id="p-0130" num="0129">the similar word extraction means extracts the similar word for each word extracted by the analysis means.</p><p id="p-0131" num="0130">(Supplementary Note 6)</p><p id="p-0132" num="0131">A voice dialogue system including:</p><p id="p-0133" num="0132">a conversion table generation device according to any one of</p><p id="p-0134" num="0133">Supplementary Notes 1 to 5;</p><p id="p-0135" num="0134">a voice recognition means configured to convert input voice data into a sentence by voice recognition;</p><p id="p-0136" num="0135">a recognition result conversion means configured to replace the second word with the first word based on the conversion table when the second word included in the conversion table is detected from the sentence recognized by the voice recognition means; and</p><p id="p-0137" num="0136">a voice dialogue control means configured to generate a sentence for response to a sentence output from the recognition result conversion means.</p><p id="p-0138" num="0137">(Supplementary Note 7)</p><p id="p-0139" num="0138">The voice dialogue system according to Supplementary Note 6, further including:</p><p id="p-0140" num="0139">a voice capture means configured to sample a voice of a user and output the voice as voice data; and</p><p id="p-0141" num="0140">a voice synthesis means configured to convert the sentence for to response output by the voice dialogue control means into voice data and outputs the voice data as a voice.</p><p id="p-0142" num="0141">(Supplementary Note 8)</p><p id="p-0143" num="0142">A conversion table generation method including:</p><p id="p-0144" num="0143">extracting a similar word similar to a first word for each of the first words included in a word group used in a dialogue; and</p><p id="p-0145" num="0144">associating a similar word similar to a plurality of the first words among the extracted similar words as a second word with any one of the first words based on priority, and generate, for voice recognition, a conversion table having the second word as a conversion source and the first word as a conversion destination.</p><p id="p-0146" num="0145">(Supplementary Note 9)</p><p id="p-0147" num="0146">The conversion table generation method according to Supplementary Note 8, wherein</p><p id="p-0148" num="0147">the priority is determined based on similarity between the first word and a vowel or consonant of the similar word.</p><p id="p-0149" num="0148">(Supplementary Note 10)</p><p id="p-0150" num="0149">The conversion table generation method according to Supplementary Note 8 or 9, wherein</p><p id="p-0151" num="0150">the conversion table generation method refers to a table in which characters having vowels and consonants in common are arranged in rows and columns, and associates the similar word similar to the plurality of first words with the first word having a matching row or column.</p><p id="p-0152" num="0151">(Supplementary Note 11)</p><p id="p-0153" num="0152">The conversion table generation method according to any one of Supplementary Notes 8 to 10, further including:</p><p id="p-0154" num="0153">acquiring a log of an operation of replacing and correcting the first word included in a result of voice recognition with the second word using the conversion table; and</p><p id="p-0155" num="0154">updating the conversion table based on the log.</p><p id="p-0156" num="0155">(Supplementary Note 12)</p><p id="p-0157" num="0156">The conversion table generation method according to any one of Supplementary Notes 8 to 11, further including:</p><p id="p-0158" num="0157">acquiring data including a word group used in a dialogue;</p><p id="p-0159" num="0158">extracting a word from data including a word group used in the dialogue; and</p><p id="p-0160" num="0159">extracting the similar word for each extracted word.</p><p id="p-0161" num="0160">(Supplementary Note 13)</p><p id="p-0162" num="0161">A recognition result conversion method including:</p><p id="p-0163" num="0162">extracting a similar word similar to a first word for each of the first words included in a word group used in a dialogue;</p><p id="p-0164" num="0163">associating a similar word similar to a plurality of the first words among the extracted similar words as a second word with any one of the first words based on priority, and generating a conversion table having the second word as a conversion source and the first word as a conversion destination; and</p><p id="p-0165" num="0164">replacing, when the second word included in the conversion table is detected from a sentence recognized by voice recognition, the second word with the first word based on the conversion table.</p><p id="p-0166" num="0165">(Supplementary Note 14)</p><p id="p-0167" num="0166">A voice dialogue method including:</p><p id="p-0168" num="0167">extracting a similar word similar to a first word for each of the first words included in a word group used in a dialogue;</p><p id="p-0169" num="0168">associating a similar word similar to a plurality of the first words among the extracted similar words as a second word with any one of the first words based on priority, and generating a conversion table having the second word as a conversion source and the first word as a conversion destination;</p><p id="p-0170" num="0169">converting input voice data into a sentence by voice recognition;</p><p id="p-0171" num="0170">replacing, when the second word included in the conversion table is detected from the sentence converted from the voice data, the second word with the first word based on the conversion table; and</p><p id="p-0172" num="0171">generating a sentence for responding to a sentence in which the second word is replaced with the first word.</p><p id="p-0173" num="0172">(Supplementary Note 15)</p><p id="p-0174" num="0173">A recording medium recording a computer program for causing a computer to execute:</p><p id="p-0175" num="0174">extracting a similar word similar to a first word for each of the first words included in a word group used in a dialogue; and</p><p id="p-0176" num="0175">associating a similar word similar to a plurality of the first words among the extracted similar words as a second word with any one of the first words based on priority, and generating, for voice recognition, a conversion table having the second word as a conversion source and the first word as a conversion destination.</p><p id="p-0177" num="0176">The present invention has been described above using the above-described example embodiments as schematic examples. However, the present invention is not limited to the above-described example embodiments. That is, the present invention can apply various aspects that can be understood by those skilled in the art within the scope of the present invention.</p><heading id="h-0014" level="1">REFERENCE SIGNS LIST</heading><p id="p-0178" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0177"><b>10</b> voice capture device</li>    <li id="ul0001-0002" num="0178"><b>20</b> voice recognition device</li>    <li id="ul0001-0003" num="0179"><b>30</b> recognition result conversion device</li>    <li id="ul0001-0004" num="0180"><b>31</b> recognition result conversion unit</li>    <li id="ul0001-0005" num="0181"><b>32</b> conversion table storage unit</li>    <li id="ul0001-0006" num="0182"><b>40</b> voice dialogue control device</li>    <li id="ul0001-0007" num="0183"><b>50</b> voice synthesis device</li>    <li id="ul0001-0008" num="0184"><b>60</b> conversion table generation device</li>    <li id="ul0001-0009" num="0185"><b>61</b> data acquisition unit</li>    <li id="ul0001-0010" num="0186"><b>62</b> analysis unit</li>    <li id="ul0001-0011" num="0187"><b>63</b> similar word extraction unit</li>    <li id="ul0001-0012" num="0188"><b>64</b> conversion table generation unit</li>    <li id="ul0001-0013" num="0189"><b>65</b> conversion table output unit</li>    <li id="ul0001-0014" num="0190"><b>66</b> dictionary data storage unit</li>    <li id="ul0001-0015" num="0191"><b>70</b> conversion table generation device</li>    <li id="ul0001-0016" num="0192"><b>71</b> conversion table generation unit</li>    <li id="ul0001-0017" num="0193"><b>72</b> log data acquisition unit</li>    <li id="ul0001-0018" num="0194"><b>73</b> conversion table storage unit</li>    <li id="ul0001-0019" num="0195"><b>101</b> similar word extraction unit</li>    <li id="ul0001-0020" num="0196"><b>102</b> conversion table generation unit</li>    <li id="ul0001-0021" num="0197"><b>200</b> computer</li>    <li id="ul0001-0022" num="0198"><b>201</b> CPU</li>    <li id="ul0001-0023" num="0199"><b>202</b> memory</li>    <li id="ul0001-0024" num="0200"><b>203</b> storage device</li>    <li id="ul0001-0025" num="0201"><b>204</b> I/F unit</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A conversion table generation device comprising:<claim-text>at least one memory storing instructions; and</claim-text><claim-text>at least one processor configured to access the at least one memory and execute the instructions to:</claim-text><claim-text>extract a similar word similar to a first word for each of the first words included in a word group used in a dialogue;</claim-text><claim-text>perform voice recognition that associates a similar word similar to a plurality of the first words among the extracted similar words as a second word with any one of the first words based on priority; and</claim-text><claim-text>generate a conversion table having the second word as a conversion source and the first word as a conversion destination.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The conversion table generation device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the at least one processor is further configured to execute the instructions to:</claim-text><claim-text>determine the priority based on similarity between the first word and a vowel or a consonant of the similar word.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The conversion table generation device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the at least one processor is further configured to execute the instructions to:</claim-text><claim-text>refer to a table in which characters having vowels and consonants in common are arranged in rows and columns; and</claim-text><claim-text>associate the similar word similar to the plurality of first words with the first word having a matching row or column.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The conversion table generation device according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein<claim-text>the at least one processor is further configured to execute the instructions to:</claim-text><claim-text>acquire a log of an operation of replacing and correcting the first word included in a result of voice recognition with the second word using the conversion table; and</claim-text><claim-text>update the conversion table based on the log.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The conversion table generation device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>acquire data including a word group used in a dialogue;</claim-text><claim-text>extract a word from data including a word group used in the dialogue; and</claim-text><claim-text>extract the similar word for each extracted word.</claim-text></claim-text></claim><claim id="CLM-006-7" num="006-7"><claim-text><b>6</b>-<b>7</b>. (canceled)</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A conversion table generation method comprising:<claim-text>extracting a similar word similar to a first word for each of the first words included in a word group used in a dialogue; and</claim-text><claim-text>associating a similar word similar to a plurality of the first words among the extracted similar words as a second word with any one of the first words based on priority, and generate, for voice recognition, a conversion table having the second word as a conversion source and the first word as a conversion destination.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The conversion table generation method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the priority is determined based on similarity between the first word and a vowel or consonant of the similar word.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The conversion table generation method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the conversion table generation method refers to a table in which characters having vowels and consonants in common are arranged in rows and columns, and associates the similar word similar to the plurality of first words with the first word having a matching row or column.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The conversion table generation method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, comprising:<claim-text>acquiring a log of an operation of replacing and correcting the first word included in a result of voice recognition with the second word using the conversion table; and</claim-text><claim-text>updating the conversion table based on the log.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The conversion table generation method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:<claim-text>acquiring data including a word group used in a dialogue;</claim-text><claim-text>extracting a word from data including a word group used in the dialogue; and</claim-text><claim-text>extracting the similar word for each extracted word.</claim-text></claim-text></claim><claim id="CLM-13-14" num="13-14"><claim-text><b>13</b>-<b>14</b>. (canceled)</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A non-transitory recording medium recording a computer program for causing a computer to execute:<claim-text>extracting a similar word similar to a first word for each of the first words included in a word group used in a dialogue; and</claim-text><claim-text>associating a similar word similar to a plurality of the first words among the extracted similar words as a second word with any one of the first words based on priority, and generating, for voice recognition, a conversion table having the second word as a conversion source and the first word as a conversion destination.</claim-text></claim-text></claim></claims></us-patent-application>
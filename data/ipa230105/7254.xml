<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007255A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007255</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17781732</doc-number><date>20201218</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>124</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>65</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>184</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>124</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>65</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>184</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">IMAGE PROCESSING DEVICE AND METHOD</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>62950055</doc-number><date>20191218</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Sony Group Corporation</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>TSUKUBA</last-name><first-name>Takeshi</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Sony Group Corporation</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/047338</doc-number><date>20201218</date></document-id><us-371c12-date><date>20220602</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present disclosure relates to an image processing device and method for enabling control of a value of a quantization parameter within a desired range.</p><p id="p-0002" num="0000">A quantization parameter is corrected on the basis of a parameter regarding adaptive color transform and further correcting the quantization parameter on the basis of a parameter regarding transform skip, and coefficient data of an image to be encoded is quantized using a corrected quantization parameter that is the quantization parameter that has been corrected. The present disclosure can be applied to, for example, an image processing device, an image encoding device, an image decoding device, a transmission device, a reception device, a transmission/reception device, an information processing device, an imaging device, a reproduction device, an electronic device, an image processing method, an information processing method, or the like.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="96.35mm" wi="158.75mm" file="US20230007255A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="235.03mm" wi="152.06mm" orientation="landscape" file="US20230007255A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="235.03mm" wi="152.06mm" orientation="landscape" file="US20230007255A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="159.77mm" wi="153.59mm" file="US20230007255A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="235.03mm" wi="152.06mm" orientation="landscape" file="US20230007255A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="160.02mm" wi="153.59mm" file="US20230007255A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="235.03mm" wi="147.49mm" orientation="landscape" file="US20230007255A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="177.80mm" wi="153.59mm" file="US20230007255A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="235.03mm" wi="152.06mm" orientation="landscape" file="US20230007255A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="160.10mm" wi="155.96mm" file="US20230007255A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="235.03mm" wi="158.07mm" orientation="landscape" file="US20230007255A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="235.03mm" wi="149.61mm" orientation="landscape" file="US20230007255A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="235.03mm" wi="152.06mm" orientation="landscape" file="US20230007255A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="192.70mm" wi="157.73mm" file="US20230007255A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="199.56mm" wi="117.26mm" file="US20230007255A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="235.03mm" wi="151.64mm" orientation="landscape" file="US20230007255A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="235.03mm" wi="149.61mm" orientation="landscape" file="US20230007255A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="235.03mm" wi="152.06mm" orientation="landscape" file="US20230007255A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="185.76mm" wi="107.70mm" file="US20230007255A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="202.18mm" wi="119.72mm" file="US20230007255A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="157.40mm" wi="130.13mm" orientation="landscape" file="US20230007255A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0001">The present disclosure relates to an image processing device and method, and particularly relates to an image processing device and method for enabling control of a value of a quantization parameter within a desired range.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0004" num="0002">In the past, there has been proposed an encoding method for deriving a prediction residual of a moving image, performing coefficient transform, quantizing, and encoding (for example, see Non-Patent Documents 1 and 2). Furthermore, as an encoding tool for improving encoding efficiency in RGB444, adaptive color transform (ACT) for executing RGB-to-YCgCo transform on a residual domain has been proposed (see, for example, Non-Patent Document 3).</p><p id="p-0005" num="0003">Furthermore, Non-Patent Document 3 has proposed processing of correcting a quantization parameter qP to be applied to a residual of each component by (dqPY, dqPCg, dqPCo)=(&#x2212;5, &#x2212;5, &#x2212;3) in consideration of transform of a dynamic range of a signal between the residual before the transform (C0, C1, C2) and the residual after the transform (C0&#x2032;, C1&#x2032;, C2&#x2032;). Non-Patent Document 1 discloses a method of correcting a quantization parameter based on application of transform skip and adaptive color transform.</p><heading id="h-0003" level="1">CITATION LIST</heading><heading id="h-0004" level="1">Non-Patent Document</heading><p id="p-0006" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0004">Non-Patent Document 1: Benjamin Bross, Jianle Chen, Shan Liu, Ye-Kui Wang, &#x201c;Versatile Video Coding (Draft 7)&#x201d;, JVET-P2001-vE, Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11 16th Meeting: Feneva, CH, 1-11 Oct. 2019</li>    <li id="ul0001-0002" num="0005">Non-Patent Document 2: Jianle Chen, Yan Ye, Seung Hwan Kim, &#x201c;Algorithm description for Versatile Video Coding and Test Model 7 (VTM 7)&#x201d;, JVET-P2002-v1, Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11 16th Meeting: Geneva, CH, 1-11 Oct. 2019</li>    <li id="ul0001-0003" num="0006">Non-Patent Document 3: Xiaoyu Xiu, Yi-Wen Chen, Tsung-Chuan Ma, Hong-Jheng Jhu, Xianglin Wang, &#x201c;Support of adaptive color transform for 444 video coding in VVC&#x201d;, JVET-P0517_r1, Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11 16th Meeting: Geneva, CH, 1-11 Oct. 2019</li></ul></p><heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading><heading id="h-0006" level="1">Problems to be Solved by the Invention</heading><p id="p-0007" num="0007">However, in the case of the method disclosed in Non-Patent Document 1, after correction of the quantization parameter based on a parameter regarding the transform skip is executed, correction of the quantization parameter based on a parameter regarding the adaptive color transform is executed. In the correction of the quantization parameter based on the parameter regarding the transform skip, a value of the quantization parameter is clipped within a desired range. Furthermore, in the correction of the quantization parameter based on the parameter regarding the adaptive color transform, a predetermined correction amount is added. Therefore, in this method, the range that can be taken by the value of the corrected quantization parameter cannot be controlled.</p><p id="p-0008" num="0008">The present disclosure has been made in view of such a situation, and enables control of a value of a quantization parameter within a desired range.</p><heading id="h-0007" level="1">Solutions to Problems</heading><p id="p-0009" num="0009">An image processing device according to one aspect of the present technology is an image processing device that includes: a quantization parameter correction unit configured to correct a quantization parameter on the basis of a parameter regarding adaptive color transform and further correct the quantization parameter on the basis of a parameter regarding transform skip; and a quantization unit configured to quantize coefficient data of an image to be encoded by using a corrected quantization parameter that is the quantization parameter corrected by the quantization parameter correction unit.</p><p id="p-0010" num="0010">An image processing method according to one aspect of the present technology is an image processing method that includes: correcting a quantization parameter on the basis of a parameter regarding adaptive color transform and further correcting the quantization parameter on the basis of a parameter regarding transform skip; and quantizing coefficient data of an image to be encoded by using a corrected quantization parameter that is the quantization parameter that has been corrected.</p><p id="p-0011" num="0011">An image processing device according to another aspect of the present technology is an image processing device that includes: a quantization parameter correction unit configured to correct a quantization parameter on the basis of a parameter regarding adaptive color transform and further correct the quantization parameter on the basis of a parameter regarding transform skip; and an inverse quantization unit configured to inversely quantize quantized coefficient data that is obtained by quantizing coefficient data of an image by using a corrected quantization parameter that is the quantization parameter corrected by the quantization parameter correction unit.</p><p id="p-0012" num="0012">An image processing method according to another aspect of the present technology is an image processing method that includes: correcting a quantization parameter on the basis of a parameter regarding adaptive color transform and further correcting the quantization parameter on the basis of a parameter regarding transform skip; and inversely quantizing quantized coefficient data that is obtained by quantizing coefficient data of an image by using a corrected quantization parameter that is the quantization parameter that has been corrected.</p><p id="p-0013" num="0013">In the image processing device and method according to one aspect of the present technology, a quantization parameter is corrected on the basis of a parameter regarding adaptive color transform and the quantization parameter is further corrected on the basis of a parameter regarding transform skip, and coefficient data of an image to be encoded is quantized by using a corrected quantization parameter that is the quantization parameter that has been corrected.</p><p id="p-0014" num="0014">In the image processing device and method according to another aspect of the present technology, a quantization parameter is corrected on the basis of a parameter regarding adaptive color transform and the quantization parameter is further corrected on the basis of a parameter regarding transform skip, and quantized coefficient data that is obtained by quantizing coefficient data of an image is inversely quantized by using a corrected quantization parameter that is the quantization parameter that has been corrected.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0008" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0015" num="0015"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram for describing an example of a method of correcting a quantization parameter.</p><p id="p-0016" num="0016"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating a main configuration example of a quantization parameter correction device.</p><p id="p-0017" num="0017"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart illustrating an example of a flow of quantization parameter correction processing.</p><p id="p-0018" num="0018"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram illustrating a main configuration example of the quantization parameter correction device.</p><p id="p-0019" num="0019"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart illustrating an example of a flow of the quantization parameter correction processing.</p><p id="p-0020" num="0020"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram illustrating a main configuration example of the quantization parameter correction device.</p><p id="p-0021" num="0021"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart illustrating an example of a flow of the quantization parameter correction processing.</p><p id="p-0022" num="0022"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram illustrating a main configuration example of the quantization parameter correction device.</p><p id="p-0023" num="0023"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example of a flow of the quantization parameter correction processing.</p><p id="p-0024" num="0024"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram illustrating a main configuration example of an image encoding device.</p><p id="p-0025" num="0025"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram illustrating a main configuration example of a transform quantization unit.</p><p id="p-0026" num="0026"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a block diagram illustrating a main configuration example of a quantization unit.</p><p id="p-0027" num="0027"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flowchart illustrating an example of a flow of image encoding processing.</p><p id="p-0028" num="0028"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart for describing an example of a flow of transform quantization processing.</p><p id="p-0029" num="0029"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart for describing an example of a flow of quantization processing.</p><p id="p-0030" num="0030"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a block diagram illustrating a main configuration example of an image decoding device.</p><p id="p-0031" num="0031"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a block diagram illustrating a main configuration example of an inverse quantization inverse transform unit.</p><p id="p-0032" num="0032"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a block diagram illustrating a main configuration example of an inverse quantization unit.</p><p id="p-0033" num="0033"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a flowchart illustrating an example of a flow of image decoding processing.</p><p id="p-0034" num="0034"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a flowchart illustrating an example of a flow of inverse quantization inverse transform processing.</p><p id="p-0035" num="0035"><figref idref="DRAWINGS">FIG. <b>21</b></figref> is a flowchart illustrating an example of a flow of inverse quantization processing.</p><p id="p-0036" num="0036"><figref idref="DRAWINGS">FIG. <b>22</b></figref> is a block diagram illustrating a main configuration example of a computer.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0009" level="1">MODE FOR CARRYING OUT THE INVENTION</heading><p id="p-0037" num="0037">Hereinafter, modes for implementing the present disclosure (hereinafter referred to as embodiments) will be described. Note that description will be given in the following order.</p><p id="p-0038" num="0038">1. Correction of Quantization Parameter</p><p id="p-0039" num="0039">2. First Embodiment (Quantization Parameter Correction Device)</p><p id="p-0040" num="0040">3. Second Embodiment (Quantization Parameter Correction Device)</p><p id="p-0041" num="0041">4. Third Embodiment (Quantization Parameter Correction Device)</p><p id="p-0042" num="0042">5. Fourth Embodiment (Quantization Parameter Correction Device)</p><p id="p-0043" num="0043">6. Fifth Embodiment (Image Encoding Device)</p><p id="p-0044" num="0044">7. Sixth Embodiment (Image Decoding Device)</p><p id="p-0045" num="0045">8. Supplementary Note</p><heading id="h-0010" level="1">1. Correction of Quantization Parameter</heading><p id="p-0046" num="0046">&#x3c;Documents and the Like that Support Technical Content and Technical Terms&#x3e;</p><p id="p-0047" num="0047">The scope disclosed in the present technology includes not only the content described in the embodiments but also the content described in the following non-patent documents and the like and the content of other documents referred to in the following non-patent documents that are known at the time of filing the application.<ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0048">Non-Patent Document 1: (described above)</li>    <li id="ul0002-0002" num="0049">Non-Patent Document 2: (described above)</li>    <li id="ul0002-0003" num="0050">Non-Patent Document 3: (described above)</li>    <li id="ul0002-0004" num="0051">Non-Patent Document 4: Recommendation ITU-T H.264 (April 2017) &#x201c;Advanced video coding for generic audiovisual services&#x201d;, April 2017</li>    <li id="ul0002-0005" num="0052">Non-Patent Document 5: Recommendation ITU-T H.265 (February 2018) &#x201c;High efficiency video coding&#x201d;, February 2018</li></ul></p><p id="p-0048" num="0053">That is, the content described in Non-Patent Documents above also serves as a basis for determining the support requirements. For example, the quad-tree block structure described in Non-Patent Documents above and the quad tree plus binary tree (QTBT) block structure fall within the disclosure range of the present technology and satisfy the support requirements of the claims even in a case where these pieces of content are not directly described in the examples. Furthermore, for example, technical terms such as parsing, syntax, and semantics are similarly fall within the disclosure range of the present technology and satisfy the support requirements of claims even in a case where these technical terms are not directly described in the examples.</p><p id="p-0049" num="0054">Furthermore, in the present specification, a &#x201c;block&#x201d; (not a block representing a processing unit) used for description as a partial region or a unit of processing of an image (picture) indicates an arbitrary partial region in a picture unless otherwise specified, and the size, shape, characteristics, and the like of the block are not limited. For example, the &#x201c;block&#x201d; includes an arbitrary partial region (unit of processing) such as a transform block (TB), a transform unit (TU), a prediction block (PB), a prediction unit (PU), a smallest coding unit (SCU), a coding unit (CU), a largest coding unit (LCU), a coding tree block (CTB), a coding tree unit (CTU), a transform block, a subblock, a macro block, a tile, or a slice, described in Non-Patent Documents above.</p><p id="p-0050" num="0055">Furthermore, in specifying the size of such a block, not only the block size is directly specified but also the block size may be indirectly specified. For example, the block size may be specified using identification information for identifying the size. Furthermore, for example, the block size may be specified by a ratio or a difference from the size of a reference block (for example, an LCU, an SCU, or the like). For example, in a case of transmitting information for specifying the block size as a syntax element or the like, information for indirectly specifying the size as described above may be used as the information. With the configuration, the amount of information can be reduced, and the encoding efficiency can be improved in some cases. Furthermore, the specification of the block size also includes specification of a range of the block size (for example, specification of a range of an allowable block sizes, or the like).</p><p id="p-0051" num="0056">Furthermore, in the present specification, encoding includes not only the whole processing of transforming an image into a bitstream but also part of the processing. For example, encoding includes not only processing that includes prediction processing, orthogonal transform, quantization, arithmetic encoding, and the like but also processing that collectively refers to quantization and arithmetic encoding, processing including prediction processing, quantization, and arithmetic encoding, and the like. Similarly, decoding includes not only the whole processing of transforming a bitstream into an image but also part of the processing. For example, decoding includes not only processing including inverse arithmetic decoding, inverse quantization, inverse orthogonal transform, prediction processing, and the like but also processing including inverse arithmetic decoding and inverse quantization, processing including inverse arithmetic decoding, inverse quantization, and prediction processing, and the like.</p><p id="p-0052" num="0057">&#x3c;Adaptive Color Transform&#x3e;</p><p id="p-0053" num="0058">Non-Patent Document 3 has proposed, as an encoding tool for improving encoding efficiency in RGB444, adaptive color transform (ACT) for executing RGB-to-YCgCo transform on a residual domain. The following expression (1) expresses the RGB-to-YCgCo transform. Furthermore, the expression (2) expresses inverse transform (YCgCo-RGB transform). In the expressions (1) and (2), coefficients C0, C1, and C2 correspond to R, G, and B, respectively. C0&#x2032;, C1&#x2032;, and C2&#x2032; correspond to Y, Cg, and Co, respectively.</p><p id="p-0054" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mo>[</mo>      <mtable>       <mtr>        <mtd>         <mrow>          <mi>C</mi>          <mo>&#x2062;</mo>          <msup>           <mn>0</mn>           <mo>&#x2032;</mo>          </msup>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mi>C</mi>          <mo>&#x2062;</mo>          <msup>           <mn>1</mn>           <mo>&#x2032;</mo>          </msup>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mi>C</mi>          <mo>&#x2062;</mo>          <msup>           <mn>2</mn>           <mo>&#x2032;</mo>          </msup>         </mrow>        </mtd>       </mtr>      </mtable>      <mo>]</mo>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <mo>[</mo>       <mtable>        <mtr>         <mtd>          <mn>2</mn>         </mtd>         <mtd>          <mn>1</mn>         </mtd>         <mtd>          <mn>1</mn>         </mtd>        </mtr>        <mtr>         <mtd>          <mn>2</mn>         </mtd>         <mtd>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>         </mtd>         <mtd>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>         </mtd>        </mtr>        <mtr>         <mtd>          <mn>0</mn>         </mtd>         <mtd>          <mrow>           <mo>-</mo>           <mn>2</mn>          </mrow>         </mtd>         <mtd>          <mn>2</mn>         </mtd>        </mtr>       </mtable>       <mo>]</mo>      </mrow>      <mo>/</mo>      <mn>4</mn>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>1</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths><maths id="MATH-US-00001-2" num="00001.2"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mo>[</mo>      <mtable>       <mtr>        <mtd>         <mrow>          <mi>C</mi>          <mo>&#x2062;</mo>          <mn>0</mn>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mi>C</mi>          <mo>&#x2062;</mo>          <mn>1</mn>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mi>C</mi>          <mo>&#x2062;</mo>          <mn>2</mn>         </mrow>        </mtd>       </mtr>      </mtable>      <mo>]</mo>     </mrow>     <mo>=</mo>     <mrow>      <mrow>       <mo>[</mo>       <mtable>        <mtr>         <mtd>          <mn>1</mn>         </mtd>         <mtd>          <mn>1</mn>         </mtd>         <mtd>          <mn>0</mn>         </mtd>        </mtr>        <mtr>         <mtd>          <mn>1</mn>         </mtd>         <mtd>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>         </mtd>         <mtd>          <mn>1</mn>         </mtd>        </mtr>        <mtr>         <mtd>          <mn>1</mn>         </mtd>         <mtd>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>         </mtd>         <mtd>          <mn>1</mn>         </mtd>        </mtr>       </mtable>       <mo>]</mo>      </mrow>      <mo>[</mo>      <mtable>       <mtr>        <mtd>         <mrow>          <mi>C</mi>          <mo>&#x2062;</mo>          <msup>           <mn>0</mn>           <mo>&#x2032;</mo>          </msup>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mi>C</mi>          <mo>&#x2062;</mo>          <msup>           <mn>1</mn>           <mo>&#x2032;</mo>          </msup>         </mrow>        </mtd>       </mtr>       <mtr>        <mtd>         <mrow>          <mi>C</mi>          <mo>&#x2062;</mo>          <msup>           <mn>2</mn>           <mo>&#x2032;</mo>          </msup>         </mrow>        </mtd>       </mtr>      </mtable>      <mo>]</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>2</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0055" num="0059">As illustrated in the expressions (1) and (2), by the adaptive color transform, an RGB signal can be transformed into a YCgCo signal equivalent to a YCbCr signal only by simple shift operation and addition/subtraction. The same similarly applies to inverse transform. Therefore, by applying such adaptive color transform, redundancy between components can be easily reduced, and reduction in encoding efficiency can be suppressed.</p><p id="p-0056" num="0060">Furthermore, in the case where this adaptive color transform is applied, processing of correcting the residual (C0, C1, C2) before transform and the quantization parameter qP to be applied to the residual of each component by the correction amount (dqPY, dqPCg, dqPCo)=(&#x2212;5, &#x2212;5, &#x2212;3) of the quantization parameter of each component has been executed by the RGB-YCgCo transform. This processing takes into consideration transform of a dynamic range of the signal with the residual (C0&#x2032;, C1&#x2032;, C2&#x2032;) after transform.</p><p id="p-0057" num="0061">&#x3c;Transform Skip&#x3e;</p><p id="p-0058" num="0062">By the way, Non-Patent Document 1 discloses transform skip that is a mode for skipping (omitting) orthogonal transform processing. In the present disclosure, a case where the transform skip is not applied is also referred to as non-transform skip.</p><p id="p-0059" num="0063">&#x3c;Correction of Quantization Parameter by Transform Skip and Adaptive Color Transform&#x3e;</p><p id="p-0060" num="0064">Non-Patent Document 1 discloses a method of correcting a quantization parameter based on application of transform skip and adaptive color transform. In this method, the correction of the quantization parameter is controlled according to whether or not to apply the transform skip and whether or not to apply the adaptive color transform. For example, in a case where the adaptive color transform is applicable and the transform skip is applied, the correction of the quantization parameter is executed as in the following expression (3). In contrast, in a case where the adaptive color transform is applicable and non-transform skip is applied (that is, the transform skip is not applied), the correction of the quantization parameter is executed as in the following expression (4).</p><p id="p-0061" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP=Max(QpPrimeTsMin,qP)&#x2212;(cu_act_enabled_flag[<i>xTbY</i>][<i>yTbY</i>]?(<i>c</i>Idx&#x3c;2?5:3):0)&#x2003;&#x2003; (3)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0062" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP=qP&#x2212;(cu_act_enabled_flag[<i>xTbY</i>][<i>yTbY</i>]?(<i>c</i>Idx&#x3c;2?5:3):0)&#x2003;&#x2003; (4)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0063" num="0065">As illustrated in the expression (3), in the case where the transform skip is applied, a lower limit of the quantization parameter is first clipped with a minimum value (QpPrimeTsMin) of the quantization parameter in the case of the transform skip. Thereafter, a correction amount corresponding to a component to be processed is added to a result of the clip according to a value of cu_act_enabled_flag. cu_act_enabled_flag is flag information in units of CUs indicating whether or not to apply the adaptive color transform. A case where cu_act_enabled_flag is true (for example, &#x201c;1&#x201d;) indicates that the adaptive color transform is applied. A case where cu_act_enabled_flag is false (for example, &#x201c;0&#x201d;) indicates that the adaptive color transform is not applied. That is, after the correction based on the parameter regarding the transform skip is executed, the correction based on the parameter regarding the adaptive color transform is executed.</p><p id="p-0064" num="0066">In the case where the non-transform skip is applied as illustrated in the expression (4), the correction based on the parameter regarding the transform skip is executed, and then the correction based on the parameter regarding the adaptive color transform is executed, similarly to the case of the expression (3). Note that, in this case, the above-described clip processing is skipped (omitted) in the correction based on the parameter regarding the transform skip. In other words, the lower limit of the quantization parameter is clipped with the minimum value that can be taken on the basis of a specification of hardware, software, or the like.</p><p id="p-0065" num="0067">As described above, in the correction method described in Non-Patent Document 1, since the correction amount is added after the clip processing, the range that can be taken by the value of the corrected quantization parameter cannot be controlled.</p><p id="p-0066" num="0068">&#x3c;Priority of Correction of Quantization Parameter by Adaptive Color Transform&#x3e;</p><p id="p-0067" num="0069">Therefore, as illustrated in the top row of the table illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the quantization parameter is corrected by transform skip after the quantization parameter by adaptive color transform is corrected.</p><p id="p-0068" num="0070">For example, in an image processing method, a quantization parameter is corrected on the basis of a parameter regarding adaptive color transform and the quantization parameter is further corrected on the basis of a parameter regarding transform skip, and coefficient data of an image to be encoded is quantized by using a corrected quantization parameter that is the quantization parameter that has been corrected.</p><p id="p-0069" num="0071">Furthermore, for example, an image processing device includes a quantization parameter correction unit configured to correct a quantization parameter on the basis of a parameter regarding adaptive color transform and further correct the quantization parameter on the basis of a parameter regarding transform skip, and a quantization unit configured to quantize coefficient data of an image to be encoded by using a corrected quantization parameter that is the quantization parameter corrected by the quantization parameter correction unit.</p><p id="p-0070" num="0072">For example, in an image processing method, a quantization parameter is corrected on the basis of a parameter regarding adaptive color transform and the quantization parameter is further corrected on the basis of a parameter regarding transform skip, and quantized coefficient data that is obtained by quantizing coefficient data of an image is inversely quantized by using a corrected quantization parameter that is the quantization parameter that has been corrected.</p><p id="p-0071" num="0073">Furthermore, for example, an image processing device includes a quantization parameter correction unit configured to correct a quantization parameter on the basis of a parameter regarding adaptive color transform and further correct the quantization parameter on the basis of a parameter regarding transform skip, and an inverse quantization unit configured to inversely quantize quantized coefficient data that is obtained by quantizing coefficient data of an image by using a corrected quantization parameter that is the quantization parameter corrected by the quantization parameter correction unit.</p><p id="p-0072" num="0074">By doing so, since the clip processing can be executed after the correction amount is added, the range that can be taken by the value of the corrected quantization parameter can be controlled.</p><p id="p-0073" num="0075">Note that, in the case where the adaptive color transform is applied, the quantization parameter may be corrected with a correction amount corresponding to a component to be processed as the correction based on the parameter regarding the adaptive color transform. For example, in the image processing device, in the case of applying the adaptive color transform, the quantization parameter correction unit may correct the quantization parameter with the correction amount corresponding to the component to be processed.</p><p id="p-0074" num="0076">Furthermore, in the case where the adaptive color transform is not applied, the quantization parameter may be corrected with the correction amount set to &#x201c;0&#x201d; as the correction based on the parameter regarding the adaptive color transform. In other words, the correction based on the parameter regarding the adaptive color transform may be skipped (omitted). For example, in the image processing device, in the case of applying the adaptive color transform, the quantization parameter correction unit may correct the quantization parameter with the correction amount set to &#x201c;0&#x201d;.</p><heading id="h-0011" level="1">2. First Embodiment</heading><p id="p-0075" num="0077">&#x3c;Lower Limit Control During Transform Skip&#x3e;</p><p id="p-0076" num="0078">As described above, in the correction method described in Non-Patent Document 1, in a case where transform skip is applied, a quantization parameter qP is corrected as illustrated in the expression (3). That is, a lower limit of the quantization parameter qP is first clipped with a minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip, and a first corrected quantization parameter qP&#x2032; is obtained. The minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip is set in advance.</p><p id="p-0077" num="0079">Next, in a case where cu_act_enabled_flag is true (for example, &#x201c;1&#x201d;), a correction amount dqP corresponding to a component identifier cIdx indicating a component to be processed is added to the first corrected quantization parameter qP&#x2032; to derive a second corrected quantization parameter qP&#x2033;. Note that, in the case where cu_act_enabled_flag is false (for example, &#x201c;0&#x201d;), similar calculation is executed with the correction amount dqP set to &#x201c;0&#x201d;, and the second corrected quantization parameter qP&#x2033; is derived. The second corrected quantization parameter qP&#x2033; derived in this manner is used for quantization processing and inverse quantization processing as a corrected quantization parameter qP (that is, a correction result).</p><p id="p-0078" num="0080">That is, in a case where adaptive color transform and transform skip are applied, the lower limit of the quantization parameter qP is clipped with QpPrimeTsMin, and then the correction amount dqP corresponding to the component identifier cIdx is added.</p><p id="p-0079" num="0081">Note that the lower limit of the quantization parameter qP is clipped with QpPrimeTsMin in order to avoid a phenomenon in which a peak signal-to-noise ratio (PSNR) decreases when a quantization step size &#x394;&#x3c;1 in the transform skip (because the quantization step size &#x394; &#x3c;1 can occur).</p><p id="p-0080" num="0082">However, as described above, by adding the correction amount dqP corresponding to the component identifier cIdx after clipping the lower limit with QpPrimeTsMin, the second corrected quantization parameter qP&#x2033; (that is, the corrected quantization parameter qP) can be a value smaller than QpPrimeTsMin. That is, in the case where the adaptive color transform and the transform skip are applied, there is a possibility that the quantization parameter smaller than the minimum value of the quantization parameter at the time of transform skip is used for the quantization and the inverse quantization (the quantization step size &#x394;&#x3c;1 can occur). Therefore, there is a possibility that the PSNR is reduced. That is, there has been a possibility that the encoding efficiency is reduced.</p><p id="p-0081" num="0083">Therefore, as described above, as illustrated in the top row of the table illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the quantization parameter is corrected by transform skip after the quantization parameter by adaptive color transform is corrected. Moreover, as illustrated in the second row from the top of the table illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in the quantization parameter correction processing by transform skip, in the case of the transform skip, the lower limit may be clipped with the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip (method 1).</p><p id="p-0082" num="0084">For example, in the image processing device, in the case of applying the transform skip, the quantization parameter correction unit may clip the lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with the preset minimum value QpPrimeTsMin of the quantization parameter of the case of the transform skip.</p><p id="p-0083" num="0085">By doing so, in the case where the adaptive color transform and the transform skip are applied, the quantization step size &#x394;&#x3c;1 can be avoided, so that the reduction in the PSNR can be suppressed and the reduction in the encoding efficiency can be suppressed.</p><p id="p-0084" num="0086">Furthermore, as illustrated in the second row from the top of the table illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in the quantization parameter correction processing by transform skip, in the case of non-transform skip, the clip of the lower limit may be omitted. For example, in the image processing device, in a case of not applying the transform skip, the quantization parameter correction unit may omit the clip of the lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform. In other words, in that case, the lower limit of the quantization parameter may be clipped with a minimum value that can be taken on the basis of a specification of hardware, software, or the like.</p><p id="p-0085" num="0087">&#x3c;Quantization Parameter Correction Device&#x3e;</p><p id="p-0086" num="0088">The above-described present technology can be applied to any device. <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an example of a configuration of a quantization parameter correction device that is one aspect of an image processing device to which the present technology is applied. A quantization parameter correction device <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a device that corrects a quantization parameter to be used for quantization processing and inverse quantization processing of coefficient data related to an image. The quantization parameter correction device <b>100</b> corrects the quantization parameter according to, for example, application of adaptive color transform and transform skip in image encoding or decoding. At that time, the quantization parameter correction device <b>100</b> corrects the quantization parameter by applying the above-described &#x201c;method 1&#x201d;.</p><p id="p-0087" num="0089">Note that <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates main processing units, data flows, and the like, and those illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> are not necessarily everything. That is, in the quantization parameter correction device <b>100</b>, there may be a processing unit not illustrated as a block in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, or there may be processing or a data flow not illustrated as an arrow or the like in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0088" num="0090">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the quantization parameter correction device <b>100</b> includes a first correction unit <b>101</b> and a second correction unit <b>102</b>.</p><p id="p-0089" num="0091">The first correction unit <b>101</b> executes processing regarding correction based on a parameter regarding adaptive color transform. For example, the first correction unit <b>101</b> acquires a quantization parameter qPx at a CU level corresponding to a component identifier cIdx indicating a component to be processed. Furthermore, the first correction unit <b>101</b> acquires cu_act_enabled_flag as the parameter regarding adaptive color transform. Moreover, the first correction unit <b>101</b> acquires a correction amount dqPx corresponding to the component identifier cIdx.</p><p id="p-0090" num="0092">Note that the component identifier cIdx is an identifier indicating the component to be processed. Furthermore, the quantization parameter qPx indicates the quantization parameter corresponding to a component. For example, the quantization parameter qPx includes a quantization parameter qPy corresponding to luminance Y, a quantization parameter qPcb corresponding to chrominance Cb, a quantization parameter qPcr corresponding to chrominance Cr, and a quantization parameter qPcbcr corresponding to chrominance CbCr. Moreover, the correction amount dqPx corresponding to each component (Y, Cg, Co) when the adaptive color transform is applied is (&#x2212;5, &#x2212;5, &#x2212;3). These parameters are similar in other embodiments unless otherwise specified.</p><p id="p-0091" num="0093">In the case where cu_act_enabled_flag is true (for example, &#x201c;1&#x201d;), the first correction unit <b>101</b> adds the correction amount dqPx corresponding to the component identifier cIdx to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. Furthermore, in the case where cu_act_enabled_flag is false (for example, &#x201c;0&#x201d;), the first correction unit <b>101</b> adds the correction amount &#x201c;0&#x201d; to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. That is, the first correction unit <b>101</b> executes processing of the following syntax.</p><p id="p-0092" num="0094">if cu_act_enabled_flag</p><p id="p-0093" num="0095">qP&#x2032;=qPx+dqPx</p><p id="p-0094" num="0096">else</p><p id="p-0095" num="0097">qP&#x2032;=qPx</p><p id="p-0096" num="0098">The first correction unit <b>101</b> supplies the derived first corrected quantization parameter qP&#x2032; to the second correction unit <b>102</b>.</p><p id="p-0097" num="0099">The second correction unit <b>102</b> executes processing regarding correction based on a parameter regarding transform skip. For example, the second correction unit <b>102</b> acquires the first corrected quantization parameter qP&#x2032; supplied from the first correction unit <b>101</b>. Furthermore, the second correction unit <b>102</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx as the parameter regarding transform skip. Moreover, the second correction unit <b>102</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip as the parameter regarding transform skip.</p><p id="p-0098" num="0100">Note that transform_skip_flag is flag information indicating whether or not to apply the transform skip. A case where transform_skip_flag is true (for example, &#x201c;1&#x201d;) indicates that the transform skip is applied. Furthermore, a case where transform_skip_flag is false (for example, &#x201c;0&#x201d;) indicates that the non-transform skip is applied (that is, no transform skip is applied). Furthermore, the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip is set in advance. Note that, in a case of signaling (transmitting) QpPrimeTsMin from an encoding-side device to a decoding-side device, QpPrimeTsMin is signaled using, for example, a parameter set. These parameters are similar in other embodiments unless otherwise specified.</p><p id="p-0099" num="0101">In the case where transform_skip_flag is true (for example, &#x201c;1&#x201d;), the second correction unit <b>102</b> clips a lower limit of the first corrected quantization parameter qP&#x2032; using QpPrimeTsMin to derive the second corrected quantization parameter qP&#x201c;. In other words, in the case where transform_skip_flag is true, the second correction unit <b>102</b> sets QpPrimeTsMin or the first corrected quantization parameter qP&#x2032;, whichever is larger, as the second corrected quantization parameter qP&#x201d;. Furthermore, in the case where transform_skip_flag is false (for example, &#x201c;0&#x201d;), the second correction unit <b>102</b> skips (omits) this clip processing and sets the first corrected quantization parameter qP&#x2032; as the second corrected quantization parameter qP&#x2033;. In other words, in the case where transform_skip_flag is false, the second correction unit <b>102</b> clips the lower limit of the first corrected quantization parameter qP&#x2032; with the minimum value that can be taken on the basis of a specification of hardware, software, or the like, and derives the second corrected quantization parameter qP&#x2033;. That is, the second correction unit <b>102</b> executes processing of the following syntax.</p><p id="p-0100" num="0102">if transform_skip_flag[cIdx]==&#x2018;IS_SKIP&#x2019;</p><p id="p-0101" num="0103">qP&#x2033;=Max(qP&#x2032;, QpPrimeTsMin)</p><p id="p-0102" num="0104">else</p><p id="p-0103" num="0105">qP&#x2033;=qP&#x2032;</p><p id="p-0104" num="0106">The second correction unit <b>102</b> outputs the derived second corrected quantization parameter qP&#x2033; to the outside of the quantization parameter correction device <b>100</b> as a correction result (corrected quantization parameter) of the input quantization parameter qP.</p><p id="p-0105" num="0107">In other words, in the case of transform skip, the quantization parameter correction device <b>100</b> executes processing as illustrated in the following expression (5) to correct the quantization parameter. Furthermore, in the case of non-transform skip, the quantization parameter correction device <b>100</b> executes processing as illustrated in the following expression (6) to correct the quantization parameter.</p><p id="p-0106" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=Max(QpPrimeTsMin,qP&#x2212;(cu_act_enabled_flag[<i>xTbY</i>][<i>yTbY</i>]?(<i>c</i>Idx&#x3c;2?5:3):0))&#x2003;&#x2003; (5)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0107" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=qP&#x2212;(cu_act_enabled_flag[<i>xTbY</i>][<i>yTbY</i>]?(<i>c</i>Idx&#x3c;2?5:3):0)&#x2003;&#x2003; (6)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0108" num="0108">In other words, the quantization parameter correction device <b>100</b> derives the quantization parameter qP to be applied to a transform block to be processed corresponding to the component identifier cIdx by reference to the adaptive color transform flag (cu_act_enabled_flag), the correction amount dqP corresponding to ACT, the transform skip flag (transform_skip_flag) corresponding to the component identifier cIdx, the quantization parameter (qPx) at the CU level corresponding to the component identifier cIdx, and the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip.</p><p id="p-0109" num="0109">By doing so, the quantization parameter correction device <b>100</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the quantization or the inverse quantization in the case where the adaptive color transform and the transform skip are applied. Therefore, for example, an encoder or a decoder executes the quantization or the inverse quantization for the coefficient data of an image using the quantization parameter corrected in this manner, so that the reduction in the PSNR can be suppressed and the reduction in the encoding efficiency can be suppressed.</p><p id="p-0110" num="0110">Note that mts_idx may be applied instead of transform_skip_flag, and notification of whether or not the transform skip is applied may be provided as one mode of mts_idx. That is, the quantization parameter correction device <b>100</b> (the second correction unit <b>102</b>) may acquire mts_idx instead of transform_skip_flag and determine whether or not the transform skip is applied on the basis of the value. Furthermore, notification of QpPrimeTsMin may be provided for each component (Y, Cb, Cr, or CbCr). That is, the quantization parameter correction device <b>100</b> (the second correction unit <b>102</b>) may acquire QpPrimeTsMin corresponding to the component identifier cIdx and clip the lower limit of the first corrected quantization parameter qP&#x2032; using QpPrimeTsMin corresponding to the component identifier cIdx.</p><p id="p-0111" num="0111">&#x3c;Flow of Quantization Parameter Correction Processing&#x3e;</p><p id="p-0112" num="0112">Next, an example of a flow of quantization parameter correction processing executed by the quantization parameter correction device <b>100</b> will be described with reference to the flowchart of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0113" num="0113">When the quantization parameter correction processing is started, in step S<b>101</b>, the first correction unit <b>101</b> of the quantization parameter correction device <b>100</b> determines whether or not to apply the adaptive color transform by determining whether or not condition 1 is satisfied. For example, the condition 1 may be cu_act_enabled_flag=1. In a case where it is determined that the condition 1 is satisfied (that is, the adaptive color transform is applied), the processing proceeds to step S<b>102</b>.</p><p id="p-0114" num="0114">In step S<b>102</b>, the first correction unit <b>101</b> adds the correction amount dqPx corresponding to the component identifier cIdx to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;.</p><p id="p-0115" num="0115">That is, the first correction unit <b>101</b> executes calculation of the following expression (7).</p><p id="p-0116" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2032;=qP<i>x+dqPx</i>&#x2003;&#x2003; (7)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0117" num="0116">At that time, the correction amount dqPx may be set as in the following expression (8) or may be set as in the following expression (9).</p><p id="p-0118" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>dqPx=c</i>Idx&#x3c;2?&#x2212;5:&#x2212;3&#x2003;&#x2003; (8)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0119" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>dqPx</i>=coded<i>C</i>Idx&#x3c;2?&#x2212;5:3&#x2003;&#x2003; (9)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0120" num="0117">When the processing in step S<b>102</b> is completed, the processing proceeds to step S<b>104</b>. Furthermore, in a case where it is determined in step S<b>101</b> that the condition 1 is not satisfied (that is, the adaptive color transform is not applied), the processing proceeds to step S<b>103</b>.</p><p id="p-0121" num="0118">In step S<b>103</b>, the first correction unit <b>101</b> adds the correction amount &#x201c;0&#x201d; to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. That is, the first correction unit <b>101</b> executes calculation of the following expression (10).</p><p id="p-0122" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2032;=qP&#x2003;&#x2003; (10)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0123" num="0119">When the processing in step S<b>103</b> is completed, the processing proceeds to step S<b>104</b>.</p><p id="p-0124" num="0120">In step S<b>104</b>, the second correction unit <b>102</b> determines whether or not the transform skip is applied by determining whether or not condition 2 is satisfied. For example, the condition 2 may be transform_skip_flag[cIdx]==&#x2018;IS_SKIP&#x2019;. Alternatively, the condition 2 may be mts_idx[cIdx]==&#x2018;IS_SKIP&#x2019;. When it is determined that the condition 2 is satisfied (that is, the transform skip is performed), the processing proceeds to step S<b>105</b>.</p><p id="p-0125" num="0121">In step S<b>105</b>, the second correction unit <b>102</b> clips the lower limit of the first corrected quantization parameter qP&#x2032; using QpPrimeTsMin to derive the second corrected quantization parameter qP&#x2033;. That is, the second correction unit <b>102</b> executes calculation of the following expression (11).</p><p id="p-0126" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=Max(QpPrimeTsMin,qP&#x2032;)&#x2003;&#x2003; (11)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0127" num="0122">When the processing of step S<b>105</b> ends, the quantization parameter correction processing ends. Furthermore, in a case where it is determined in step S<b>104</b> that the condition 2 is not satisfied (that is, the non-transform skip is applied), the processing proceeds to step S<b>106</b>.</p><p id="p-0128" num="0123">In step S<b>106</b>, the second correction unit <b>102</b> skips (omits) this clip processing and sets the first corrected quantization parameter qP&#x2032; as the second corrected quantization parameter qP&#x2033;. That is, the second correction unit <b>102</b> executes calculation of the following expression (12).</p><p id="p-0129" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=qP&#x2032;&#x2003;&#x2003; (12)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0130" num="0124">When the processing of step S<b>106</b> ends, the quantization parameter correction processing ends.</p><p id="p-0131" num="0125">By executing the quantization parameter correction processing as described above, the quantization parameter correction device <b>100</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the quantization or the inverse quantization when the adaptive color transform and the transform skip are applied. Therefore, for example, an encoder or a decoder executes the quantization or the inverse quantization for the coefficient data of an image using the quantization parameter corrected in this manner, so that the reduction in the PSNR can be suppressed and the reduction in the encoding efficiency can be suppressed.</p><heading id="h-0012" level="1">3. Second Embodiment</heading><p id="p-0132" num="0126">&#x3c;Lower Limit Control During Non-Transform Skip&#x3e;</p><p id="p-0133" num="0127">As described above, in the correction method described in Non-Patent Document 1, in the case where non-transform skip is applied, clip is omitted as illustrated in the expression (4). Then, in the case where cu_act_enabled_flag is true (for example, &#x201c;1&#x201d;), the correction amount dqP corresponding to the component identifier cIdx is added to the first corrected quantization parameter qP&#x2032; to derive the second corrected quantization parameter qP&#x2033;. Note that, in the case where cu_act_enabled_flag is false (for example, &#x201c;0&#x201d;), similar calculation is executed with the correction amount dqP set to &#x201c;0&#x201d;, and the second corrected quantization parameter qP&#x2033; is derived. The second corrected quantization parameter qP&#x2033; derived in this manner is used for quantization processing and inverse quantization processing as a corrected quantization parameter qP (that is, a correction result).</p><p id="p-0134" num="0128">Therefore, in the case of non-transform skip, the second corrected quantization parameter qP&#x2033; (that is, corrected quantization parameter qP) may be a value smaller than the minimum value &#x201c;0&#x201d; of the quantization parameter. That is, in the case where adaptive color transform and non-transform skip are applied, there is a possibility that the quantization parameter smaller than the minimum value &#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip is used for quantization and inverse quantization (a quantization step size &#x394;&#x3c;1 may occur). Therefore, there is a possibility that the PSNR is reduced. That is, there has been a possibility that the encoding efficiency is reduced.</p><p id="p-0135" num="0129">Therefore, as described above, as illustrated in the top row of the table illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the quantization parameter is corrected by transform skip after the quantization parameter by adaptive color transform is corrected. Moreover, as illustrated in the third row from the top of the table illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in quantization parameter correction processing by transform skip, in a case of the transform skip, a lower limit of a quantization parameter may be clipped with a minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip, and in a case of non-transform skip, the lower limit of the quantization parameter may be clipped with a minimum value &#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip (method 2).</p><p id="p-0136" num="0130">For example, in an image processing device, in the case of not applying the transform skip, a quantization parameter correction unit may clip the lower limit of the quantization parameter corrected on the basis of a parameter regarding adaptive color transform with the preset minimum value of the quantization parameter.</p><p id="p-0137" num="0131">For example, the minimum value of the quantization parameter may be &#x201c;0&#x201d;. That is, in the case of not applying the transform skip, the quantization parameter correction unit may clip the lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with the value &#x201c;0&#x201d;.</p><p id="p-0138" num="0132">In doing so, in the case where the adaptive color transform and the non-transform skip are applied, a quantization step size &#x394;&#x3c;1 can be avoided, so that reduction in PSNR can be suppressed and reduction in encoding efficiency can be suppressed.</p><p id="p-0139" num="0133">&#x3c;Quantization Parameter Correction Device&#x3e;</p><p id="p-0140" num="0134">The above-described present technology can be applied to any device. <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram illustrating an example of a configuration of a quantization parameter correction device that is one aspect of an image processing device to which the present technology is applied. A quantization parameter correction device <b>120</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a device similar to the quantization parameter correction device <b>100</b>, and corrects a quantization parameter used for quantization processing and inverse quantization processing of coefficient data related to an image. At that time, the quantization parameter correction device <b>120</b> corrects the quantization parameter by applying the above-described &#x201c;method 2&#x201d;.</p><p id="p-0141" num="0135">Note that <figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates main processing units, data flows, and the like, and those illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> are not necessarily everything. That is, in the quantization parameter correction device <b>120</b>, there may be a processing unit not illustrated as a block in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, or there may be processing or a data flow not illustrated as an arrow or the like in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0142" num="0136">As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the quantization parameter correction device <b>120</b> includes a first correction unit <b>121</b> and a second correction unit <b>122</b>.</p><p id="p-0143" num="0137">The first correction unit <b>121</b> is a processing unit similar to the first correction unit <b>101</b> of the quantization parameter correction device <b>100</b> and executes similar processing. That is, the first correction unit <b>121</b> executes processing regarding correction based on the parameter regarding adaptive color transform. For example, the first correction unit <b>121</b> acquires a quantization parameter qPx at a CU level corresponding to the component identifier cIdx indicating the component to be processed. Furthermore, the first correction unit <b>121</b> acquires cu_act_enabled_flag as the parameter regarding adaptive color transform. Moreover, the first correction unit <b>121</b> acquires a correction amount dqPx corresponding to the component identifier cIdx.</p><p id="p-0144" num="0138">In the case where cu_act_enabled_flag is true (for example, &#x201c;1&#x201d;), the first correction unit <b>121</b> adds the correction amount dqPx corresponding to the component identifier cIdx to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. Furthermore, in the case where cu_act_enabled_flag is false (for example, &#x201c;0&#x201d;), the first correction unit <b>121</b> adds the correction amount &#x201c;0&#x201d; to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. That is, the first correction unit <b>121</b> executes processing of the following syntax.</p><p id="p-0145" num="0139">if cu_act_enabled_flag</p><p id="p-0146" num="0140">qP&#x2032;=qPx+dqPx</p><p id="p-0147" num="0141">else</p><p id="p-0148" num="0142">qP&#x2032;=qPx</p><p id="p-0149" num="0143">The first correction unit <b>121</b> supplies the derived first corrected quantization parameter qP&#x2032; to the second correction unit <b>122</b>.</p><p id="p-0150" num="0144">Similarly to the second correction unit <b>102</b> of the quantization parameter correction device <b>100</b>, the second correction unit <b>122</b> executes processing regarding correction based on the parameter regarding transform skip. For example, the second correction unit <b>122</b> acquires the first corrected quantization parameter qP&#x2032; supplied from the first correction unit <b>121</b>. Furthermore, the second correction unit <b>122</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx as the parameter regarding transform skip. Moreover, the second correction unit <b>122</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip as the parameter regarding the transform skip. Furthermore, the second correction unit <b>122</b> acquires the minimum value &#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip as the parameter regarding transform skip.</p><p id="p-0151" num="0145">In the case where transform_skip_flag is true (for example, &#x201c;1&#x201d;), the second correction unit <b>122</b> clips a lower limit of the first corrected quantization parameter qP&#x2032; using QpPrimeTsMin to derive the second corrected quantization parameter qP&#x2033;. In other words, in the case where transform_skip_flag is true, the second correction unit <b>122</b> sets QpPrimeTsMin or the first corrected quantization parameter qP&#x2032;, whichever is larger, as the second corrected quantization parameter qP&#x2033;.</p><p id="p-0152" num="0146">In contrast, in the case where transform_skip_flag is false (for example, &#x201c;0&#x201d;), the second correction unit <b>122</b> clips a lower limit of the quantization parameter with the minimum value &#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip, and derives the second corrected quantization parameter qP&#x2033;. In other words, in the case where transform_skip_flag is false, the second correction unit <b>122</b> sets the value &#x201c;0&#x201d; or the first corrected quantization parameter qP&#x2032;, whichever is larger, as the second corrected quantization parameter qP&#x2033;. That is, the second correction unit <b>122</b> executes processing of the following syntax.</p><p id="p-0153" num="0147">if transform_skip_flag[cIdx]==&#x2018;IS_SKIP&#x2019;</p><p id="p-0154" num="0148">qP&#x2033;=Max(qP&#x2032;, QpPrimeTsMin)</p><p id="p-0155" num="0149">else</p><p id="p-0156" num="0150">qP&#x2033;=Max(qP&#x2032;, 0)</p><p id="p-0157" num="0151">The second correction unit <b>122</b> outputs the derived second corrected quantization parameter qP&#x2033; to the outside of the quantization parameter correction device <b>120</b> as a correction result (corrected quantization parameter) of the input quantization parameter qP.</p><p id="p-0158" num="0152">In other words, in the case of transform skip, the quantization parameter correction device <b>120</b> executes processing as illustrated in expression (5) above to correct the quantization parameter. Furthermore, in the case of non-transform skip, the quantization parameter correction device <b>120</b> executes processing as illustrated in the following expression (13) to correct the quantization parameter.</p><p id="p-0159" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=Max(QpPrimeTsMin,qP&#x2212;(cu_act_enabled_flag[<i>xTbY</i>][<i>yTbY</i>]?(<i>c</i>Idx&#x3c;2?5:3):0))&#x2003;&#x2003; (5) (re-described)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0160" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=Max(0,qP&#x2212;(cu_act_enabled_flag[<i>xTbY</i>][<i>yTbY</i>]?(<i>c</i>Idx&#x3c;2?5:3):0))&#x2003;&#x2003; (13)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0161" num="0153">In other words, the quantization parameter correction device <b>120</b> derives the quantization parameter qP to be applied to a transform block to be processed corresponding to the component identifier cIdx by reference to the adaptive color transform flag (cu_act_enabled_flag), the correction amount dqP corresponding to ACT, the transform skip flag (transform_skip_flag) corresponding to the component identifier cIdx, the quantization parameter (qPx) at the CU level corresponding to the component identifier cIdx, the minimum value &#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip, and the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip.</p><p id="p-0162" num="0154">By doing so, the quantization parameter correction device <b>120</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in quantization or inverse quantization when the adaptive color transform and the non-transform skip are applied. That is, the quantization parameter correction device <b>120</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the quantization or inverse quantization, regardless of whether or not the transform skip is applied, in the case where the adaptive color transform is applied. Therefore, for example, an encoder or a decoder executes the quantization or the inverse quantization for the coefficient data of an image using the quantization parameter corrected in this manner, so that the reduction in the PSNR can be suppressed and the reduction in the encoding efficiency can be suppressed.</p><p id="p-0163" num="0155">Note that mts_idx may be applied instead of transform_skip_flag, and notification of whether or not the transform skip is applied may be provided as one mode of mts_idx. That is, the quantization parameter correction device <b>120</b> (the second correction unit <b>122</b>) may acquire mts_idx instead of transform_skip_flag and determine whether or not the transform skip is applied on the basis of the value. Furthermore, notification of QpPrimeTsMin may be provided for each component (Y, Cb, Cr, or CbCr). That is, the quantization parameter correction device <b>120</b> (the second correction unit <b>122</b>) may acquire QpPrimeTsMin corresponding to the component identifier cIdx and clip the lower limit of the first corrected quantization parameter qP&#x2032; using QpPrimeTsMin corresponding to the component identifier cIdx.</p><p id="p-0164" num="0156">&#x3c;Flow of Quantization Parameter Correction Processing&#x3e;</p><p id="p-0165" num="0157">Next, an example of a flow of quantization parameter correction processing executed by the quantization parameter correction device <b>120</b> will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0166" num="0158">When the quantization parameter correction processing is started, in step S<b>121</b>, the first correction unit <b>121</b> of the quantization parameter correction device <b>120</b> determines whether or not to apply the adaptive color transform by determining whether or not condition 1 is satisfied. This condition 1 is similar to the case of the first embodiment (<figref idref="DRAWINGS">FIG. <b>3</b></figref>). In a case where it is determined that the condition 1 is satisfied (that is, the adaptive color transform is applied), the processing proceeds to step S<b>122</b>.</p><p id="p-0167" num="0159">In step S<b>122</b>, the first correction unit <b>121</b> adds the correction amount dqPx corresponding to the component identifier cIdx to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. This processing is executed similarly to the processing in step S<b>102</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0168" num="0160">When the processing in step S<b>122</b> is completed, the processing proceeds to step S<b>124</b>. Furthermore, in a case where it is determined in step S<b>121</b> that the condition 1 is not satisfied (that is, the adaptive color transform is not applied), the processing proceeds to step S<b>123</b>.</p><p id="p-0169" num="0161">In step S<b>123</b>, the first correction unit <b>121</b> adds the correction amount &#x201c;0&#x201d; to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. This processing is executed similarly to the processing in step S<b>103</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0170" num="0162">When the processing in step S<b>123</b> is completed, the processing proceeds to step S<b>124</b>.</p><p id="p-0171" num="0163">In step S<b>124</b>, the second correction unit <b>122</b> determines whether or not the transform skip is applied by determining whether or not condition 2 is satisfied. This condition 2 is similar to the case of the first embodiment (<figref idref="DRAWINGS">FIG. <b>3</b></figref>). When it is determined that Condition 2 is satisfied (that is, the transform skip is performed), the processing proceeds to step S<b>125</b>.</p><p id="p-0172" num="0164">In step S<b>125</b>, the second correction unit <b>122</b> clips the lower limit of the first corrected quantization parameter qP&#x2032; using QpPrimeTsMin to derive the second corrected quantization parameter qP&#x2033;. This processing is executed similarly to the processing in step S<b>105</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0173" num="0165">When the processing of step S<b>125</b> ends, the quantization parameter correction processing ends. Furthermore, in a case where it is determined in step S<b>124</b> that the condition 2 is not satisfied (that is, the non-transform skip is applied), the processing proceeds to step S<b>126</b>.</p><p id="p-0174" num="0166">In step S<b>126</b>, the second correction unit <b>122</b> clips the lower limit of the first corrected quantization parameter qP&#x2032; using the minimum value &#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip to derive the second corrected quantization parameter qP&#x2033;. That is, the second correction unit <b>122</b> executes calculation of the following expression (14).</p><p id="p-0175" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=Max(0,qP&#x2032;)&#x2003;&#x2003; (14)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0176" num="0167">When the processing of step S<b>126</b> ends, the quantization parameter correction processing ends.</p><p id="p-0177" num="0168">By executing the quantization parameter correction processing as described above, the quantization parameter correction device <b>100</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the quantization or the inverse quantization when the adaptive color transform and the non-transform skip are applied. Therefore, for example, an encoder or a decoder executes the quantization or the inverse quantization for the coefficient data of an image using the quantization parameter corrected in this manner, so that the reduction in the PSNR can be suppressed and the reduction in the encoding efficiency can be suppressed.</p><heading id="h-0013" level="1">4. Third Embodiment</heading><p id="p-0178" num="0169">&#x3c;Upper Limit Control of Quantization Parameter&#x3e;</p><p id="p-0179" num="0170">Moreover, an upper limit of a quantization parameter may be clipped. For example, as illustrated in the fourth row from the top of the table illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, correction of the quantization parameter by adaptive color transform is executed. Then, the corrected quantization parameter may be clipped with a minimum value and a maximum value of the quantization parameter (method 3).</p><p id="p-0180" num="0171">Assuming that the quantization parameter is set in a range from 0 to 63, the minimum value of the quantization parameter is &#x201c;0&#x201d;, and the maximum value of the quantization parameter is &#x201c;63+QpBdOffset&#x201d;. Note that QpBdOffset is a correction amount corresponding to a bit depth of the quantization parameter.</p><p id="p-0181" num="0172">For example, in an image processing device, a quantization parameter correction unit may clip an upper limit of the quantization parameter corrected on the basis of a parameter regarding adaptive color transform with the maximum value (63+QpBdOffset) of the quantization parameter and clip a lower limit with the minimum value (value &#x201c;0&#x201d;) of the quantization parameter.</p><p id="p-0182" num="0173">That is, after the quantization parameter is corrected by adaptive color transform, the quantization parameter may be corrected to fall within a valid value on the basis of the minimum value and the maximum value of the quantization parameter. By doing so, the value of the corrected quantization parameter falls within the range from the minimum value to the maximum value of the quantization parameter. Therefore, reduction in PSNR can be suppressed, and reduction in encoding efficiency can be suppressed.</p><p id="p-0183" num="0174">Note that the clipped quantization parameter may be corrected on the basis of a parameter regarding transform skip. The correction based on the parameter regarding transform skip may be executed similarly to the case of the method 1. Furthermore, in the case of transform skip, a lower limit of the clipped quantization parameter may be further clipped with a minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip. Furthermore, in the case of non-transform skip, the lower limit clipping processing may be skipped (omitted).</p><p id="p-0184" num="0175">By doing so, the corrected quantization parameter does not become a value smaller than QpPrimeTsMin. Therefore, regardless of whether the transform skip or the non-transform skip is applied, the reduction in the PSNR can be suppressed, and the reduction in the encoding efficiency can be suppressed.</p><p id="p-0185" num="0176">Note that, in the case of non-transform skip, the lower limit of the quantization parameter may be clipped with the minimum value (value &#x201c;0&#x201d;) of the quantization parameter at the time of non-transform skip. Since the lower limit of the quantization parameter to undergo the clipping processing is clipped with the value &#x201c;0&#x201d; by the clip for the quantization parameter corrected on the basis of the parameter regarding adaptive color transform described above, a correction result substantially equivalent to the case of skipping the clip with the lower limit is also obtained in this case.</p><p id="p-0186" num="0177">&#x3c;Quantization Parameter Correction Device&#x3e;</p><p id="p-0187" num="0178">The above-described present technology can be applied to any device. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram illustrating an example of a configuration of a quantization parameter correction device that is one aspect of an image processing device to which the present technology is applied. A quantization parameter correction device <b>140</b> illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a device similar to the quantization parameter correction device <b>100</b>, and corrects a quantization parameter used for quantization processing and inverse quantization processing of coefficient data related to an image. At that time, the quantization parameter correction device <b>140</b> corrects the quantization parameter by applying the above-described &#x201c;method 3&#x201d;.</p><p id="p-0188" num="0179">Note that <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates main processing units, data flows, and the like, and those illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> are not necessarily everything. That is, in the quantization parameter correction device <b>140</b>, there may be a processing unit not illustrated as a block in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, or there may be processing or a data flow not illustrated as an arrow or the like in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0189" num="0180">As illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the quantization parameter correction device <b>140</b> includes a first correction unit <b>141</b>, a second correction unit <b>142</b>, and a third correction unit <b>143</b>.</p><p id="p-0190" num="0181">The first correction unit <b>141</b> is a processing unit similar to the first correction unit <b>101</b> of the quantization parameter correction device <b>100</b> and executes similar processing. That is, the first correction unit <b>141</b> executes processing regarding correction based on the parameter regarding adaptive color transform. For example, the first correction unit <b>141</b> acquires a quantization parameter qPx at a CU level corresponding to a component identifier cIdx indicating a component to be processed. Furthermore, the first correction unit <b>141</b> acquires cu_act_enabled_flag as the parameter regarding adaptive color transform. Moreover, the first correction unit <b>141</b> acquires a correction amount dqPx corresponding to the component identifier cIdx.</p><p id="p-0191" num="0182">In the case where cu_act_enabled_flag is true (for example, &#x201c;1&#x201d;), the first correction unit <b>141</b> adds the correction amount dqPx corresponding to the component identifier cIdx to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive a first corrected quantization parameter qP&#x2032;. Furthermore, in the case where cu_act_enabled_flag is false (for example, &#x201c;0&#x201d;), the first correction unit <b>141</b> adds the correction amount &#x201c;0&#x201d; to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. That is, the first correction unit <b>141</b> executes processing of the following syntax.</p><p id="p-0192" num="0183">if cu_act_enabled_flag</p><p id="p-0193" num="0184">qP&#x2032;=qPx+dqPx</p><p id="p-0194" num="0185">else</p><p id="p-0195" num="0186">qP&#x2032;=qPx</p><p id="p-0196" num="0187">The first correction unit <b>141</b> supplies the derived first corrected quantization parameter qP&#x2032; to the second correction unit <b>142</b>.</p><p id="p-0197" num="0188">The second correction unit <b>142</b> executes clipping processing for the first corrected quantization parameter qP&#x2032;. For example, the second correction unit <b>142</b> acquires the first corrected quantization parameter qP&#x2032; supplied from the first correction unit <b>141</b>. The second correction unit <b>142</b> acquires the correction amount QpBdOffset corresponding to the bit depth.</p><p id="p-0198" num="0189">The second correction unit <b>142</b> clips an upper limit of the first corrected quantization parameter qP&#x2032; with the maximum value (63+QpBdOffset) of the quantization parameter and clips the lower limit of the first corrected quantization parameter qP&#x2032; with the minimum value (value &#x201c;0&#x201d;) of the quantization parameter. By this processing, the second correction unit <b>142</b> derives a second corrected quantization parameter qP&#x2033;.</p><p id="p-0199" num="0190">In other words, the second correction unit <b>142</b> executes processing as in the following expression (15) for the first corrected quantization parameter qP&#x2032; to derive the second corrected quantization parameter qP&#x2033;.</p><p id="p-0200" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=Clip3(0,63+QpBdOffset,qP&#x2032;)&#x2003;&#x2003; (15)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0201" num="0191">The second correction unit <b>142</b> supplies the derived second corrected quantization parameter qP&#x2033; to the third correction unit <b>143</b>.</p><p id="p-0202" num="0192">Similarly to the second correction unit <b>102</b> of the quantization parameter correction device <b>100</b>, the third correction unit <b>143</b> executes processing regarding correction based on the parameter regarding transform skip. For example, the third correction unit <b>143</b> acquires the second corrected quantization parameter qP&#x2033; supplied from the second correction unit <b>142</b>. Furthermore, the third correction unit <b>143</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx as the parameter regarding transform skip. Moreover, the third correction unit <b>143</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip as the parameter regarding transform skip.</p><p id="p-0203" num="0193">In the case where transform_skip_flag is true (for example, &#x201c;1&#x201d;), the third correction unit <b>143</b> clips a lower limit of the second corrected quantization parameter qP&#x2033; using QpPrimeTsMin to derive a third corrected quantization parameter qP&#x2032;&#x2033;. In other words, in the case where transform_skip_flag is true, the third correction unit <b>143</b> sets QpPrimeTsMin or the second corrected quantization parameter qP&#x2033;, whichever is larger, as the third corrected quantization parameter</p><p id="p-0204" num="0194">In contrast, in the case where transform_skip_flag is false (for example, &#x201c;0&#x201d;), the third correction unit <b>143</b> skips (omits) this clip processing and sets the second corrected quantization parameter qP&#x2033; as the third corrected quantization parameter qP&#x2032;&#x2033;. In other words, in the case where transform_skip_flag is false, the third correction unit <b>143</b> clips the lower limit of the first corrected quantization parameter qP&#x2032; with a minimum value that can be taken on the basis of a specification of hardware, software, or the like, and derives the third corrected quantization parameter qP&#x2032;&#x2033;. That is, the third correction unit <b>143</b> executes processing of the following syntax.</p><p id="p-0205" num="0195">if transform_skip_flag[cIdx]==&#x2018;IS_SKIP&#x2019;</p><p id="p-0206" num="0196">qP&#x2032;&#x2033;=Max(qP&#x2033;, QpPrimeTsMin)</p><p id="p-0207" num="0197">else</p><p id="p-0208" num="0198">qP&#x2032;&#x2033;=qP&#x2033;</p><p id="p-0209" num="0199">The third correction unit <b>143</b> outputs the derived third corrected quantization parameter qP&#x2032;&#x2033; to the outside of the quantization parameter correction device <b>140</b> as a correction result (corrected quantization parameter) of the input quantization parameter qP.</p><p id="p-0210" num="0200">In other words, in the case of transform skip, the quantization parameter correction device <b>140</b> executes processing as illustrated in the following expression (16) to correct the quantization parameter. Furthermore, in the case of non-transform skip, the quantization parameter correction device <b>140</b> executes processing as illustrated in the following expression (17) to correct the quantization parameter.</p><p id="p-0211" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=Max(QpPrimeTsMin,Clip3(0,63+QpBdOffset,qP&#x2212;(cu_act_enabled_flag[<i>xTbY</i>][<i>yTbY</i>]?(<i>c</i>Idx&#x3c;2?5:3):0)))&#x2003;&#x2003; (16)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0212" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=Clip3(0,63+QpBdOffset,qP&#x2212;(cu_act_enabled_flag[<i>xTbY</i>][<i>yTbY</i>]?(<i>c</i>Idx&#x3c;2?5:3):0))&#x2003;&#x2003; (17)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0213" num="0201">In other words, the quantization parameter correction device <b>120</b> derives the quantization parameter qP to be applied to a transform block to be processed corresponding to the component identifier cIdx by reference to the adaptive color transform flag (cu_act_enabled_flag), the correction amount dqP corresponding to ACT, the transform skip flag (transform_skip_flag) corresponding to the component identifier cIdx, the quantization parameter (qPx) at the CU level corresponding to the component identifier cIdx, the correction amount QpBdOffset corresponding to the bit depth, the minimum value &#x201c;0&#x201d; of the quantization parameter, the maximum value&#x201c;63&#x201d; of the quantization parameter before correction with the correction amount QpBdOffset corresponding to the bit depth, and the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip.</p><p id="p-0214" num="0202">In this way, the quantization parameter correction device <b>140</b> corrects the quantization parameter to fall within a valid value on the basis of the minimum value and the maximum value of the quantization parameter after correcting the quantization parameter by adaptive color transform. That is, by correcting the quantization parameter in this way, the value of the corrected quantization parameter falls within the range from the minimum value to the maximum value of the quantization parameter. Therefore, for example, an encoder or a decoder executes the quantization or the inverse quantization for the coefficient data of an image using the quantization parameter corrected in this manner, so that the reduction in the PSNR can be suppressed and the reduction in the encoding efficiency can be suppressed.</p><p id="p-0215" num="0203">Furthermore, in the case of transform skip, since the lower limit of the quantization parameter is further clipped with the minimum value QpPrimeTsMin of the quantization parameter at the time of the transform skip, the corrected quantization parameter does not become a value smaller than QpPrimeTsMin. Therefore, for example, the encoder or the decoder executes the quantization or the inverse quantization for the coefficient data of an image using the quantization parameter corrected in this manner, so that the reduction in the PSNR can be suppressed and the reduction in the encoding efficiency can be suppressed, regardless of whether the transform skip or the non-transform skip is performed.</p><p id="p-0216" num="0204">Note that mts_idx may be applied instead of transform_skip_flag, and notification of whether or not the transform skip is applied may be provided as one mode of mts_idx. That is, the quantization parameter correction device <b>140</b> (third correction unit <b>143</b>) may acquire mts_idx instead of transform_skip_flag and determine whether or not the transform skip is applied on the basis of the value. Furthermore, notification of QpPrimeTsMin may be provided for each component (Y, Cb, Cr, or CbCr). That is, the quantization parameter correction device <b>140</b> (the third correction unit <b>143</b>) may acquire QpPrimeTsMin corresponding to the component identifier cIdx and clip the lower limit of the second corrected quantization parameter qP&#x2033; using QpPrimeTsMin corresponding to the component identifier cIdx.</p><p id="p-0217" num="0205">&#x3c;Flow of Quantization Parameter Correction Processing&#x3e;</p><p id="p-0218" num="0206">Next, an example of a flow of quantization parameter correction processing executed by the quantization parameter correction device <b>140</b> will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0219" num="0207">When the quantization parameter correction processing is started, in step S<b>141</b>, the first correction unit <b>141</b> of the quantization parameter correction device <b>140</b> determines whether or not to apply the adaptive color transform by determining whether or not condition 1 is satisfied. This condition 1 is similar to the case of the first embodiment (<figref idref="DRAWINGS">FIG. <b>3</b></figref>). In a case where it is determined that the condition 1 is satisfied (that is, the adaptive color transform is applied), the processing proceeds to step S<b>142</b>.</p><p id="p-0220" num="0208">In step S<b>142</b>, the first correction unit <b>141</b> adds the correction amount dqPx corresponding to the component identifier cIdx to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. This processing is executed similarly to the processing in step S<b>102</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0221" num="0209">When the processing in step S<b>142</b> is completed, the processing proceeds to step S<b>144</b>. Furthermore, in a case where it is determined in step S<b>141</b> that the condition 1 is not satisfied (that is, the adaptive color transform is not applied), the processing proceeds to step S<b>143</b>.</p><p id="p-0222" num="0210">In step S<b>143</b>, the first correction unit <b>141</b> adds the correction amount &#x201c;0&#x201d; to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. This processing is executed similarly to the processing in step S<b>103</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0223" num="0211">When the processing in step S<b>143</b> is completed, the processing proceeds to step S<b>144</b>.</p><p id="p-0224" num="0212">In step S<b>144</b>, the second correction unit <b>142</b> clips the upper limit of the first corrected quantization parameter qP&#x2032; with the maximum value (63+QpBdOffset) of the quantization parameter and clips the lower limit of the first corrected quantization parameter qP&#x2032; with the minimum value (value &#x201c;0&#x201d;) of the quantization parameter. By this processing, the second correction unit <b>142</b> derives the second corrected quantization parameter qP&#x2033;.</p><p id="p-0225" num="0213">That is, the second correction unit <b>142</b> executes processing as in the above-described expression (15) for the first corrected quantization parameter qP&#x2032; to derive the second corrected quantization parameter qP&#x2033;. When the processing in step S<b>144</b> is completed, the processing proceeds to step S<b>145</b>.</p><p id="p-0226" num="0214">In step S<b>145</b>, the third correction unit <b>143</b> determines whether or not the transform skip is applied by determining whether or not condition 2 is satisfied. This condition 2 is similar to the case of the first embodiment (<figref idref="DRAWINGS">FIG. <b>3</b></figref>). When it is determined that Condition 2 is satisfied (that is, the transform skip is performed), the processing proceeds to step S<b>146</b>.</p><p id="p-0227" num="0215">In step S<b>146</b>, the third correction unit <b>143</b> clips the lower limit of the second corrected quantization parameter qP&#x2033; using QpPrimeTsMin to derive the third corrected quantization parameter qP&#x2032;&#x2033;. This processing is executed similarly to the processing in step S<b>105</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0228" num="0216">When the processing of step S<b>146</b> ends, the quantization parameter correction processing ends. Furthermore, in a case where it is determined in step S<b>145</b> that the condition 2 is not satisfied (that is, the non-transform skip is applied), the processing proceeds to step S<b>147</b>.</p><p id="p-0229" num="0217">In step S<b>147</b>, the third correction unit <b>143</b> skips (omits) the clip processing in step S<b>146</b> and sets the second corrected quantization parameter qP&#x2033; as the third corrected quantization parameter qP&#x2032;&#x2033;. This processing is executed similarly to the processing in step S<b>106</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0230" num="0218">When the processing of step S<b>147</b> ends, the quantization parameter correction processing ends.</p><p id="p-0231" num="0219">By executing the quantization parameter correction processing as described above, the quantization parameter correction device <b>140</b> can keep the value of the corrected quantization parameter within the range from the minimum value to the maximum value of the quantization parameter. Therefore, for example, an encoder or a decoder executes the quantization or the inverse quantization for the coefficient data of an image using the quantization parameter corrected in this manner, so that the reduction in the PSNR can be suppressed and the reduction in the encoding efficiency can be suppressed.</p><p id="p-0232" num="0220">Furthermore, even in the case of transform skip, since the lower limit of the quantization parameter is clipped with QpPrimeTsMin, the corrected quantization parameter does not become a value smaller than QpPrimeTsMin. Therefore, for example, the encoder or the decoder executes the quantization or the inverse quantization for the coefficient data of an image using the quantization parameter corrected in this manner, so that the reduction in the PSNR can be suppressed and the reduction in the encoding efficiency can be suppressed, regardless of whether the transform skip or the non-transform skip is performed.</p><heading id="h-0014" level="1">5. Fourth Embodiment</heading><p id="p-0233" num="0221">&#x3c;Upper Limit Control of Quantization Parameter&#x3e;</p><p id="p-0234" num="0222">The clip processing for the first corrected quantization parameter qP&#x2032; in the method 3 described in the third embodiment may be combined with clip processing for correction based on a parameter regarding transform skip.</p><p id="p-0235" num="0223">That is, as illustrated at the bottom of the table illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, quantization parameter correction processing by transform skip may be executed as follows. That is, in a case of transform skip, a lower limit of a first corrected quantization parameter qP&#x2032; may be clipped with a minimum value QpPrimeTsMin of a quantization parameter at the time of transform skip, and an upper limit thereof may be clipped with a maximum value (63+QpBdOffset) of the quantization parameter. Furthermore, in a case of non-transform skip, the lower limit of the first corrected quantization parameter qP&#x2032; may be clipped with a minimum value &#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip, and the upper limit thereof may be clipped with the maximum value (63+QpBdOffset) of the quantization parameter (method 4).</p><p id="p-0236" num="0224">For example, in an image processing device, in a case of applying transform skip, a quantization parameter correction unit clips the lower limit of the quantization parameter corrected on the basis of a parameter regarding adaptive color transform with a preset minimum value of the quantization parameter of the case of applying the transform skip, and clips the upper limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with a preset maximum value of the quantization parameter. The maximum value of the quantization parameter may be a value corrected with a correction amount based on a bit depth. For example, the maximum value of the quantization parameter may be a sum of the maximum value of the quantization parameter before being corrected with the correction amount based on the bit depth and the correction amount based on the bit depth.</p><p id="p-0237" num="0225">Furthermore, for example, in the image processing device, in a case of not applying transform skip, the quantization parameter correction unit clips the lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with the preset minimum value of the quantization parameter, and clips the upper limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with the preset maximum value of the quantization parameter. The maximum value of the quantization parameter may be a value corrected with a correction amount based on a bit depth. For example, the maximum value of the quantization parameter may be a sum of the maximum value of the quantization parameter before being corrected with the correction amount based on the bit depth and the correction amount based on the bit depth.</p><p id="p-0238" num="0226">By doing so, the value of the corrected quantization parameter similar to the case of the method 3 is obtained. That is, the value of the corrected quantization parameter falls within a range from the minimum value to the maximum value of the quantization parameter. Therefore, reduction in PSNR can be suppressed, and reduction in encoding efficiency can be suppressed.</p><p id="p-0239" num="0227">Furthermore, in the case of transform skip, since the lower limit of the quantization parameter is clipped with the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip, the corrected quantization parameter does not become a value smaller than QpPrimeTsMin. Therefore, regardless of whether the transform skip or the non-transform skip is applied, the reduction in the PSNR can be suppressed, and the reduction in the encoding efficiency can be suppressed.</p><p id="p-0240" num="0228">&#x3c;Quantization Parameter Correction Device&#x3e;</p><p id="p-0241" num="0229">The above-described present technology can be applied to any device. <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram illustrating an example of a configuration of a quantization parameter correction device that is one aspect of an image processing device to which the present technology is applied. A quantization parameter correction device <b>160</b> illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a device similar to the quantization parameter correction device <b>100</b>, and corrects a quantization parameter used for quantization processing and inverse quantization processing of coefficient data related to an image. At that time, the quantization parameter correction device <b>160</b> corrects the quantization parameter by applying the above-described &#x201c;method 4&#x201d;.</p><p id="p-0242" num="0230">Note that <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates main processing units, data flows, and the like, and those illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> are not necessarily everything. That is, in the quantization parameter correction device <b>160</b>, there may be a processing unit not illustrated as a block in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, or there may be processing or a data flow not illustrated as an arrow or the like in <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0243" num="0231">As illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the quantization parameter correction device <b>160</b> includes a first correction unit <b>161</b> and a second correction unit <b>162</b>.</p><p id="p-0244" num="0232">The first correction unit <b>161</b> is a processing unit similar to the first correction unit <b>101</b> of the quantization parameter correction device <b>100</b> and executes similar processing. That is, the first correction unit <b>161</b> executes processing regarding correction based on the parameter regarding adaptive color transform. For example, the first correction unit <b>161</b> acquires a quantization parameter qPx at a CU level corresponding to a component identifier cIdx indicating a component to be processed. Furthermore, the first correction unit <b>161</b> acquires cu_act_enabled_flag as the parameter regarding adaptive color transform. Moreover, the first correction unit <b>161</b> acquires a correction amount dqPx corresponding to the component identifier cIdx.</p><p id="p-0245" num="0233">In the case where cu_act_enabled_flag is true (for example, &#x201c;1&#x201d;), the first correction unit <b>161</b> adds the correction amount dqPx corresponding to the component identifier cIdx to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive a first corrected quantization parameter qP&#x2032;. Furthermore, in the case where cu_act_enabled_flag is false (for example, &#x201c;0&#x201d;), the first correction unit <b>161</b> adds the correction amount &#x201c;0&#x201d; to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. That is, the first correction unit <b>161</b> executes processing of the following syntax.</p><p id="p-0246" num="0234">if cu_act_enabled_flag</p><p id="p-0247" num="0235">qP&#x2032;=qPx+dqPx</p><p id="p-0248" num="0236">else</p><p id="p-0249" num="0237">qP&#x2032;=qPx</p><p id="p-0250" num="0238">The first correction unit <b>161</b> supplies the derived first corrected quantization parameter qP&#x2032; to the second correction unit <b>162</b>.</p><p id="p-0251" num="0239">Similarly to the second correction unit <b>102</b> of the quantization parameter correction device <b>100</b>, the second correction unit <b>162</b> executes processing regarding correction based on the parameter regarding transform skip. For example, the second correction unit <b>162</b> acquires the first corrected quantization parameter qP&#x2032; supplied from the first correction unit <b>161</b>. Furthermore, the second correction unit <b>162</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx as the parameter regarding transform skip. Moreover, the second correction unit <b>162</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip as the parameter regarding transform skip.</p><p id="p-0252" num="0240">Moreover, the second correction unit <b>162</b> acquires the correction amount QpBdOffset corresponding to the bit depth.</p><p id="p-0253" num="0241">In a case where transform_skip_flag is true (for example, &#x201c;1&#x201d;), the second correction unit <b>162</b> clips a lower limit of the first corrected quantization parameter qP&#x2032; using QpPrimeTsMin and clips an upper limit of the first corrected quantization parameter qP&#x2032; using (63+QpBdOffset). The second correction unit <b>162</b> derives a second corrected quantization parameter qP&#x2033; from the first corrected quantization parameter qP&#x2032; by such clip processing. That is, the value of the second corrected quantization parameter qP&#x2033; is limited within the range from (QpPrimeTsMin to (63+QpBdOffset)) (the value of the second corrected quantization parameter qP&#x2033; is controlled to fall within the range from (QpPrimeTsMin to (63+QpBdOffset))).</p><p id="p-0254" num="0242">In contrast, in a case where transform_skip_flag is false (for example, &#x201c;0&#x201d;), the second correction unit <b>162</b> clips the lower limit of the quantization parameter using the value &#x201c;0&#x201d; and clips the upper limit of the first corrected quantization parameter qP&#x2032; using (63+QpBdOffset). That is, the second correction unit <b>162</b> clips the upper limit and the lower limit of the first corrected quantization parameter qP&#x2032; with the minimum value and the maximum value of the quantization parameter at the time of non-transform skip. The second correction unit <b>162</b> derives the second corrected quantization parameter qP&#x2033; from the first corrected quantization parameter qP&#x2032; by such clip processing. That is, the value of the second corrected quantization parameter qP&#x2033; is limited within the range from (<b>0</b> to (63+QpBdOffset)) (the value of the second corrected quantization parameter qP&#x2033; is controlled to fall within the range from (<b>0</b> to (63+QpBdOffset))).</p><p id="p-0255" num="0243">That is, the second correction unit <b>162</b> executes processing of the following syntax.</p><p id="p-0256" num="0244">if transform_skip_flag[cIdx]==&#x2018;IS_SKIP&#x2019;</p><p id="p-0257" num="0245">qP&#x2033;=Clip3(QpPrimeTsMin, 63+QpBdOffset, qP&#x2032;)</p><p id="p-0258" num="0246">else</p><p id="p-0259" num="0247">qP&#x2033;=Clip3(0, 63+QpBdOffset, qP&#x2032;)</p><p id="p-0260" num="0248">The second correction unit <b>162</b> outputs the derived second corrected quantization parameter qP&#x2033; to the outside of the quantization parameter correction device <b>160</b> as a correction result (corrected quantization parameter) of the input quantization parameter qP.</p><p id="p-0261" num="0249">In other words, in the case of transform skip, the quantization parameter correction device <b>160</b> executes processing as illustrated in the following expression (16) to correct the quantization parameter. Furthermore, in the case of non-transform skip, the quantization parameter correction device <b>120</b> executes processing as illustrated in expression (17) above to correct the quantization parameter.</p><p id="p-0262" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=Clip3(QpPrimeTsMin,63+QpBdOffset,qP&#x2212;(cu_act_enabled_flag[<i>xTbY</i>][<i>yTbY</i>]?(<i>c</i>Idx&#x3c;2?5:3):0))&#x2003;&#x2003; (18)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0263" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=Clip3(0,63+QpBdOffset,qP&#x2212;(cu_act_enabled_flag[<i>xTbY</i>][<i>yTbY</i>]?(<i>c</i>Idx&#x3c;2?5:3):0))&#x2003;&#x2003; (17) (re-described)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0264" num="0250">That is, in the case of the method 4, calculation substantially similar to the case of the method 3 is executed, and a similar correction result is obtained.</p><p id="p-0265" num="0251">In other words, the quantization parameter correction device <b>120</b> derives, similarly to the case of the method 3, the quantization parameter qP to be applied to a transform block to be processed corresponding to the component identifier cIdx by reference to the adaptive color transform flag (cu_act_enabled_flag), the correction amount dqP corresponding to ACT, the transform skip flag (transform_skip_flag) corresponding to the component identifier cIdx, the quantization parameter (qPx) at the CU level corresponding to the component identifier cIdx, the correction amount QpBdOffset corresponding to the bit depth, the minimum value &#x201c;0&#x201d; of the quantization parameter, the maximum value&#x201c;63&#x201d; of the quantization parameter before correction with the correction amount QpBdOffset corresponding to the bit depth, and the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip.</p><p id="p-0266" num="0252">In this way, the quantization parameter correction device <b>160</b> corrects the quantization parameter to fall within a valid value on the basis of the minimum value and the maximum value of the quantization parameter after correcting the quantization parameter by adaptive color transform, in the case of non-transform skip. Furthermore, the quantization parameter correction device <b>160</b> corrects the quantization parameter to fall within a valid value on the basis of the minimum value and the maximum value of the quantization parameter of the case of transform skip after correcting the quantization parameter by adaptive color transform, in the case of transform skip. By doing so, the quantization parameter correction device <b>100</b> can correct the quantization parameter so that a quantization step size &#x394;&#x3c;1 is avoided in quantization or inverse quantization in the case where the adaptive color transform and the transform skip are applied. Therefore, for example, an encoder or a decoder executes the quantization or the inverse quantization for coefficient data of an image using the quantization parameter corrected in this manner, so that the reduction in the PSNR can be suppressed and the reduction in the encoding efficiency can be suppressed, regardless of whether the transform skip or the non-transform skip is performed.</p><p id="p-0267" num="0253">Note that mts_idx may be applied instead of transform_skip_flag, and notification of whether or not the transform skip is applied may be provided as one mode of mts_idx. That is, the quantization parameter correction device <b>160</b> (the second correction unit <b>162</b>) may acquire mts_idx instead of transform_skip_flag and determine whether or not the transform skip is applied on the basis of the value. Furthermore, notification of QpPrimeTsMin may be provided for each component (Y, Cb, Cr, or CbCr). That is, the quantization parameter correction device <b>160</b> (the second correction unit <b>162</b>) may acquire QpPrimeTsMin corresponding to the component identifier cIdx and clip the lower limit of the first corrected quantization parameter qP&#x2032; using QpPrimeTsMin corresponding to the component identifier cIdx.</p><p id="p-0268" num="0254">&#x3c;Flow of Quantization Parameter Correction Processing&#x3e;</p><p id="p-0269" num="0255">Next, an example of a flow of quantization parameter correction processing executed by the quantization parameter correction device <b>160</b> will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0270" num="0256">When the quantization parameter correction processing is started, in step S<b>161</b>, the first correction unit <b>161</b> of the quantization parameter correction device <b>160</b> determines whether or not to apply the adaptive color transform by determining whether or not condition 1 is satisfied. This condition 1 is similar to the case of the first embodiment (<figref idref="DRAWINGS">FIG. <b>3</b></figref>). In a case where it is determined that the condition 1 is satisfied (that is, the adaptive color transform is applied), the processing proceeds to step S<b>162</b>.</p><p id="p-0271" num="0257">In step S<b>162</b>, the first correction unit <b>161</b> adds the correction amount dqPx corresponding to the component identifier cIdx to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. This processing is executed similarly to the processing in step S<b>102</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0272" num="0258">When the processing in step S<b>162</b> is completed, the processing proceeds to step S<b>164</b>. Furthermore, in a case where it is determined in step S<b>161</b> that the condition 1 is not satisfied (that is, the adaptive color transform is not applied), the processing proceeds to step S<b>163</b>.</p><p id="p-0273" num="0259">In step S<b>163</b>, the first correction unit <b>161</b> adds the correction amount &#x201c;0&#x201d; to the quantization parameter qPx at the CU level corresponding to the component identifier cIdx to derive the first corrected quantization parameter qP&#x2032;. This processing is executed similarly to the processing in step S<b>103</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0274" num="0260">When the processing in step S<b>163</b> is completed, the processing proceeds to step S<b>164</b>.</p><p id="p-0275" num="0261">In step S<b>164</b>, the second correction unit <b>162</b> determines whether or not the transform skip is applied by determining whether or not condition 2 is satisfied. This condition 2 is similar to the case of the first embodiment (<figref idref="DRAWINGS">FIG. <b>3</b></figref>). When it is determined that the condition 2 is satisfied (that is, the transform skip is performed), the processing proceeds to step S<b>165</b>.</p><p id="p-0276" num="0262">In step S<b>165</b>, the second correction unit <b>162</b> clips the upper limit and the lower limit of the first corrected quantization parameter qP&#x2032; using (63+QpBdOffset) and QpPrimeTsMin to derive the second corrected quantization parameter qP&#x2033;. That is, the second correction unit <b>162</b> executes calculation of the following expression (19).</p><p id="p-0277" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=Clip3(QpPrimeTsMin,63+QpBdOffset,qP&#x2032;)&#x2003;&#x2003; (19)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0278" num="0263">When the processing of step S<b>165</b> ends, the quantization parameter correction processing ends. Furthermore, in a case where it is determined in step S<b>164</b> that the condition 2 is not satisfied (that is, the non-transform skip is applied), the processing proceeds to step S<b>166</b>.</p><p id="p-0279" num="0264">In step S<b>166</b>, the second correction unit <b>162</b> clips the upper limit and the lower limit of the first corrected quantization parameter qP&#x2032; using (63+QpBdOffset) and the value &#x201c;0&#x201d; to derive the second corrected quantization parameter qP&#x2033;. That is, the second correction unit <b>162</b> executes calculation of the above-described expression (15).</p><p id="p-0280" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>qP&#x2033;=Clip3(0,63+QpBdOffset,qP&#x2032;)&#x2003;&#x2003; (15) (re-described)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0281" num="0265">When the processing of step S<b>166</b> ends, the quantization parameter correction processing ends.</p><p id="p-0282" num="0266">By executing the quantization parameter correction processing as described above, the quantization parameter correction device <b>100</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the quantization or the inverse quantization when the adaptive color transform and the transform skip are applied. Therefore, for example, an encoder or a decoder executes the quantization or the inverse quantization for the coefficient data of an image using the quantization parameter corrected in this manner, so that the reduction in the PSNR can be suppressed and the reduction in the encoding efficiency can be suppressed.</p><heading id="h-0015" level="1">6. Fifth Embodiment</heading><p id="p-0283" num="0267">&#x3c;Image Encoding Device&#x3e;</p><p id="p-0284" num="0268">The present technology (various methods) described above can be applied to arbitrary apparatuses, devices, systems, and the like. For example, the present technology can be applied to an image encoding device that encodes image data.</p><p id="p-0285" num="0269"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram illustrating an example of a configuration of an image encoding device that is one aspect of an image processing device to which the present technology is applied. An image encoding device <b>300</b> illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> is a device that encodes image data of a moving image. For example, the image encoding device <b>300</b> encodes image data of a moving image by an encoding method such as versatile video coding (VVC), advanced video coding (AVC), or high efficiency video coding (HEVC) described in the above-described Non-Patent Documents.</p><p id="p-0286" num="0270">Note that <figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates main processing units, data flows, and the like, and those illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> are not necessarily everything. That is, in the image encoding device <b>300</b>, there may be a processing unit not illustrated as a block in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, or processing or data flow not illustrated as an arrow or the like in <figref idref="DRAWINGS">FIG. <b>10</b></figref>. This is similar in other drawings for describing a processing unit and the like in the image encoding device <b>300</b>.</p><p id="p-0287" num="0271">As illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the image encoding device <b>300</b> includes a control unit <b>301</b>, a rearrangement buffer <b>311</b>, a calculation unit <b>312</b>, a transform quantization unit <b>313</b>, an encoding unit <b>314</b>, and an accumulation buffer <b>315</b>. Furthermore, the image encoding device <b>300</b> includes an inverse quantization inverse transform unit <b>316</b>, a calculation unit <b>317</b>, an in-loop filter unit <b>318</b>, a frame memory <b>319</b>, a prediction unit <b>320</b>, and a rate control unit <b>321</b>.</p><p id="p-0288" num="0272">&#x3c;Control Unit&#x3e;</p><p id="p-0289" num="0273">The control unit <b>301</b> divides moving image data held by the rearrangement buffer <b>311</b> into blocks (CUs, PUs, TUs, or the like) in units of processing on the basis of a block size in external or pre-designated units of processing. Furthermore, the control unit <b>301</b> determines encoding parameters (header information Hinfo, prediction mode information Pinfo, transform information Tinfo, filter information Finfo, and the like) to be supplied to each block on the basis of, for example, rate-distortion optimization (RDO). For example, the control unit <b>301</b> can set a transform skip flag or the like.</p><p id="p-0290" num="0274">Details of these encoding parameters will be described below. After determining the above-described encoding parameters, the control unit <b>301</b> supplies the encoding parameters to each block. Specifically, the encoding parameters are as follows.</p><p id="p-0291" num="0275">The header information Hinfo is supplied to each block. The prediction mode information Pinfo is supplied to the encoding unit <b>314</b> and the prediction unit <b>320</b>. The transform information Tinfo is supplied to the encoding unit <b>314</b>, the transform quantization unit <b>313</b>, and the inverse quantization inverse transform unit <b>316</b>. The filter information Finfo is supplied to the encoding unit <b>314</b> and the in-loop filter unit <b>318</b>.</p><p id="p-0292" num="0276">&#x3c;Rearrangement Buffer&#x3e;</p><p id="p-0293" num="0277">Each field (input image) of moving image data is input to the image encoding device <b>300</b> in reproduction order (display order). The rearrangement buffer <b>311</b> acquires and holds (stores) each input image in its reproduction order (display order). The rearrangement buffer <b>311</b> rearranges the input images in encoding order (decoding order) or divides the input images into blocks in units of processing on the basis of the control of the control unit <b>301</b>. The rearrangement buffer <b>311</b> supplies the processed input image to the calculation unit <b>312</b>.</p><p id="p-0294" num="0278">&#x3c;Calculation Unit&#x3e;</p><p id="p-0295" num="0279">The calculation unit <b>312</b> subtracts a predicted image P supplied from the prediction unit <b>320</b> from an image corresponding to a block in units of processing supplied from the rearrangement buffer <b>311</b> to derive residual data D, and supplies the residual data D to the transform quantization unit <b>313</b>.</p><p id="p-0296" num="0280">&#x3c;Transform Quantization Unit&#x3e;</p><p id="p-0297" num="0281">The transform quantization unit <b>313</b> executes processing regarding transform quantization. For example, the transform quantization unit <b>313</b> acquires the residual data D supplied from the calculation unit <b>312</b>. Furthermore, the transform quantization unit <b>313</b> acquires the prediction mode information Pinfo and the transform information Tinfo supplied from the control unit <b>301</b>. The transform quantization unit <b>313</b> executes transform quantization processing for the residual data D on the basis of the prediction mode information Pinfo and the transform information Tinfo to derive quantized coefficient data level. In the transform quantization processing, for example, pieces of processing such as adaptive color transform, orthogonal transform, and quantization are executed. Of course, the processing included in the transform quantization processing is arbitrary, and some of the above-described pieces of processing may be omitted, or processing other than the above-described pieces of processing may be included. The transform quantization unit <b>313</b> supplies the derived quantized coefficient data level to the encoding unit <b>314</b> and the inverse quantization inverse transform unit <b>316</b>.</p><p id="p-0298" num="0282">&#x3c;Encoding Unit&#x3e;</p><p id="p-0299" num="0283">The encoding unit <b>314</b> acquires the quantized coefficient data level (or the residual data D) supplied from the transform quantization unit <b>313</b>. Furthermore, the encoding unit <b>314</b> acquires various encoding parameters (header information Hinfo, prediction mode information Pinfo, transform information Tinfo, filter information Finfo, and the like) supplied from the control unit <b>301</b>. Moreover, the encoding unit <b>314</b> acquires information regarding a filter such as a filter coefficient supplied from the in-loop filter unit <b>318</b>. Furthermore, the encoding unit <b>314</b> acquires information regarding an optimum prediction mode supplied from the prediction unit <b>320</b>.</p><p id="p-0300" num="0284">The encoding unit <b>314</b> performs entropy encoding (lossless encoding) for the quantized coefficient data level or the residual data D to generate a bit string (coded data). The encoding unit <b>314</b> can apply, for example, context-based adaptive binary arithmetic code (CABAC) as the entropy encoding. The encoding unit <b>314</b> can apply, for example, context-based adaptive variable length code (CAVLC) as the entropy encoding. Of course, the content of this entropy encoding is arbitrary and is not limited to these examples.</p><p id="p-0301" num="0285">Furthermore, the encoding unit <b>314</b> derives residual information Rinfo from the quantized transform coefficient level, and encodes the residual information Rinfo to generate a bit string.</p><p id="p-0302" num="0286">Moreover, the encoding unit <b>314</b> includes the information regarding a filter supplied from the in-loop filter unit <b>318</b> to the filter information Finfo, and includes the information regarding an optimal prediction mode supplied from the prediction unit <b>320</b> to the prediction mode information Pinfo. Then, the encoding unit <b>314</b> encodes the above-described various encoding parameters (header information Hinfo, prediction mode information Pinfo, transform information Tinfo, filter information Finfo, and the like) to generate a bit string.</p><p id="p-0303" num="0287">Furthermore, the encoding unit <b>314</b> multiplexes the bit string of the various types of information generated as described above to generate coded data. The encoding unit <b>314</b> supplies the coded data to the accumulation buffer <b>315</b>.</p><p id="p-0304" num="0288">&#x3c;Accumulation Buffer&#x3e;</p><p id="p-0305" num="0289">The accumulation buffer <b>315</b> temporarily stores the coded data obtained by the encoding unit <b>314</b>. The accumulation buffer <b>315</b> outputs the stored coded data to an outside of the image encoding device <b>300</b> as a bitstream or the like at predetermined timing. For example, the coded data is transmitted to a decoding side via an arbitrary recording medium, an arbitrary transmission medium, an arbitrary information processing device, or the like. That is, the accumulation buffer <b>315</b> is also a transmission unit that transmits coded data (bitstream).</p><p id="p-0306" num="0290">&#x3c;Inverse Quantization Inverse Transform Unit&#x3e;</p><p id="p-0307" num="0291">The inverse quantization inverse transform unit <b>316</b> executes processing regarding inverse quantization inverse transform. For example, the inverse quantization inverse transform unit <b>316</b> acquires the quantized coefficient data level supplied from the transform quantization unit <b>313</b>. For example, the inverse quantization inverse transform unit <b>316</b> acquires the transform information Tinfo supplied from the control unit <b>301</b>.</p><p id="p-0308" num="0292">The inverse quantization inverse transform unit <b>316</b> executes inverse quantization inverse transformation processing for the quantized coefficient data level on the basis of the transformation information Tinfo to derive residual data D&#x2032;. This inverse quantization inverse transform processing is inverse processing of the transform quantization processing executed in the transform quantization unit <b>313</b>. That is, in the inverse quantization inverse transform processing, for example, processing such as inverse quantization, inverse orthogonal transform, and inverse adaptive color transform are executed. The inverse quantization is inverse processing of the quantization executed in the transform quantization unit <b>313</b>. The inverse orthogonal transform is inverse processing of the orthogonal transform executed in the transform quantization unit <b>313</b>. The inverse adaptive color transform is inverse processing of the adaptive color transform executed in the transform quantization unit <b>313</b>. Of course, the processing included in the inverse quantization inverse transform processing is arbitrary, and some of the above-described pieces of processing may be omitted, or processing other than the above-described processing may be included. The inverse quantization inverse transform unit <b>316</b> supplies the derived residual data D&#x2032; to the calculation unit <b>317</b>.</p><p id="p-0309" num="0293">Note that since the inverse quantization inverse transform unit <b>316</b> is similar to an inverse quantization inverse transform unit on a decoding side (to be described below), description of the decoding side (to be described below) can be applied to the inverse quantization inverse transform unit <b>316</b>.</p><p id="p-0310" num="0294">&#x3c;Calculation Unit&#x3e;</p><p id="p-0311" num="0295">The calculation unit <b>317</b> acquires the residual data D&#x2032; supplied from the inverse quantization inverse transform unit <b>316</b> and the predicted image P supplied from the prediction unit <b>320</b>. The calculation unit <b>317</b> adds the residual data D&#x2032; and the predicted image corresponding to the residual data D&#x2032; to derive a locally decoded image. The calculation unit <b>317</b> supplies the derived locally decoded image to the in-loop filter unit <b>318</b> and the frame memory <b>319</b>.</p><p id="p-0312" num="0296">&#x3c;In-Loop Filter Unit&#x3e;</p><p id="p-0313" num="0297">The in-loop filter unit <b>318</b> executes processing regarding in-loop filter processing. For example, the in-loop filter unit <b>318</b> acquires the locally decoded image supplied from the calculation unit <b>317</b>. For example, the in-loop filter unit <b>318</b> acquires the filter information Finfo supplied from the control unit <b>301</b>. For example, the in-loop filter unit <b>318</b> acquires the input image (original image) supplied from the rearrangement buffer <b>311</b>. Note that the information input to the in-loop filter unit <b>318</b> is arbitrary, and information other than the aforementioned information may be included. For example, information such as a prediction mode, motion information, a code amount target value, a quantization parameter QP, a picture type, a block (a CU, a CTU, or the like) may be input to the in-loop filter unit <b>318</b>, as necessary.</p><p id="p-0314" num="0298">The in-loop filter unit <b>318</b> appropriately executes filter processing for the locally decoded image on the basis of the filter information Finfo. The in-loop filter unit <b>318</b> also uses the input image (original image) and other input information for the filter processing as necessary.</p><p id="p-0315" num="0299">For example, the in-loop filter unit <b>318</b> can apply a bilateral filter as the filter processing. For example, the in-loop filter unit <b>318</b> can apply a deblocking filter (DBF) as the filter processing. For example, the in-loop filter unit <b>318</b> can apply an adaptive offset filter (sample adaptive offset (SAO)) as the filter processing. For example, the in-loop filter unit <b>318</b> can apply an adaptive loop filter (ALF) as the filter processing. Furthermore, the in-loop filter unit <b>318</b> can apply a plurality of filters in combination as the filter processing. Note that which filter is applied and in which order the filters are applied are arbitrary and can be selected as appropriate. For example, the in-loop filter unit <b>318</b> applies four in-loop filters of the bilateral filter, the deblocking filter, the adaptive offset filter, and the adaptive loop filter in this order as the filter processing.</p><p id="p-0316" num="0300">Of course, the filter processing executed by the in-loop filter unit <b>318</b> is arbitrary and is not limited to the above example. For example, the in-loop filter unit <b>318</b> may apply a Wiener filter or the like.</p><p id="p-0317" num="0301">The in-loop filter unit <b>318</b> supplies the filtered locally decoded image to the frame memory <b>319</b>. Note that, in a case of transmitting the information regarding filters such as filter coefficients to the decoding side, the in-loop filter unit <b>318</b> supplies the information regarding filters to the encoding unit <b>314</b>.</p><p id="p-0318" num="0302">&#x3c;Frame Memory&#x3e;</p><p id="p-0319" num="0303">The frame memory <b>319</b> executes processing regarding storage of data related to an image. For example, the frame memory <b>319</b> acquires the locally decoded image supplied from the calculation unit <b>317</b> and the filtered locally decoded image supplied from the in-loop filter unit <b>318</b>, and retains (stores) the locally decoded images. Furthermore, the frame memory <b>319</b> reconstructs and retains a decoded image for each picture using the locally decoded images (stores the decoded image in a buffer in the frame memory <b>319</b>). The frame memory <b>319</b> supplies the decoded image (or a part thereof) to the prediction unit <b>320</b> in response to a request from the prediction unit <b>320</b>.</p><p id="p-0320" num="0304">&#x3c;Prediction Unit&#x3e;</p><p id="p-0321" num="0305">The prediction unit <b>320</b> executes processing regarding generation of a predicted image. For example, the prediction unit <b>320</b> acquires the prediction mode information Pinfo supplied from the control unit <b>301</b>. For example, the prediction unit <b>320</b> acquires the input image (original image) supplied from the rearrangement buffer <b>311</b>. For example, the prediction unit <b>320</b> acquires the decoded image (or a part thereof) read from the frame memory <b>319</b>.</p><p id="p-0322" num="0306">The prediction unit <b>320</b> executes prediction processing such as inter prediction or intra prediction using the prediction mode information Pinfo and the input image (original image). That is, the prediction unit <b>320</b> performs prediction and motion compensation by reference to the decoded image as a reference to generate the predicted image P. The prediction unit <b>320</b> supplies the generated predicted image P to the calculation units <b>312</b> and <b>317</b>. Furthermore, the prediction unit <b>320</b> supplies the prediction mode selected by the above processing, that is, the information regarding an optimal prediction mode to the encoding unit <b>314</b>, as necessary.</p><p id="p-0323" num="0307">&#x3c;Rate control Unit&#x3e;</p><p id="p-0324" num="0308">The rate control unit <b>321</b> executes processing regarding rate control. For example, the rate control unit <b>321</b> controls a rate of a quantization operation of the transform quantization unit <b>313</b> so that overflow or underflow does not occur on the basis of a code amount of the coded data accumulated in the accumulation buffer <b>315</b>.</p><p id="p-0325" num="0309">&#x3c;Application of Present Technology&#x3e;</p><p id="p-0326" num="0310">The present technology described in &#x3c;1. Correction of Quantization Parameter&#x3e;, &#x3c;2. First Embodiment&#x3e;, &#x3c;3. Second Embodiment&#x3e;, &#x3c;4. Third Embodiment&#x3e;, and &#x3c;5. Fourth Embodiment&#x3e; can be applied to the image encoding device <b>300</b> having the above configuration.</p><p id="p-0327" num="0311">&#x3c;Control Unit&#x3e;</p><p id="p-0328" num="0312">For example, in a case of applying the above-described &#x201c;method 1&#x201d;, the control unit <b>301</b> derives a quantization parameter qPx at a CU level corresponding to a component identifier cIdx and supplies the quantization parameter qPx to the transform quantization unit <b>313</b> and the inverse quantization inverse transform unit <b>316</b>. The control unit <b>301</b> derives cu_act_enabled_flag as a parameter regarding adaptive color transform, and supplies cu_act_enabled_flag to the transform quantization unit <b>313</b> and the inverse quantization inverse transform unit <b>316</b>. The control unit <b>301</b> derives a correction amount dqPx corresponding to the component identifier cIdx as the parameter regarding adaptive color transform, and supplies the correction amount dqPx to the transform quantization unit <b>313</b> and the inverse quantization inverse transform unit <b>316</b>. The control unit <b>301</b> derives transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx as a parameter regarding transform skip, and supplies the transform_skip_flag[xTbY][yTbY][cIdx] to the transform quantization unit <b>313</b> and the inverse quantization inverse transform unit <b>316</b>. The control unit <b>301</b> derives a minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip as the parameter regarding transform skip, and supplies the minimum value QpPrimeTsMin to the transform quantization unit <b>313</b> and the inverse quantization inverse transform unit <b>316</b>. Furthermore, the control unit <b>301</b> also supplies these parameters to the encoding unit <b>314</b>.</p><p id="p-0329" num="0313">For example, in a case of applying the above-described &#x201c;method 2&#x201d;, the control unit <b>301</b> supplies the parameters to be supplied in the case of applying the &#x201c;method 1&#x201d; to the transform quantization unit <b>313</b>, the inverse quantization inverse transform unit <b>316</b>, and the encoding unit <b>314</b>. In addition to these parameters, the control unit <b>301</b> supplies a minimum value &#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip to the inverse quantization inverse transform unit <b>316</b> and the encoding unit <b>314</b> as the parameter regarding transform skip.</p><p id="p-0330" num="0314">For example, in a case of applying the above-described &#x201c;method 3&#x201d;, the control unit <b>301</b> supplies the parameters to be supplied in the case of applying the &#x201c;method 1&#x201d; to the transform quantization unit <b>313</b>, the inverse quantization inverse transform unit <b>316</b>, and the encoding unit <b>314</b>. In addition to these parameters, the control unit <b>301</b> supplies a correction amount QpBdOffset corresponding to a bit depth to the transform quantization unit <b>313</b>, the inverse quantization inverse transform unit <b>316</b>, and the encoding unit <b>314</b>.</p><p id="p-0331" num="0315">For example, in a case of applying the above-described &#x201c;method 4&#x201d;, the control unit <b>301</b> supplies the parameters to be supplied in the case of applying the &#x201c;method 3&#x201d; to the transform quantization unit <b>313</b>, the inverse quantization inverse transform unit <b>316</b>, and the encoding unit <b>314</b>.</p><p id="p-0332" num="0316">&#x3c;Transform Quantization Unit&#x3e;</p><p id="p-0333" num="0317">For example, in the case of applying the above-described &#x201c;method 1&#x201d;, the transform quantization unit <b>313</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>301</b>. Furthermore, the transform quantization unit <b>313</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b> as the parameter regarding adaptive color transform. The transform quantization unit <b>313</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding adaptive color transform. Moreover, the transform quantization unit <b>313</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding transform skip. The transform quantization unit <b>313</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip. The transform quantization unit <b>313</b> executes transform quantization processing using the acquired parameters.</p><p id="p-0334" num="0318">For example, in the case of applying the above-described &#x201c;method 2&#x201d;, the transform quantization unit <b>313</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>301</b>. Furthermore, the transform quantization unit <b>313</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b> as the parameter regarding adaptive color transform. The transform quantization unit <b>313</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding adaptive color transform. Moreover, the transform quantization unit <b>313</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding transform skip. The transform quantization unit <b>313</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip. The transform quantization unit <b>313</b> acquires the minimum value&#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip. The transform quantization unit <b>313</b> executes transform quantization processing using the acquired parameters.</p><p id="p-0335" num="0319">For example, in the case of applying the above-described &#x201c;method 3&#x201d;, the transform quantization unit <b>313</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>301</b>. Furthermore, the transform quantization unit <b>313</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b> as the parameter regarding adaptive color transform. The transform quantization unit <b>313</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding adaptive color transform. Moreover, the transform quantization unit <b>313</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding transform skip. The transform quantization unit <b>313</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip. The transform quantization unit <b>313</b> acquires the correction amount QpBdOffset corresponding to the bit depth supplied from the control unit <b>301</b> as the parameter regarding transform skip. The transform quantization unit <b>313</b> executes transform quantization processing using the acquired parameters.</p><p id="p-0336" num="0320">For example, in the case of applying the above-described &#x201c;method 4&#x201d;, the transform quantization unit <b>313</b> acquires the same parameters as those acquired in the case of applying the &#x201c;method 3&#x201d;. The transform quantization unit <b>313</b> executes transform quantization processing using the acquired parameters.</p><p id="p-0337" num="0321">&#x3c;Configuration Example of Transform Quantization Unit&#x3e;</p><p id="p-0338" num="0322"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram illustrating a main configuration example of the transform quantization unit <b>313</b> in <figref idref="DRAWINGS">FIG. <b>10</b></figref>. As illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the transform quantization unit <b>313</b> includes an adaptive color transform unit <b>341</b>, an orthogonal transform unit <b>342</b>, and a quantization unit <b>343</b>.</p><p id="p-0339" num="0323">The adaptive color transform unit <b>341</b> executes processing regarding adaptive color transform (ALT). For example, the adaptive color transform unit <b>341</b> acquires residual data res_x (that is, the residual data D in <figref idref="DRAWINGS">FIG. <b>10</b></figref>) supplied from the calculation unit <b>312</b>. The adaptive color transform unit <b>341</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b>. The adaptive color transform unit <b>341</b> executes adaptive color transform for the residual data res_x on the basis of the value of cu_act_enabled_flag. For example, in a case where cu_act_enabled_flag is true (for example, &#x201c;1&#x201d;), the adaptive color transform unit <b>341</b> executes calculation as described in the expression (1) and performs RGB-to-YCgCo transform for the residual data res_x including R, G, and B components. By the processing, adaptive color transform coefficient data res_x&#x2032; including components of Y, Cg, and Co is generated. The adaptive color transform unit <b>341</b> supplies the generated adaptive color transform coefficient data res_x&#x2032; to the orthogonal transform unit <b>342</b>.</p><p id="p-0340" num="0324">The orthogonal transform unit <b>342</b> executes processing regarding orthogonal transform. For example, the orthogonal transform unit <b>342</b> acquires the adaptive color transform coefficient data res_x&#x2032; supplied from the adaptive color transform unit <b>341</b>. The orthogonal transform unit <b>342</b> acquires the transform information Tinfo and the prediction mode information Pinfo supplied from the control unit <b>301</b>. For example, the orthogonal transform unit <b>342</b> can acquire information such as transform_skip_flag, mts_idx, and lfnst_idx as the transform information Tinfo. The orthogonal transform unit <b>342</b> orthogonally transforms the adaptive color transform coefficient data res_x&#x2032; using the acquired information to generate orthogonally transformed coefficient data coef_x. The orthogonal transform unit <b>342</b> supplies the generated orthogonally transformed coefficient data coef_x to the quantization unit <b>343</b>.</p><p id="p-0341" num="0325">The quantization unit <b>343</b> executes processing regarding quantization. For example, the quantization unit <b>343</b> acquires the orthogonally transformed coefficient data coeff_x supplied from the orthogonal transform unit <b>342</b>. The quantization unit <b>343</b> quantizes the orthogonally transformed coefficient data coeff_x to generate quantized coefficient data qcoef_x. The quantization unit <b>343</b> supplies the generated quantized coefficient data qcoef_x (that is, the quantized coefficient data level in <figref idref="DRAWINGS">FIG. <b>10</b></figref>) to the encoding unit <b>314</b> and the inverse quantization inverse transform unit <b>316</b>.</p><p id="p-0342" num="0326">For example, in the case of applying the above-described &#x201c;method 1&#x201d;, the quantization unit <b>343</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>301</b>. Furthermore, the quantization unit <b>343</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. The quantization unit <b>343</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. Moreover, the quantization unit <b>343</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the transform skip. The quantization unit <b>343</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>301</b> as the parameter regarding the transform skip.</p><p id="p-0343" num="0327">The quantization unit <b>343</b> quantizes the orthogonally transformed coefficient data coeff_x using the acquired parameters to generate the quantized coefficient data qcoef_x.</p><p id="p-0344" num="0328">For example, in the case of applying the above-described &#x201c;method 2&#x201d;, the quantization unit <b>343</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>301</b>. Furthermore, the quantization unit <b>343</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. The quantization unit <b>343</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. Moreover, the quantization unit <b>343</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the transform skip. The quantization unit <b>343</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>301</b> as the parameter regarding the transform skip. The quantization unit <b>343</b> acquires the minimum value&#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip.</p><p id="p-0345" num="0329">The quantization unit <b>343</b> quantizes the orthogonally transformed coefficient data coeff_x using the acquired parameters to generate the quantized coefficient data qcoef_x.</p><p id="p-0346" num="0330">For example, in the case of applying the above-described &#x201c;method 3&#x201d;, the quantization unit <b>343</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>301</b>. Furthermore, the quantization unit <b>343</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. The quantization unit <b>343</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. Moreover, the quantization unit <b>343</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the transform skip. The quantization unit <b>343</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>301</b> as the parameter regarding the transform skip. The quantization unit <b>343</b> acquires the correction amount QpBdOffset corresponding to the bit depth supplied from the control unit <b>301</b> as the parameter regarding transform skip.</p><p id="p-0347" num="0331">The quantization unit <b>343</b> quantizes the orthogonally transformed coefficient data coeff_x using the acquired parameters to generate the quantized coefficient data qcoef_x.</p><p id="p-0348" num="0332">For example, in the case of applying the above-described &#x201c;method 4&#x201d;, the quantization unit <b>343</b> acquires the same parameters as those acquired in the case of applying the &#x201c;method 3&#x201d;. The quantization unit <b>343</b> quantizes the orthogonally transformed coefficient data coeff_x using the acquired parameters to generate the quantized coefficient data qcoef_x.</p><p id="p-0349" num="0333">&#x3c;Configuration Example of Quantization Unit&#x3e;</p><p id="p-0350" num="0334"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a block diagram illustrating a main configuration example of the quantization unit <b>343</b> in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. As illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the quantization unit <b>343</b> includes a quantization parameter correction unit <b>351</b> and a quantization processing unit <b>352</b>.</p><p id="p-0351" num="0335">The quantization parameter correction unit <b>351</b> executes processing regarding correction of the quantization parameter. For example, the quantization parameter correction unit <b>351</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx. The quantization parameter correction unit <b>351</b> corrects the quantization parameter qPx at the CU level corresponding to the component identifier cIdx and supplies the corrected quantization parameter that is the quantization parameter after correction to the quantization processing unit <b>352</b>.</p><p id="p-0352" num="0336">The quantization processing unit <b>352</b> executes processing regarding quantization. For example, the quantization processing unit <b>352</b> acquires the orthogonally transformed coefficient data coef_x supplied from the orthogonal transform unit <b>342</b>. The quantization processing unit <b>352</b> acquires the corrected quantization parameter supplied from the quantization parameter correction unit <b>351</b>. The quantization processing unit <b>352</b> quantizes the orthogonally transformed coefficient data coef_x using the corrected quantization parameter to generate the quantized coefficient data qcoef_x. The quantization processing unit <b>352</b> supplies the generated quantized coefficient data qcoef_x (that is, the quantized coefficient data level in <figref idref="DRAWINGS">FIG. <b>10</b></figref>) to the encoding unit <b>314</b> and the inverse quantization inverse transform unit <b>316</b>.</p><p id="p-0353" num="0337">In a case where the present technology is applied in the quantization unit <b>343</b> having the above-described configuration, the quantization parameter correction unit <b>351</b> corrects the quantization parameter on the basis of the parameter regarding adaptive color transform and further corrects the quantization parameter on the basis of the parameter regarding transform skip. The quantization processing unit <b>352</b> quantizes the coefficient data of an image to be encoded by using the corrected quantization parameter that is the quantization parameter corrected by the quantization parameter correction unit <b>351</b>.</p><p id="p-0354" num="0338">For example, in the case of applying the above-described &#x201c;method 1&#x201d;, the quantization parameter correction device <b>100</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) is applied as the quantization parameter correction unit <b>351</b>. That is, the quantization parameter correction unit <b>351</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>301</b>. Furthermore, the quantization parameter correction unit <b>351</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. The quantization parameter correction unit <b>351</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. Moreover, the quantization parameter correction unit <b>351</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding transform skip. The quantization parameter correction unit <b>351</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip.</p><p id="p-0355" num="0339">The quantization parameter correction unit <b>351</b> corrects qPx by a method as described in the first embodiment, using the acquired cu_act_enabled_flag, dqPx, transform_skip_flag[xTbY][yTbY][cIdx], and QpPrimeTsMin. That is, the quantization parameter correction unit <b>351</b> executes calculation as in the expression (5) or the expression (6) to generate the second corrected quantization parameter qP&#x2033;. The quantization parameter correction unit <b>351</b> supplies the generated second corrected quantization parameter qP&#x2033; to the quantization processing unit <b>352</b>.</p><p id="p-0356" num="0340">By doing so, the quantization parameter correction unit <b>351</b> can correct the quantization parameter so that a quantization step size &#x394;&#x3c;1 is avoided in the quantization when the adaptive color transform and the transform skip are applied. Therefore, the quantization processing unit <b>352</b> quantizes the coefficient data of an image using the quantization parameter corrected in this way, so that the quantization unit <b>343</b> (transform quantization unit <b>313</b>) can suppress the reduction in the PSNR. Therefore, the image encoding device <b>300</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0357" num="0341">For example, in the case of applying the above-described &#x201c;method 2&#x201d;, the quantization parameter correction device <b>120</b> (<figref idref="DRAWINGS">FIG. <b>4</b></figref>) is applied as the quantization parameter correction unit <b>351</b>. That is, the quantization parameter correction unit <b>351</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>301</b>. Furthermore, the quantization parameter correction unit <b>351</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. The quantization parameter correction unit <b>351</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. Moreover, the quantization parameter correction unit <b>351</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding transform skip. The quantization parameter correction unit <b>351</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip. The quantization parameter correction unit <b>351</b> acquires the minimum value&#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip.</p><p id="p-0358" num="0342">The quantization parameter correction unit <b>351</b> corrects qPx by a method as described in the second embodiment, using the acquired cu_act_enabled_flag, dqPx, transform_skip_flag[xTbY][yTbY][cIdx], QpPrimeTsMin, and the value &#x201c;0&#x201d;. That is, the quantization parameter correction unit <b>351</b> executes calculation as in the expression (5) or the expression (13) to generate the second corrected quantization parameter qP&#x2033;. The quantization parameter correction unit <b>351</b> supplies the generated second corrected quantization parameter qP&#x2033; to the quantization processing unit <b>352</b>.</p><p id="p-0359" num="0343">By doing so, the quantization parameter correction unit <b>351</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the quantization, regardless of whether or not the transform skip is applied, in the case where the adaptive color transform is applied. Therefore, the quantization processing unit <b>352</b> quantizes the coefficient data of an image using the quantization parameter corrected in this way, so that the quantization unit <b>343</b> (transform quantization unit <b>313</b>) can suppress the reduction in the PSNR. Therefore, the image encoding device <b>300</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0360" num="0344">For example, in the case of applying the above-described &#x201c;method 3&#x201d;, the quantization parameter correction device <b>140</b> (<figref idref="DRAWINGS">FIG. <b>6</b></figref>) is applied as the quantization parameter correction unit <b>351</b>. That is, the quantization parameter correction unit <b>351</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>301</b>. Furthermore, the quantization parameter correction unit <b>351</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. The quantization parameter correction unit <b>351</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. Moreover, the quantization parameter correction unit <b>351</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding transform skip. The quantization parameter correction unit <b>351</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip. The quantization parameter correction unit <b>351</b> acquires the correction amount QpBdOffset corresponding to the bit depth supplied from the control unit <b>301</b> as the parameter regarding transform skip.</p><p id="p-0361" num="0345">The quantization parameter correction unit <b>351</b> corrects qPx by a method as described in the third embodiment, using the acquired cu_act_enabled_flag, dqPx, transform_skip_flag[xTbY][yTbY][cIdx], QpPrimeTsMin, and QpBdOffset. That is, the quantization parameter correction unit <b>351</b> executes calculation as in the expression (16) or the expression (17) to generate the third corrected quantization parameter qP&#x2032;&#x2033;. The quantization parameter correction unit <b>351</b> supplies the generated third corrected quantization parameter qP&#x2032;&#x2033; to the quantization processing unit <b>352</b>.</p><p id="p-0362" num="0346">By doing so, the value of the corrected quantization parameter falls within a range of a minimum value to a maximum value of the quantization parameter, regardless of whether or not the transform skip is applied. Furthermore, in the case of transform skip, the lower limit of the quantization parameter is further clipped with the minimum value QpPrimeTsMin of the quantization parameter at the time of the transform skip. That is, the quantization parameter correction unit <b>351</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the quantization, regardless of whether or not the transform skip is applied, in the case where the adaptive color transform is applied. Therefore, the quantization processing unit <b>352</b> quantizes the coefficient data of an image using the quantization parameter corrected in this way, so that the quantization unit <b>343</b> (transform quantization unit <b>313</b>) can suppress the reduction in the PSNR. Therefore, the image encoding device <b>300</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0363" num="0347">For example, in the case of applying the above-described &#x201c;method 4&#x201d;, the quantization parameter correction device <b>160</b> (<figref idref="DRAWINGS">FIG. <b>8</b></figref>) is applied as the quantization parameter correction unit <b>351</b>. That is, the quantization parameter correction unit <b>351</b> acquires parameters similar to those in the case of the &#x201c;method 3&#x201d;.</p><p id="p-0364" num="0348">The quantization parameter correction unit <b>351</b> corrects qPx by a method as described in the fourth embodiment, using the acquired parameters (cu_act_enabled_flag, dqPx, transform_skip_flag[xTbY][yTbY][cIdx], QpPrimeTsMin, and QpBdOffset). That is, the quantization parameter correction unit <b>351</b> executes calculation as in the expression (18) or the expression (17) to generate the second corrected quantization parameter qP&#x2033;. The quantization parameter correction unit <b>351</b> supplies the generated second corrected quantization parameter qP&#x2033; to the quantization processing unit <b>352</b>.</p><p id="p-0365" num="0349">That is, in the case of the method 4, calculation substantially similar to the case of the method 3 is executed, and a similar correction result is obtained. Therefore, even in this case, the quantization parameter correction unit <b>351</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the quantization, regardless of whether or not the transform skip is applied, in the case where the adaptive color transform is applied, similarly to the case of the method 3. Therefore, the quantization processing unit <b>352</b> quantizes the coefficient data of an image using the quantization parameter corrected in this way, so that the quantization unit <b>343</b> (transform quantization unit <b>313</b>) can suppress the reduction in the PSNR. Therefore, the image encoding device <b>300</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0366" num="0350">&#x3c;Encoding Unit&#x3e;</p><p id="p-0367" num="0351">For example, in the case of applying the above-described &#x201c;method 1&#x201d;, the encoding unit <b>314</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>301</b>. Furthermore, the encoding unit <b>314</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. The encoding unit <b>314</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. Moreover, the encoding unit <b>314</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the transform skip. The encoding unit <b>314</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip. The encoding unit <b>314</b> encodes the acquired parameters, generates a bit string, and includes the bit string in the coded data.</p><p id="p-0368" num="0352">By doing so, these pieces of information are signaled. That is, these pieces of information are supplied to the decoding-side device (decoder or the like). Therefore, the decoding-side device can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the case where the adaptive color transform and the transform skip are applied in the decoding processing. Therefore, the decoding-side device can execute inverse quantization using the quantization parameter corrected in this manner in the decoding processing. Therefore, the decoding side device can suppress the reduction in the PSNR. Therefore, the decoding-side device can implement suppression of reduction in the encoding efficiency.</p><p id="p-0369" num="0353">For example, in the case of applying the above-described &#x201c;method 2&#x201d;, the encoding unit <b>314</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>301</b>. Furthermore, the encoding unit <b>314</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. The encoding unit <b>314</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. Moreover, the encoding unit <b>314</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the transform skip. The encoding unit <b>314</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip. The encoding unit <b>314</b> acquires the minimum value&#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip. The encoding unit <b>314</b> encodes the acquired parameters, generates a bit string, and includes the bit string in the coded data.</p><p id="p-0370" num="0354">By doing so, these pieces of information are signaled. That is, these pieces of information are supplied to the decoding-side device (decoder or the like). Therefore, the decoding side device can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the case of applying adaptive color transform, regardless of whether or not the transform skip is applied in the decoding processing. Therefore, the decoding-side device can execute inverse quantization using the quantization parameter corrected in this manner in the decoding processing. Therefore, the decoding side device can suppress the reduction in the PSNR. Therefore, the decoding-side device can implement suppression of reduction in the encoding efficiency.</p><p id="p-0371" num="0355">For example, in the case of applying the above-described &#x201c;method 3&#x201d;, the encoding unit <b>314</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>301</b>. Furthermore, the encoding unit <b>314</b> acquires cu_act_enabled_flag supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. The encoding unit <b>314</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the adaptive color transform. Moreover, the encoding unit <b>314</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>301</b> as the parameter regarding the transform skip. The encoding unit <b>314</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>301</b> as the parameter regarding transform skip. The encoding unit <b>314</b> acquires the correction amount QpBdOffset corresponding to the bit depth supplied from the control unit <b>301</b> as the parameter regarding transform skip. The encoding unit <b>314</b> encodes the acquired parameters, generates a bit string, and includes the bit string in the coded data.</p><p id="p-0372" num="0356">By doing so, these pieces of information are signaled. That is, these pieces of information are supplied to the decoding-side device (decoder or the like). Therefore, the value of the corrected quantization parameter falls within the range from the minimum value to the maximum value of the quantization parameter regardless of whether or not the transform skip is applied in the decoding processing by the decoding-side device. Furthermore, in the case of transform skip, the lower limit of the quantization parameter is further clipped with the minimum value QpPrimeTsMin of the quantization parameter at the time of the transform skip. That is, the decoding side device can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the case of applying adaptive color transform, regardless of whether or not the transform skip is applied in the decoding processing. Therefore, the decoding-side device can execute inverse quantization using the quantization parameter corrected in this manner in the decoding processing. Therefore, the decoding side device can suppress the reduction in the PSNR. Therefore, the decoding-side device can implement suppression of reduction in the encoding efficiency.</p><p id="p-0373" num="0357">For example, in the case of applying the above-described &#x201c;method 4&#x201d;, the encoding unit <b>314</b> acquires parameters similar to those in the case of the &#x201c;method 3&#x201d;. The encoding unit <b>314</b> encodes the acquired parameters (cu_act_enabled_flag, dqPx, transform_skip_flag[xTbY][yTbY][cIdx], QpPrimeTsMin, and QpBdOffset), generates a bit string, and includes the bit string in the coded data.</p><p id="p-0374" num="0358">By doing so, these pieces of information are signaled. That is, these pieces of information are supplied to the decoding-side device (decoder or the like). Therefore, even in this case, the decoding side device can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the case of applying adaptive color transform, regardless of whether or not the transform skip is applied in the decoding processing. Therefore, the decoding-side device can execute inverse quantization using the quantization parameter corrected in this manner in the decoding processing. Therefore, the decoding side device can suppress the reduction in the PSNR. Therefore, the decoding-side device can implement suppression of reduction in the encoding efficiency.</p><p id="p-0375" num="0359">&#x3c;Flow of Image Encoding Processing&#x3e;</p><p id="p-0376" num="0360">Next, a flow of each processing executed by the above image encoding device <b>300</b> will be described. First, an example of a flow of image encoding processing will be described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>13</b></figref>.</p><p id="p-0377" num="0361">When the image encoding processing is started, in step S<b>301</b>, the rearrangement buffer <b>311</b> is controlled by the control unit <b>301</b> and rearranges frames of input moving image data from the display order to the encoding order.</p><p id="p-0378" num="0362">In step S<b>302</b>, the control unit <b>301</b> sets the unit of processing (performs block division) for an input image held by the rearrangement buffer <b>311</b>.</p><p id="p-0379" num="0363">In step S<b>303</b>, the control unit <b>301</b> sets the encoding parameters (for example, header information Hinfo, prediction mode information Pinfo, transform information Tinfo, and the like) for the input image held by the rearrangement buffer <b>311</b>.</p><p id="p-0380" num="0364">In step S<b>304</b>, the prediction unit <b>320</b> executes the prediction processing and generates a predicted image or the like in an optimum prediction mode. For example, in the prediction processing, the prediction unit <b>320</b> executes the intra prediction to generate a predicted image in an optimal intra prediction mode, executes the inter prediction to generate a predicted image in an optimal inter prediction mode, and selects an optimal prediction mode from among the predicted images on the basis of a cost function value and the like.</p><p id="p-0381" num="0365">In step S<b>305</b>, the calculation unit <b>312</b> calculates a difference between the input image and the predicted image in the optimal mode selected by the prediction processing in step S<b>304</b>. That is, the calculation unit <b>312</b> generates the residual data D between the input image and the predicted image. The residual data D obtained in this manner has a smaller data amount than the original image data. Therefore, the data amount can be compressed as compared with a case of encoding the image as it is.</p><p id="p-0382" num="0366">In step S<b>306</b>, the transform quantization unit <b>313</b> executes the transform quantization processing for the residual data D generated by the processing in step S<b>305</b>, using the encoding parameters such as the transform information Tinfo generated in step S<b>303</b>, and generates the quantized coefficient data level.</p><p id="p-0383" num="0367">In step S<b>307</b>, the inverse quantization inverse transform unit <b>316</b> executes the inverse quantization inverse transform processing for the quantized coefficient data level generated in step S<b>306</b>, using the encoding parameters such as the transform information Tinfo generated in step S<b>303</b>, and generates the residual data D&#x2032;.</p><p id="p-0384" num="0368">This inverse quantization inverse transform processing is inverse processing of the transform quantization processing of step S<b>306</b>. A decoding-side device (image decoding device <b>400</b>) to be described below also executes similar processing. Therefore, the inverse quantization inverse transform processing will be described as processing of the decoding-side device (the image decoding device <b>400</b>). Then, the description can be applied to this inverse quantization inverse transform processing (step S<b>307</b>).</p><p id="p-0385" num="0369">In step S<b>308</b>, the calculation unit <b>317</b> adds the predicted image obtained by the prediction processing in step S<b>304</b> to the residual data D&#x2032; obtained by the inverse quantization inverse transform processing in step S<b>307</b>, thereby generating a locally decoded image.</p><p id="p-0386" num="0370">In step S<b>309</b>, the in-loop filter unit <b>318</b> executes the in-loop filter processing for the locally decoded image derived by the processing in step S<b>308</b>.</p><p id="p-0387" num="0371">In step S<b>310</b>, the frame memory <b>319</b> stores the locally decoded image derived by the processing in step S<b>308</b> and the locally decoded image filtered in step S<b>309</b>.</p><p id="p-0388" num="0372">In step S<b>311</b>, the encoding unit <b>314</b> encodes the quantized coefficient data level obtained by the transform quantization processing in step S<b>306</b> to generate coded data. Furthermore, at this time, the encoding unit <b>314</b> encodes the various encoding parameters (header information Hinfo, prediction mode information Pinfo, and transform information Tinfo). Moreover, the encoding unit <b>314</b> derives the residual information RInfo from the quantized transform coefficient data level and encodes the residual information RInfo.</p><p id="p-0389" num="0373">In step S<b>312</b>, the accumulation buffer <b>315</b> accumulates the coded data thus obtained, and outputs the coded data to the outside of the image encoding device <b>300</b>, for example, as a bitstream. The bitstream is transmitted to the decoding-side device via a transmission path or a recording medium, for example. Furthermore, the rate control unit <b>321</b> controls the rate as necessary. When the processing in step S<b>312</b> ends, the image encoding processing ends.</p><p id="p-0390" num="0374">&#x3c;Flow of Transform Quantization Processing&#x3e;</p><p id="p-0391" num="0375">Next, an example of a flow of the transform quantization processing executed in step S<b>306</b> of <figref idref="DRAWINGS">FIG. <b>13</b></figref> will be described with reference to the flowchart of <figref idref="DRAWINGS">FIG. <b>14</b></figref>.</p><p id="p-0392" num="0376">When the transform quantization processing is started, in step S<b>341</b>, the adaptive color transform unit <b>341</b> performs adaptive color transform for the residual data res_x generated by the processing of step S<b>305</b> on the basis of cu_act_enabled_flag generated in step S<b>303</b> (<figref idref="DRAWINGS">FIG. <b>13</b></figref>) to generate the adaptive color transform coefficient data res_x&#x2032;.</p><p id="p-0393" num="0377">In step S<b>342</b>, the orthogonal transform unit <b>342</b> orthogonally transforms the adaptive color transform coefficient data res_x&#x2032; generated in step S<b>341</b> by using the transform information Tinfo, the prediction mode information Pinfo, and the like generated in step S<b>303</b> (<figref idref="DRAWINGS">FIG. <b>13</b></figref>) to generate the orthogonally transformed coefficient data coef_x.</p><p id="p-0394" num="0378">In step S<b>343</b>, the quantization unit <b>343</b> quantizes the orthogonally transformed coefficient data coef_x generated in step S<b>342</b> by using the transform information Tinfo and the like generated in step S<b>303</b> (<figref idref="DRAWINGS">FIG. <b>13</b></figref>) to generate the quantized coefficient data qcoef_x.</p><p id="p-0395" num="0379">When the processing of step S<b>343</b> ends, the processing returns to <figref idref="DRAWINGS">FIG. <b>13</b></figref>.</p><p id="p-0396" num="0380">&#x3c;Flow of Quantization Processing&#x3e;</p><p id="p-0397" num="0381">Next, an example of a flow of the quantization processing executed in step S<b>343</b> of <figref idref="DRAWINGS">FIG. <b>14</b></figref> will be described with reference to the flowchart of <figref idref="DRAWINGS">FIG. <b>15</b></figref>.</p><p id="p-0398" num="0382">When the quantization processing is started, in step S<b>351</b>, the quantization parameter correction unit <b>351</b> executes the quantization parameter correction processing, corrects the quantization parameter, and generates the corrected quantization parameter.</p><p id="p-0399" num="0383">In step S<b>352</b>, the quantization processing unit <b>352</b> quantizes the orthogonally transformed coefficient data coef_x generated in step S<b>342</b> (<figref idref="DRAWINGS">FIG. <b>14</b></figref>) using the corrected quantization parameter generated in step S<b>351</b> to generate the quantized coefficient data qcoef_x.</p><p id="p-0400" num="0384">When the processing of step S<b>352</b> ends, the quantization processing ends, and the processing returns to <figref idref="DRAWINGS">FIG. <b>14</b></figref>.</p><p id="p-0401" num="0385">The present technology described in &#x3c;1. Correction of Quantization Parameter&#x3e;, &#x3c;2. First Embodiment&#x3e;, &#x3c;3. Second Embodiment&#x3e;, &#x3c;4. Third Embodiment&#x3e;, and &#x3c;5. Fourth Embodiment&#x3e; can be applied to such quantization processing.</p><p id="p-0402" num="0386">That is, in a case where the present technology is applied in the above quantization processing, in step S<b>351</b>, the quantization parameter correction unit <b>351</b> corrects the quantization parameter on the basis of the parameter regarding adaptive color transform and further corrects the quantization parameter on the basis of the parameter regarding transform skip. In step S<b>352</b>, the quantization processing unit <b>352</b> quantizes the coefficient data of an image to be encoded by using the corrected quantization parameter that is the quantization parameter that has been corrected.</p><p id="p-0403" num="0387">For example, in the case of applying the above-described &#x201c;method 1&#x201d;, the quantization parameter correction unit <b>351</b> applies the quantization parameter correction processing described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>3</b></figref> as the quantization parameter correction processing in step S<b>351</b>. That is, the quantization parameter correction unit <b>351</b> executes calculation as in the expression (5) or the expression (6) to generate the second corrected quantization parameter qP&#x2033;.</p><p id="p-0404" num="0388">By doing so, the quantization parameter correction unit <b>351</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the quantization when the adaptive color transform and the transform skip are applied. Therefore, the quantization processing unit <b>352</b> quantizes the coefficient data of an image using the quantization parameter corrected in this way, so that the quantization unit <b>343</b> (transform quantization unit <b>313</b>) can suppress the reduction in the PSNR. Therefore, the image encoding device <b>300</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0405" num="0389">For example, in the case of applying the above-described &#x201c;method 2&#x201d;, the quantization parameter correction unit <b>351</b> applies the quantization parameter correction processing described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>5</b></figref> as the quantization parameter correction processing in step S<b>351</b>. That is, the quantization parameter correction unit <b>351</b> executes calculation as in the expression (5) or the expression (13) to generate the second corrected quantization parameter qP&#x2033;.</p><p id="p-0406" num="0390">By doing so, the quantization parameter correction unit <b>351</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the quantization, regardless of whether or not the transform skip is applied, in the case where the adaptive color transform is applied. Therefore, the quantization processing unit <b>352</b> quantizes the coefficient data of an image using the quantization parameter corrected in this way, so that the quantization unit <b>343</b> (transform quantization unit <b>313</b>) can suppress the reduction in the PSNR. Therefore, the image encoding device <b>300</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0407" num="0391">For example, in the case of applying the above-described &#x201c;method 3&#x201d;, the quantization parameter correction unit <b>351</b> applies the quantization parameter correction processing described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>7</b></figref> as the quantization parameter correction processing in step S<b>351</b>. That is, the quantization parameter correction unit <b>351</b> executes calculation as in the expression (16) or the expression (17) to generate the third corrected quantization parameter qP&#x2032;&#x2033;.</p><p id="p-0408" num="0392">By doing so, the value of the corrected quantization parameter falls within a range of a minimum value to a maximum value of the quantization parameter, regardless of whether or not the transform skip is applied. In the case of transform skip, the lower limit of the quantization parameter is further clipped with the minimum value QpPrimeTsMin of the quantization parameter at the time of the transform skip. That is, the quantization parameter correction unit <b>351</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the quantization, regardless of whether or not the transform skip is applied, in the case where the adaptive color transform is applied. Therefore, the quantization processing unit <b>352</b> quantizes the coefficient data of an image using the quantization parameter corrected in this way, so that the quantization unit <b>343</b> (transform quantization unit <b>313</b>) can suppress the reduction in the PSNR. Therefore, the image encoding device <b>300</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0409" num="0393">For example, in the case of applying the above-described &#x201c;method 4&#x201d;, the quantization parameter correction unit <b>351</b> applies the quantization parameter correction processing described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>9</b></figref> as the quantization parameter correction processing in step S<b>351</b>. That is, the quantization parameter correction unit <b>351</b> executes calculation as in the expression (18) or the expression (17) to generate the second corrected quantization parameter qP&#x2033;.</p><p id="p-0410" num="0394">That is, in the case of the method 4, calculation substantially similar to the case of the method 3 is executed, and a similar correction result is obtained. Therefore, even in this case, the quantization parameter can be corrected so that the quantization step size &#x394;&#x3c;1 is avoided in the quantization, regardless of whether or not the transform skip is applied, in the case where the adaptive color transform is applied, similarly to the case of the method 3. Therefore, the quantization processing unit <b>352</b> quantizes the coefficient data of an image using the quantization parameter corrected in this way, so that the quantization unit <b>343</b> (transform quantization unit <b>313</b>) can suppress the reduction in the PSNR. Therefore, the image encoding device <b>300</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0411" num="0395">&#x3c;Encoding&#x3e;</p><p id="p-0412" num="0396">Note that, in step S<b>311</b> in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the encoding unit <b>314</b> encodes the various encoding parameters (header information Hinfo, prediction mode information Pinfo, and transform information Tinfo). In a case where the present technology is applied, the encoding unit <b>314</b> encodes the above-described various parameters to be applied to the correction of the quantization parameter as the encoding parameters. For example, in the case of applying the &#x201c;method 1&#x201d;, the encoding unit <b>314</b> encodes parameters such as the quantization parameter qPx at the CU level corresponding to the component identifier cIdx, cu_act_enabled_flag, the correction amount dqPx corresponding to the component identifier cIdx, transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx, and the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip. Furthermore, in the case of applying the &#x201c;method 2&#x201d;, the encoding unit <b>314</b> encodes the minimum value &#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip, in addition to the parameters to be encoded in the case of applying the &#x201c;method 1&#x201d;. Moreover, in the case of applying the &#x201c;method 3&#x201d; or the &#x201c;method 4&#x201d;, the encoding unit <b>314</b> encodes the correction amount QpBdOffset corresponding to the bit depth, in addition to the parameters to be encoded in the case of applying the &#x201c;method 1&#x201d;.</p><p id="p-0413" num="0397">By doing so, these pieces of information are signaled, so that the decoding side device can suppress the reduction in the PSNR. Therefore, the decoding-side device can implement suppression of reduction in the encoding efficiency.</p><heading id="h-0016" level="1">7. Sixth Embodiment</heading><p id="p-0414" num="0398">&#x3c;Image Decoding Device&#x3e;</p><p id="p-0415" num="0399">The present technology (various methods) described above can also be applied to an image decoding device that decodes coded data of image data.</p><p id="p-0416" num="0400"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a block diagram illustrating an example of a configuration of an image decoding device as one aspect of an image processing device to which the present technology is applied. An image decoding device <b>400</b> illustrated in <figref idref="DRAWINGS">FIG. <b>16</b></figref> is a device that decodes coded data of a moving image. For example, the image decoding device <b>400</b> decodes coded data of a moving image encoded by an encoding method such as VVC, AVC, or HEVC described in the above-described Non-Patent Documents. For example, the image decoding device <b>400</b> can decode coded data (bitstream) generated by the above-described image encoding device <b>300</b> (<figref idref="DRAWINGS">FIG. <b>10</b></figref>).</p><p id="p-0417" num="0401">Note that <figref idref="DRAWINGS">FIG. <b>16</b></figref> illustrates main processing units, data flows, and the like, and those illustrated in <figref idref="DRAWINGS">FIG. <b>16</b></figref> are not necessarily everything. That is, in the image decoding device <b>400</b>, there may be a processing unit not illustrated as a block in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, or processing or data flow not illustrated as an arrow or the like in <figref idref="DRAWINGS">FIG. <b>16</b></figref>. This is similar in other drawings for describing a processing unit and the like in the image decoding device <b>400</b>.</p><p id="p-0418" num="0402">As illustrated in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, the image decoding device <b>400</b> includes a control unit <b>401</b>, an accumulation buffer <b>411</b>, a decoding unit <b>412</b>, an inverse quantization inverse transform unit <b>413</b>, a calculation unit <b>414</b>, an in-loop filter unit <b>415</b>, a rearrangement buffer <b>416</b>, a frame memory <b>417</b>, and a prediction unit <b>418</b>. Note that the prediction unit <b>418</b> includes an intra prediction unit and an inter prediction unit (not illustrated).</p><p id="p-0419" num="0403">&#x3c;Control Unit&#x3e;</p><p id="p-0420" num="0404">The control unit <b>401</b> executes processing regarding decoding control. For example, the control unit <b>401</b> acquires encoding parameters (header information Hinfo, prediction mode information Pinfo, transform information Tinfo, residual information Rinfo, filter information Finfo, and the like) included in the bitstream via the decoding unit <b>412</b>. Furthermore, the control unit <b>401</b> can estimate encoding parameters not included in the bitstream. Moreover, the control unit <b>401</b> controls the processing units (the accumulation buffer <b>411</b> to the prediction unit <b>418</b>) of the image decoding device <b>400</b> on the basis of the acquired (or estimated) encoding parameters to control decoding.</p><p id="p-0421" num="0405">For example, the control unit <b>401</b> supplies the header information Hinfo to the inverse quantization inverse transform unit <b>413</b>, the prediction unit <b>418</b>, and the in-loop filter unit <b>415</b>. Furthermore, the control unit <b>401</b> supplies the prediction mode information Pinfo to the inverse quantization inverse transform unit <b>413</b> and the prediction unit <b>418</b>. Moreover, the control unit <b>401</b> supplies the transform information Tinfo to the inverse quantization inverse transform unit <b>413</b>. Furthermore, the control unit <b>401</b> supplies the residual information Rinfo to the decoding unit <b>412</b>. Moreover, the control unit <b>401</b> supplies the filter information Finfo to the in-loop filter unit <b>415</b>.</p><p id="p-0422" num="0406">Of course, the above example is an example, and the present embodiment is not limited to this example. For example, each encoding parameter may be supplied to an arbitrary processing unit. Furthermore, other information may be supplied to an arbitrary processing unit.</p><p id="p-0423" num="0407">&#x3c;Header Information Hinfo&#x3e;</p><p id="p-0424" num="0408">The header information Hinfo includes, for example, header information such as a video parameter set (VPS), a sequence parameter set (SPS), a picture parameter set (PPS), a picture header (PH), and a slice header (SH). The header information Hinfo includes, for example, information defining image size (width PicWidth and height PicHeight), bit depth (luminance bitDepthY and chrominance bitDepthC), a chrominance array type ChromaArrayType, CU size maximum value MaxCUSize and minimum value MinCUSize, maximum depth MaxQTDepth and minimum depth MinQTDepth of quad-tree division, maximum depth MaxBTDepth and minimum depth MinBTDepth of binary-tree division, a maximum value MaxTSSize of a transform skip block (also called maximum transform skip block size), an on/off flag of each coding tool (also called enabled flag), and the like.</p><p id="p-0425" num="0409">For example, an example of the on/off flag of the coding tool included in the header information Hinfo includes an on/off flag related to transform and quantization processing below. Note that the on/off flag of the coding tool can also be interpreted as a flag indicating whether or not a syntax related to the coding tool exists in the coded data. Furthermore, a case where the value of the on/off flag is 1 (true) indicates that the coding tool is available. A case where the value of the on/off flag is 0 (false) indicates that the coding tool is unavailable. Note that the interpretation of the flag value may be reversed.</p><p id="p-0426" num="0410">&#x3c;Prediction Mode Information Pinfo&#x3e;</p><p id="p-0427" num="0411">The prediction mode information Pinfo includes, for example, information such as size information PBSize (prediction block size) of a prediction block (PB) to be processed, intra prediction mode information IPinfo, and motion prediction information MVinfo.</p><p id="p-0428" num="0412">The intra prediction mode information IPinfo includes, for example, prev_intra_luma_pred_flag, mpm_idx, and rem_intra_pred_mode in JCTVC-W1005, 7.3.8.5 Coding Unit syntax, a luminance intra prediction mode IntraPredModeY derived from the syntax, and the like.</p><p id="p-0429" num="0413">Furthermore, the intra prediction mode information IPinfo can include, for example, an inter-component prediction flag (ccp_flag (cclmp_flag)), a multi-class linear prediction mode flag (mclm_flag), a chrominance sample position type identifier (chroma_sample_loc_type_idx), a chrominance MPM identifier (chroma_mpm_idx), a luminance intra prediction mode (IntraPredModeC) derived from these syntaxes, and the like.</p><p id="p-0430" num="0414">The inter-component prediction flag (ccp_flag (cclmp_flag)) is flag information indicating whether or not to apply inter-component linear prediction. For example, ccp_flag==1 indicates that inter-component prediction is applied, and ccp_flag==0 indicates that the inter-component prediction is not applied.</p><p id="p-0431" num="0415">The multi-class linear prediction mode flag (mclm_flag) is information regarding a linear prediction mode (linear prediction mode information). More specifically, the multi-class linear prediction mode flag (mclm_flag) is flag information indicating whether or not to set a multi-class linear prediction mode. For example, &#x201c;0&#x201d; indicates one-class mode (single class mode) (for example, CCLMP), and &#x201c;1&#x201d; indicates two-class mode (multi-class mode) (for example, MCLMP).</p><p id="p-0432" num="0416">The chrominance sample position type identifier (chroma_sample_loc_type_idx) is an identifier for identifying a type of a pixel position of a chrominance component (also referred to as a chrominance sample position type).</p><p id="p-0433" num="0417">Note that the chrominance sample position type identifier (chroma_sample_loc_type_idx) is transmitted as (by being stored in) information (chroma_sample_loc_info ( )) regarding the pixel position of the chrominance component.</p><p id="p-0434" num="0418">The chrominance MPM identifier (chroma_mpm_idx) is an identifier indicating which prediction mode candidate in a chrominance intra prediction mode candidate list (intraPredModeCandListC) is to be specified as a chrominance intra prediction mode.</p><p id="p-0435" num="0419">The motion prediction information MVinfo can include, for example, information such as merge_idx, merge_flag, inter_pred_idc, ref_idx_LX, mvp_1X_flag, X={0,1}, mvd, and the like (see, for example, JCTVC-W1005, 7.3.8.6 Prediction Unit Syntax).</p><p id="p-0436" num="0420">Of course, the information included in the prediction mode information Pinfo is arbitrary, and information other than the above information may be included.</p><p id="p-0437" num="0421">&#x3c;Transform Information Tinfo&#x3e;</p><p id="p-0438" num="0422">The transform information Tinfo can include, for example, the following information:</p><p id="p-0439" num="0423">the width TBWSize and the height TBHSize of the transform block to be processed: logarithmic values log 2TBWSize and log 2TBHSize of TBWSize and TBHSize having a base of 2;</p><p id="p-0440" num="0424">a transform skip flag (ts_flag): a flag indicating whether or not to skip (inverse) primary transform and (inverse) secondary transform;</p><p id="p-0441" num="0425">a scan identifier (scanIdx);</p><p id="p-0442" num="0426">a quantization parameter (qp); and</p><p id="p-0443" num="0427">a quantization matrix (scaling matrix): for example, JCTVC-W1005, 7.3.4 Scaling list data syntax.</p><p id="p-0444" num="0428">Of course, the information included in the transform information Tinfo is arbitrary, and information other than the above information may be included:</p><p id="p-0445" num="0429">&#x3c;Residual Information Rinfo&#x3e;</p><p id="p-0446" num="0430">The residual information Rinfo (for example, see 7.3.8.11 Residual Coding syntax of JCTVC-W1005) can include, for example, the following information:</p><p id="p-0447" num="0431">cbf (coded_block_flag): a residual data presence/absence flag;</p><p id="p-0448" num="0432">last_sig_coeff_x_pos: a last nonzero coefficient X coordinate;</p><p id="p-0449" num="0433">last_sig_coeff_y_pos: a last nonzero coefficient Y coordinate;</p><p id="p-0450" num="0434">coded_sub_block_flag: a subblock nonzero coefficient presence/absence flag;</p><p id="p-0451" num="0435">sig_coeff_flag: a nonzero coefficient presence/absence flag;</p><p id="p-0452" num="0436">gr1_flag: a flag indicating whether or not the level of the nonzero coefficient is larger than 1 (also referred to as GR1 flag); gr2_flag: a flag indicating whether or not the level of the nonzero coefficient is larger than 2 (also referred to as GR2 flag); sign flag: a sign indicating positive or negative of the nonzero coefficient (also referred to as sign code); and</p><p id="p-0453" num="0437">coeff_abs_level_remaining: a residual level of the nonzero coefficient (also called a nonzero coefficient residual level).</p><p id="p-0454" num="0438">Of course, the information included in the residual information Rinfo is arbitrary, and information other than the above information may be included.</p><p id="p-0455" num="0439">&#x3c;Filter Information Finfo&#x3e;</p><p id="p-0456" num="0440">The filter information Finfo can include, for example, control information regarding the following filtering processing:</p><p id="p-0457" num="0441">control information regarding a deblocking filter (DBF);</p><p id="p-0458" num="0442">control information regarding a pixel adaptive offset (SAO);</p><p id="p-0459" num="0443">control information regarding an adaptive loop filter (ALF); and</p><p id="p-0460" num="0444">control information regarding other linear and nonlinear filters.</p><p id="p-0461" num="0445">Furthermore, for example, the filter information Finfo may include a picture to which each filter is applied, information for specifying an area in the picture, filter on/off control information for each CU, filter on/off control information for slice and tile boundaries, and the like. Of course, the information included in the filter information Finfo is arbitrary, and information other than the above information may be included.</p><p id="p-0462" num="0446">&#x3c;Accumulation Buffer&#x3e;</p><p id="p-0463" num="0447">The accumulation buffer <b>411</b> acquires the bitstream input to the image decoding device <b>400</b> and holds (stores) the bitstream. The accumulation buffer <b>411</b> extracts the coded data included in the accumulated bitstream and supplies the coded data to the decoding unit <b>412</b> at predetermined timing or in a case where a predetermined condition is satisfied.</p><p id="p-0464" num="0448">&#x3c;Decoding Unit&#x3e;</p><p id="p-0465" num="0449">The decoding unit <b>412</b> executes processing regarding image decoding. For example, the decoding unit <b>412</b> acquires the coded data supplied from the accumulation buffer <b>411</b>, performs entropy decoding (lossless decoding) for a syntax value of each syntax element from the bit string according to a definition of a syntax table, and derives encoding parameters.</p><p id="p-0466" num="0450">The encoding parameters may include, for example, information such as the header information Hinfo, prediction mode information Pinfo, transform information Tinfo, residual information Rinfo, and filter information Finfo. That is, the decoding unit <b>412</b> decodes and parses (analyzes and acquires) such information from the bitstream.</p><p id="p-0467" num="0451">The decoding unit <b>412</b> executes such processing (decoding, parsing, and the like) under the control of the control unit <b>401</b>, and supplies the obtained information to the control unit <b>401</b>.</p><p id="p-0468" num="0452">Moreover, the decoding unit <b>412</b> decodes the coded data by reference to the residual information Rinfo. At that time, the decoding unit <b>412</b> applies entropy decoding (lossless decoding) such as CABAC or CAVLC, for example. That is, the decoding unit <b>412</b> decodes the coded data by a decoding method corresponding to the encoding method of the encoding processing executed by the encoding unit <b>314</b> of the image encoding device <b>300</b>.</p><p id="p-0469" num="0453">For example, CABAC is assumed to be applied. The decoding unit <b>412</b> performs arithmetic decoding using a context model for the coded data and derives quantized coefficient data level at each coefficient position in each transformation block. The decoding unit <b>412</b> supplies the derived quantized coefficient data level to the inverse quantization inverse transform unit <b>413</b>.</p><p id="p-0470" num="0454">&#x3c;Inverse Quantization Inverse Transform Unit&#x3e;</p><p id="p-0471" num="0455">The inverse quantization inverse transform unit <b>413</b> executes processing regarding inverse quantization and inverse coefficient transform. For example, the inverse quantization inverse transform unit <b>413</b> acquires the quantized coefficient data level supplied from the decoding unit <b>412</b>. The inverse quantization inverse transform unit <b>413</b> acquires the encoding parameters such as the prediction mode information Pinfo and the transform information Tinfo supplied from the control unit <b>401</b>.</p><p id="p-0472" num="0456">The inverse quantization inverse transform unit <b>413</b> executes inverse quantization inverse transform processing for the quantized coefficient data level on the basis of the encoding parameters such as the prediction mode information Pinfo and the transform information Tinfo to derive residual data D&#x2032;. This inverse quantization inverse transform processing is inverse processing of the transform quantization processing executed in the transform quantization unit <b>313</b>. That is, in the inverse quantization inverse transform processing, for example, processing such as inverse quantization, inverse orthogonal transform, and inverse adaptive color transform are executed. The inverse quantization is inverse processing of the quantization executed in the transform quantization unit <b>313</b>. The inverse orthogonal transform is inverse processing of the orthogonal transform executed in the transform quantization unit <b>313</b>. The inverse adaptive color transform is inverse processing of the adaptive color transform executed in the transform quantization unit <b>313</b>. Of course, the processing included in the inverse quantization inverse transform processing is arbitrary, and some of the above-described pieces of processing may be omitted, or processing other than the above-described processing may be included. The inverse quantization inverse transform unit <b>413</b> supplies the derived residual data D&#x2032; to the calculation unit <b>414</b>.</p><p id="p-0473" num="0457">&#x3c;Calculation Unit&#x3e;</p><p id="p-0474" num="0458">The calculation unit <b>414</b> executes processing regarding addition of information regarding an image. For example, the calculation unit <b>414</b> acquires the residual data D&#x2032; supplied from the inverse quantization inverse transform unit <b>413</b> and a predicted image supplied from the prediction unit <b>418</b>. The calculation unit <b>414</b> adds the residual data and the predicted image (predicted signal) corresponding to the residual data to derive a locally decoded image. The calculation unit <b>414</b> supplies the derived locally decoded image to the in-loop filter unit <b>415</b> and the frame memory <b>417</b>.</p><p id="p-0475" num="0459">&#x3c;In-Loop Filter Unit&#x3e;</p><p id="p-0476" num="0460">The in-loop filter unit <b>415</b> executes processing regarding in-loop filter processing. For example, the in-loop filter unit <b>415</b> acquires the locally decoded image supplied from the calculation unit <b>414</b>. The in-loop filter unit <b>415</b> acquires the filter information Finfo supplied from the control unit <b>401</b>. Note that the information input to the in-loop filter unit <b>415</b> is arbitrary, and information other than the aforementioned information may be input.</p><p id="p-0477" num="0461">The in-loop filter unit <b>415</b> appropriately executes filter processing for the locally decoded image on the basis of the filter information Finfo. For example, the in-loop filter unit <b>415</b> can apply a bilateral filter as the filter processing. For example, the in-loop filter unit <b>415</b> can apply a deblocking filter (DBF) as the filter processing. For example, the in-loop filter unit <b>415</b> can apply an adaptive offset filter (sample adaptive offset (SAO)) as the filter processing. For example, the in-loop filter unit <b>415</b> can apply an adaptive loop filter (ALF) as the filter processing. Furthermore, the in-loop filter unit <b>415</b> can apply a plurality of filters in combination as the filter processing. Note that which filter is applied and in which order the filters are applied are arbitrary and can be selected as appropriate. For example, the in-loop filter unit <b>415</b> applies four in-loop filters of the bilateral filter, the deblocking filter, the adaptive offset filter, and the adaptive loop filter in this order as the filter processing.</p><p id="p-0478" num="0462">The in-loop filter unit <b>415</b> executes the filter processing corresponding to the filter processing executed by the encoding-side device (for example, the in-loop filter unit <b>318</b> of the image encoding device <b>300</b>). Of course, the filter processing executed by the in-loop filter unit <b>415</b> is arbitrary and is not limited to the above example. For example, the in-loop filter unit <b>415</b> may apply a Wiener filter or the like.</p><p id="p-0479" num="0463">The in-loop filter unit <b>415</b> supplies the filtered locally decoded image to the rearrangement buffer <b>416</b> and the frame memory <b>417</b>.</p><p id="p-0480" num="0464">&#x3c;Rearrangement Buffer&#x3e;</p><p id="p-0481" num="0465">The rearrangement buffer <b>416</b> receives the locally decoded image supplied from the in-loop filter unit <b>415</b> as an input, and holds (stores) the locally decoded image. The rearrangement buffer <b>416</b> reconstructs a decoded image for each picture, using locally decoded image, and holds (stores in the buffer) the decoded image. The rearrangement buffer <b>416</b> rearranges the obtained decoded images from a decoding order to a reproduction order. The rearrangement buffer <b>416</b> outputs a rearranged decoded image group to the outside of the image decoding device <b>400</b> as moving image data.</p><p id="p-0482" num="0466">&#x3c;Frame Memory&#x3e;</p><p id="p-0483" num="0467">The frame memory <b>417</b> executes processing regarding storage of data related to an image. For example, the frame memory <b>417</b> acquires the locally decoded image supplied from the calculation unit <b>414</b>, reconstructs the decoded image for each picture, and stores the decoded image in the buffer in the frame memory <b>417</b>.</p><p id="p-0484" num="0468">Furthermore, the frame memory <b>417</b> acquires the locally decoded image that has undergone the in-loop filter processing supplied from the in-loop filter unit <b>415</b>, reconstructs the decoded image for each picture, and stores the decoded image in the buffer in the frame memory <b>417</b>. The frame memory <b>417</b> appropriately supplies the stored decoded image (or a part thereof) to the prediction unit <b>418</b> as a reference image.</p><p id="p-0485" num="0469">Note that the frame memory <b>417</b> may store the header information Hinfo, the prediction mode information Pinfo, the transform information Tinfo, the filter information Finfo, and the like related to generation of the decoded image.</p><p id="p-0486" num="0470">&#x3c;Prediction Unit&#x3e;</p><p id="p-0487" num="0471">The prediction unit <b>418</b> executes processing regarding generation of a predicted image. For example, the prediction unit <b>418</b> acquires the prediction mode information Pinfo supplied from the control unit <b>401</b>. Furthermore, the prediction unit <b>418</b> acquires the decoded image (or a part thereof) read from the frame memory <b>417</b>. The prediction unit <b>418</b> executes prediction processing in a prediction mode adopted at the time of encoding on the basis of the prediction mode information Pinfo, and generates a predicted image by referring to the decoded image as a reference image. The prediction unit <b>418</b> supplies the generated predicted image to the calculation unit <b>414</b>.</p><p id="p-0488" num="0472">&#x3c;Application of Present Technology&#x3e;</p><p id="p-0489" num="0473">The present technology described in &#x3c;1. Correction of Quantization Parameter&#x3e;, &#x3c;2. First Embodiment&#x3e;, &#x3c;3. Second Embodiment&#x3e;, &#x3c;4. Third Embodiment&#x3e;, and &#x3c;5. Fourth Embodiment&#x3e; can be applied to the image decoding device <b>400</b> having the above configuration.</p><p id="p-0490" num="0474">&#x3c;Decoding Unit&#x3e;</p><p id="p-0491" num="0475">As described above, the decoding unit <b>412</b> parses the encoding parameters such as the header information Hinfo, the prediction mode information Pinfo, the transform information Tinfo, the residual information Rinfo, and the filter information Finfo from the bitstream.</p><p id="p-0492" num="0476">Therefore, in a case where the present technology is applied, the decoding unit <b>412</b> decodes the bitstream, and parses parameters to be used for correction of the quantization parameter supplied from the encoding-side device (for example, the image encoding device <b>300</b>).</p><p id="p-0493" num="0477">For example, in a case of applying &#x201c;method 1&#x201d;, the decoding unit <b>412</b> parses the parameters such as a quantization parameter qPx at a CU level corresponding to a component identifier cIdx, cu_act_enabled_flag, a correction amount dqPx corresponding to the component identifier cIdx, transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx, and a minimum value QpPrimeTsMin of a quantization parameter at the time of transform skip. Furthermore, in a case of applying &#x201c;method 2&#x201d;, the decoding unit <b>412</b> parses a minimum value &#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip, in addition to the parameters to be encoded in the case of applying the &#x201c;method 1&#x201d;. Furthermore, in a case of applying &#x201c;method 3&#x201d; or the &#x201c;method 4&#x201d;, the decoding unit <b>412</b> parses a correction amount QpBdOffset corresponding to a bit depth, in addition to the parameters to be encoded in the case of applying the &#x201c;method 1&#x201d;.</p><p id="p-0494" num="0478">&#x3c;Control Unit&#x3e;</p><p id="p-0495" num="0479">For example, in the case of applying the &#x201c;method 1&#x201d;, the control unit <b>401</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx from the decoding unit <b>412</b>, and supplies the quantization parameter qPx to the inverse quantization inverse transform unit <b>413</b>. The control unit <b>401</b> acquires cu_act_enabled_flag from the decoding unit <b>412</b> as a parameter regarding adaptive color transform, and supplies the cu_act_enabled_flag to the inverse quantization inverse transform unit <b>413</b>. The control unit <b>401</b> acquires the correction amount dqPx corresponding to the component identifier cIdx from the decoding unit <b>412</b> as the parameter regarding adaptive color transform, and supplies the correction amount dqPx to the inverse quantization inverse transform unit <b>413</b>. The control unit <b>401</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx from the decoding unit <b>412</b> as a parameter regarding transform skip, and supplies the transform_skip_flag[xTbY][yTbY][cIdx] to the inverse quantization inverse transform unit <b>413</b>. The control unit <b>401</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip from the decoding unit <b>412</b> as the parameter regarding transform skip, and supplies the minimum value QpPrimeTsMin to the inverse quantization inverse transform unit <b>413</b>.</p><p id="p-0496" num="0480">For example, in the case of applying the &#x201c;method 2&#x201d;, the control unit <b>401</b> supplies the parameters to be supplied in the case of applying the &#x201c;method 1&#x201d; to the inverse quantization inverse transform unit <b>413</b>. In addition to these parameters, the control unit <b>401</b> supplies the minimum value &#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip to the inverse quantization inverse transform unit <b>413</b> as the parameter regarding transform skip.</p><p id="p-0497" num="0481">For example, in the case of applying the &#x201c;method 3&#x201d;, the control unit <b>401</b> supplies the parameters to be supplied in the case of applying the &#x201c;method 1&#x201d; to the inverse quantization inverse transform unit <b>413</b>. In addition to these parameters, the control unit <b>401</b> supplies the correction amount QpBdOffset corresponding to the bit depth to the inverse quantization inverse transform unit <b>413</b>.</p><p id="p-0498" num="0482">For example, in the case of applying the &#x201c;method 4&#x201d;, the control unit <b>401</b> supplies the parameters to be supplied in the case of applying the &#x201c;method 3&#x201d; to the inverse quantization inverse transform unit <b>413</b>.</p><p id="p-0499" num="0483">&#x3c;Inverse Quantization Inverse Transform Unit&#x3e;</p><p id="p-0500" num="0484">For example, in the case of applying the above-described &#x201c;method 1&#x201d;, the inverse quantization inverse transform unit <b>413</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>401</b>. Furthermore, the inverse quantization inverse transform unit <b>413</b> acquires cu_act_enabled_flag supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. The inverse quantization inverse transform unit <b>413</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. Moreover, the inverse quantization inverse transform unit <b>413</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The inverse quantization inverse transform unit <b>413</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The inverse quantization inverse transform unit <b>413</b> executes inverse quantization inverse transform processing using the acquired parameters.</p><p id="p-0501" num="0485">For example, in the case of applying the above-described &#x201c;method 2&#x201d;, the inverse quantization inverse transform unit <b>413</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>401</b>. Furthermore, the inverse quantization inverse transform unit <b>413</b> acquires cu_act_enabled_flag supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. The inverse quantization inverse transform unit <b>413</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. Moreover, the inverse quantization inverse transform unit <b>413</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The inverse quantization inverse transform unit <b>413</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The inverse quantization inverse transform unit <b>413</b> acquires the minimum value&#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip supplied from the control unit <b>401</b> as the parameter regarding transform skip. The inverse quantization inverse transform unit <b>413</b> executes inverse quantization inverse transform processing using the acquired parameters.</p><p id="p-0502" num="0486">For example, in the case of applying the above-described &#x201c;method 3&#x201d;, the inverse quantization inverse transform unit <b>413</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>401</b>. Furthermore, the inverse quantization inverse transform unit <b>413</b> acquires cu_act_enabled_flag supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. The inverse quantization inverse transform unit <b>413</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. Moreover, the inverse quantization inverse transform unit <b>413</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The inverse quantization inverse transform unit <b>413</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The inverse quantization inverse transform unit <b>413</b> acquires the correction amount QpBdOffset corresponding to the bit depth supplied from the control unit <b>401</b> as the parameter regarding transform skip. The inverse quantization inverse transform unit <b>413</b> executes inverse quantization inverse transform processing using the acquired parameters.</p><p id="p-0503" num="0487">For example, in the case of applying the above-described &#x201c;method 4&#x201d;, the inverse quantization inverse transform unit <b>413</b> acquires the same parameters as those acquired in the case of applying the &#x201c;method 3&#x201d;. The inverse quantization inverse transform unit <b>413</b> executes inverse quantization inverse transform processing using the acquired parameters.</p><p id="p-0504" num="0488">&#x3c;Configuration Example of Inverse Quantization Inverse Transform Unit&#x3e;</p><p id="p-0505" num="0489"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a block diagram illustrating a main configuration example of the inverse quantization inverse transform unit <b>413</b> in <figref idref="DRAWINGS">FIG. <b>16</b></figref>. As illustrated in <figref idref="DRAWINGS">FIG. <b>17</b></figref>, the inverse quantization inverse transform unit <b>413</b> includes an inverse quantization unit <b>441</b>, an inverse orthogonal transform unit <b>442</b>, and an inverse adaptive color transform unit <b>443</b>.</p><p id="p-0506" num="0490">The inverse quantization unit <b>441</b> executes processing regarding inverse quantization. For example, the inverse quantization unit <b>441</b> acquires quantized coefficient data qcoeff_x (that is, the quantized coefficient data level in <figref idref="DRAWINGS">FIG. <b>16</b></figref>) supplied from the decoding unit <b>412</b>. The inverse quantization unit <b>441</b> inversely quantizes the quantized coefficient data qcoeff_x to generate orthogonally transformed coefficient data coef_x. The inverse quantization unit <b>441</b> supplies the generated orthogonally transformed coefficient data coef_x to the inverse orthogonal transform unit <b>442</b>.</p><p id="p-0507" num="0491">The inverse orthogonal transform unit <b>442</b> executes processing regarding inverse orthogonal transform. For example, the inverse orthogonal transform unit <b>442</b> acquires the orthogonally transformed coefficient data coeff_x supplied from the inverse quantization unit <b>441</b>. The inverse orthogonal transform unit <b>442</b> acquires the transform information Tinfo and the prediction mode information Pinfo supplied from the control unit <b>401</b>. For example, the inverse orthogonal transform unit <b>442</b> can acquire information such as transform_skip_flag, mts_idx, and lfnst_idx as the transform information Tinfo. The inverse orthogonal transform unit <b>442</b> inversely orthogonally transforms the orthogonally transformed coefficient data coeff_x using the acquired information to generate adaptive color transform coefficient data res_x&#x2032;. The inverse orthogonal transform unit <b>442</b> supplies the generated adaptive color transform coefficient data res_x&#x2032; to the inverse adaptive color transform unit <b>443</b>.</p><p id="p-0508" num="0492">The inverse adaptive color transform unit <b>443</b> executes processing regarding inverse adaptive color transform. For example, the inverse adaptive color transform unit <b>443</b> acquires the adaptive color transform coefficient data res_x&#x2032; supplied from the inverse orthogonal transform unit <b>442</b>. The inverse adaptive color transform unit <b>443</b> acquires cu_act_enabled_flag supplied from the control unit <b>401</b>. The inverse adaptive color transform unit <b>443</b> executes adaptive color transform for the residual data res_x on the basis of the value of cu_act_enabled_flag. For example, in a case where cu_act_enabled_flag is true (for example, &#x201c;1&#x201d;), the inverse adaptive color transform unit <b>443</b> executes calculation as in the above-described expression (2) and performs YCgCo-RGB transform for the adaptive color transform coefficient data res_x&#x2032; including components of Y, Cg, and Co. By the processing, the residual data res_x (that is, the residual data D in <figref idref="DRAWINGS">FIG. <b>10</b></figref>) including the components of R, G, and B is generated. The inverse adaptive color transform unit <b>443</b> supplies the generated residual data res_x to the calculation unit <b>414</b>.</p><p id="p-0509" num="0493">For example, in the case of applying the above-described &#x201c;method 1&#x201d;, the inverse quantization unit <b>441</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>401</b>. Furthermore, the inverse quantization unit <b>441</b> acquires cu_act_enabled_flag supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. The inverse quantization unit <b>441</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. Moreover, the inverse quantization unit <b>441</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The inverse quantization unit <b>441</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>401</b> as the parameter regarding the transform skip.</p><p id="p-0510" num="0494">The inverse quantization unit <b>441</b> inversely quantizes the quantized coefficient data qcoef_x using the acquired parameters to generate orthogonally transformed coefficient data coeff_x.</p><p id="p-0511" num="0495">For example, in the case of applying the above-described &#x201c;method 2&#x201d;, the inverse quantization unit <b>441</b>, the inverse quantization unit <b>441</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>401</b>. Furthermore, the inverse quantization unit <b>441</b> acquires cu_act_enabled_flag supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. The inverse quantization unit <b>441</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. Moreover, the inverse quantization unit <b>441</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The inverse quantization unit <b>441</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The inverse quantization unit <b>441</b> acquires the minimum value&#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip supplied from the control unit <b>401</b> as the parameter regarding transform skip.</p><p id="p-0512" num="0496">The inverse quantization unit <b>441</b> inversely quantizes the quantized coefficient data qcoef_x using the acquired parameters to generate orthogonally transformed coefficient data coeff_x.</p><p id="p-0513" num="0497">For example, in the case of applying the above-described &#x201c;method 3&#x201d;, the inverse quantization unit <b>441</b>, the inverse quantization unit <b>441</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>401</b>. Furthermore, the inverse quantization unit <b>441</b> acquires cu_act_enabled_flag supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. The inverse quantization unit <b>441</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. Moreover, the inverse quantization unit <b>441</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The inverse quantization unit <b>441</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The inverse quantization unit <b>441</b> acquires the correction amount QpBdOffset corresponding to the bit depth supplied from the control unit <b>401</b> as the parameter regarding transform skip.</p><p id="p-0514" num="0498">The inverse quantization unit <b>441</b> inversely quantizes the quantized coefficient data qcoef_x using the acquired parameters to generate orthogonally transformed coefficient data coeff_x.</p><p id="p-0515" num="0499">For example, in the case of applying the above-described &#x201c;method 4&#x201d;, the inverse quantization unit <b>441</b> acquires the same parameters as those acquired in the case of applying the &#x201c;method 3&#x201d;. The inverse quantization unit <b>441</b> inversely quantizes the quantized coefficient data qcoef_x using the acquired parameters to generate orthogonally transformed coefficient data coeff_x.</p><p id="p-0516" num="0500">&#x3c;Configuration Example of Inverse Quantization Unit&#x3e;</p><p id="p-0517" num="0501"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a block diagram illustrating a main configuration example of the inverse quantization unit <b>441</b> of <figref idref="DRAWINGS">FIG. <b>17</b></figref>. As illustrated in <figref idref="DRAWINGS">FIG. <b>18</b></figref>, the inverse quantization unit <b>441</b> includes a quantization parameter correction unit <b>451</b> and an inverse quantization processing unit <b>452</b>.</p><p id="p-0518" num="0502">The quantization parameter correction unit <b>451</b> executes processing regarding correction of the quantization parameter. For example, the quantization parameter correction unit <b>451</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx. The quantization parameter correction unit <b>451</b> corrects the quantization parameter qPx at the CU level corresponding to the component identifier cIdx and supplies the corrected quantization parameter that is the quantization parameter after correction to the inverse quantization processing unit <b>452</b>.</p><p id="p-0519" num="0503">The inverse quantization processing unit <b>452</b> executes processing regarding inverse quantization. For example, the inverse quantization processing unit <b>452</b> acquires the quantized coefficient data qcoef_x supplied from the decoding unit <b>412</b>. The inverse quantization processing unit <b>452</b> acquires the corrected quantization parameter supplied from the quantization parameter correction unit <b>451</b>. The inverse quantization processing unit <b>452</b> inversely quantizes the quantized coefficient data qcoef_x using the corrected quantization parameter to generate the orthogonally transformed coefficient data coef_x. The inverse quantization processing unit <b>452</b> supplies the generated orthogonally transformed coefficient data coef_x to the inverse orthogonal transform unit <b>442</b>.</p><p id="p-0520" num="0504">In a case where the present technology is applied in the inverse quantization unit <b>441</b> having the above-described configuration, the quantization parameter correction unit <b>451</b> corrects the quantization parameter on the basis of the parameter regarding adaptive color transform and further corrects the quantization parameter on the basis of the parameter regarding transform skip. The inverse quantization processing unit <b>452</b> inversely quantizes the quantized coefficient data obtained by quantizing the coefficient data of an image, using the corrected quantization parameter that is the quantization parameter corrected by the quantization parameter correction unit <b>451</b>.</p><p id="p-0521" num="0505">For example, in the case of applying the above-described &#x201c;method 1&#x201d;, the quantization parameter correction device <b>100</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) is applied as the quantization parameter correction unit <b>451</b>. That is, the quantization parameter correction unit <b>451</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>401</b>. Furthermore, the quantization parameter correction unit <b>451</b> acquires cu_act_enabled_flag supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. The quantization parameter correction unit <b>451</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. The quantization parameter correction unit <b>451</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The quantization parameter correction unit <b>451</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>401</b> as the parameter regarding the transform skip.</p><p id="p-0522" num="0506">The quantization parameter correction unit <b>451</b> corrects qPx by a method as described in the first embodiment, using the acquired cu_act_enabled_flag, dqPx, transform_skip_flag[xTbY][yTbY][cIdx], and QpPrimeTsMin. That is, the quantization parameter correction unit <b>451</b> executes calculation as in the expression (5) or the expression (6) to generate the second corrected quantization parameter qP&#x2033;. The quantization parameter correction unit <b>451</b> supplies the generated second corrected quantization parameter qP&#x2033; to the inverse quantization processing unit <b>452</b>.</p><p id="p-0523" num="0507">By doing so, the quantization parameter correction unit <b>451</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the inverse quantization when the adaptive color transform and the transform skip are applied. Therefore, the inverse quantization processing unit <b>452</b> inversely quantizes the quantized coefficient data using the quantization parameter corrected in this manner, so that the inverse quantization unit <b>441</b> (inverse quantization inverse transform unit <b>413</b>) can suppress the reduction in the PSNR. Therefore, the image decoding device <b>400</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0524" num="0508">For example, in the case of applying the above-described &#x201c;method 2&#x201d;, the quantization parameter correction device <b>100</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) is applied as the quantization parameter correction unit <b>451</b>. That is, the quantization parameter correction unit <b>451</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>401</b>. Furthermore, the quantization parameter correction unit <b>451</b> acquires cu_act_enabled_flag supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. The quantization parameter correction unit <b>451</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. The quantization parameter correction unit <b>451</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The quantization parameter correction unit <b>451</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The quantization parameter correction unit <b>451</b> acquires the minimum value&#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip supplied from the control unit <b>401</b> as the parameter regarding transform skip.</p><p id="p-0525" num="0509">The quantization parameter correction unit <b>451</b> corrects qPx by a method as described in the second embodiment, using the cu_act_enabled_flag, dqPx, transform_skip_flag[xTbY][yTbY][cIdx], QpPrimeTsMin, and the value &#x201c;0&#x201d;. That is, the quantization parameter correction unit <b>451</b> executes calculation as in the expression (5) or the expression (13) to generate the second corrected quantization parameter qP&#x2033;. The quantization parameter correction unit <b>451</b> supplies the generated second corrected quantization parameter qP&#x2033; to the inverse quantization processing unit <b>452</b>.</p><p id="p-0526" num="0510">By doing so, the quantization parameter correction unit <b>451</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the inverse quantization, regardless of whether or not the transform skip is applied in the inverse quantization, in the case where the adaptive color transform is applied. Therefore, the inverse quantization processing unit <b>452</b> inversely quantizes the quantized coefficient data using the quantization parameter corrected in this manner, so that the inverse quantization unit <b>441</b> (inverse quantization inverse transform unit <b>413</b>) can suppress the reduction in the PSNR. Therefore, the image decoding device <b>400</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0527" num="0511">For example, in the case of applying the above-described &#x201c;method 3&#x201d;, the quantization parameter correction device <b>100</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) is applied as the quantization parameter correction unit <b>451</b>. That is, the quantization parameter correction unit <b>451</b> acquires the quantization parameter qPx at the CU level corresponding to the component identifier cIdx supplied from the control unit <b>401</b>. Furthermore, the quantization parameter correction unit <b>451</b> acquires cu_act_enabled_flag supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. The quantization parameter correction unit <b>451</b> acquires the correction amount dqPx corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the adaptive color transform. The quantization parameter correction unit <b>451</b> acquires transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The quantization parameter correction unit <b>451</b> acquires the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip supplied from the control unit <b>401</b> as the parameter regarding the transform skip. The quantization parameter correction unit <b>451</b> acquires the correction amount QpBdOffset corresponding to the bit depth supplied from the control unit <b>401</b> as the parameter regarding transform skip.</p><p id="p-0528" num="0512">The quantization parameter correction unit <b>451</b> corrects qPx by a method as described in the second embodiment, using the cu_act_enabled_flag, dqPx, transform_skip_flag[xTbY][yTbY][cIdx], QpPrimeTsMin, and QpBdOffset. That is, the quantization parameter correction unit <b>451</b> executes calculation as in the expression (16) or the expression (17) to generate the third corrected quantization parameter qP&#x2032;&#x2033;. The quantization parameter correction unit <b>451</b> supplies the generated third corrected quantization parameter qP&#x2032;&#x2033; to the inverse quantization processing unit <b>452</b>.</p><p id="p-0529" num="0513">By doing so, the value of the corrected quantization parameter falls within a range of a minimum value to a maximum value of the quantization parameter, regardless of whether or not the transform skip is applied. Furthermore, in the case of transform skip, the lower limit of the quantization parameter is further clipped with the minimum value QpPrimeTsMin of the quantization parameter at the time of the transform skip. That is, the quantization parameter correction unit <b>451</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the inverse quantization, regardless of whether or not the transform skip is applied, in the case where the adaptive color transform is applied. Therefore, the inverse quantization processing unit <b>452</b> inversely quantizes the quantized coefficient data using the quantization parameter corrected in this manner, so that the inverse quantization unit <b>441</b> (inverse quantization inverse transform unit <b>413</b>) can suppress the reduction in the PSNR. Therefore, the image decoding device <b>400</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0530" num="0514">For example, in the case of applying the above-described &#x201c;method 4&#x201d;, the quantization parameter correction device <b>160</b> (<figref idref="DRAWINGS">FIG. <b>8</b></figref>) is applied as the quantization parameter correction unit <b>451</b>. That is, the quantization parameter correction unit <b>451</b> acquires parameters similar to those in the case of the &#x201c;method 3&#x201d;.</p><p id="p-0531" num="0515">The quantization parameter correction unit <b>451</b> corrects qPx by a method as described in the fourth embodiment, using the acquired parameters (cu_act_enabled_flag, dqPx, transform_skip_flag[xTbY][yTbY][cIdx], QpPrimeTsMin, and QpBdOffset). That is, the quantization parameter correction unit <b>451</b> executes calculation as in the expression (18) or the expression (17) to generate the second corrected quantization parameter qP&#x2033;. The quantization parameter correction unit <b>451</b> supplies the generated second corrected quantization parameter qP&#x2033; to the inverse quantization processing unit <b>452</b>.</p><p id="p-0532" num="0516">That is, in the case of the method 4, calculation substantially similar to the case of the method 3 is executed, and a similar correction result is obtained. Therefore, even in this case, the quantization parameter correction unit <b>451</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the inverse quantization, regardless of whether or not the transform skip is applied, in the case where the adaptive color transform is applied, similarly to the case of the method 3. Therefore, the inverse quantization processing unit <b>452</b> inversely quantizes the quantized coefficient data using the quantization parameter corrected in this manner, so that the inverse quantization unit <b>441</b> (inverse quantization inverse transform unit <b>413</b>) can suppress the reduction in the PSNR. Therefore, the image decoding device <b>400</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0533" num="0517">The description of the inverse quantization inverse transform unit <b>413</b> described in the present embodiment can also be applied to the inverse quantization inverse transform unit <b>316</b> of the image encoding device <b>300</b>. Note that, in that case, a supply source of the encoding parameter is the control unit <b>301</b>. Furthermore, the supply source of the quantized coefficient data is the transform quantization unit <b>313</b>. Moreover, a supply destination of the residual data D&#x2032; is the calculation unit <b>317</b>.</p><p id="p-0534" num="0518">&#x3c;Flow of Image Decoding Processing&#x3e;</p><p id="p-0535" num="0519">Next, a flow of each processing executed by the above image decoding device <b>400</b> will be described. First, an example of a flow of image decoding processing will be described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>19</b></figref>.</p><p id="p-0536" num="0520">When the image decoding processing is started, in step S<b>401</b>, the accumulation buffer <b>411</b> acquires and holds (accumulates) the bitstream (coded data) supplied from the outside of the image decoding device <b>400</b>.</p><p id="p-0537" num="0521">In step S<b>402</b>, the decoding unit <b>412</b> executes the decoding processing. For example, the decoding unit <b>412</b> parses (analyzes and acquires) the various encoding parameters (for example, header information Hinfo, prediction mode information Pinfo, transform information Tinfo, and the like) from the bitstream. The control unit <b>401</b> supplies the acquired various encoding parameters to the various processing units to set the various encoding parameters.</p><p id="p-0538" num="0522">Furthermore, the control unit <b>401</b> sets the unit of processing on the basis of the obtained encoding parameters. Moreover, the decoding unit <b>412</b> decodes the bitstream according to the control of the control unit <b>401</b> to obtain the quantized coefficient data level.</p><p id="p-0539" num="0523">In step S<b>403</b>, the inverse quantization inverse transform unit <b>413</b> executes the inverse quantization inverse transform processing to generate the residual data D&#x2032;. The inverse quantization inverse transform processing will be described below.</p><p id="p-0540" num="0524">In step S<b>404</b>, the prediction unit <b>418</b> generates a predicted image. For example, the prediction unit <b>418</b> executes the prediction processing by a prediction method designated by the encoding side on the basis of the encoding parameters and the like set in step S<b>402</b>, and generates the predicted image P by referring to the reference image stored in the frame memory <b>417</b>.</p><p id="p-0541" num="0525">In step S<b>405</b>, the calculation unit <b>414</b> adds the residual data D&#x2032; obtained in step S<b>403</b> and the predicted image P obtained in step S<b>404</b> to derive a locally decoded image Rlocal.</p><p id="p-0542" num="0526">In step S<b>406</b>, the in-loop filter unit <b>415</b> executes the in-loop filter processing for the locally decoded image Rlocal obtained by the processing of step S<b>405</b>.</p><p id="p-0543" num="0527">In step S<b>407</b>, the rearrangement buffer <b>416</b> derives the decoded image R using the locally decoded image Rlocal filtered by the processing in step S<b>406</b>, and rearranges the decoded image R group from the decoding order to the reproduction order. The decoded image R group rearranged in the reproduction order is output to the outside of the image decoding device <b>400</b> as a moving image.</p><p id="p-0544" num="0528">Furthermore, in step S<b>408</b>, the frame memory <b>417</b> stores at least one of the locally decoded image Rlocal obtained by the processing in step S<b>405</b> or the locally decoded image Rlocal filtered by the processing in step S<b>406</b>.</p><p id="p-0545" num="0529">When the processing in step S<b>408</b> ends, the image decoding processing ends.</p><p id="p-0546" num="0530">&#x3c;Flow of Inverse Quantization Inverse Transform Processing&#x3e;</p><p id="p-0547" num="0531">Next, an example of a flow of the inverse quantization inverse transform processing executed in step S<b>403</b> of <figref idref="DRAWINGS">FIG. <b>19</b></figref> will be described with reference to the flowchart of <figref idref="DRAWINGS">FIG. <b>20</b></figref>.</p><p id="p-0548" num="0532">When the inverse quantization inverse transform processing is started, in step S<b>441</b>, the inverse quantization unit <b>441</b> inversely quantizes the quantized coefficient data qcoef_x using the transform information Tinfo and the like set in step S<b>402</b> (<figref idref="DRAWINGS">FIG. <b>19</b></figref>) to generate the orthogonally transformed coefficient data coef_x. The quantized coefficient data qcoef_x corresponds to the quantized coefficient data level generated in the processing of step S<b>402</b> of <figref idref="DRAWINGS">FIG. <b>19</b></figref>.</p><p id="p-0549" num="0533">In step S<b>442</b>, the inverse orthogonal transform unit <b>442</b> inversely orthogonally transforms the orthogonally transformed coefficient data coef_x generated in step S<b>441</b>, using the transform information Tinfo and the like set in step S<b>402</b> (<figref idref="DRAWINGS">FIG. <b>19</b></figref>), to generate the adaptive color transform coefficient data res_x&#x2032;.</p><p id="p-0550" num="0534">In step S<b>443</b>, the inverse adaptive color transform unit <b>443</b> performs inverse adaptive color transform for the adaptive color transform coefficient data res_x&#x2032; generated in step S<b>442</b> on the basis of cu_act_enabled_flag set in step S<b>402</b> (<figref idref="DRAWINGS">FIG. <b>19</b></figref>) to generate the residual data res_x (residual data D&#x2032;).</p><p id="p-0551" num="0535">When the processing of step S<b>443</b> ends, the inverse quantization inverse transform processing ends, and the processing returns to <figref idref="DRAWINGS">FIG. <b>19</b></figref>.</p><p id="p-0552" num="0536">&#x3c;Flow of Quantization Processing&#x3e;</p><p id="p-0553" num="0537">Next, an example of a flow of the inverse quantization processing executed in step S<b>441</b> of <figref idref="DRAWINGS">FIG. <b>20</b></figref> will be described with reference to the flowchart of <figref idref="DRAWINGS">FIG. <b>21</b></figref>.</p><p id="p-0554" num="0538">When the inverse quantization processing is started, in step S<b>451</b>, the quantization parameter correction unit <b>451</b> executes the quantization parameter correction processing, corrects the quantization parameter, and generates the corrected quantization parameter.</p><p id="p-0555" num="0539">In step S<b>452</b>, the inverse quantization processing unit <b>452</b> inversely quantizes the quantized coefficient data qcoef_x using the corrected quantization parameter generated in step S<b>451</b> to generate the orthogonally transformed coefficient data coef_x.</p><p id="p-0556" num="0540">When the processing of step S<b>452</b> ends, the inverse quantization processing ends, and the processing returns to <figref idref="DRAWINGS">FIG. <b>20</b></figref>.</p><p id="p-0557" num="0541">The present technology described in &#x3c;1. Correction of Quantization Parameter&#x3e;, &#x3c;2. First Embodiment&#x3e;, &#x3c;3. Second Embodiment&#x3e;, &#x3c;4. Third Embodiment&#x3e;, and &#x3c;5. Fourth Embodiment&#x3e; can be applied to such inverse quantization processing.</p><p id="p-0558" num="0542">That is, in a case where the present technology is applied in the above inverse quantization processing, in step S<b>451</b>, the quantization parameter correction unit <b>451</b> corrects the quantization parameter on the basis of the parameter regarding adaptive color transform and further corrects the quantization parameter on the basis of the parameter regarding transform skip. In step S<b>452</b>, the inverse quantization processing unit <b>452</b> inversely quantizes the quantized coefficient data obtained by quantizing the coefficient data of an image, using the corrected quantization parameter that is the quantization parameter that has been corrected.</p><p id="p-0559" num="0543">For example, in the case of applying the above-described &#x201c;method 1&#x201d;, the quantization parameter correction unit <b>451</b> applies the quantization parameter correction processing described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>3</b></figref> as the quantization parameter correction processing in step S<b>351</b>. That is, the quantization parameter correction unit <b>451</b> executes calculation as in the expression (5) or the expression (6) to generate the second corrected quantization parameter qP&#x2033;.</p><p id="p-0560" num="0544">By doing so, the quantization parameter correction unit <b>451</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the inverse quantization when the adaptive color transform and the transform skip are applied. Therefore, the inverse quantization processing unit <b>452</b> inversely quantizes the quantized coefficient data using the quantization parameter corrected in this manner, so that the inverse quantization unit <b>441</b> (inverse quantization inverse transform unit <b>413</b>) can suppress the reduction in the PSNR. Therefore, the image decoding device <b>400</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0561" num="0545">For example, in the case of applying the above-described &#x201c;method 2&#x201d;, the quantization parameter correction unit <b>451</b> applies the quantization parameter correction processing described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>5</b></figref> as the quantization parameter correction processing in step S<b>351</b>. That is, the quantization parameter correction unit <b>451</b> executes calculation as in the expression (5) or the expression (13) to generate the second corrected quantization parameter qP&#x2033;.</p><p id="p-0562" num="0546">By doing so, the quantization parameter correction unit <b>451</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the inverse quantization, regardless of whether or not the transform skip is applied in the inverse quantization, in the case where the adaptive color transform is applied. Therefore, the inverse quantization processing unit <b>452</b> inversely quantizes the quantized coefficient data using the quantization parameter corrected in this manner, so that the inverse quantization unit <b>441</b> (inverse quantization inverse transform unit <b>413</b>) can suppress the reduction in the PSNR. Therefore, the image decoding device <b>400</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0563" num="0547">For example, in the case of applying the above-described &#x201c;method 3&#x201d;, the quantization parameter correction unit <b>451</b> applies the quantization parameter correction processing described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>7</b></figref> as the quantization parameter correction processing in step S<b>351</b>. That is, the quantization parameter correction unit <b>451</b> executes calculation as in the expression (16) or the expression (17) to generate the third corrected quantization parameter qP&#x2032;&#x2033;.</p><p id="p-0564" num="0548">By doing so, the value of the corrected quantization parameter falls within a range of a minimum value to a maximum value of the quantization parameter, regardless of whether or not the transform skip is applied. Furthermore, in the case of transform skip, the lower limit of the quantization parameter is further clipped with the minimum value QpPrimeTsMin of the quantization parameter at the time of the transform skip. That is, the quantization parameter correction unit <b>451</b> can correct the quantization parameter so that the quantization step size &#x394;&#x3c;1 is avoided in the inverse quantization, regardless of whether or not the transform skip is applied, in the case where the adaptive color transform is applied. Therefore, the inverse quantization processing unit <b>452</b> inversely quantizes the quantized coefficient data using the quantization parameter corrected in this manner, so that the inverse quantization unit <b>441</b> (inverse quantization inverse transform unit <b>413</b>) can suppress the reduction in the PSNR. Therefore, the image decoding device <b>400</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0565" num="0549">For example, in the case of applying the above-described &#x201c;method 4&#x201d;, the quantization parameter correction unit <b>451</b> applies the quantization parameter correction processing described with reference to the flowchart in <figref idref="DRAWINGS">FIG. <b>9</b></figref> as the quantization parameter correction processing in step S<b>351</b>. That is, the quantization parameter correction unit <b>451</b> executes calculation as in the expression (18) or the expression (17) to generate the second corrected quantization parameter qP&#x2033;.</p><p id="p-0566" num="0550">That is, in the case of the method 4, calculation substantially similar to the case of the method 3 is executed, and a similar correction result is obtained. Therefore, even in this case, the quantization parameter can be corrected so that the quantization step size &#x394;&#x3c;1 is avoided, regardless of whether or not the transform skip is applied, in the case where the adaptive color transform is applied, similarly to the case of the method 3. Therefore, the inverse quantization processing unit <b>452</b> inversely quantizes the quantized coefficient data using the quantization parameter corrected in this manner, so that the inverse quantization unit <b>441</b> (inverse quantization inverse transform unit <b>413</b>) can suppress the reduction in the PSNR. Therefore, the image decoding device <b>400</b> can suppress the reduction in the encoding efficiency.</p><p id="p-0567" num="0551">&#x3c;Decoding Unit&#x3e;</p><p id="p-0568" num="0552">Note that, in step S<b>402</b> in <figref idref="DRAWINGS">FIG. <b>19</b></figref>, the decoding unit <b>412</b> decodes the various encoding parameters (header information Hinfo, prediction mode information Pinfo, and transform information Tinfo). Therefore, in a case where the present technology is applied, the decoding unit <b>412</b> decodes the above-described various parameters to be applied to the correction of the quantization parameter. For example, in the case of applying &#x201c;method 1&#x201d;, the decoding unit <b>412</b> decodes the parameters such as the quantization parameter qPx at the CU level corresponding to the component identifier cIdx, cu_act_enabled_flag, the correction amount dqPx corresponding to the component identifier cIdx, transform_skip_flag[xTbY][yTbY][cIdx] corresponding to the component identifier cIdx, and the minimum value QpPrimeTsMin of the quantization parameter at the time of transform skip. Furthermore, in the case of applying the &#x201c;method 2&#x201d;, the encoding unit <b>314</b> decodes the minimum value &#x201c;0&#x201d; of the quantization parameter at the time of non-transform skip, in addition to the parameters to be encoded in the case of applying the &#x201c;method 1&#x201d;. Furthermore, in a case of applying the &#x201c;method 3&#x201d; or the &#x201c;method 4&#x201d;, the encoding unit <b>314</b> decodes the correction amount QpBdOffset corresponding to the bit depth, in addition to the parameters to be encoded in the case of applying the &#x201c;method 1&#x201d;.</p><p id="p-0569" num="0553">By doing so, the image decoding device <b>400</b> can obtain the signaled information. Therefore, the image decoding device <b>400</b> can suppress the reduction in the PSNR. Therefore, the image decoding device <b>400</b> can implement suppression of the reduction in the encoding efficiency.</p><p id="p-0570" num="0554">The description of the inverse quantization inverse transform process (step S<b>403</b> in <figref idref="DRAWINGS">FIG. <b>19</b></figref> and <figref idref="DRAWINGS">FIG. <b>20</b></figref>) described in the present embodiment can also be applied to the inverse quantization inverse transform processing (step S<b>307</b>) executed in the image encoding processing (<figref idref="DRAWINGS">FIG. <b>13</b></figref>).</p><heading id="h-0017" level="1">8. Supplementary Note</heading><p id="p-0571" num="0555">&#x3c;Computer&#x3e;</p><p id="p-0572" num="0556">The above-described series of processing can be executed by hardware or by software. In the case of executing the series of processing by software, a program that configures the software is installed in a computer. Here, the computer includes a computer incorporated in dedicated hardware, a computer, for example, general-purpose personal computer, capable of executing various functions by installing various programs, and the like.</p><p id="p-0573" num="0557"><figref idref="DRAWINGS">FIG. <b>22</b></figref> is a block diagram illustrating a configuration example of hardware of a computer that executes the above-described series of processing by a program.</p><p id="p-0574" num="0558">In a computer <b>800</b> illustrated in <figref idref="DRAWINGS">FIG. <b>22</b></figref>, a central processing unit (CPU) <b>801</b>, a read only memory (ROM) <b>802</b>, and a random access memory (RAM) <b>803</b> are mutually connected by a bus <b>804</b>.</p><p id="p-0575" num="0559">An input/output interface <b>810</b> is also connected to the bus <b>804</b>. An input unit <b>811</b>, an output unit <b>812</b>, a storage unit <b>813</b>, a communication unit <b>814</b>, and a drive <b>815</b> are connected to the input/output interface <b>810</b>.</p><p id="p-0576" num="0560">The input unit <b>811</b> includes, for example, a keyboard, a mouse, a microphone, a touch panel, an input terminal, and the like. The output unit <b>812</b> includes, for example, a display, a speaker, an output terminal, and the like. The storage unit <b>813</b> includes, for example, a hard disk, a RAM disk, a nonvolatile memory, and the like. The communication unit <b>814</b> includes, for example, a network interface. The drive <b>815</b> drives a removable medium <b>821</b> such as a magnetic disk, an optical disk, a magneto-optical disk, or a semiconductor memory.</p><p id="p-0577" num="0561">In the computer configured as described above, the CPU <b>801</b> loads, for example, a program stored in the storage unit <b>813</b> into the RAM <b>803</b> and executes the program via the input/output interface <b>810</b> and the bus <b>804</b>, so that the above-described series of processing is executed. Furthermore, the RAM <b>803</b> appropriately stores data and the like necessary for the CPU <b>801</b> to execute the various types of processing.</p><p id="p-0578" num="0562">The program to be executed by the computer can be recorded and applied on the removable medium <b>821</b> as a package medium or the like, for example, and can be provided. In that case, the program can be installed to the storage unit <b>813</b> via the input/output interface <b>810</b> by attaching the removable medium <b>821</b> to the drive <b>815</b>.</p><p id="p-0579" num="0563">Furthermore, this program can be provided via a wired or wireless transmission medium such as a local area network, the Internet, or digital satellite broadcast. In that case, the program can be received by the communication unit <b>814</b> and installed in the storage unit <b>813</b>.</p><p id="p-0580" num="0564">Other than the above method, the program can be installed in the ROM <b>802</b> or the storage unit <b>813</b> in advance.</p><p id="p-0581" num="0565">&#x3c;Applicable Object of Present Technology&#x3e;</p><p id="p-0582" num="0566">The present technology can be applied to any image encoding method and decoding method. That is, specifications of various types of processing regarding image encoding/decoding such as transform (inverse transform), quantization (inverse quantization), encoding (decoding), and prediction are arbitrary and are not limited to the above-described examples as long as no contradiction occurs with the above-described present technology. Furthermore, part of the processing may be omitted as long as no contradiction occurs with the above-described present technology.</p><p id="p-0583" num="0567">Furthermore, the present technology can be applied to a multi-view image encoding system that encodes a multi-view image including images of a plurality of viewpoints (views). Furthermore, the present technology can be applied to a multi-view image decoding system that decodes coded data of a multi-view image including images of a plurality of viewpoints (views). In this case, the present technology is simply applied to encoding and decoding of each viewpoint (view).</p><p id="p-0584" num="0568">Moreover, the present technology can be applied to a hierarchical image encoding (scalable encoding) system that encodes a hierarchical image that is multi-layered (hierarchized) so as to have a scalability function for a predetermined parameter. Furthermore, the present technology can be applied to a hierarchical image decoding (scalable decoding) system that decodes coded data of a hierarchical image that is multi-layered (hierarchized) so as to have a scalability function for a predetermined parameter. In this case, the present technology is simply applied to encoding/decoding of each layer (layer).</p><p id="p-0585" num="0569">Furthermore, although the quantization parameter correction device <b>100</b>, the quantization parameter correction device <b>120</b>, the quantization parameter correction device <b>140</b>, the quantization parameter correction device <b>160</b>, the image encoding device <b>300</b>, and the image decoding device <b>400</b> have been described as application examples of the present technology, the present technology can be applied to an arbitrary configuration.</p><p id="p-0586" num="0570">The present technology can be applied to, for example, various electron devices, such as transmitters and receivers (such as television receivers and mobile phones) in satellite broadcasting, cable broadcasting such as cable TV, distribution on the Internet, and distribution to terminals by cellular communication, or devices (for example, hard disk recorders and cameras) that record images on media such as optical disks, magnetic disks, and flash memories, and reproduce images from these storage media.</p><p id="p-0587" num="0571">Furthermore, the present technology can be implemented as a configuration of a part of a device such as a processor (for example, a video processor) as a system large scale integration (LSI) or the like, a module (for example, a video module) using a plurality of processors or the like, a unit (for example, a video unit) using a plurality of modules or the like, or a set (for example, a video set) in which other functions are added to the unit (that is, a configuration of a part of the device).</p><p id="p-0588" num="0572">Furthermore, for example, the present technology can also be applied to a network system including a plurality of devices. For example, the present technology may be implemented as cloud computing shared and processed in cooperation by a plurality of devices via a network. For example, the present technology may be implemented in a cloud service that provides a service regarding an image (moving image) to an arbitrary terminal such as a computer, an audio visual (AV) device, a portable information processing terminal, or an internet of things (IoT) device.</p><p id="p-0589" num="0573">Note that, in this specification, the term &#x201c;system&#x201d; means a set of a plurality of configuration elements (devices, modules (parts), and the like), and whether or not all the configuration elements are in the same casing is irrelevant. Therefore, a plurality of devices housed in separate casings and connected via a network, and one device that houses a plurality of modules in one casing are both systems.</p><p id="p-0590" num="0574">&#x3c;Field and Application to which Present Technology is Applicable&#x3e;</p><p id="p-0591" num="0575">The systems, devices, processing units, and the like to which the present technology is applied can be used in arbitrary fields such as traffic, medical care, crime prevention, agriculture, livestock industry, mining, beauty, factory, household appliance, weather, and natural surveillance, for example. Furthermore, uses in the arbitrary fields are also arbitrary.</p><p id="p-0592" num="0576">For example, the present technology can be applied to systems and devices provided for providing content for appreciation and the like. Furthermore, for example, the present technology can also be applied to systems and devices used for traffic, such as traffic condition monitoring and automatic driving control. Moreover, for example, the present technology can also be applied to systems and devices provided for security. Furthermore, for example, the present technology can be applied to systems and devices provided for automatic control of machines and the like. Moreover, for example, the present technology can also be applied to systems and devices provided for agriculture or livestock industry. Furthermore, the present technology can also be applied to systems and devices that monitor nature states such as volcanos, forests, and ocean, wildlife, and the like. Moreover, for example, the present technology can also be applied to systems and devices provided for sports.</p><heading id="h-0018" level="1">Others</heading><p id="p-0593" num="0577">Note that the &#x201c;flag&#x201d; in the present specification is information for identifying a plurality of states, and includes not only information used for identifying two states of true (1) and false (0) but also information capable of identifying three or more states. Therefore, the value that the &#x201c;flag&#x201d; can take may be, for example, a binary value of I/O or may be a ternary value or more. That is, the number of bits constituting the &#x201c;flag&#x201d; is arbitrary, and may be 1 bit or a plurality of bits. Furthermore, the identification information (including flag) is assumed to be in not only a form of including the identification information in a bitstream but also a form of including difference information of the identification information from certain reference information in a bitstream. Therefore, in the present specification, the &#x201c;flag&#x201d; and &#x201c;identification information&#x201d; include not only the information itself but also the difference information for the reference information.</p><p id="p-0594" num="0578">Furthermore, various types of information (metadata and the like) regarding coded data (bitstream) may be transmitted or recorded in any form as long as the various types of information are associated with the coded data. Here, the term &#x201c;associate&#x201d; means that, for example, one data can be used (linked) when the other data is processed. That is, data associated with each other may be collected as one data or may be individual data. For example, information associated with coded data (image) may be transmitted on a transmission path different from that of the coded data (image). Furthermore, for example, information associated with coded data (image) may be recorded on a different recording medium (or another recording area of the same recording medium) from the coded data (image). Note that this &#x201c;association&#x201d; may be a part of data instead of entire data. For example, an image and information corresponding to the image may be associated with each other in an arbitrary unit such as a plurality of frames, one frame, or a part in a frame.</p><p id="p-0595" num="0579">Note that, in the present specification, terms such as &#x201c;combining&#x201d;, &#x201c;multiplexing&#x201d;, &#x201c;adding&#x201d;, &#x201c;integrating&#x201d;, &#x201c;including&#x201d;, &#x201c;storing&#x201d;, and &#x201c;inserting&#x201d; mean putting a plurality of things into one, such as putting coded data and metadata into one data, and means one method of the above-described &#x201c;association&#x201d;.</p><p id="p-0596" num="0580">Furthermore, embodiments of the present technology are not limited to the above-described embodiments, and various modifications can be made without departing from the gist of the present technology.</p><p id="p-0597" num="0581">For example, the configuration described as one device (or processing unit) may be divided into and configured as a plurality of devices (or processing units). On the contrary, the configuration described as a plurality of devices (or processing units) may be collectively configured as one device (or processing unit). Furthermore, a configuration other than the above-described configuration may be added to the configuration of each device (or each processing unit). Moreover, a part of the configuration of a certain device (or processing unit) may be included in the configuration of another device (or another processing unit) as long as the configuration and operation of the system as a whole are substantially the same.</p><p id="p-0598" num="0582">Furthermore, for example, the above-described program may be executed in an arbitrary device. In that case, the device is only required to have necessary functions (functional blocks and the like) and obtain necessary information.</p><p id="p-0599" num="0583">Furthermore, for example, each step of one flowchart may be executed by one device, or may be shared and executed by a plurality of devices. Moreover, in a case where a plurality of processes is included in one step, the plurality of processes may be executed by one device, or may be shared and executed by a plurality of devices. In other words, the plurality of processes included in one step can be executed as processes of a plurality of steps. Conversely, the processing described as a plurality of steps can be collectively executed as one step.</p><p id="p-0600" num="0584">Furthermore, the program executed by the computer may have the following characteristics. For example, the processing of steps describing the program may be executed in time series in the order described in the present specification. Furthermore, pieces of the processing of steps describing the program may be executed in parallel. Moreover, the processing of steps describing the program may be individually executed at necessary timing such as when called. That is, the processing of each step may be executed in an order different from the above-described order as long as no contradiction occurs. Furthermore, processing of steps describing the program may be executed in parallel with processing of another program. Moreover, the processing of steps describing the program may be executed in combination with processing of another program.</p><p id="p-0601" num="0585">Furthermore, for example, a plurality of techniques related to the present technology can be implemented independently as a single body as long as there is no contradiction. Of course, an arbitrary number of the present technologies can be implemented together. For example, part or whole of the present technology described in any of the embodiments can be implemented in combination with part or whole of the present technology described in another embodiment. Further, part or whole of the above-described arbitrary present technology can be implemented in combination with another technology not described above.</p><p id="p-0602" num="0586">Note that the present technology can also have the following configurations.</p><p id="p-0603" num="0587">(1) An image processing device including:</p><p id="p-0604" num="0588">a quantization parameter correction unit configured to correct a quantization parameter on the basis of a parameter regarding adaptive color transform and further correct the quantization parameter on the basis of a parameter regarding transform skip; and</p><p id="p-0605" num="0589">a quantization unit configured to quantize coefficient data of an image to be encoded by using a corrected quantization parameter that is the quantization parameter corrected by the quantization parameter correction unit.</p><p id="p-0606" num="0590">(2) The image processing device according to (1), in which,</p><p id="p-0607" num="0591">in a case of applying the adaptive color transform, the quantization parameter correction unit corrects the quantization parameter with a correction amount corresponding to a component to be processed.</p><p id="p-0608" num="0592">(3) The image processing device according to (2), in which</p><p id="p-0609" num="0593">the correction amount is &#x201c;0&#x201d; in a case of not applying the adaptive color transform.</p><p id="p-0610" num="0594">(4) The image processing device according to any one of (1) to (3), in which,</p><p id="p-0611" num="0595">in a case of applying the transform skip, the quantization parameter correction unit clips a lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with a preset minimum value of the quantization parameter of a case of applying the transform skip.</p><p id="p-0612" num="0596">(5) The image processing device according to (4), in which,</p><p id="p-0613" num="0597">in a case of not applying the transform skip, the quantization parameter correction unit omits the clip of the lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform.</p><p id="p-0614" num="0598">(6) The image processing device according to any one of (1) to (5), in which,</p><p id="p-0615" num="0599">in a case of not applying the transform skip, the quantization parameter correction unit clips a lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with a preset minimum value of the quantization parameter.</p><p id="p-0616" num="0600">(7) The image processing device according to (6),</p><p id="p-0617" num="0000">in which</p><p id="p-0618" num="0601">the minimum value of the quantization parameter is &#x201c;0&#x201d;.</p><p id="p-0619" num="0602">(8) The image processing device according to any one of (1) to (7), in which,</p><p id="p-0620" num="0603">in a case of applying the transform skip, the quantization parameter correction unit clips a lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with a preset minimum value of the quantization parameter of the case of applying the transform skip, and clips an upper limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with a preset sum of a maximum value of the quantization parameter and a correction amount based on a bit depth.</p><p id="p-0621" num="0604">(9) The image processing device according to (8), in which,</p><p id="p-0622" num="0605">in a case of not applying the transform skip, the quantization parameter correction unit clips the lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with the preset minimum value of the quantization parameter, and clips the upper limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with the preset sum of a maximum value of the quantization parameter and a correction amount based on a bit depth.</p><p id="p-0623" num="0606">(10) An image processing method including:</p><p id="p-0624" num="0607">correcting a quantization parameter on the basis of a parameter regarding adaptive color transform and further correcting the quantization parameter on the basis of a parameter regarding transform skip; and</p><p id="p-0625" num="0608">quantizing coefficient data of an image to be encoded by using a corrected quantization parameter that is the quantization parameter that has been corrected.</p><p id="p-0626" num="0609">(11) An image processing device including:</p><p id="p-0627" num="0610">a quantization parameter correction unit configured to correct a quantization parameter on the basis of a parameter regarding adaptive color transform and further correct the quantization parameter on the basis of a parameter regarding transform skip; and</p><p id="p-0628" num="0611">an inverse quantization unit configured to inversely quantize quantized coefficient data that is obtained by quantizing coefficient data of an image by using a corrected quantization parameter that is the quantization parameter corrected by the quantization parameter correction unit.</p><p id="p-0629" num="0612">(12) The image processing device according to (11), in which,</p><p id="p-0630" num="0613">in a case of applying the adaptive color transform, the quantization parameter correction unit corrects the quantization parameter with a correction amount corresponding to a component to be processed.</p><p id="p-0631" num="0614">(13) The image processing device according to (12), in which</p><p id="p-0632" num="0615">the correction amount is &#x201c;0&#x201d; in a case of not applying the adaptive color transform.</p><p id="p-0633" num="0616">(14) The image processing device according to any one of (11) to (13), in which,</p><p id="p-0634" num="0617">in a case of applying the transform skip, the quantization parameter correction unit clips a lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with a preset minimum value of the quantization parameter of a case of applying the transform skip.</p><p id="p-0635" num="0618">(15) The image processing device according to (14), in which,</p><p id="p-0636" num="0619">in a case of not applying the transform skip, the quantization parameter correction unit omits the clip of the lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform.</p><p id="p-0637" num="0620">(16) The image processing device according to any one of (11) to (15), in which,</p><p id="p-0638" num="0621">in a case of not applying the transform skip, the quantization parameter correction unit clips a lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with a preset minimum value of the quantization parameter.</p><p id="p-0639" num="0622">(17) The image processing device according to (16), in which</p><p id="p-0640" num="0623">the minimum value of the quantization parameter is &#x201c;0&#x201d;.</p><p id="p-0641" num="0624">(18) The image processing device according to any one of (11) to (17), in which,</p><p id="p-0642" num="0625">in a case of applying the transform skip, the quantization parameter correction unit clips a lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with a preset minimum value of the quantization parameter of the case of applying the transform skip, and clips an upper limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with a preset sum of a maximum value of the quantization parameter and a correction amount based on a bit depth.</p><p id="p-0643" num="0626">(19) The image processing device according to (18), in which,</p><p id="p-0644" num="0627">in a case of not applying the transform skip, the quantization parameter correction unit clips the lower limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with the preset minimum value of the quantization parameter, and clips the upper limit of the quantization parameter corrected on the basis of the parameter regarding adaptive color transform with the preset sum of a maximum value of the quantization parameter and a correction amount based on a bit depth.</p><p id="p-0645" num="0628">(20) An image processing method including:</p><p id="p-0646" num="0629">correcting a quantization parameter on the basis of a parameter regarding adaptive color transform and further correcting the quantization parameter on the basis of a parameter regarding transform skip; and</p><p id="p-0647" num="0630">inversely quantizing quantized coefficient data that is obtained by quantizing coefficient data of an image by using a corrected quantization parameter that is the quantization parameter that has been corrected.</p><heading id="h-0019" level="1">REFERENCE SIGNS LIST</heading><p id="p-0648" num="0000"><ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0631"><b>100</b> Quantization parameter correction device</li>    <li id="ul0003-0002" num="0632"><b>101</b> First correction unit</li>    <li id="ul0003-0003" num="0633"><b>102</b> Second correction unit</li>    <li id="ul0003-0004" num="0634"><b>120</b> Quantization parameter correction device</li>    <li id="ul0003-0005" num="0635"><b>121</b> First correction unit</li>    <li id="ul0003-0006" num="0636"><b>122</b> Second correction unit</li>    <li id="ul0003-0007" num="0637"><b>140</b> Quantization parameter correction device</li>    <li id="ul0003-0008" num="0638"><b>141</b> First correction unit</li>    <li id="ul0003-0009" num="0639"><b>142</b> Second correction unit</li>    <li id="ul0003-0010" num="0640"><b>143</b> Third correction unit</li>    <li id="ul0003-0011" num="0641"><b>160</b> Quantization parameter correction device</li>    <li id="ul0003-0012" num="0642"><b>161</b> First correction unit</li>    <li id="ul0003-0013" num="0643"><b>162</b> Second correction unit</li>    <li id="ul0003-0014" num="0644"><b>300</b> Image encoding device</li>    <li id="ul0003-0015" num="0645"><b>301</b> Control unit</li>    <li id="ul0003-0016" num="0646"><b>313</b> Transform quantization unit</li>    <li id="ul0003-0017" num="0647"><b>314</b> Encoding unit</li>    <li id="ul0003-0018" num="0648"><b>341</b> Adaptive color transform unit</li>    <li id="ul0003-0019" num="0649"><b>342</b> Orthogonal transform unit</li>    <li id="ul0003-0020" num="0650"><b>343</b> Quantization unit</li>    <li id="ul0003-0021" num="0651"><b>351</b> Quantization parameter correction unit</li>    <li id="ul0003-0022" num="0652"><b>352</b> Quantization processing unit</li>    <li id="ul0003-0023" num="0653"><b>400</b> Image decoding device</li>    <li id="ul0003-0024" num="0654"><b>401</b> Control unit</li>    <li id="ul0003-0025" num="0655"><b>412</b> Decoding unit</li>    <li id="ul0003-0026" num="0656"><b>413</b> Inverse quantization inverse transform unit</li>    <li id="ul0003-0027" num="0657"><b>441</b> Inverse quantization unit</li>    <li id="ul0003-0028" num="0658"><b>442</b> Inverse orthogonal transform unit</li>    <li id="ul0003-0029" num="0659"><b>443</b> Inverse adaptive color transform unit</li>    <li id="ul0003-0030" num="0660"><b>451</b> Quantization parameter correction unit</li>    <li id="ul0003-0031" num="0661"><b>452</b> Inverse quantization processing unit</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001 MATH-US-00001-2" nb-file="US20230007255A1-20230105-M00001.NB"><img id="EMI-M00001" he="21.17mm" wi="76.20mm" file="US20230007255A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image processing device comprising:<claim-text>a quantization parameter correction unit configured to correct a quantization parameter on a basis of a parameter regarding adaptive color transform and further correct the quantization parameter on a basis of a parameter regarding transform skip; and</claim-text><claim-text>a quantization unit configured to quantize coefficient data of an image to be encoded by using a corrected quantization parameter that is the quantization parameter corrected by the quantization parameter correction unit.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The image processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein,<claim-text>in a case of applying the adaptive color transform, the quantization parameter correction unit corrects the quantization parameter with a correction amount corresponding to a component to be processed.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The image processing device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the correction amount is &#x201c;0&#x201d; in a case of not applying the adaptive color transform.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The image processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein,<claim-text>in a case of applying the transform skip, the quantization parameter correction unit clips a lower limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform with a preset minimum value of the quantization parameter of a case of applying the transform skip.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The image processing device according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein,<claim-text>in a case of not applying the transform skip, the quantization parameter correction unit omits the clip of the lower limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The image processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein,<claim-text>in a case of not applying the transform skip, the quantization parameter correction unit clips a lower limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform with a preset minimum value of the quantization parameter.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The image processing device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein<claim-text>the minimum value of the quantization parameter is &#x201c;0&#x201d;.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The image processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein,<claim-text>in a case of applying the transform skip, the quantization parameter correction unit clips a lower limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform with a preset minimum value of the quantization parameter of the case of applying the transform skip, and clips an upper limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform with a preset sum of a maximum value of the quantization parameter and a correction amount based on a bit depth.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The image processing device according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein,<claim-text>in a case of not applying the transform skip, the quantization parameter correction unit clips the lower limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform with the preset minimum value of the quantization parameter, and clips the upper limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform with the preset sum of a maximum value of the quantization parameter and a correction amount based on a bit depth.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. An image processing method comprising:<claim-text>correcting a quantization parameter on a basis of a parameter regarding adaptive color transform and further correcting the quantization parameter on a basis of a parameter regarding transform skip; and</claim-text><claim-text>quantizing coefficient data of an image to be encoded by using a corrected quantization parameter that is the quantization parameter that has been corrected.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. An image processing device comprising:<claim-text>a quantization parameter correction unit configured to correct a quantization parameter on a basis of a parameter regarding adaptive color transform and further correct the quantization parameter on a basis of a parameter regarding transform skip; and</claim-text><claim-text>an inverse quantization unit configured to inversely quantize quantized coefficient data that is obtained by quantizing coefficient data of an image by using a corrected quantization parameter that is the quantization parameter corrected by the quantization parameter correction unit.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The image processing device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein,<claim-text>in a case of applying the adaptive color transform, the quantization parameter correction unit corrects the quantization parameter with a correction amount corresponding to a component to be processed.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The image processing device according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein<claim-text>the correction amount is &#x201c;0&#x201d; in a case of not applying the adaptive color transform.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The image processing device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein,<claim-text>in a case of applying the transform skip, the quantization parameter correction unit clips a lower limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform with a preset minimum value of the quantization parameter of a case of applying the transform skip.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The image processing device according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein,<claim-text>in a case of not applying the transform skip, the quantization parameter correction unit omits the clip of the lower limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The image processing device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein,<claim-text>in a case of not applying the transform skip, the quantization parameter correction unit clips a lower limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform with a preset minimum value of the quantization parameter.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The image processing device according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein<claim-text>the minimum value of the quantization parameter is &#x201c;0&#x201d;.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The image processing device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein,<claim-text>in a case of applying the transform skip, the quantization parameter correction unit clips a lower limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform with a preset minimum value of the quantization parameter of the case of applying the transform skip, and clips an upper limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform with a preset sum of a maximum value of the quantization parameter and a correction amount based on a bit depth.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The image processing device according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein,<claim-text>in a case of not applying the transform skip, the quantization parameter correction unit clips the lower limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform with the preset minimum value of the quantization parameter, and clips the upper limit of the quantization parameter corrected on a basis of the parameter regarding adaptive color transform with the preset sum of a maximum value of the quantization parameter and a correction amount based on a bit depth.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. An image processing method comprising:<claim-text>correcting a quantization parameter on a basis of a parameter regarding adaptive color transform and further correcting the quantization parameter on a basis of a parameter regarding transform skip; and</claim-text><claim-text>inversely quantizing quantized coefficient data that is obtained by quantizing coefficient data of an image by using a corrected quantization parameter that is the quantization parameter that has been corrected.</claim-text></claim-text></claim></claims></us-patent-application>